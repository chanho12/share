{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6cdda42-096c-48c3-b264-407ec7a3c06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads a JSON file with multiple JSON objects (one per line) and returns the data as a list of dictionaries.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): The path to the JSON file.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of dictionaries containing the data from the JSON file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                try:\n",
    "                    json_obj = json.loads(line)\n",
    "                    data.append(json_obj)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"JSONDecodeError in line: {line.strip()}\")\n",
    "                    print(f\"Error message: {e}\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file at {file_path} does not exist.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2ffa6f7-c5ae-462f-898a-55163009ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_without_tag(prompt):\n",
    "    prompts = prompt['prompt']\n",
    "\n",
    "    last_utter = f\"{prompt['last_speaker']} :\" \n",
    "\n",
    "    dialogue = prompts + last_utter\n",
    "    \n",
    "    return dialogue, prompt['last_speaker'], prompt['answer']\n",
    "    \n",
    "\n",
    "def extract_data_with_tag(prompt):\n",
    "    prompts = prompt['prompt']\n",
    "\n",
    "    last_utter = f\"{prompt['last_speaker']} : ({prompt['gold_tag']})\" \n",
    "\n",
    "    dialogue = prompts + last_utter\n",
    "    \n",
    "    return dialogue, prompt['last_speaker'], prompt['gold_tag'], prompt['answer']\n",
    "\n",
    "def distinct_ngrams(sentences, n):\n",
    "    \"\"\"\n",
    "    Calculate the distinct-n metric for a list of sentences.\n",
    "    \n",
    "    Args:\n",
    "        sentences (list of str): The list of sentences generated by the model.\n",
    "        n (int): The n-gram length.\n",
    "\n",
    "    Returns:\n",
    "        float: The distinct-n score.\n",
    "    \"\"\"\n",
    "    ngrams = Counter()\n",
    "    total_ngrams = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokens = sentence.split()\n",
    "        sentence_ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "        ngrams.update(sentence_ngrams)\n",
    "        total_ngrams += len(tokens) - n + 1\n",
    "    \n",
    "    return len(ngrams) / total_ngrams if total_ngrams > 0 else 0\n",
    "\n",
    "\n",
    "def get_ppl(text ,model, tokenizer):\n",
    "    encodings = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    max_length = model.config.max_position_embeddings\n",
    "    stride = 512\n",
    "    seq_len = encodings.input_ids.size(1)\n",
    "    \n",
    "    nlls = []\n",
    "    prev_end_loc = 0\n",
    "    for begin_loc in tqdm(range(0, seq_len, stride)):\n",
    "        end_loc = min(begin_loc + max_length, seq_len)\n",
    "        trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "        input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
    "        target_ids = input_ids.clone()\n",
    "        target_ids[:, :-trg_len] = -100\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=target_ids)\n",
    "    \n",
    "            # loss is calculated using CrossEntropyLoss which averages over valid labels\n",
    "            # N.B. the model only calculates loss over trg_len - 1 labels, because it internally shifts the labels\n",
    "            # to the left by 1. \n",
    "            neg_log_likelihood = outputs.loss\n",
    "    \n",
    "        nlls.append(neg_log_likelihood)\n",
    "    \n",
    "        prev_end_loc = end_loc\n",
    "        if end_loc == seq_len:\n",
    "            break\n",
    "    ppl = torch.exp(torch.stack(nlls).mean())\n",
    "    return ppl    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db1787f2-0d79-49be-9de8-ce82fdb060eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = '1'\n",
    "\n",
    "import re\n",
    "import torch\n",
    "import evaluate\n",
    "from evaluate import load\n",
    "current_dir = os.getcwd()\n",
    "episode_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(episode_dir)\n",
    "\n",
    "from utils.model_utils import get_peft_checkpoint, generate, get_peft_checkpoint_\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer)\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "from collections import Counter\n",
    "from accelerate import Accelerator\n",
    "\n",
    "\n",
    "def evaluation_chat_system(num, prompt , model, tokenizer, device, bert_eval,rough_eval,bleu_eval):\n",
    "\n",
    "    \n",
    "    if num == 2:\n",
    "        print(\"This is a wo tag evaluation\")\n",
    "        print(prompt)\n",
    "        input__, person, utterance,  = extract_data_without_tag(prompt)\n",
    "        print(f'Last word -> {person} : \"{utterance}\"')\n",
    "        \n",
    "        input_ = tokenizer(input__, return_tensors = 'pt').to(device)     \n",
    "        output = generate(model,tokenizer,\n",
    "                                      input_,\n",
    "                                      num_beams=1,\n",
    "                                      num_return_sequences=1,\n",
    "                                      max_new_tokens=100)\n",
    "\n",
    "\n",
    "        \n",
    "        response = output.replace(input__, '')\n",
    "        response = response.split(\"\\n\")[0]\n",
    "        print(f\"prediction : {response}\")\n",
    "        print(f\"Real answer : {utterance}\")\n",
    "\n",
    "        reference = [utterance.split()]\n",
    "        candidate = response.split()\n",
    "\n",
    "            \n",
    "        output_list = [response.strip()]\n",
    "        last_utter_list = [utterance.strip()]\n",
    "        #evalation\n",
    "        bert_score = bert_eval.compute(predictions=output_list, references=last_utter_list, lang=\"en\")\n",
    "        rouge_score = rouge_eval.compute(predictions=output_list, references=last_utter_list)\n",
    "\n",
    "        ## bleu\n",
    "\n",
    "        weights_unigram = (1, 0, 0, 0)\n",
    "        bleu_unigram = sentence_bleu(reference, candidate, weights=weights_unigram, smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "        weights_bigram = (0.5, 0.5, 0, 0)\n",
    "        bleu_bigram = sentence_bleu(reference, candidate, weights=weights_bigram, smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "        ### ppl\n",
    "        ppl = get_ppl(response, model, tokenizer)\n",
    "        \n",
    "        print(f\"Bert Score : {bert_score}\")\n",
    "        print(f\"Rouge Score : {rouge_score}\")\n",
    "        print(f\"bleu 1/2 : {bleu_unigram} {bleu_bigram}\")\n",
    "        print(f\"ppl : {ppl}\")\n",
    "        return bert_score, rouge_score, bleu_unigram, bleu_bigram, response ,ppl\n",
    "    \n",
    "    \n",
    "    if num == 3:\n",
    "        print(\"This is with tag evaluation\")\n",
    "        print(prompt)\n",
    "        input__ , person, trait, utterance = extract_data_tag(prompt)\n",
    "        print(f'Last word -> {person} : ({trait}) \"{utterance}\"')\n",
    "        input_ = tokenizer(input__, return_tensors = 'pt').to(device)\n",
    "     \n",
    "        output = generate(model,tokenizer,\n",
    "                                      input_,\n",
    "                                      num_beams=1,\n",
    "                                      num_return_sequences=1,\n",
    "                                      max_new_tokens=100)\n",
    "\n",
    "\n",
    "        print(input__)\n",
    "\n",
    "        print(output)\n",
    "\n",
    "        \n",
    "        response = output.replace(input__, '')\n",
    "        print(response)\n",
    "        \n",
    "        response = response.split(\"\\n\")[0]\n",
    "        print(response)\n",
    "\n",
    "        assert False\n",
    "        print(f\"prediction : {response}\")\n",
    "        print(f\"Real answer : {utterance}\")\n",
    "        \n",
    "            \n",
    "        output_list = [response.strip()]\n",
    "        last_utter_list = [utterance.strip()]\n",
    "        bert_score = bert_eval.compute(predictions=output_list, references=last_utter_list, lang=\"en\")\n",
    "        rouge_score = rouge_eval.compute(predictions=output_list, references=last_utter_list)\n",
    "\n",
    "        reference = [utterance.split()]\n",
    "        candidate = response.split()\n",
    "\n",
    "        \n",
    "        weights_unigram = (1, 0, 0, 0)\n",
    "        bleu_unigram = sentence_bleu(reference, candidate, weights=weights_unigram, smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "        weights_bigram = (0.5, 0.5, 0, 0)\n",
    "        bleu_bigram = sentence_bleu(reference, candidate, weights=weights_bigram, smoothing_function=SmoothingFunction().method1)\n",
    "        \n",
    "        ppl = get_ppl(response, model, tokenizer)\n",
    "        infer = utterance\n",
    "        print(f\"Bert Score : {bert_score}\")\n",
    "        print(f\"Rouge Score : {rouge_score}\")\n",
    "        print(f\"bleu Score : {bleu_score}\")\n",
    "        print(f\"ppl : {ppl}\")\n",
    "        \n",
    "        return bert_score, rouge_score, bleu_score, infer, ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b6e550-1516-4860-8d0c-d2d280e7cc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be639074321477ab83bbbffcf359b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = '/home/chanho/Model/SHARE/Refactorizing/result/model_save/gemma with tag'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, tokenizer = get_peft_checkpoint(path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b627977-14ed-44db-91af-108979dfc7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd21ab89-9aea-4907-a847-62cfb090e1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/chanho/Model/SHARE/Refactorizing/result/dataset/test_without_tag.json'\n",
    "json_data = read_json_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71d5c1ba-1c6b-4819-836e-2eb10d0d1433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLOLA: Hello, Mr. Neff. It's me.\\nNEFF: Something the matter?\\nLOLA: I've been waiting for you.\\nNEFF: For me? What for?\\nLOLA: I thought you could let me ride with you, if you're going my way.\\n\\n\",\n",
       " 'answer': \"Which way would that be? Oh, sure. Vermont and Franklin. North- west corner, wasn't it? Be glad to, Miss Dietrichson.\",\n",
       " 'gold_tag': 'NEFF is familiar with the local geographic area , NEFF references specific streets',\n",
       " 'last_speaker': 'NEFF'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6a05f1c-a76e-423f-b3c4-3ad53bea4ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = []\n",
    "rough = []\n",
    "bleu_1_list = []\n",
    "bleu_2_list = []\n",
    "infer = []\n",
    "ppl_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5acf90aa-20e6-4b88-b067-b744aaffb3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLOLA: Hello, Mr. Neff. It's me.\\nNEFF: Something the matter?\\nLOLA: I've been waiting for you.\\nNEFF: For me? What for?\\nLOLA: I thought you could let me ride with you, if you're going my way.\\n\\n\", 'answer': \"Which way would that be? Oh, sure. Vermont and Franklin. North- west corner, wasn't it? Be glad to, Miss Dietrichson.\", 'gold_tag': 'NEFF is familiar with the local geographic area , NEFF references specific streets', 'last_speaker': 'NEFF'}\n",
      "Last word -> NEFF : \"Which way would that be? Oh, sure. Vermont and Franklin. North- west corner, wasn't it? Be glad to, Miss Dietrichson.\"\n",
      "prediction :  Okay!\n",
      "Real answer : Which way would that be? Oh, sure. Vermont and Franklin. North- west corner, wasn't it? Be glad to, Miss Dietrichson.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8356287479400635], 'recall': [0.7825762033462524], 'f1': [0.808232843875885], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11553.6015625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEFF: Roller skating, eh? You like roller skating?\\nLOLA: I can take it or leave it.\\nNEFF: Only tonight you're leaving it?\\nLOLA: Yes, I am. You see, Mr. Neff, I'm having a very tough time at home. My father doesn't understand me and Phyllis hates me.\\nNEFF: That does sound tough, all right.\\nLOLA: That's why I have to lie sometimes.\\nNEFF: You mean it's not Vermont and Franklin.\\nLOLA: It's Vermont and Franklin all right. Only it's not Anne Matthews. It's Nino Zachetti. You won't tell on me, will you?\\nNEFF: I'd have to think it over.\\nLOLA: Nino's not what my father says at all. He just had bad luck. He was doing pre-med at U.S.C. and working nights as an usher in a theater downtown. He got behind in his credits and flunked out. Then he lost his job for talking back. He's so hot- headed.\\nNEFF: That comes expensive, doesn't it?\\nLOLA: I guess my father thinks nobody's good enough for his daughter except maybe the guy that owns Standard Oil. Would you like a stick of gum?\\nNEFF: Never use it, thanks.\\nLOLA: I can't give Nino up. I wish father could see it my way.\\nNEFF: It'll straighten out all right, Miss\\n\\n\", 'answer': 'I suppose it will sometime. This is the corner right here, Mr. Neff. There he is. By the bus stop.', 'gold_tag': \"LOLA's temporal information: Lola is undergoing a challenging time at home presently, and her relationship with Nino is also current\", 'last_speaker': 'LOLA'}\n",
      "Last word -> LOLA : \"I suppose it will sometime. This is the corner right here, Mr. Neff. There he is. By the bus stop.\"\n",
      "prediction : I'm glad that's settled.\n",
      "Real answer : I suppose it will sometime. This is the corner right here, Mr. Neff. There he is. By the bus stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8692246675491333], 'recall': [0.8588073253631592], 'f1': [0.8639845848083496], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307691, 'rouge2': 0.0, 'rougeL': 0.07692307692307691, 'rougeLsum': 0.07692307692307691}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.772769927978516\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLOLA: Hello, Mr. Neff.\\nNEFF: Hello.\\nLOLA: Lola Dietrichson. Don't you remember me?\\nNEFF: Yes. Of course.\\nLOLA: Could I talk to you, just for a few minutes? Somewhere where we can be alone?\\n\\n\", 'answer': 'Sure. Come on into my office.', 'gold_tag': 'NEFF has an office , NEFF implies a professional occupation', 'last_speaker': 'NEFF'}\n",
      "Last word -> NEFF : \"Sure. Come on into my office.\"\n",
      "prediction :  You were very funny.\n",
      "Real answer : Sure. Come on into my office.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8639878034591675], 'recall': [0.8563694953918457], 'f1': [0.8601617813110352], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 395.3274230957031\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEFF: Is it something to do with -- what happened?\\nLOLA: Yes, Mr. Neff. It's about my father's death.\\n\\n\", 'answer': \"I'm terribly sorry, Miss Dietrichson.\", 'gold_tag': \"NEFF is aware of Lola's father's death , NEFF is empathetic about it\", 'last_speaker': 'NEFF'}\n",
      "Last word -> NEFF : \"I'm terribly sorry, Miss Dietrichson.\"\n",
      "prediction :  My father was murdered by some bad man on his way to work this morning.\n",
      "Real answer : I'm terribly sorry, Miss Dietrichson.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8274996280670166], 'recall': [0.840857744216919], 'f1': [0.8341252207756042], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 35.40941619873047\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEFF: Why are you crying? You won't tell me?\\nLOLA: Of course I will, Walter. I wouldn't tell anybody else but you. It's about Nino.\\nNEFF: Zachetti? What about him?\\nLOLA: They killed my father together. He and Phyllis. He helped her do it. I know he did.\\nNEFF: What makes you say that?\\nLOLA: I've been following him. He's at her house, night after night. It was Phyllis and him all the time. Maybe he was going with me just for a blind. And the night of the murder --\\nNEFF: You promised not to talk that way any more.\\nLOLA: -- he was supposed to pick me up after a lecture at U.C.L.A. -- but he never showed up. He said he was sick. Sick! He couldn't show up, because the train was leaving with my father on it. Maybe I'm just crazy. Maybe it's all just in my mind.\\nNEFF: Sure, it's all in your mind.\\n\\n\", 'answer': 'I only wish it was, Walter, because I still love him.', 'gold_tag': 'LOLA still harbors love for Nino', 'last_speaker': 'LOLA'}\n",
      "Last word -> LOLA : \"I only wish it was, Walter, because I still love him.\"\n",
      "prediction :  Is he gone?\n",
      "Real answer : I only wish it was, Walter, because I still love him.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8634580373764038], 'recall': [0.8603291511535645], 'f1': [0.8618907332420349], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1100.4786376953125\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: Our son just called me a bitch.\\n\\n', 'answer': \"You're not a bitch.\", 'gold_tag': 'EDDIE is a supportive husband , EDDIE is a supportive father', 'last_speaker': 'EDDIE'}\n",
      "Last word -> EDDIE : \"You're not a bitch.\"\n",
      "prediction :  No. Your mother said she hates you too, for being such a bitch! What are you gonna do?\n",
      "Real answer : You're not a bitch.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8449645638465881], 'recall': [0.8823566436767578], 'f1': [0.8632559180259705], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2608695652173913, 'rouge2': 0.09523809523809523, 'rougeL': 0.2608695652173913, 'rougeLsum': 0.2608695652173913}\n",
      "bleu 1/2 : 0.05555555555555554 0.018077538151554672\n",
      "ppl : 44.035003662109375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: So let me get this straight. No airline will claim ownership of the engine. So we have to wait for the FAA to decide who fixes my roof. Fuck that. We're taking the money out of savings.\\n\\n\", 'answer': '(quoting Rod Serling) You are entering a new dimension of sight and sound...', 'gold_tag': 'EDDIE is familiar with the work of Rod Serling , EDDIE has a potential interest in science fiction or classic television', 'last_speaker': 'EDDIE'}\n",
      "Last word -> EDDIE : \"(quoting Rod Serling) You are entering a new dimension of sight and sound...\"\n",
      "prediction :  Why don't we just eat an olive every day or something? That sounds a little better.\n",
      "Real answer : (quoting Rod Serling) You are entering a new dimension of sight and sound...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.828396201133728], 'recall': [0.8411673903465271], 'f1': [0.8347329497337341], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06666666666666667, 'rouge2': 0.0, 'rougeL': 0.06666666666666667, 'rougeLsum': 0.06666666666666667}\n",
      "bleu 1/2 : 0.0625 0.02041241452319315\n",
      "ppl : 32.58978271484375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: He's too old to be behaving this way.\\n\\n\", 'answer': 'Oh, I say we buy him a moped.', 'gold_tag': 'EDDIE suggests buying a moped , EDDIE has a pragmatic, solution-oriented attitude', 'last_speaker': 'EDDIE'}\n",
      "Last word -> EDDIE : \"Oh, I say we buy him a moped.\"\n",
      "prediction :  [Chuckling] Oh, man!\n",
      "Real answer : Oh, I say we buy him a moped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8216872215270996], 'recall': [0.8512065410614014], 'f1': [0.836186408996582], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0.06295853427918728 0.024383735476492117\n",
      "ppl : 109.24520111083984\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWERNER: You've been here since you were a baby -- you know nothing of America --\\nJULIUS: I know it is the cradle of democracy and the land of the free; besides, I speak twelve languages -- I'm sure I can get a job.\\nWERNER: They're a simple people; rather primitive, not like us.\\n\\n\", 'answer': 'My brother will look after me.', 'gold_tag': 'JULIUS believes his brother will take care of him once he reaches America', 'last_speaker': 'JULIUS'}\n",
      "Last word -> JULIUS : \"My brother will look after me.\"\n",
      "prediction :  Why have you not come to know us?\n",
      "Real answer : My brother will look after me.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8454692363739014], 'recall': [0.8642604351043701], 'f1': [0.8547616004943848], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 80.92160034179688\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJULIUS: It's your only copy --\\nWERNER: -- My need for it is only sentimental -- yours may be practical --\\nJULIUS: Thank you -- I'll miss you.\\n\\n\", 'answer': \"I'll miss you.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'WERNER'}\n",
      "Last word -> WERNER : \"I'll miss you.\"\n",
      "prediction :  I'll see you around -- 1459036736103.\n",
      "Real answer : I'll miss you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8243613243103027], 'recall': [0.9198824167251587], 'f1': [0.8695063591003418], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.6, 'rouge2': 0.25, 'rougeL': 0.6, 'rougeLsum': 0.6}\n",
      "bleu 1/2 : 0.16666666666666669 0.05773502691896258\n",
      "ppl : 34.73563003540039\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWERNER: And...?\\nJULIUS: Well, if a woman loved my brother enough to marry him, she might have a sister who'd feel the same way about me. That often happens with twins, you know.\\nWERNER: Julius -- please -- don't get your hopes up. Your brother doesn't even know you exist.\\n\\n\", 'answer': \"Of course he does. I've always known there was something missing in my life! And deep down, I'm sure Vincent feels the same way! He's probably just like meeeee!\", 'gold_tag': \"Julius has an optimist and romantic outlook on life , Julius has a twin brother whom he hasn't met yet\", 'last_speaker': 'JULIUS'}\n",
      "Last word -> JULIUS : \"Of course he does. I've always known there was something missing in my life! And deep down, I'm sure Vincent feels the same way! He's probably just like meeeee!\"\n",
      "prediction :  Are you serious ? You'd marry my brother ?\n",
      "Real answer : Of course he does. I've always known there was something missing in my life! And deep down, I'm sure Vincent feels the same way! He's probably just like meeeee!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8289239406585693], 'recall': [0.8258674144744873], 'f1': [0.8273928761482239], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05, 'rouge2': 0.0, 'rougeL': 0.05, 'rougeLsum': 0.05}\n",
      "bleu 1/2 : 0.012040891469099537 0.004038637775190581\n",
      "ppl : 125.05367279052734\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBESS: Whatever is the matter with you? Your behaviour is so out of the ordinary.\\n\\n', 'answer': 'I just feel like keeping to myself today...', 'gold_tag': 'GEORGIANA is introverted , GEORGIANA prefers solitude at times', 'last_speaker': 'GEORGIANA'}\n",
      "Last word -> GEORGIANA : \"I just feel like keeping to myself today...\"\n",
      "prediction :  Your mother. I just need my mother. I can barely feel her when she is so far away.\n",
      "Real answer : I just feel like keeping to myself today...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8610793948173523], 'recall': [0.8483717441558838], 'f1': [0.8546782732009888], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23076923076923078, 'rouge2': 0.08333333333333333, 'rougeL': 0.23076923076923078, 'rougeLsum': 0.23076923076923078}\n",
      "bleu 1/2 : 0.16666666666666669 0.0990147542976674\n",
      "ppl : 37.88048553466797\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGEORGIANA: I may not have the authority to remove you from this house, but I can at least order you out of my room.\\nBESS: Won't you please let me explain?\\nGEORGIANA: There is nothing to explain. I trusted you, I made you my confidante, and you repaid me by stealing what is mine.\\nBESS: This is my only chance of ever seeing my children again. The Duke is the most powerful peer in England. He is my only chance.\\nGEORGIANA: There are limits to the sacrifices one makes to see one's children.\\nBESS: No, there aren't. No limits whatsoever.\\n\\n\", 'answer': 'Get out of here. We have nothing more to say to one another.', 'gold_tag': 'GEORGIANA has a strong sense of personal boundaries, property, and trust', 'last_speaker': 'GEORGIANA'}\n",
      "Last word -> GEORGIANA : \"Get out of here. We have nothing more to say to one another.\"\n",
      "prediction : I would know\n",
      "Real answer : Get out of here. We have nothing more to say to one another.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8393616676330566], 'recall': [0.8305653929710388], 'f1': [0.8349403142929077], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 261.1163635253906\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGEORGIANA: Thank you for coming.\\nBESS: I couldn’t not be with you.\\nGEORGIANA: I count it a triumph we have become friends again when fate has been so intent on keeping us rivals.\\nBESS: So do I. The Duke is for my boys only. You are for me.\\nGEORGIANA: Bess, how will I do this?\\n\\n', 'answer': 'For Charlotte, for Harryo, for little G, for Hart...', 'gold_tag': \"BESS has children she refers to as 'my boys' , GEORGIANA is a mother to Charlotte, Harryo, Little G, and Hart\", 'last_speaker': 'BESS'}\n",
      "Last word -> BESS : \"For Charlotte, for Harryo, for little G, for Hart...\"\n",
      "prediction :  I’ll do it.\n",
      "Real answer : For Charlotte, for Harryo, for little G, for Hart...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8678241968154907], 'recall': [0.7937864661216736], 'f1': [0.8291558623313904], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 45.04303741455078\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDR. SHIRLEY: What are you doing?\\nLIP: I gotta take a leak.\\nDR. SHIRLEY: Here? Now?\\n\\n', 'answer': 'What, you want me to piss my pants?', 'gold_tag': 'Everyday Language', 'last_speaker': 'LIP'}\n",
      "Last word -> LIP : \"What, you want me to piss my pants?\"\n",
      "prediction :  Well I want to piss.\n",
      "Real answer : What, you want me to piss my pants?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.909238338470459], 'recall': [0.8633615970611572], 'f1': [0.8857063055038452], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4615384615384615, 'rouge2': 0.18181818181818182, 'rougeL': 0.4615384615384615, 'rougeLsum': 0.4615384615384615}\n",
      "bleu 1/2 : 0.21952465443761057 0.05488116360940265\n",
      "ppl : 940.7593383789062\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLIP: What do you want?\\n\\n', 'answer': 'I’m fine. Thank you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DR. SHIRLEY'}\n",
      "Last word -> DR. SHIRLEY : \"I’m fine. Thank you.\"\n",
      "prediction :  I want to become a great researcher\n",
      "Real answer : I’m fine. Thank you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8606492877006531], 'recall': [0.8667268753051758], 'f1': [0.8636773824691772], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 77.50735473632812\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLIP: This can’t be it. Says right here......cozy as your own home... This place looks like my ass.\\nDR. SHIRLEY: This is the place.\\n\\n', 'answer': 'If you need anything, I’ll be up the street at the Easton Inn. So...see you tomorrow.', 'gold_tag': 'LIP offers to be available for DR. SHIRLEY if needed , LIP will be at the Easton Inn up the street , LIP plans to see DR. SHIRLEY the following day', 'last_speaker': 'LIP'}\n",
      "Last word -> LIP : \"If you need anything, I’ll be up the street at the Easton Inn. So...see you tomorrow.\"\n",
      "prediction :  Who the hell are you talking to?\n",
      "Real answer : If you need anything, I’ll be up the street at the Easton Inn. So...see you tomorrow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8062158226966858], 'recall': [0.8271626830101013], 'f1': [0.8165549635887146], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16, 'rouge2': 0.0, 'rougeL': 0.16, 'rougeLsum': 0.16}\n",
      "bleu 1/2 : 0.07898658475130411 0.01907707262543283\n",
      "ppl : 41.819915771484375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLIP: What the hell’s wrong with you?! You go in there alone?\\nDR. SHIRLEY: I apologize for putting you in that position, Tony.\\nLIP: I don’t understand you, Doc, honest to God. Why couldn’t you just drink here--you got a whole bottle?\\nDR. SHIRLEY: I needed some air.\\nLIP: Air?! Don’t you know where you are?\\nDR. SHIRLEY: Does the geography really matter?\\nLIP: What?\\nDR. SHIRLEY: If I walked into a bar in your neighborhood, would this conversation be any different?\\nLIP: From now on you don’t go nowhere without me. Nowhere!\\nDR. SHIRLEY: Tony...Do you really have a gun?\\n\\n', 'answer': '‘Course not. Now get some rest. You got a big show tomorrow night. Now where’s your room doc?', 'gold_tag': 'DR. SHIRLEY has a show the following night', 'last_speaker': 'LIP'}\n",
      "Last word -> LIP : \"‘Course not. Now get some rest. You got a big show tomorrow night. Now where’s your room doc?\"\n",
      "prediction :  I would have to. What do you think? I’m not a kid. I’m a grown man.\n",
      "Real answer : ‘Course not. Now get some rest. You got a big show tomorrow night. Now where’s your room doc?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8701955676078796], 'recall': [0.8537177443504333], 'f1': [0.8618779182434082], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16216216216216214, 'rouge2': 0.0, 'rougeL': 0.10810810810810811, 'rougeLsum': 0.10810810810810811}\n",
      "bleu 1/2 : 0.055156056411537216 0.018013892590990767\n",
      "ppl : 13.426088333129883\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLIP: “Betty bought... a bit of buttah... but she found the buttah bittah...”\\nDR. SHIRLEY: Not buttah... butter. Say the “er.”\\nLIP: Er.\\nDR. SHIRLEY: “So Betty bought a bit of better butter to make the bitter butter better...”\\nLIP: “So Betty bit a buttah...”\\nDR. SHIRLEY: Don’t be lazy--enunciate. “So Betty bought a bit of better butter...”\\nLIP: “So, Betty bit a better buttah--” this is bullshit.\\n\\n', 'answer': 'No, you need to start somewhere. exercises. These drills will strengthen your speech muscles.', 'gold_tag': 'DR. SHIRLEY may be in a teaching or coaching role', 'last_speaker': 'DR. SHIRLEY'}\n",
      "Last word -> DR. SHIRLEY : \"No, you need to start somewhere. exercises. These drills will strengthen your speech muscles.\"\n",
      "prediction :  This, yes. It’s too little for her, she needs more.\n",
      "Real answer : No, you need to start somewhere. exercises. These drills will strengthen your speech muscles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8696684837341309], 'recall': [0.8654886484146118], 'f1': [0.8675735592842102], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 43.65284729003906\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDR. SHIRLEY: They were wrong for the way they treated me, and you rewarded them.\\nLIP: I was hired to make sure you get from one show to the next. How I do it shouldn’t matter to you.\\nDR. SHIRLEY: I just wish you hadn’t paid them off.\\nLIP: I did what I had to do. You know, if this got out it would kill your career.\\nDR. SHIRLEY: Okay, Tony, quit your phony altruism and concern for my career.\\nLIP: What the hell does that mean?\\nDR. SHIRLEY: You were only thinking about yourself back there, because you know if I miss a show, it comes out of your pocket.\\nLIP: Of course I don’t want you to miss a show, you ungrateful bastard! You think I’m doing this for my health?! Tonight I saved your ass, so show a little appreciation. Besides, I told you never to go nowhere without me!\\n\\n', 'answer': 'I assumed you would want this to be the exception.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DR. SHIRLEY'}\n",
      "Last word -> DR. SHIRLEY : \"I assumed you would want this to be the exception.\"\n",
      "prediction :  And what about us? Is anyone considering how we feel?\n",
      "Real answer : I assumed you would want this to be the exception.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8305857181549072], 'recall': [0.864684522151947], 'f1': [0.8472921252250671], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 70.15714263916016\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLIP: Should I try to find you some make- up or somethin’ before the show?\\nDR. SHIRLEY: I’m fine.\\nLIP: You sure?\\n\\n', 'answer': 'I said I’m fine.', 'gold_tag': 'DR. SHIRLEY expresses that he is fine even without makeup before a show', 'last_speaker': 'DR. SHIRLEY'}\n",
      "Last word -> DR. SHIRLEY : \"I said I’m fine.\"\n",
      "prediction :  No, you don’t have to. You always sound so sad to us.\n",
      "Real answer : I said I’m fine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8503289222717285], 'recall': [0.8884605169296265], 'f1': [0.8689765930175781], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 43.695186614990234\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLIP: So, how’d you learn how to play so good, Doc?\\nDR. SHIRLEY: My mother. She taught me how to play on an old spinet. Soon as I could walk, we’d travel around the Florida panhandle and I’d put on little shows in parishes and halls. A man who had seen me play arranged for me to study at the Leningrad Conservatory of Music.\\nLIP: So that’s where they taught you all them songs you play?\\nDR. SHIRLEY: Actually, I was trained to play classical music. Brahms, Franz Liszt, Chopin--it’s all I ever wanted to play. But I was persuaded by my record company to pursue a career in popular music instead. They told me audiences would never accept a black pianist on the classical stage. Wanted to turn me into just another “colored entertainer.” You know, the guy who smokes while he’s playing, who puts a glass of whisky on the piano and then gets mad when he’s not respected like Arthur Rubinstein. Well, you don’t see Arthur Rubenstein smoking and putting a drink on his piano.\\nLIP: Personally, if you stuck to that classic stuff I think it would’ve been a big mistake.\\nDR. SHIRLEY: A mistake? Performing the music I trained my entire life to play?\\nLIP: Trained? What are you, a seal? Anyone can sound like Beethoven or Joe Pan or them other guys you said. But your music, what you do, only you can do, and nobody can train for that.\\n\\n', 'answer': 'Thank you, Tony. But...not everyone can play Chopin...not the way I can.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DR. SHIRLEY'}\n",
      "Last word -> DR. SHIRLEY : \"Thank you, Tony. But...not everyone can play Chopin...not the way I can.\"\n",
      "prediction :  So why are you here?\n",
      "Real answer : Thank you, Tony. But...not everyone can play Chopin...not the way I can.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8349109888076782], 'recall': [0.8323906064033508], 'f1': [0.8336488604545593], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473682, 'rouge2': 0.0, 'rougeL': 0.10526315789473682, 'rougeLsum': 0.10526315789473682}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 62.833003997802734\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDR. SHIRLEY: I need sleep.\\nLIP: Okay, I’ll pull over at the next place we see and I’ll sneak you into my room.\\nDR. SHIRLEY: No. No. I refuse to stay at an establishment that doesn’t want me.\\n\\n', 'answer': 'Okay.', 'gold_tag': 'Everyday Language', 'last_speaker': 'LIP'}\n",
      "Last word -> LIP : \"Okay.\"\n",
      "prediction :  Okay, okay, I’m going to get you a place to sleep. I’ll get it for you somewhere in the city, somewhere safe and secluded.\n",
      "Real answer : Okay.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8229926824569702], 'recall': [0.933280348777771], 'f1': [0.8746737241744995], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07407407407407407, 'rouge2': 0.0, 'rougeL': 0.07407407407407407, 'rougeLsum': 0.07407407407407407}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.316057205200195\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDR. SHIRLEY: If we leave right now, I think you can make it.\\nLIP: Make what?\\nDR. SHIRLEY: Christmas Eve.\\nLIP: Don’t ever flash a wad of cash in a\\n\\n', 'answer': 'I knew you had a gun!', 'gold_tag': \"DR. SHIRLEY is aware of LIP's concealed weapon , LIP carries a gun\", 'last_speaker': 'DR. SHIRLEY'}\n",
      "Last word -> DR. SHIRLEY : \"I knew you had a gun!\"\n",
      "prediction :  Well, they do. You don’t care for them are they?\n",
      "Real answer : I knew you had a gun!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8422359228134155], 'recall': [0.8752570152282715], 'f1': [0.8584290146827698], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352942, 'rouge2': 0.0, 'rougeL': 0.11764705882352942, 'rougeLsum': 0.11764705882352942}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 44.16279983520508\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLIP: Doc, my eyes are stingin’, I might need to pull over.\\n\\n', 'answer': 'Keep going as long as you can,', 'gold_tag': 'Everyday Language', 'last_speaker': 'DR. SHIRLEY'}\n",
      "Last word -> DR. SHIRLEY : \"Keep going as long as you can,\"\n",
      "prediction :  Can we pull into the next entrance?\n",
      "Real answer : Keep going as long as you can,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8655704259872437], 'recall': [0.8120710849761963], 'f1': [0.8379676938056946], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 247.1802978515625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLIP: That’s it. I’m pulling us into the next motel.\\nDR. SHIRLEY: Keep going, Tony, you can make it.\\n\\n', 'answer': 'I can’t keep my eyes open, Doc--I’m gettin’ hytnotized by the snow. I think my brain’s gonna explode.', 'gold_tag': 'LIP is willing to assert his boundaries and needs , LIP is extremely tired and struggling to stay awake', 'last_speaker': 'LIP'}\n",
      "Last word -> LIP : \"I can’t keep my eyes open, Doc--I’m gettin’ hytnotized by the snow. I think my brain’s gonna explode.\"\n",
      "prediction :  No. There’s not enough time.\n",
      "Real answer : I can’t keep my eyes open, Doc--I’m gettin’ hytnotized by the snow. I think my brain’s gonna explode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8872486352920532], 'recall': [0.8187161087989807], 'f1': [0.8516057729721069], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07142857142857144, 'rouge2': 0.0, 'rougeL': 0.07142857142857144, 'rougeLsum': 0.07142857142857144}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 55.29771423339844\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAMELA: We need to get in there.\\n\\n', 'answer': \"I'm working on it.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'CRONIN'}\n",
      "Last word -> CRONIN : \"I'm working on it.\"\n",
      "prediction :  Yes.\n",
      "Real answer : I'm working on it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9478527307510376], 'recall': [0.8724187612533569], 'f1': [0.9085727334022522], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2505.07666015625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCRONIN: Looks like he's been detained.\\nPAMELA: Who's going? Us?\\nCRONIN: There's only a Consulate, they sent a field officer out half an hour ago --\\n\\n\", 'answer': \"Then get a number, they need to know who they're dealing with.\", 'gold_tag': 'PAMELA wants to acquire a number, suggesting there is an immediate need or urgency to identify the person they are dealing with', 'last_speaker': 'PAMELA'}\n",
      "Last word -> PAMELA : \"Then get a number, they need to know who they're dealing with.\"\n",
      "prediction :  Just you and me, then.\n",
      "Real answer : Then get a number, they need to know who they're dealing with.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8590992093086243], 'recall': [0.8458447456359863], 'f1': [0.852420449256897], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 107.91692352294922\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCRONIN: -- Kurt's reopening all the wyfi and sat\\n\\n\", 'answer': '-- uplink all relevant files to Kim -- -- and I want them to contact anyone who had anything to do with Treadstone --', 'gold_tag': 'PAMELA holds a senior position , PAMELA can command the uplinking of files , PAMELA is likely in intelligence or law enforcement , PAMELA can order others to contact individuals related to \"Treadstone\" , PAMELA is making immediate demands concerning information about \"Treadstone\"', 'last_speaker': 'PAMELA'}\n",
      "Last word -> PAMELA : \"-- uplink all relevant files to Kim -- -- and I want them to contact anyone who had anything to do with Treadstone --\"\n",
      "prediction :  -- I don't understand\n",
      "Real answer : -- uplink all relevant files to Kim -- -- and I want them to contact anyone who had anything to do with Treadstone --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8149758577346802], 'recall': [0.8029505014419556], 'f1': [0.8089184761047363], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08333333333333334, 'rouge2': 0.0, 'rougeL': 0.08333333333333334, 'rougeLsum': 0.08333333333333334}\n",
      "bleu 1/2 : 0.0033689734995427335 0.000869865217169542\n",
      "ppl : 57.68941879272461\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCRONIN: The room he checked into was across the hall -- why, why would he come here?\\nPAMELA: He must've had a reason. That's how they were trained.\\n\\n\", 'answer': 'He went out the window in here...', 'gold_tag': 'CRONIN is a problem solver or investigative type', 'last_speaker': 'CRONIN'}\n",
      "Last word -> CRONIN : \"He went out the window in here...\"\n",
      "prediction :  He must've had a reason, he checked into this room, so he must've had a reason. Why would someone come here?\n",
      "Real answer : He went out the window in here...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8354390859603882], 'recall': [0.8728935718536377], 'f1': [0.8537557721138], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0.047619047619047616 0.01543033499620919\n",
      "ppl : 21.879737854003906\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCRONIN: You're sure?\\nPAMELA: What? The tapes?\\n\\n\", 'answer': 'Hold on... Yep. And Abbott just direct dialed Moscow', 'gold_tag': \"CRONIN is in a job that deals with tapes and important direct calls , CRONIN's job is possibly in a government agency or high-level corporate position\", 'last_speaker': 'CRONIN'}\n",
      "Last word -> CRONIN : \"Hold on... Yep. And Abbott just direct dialed Moscow\"\n",
      "prediction :  I'm sure. You're sure you want to see them right now?\n",
      "Real answer : Hold on... Yep. And Abbott just direct dialed Moscow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8210157752037048], 'recall': [0.8310750722885132], 'f1': [0.8260148167610168], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 20.600881576538086\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWALTON: You are now an Erewhon inmate -- a citizen of nowhere. Human rights zealots, the Geneva convention and the P.C. police have no authority here. You have no right... When I say your ass belongs to me -- I mean it. Bend over. Step into them. Don't sniff 'em, you perv. Just step into them.\\nARCHER: They're too tight.\\n\\n\", 'answer': \"So's a noose. Now keep your mouth shut. The prison's one big magnetic field. The boots'll tell us where you are -- every second of the day. I've got fifty bucks says you're dead by dinner. Don't disappoint me.\", 'gold_tag': \"WALTON has a wager on ARCHER's survival till dinner , ARCHER being threatened with potential death by dinner\", 'last_speaker': 'WALTON'}\n",
      "Last word -> WALTON : \"So's a noose. Now keep your mouth shut. The prison's one big magnetic field. The boots'll tell us where you are -- every second of the day. I've got fifty bucks says you're dead by dinner. Don't disappoint me.\"\n",
      "prediction :  That's fine. That's fine. But remember, you're now my prisoner. You. Are. Now. My. Prisoner. Here's why.\n",
      "Real answer : So's a noose. Now keep your mouth shut. The prison's one big magnetic field. The boots'll tell us where you are -- every second of the day. I've got fifty bucks says you're dead by dinner. Don't disappoint me.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8583807945251465], 'recall': [0.839551568031311], 'f1': [0.848861813545227], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.21538461538461537, 'rouge2': 0.06349206349206349, 'rougeL': 0.12307692307692307, 'rougeLsum': 0.12307692307692307}\n",
      "bleu 1/2 : 0.016125861504125143 0.005256387755182872\n",
      "ppl : 10.961220741271973\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARCHER: What? He started it! When I get out of here --\\nWALTON: You'll what?\\nARCHER: I'm going to have you fired.\\n\\n\", 'answer': \"That's two strikes, Dubov. One more and you know where you're going. Back to your 'suites' -- or no\", 'gold_tag': 'WALTON holds a position of authority, possibly a supervisor or manager , WALTON has the power to assign punitive actions , WALTON implies imminent punitive action if ARCHER continues his current behavior , Shared history of conflict or disagreement between ARCHER and WALTON', 'last_speaker': 'WALTON'}\n",
      "Last word -> WALTON : \"That's two strikes, Dubov. One more and you know where you're going. Back to your 'suites' -- or no\"\n",
      "prediction :  You wanna do something. Go ahead.\n",
      "Real answer : That's two strikes, Dubov. One more and you know where you're going. Back to your 'suites' -- or no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8727052807807922], 'recall': [0.8095386624336243], 'f1': [0.8399360775947571], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307691, 'rouge2': 0.0, 'rougeL': 0.07692307692307691, 'rougeLsum': 0.07692307692307691}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 95.32534790039062\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWALTON: Better be nice, Castor. You could get mighty lonely now that Pollux is gone.\\nARCHER: Pollux is -- what?\\nWALTON: Archer cut him a deal for turning state's evidence. He's been released...\\nARCHER: Walton, you have to listen to me -- right now!\\n\\n\", 'answer': \"Or what? You'll have me fired? You're confined until I say otherwise...\", 'gold_tag': 'WALTON is responsible for the confinement of ARCHER and his release', 'last_speaker': 'WALTON'}\n",
      "Last word -> WALTON : \"Or what? You'll have me fired? You're confined until I say otherwise...\"\n",
      "prediction :  Who the hell is Castor?\n",
      "Real answer : Or what? You'll have me fired? You're confined until I say otherwise...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8055114150047302], 'recall': [0.7982341051101685], 'f1': [0.8018562197685242], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 385.25579833984375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWALTON: There!\\n\\n', 'answer': \"Let's go!\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ARCHER'}\n",
      "Last word -> ARCHER : \"Let's go!\"\n",
      "prediction :  Who?\n",
      "Real answer : Let's go!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8889866471290588], 'recall': [0.8338420391082764], 'f1': [0.8605318069458008], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13011.365234375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: How did the visit go?\\nKYLE: OK. He fell asleep watching TV. So he lives there now?\\nMIKE: Yeah. Your grandfather is in the things that don't make sense.\\nKYLE: Are you a friend of his or something?\\nMIKE: I'm his guardian.\\nKYLE: What's that mean?\\nMIKE: It means I make sure he's well taken care of.\\n\\n\", 'answer': \"That's cool.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'KYLE'}\n",
      "Last word -> KYLE : \"That's cool.\"\n",
      "prediction :  What does that mean.\n",
      "Real answer : That's cool.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8829588294029236], 'recall': [0.8830289244651794], 'f1': [0.8829938769340515], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 136.19683837890625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: Here's fifty bucks in case you need it.\\nKYLE: I have money.\\nMIKE: Actually it's only forty-three but take it. You never know.\\nKYLE: I have enough money. But thanks.\\nMIKE: Well, good luck, Kyle.\\n\\n\", 'answer': 'Yeah. You too, Mike.', 'gold_tag': 'Everyday Language', 'last_speaker': 'KYLE'}\n",
      "Last word -> KYLE : \"Yeah. You too, Mike.\"\n",
      "prediction :  Do you want to go?\n",
      "Real answer : Yeah. You too, Mike.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8295918107032776], 'recall': [0.8688901662826538], 'f1': [0.8487863540649414], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.22222222222222224, 'rougeLsum': 0.22222222222222224}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 66.48255157470703\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: So what happened?\\nKYLE: I decided not to go home.\\nMIKE: And then you decided you'd break into your Grandfather's house?\\nKYLE: You mind if I have a quick smoke?\\n\\n\", 'answer': 'Yeah, I do. Get in the car.', 'gold_tag': \"MIKE disapproves of KYLE's smoking habit , MIKE is the responsible and authoritative figure\", 'last_speaker': 'MIKE'}\n",
      "Last word -> MIKE : \"Yeah, I do. Get in the car.\"\n",
      "prediction :  I don’t mind if Kyle has a quick one .\n",
      "Real answer : Yeah, I do. Get in the car.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8508206605911255], 'recall': [0.8730840682983398], 'f1': [0.8618085980415344], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.10000000000000002 0.03333333333333335\n",
      "ppl : 114.26062774658203\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: You have fun?\\nKYLE: Yeah.\\nMIKE: When's the last time you wrestled?\\nKYLE: A couple years ago.\\nMIKE: Why'd you stop?\\nKYLE: Just felt like it.\\nMIKE: So let me ask you something, Kyle. How good are you?\\n\\n\", 'answer': \"I'm pretty good.\", 'gold_tag': 'KYLE believes he is pretty good at wrestling', 'last_speaker': 'KYLE'}\n",
      "Last word -> KYLE : \"I'm pretty good.\"\n",
      "prediction :  I was on the collegiate level until I messed up.\n",
      "Real answer : I'm pretty good.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8766563534736633], 'recall': [0.9040913581848145], 'f1': [0.8901625871658325], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714288, 'rouge2': 0.0, 'rougeL': 0.14285714285714288, 'rougeLsum': 0.14285714285714288}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 100.11956787109375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: Were you outside?\\nKYLE: Yeah. I went for a run.\\nMIKE: It's pretty early. You do this every morning?\\nKYLE: In season, yeah. I like to get my run in early and then drill some moves for an hour before school.\\nMIKE: Oh. Wow.\\n\\n\", 'answer': \"Yeah...so I'm gonna do it. See you. 5/15/10 - FULL SHOOTING SCRIPT - WIN WIN 58\", 'gold_tag': 'KYLE has an intense morning routine', 'last_speaker': 'KYLE'}\n",
      "Last word -> KYLE : \"Yeah...so I'm gonna do it. See you. 5/15/10 - FULL SHOOTING SCRIPT - WIN WIN 58\"\n",
      "prediction :  Yeah. I try and get a workout in, every day.\n",
      "Real answer : Yeah...so I'm gonna do it. See you. 5/15/10 - FULL SHOOTING SCRIPT - WIN WIN 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8774928450584412], 'recall': [0.8058187961578369], 'f1': [0.8401298522949219], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 38.61552429199219\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: Hey, I'm proud of what you did today. That win meant a lot to the guys.\\n\\n\", 'answer': 'Cool. It was good coaching with Stemler.', 'gold_tag': 'KYLE is involved in coaching with Stemler', 'last_speaker': 'KYLE'}\n",
      "Last word -> KYLE : \"Cool. It was good coaching with Stemler.\"\n",
      "prediction :  Hey, you know what? That was probably the biggest upset of the year, actually.\n",
      "Real answer : Cool. It was good coaching with Stemler.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8508485555648804], 'recall': [0.8894214630126953], 'f1': [0.8697075247764587], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809523, 'rouge2': 0.0, 'rougeL': 0.09523809523809523, 'rougeLsum': 0.09523809523809523}\n",
      "bleu 1/2 : 0.07142857142857141 0.023440361546924773\n",
      "ppl : 23.027809143066406\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: Let me ask you something. What's it like? Being as good as you are? What's it feel like?\\nKYLE: I don't know. I guess it just feels like I'm in control. Of everything. You know what I mean?\\nMIKE: Yeah, I do. Must be nice.\\n\\n\", 'answer': 'It is.', 'gold_tag': 'KYLE is good at something', 'last_speaker': 'KYLE'}\n",
      "Last word -> KYLE : \"It is.\"\n",
      "prediction :  It's never been a problem, really. Nothing ever seems to phase me. Everything changes. Everyone's going to get what we bring about. You know, it just changes everything.\n",
      "Real answer : It is.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8437908291816711], 'recall': [0.9028236865997314], 'f1': [0.872309684753418], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0625, 'rouge2': 0.0, 'rougeL': 0.0625, 'rougeLsum': 0.0625}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.88302230834961\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: How you doing?\\nKYLE: I'm sorry.\\nMIKE: Hey, it's alright.\\nKYLE: I don't want to go with her. I don't.\\n\\n\", 'answer': 'OK, pal. OK.', 'gold_tag': 'MIKE is supportive', 'last_speaker': 'MIKE'}\n",
      "Last word -> MIKE : \"OK, pal. OK.\"\n",
      "prediction :  She is like, really nice and sweet and I just. Like, I don't know what it is, I really like her.\n",
      "Real answer : OK, pal. OK.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8071742057800293], 'recall': [0.8689056634902954], 'f1': [0.8369031548500061], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13.99208927154541\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHERMAN: Sure. Yes. Go ahead.\\nMARTIN: So. Let's see. Can you tell us if your car was in use the night this happened?\\nSHERMAN: When exactly was it?\\nMARTIN: Tuesday a week ago.\\nSHERMAN: I don't know. Let me think. I'd have to figure...\\nMARTIN: Anybody else use your car?\\nSHERMAN: My wife. Sometimes. And the\\nMARTIN: Parking garage.\\nSHERMAN: Yes.\\nMARTIN: You leave the car with the keys\\nSHERMAN: Well... yes.\\n\\n\", 'answer': 'Could we go there and take a look at it?', 'gold_tag': 'Everyday Language', 'last_speaker': 'MARTIN'}\n",
      "Last word -> MARTIN : \"Could we go there and take a look at it?\"\n",
      "prediction :  So? Can you tell us how the car got into that state?\n",
      "Real answer : Could we go there and take a look at it?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8700072765350342], 'recall': [0.8777201175689697], 'f1': [0.8738466501235962], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 49.90876007080078\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHERMAN: The car?\\nMARTIN: Yes.\\nSHERMAN: Now?\\n\\n', 'answer': \"Soon as we leave here. We could take a look. There's things that's consistent with an incident like this. We don't find those things, we move on down the list. And we're out of your hair.\", 'gold_tag': \"MARTIN intends to examine the car as soon as they leave their current location , MARTIN is in a profession requiring some form of investigation, likely law enforcement , MARTIN has a methodical approach to the 'incident' involving a car , MARTIN demonstrates a willingness to be fair in his inquiry\", 'last_speaker': 'MARTIN'}\n",
      "Last word -> MARTIN : \"Soon as we leave here. We could take a look. There's things that's consistent with an incident like this. We don't find those things, we move on down the list. And we're out of your hair.\"\n",
      "prediction :  The whole day? OK, I'll tell you what. You get the dog out of the car first, and then I'll come in a minute. I'll run to the bank and get you the money.\n",
      "Real answer : Soon as we leave here. We could take a look. There's things that's consistent with an incident like this. We don't find those things, we move on down the list. And we're out of your hair.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8387515544891357], 'recall': [0.8477673530578613], 'f1': [0.8432353734970093], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12987012987012989, 'rouge2': 0.026666666666666665, 'rougeL': 0.07792207792207792, 'rougeLsum': 0.07792207792207792}\n",
      "bleu 1/2 : 0.11092625221822057 0.05629720488379733\n",
      "ppl : 12.745979309082031\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHERMAN: So you want to take a look at the car then.\\nMARTIN: Yeah. We don't have a description of a driver. So we gotta look for the car. And that means bothering a lot of innocent people. We're sorry about the inconvenience.\\n\\n\", 'answer': \"I understand. But if it is a routine, well, I should, I guess I ought to... well, follow the routine that's appropriate to me, to someone with a car in this situation. You see?\", 'gold_tag': 'SHERMAN is likely the owner of the car being investigated , SHERMAN is respectful of protocol and willing to follow proper procedures , SHERMAN is a law-abiding citizen', 'last_speaker': 'SHERMAN'}\n",
      "Last word -> SHERMAN : \"I understand. But if it is a routine, well, I should, I guess I ought to... well, follow the routine that's appropriate to me, to someone with a car in this situation. You see?\"\n",
      "prediction :  You're free to leave then.\n",
      "Real answer : I understand. But if it is a routine, well, I should, I guess I ought to... well, follow the routine that's appropriate to me, to someone with a car in this situation. You see?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8566134572029114], 'recall': [0.8145556449890137], 'f1': [0.8350553512573242], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09756097560975609, 'rouge2': 0.0, 'rougeL': 0.048780487804878044, 'rougeLsum': 0.048780487804878044}\n",
      "bleu 1/2 : 0.0006055109490751632 0.00021408044908687507\n",
      "ppl : 98.21095275878906\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGRAHAM: Breakfast?\\nCLIVE: Java. Straight up.\\nGRAHAM: Any solids?\\nCLIVE: No, let\\'s punch through. Miles make the eggs taste sweeter.\\nGRAHAM: I love eggs!\\nCLIVE: I hear that. Now, get that \"�Joe\\' on the go and jump in the Chewie seat. I need your map skills.\\nGRAHAM: Good job I pre-pared. It\\'s a shame I don\\'t have some controls on this side. That way, I could take over if you needed the loo.\\nCLIVE: Yeah, I could say \"take the helm.\"�\\nGRAHAM: \"Take the helm, number one.\"�\\nCLIVE: Yeah, \"take the helm, number one, I need a number two.\"�\\nGRAHAM: \"�Least I\\'ve got Cerebro, eh?\\nCLIVE: Absolutely. Real-time sat-nav multi map and advanced geo-tagging with continual info stream?\\nGRAHAM: Impressive.\\nCLIVE: Most impressive.\\nGRAHAM: And let\\'s not forget, we\\'ve always got Analogue.\\nCLIVE: Not when we\\'re driving Graham.\\nGRAHAM: Sorry. Sounds like coffee o\\'clock.\\n\\n', 'answer': \"Thank god. I'm a wreck until I've had my first cup of J.\", 'gold_tag': 'CLIVE prefers coffee over solid food in the morning , CLIVE indicates needing coffee to function optimally , CLIVE needs a cup of coffee immediately', 'last_speaker': 'CLIVE'}\n",
      "Last word -> CLIVE : \"Thank god. I'm a wreck until I've had my first cup of J.\"\n",
      "prediction :  That must be a tough question. We could start at the bottom.\n",
      "Real answer : Thank god. I'm a wreck until I've had my first cup of J.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8536180853843689], 'recall': [0.8586918115615845], 'f1': [0.8561474680900574], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07407407407407407, 'rouge2': 0.0, 'rougeL': 0.07407407407407407, 'rougeLsum': 0.07407407407407407}\n",
      "bleu 1/2 : 0.07667036788577694 0.025323389070344468\n",
      "ppl : 54.317222595214844\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLIVE: Amazing, isn't it? There are 295,734,134 people in this country and we haven't seen a soul for a hundred miles. Where is everybody?\\nGRAHAM: What about that old woman on crutches we saw hitchhiking?\\nCLIVE: Apart from her. I suppose that's why they established the Dreamland facility out here.\\nGRAHAM: Far from prying eyes.\\nCLIVE: Did you know the site was selected in the mid-1950s for testing of the U-2 spyplane, due to its remoteness, proximity to existing facilities and presence of a dry lake bad for landings?\\nGRAHAM: Yes.\\nCLIVE: Oh.\\nGRAHAM: Shall we have a bite before or after we hit the Black Mailbox?\\n\\n\", 'answer': 'Before.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CLIVE'}\n",
      "Last word -> CLIVE : \"Before.\"\n",
      "prediction :  The last time I used an iPhone I was charged $5 to use it for a hour. Now it's $0.99 for 20 minutes.\n",
      "Real answer : Before.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8360790014266968], 'recall': [0.9178653955459595], 'f1': [0.8750653266906738], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 10.740745544433594\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGRAHAM: What's the matter?\\nCLIVE: Nothing. How we doing?\\nGRAHAM: We should be just about there.\\nCLIVE: I've found it.\\nGRAHAM: Where?\\n\\n\", 'answer': 'THERE!!!', 'gold_tag': 'Everyday Language', 'last_speaker': 'CLIVE'}\n",
      "Last word -> CLIVE : \"THERE!!!\"\n",
      "prediction :  Oh! I think I know the address. You must be tired and hungry .\n",
      "Real answer : THERE!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8087658286094666], 'recall': [0.8728052973747253], 'f1': [0.839566171169281], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 47.13725280761719\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLIVE: It's amazing, isn't it? We're actually here.\\nGRAHAM: Area 51.\\nCLIVE: Dreamland.\\nGRAHAM: The Groom Lake Military Test Facility.\\nCLIVE: MacArthur's Black Mile.\\nGRAHAM: Is that a real one?\\nCLIVE: No, I made it up myself.\\nGRAHAM: I like it.\\nCLIVE: Be great if we saw something.\\nGRAHAM: Yes, imagine if we got buzzed up by a craft.\\nCLIVE: That would be incredible. It just\\nGRAHAM: What would you do if they actually landed?\\nCLIVE: Keep it together. First contact is a big responsibility. They come in peace, we go to pieces? That's not how I roll. What's wrong?\\nGRAHAM: It's them. They found us. I don't know how but they found us.\\nCLIVE: Who? Who's found us?\\nGRAHAM: The Libyans!\\n\\n\", 'answer': 'Run for it Marty!', 'gold_tag': 'Everyday Language', 'last_speaker': 'CLIVE'}\n",
      "Last word -> CLIVE : \"Run for it Marty!\"\n",
      "prediction :  Look, it's you again. What's wrong?\n",
      "Real answer : Run for it Marty!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8387784957885742], 'recall': [0.8411428928375244], 'f1': [0.8399590253829956], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.8873233795166\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGRAHAM: Perhaps it's not them. Perhaps whoever it was turned doff.\\nCLIVE: Of course it's them. We're dead. It's like Deliverance. They're going to rape us and break our arms.\\nGRAHAM: I don't want my arms broken!\\nCLIVE: There's only one thing for it.\\nGRAHAM: What?\\nCLIVE: I'm gonna have to fly blind. Probably best not to do that. I couldn't really see anything. Oh God, oh God, oh God.\\nGRAHAM: I need the toilet.\\nCLIVE: Me too. They're trying to overtake.\\nGRAHAM: Don't let them get past.\\nCLIVE: Should I ram them?\\nGRAHAM: What about the deposit?\\nCLIVE: It wasn't them. We should see if they're okay.\\nGRAHAM: I still need a wee.\\nCLIVE: I can hold mine.\\n\\n\", 'answer': \"The bulb's gone in there.\", 'gold_tag': 'GRAHAM mentions the bulb has gone, which is a temporary issue', 'last_speaker': 'GRAHAM'}\n",
      "Last word -> GRAHAM : \"The bulb's gone in there.\"\n",
      "prediction :  Perhaps it's not them. Perhaps whoever it was turned off.\n",
      "Real answer : The bulb's gone in there.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8462984561920166], 'recall': [0.8409245014190674], 'f1': [0.8436028957366943], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352942, 'rouge2': 0.0, 'rougeL': 0.11764705882352942, 'rougeLsum': 0.11764705882352942}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 86.13249969482422\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGRAHAM: Now's not really the time, Sausage.\\nCLIVE: I must have it.\\nGRAHAM: It's very cheap. Are you sure you don't want to save up and get a proper on?\\n\\n\", 'answer': \"Oh, come on, we've got time.\", 'gold_tag': 'CLIVE does not save for something better', 'last_speaker': 'CLIVE'}\n",
      "Last word -> CLIVE : \"Oh, come on, we've got time.\"\n",
      "prediction :  I don't have the patience.\n",
      "Real answer : Oh, come on, we've got time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8758091926574707], 'recall': [0.8523832559585571], 'f1': [0.863937497138977], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 27.87188148498535\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGRAHAM: It's gone!\\n\\n\", 'answer': 'Where did it go?', 'gold_tag': 'Everyday Language', 'last_speaker': 'CLIVE'}\n",
      "Last word -> CLIVE : \"Where did it go?\"\n",
      "prediction :  [sighs] Good. Good, we've got about...\n",
      "Real answer : Where did it go?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8269937038421631], 'recall': [0.8226573467254639], 'f1': [0.824819803237915], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 80.49722290039062\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBILL: No, you listen to me. You don't understand, Gene. Don't lie, just give the family what it wants... No... No, you don't understand.\\nROSE: Why me ?... Hi !... I'm Rose.\\nBILL: Hi, Rose !... I't nice to run into me like this !... I'm Bill Capa...\\nROSE: I got no insurance... She gets out of her car. I know it's against the law and everything. Don't bust my chops. I'll bring the money to you, if you just get an estimate.\\nBILL: Got a pen ?\\nROSE: Oh, poor old brain can't remember its own phone number.\\nBILL: I just moved here... From New York... I wrote my address down, because I am not sure about this number, and how long I gonna be there, so maybe you can call me sometimes for the next couple of days.\\nROSE: I will.\\nBILL: Bye !\\nROSE: Hey !... Don't you want my address ?\\n\\n\", 'answer': 'You could lie.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BILL'}\n",
      "Last word -> BILL : \"You could lie.\"\n",
      "prediction :  OK, look. You're welcome to stay wherever you want to be. But, I'll be coming back. And I'll take my family camping with us. You better come with.\n",
      "Real answer : You could lie.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8324453830718994], 'recall': [0.879741907119751], 'f1': [0.8554404377937317], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0588235294117647, 'rouge2': 0.0, 'rougeL': 0.0588235294117647, 'rougeLsum': 0.0588235294117647}\n",
      "bleu 1/2 : 0.03571428571428572 0.011501092655705905\n",
      "ppl : 17.261947631835938\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: Hello !\\nBILL: Who's there ?\\nROSE: Hi !... Remember me ?... Fender-bender !...\\nBILL: There she is, a little angel, dancing on the head of a pin.\\nROSE: So... did you get that estimate ?\\nBILL: No.\\nROSE: Waow !... Nice place you got here. It's a little cold... but it's kind of tasteful, right ?\\nBILL: And wet !\\nROSE: You too, I guess.\\nBILL: Cold or tasteful ?\\n\\n\", 'answer': 'So... Are we eating in here, or you take me out ?...', 'gold_tag': 'ROSE is socially forward, asking about their eating arrangements', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"So... Are we eating in here, or you take me out ?...\"\n",
      "prediction :  Bill ! Oh, Bill ! Bill ! Bill !\n",
      "Real answer : So... Are we eating in here, or you take me out ?...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8060929179191589], 'recall': [0.8344497680664062], 'f1': [0.8200262188911438], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 74.67772674560547\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: Not even a shade of pink ?... Can't tell me if it's smeared or not ?\\nBILL: I can't tell you if your eyes are bloodshed.\\nROSE: Really !... That's sad !... You know what ?... In respect for your infirmity, I'm gonna give up wearing lipstick. Close-up on Rose putting her lipstick in her glass of water. There is something about me that I bet you find a little strange. Right ?\\nBILL: What is that ?\\nROSE: Well, I haven't asked you what you do.\\nBILL: That's right. You showed a remarkable restraint.\\nROSE: Well, it's because I'd rather guess. You know, I actually get upset if someone tries to tell me before I can... figure it out for myself, you know ?\\nBILL: But what if I am ashamed of what I do.\\nROSE: Why... Why should you be ashamed of being a shrink.\\nBILL: Who told you I was a shrink ?\\nROSE: Well... Are you ?\\nBILL: How did you know ?\\nROSE: The way you looked at me, you know ?\\nBILL: How I look at you ?\\nROSE: You... you have this kindness in your eyes. But I think you're using it to keep me away. You know, you're trying to play safe. You're trying to think of a case instead of thinking of a female.\\nBILL: So, you have a tuning fork too.\\nROSE: I guess we have a lot in common.\\nBILL: We seem to be playing the same game.\\nROSE: Why do you say I'm playing a game?\\nBILL: Because you're the fantasy girl, aren't you? Quicksilver?\\nROSE: Yeah, that's... That's exactly what I am.\\nBILL: You'll be whatever they want you to be... no substance, no rules. Light as air. So your feet never have to touch those burning hot coals the rest of us walk around on.\\nROSE: Yeah. Sort of like... not seeing red?\\n\\n\", 'answer': 'Yeah, sort of like that.', 'gold_tag': 'BILL is a professional shrink, possibly introverted, cautious, analytical, and sensitive', 'last_speaker': 'BILL'}\n",
      "Last word -> BILL : \"Yeah, sort of like that.\"\n",
      "prediction :  What about you... When you see someone with red eyes, do you?\n",
      "Real answer : Yeah, sort of like that.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8220106363296509], 'recall': [0.8200147747993469], 'f1': [0.821011483669281], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 44.50728225708008\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBILL: Yes, but that was part of my plan. I mean, I wanted to.\\nROSE: Oh, I need a taxi. Taxi !\\nBILL: No, hey, hey. Wait, wait, wait. What are you being so tough for ?\\nROSE: I'm just beginning to think that maybe I'Il...\\nBILL: I am thinking you should just let me take you home and forget about this stupid taxi.\\nROSE: Rose walks to her waiting cab. Well, I'm thinkin' you should stay exactly where you are, 'cause...\\nBILL: Give me your phone number and address.\\n\\n\", 'answer': 'Why? You want to make me fall to earth and burn my feet ? Whatever happened to quicksilver and light as air?', 'gold_tag': 'ROSE has a poetic side, as evidenced by her last line', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"Why? You want to make me fall to earth and burn my feet ? Whatever happened to quicksilver and light as air?\"\n",
      "prediction :  Okay, I'll tell you my address and I'll call you. Can, you, promise you'll be here and not moving around? I really need a driver right now. That's how I know it's a cab, right? They all just sit there.\n",
      "Real answer : Why? You want to make me fall to earth and burn my feet ? Whatever happened to quicksilver and light as air?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8340535759925842], 'recall': [0.8187589645385742], 'f1': [0.8263355493545532], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12121212121212122, 'rouge2': 0.0, 'rougeL': 0.09090909090909091, 'rougeLsum': 0.09090909090909091}\n",
      "bleu 1/2 : 0.075 0.013867504905630728\n",
      "ppl : 17.773876190185547\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: It's red, poor thing.\\nBILL: Thank you.\\nROSE: I was thinking. Maybe I should see a shrink.\\nBILL: I can recommend someone.\\nROSE: I feel better already.\\nBILL: God, I missed you.\\n\\n\", 'answer': \"This time you won't miss.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"This time you won't miss.\"\n",
      "prediction :  He's a good guy. But don't you want to help him?\n",
      "Real answer : This time you won't miss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8359932899475098], 'recall': [0.839889407157898], 'f1': [0.8379367589950562], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.21052631578947367, 'rouge2': 0.0, 'rougeL': 0.10526315789473684, 'rougeLsum': 0.10526315789473684}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 16.316486358642578\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: I want you to get dressed up... Get dressed up... All right ?\\nBILL: Right now ?\\n\\n', 'answer': 'Uh-huh.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"Uh-huh.\"\n",
      "prediction :  You're going to the theater. All right? Get dressed up, all right, all right. Do it, I'm waiting. Okay, all right, go on then.\n",
      "Real answer : Uh-huh.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8249920606613159], 'recall': [0.7956313490867615], 'f1': [0.8100457787513733], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.157852172851562\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: You're not eating. Don't you like my food?\\nBILL: I'd like your food five inches to the left.\\nROSE: Okay.\\nBILL: Yeah, okay.\\n\\n\", 'answer': \"I think it's ready.\", 'gold_tag': 'ROSE is the one cooking , ROSE may be adept at cooking or be the designated cook among the two', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"I think it's ready.\"\n",
      "prediction :  But, okay, Bill, I mean I'll make your salad that I've spent an hour making. Would you like that salad, or should I just go outside?\n",
      "Real answer : I think it's ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.818966269493103], 'recall': [0.8693430423736572], 'f1': [0.8434031009674072], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06060606060606061, 'rouge2': 0.0, 'rougeL': 0.06060606060606061, 'rougeLsum': 0.06060606060606061}\n",
      "bleu 1/2 : 0.03846153846153846 0.012403473458920851\n",
      "ppl : 31.316980361938477\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: Hey.\\nBILL: How did you get in here ?\\nROSE: Last time I was here, I stole the key. It was by the door.\\nBILL: What about the alarm ?\\nROSE: Oh ! I never thought about that.\\nBILL: It didn't go off ?\\nROSE: No. Um, did I make a mistake ? You have someone in the car ?\\nBILL: No, goddamn it, there isn't someone in the car ! People are getting killed around here ! You walk around like it's goddamn Disneyland ! What if something were to happen to you ?\\nROSE: She seems not to understand Bill's anger. I just thought that it would be a nice surprise, that's all. You don't look too happy to see me. I'm sorry.\\nBILL: I'm sorry. Baby, I'm sorry. This is a very nice surprise.\\nROSE: I'll never take a risk like that again.\\nBILL: Why don't you take the biggest risk of all and give me... your phone number.\\n\\n\", 'answer': \"She laughs and goes away from him and back to her cooking. Christ, Capa ! I can't have people tying up the phone lines. I'm trying to run a business here.\", 'gold_tag': \"ROSE is business-oriented, mentioning that she runs a business and can't have people tying up her phone lines\", 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"She laughs and goes away from him and back to her cooking. Christ, Capa ! I can't have people tying up the phone lines. I'm trying to run a business here.\"\n",
      "prediction :  I'm calling my Dad.\n",
      "Real answer : She laughs and goes away from him and back to her cooking. Christ, Capa ! I can't have people tying up the phone lines. I'm trying to run a business here.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8858352899551392], 'recall': [0.8371662497520447], 'f1': [0.8608134388923645], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10810810810810811, 'rouge2': 0.05714285714285715, 'rougeL': 0.10810810810810811, 'rougeLsum': 0.10810810810810811}\n",
      "bleu 1/2 : 0.0002927199051977936 0.00010688619673840353\n",
      "ppl : 79.89852142333984\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBILL: Voice over.\\nROSE: Voice ironically disappointed.\\nBILL: Oh, our, our tank fleet is crippled.\\nROSE: Yeah ?\\nBILL: It's goin' away.\\nROSE: How's the submarine fleet ?\\nBILL: Hey, hey, hey, hey, please, please. I gotta get some sleep.\\nROSE: They kiss. Oh, you're chicken.\\nBILL: I gotta be up...\\nROSE: You're chicken.\\nBILL: I gotta be up at 6:00 in the morning.\\n\\n\", 'answer': \"She turns around to kiss him. You're chicken, chicken.\", 'gold_tag': 'ROSE is playful , ROSE enjoys teasing BILL , ROSE calls BILL \"chicken\"', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"She turns around to kiss him. You're chicken, chicken.\"\n",
      "prediction :  I'm gonna give you that, but I gotta tell you --\n",
      "Real answer : She turns around to kiss him. You're chicken, chicken.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8263660669326782], 'recall': [0.843869686126709], 'f1': [0.8350261449813843], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809525, 'rouge2': 0.0, 'rougeL': 0.09523809523809525, 'rougeLsum': 0.09523809523809525}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.770479202270508\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBILL: One of my patients was killed last night. He was murdered.\\nROSE: She seems very disturbed by the news. What ?\\nBILL: The painter. Casey.\\nROSE: She has tears in her eyes. Were you there ?\\nBILL: A little bit after.\\nROSE: What did you see ?\\nBILL: You don't want to know. About a half hour before group. I'm gonna get a shower. You gonna be okay out here ?\\n\\n\", 'answer': 'Yeah.', 'gold_tag': 'ROSE will stay in the current location while BILL showers', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"Yeah.\"\n",
      "prediction :  I'm fine.\n",
      "Real answer : Yeah.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8828050494194031], 'recall': [0.9474420547485352], 'f1': [0.9139821529388428], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 87.44342803955078\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBILL: Rose.\\nROSE: She jumps. Oh ! Oh !\\n\\n', 'answer': 'Rose ! Rose !', 'gold_tag': 'Everyday Language', 'last_speaker': 'BILL'}\n",
      "Last word -> BILL : \"Rose ! Rose !\"\n",
      "prediction :  Rose, what kind of idiot do you think Rose (rose) is to jump (jump), right in the air. I'll take you to Rose Hospital. If you try to commit suicide again, you just walk right to the nurse at the reception and tell her you want to die.\n",
      "Real answer : Rose ! Rose !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8064841032028198], 'recall': [0.854041576385498], 'f1': [0.8295817971229553], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07843137254901959, 'rouge2': 0.04081632653061225, 'rougeL': 0.07843137254901959, 'rougeLsum': 0.07843137254901959}\n",
      "bleu 1/2 : 0.041666666666666664 0.00941554471443387\n",
      "ppl : 30.20322036743164\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMO: Hey. You're creasing the pants.\\nSHADES: Tough guy.\\nMO: Shut up.\\nSHADES: That's why you're still in the corps, isn't it?\\nMO: Why?\\nSHADES: You tell me. No, really. Tell me why.\\nMO: The money's good. I get around. I see what's left of the world.\\nSHADES: I get around, too, and at least I'm still in one piece.\\nMO: Yeah, until one of your boosters blows up under you or your heatshield rips off on the way home.\\nSHADES: Don't knock it. At least it’s quick. One pssht and you're gas spread out over a thousand miles of stratosphere. Think of the view. No coughing your lungs out in a bunker or sitting around waiting for the first cancer cells to show up or your kids to be born blind and blue because you've had one dose too many and come up snake eyes in the genetic crap game you play every time you go zone tripping. DO you think Jill wants you to go on strolling around out there up to your ass in radioactive iodine for the rest of your life?\\n\\n\", 'answer': \"Think she'd like it better if I was on welfare? Wound up like these bums? Nothing else I can do. Not now. Anyway, I don't want kids. Can't stand the little motherfuckers.\", 'gold_tag': 'MO dislikes being dependent on welfare , MO is not keen on having children , MO has a grim, fatalistic outlook on life', 'last_speaker': 'MO'}\n",
      "Last word -> MO : \"Think she'd like it better if I was on welfare? Wound up like these bums? Nothing else I can do. Not now. Anyway, I don't want kids. Can't stand the little motherfuckers.\"\n",
      "prediction :  That's not so bad, eh?\n",
      "Real answer : Think she'd like it better if I was on welfare? Wound up like these bums? Nothing else I can do. Not now. Anyway, I don't want kids. Can't stand the little motherfuckers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8250527381896973], 'recall': [0.8165053725242615], 'f1': [0.820756733417511], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.048780487804878044, 'rouge2': 0.0, 'rougeL': 0.048780487804878044, 'rougeLsum': 0.048780487804878044}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 28.86924934387207\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMO: Jesus... Oh, Jesus... Jill. Come on...come on...!\\nSHADES: Ayuh... Hey, uh...wow, um...it's cool, but...right now it's, uh, kinda difficult... Do you know what time it is?\\nMO: Listen to me! This is serious! Jill's in danger and you've gotta help her!\\nSHADES: Oh, Jeez. Oh...Christ. It had to be tonight.\\nMO: What's wrong?\\nSHADES: My heart feels like an alligator.\\nMO: What?! Shades. What's wrong with you?!\\nSHADES: You know that tab of acid I was saving...?\\nMO: Oh no...\\n\\n\", 'answer': \"Yeah. I dropped it. Like...Christmas can get pretty crazy on your own, y'know? I've just been sitting here staring at the stars all night. The sky's so beautiful...\", 'gold_tag': 'SHADES has recently consumed acid and is currently under its effects', 'last_speaker': 'SHADES'}\n",
      "Last word -> SHADES : \"Yeah. I dropped it. Like...Christmas can get pretty crazy on your own, y'know? I've just been sitting here staring at the stars all night. The sky's so beautiful...\"\n",
      "prediction :  Oh, Jesus. How'd this get to be so...how come it got to be so bad?!\n",
      "Real answer : Yeah. I dropped it. Like...Christmas can get pretty crazy on your own, y'know? I've just been sitting here staring at the stars all night. The sky's so beautiful...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8402701020240784], 'recall': [0.8348913192749023], 'f1': [0.8375720977783203], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12244897959183672, 'rouge2': 0.0, 'rougeL': 0.08163265306122448, 'rougeLsum': 0.08163265306122448}\n",
      "bleu 1/2 : 0.05604671793449092 0.01297229449750861\n",
      "ppl : 31.023096084594727\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMO: Hey! Hey! Listen to me! Come back! You've got to do this for me! You've got to go down to the apartment and get Jill out of there right\\nSHADES: Yeah, yeah. Okay.\\nMO: Go get Jill. Bring her to your place and lock the door. Got that?\\nSHADES: What's going on? You in trouble with the cops again or --\\nMO: I'll tell you later! Just do it! Now!\\nSHADES: Okay, okay. Just let me get my pants on.\\nMO: Hurry, Shades. I'm counting on you.\\nSHADES: No sweat. I'll be seeing you later, huh?\\nMO: Yeah, just watch yourself, okay?\\n\\n\", 'answer': 'Oh, yeah. Noooooo problem. See ya. Bye.', 'gold_tag': \"SHADES shows a calm demeanor despite MO's urgency\", 'last_speaker': 'SHADES'}\n",
      "Last word -> SHADES : \"Oh, yeah. Noooooo problem. See ya. Bye.\"\n",
      "prediction :  Okay... All right. I'll get down there right....\n",
      "Real answer : Oh, yeah. Noooooo problem. See ya. Bye.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8079285621643066], 'recall': [0.8502340316772461], 'f1': [0.8285415768623352], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 82.17268371582031\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTAFT: Eddie Shitface! Where you been, boy? Eddie, I don't think I introduced you to my new partner, Michael Hernandez...\\n\\n\", 'answer': 'Pleased to meet you, Mr. Shitface...', 'gold_tag': 'HERNANDEZ is a new partner to TAFT , HERNANDEZ has a formal tone indicating a level of education or professionalism', 'last_speaker': 'HERNANDEZ'}\n",
      "Last word -> HERNANDEZ : \"Pleased to meet you, Mr. Shitface...\"\n",
      "prediction :  I'm sorry, sir.\n",
      "Real answer : Pleased to meet you, Mr. Shitface...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8852166533470154], 'recall': [0.8502141833305359], 'f1': [0.8673624396324158], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 38.490203857421875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTAFT: This is our collar? Who is he?\\n\\n', 'answer': 'Some scumbag...', 'gold_tag': \"HERNANDEZ has a negative view of people they consider 'scumbags' , This negative view is likely due to their job\", 'last_speaker': 'HERNANDEZ'}\n",
      "Last word -> HERNANDEZ : \"Some scumbag...\"\n",
      "prediction :  It’s me; it used to be my mother’s; she didn’t have children.\n",
      "Real answer : Some scumbag...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8127333521842957], 'recall': [0.8171452283859253], 'f1': [0.8149333000183105], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 25.277511596679688\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTAFT: Who are you, man? Who the fuck are you?\\n\\n', 'answer': \"I'm me.\", 'gold_tag': 'HERNANDEZ indicates his identity only as \"me\"', 'last_speaker': 'HERNANDEZ'}\n",
      "Last word -> HERNANDEZ : \"I'm me.\"\n",
      "prediction :  I’m your best friend Jack. I’m the only one who has your back.\n",
      "Real answer : I'm me.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8531115651130676], 'recall': [0.9214187264442444], 'f1': [0.8859504461288452], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2222222222222222, 'rouge2': 0.125, 'rougeL': 0.2222222222222222, 'rougeLsum': 0.2222222222222222}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.391372680664062\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLATESHA: Tell me she has an off switch --\\nSCOTT: We can only unlock the emergency override from the main terminal, and that's assuming she lets us in.\\nLATESHA: What're we supposed to do, say pretty\\n\\n\", 'answer': \"We can't shut her down, but maybe we can get her to shut herself down. Help me with this As they tug at the hatch --\", 'gold_tag': 'SCOTT is responsible for problem-solving', 'last_speaker': 'SCOTT'}\n",
      "Last word -> SCOTT : \"We can't shut her down, but maybe we can get her to shut herself down. Help me with this As they tug at the hatch --\"\n",
      "prediction :  Okay, do what you want, but make sure you take out your weapon after you're done.\n",
      "Real answer : We can't shut her down, but maybe we can get her to shut herself down. Help me with this As they tug at the hatch --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8548156023025513], 'recall': [0.8466219305992126], 'f1': [0.8506990671157837], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.04651162790697675, 'rouge2': 0.0, 'rougeL': 0.04651162790697675, 'rougeLsum': 0.04651162790697675}\n",
      "bleu 1/2 : 0.03345383928243689 0.010925978157206149\n",
      "ppl : 21.93385887145996\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSCOTT: This controls her primary cooling system... if we cut the circulation, the temp in her tank goes up.\\nLATESHA: So we boil her brain.\\nSCOTT: She'll have to shut herself down to keep from overheating.\\nLATESHA: Can't she just drain the. water?\\n\\n\", 'answer': 'Not anymore.', 'gold_tag': 'SCOTT demonstrates technical expertise', 'last_speaker': 'SCOTT'}\n",
      "Last word -> SCOTT : \"Not anymore.\"\n",
      "prediction :  I think what I need to do is I need to bring her into the control room.\n",
      "Real answer : Not anymore.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.838405966758728], 'recall': [0.8741185665130615], 'f1': [0.8558899164199829], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 20.65447998046875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSCOTT: So...\\nLATESHA: So...\\nSCOTT: Hey :you think I could have your... you KNOW\\n\\n', 'answer': \"That's my address. I'm not using a cell phone anymore. Pick me up at eight.\", 'gold_tag': 'LATESHA has decided not to use a cell phone anymore , LATESHA will be available for SCOTT to pick her up at eight', 'last_speaker': 'LATESHA'}\n",
      "Last word -> LATESHA : \"That's my address. I'm not using a cell phone anymore. Pick me up at eight.\"\n",
      "prediction :  yeah.\n",
      "Real answer : That's my address. I'm not using a cell phone anymore. Pick me up at eight.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9067261815071106], 'recall': [0.8449791669845581], 'f1': [0.8747643232345581], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 6502.19970703125\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRON: You can have our old room. I’m in the basement.\\nJOHN: What, you live here now?\\n\\n', 'answer': 'We’re in a recession.', 'gold_tag': 'RON refers to the recession', 'last_speaker': 'RON'}\n",
      "Last word -> RON : \"We’re in a recession.\"\n",
      "prediction :  I'm still here.\n",
      "Real answer : We’re in a recession.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9067401885986328], 'recall': [0.8988308906555176], 'f1': [0.9027681946754456], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 33.58161544799805\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRON: She is going to be okay, right?\\nJOHN: Yeah. Better then ever.\\n\\n', 'answer': 'Tell Dad I’ll take the job.', 'gold_tag': 'RON is going to take a job , RON has an upcoming occupational commitment', 'last_speaker': 'RON'}\n",
      "Last word -> RON : \"Tell Dad I’ll take the job.\"\n",
      "prediction :  Why you acting so hostile?\n",
      "Real answer : Tell Dad I’ll take the job.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8421616554260254], 'recall': [0.8447511196136475], 'f1': [0.8434544205665588], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 715.8826904296875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRON: John. John.\\n\\n', 'answer': 'What? What is it?', 'gold_tag': 'Everyday Language', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"What? What is it?\"\n",
      "prediction :  Yeah?\n",
      "Real answer : What? What is it?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9347659349441528], 'recall': [0.8829267024993896], 'f1': [0.9081071019172668], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 67594.546875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRON: Everyone got on their seat belts?\\nJOHN: Yeah. Just go. Go, go!\\nRON: Shit. I never did get that fixed.\\n\\n', 'answer': 'Oh my God.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"Oh my God.\"\n",
      "prediction :  (2015 Nissan Pathfinder King Sized SUV (9 Seat) with a 3.5 Liter V6 Engine)\n",
      "Real answer : Oh my God.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7838701009750366], 'recall': [0.8128703832626343], 'f1': [0.7981069087982178], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 19.529016494750977\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMALCOLM: That's one fine frame. A fine frame it is. How much does a fine frame like that cost, you think?\\nANNA: I've never told you... but you sound a little like Dr. Seuss when you're drunk.\\nMALCOLM: Anna, I'm serious. Serious I am, Anna.\\nANNA: Mahogany. I'd say that cost at least a couple hundred. Maybe three.\\nMALCOLM: Three? We should hock it. Buy a C.D. rack for the bedroom.\\nANNA: Do you know how important this is? This is big time. I'm going to read it for you, doctor.\\nMALCOLM: Do I really sound like Dr. Seuss?\\nANNA: In recognition for his outstanding achievement in the field of child psychology, his dedication to his work, and his continuing efforts to improve the quality of life for countless children and their families, the City of Philadelphia proudly bestows upon its son Dr. Malcolm Crowe... That's you... the Mayor's Citation for Professional Excellence. Wow. They called you their son.\\nMALCOLM: We can keep it in the bathroom. It's not real, Anna. Some secretary wrote that up. Don't tell me you thought it was real? What? Don't do the quiet thing. You know I hate it.\\nANNA: This is an important night for us. Finally someone is recognizing the sacrifices you made. That you have put everything second, including me, for those families they're talking about. They're also saying that my husband has a gift. Not an ordinary gift that allows him to hit a ball over a fence. Or a gift that lets him produce beautiful images on a canvas... Your gift teaches children how to be strong in situations where most adults would piss on themselves. Yes, I believe what they wrote about you.\\nMALCOLM: Thank you. What are we hugging about again?\\nANNA: Nothing. There wasn't supposed to be any crying at this celebration. Just a lot of drinking and sex.\\n\\n\", 'answer': 'I would like some red wine in a glass. I would not like it in a mug. I would not like it in a jug.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MALCOLM'}\n",
      "Last word -> MALCOLM : \"I would like some red wine in a glass. I would not like it in a mug. I would not like it in a jug.\"\n",
      "prediction :  When you have a child, you never sleep. Ever. They eat at night. There's never any quiet. There's the sound of a baby crying at 7 AM. Or they're awoken at 8 AM to a baby yelling at the bottom of the stairs. You know - he's yelling at his baby. I mean, what kind of guy does that?\n",
      "Real answer : I would like some red wine in a glass. I would not like it in a mug. I would not like it in a jug.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8280274271965027], 'recall': [0.8502469062805176], 'f1': [0.8389900922775269], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09195402298850575, 'rouge2': 0.0, 'rougeL': 0.0689655172413793, 'rougeLsum': 0.0689655172413793}\n",
      "bleu 1/2 : 0.06779661016949153 0.010811600584038359\n",
      "ppl : 11.974944114685059\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMALCOLM: Anna, I've been so lost. I need my best friend.\\nANNA: I miss you.\\nMALCOLM: I miss you.\\nANNA: Why, Malcolm?\\nMALCOLM: What, Anna? What did I do? What's made you so sad?\\nANNA: Why did you leave me?\\n\\n\", 'answer': \"I didn't leave you. No...\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MALCOLM'}\n",
      "Last word -> MALCOLM : \"I didn't leave you. No...\"\n",
      "prediction :  Anna!\n",
      "Real answer : I didn't leave you. No...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8684155344963074], 'recall': [0.8494476675987244], 'f1': [0.8588268756866455], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 88265.40625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMALCOLM: ANNA! Don't cry. I think I have to go. I just needed to do a couple of things. And I needed to tell you something.\\nANNA: Tell me.\\nMALCOLM: You were never second... Ever. You sleep now, Anna. Everything will be different in the morning.\\nANNA: Goodnight, Malcolm.\\n\\n\", 'answer': \"Goodnight, sweetheart. ...I think I've had too much to drink. I just have to say, this day today has been one very special day... I wish we all could stay and play. What? Anna, I never thought I'd feel the things I'm feeling. I never thought I'd be able to stand up in front of my friends and family and tell them what's inside me... Today I can... Anna Crowe... I am in love. In love I am.\", 'gold_tag': \"MALCOLM attempted to comfort Anna and confessed his love , MALCOLM has a tendency for drinking , MALCOLM reveals he has had too much to drink and infers it's evening or night time\", 'last_speaker': 'MALCOLM'}\n",
      "Last word -> MALCOLM : \"Goodnight, sweetheart. ...I think I've had too much to drink. I just have to say, this day today has been one very special day... I wish we all could stay and play. What? Anna, I never thought I'd feel the things I'm feeling. I never thought I'd be able to stand up in front of my friends and family and tell them what's inside me... Today I can... Anna Crowe... I am in love. In love I am.\"\n",
      "prediction :  Anna, I don't know where my life is going, but I'd love for you and our kids to be a part of it.\n",
      "Real answer : Goodnight, sweetheart. ...I think I've had too much to drink. I just have to say, this day today has been one very special day... I wish we all could stay and play. What? Anna, I never thought I'd feel the things I'm feeling. I never thought I'd be able to stand up in front of my friends and family and tell them what's inside me... Today I can... Anna Crowe... I am in love. In love I am.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8573594093322754], 'recall': [0.8253467082977295], 'f1': [0.841048538684845], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18518518518518517, 'rouge2': 0.037735849056603765, 'rougeL': 0.11111111111111109, 'rougeLsum': 0.11111111111111109}\n",
      "bleu 1/2 : 0.0358083566649828 0.012204379773959488\n",
      "ppl : 10.754672050476074\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMONA: Why did you join a support group of unattractive, militant lesbians when you have me?\\nZOE: Because you\\'re really not that supportive.\\nMONA: Sure I am.\\nZOE: You just told me that if I breast- feed \"my girls\" will end up looking like empty tube socks.\\nMONA: I\\'m just being honest. And don\\'t even get me started on what childbirth does to your bladder.\\nZOE: What does it do to your bladder?\\nMONA: I just peed a little bit.\\nZOE: I don\\'t think I\\'m pregnant. The doctor says it will probably take several tries. Something about frozen sperm being lazy.\\nMONA: Good. Take your time.\\nZOE: So, should I call this guy? Do you think that would be weird?\\nMONA: Do I think it\\'s weird that you\\'re pursuing someone at the exact moment in time that you might be most unavailable? No. Because that\\'s what you do. You sabotage.\\nZOE: He works at the Farmer\\'s market. And it\\'s right around the corner. Are you thinking what I\\'m thinking? No.\\nMONA: Then, no.\\nZOE: Let\\'s go spy on him. Come on. It will be fun. Like high school.\\n\\n', 'answer': 'I can\\'t. This twenty minute breakfast concludes my \"me\" time for the week. More proof that you should not have kids.', 'gold_tag': 'MONA has limited personal time, reflecting a busy lifestyle', 'last_speaker': 'MONA'}\n",
      "Last word -> MONA : \"I can't. This twenty minute breakfast concludes my \"me\" time for the week. More proof that you should not have kids.\"\n",
      "prediction :  But I didn't see any eggs.\n",
      "Real answer : I can't. This twenty minute breakfast concludes my \"me\" time for the week. More proof that you should not have kids.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8615032434463501], 'recall': [0.8467578291893005], 'f1': [0.8540669083595276], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13793103448275862, 'rouge2': 0.0, 'rougeL': 0.13793103448275862, 'rougeLsum': 0.13793103448275862}\n",
      "bleu 1/2 : 0.013680833103983134 0.0047391796051938035\n",
      "ppl : 54.48143005371094\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZOE: What if I\\'m pregnant?\\nMONA: Then you\\'ll get fat and hormonal and I\\'ll say, \"I told you so.\"\\nZOE: But what if this could go somewhere with Stan? Like, really go somewhere.\\nMONA: Then it will work out perfectly.\\nZOE: What do you mean?\\nMONA: Because just when you really like him, you\\'ll break up because you\\'re pregnant and then you never have to put yourself out there and possibly get hurt. That\\'s your dream.\\n\\n', 'answer': \"I'm not pregnant.\", 'gold_tag': 'Zoe may be pregnant, which will only be relevant for a short period until pregnancy is confirmed or ruled out', 'last_speaker': 'ZOE'}\n",
      "Last word -> ZOE : \"I'm not pregnant.\"\n",
      "prediction :  I love you. I do.\n",
      "Real answer : I'm not pregnant.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8846467137336731], 'recall': [0.8880783319473267], 'f1': [0.8863592147827148], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.22222222222222224, 'rougeLsum': 0.22222222222222224}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 41.70455551147461\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMONA: Why are you even working out? This is the one time in your life you're allowed to let it go.\\nZOE: Because look at me. I just keep\\nMONA: Well, yeah. That's kind of how it goes.\\nZOE: I'm afraid I'm going to scare him away. I'm like one of those giant bouncy castles. Soon I'm going to take over the whole back yard.\\nMONA: Come on. He loves you for you.\\nZOE: I'm just getting kind of freaked out by everything. He asked me to go to this wedding with him. What\\nMONA: Well, you're knocked up with some stranger's twins. So, already you're not exactly...\\nZOE: Not helping.\\n\\n\", 'answer': 'Do you have anything to wear at least?', 'gold_tag': 'Everyday Language', 'last_speaker': 'MONA'}\n",
      "Last word -> MONA : \"Do you have anything to wear at least?\"\n",
      "prediction :  Are you a vegetarian? I am a vegetarian, and I'm not a great one but you know. I like a little bit of meat.\n",
      "Real answer : Do you have anything to wear at least?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8386309146881104], 'recall': [0.8457162380218506], 'f1': [0.8421586751937866], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06060606060606061, 'rouge2': 0.0, 'rougeL': 0.06060606060606061, 'rougeLsum': 0.06060606060606061}\n",
      "bleu 1/2 : 0.041666666666666664 0.013459547551454133\n",
      "ppl : 14.775688171386719\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLESLIE: We'll be right down.\\nALEC: June first!'\\nLESLIE: Honey, I just got promoted. I'm going to have a lot more responsibility. I'm sure it's\\nALEC: Looking at my big picture agenda, I want to be playing softball with my firstborn in about four years.\\nLESLIE: Do you realize that over half the marriages today end in divorce.\\nALEC: And the other half don't.\\nLESLIE: My six-year-old niece asked me today why everyone's father doesn't live in a separate house like her father does. I don't want us to become another divorce statistic in Newsweek.\\nALEC: Look at my parents. My father may not come home with a raging hard- on, anymore, but they're happy.\\nLESLIE: Your father sits around playing chess while your mother talks to him constantly. But he's not listening.\\nALEC: That's probably why they're happy. Leslie, let's stop living together . get married and start really living together!\\nLESLIE: Sweetheart, please. Let's not talk about it tonight. This party means a lot to Kirbo. The floor's filthy again.\\nALEC: Just pick a date, any date...\\n\\n\", 'answer': 'There are some things we have to work out first.', 'gold_tag': 'LESLIE wants to work things out before setting a wedding date', 'last_speaker': 'LESLIE'}\n",
      "Last word -> LESLIE : \"There are some things we have to work out first.\"\n",
      "prediction :  And remember, our honeymoon must begin at midnight. It's very important to your father.\n",
      "Real answer : There are some things we have to work out first.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8638664484024048], 'recall': [0.8711125254631042], 'f1': [0.8674744367599487], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0.07142857142857141 0.023440361546924773\n",
      "ppl : 59.11177062988281\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALEC: Okay. Okay. Like my mom always says, 'Don't get a hard-on'...\\nLESLIE: And like my mom always says... 'Marriage makes two people one. But you never know which one.'\\n\\n\", 'answer': \"Yeah, and like my pop says, 'The way to woman's heart is,to saw her in half.'\", 'gold_tag': 'ALEC might have a sarcastic and humorous personality', 'last_speaker': 'ALEC'}\n",
      "Last word -> ALEC : \"Yeah, and like my pop says, 'The way to woman's heart is,to saw her in half.'\"\n",
      "prediction :  I hope you had fun, but now its time to go, remember...\n",
      "Real answer : Yeah, and like my pop says, 'The way to woman's heart is,to saw her in half.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.836189866065979], 'recall': [0.827646017074585], 'f1': [0.8318960070610046], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06666666666666667, 'rouge2': 0.0, 'rougeL': 0.06666666666666667, 'rougeLsum': 0.06666666666666667}\n",
      "bleu 1/2 : 0.05971094254781577 0.019721875238006125\n",
      "ppl : 37.02888870239258\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALEC: Did you forget one of your albums?\\n\\n', 'answer': \"I'm sorry to bother you here. It's Jules. After she left for work this morning, the finance company came and took away all her furniture, her Jeep, everything they could get their hands on... I couldn't reach her so I finally went over to her office. Alec -- she was fired three weeks ago! All this time, she's been pretending to go to work every day having this affair with her boss. And she's been doing a lot of coke .. Well, anyway, I confronted her at the apartment, and at first she denied everything, but then she went crazy -- and now she's locked herself in the apartment and she won't let me back in... I'm really worried about her. Alec, please. I need your help.\", 'gold_tag': \"LESLIE is a caring friend , LESLIE is concerned about Jules , LESLIE takes the initiative to check on Jules's wellbeing , LESLIE confronts Jules about her problems , LESLIE has a current issue that Jules has lost her job, possessions, and is now locked inside her apartment\", 'last_speaker': 'LESLIE'}\n",
      "Last word -> LESLIE : \"I'm sorry to bother you here. It's Jules. After she left for work this morning, the finance company came and took away all her furniture, her Jeep, everything they could get their hands on... I couldn't reach her so I finally went over to her office. Alec -- she was fired three weeks ago! All this time, she's been pretending to go to work every day having this affair with her boss. And she's been doing a lot of coke .. Well, anyway, I confronted her at the apartment, and at first she denied everything, but then she went crazy -- and now she's locked herself in the apartment and she won't let me back in... I'm really worried about her. Alec, please. I need your help.\"\n",
      "prediction :  I got the whole thing, Alec. Why do we always have to put them out of order?\n",
      "Real answer : I'm sorry to bother you here. It's Jules. After she left for work this morning, the finance company came and took away all her furniture, her Jeep, everything they could get their hands on... I couldn't reach her so I finally went over to her office. Alec -- she was fired three weeks ago! All this time, she's been pretending to go to work every day having this affair with her boss. And she's been doing a lot of coke .. Well, anyway, I confronted her at the apartment, and at first she denied everything, but then she went crazy -- and now she's locked herself in the apartment and she won't let me back in... I'm really worried about her. Alec, please. I need your help.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8292198181152344], 'recall': [0.7962767481803894], 'f1': [0.8124144077301025], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06711409395973154, 'rouge2': 0.0, 'rougeL': 0.06711409395973154, 'rougeLsum': 0.06711409395973154}\n",
      "bleu 1/2 : 0.0003643093392122539 5.937515801075783e-05\n",
      "ppl : 55.18923568725586\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEIL: Come away with me.\\nEADY: What?\\nNEIL: New Zealand.\\nEADY: When?\\nNEIL: Soon.\\nEADY: You\\'re kidding.\\nNEIL: What\\'s stopping you? What\\'s here?\\nEADY: I don\\'t know you.\\nNEIL: What\\'s to know?\\nEADY: Are you married?\\nNEIL: Why?\\nEADY: Way you come and go.\\nNEIL: I deal with state officials. County. Weird hours. A lot of traveling, entertaining. The last thing I am is married.\\nEADY: You don\\'t know me at all, Neil...\\nNEIL: I know enough.\\nEADY: My father wanted me to marry someone in Taipei. It was like I was a piece of furniture: \"Go be his wife.\" After I left he won\\'t talk to me. Because I went on my own. I can\\'t let people tell roe what to do again. And that trust comes from knowing someone over time. This is hard between us for me. Because I like you very much.\\n\\n', 'answer': \"I have to leave. Come away with me. No one will ever tell you what to do... You'll never lose yourself with me.\", 'gold_tag': 'NEIL has plans to leave soon and wants EADY to join him , NEIL is inquisitive and adventurous, proposing to travel to New Zealand', 'last_speaker': 'NEIL'}\n",
      "Last word -> NEIL : \"I have to leave. Come away with me. No one will ever tell you what to do... You'll never lose yourself with me.\"\n",
      "prediction :  You should try to get along. My father hates you. You could make peace between us.\n",
      "Real answer : I have to leave. Come away with me. No one will ever tell you what to do... You'll never lose yourself with me.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8923746943473816], 'recall': [0.8685712814331055], 'f1': [0.8803120851516724], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15, 'rouge2': 0.0, 'rougeL': 0.15, 'rougeLsum': 0.15}\n",
      "bleu 1/2 : 0.04035303290174325 0.013179245357734959\n",
      "ppl : 43.77810287475586\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEADY: What did you do? Was that you?\\nNEIL: It's what I don't do. I don't sell swimming pools. It would have been okay. You would have flown out after. You didn't need to do a thing. Now I'm jammed. We got to go together. Because we get dropped in a place and then I decide: New Zealand or Brazil or Tunisia, whatever. I can't leave a string back here to where I am.\\nEADY: What.\\nNEIL: I rob and steal for a living. Do you understand?\\nEADY: You killed people?\\nNEIL: If they got in the way. Yes. It's their problem.\\nEADY: The woman on the grass...where her husband got shot..\\nNEIL: Elaine Cerrito. Michael Cerrito's wife. Michael was my friend. He knew the risks. He didn't have to be there. He coulda been a...been a mailman.\\nEADY: I don't believe it.\\n\\n\", 'answer': \"Believe it. Eady. Get packed. Get dressed. Let's go.\", 'gold_tag': 'NEIL indicates a need to leave quickly, with their destination decided on the spot', 'last_speaker': 'NEIL'}\n",
      "Last word -> NEIL : \"Believe it. Eady. Get packed. Get dressed. Let's go.\"\n",
      "prediction :  I’m not mad. And I don’t like to think about it. I mean, it happened. And no reason for you to get angry. All right? I’m sure there’s a reason for you. All right?\n",
      "Real answer : Believe it. Eady. Get packed. Get dressed. Let's go.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8213638067245483], 'recall': [0.8666649460792542], 'f1': [0.8434064984321594], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.02941176470588235 0.009440686400617014\n",
      "ppl : 10.192008972167969\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEIL: Eady! !\\nEADY: Why you do this to me! What I do to you?!\\n\\n', 'answer': 'Shut up!', 'gold_tag': 'Everyday Language', 'last_speaker': 'NEIL'}\n",
      "Last word -> NEIL : \"Shut up!\"\n",
      "prediction :  You know it. I am so sorry darling I am just so very very sorry...\n",
      "Real answer : Shut up!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7895169258117676], 'recall': [0.8439542055130005], 'f1': [0.8158285021781921], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 61.08317565917969\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEIL: Use these credit cards. They say \"Mr. and Mrs.\" I reserved the car. Buy me some clothes. Here\\'s a list. I can\\'t go home for my stuff. Can you do it?\\nEADY: When\\'s it over?\\nNEIL: Twenty-two hours. Then we fly out of here...clean.\\nEADY: I want you to let me go. When will you let me go?\\nNEIL: You can go now. There\\'s the door, you want out...\\nEADY: No, I have to do what you say. But will you let me leave after?\\n\\n', 'answer': 'It will be different...', 'gold_tag': 'NEIL suggests a life involving criminal activities or running from something', 'last_speaker': 'NEIL'}\n",
      "Last word -> NEIL : \"It will be different...\"\n",
      "prediction :  Will you please help me pack and send some of it to my brother?\n",
      "Real answer : It will be different...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8302193880081177], 'recall': [0.8441498875617981], 'f1': [0.8371266722679138], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.11111111111111112, 'rougeLsum': 0.11111111111111112}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 39.07798767089844\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEIL: Any trouble?\\nEADY: No. When's it over?\\n\\n\", 'answer': \"Six hours. 8 p.m. I'll buy you lunch. Everything's smooth. We're going to fly away...\", 'gold_tag': \"NEIL is involved in an operation or job that will be concluded in six hours , NEIL is confident enough to plan ahead for a meal and a future escape , NEIL's job or operation will be over in six hours at 8 p.m.\", 'last_speaker': 'NEIL'}\n",
      "Last word -> NEIL : \"Six hours. 8 p.m. I'll buy you lunch. Everything's smooth. We're going to fly away...\"\n",
      "prediction :  I'll be over there. Do you want to go up to the house?\n",
      "Real answer : Six hours. 8 p.m. I'll buy you lunch. Everything's smooth. We're going to fly away...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8614199161529541], 'recall': [0.8602536916732788], 'f1': [0.860836386680603], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.24242424242424243, 'rouge2': 0.06451612903225808, 'rougeL': 0.24242424242424243, 'rougeLsum': 0.24242424242424243}\n",
      "bleu 1/2 : 0.19786244288317878 0.037599649154247045\n",
      "ppl : 16.1672306060791\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEIL: Leave it running. ...be right back, Eady.\\n\\n', 'answer': 'Neil...?', 'gold_tag': 'Everyday Language', 'last_speaker': 'EADY'}\n",
      "Last word -> EADY : \"Neil...?\"\n",
      "prediction :  Hey, Neil. Let me know what's going on.\n",
      "Real answer : Neil...?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8400010466575623], 'recall': [0.8199547529220581], 'f1': [0.8298568725585938], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.19999999999999998, 'rouge2': 0.0, 'rougeL': 0.19999999999999998, 'rougeLsum': 0.19999999999999998}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 36.11728286743164\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJAMES: Do you have an ice pick I can jam into my ears? I can’t listen to this song again!\\nCONNELL: No, but I have this. Be cool with that. So, were you on a date the other night?\\nJAMES: Um. I wouldn’t call it a date.\\nCONNELL: Not into Em?\\nJAMES: No, she’s great. But I’m not really looking for a girlfriend. I’m getting over a broken heart.\\nCONNELL: You didn’t tell her that, did you?\\nJAMES: Um, why?\\nCONNELL: Christ. Girls don’t want to hear about your broken heart.\\nJAMES: Wh-why not?\\nCONNELL: Because women don’t want a guy who’s all confused and torn up over someone else. Look, I’m not saying you should never be vulnerable in front of a girl. But you don’t play that card first.\\nJAMES: It’s a card? Like a...card?\\n\\n', 'answer': 'There’s a science to it all. You should like that, I bet you’re good at science.', 'gold_tag': 'JAMES could potentially have an interest or proficiency in science, as suggested by CONNELL', 'last_speaker': 'CONNELL'}\n",
      "Last word -> CONNELL : \"There’s a science to it all. You should like that, I bet you’re good at science.\"\n",
      "prediction :  Good morning to you, Mr. Bond.\n",
      "Real answer : There’s a science to it all. You should like that, I bet you’re good at science.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8642997741699219], 'recall': [0.8327834606170654], 'f1': [0.8482489585876465], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.03147926713959365 0.010904738014161919\n",
      "ppl : 63.490352630615234\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCONNELL: You got one of those little baby joints on you?\\nJAMES: I do.\\n\\n', 'answer': 'I could use that. Let’s go for a ride.', 'gold_tag': 'CONNELL has a habit of using marijuana', 'last_speaker': 'CONNELL'}\n",
      "Last word -> CONNELL : \"I could use that. Let’s go for a ride.\"\n",
      "prediction :  Do you need any help holding that joint in place?\n",
      "Real answer : I could use that. Let’s go for a ride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8353679776191711], 'recall': [0.8717184662818909], 'f1': [0.8531562089920044], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10000000000000002, 'rouge2': 0.0, 'rougeL': 0.10000000000000002, 'rougeLsum': 0.10000000000000002}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 86.10474395751953\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJAMES: Your mom okay?\\nCONNELL: My mother’s over three hundred pounds, half-blind from diabetes. She’s also got arthritis and emphysema. And now she can’t control her bowels. Personally, I’d rather be dead.\\nJAMES: I’m sorry...\\nCONNELL: That’s cool...\\nJAMES: It’s Neil Young.\\nCONNELL: Oh. Right.\\nJAMES: Cortez the Killer.\\nCONNELL: Yeh-yeh. ADVENTURELAND (revised 8/5/07)\\nJAMES: You gotta tell me your Neil Young story. He’s, like, a real hero to me. Oh, shit-\\nCONNELL: What the fuck are you doing?\\nJAMES: Cop car.\\nCONNELL: Uh, desperado, it’s a driving school car.\\nJAMES: Oh. So you going tonight?\\nCONNELL: Razzmatazz? Not really my scene. How goes it with Em?\\n\\n', 'answer': 'It’s going...she’s...it’s been... I think I’m in love with her.', 'gold_tag': 'James admits to being in love with a girl named Em', 'last_speaker': 'JAMES'}\n",
      "Last word -> JAMES : \"It’s going...she’s...it’s been... I think I’m in love with her.\"\n",
      "prediction :  Hey, I know what’s wrong. It’s not you. It’s your dog.\n",
      "Real answer : It’s going...she’s...it’s been... I think I’m in love with her.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8713339567184448], 'recall': [0.8503744602203369], 'f1': [0.8607265949249268], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.39999999999999997, 'rouge2': 0.14285714285714288, 'rougeL': 0.26666666666666666, 'rougeLsum': 0.26666666666666666}\n",
      "bleu 1/2 : 0.18181818181818182 0.042640143271122095\n",
      "ppl : 9.886153221130371\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCONNELL: I talked to Em. I know you know... Look, I can’t expect you to be happy about any of this. But will you hear me out? You’re a smart guy. You know that it’s possible to love two people at the same time, right? I love my wife. I really do. I don’t want to hurt her. I fucking despise the idea of her getting hurt. And I don’t think she has to. Beat.\\nJAMES: I won’t tell anyone.\\nCONNELL: Thank you.\\nJAMES: What about Frigo?\\nCONNELL: He won’t tell anyone. I gave him fifty bucks. Are we cool?\\n\\n', 'answer': 'Yeah.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JAMES'}\n",
      "Last word -> JAMES : \"Yeah.\"\n",
      "prediction :  Frigo, Frigo.\n",
      "Real answer : Yeah.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7963256239891052], 'recall': [0.9299108982086182], 'f1': [0.8579494953155518], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 249.41468811035156\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTARLETON: General, a message from the commander of the rebel militia.\\nCORNWALLIS: It seems our Swamp Fox wants to have a formal parley.\\nTARLETON: Are you going to meet with him?\\n\\n', 'answer': 'Most certainly. Arrange it.', 'gold_tag': 'CORNWALLIS has the authority to command TARLETON to arrange the meeting , CORNWALLIS will soon have a meeting with the commander of the rebel militia , TARLETON has to arrange a meeting between CORNWALLIS and the commander of the rebel militia soon', 'last_speaker': 'CORNWALLIS'}\n",
      "Last word -> CORNWALLIS : \"Most certainly. Arrange it.\"\n",
      "prediction :  No. A man of my reputation won't do business with anyone.\n",
      "Real answer : Most certainly. Arrange it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8595876693725586], 'recall': [0.8881466388702393], 'f1': [0.8736338019371033], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 70.3725814819336\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORNWALLIS: From General Clinton in New York... \"... your request to move north is denied until you have properly dealt with your militia problem.\" He underlined, \\'militia\\'. \"You have spent over six months dealing with a six-week problem. It is essential that you quell the militia...\" Underlined again. \"... insurgency, particularly because of the likely move south of Washington and the inevitable arrival of the French. Militia, as you have so often pointed out, is not worth the attention of a significant army, hence it is mystifying why militia has bedeviled you for so long...\" \"... it is my fervent hope that the vigor of your campaign comes to match the vigor of your correspondence with your Parliamentary and Court patrons. Only then might you share in the victory, on the verge of which I now stand.\" \"Your guardedly respectful Commander, General Sir George Clinton.\" If I fail, you fail.\\nTARLETON: Perhaps.\\nCORNWALLIS: And if I triumph, you triumph.\\nTARLETON: Probably.\\nCORNWALLIS: How can we end this madness?\\nTARLETON: Difficult, sir. This is, as you pointed out, a civil war.\\nCORNWALLIS: Civility is a secondary virtue. It is superseded by duty.\\n\\n', 'answer': 'I understand, sir.', 'gold_tag': 'TARLETON understands the importance of duty as pointed out by Cornwallis', 'last_speaker': 'TARLETON'}\n",
      "Last word -> TARLETON : \"I understand, sir.\"\n",
      "prediction :  That was why you took my son, John. When my first son was shot down, you promised to bring back my second-and I would have died if you hadn't. Because I cared about my son and about you. Because I trusted my son would not hurt you. Because I could not bear the thought of him dying on the battlefield without help. Because I knew you cared for your son as much as I cared for mine. I know it was a mistake and it will still be\n",
      "Real answer : I understand, sir.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7955217957496643], 'recall': [0.8585647344589233], 'f1': [0.8258418440818787], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.021505376344086023, 'rouge2': 0.0, 'rougeL': 0.021505376344086023, 'rougeLsum': 0.021505376344086023}\n",
      "bleu 1/2 : 0.011363636363636359 0.003614090617663796\n",
      "ppl : 11.604601860046387\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORNWALLIS: Do you see that, Colonel?\\n\\n', 'answer': \"Unless I'm dreaming, I think I see irregulars at their center.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'TARLETON'}\n",
      "Last word -> TARLETON : \"Unless I'm dreaming, I think I see irregulars at their center.\"\n",
      "prediction :  Yes sir.\n",
      "Real answer : Unless I'm dreaming, I think I see irregulars at their center.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8445848822593689], 'recall': [0.8352676630020142], 'f1': [0.8399004936218262], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1380.511474609375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSYDNEY: Had a sudden intense craving for a cherry popsicle.\\nLUKE: You can check in that freezer.\\nSYDNEY: What a relief. I\\'m Sydney. You?\\nLUKE: Luke.\\nSYDNEY: Workin\\' late, huh? Luke?\\nLUKE: Yeah, four AM. It sucks.\\nSYDNEY: Sometimes you guys are just unfathomably stupid.\\nLUKE: Excuse me?\\nSYDNEY: Why in the world do guys say \"it sucks\" as if it were a bad thing? I mean, every guy\\'s dying to get a blow job, right? So, you think they\\'d treat those words with profound respect, like holy scripture. \"What an unbelievable sunset, honey: doesn\\'t it just SUCK?,\"... \"You won an Olympic Gold Medal?!, that BLOWS!\"\\nLUKE: I guess you\\'re right.\\nSYDNEY: It must be great at your age. That river of testosterone coursing through your veins, the damn about to burst! How about we just lock this place up and go for an Olympic Gold?\\nLUKE: No thanks. Jeez, lady.\\nSYDNEY: I ought to dye my hair. Don\\'t you think?\\nLUKE: Uh, I don\\'t know. Looks fine.\\nSYDNEY: Your hair is such an incredible color.\\nLUKE: It\\'s brown.\\nSYDNEY: I love it. Do you think I could cut just a little piece? Match the color? It really \"sucks.\"\\nLUKE: Nah, c\\'mon. You\\'re messin\\' with me.\\nSYDNEY: I\\'m not. I love it. You really should get rid a\\' that thing, anyway. I have clippers in my bag.\\nLUKE: What thing?\\nSYDNEY: Cowlick. Right here. See? I can just snip it off.\\nLUKE: Hey.\\nSYDNEY: What\\'s the matter? Don\\'t you like being touched? Don\\'t you like being a guy?\\nLUKE: No. I mean,... What? Sorry, but you\\'re just bizarre.\\n\\n', 'answer': \"May be. But I learned long ago, you can't change your true nature, even if it can change you.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SYDNEY'}\n",
      "Last word -> SYDNEY : \"May be. But I learned long ago, you can't change your true nature, even if it can change you.\"\n",
      "prediction :  Hey Luke...\n",
      "Real answer : May be. But I learned long ago, you can't change your true nature, even if it can change you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8210625648498535], 'recall': [0.8140614032745361], 'f1': [0.8175469636917114], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13366.4169921875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSYDNEY: What are we doing here?\\nLUKE: Didn't want anyone around. So, I did what you said.\\nSYDNEY: Amazing, huh?\\nLUKE: Weird. Awful.\\nSYDNEY: Hmm. Was it difficult making the switch?\\nLUKE: No. It was hard gettin' back. I need an owner's manual.\\nSYDNEY: A lot of guys could use one of those.\\nLUKE: So, what now? Do I take pills or something?\\nSYDNEY: No, it doesn't work like that. This may sound odd, but I need to know if you're attracted to me.\\nLUKE: What? No.\\nSYDNEY: Hmm. You're not gay, are you?\\nLUKE: NO! Jeez! I'm just not attracted to you like that.\\nSYDNEY: Okay, calm down. This could be a problem. Right now, you can go either way anytime you want. It's a very special and critical time for a Z, something you'll experience only once in life.\\nLUKE: Good.\\nSYDNEY: You need to use this incredible opportunity you've been given, to figure out which you're supposed to be: male or female.\\nLUKE: What?\\nSYDNEY: Don't you see? You get to choose.\\nLUKE: I don't want to choose. I want to be a guy.\\nSYDNEY: Yes, well, the thing is, sometimes your desires can conflict with your desires. It's important to know for sure.\\nLUKE: Believe me, I know.\\nSYDNEY: I think you need to try again.\\nLUKE: No way!\\nSYDNEY: Why're you so resistant? If the truth is, you want to be a guy, great, but if not...\\nLUKE: Don't even say that!\\nSYDNEY: Well, clearly some part of you feels differently. You couldn't change if you didn't want to.\\nLUKE: What?! That's crap!\\nSYDNEY: That's the thing about the truth. It'll set you free, but first it can really piss you off.\\nLUKE: This is nuts! I'm supposed to be a guy!\\nSYDNEY: Then what's the problem? You are one.\\nLUKE: You're not gonna' help?!\\nSYDNEY: I will, the moment you're ready to try again. You can come back to my place right now if you want.\\n\\n\", 'answer': 'Forget it!', 'gold_tag': 'LUKE is resistant and frustrated', 'last_speaker': 'LUKE'}\n",
      "Last word -> LUKE : \"Forget it!\"\n",
      "prediction :  I’m sorry. I’ll go to the bathroom. Will you tell everyone it was my dog?\n",
      "Real answer : Forget it!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8244373202323914], 'recall': [0.8689695596694946], 'f1': [0.8461179137229919], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473684, 'rouge2': 0.0, 'rougeL': 0.10526315789473684, 'rougeLsum': 0.10526315789473684}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18.890897750854492\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSYDNEY: Oh, honey. Come in.\\nLUKE: You're one too. Why didn't you tell me?\\nSYDNEY: I didn't want to confuse the issue.\\nLUKE: So, it's true what you said? You really know. I wouldn't change unless I wanted to?\\nSYDNEY: Maybe some part of you.\\nLUKE: What part? How much of me? I mean, for it to work? Half? More than half? What if it was only a tiny bit, -a thought?\\nSYDNEY: I don't know. But I believe there may be thousands of Z's out there, millions for all we know, go their whole lives without even knowing they are one. Nothing ever happens. You couldn't keep it from\\nLUKE: I love being with Michelle. How come I can't control it when she's around?\\nSYDNEY: I think whatever part of yourself you deny, just gets bigger and bigger until it takes you over.\\nLUKE: You think I don't really want to be a man.\\nSYDNEY: I think for some, making it stop is more important than knowing who you are. It was for me.\\nLUKE: Maybe for me too.\\nSYDNEY: Right now, you're Morphescent. The key is to have sex with another Z. You become Adulmorphic. Your gender locks. You can't just change anytime you want.\\nLUKE: Another Z?\\nSYDNEY: That's why I came all the way out here.\\nLUKE: And why you keep tryin' to get me in the sack?\\nSYDNEY: Thought maybe I could save you some distress. But you say you're not attracted to me. For it to work, both of us have to be into it.\\nLUKE: That won't be a problem.\\nSYDNEY: Okay then.\\nLUKE: Tonight.\\n\\n\", 'answer': 'Not right now? Okay. Tonight.', 'gold_tag': \"SYDNEY's temporal information\", 'last_speaker': 'SYDNEY'}\n",
      "Last word -> SYDNEY : \"Not right now? Okay. Tonight.\"\n",
      "prediction :  We'll make our decision at the next full moon.\n",
      "Real answer : Not right now? Okay. Tonight.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8495508432388306], 'recall': [0.836034893989563], 'f1': [0.842738687992096], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 52.47615432739258\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSYDNEY: Do you like this dress?\\nLUKE: Sure. Looks great on you. Man, dresses! Even without everything else, dresses are reason enough right there to stay a guy.\\nSYDNEY: \"Stay a guy?\" Let me get this straight. You didn\\'t decide to be a woman?\\nLUKE: No. Of course not. What?\\nSYDNEY: Just testing you. Hold on a moment. There\\'s something I forgot...\\nLUKE: What\\'s that for?\\nSYDNEY: You\\'ve never done it with another Z. Trust me, you need to be tied down.\\nLUKE: Does it hurt?\\n\\n', 'answer': 'On the contrary.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SYDNEY'}\n",
      "Last word -> SYDNEY : \"On the contrary.\"\n",
      "prediction :  7 more 550 in my account, I’ll call to arrange delivery\n",
      "Real answer : On the contrary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8287498950958252], 'recall': [0.827670693397522], 'f1': [0.8282099366188049], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 67.0344009399414\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICKY: I was posted here after Berlin.\\n\\n', 'answer': \"Where's Daniels?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'BOURNE'}\n",
      "Last word -> BOURNE : \"Where's Daniels?\"\n",
      "prediction :  I was posted here after Berlin.\n",
      "Real answer : Where's Daniels?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8424702882766724], 'recall': [0.8138279318809509], 'f1': [0.8279014825820923], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 588.6737060546875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICKY: Okay. They know you're here.\\nBOURNE: How long do I have?\\n\\n\", 'answer': 'Three minutes...', 'gold_tag': 'Everyday Language', 'last_speaker': 'NICKY'}\n",
      "Last word -> NICKY : \"Three minutes...\"\n",
      "prediction :  10 years.\n",
      "Real answer : Three minutes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9464040398597717], 'recall': [0.8847657442092896], 'f1': [0.9145475029945374], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 31.827241897583008\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICKY: 8 o'clock this morning, he wired $100,000. to a numbered bank account in Tangier.\\nBOURNE: Okay, Tangier is about 300 miles away, we can make the morning ferry.\\n\\n\", 'answer': 'And then what?', 'gold_tag': 'Everyday Language', 'last_speaker': 'NICKY'}\n",
      "Last word -> NICKY : \"And then what?\"\n",
      "prediction :  There's two things I need first.\n",
      "Real answer : And then what?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8477382659912109], 'recall': [0.8383026719093323], 'f1': [0.8429940938949585], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 51.05104446411133\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICKY: What are you after, Jason? Why are you looking for Daniels?\\nBOURNE: Do you know who this is?\\nNICKY: That's Daniels. I don't know who that is.\\nBOURNE: I have to get back to the beginning...or I'll never be free of this. I think he started Treadstone. I remember meeting him. I remember the first day... Daniels brought me to him.\\nNICKY: What happened?\\n\\n\", 'answer': 'An initiation...I guess...', 'gold_tag': 'BOURNE was involved in some initiation process spearheaded by Daniels', 'last_speaker': 'BOURNE'}\n",
      "Last word -> BOURNE : \"An initiation...I guess...\"\n",
      "prediction :  I'm afraid. So afraid. But he was afraid too. He saw things in you that I could not see, which brought him to us. And that's when it began...\n",
      "Real answer : An initiation...I guess...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8463375568389893], 'recall': [0.8452102541923523], 'f1': [0.845773458480835], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05714285714285715, 'rouge2': 0.0, 'rougeL': 0.05714285714285715, 'rougeLsum': 0.05714285714285715}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.1875057220459\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOURNE: Now they found Daniels, do you know where he is?\\nNICKY: They'll get one of the operatives to terminate him.\\n\\n\", 'answer': 'Find out who.', 'gold_tag': 'BOURNE is determined and assertive, demanding immediate results', 'last_speaker': 'BOURNE'}\n",
      "Last word -> BOURNE : \"Find out who.\"\n",
      "prediction :  You've just been in a very real situation, and you coped.\n",
      "Real answer : Find out who.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8438683748245239], 'recall': [0.8627321720123291], 'f1': [0.8531960248947144], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 31.062721252441406\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOURNE: Tell him you're going to meet him and that you have a new phone for him.\\nNICKY: If you stop Desh they'll just get someone else.\\n\\n\", 'answer': \"We're not going to stop him. We're going to follow him. He'll take us right to Daniels.\", 'gold_tag': 'BOURNE has knowledge or experience in covert operations', 'last_speaker': 'BOURNE'}\n",
      "Last word -> BOURNE : \"We're not going to stop him. We're going to follow him. He'll take us right to Daniels.\"\n",
      "prediction :  You're 12. You don't have a new phone. Just let me know what happened.\n",
      "Real answer : We're not going to stop him. We're going to follow him. He'll take us right to Daniels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8811036944389343], 'recall': [0.8651548027992249], 'f1': [0.8730564117431641], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05555555555555556, 'rouge2': 0.0, 'rougeL': 0.05555555555555556, 'rougeLsum': 0.05555555555555556}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18.66954231262207\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOURNE: I was starting to remember who they were...in India...with Marie.\\nNICKY: It's just going to lead to more killing, Jason. Are you sure you want that?\\n\\n\", 'answer': \"I've killed people and I've tried to apologize for what I've done, for what I am. None of it makes it better... They're going to come for you again. You are going to have to run now.\", 'gold_tag': \"BOURNE is a killer who is experiencing guilt and remorse for his actions , NICKY is aware of BOURNE's violent past , BOURNE implies a potential threat to NICKY in the near future\", 'last_speaker': 'BOURNE'}\n",
      "Last word -> BOURNE : \"I've killed people and I've tried to apologize for what I've done, for what I am. None of it makes it better... They're going to come for you again. You are going to have to run now.\"\n",
      "prediction :  I'm sorry...but Marie had a friend in India...a guy she knew while she was working as a nurse.\n",
      "Real answer : I've killed people and I've tried to apologize for what I've done, for what I am. None of it makes it better... They're going to come for you again. You are going to have to run now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8468618392944336], 'recall': [0.8418890237808228], 'f1': [0.8443681001663208], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.03225806451612904, 'rouge2': 0.0, 'rougeL': 0.03225806451612904, 'rougeLsum': 0.03225806451612904}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 42.00212478637695\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNARRATOR: Napoleon was born at Ajaccio in Corsica on August 15th, 1769. He had not been a healthy baby and his mother, Letizia, lavished him with care and devotion. In middle age, he would write about her from St. Helena.\\n\\n', 'answer': 'My mother has always loved me. She would do anything for me.', 'gold_tag': \"NAPOLEON V.O. had a loving relationship with his mother, Letizia, who lavished him with care and devotion , NAPOLEON V.O. acknowledges love and care from his mother , NAPOLEON V.O. refers to his mother's past love and care, implying nostalgia and reflection from his middle age as he writes from St. Helena\", 'last_speaker': 'NAPOLEON (V.O.)'}\n",
      "Last word -> NAPOLEON (V.O.) : \"My mother has always loved me. She would do anything for me.\"\n",
      "prediction :  When I was four years old my mother gave me a name to call her by; my father named her Maria- Louisa, Mary-Louisa, or, in her own style, MariaLouise. I call her, on the contrary, \"Maria.\"\n",
      "Real answer : My mother has always loved me. She would do anything for me.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.829791784286499], 'recall': [0.8838039636611938], 'f1': [0.8559466600418091], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12244897959183675, 'rouge2': 0.0425531914893617, 'rougeL': 0.12244897959183675, 'rougeLsum': 0.12244897959183675}\n",
      "bleu 1/2 : 0.02777777777777778 0.00890870806374748\n",
      "ppl : 21.188583374023438\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNARRATOR: His moods at this time were complex and varied.\\n\\n', 'answer': 'Life is a burden for me. Nothing gives me any pleasure; I find only sadness in everything around me. It is very difficult because the ways of those with whom I live, and probably always shall live, are as different from mine as moonlight is from sunlight.', 'gold_tag': \"NAPOLEON V.O. sees life as a burden and finds no pleasure in anything, experiencing only sadness , NAPOLEON V.O.'s personality is melancholic and introverted , NAPOLEON V.O.'s lifestyle and way of thinking are drastically different from those around him\", 'last_speaker': 'NAPOLEON (V.O.)'}\n",
      "Last word -> NAPOLEON (V.O.) : \"Life is a burden for me. Nothing gives me any pleasure; I find only sadness in everything around me. It is very difficult because the ways of those with whom I live, and probably always shall live, are as different from mine as moonlight is from sunlight.\"\n",
      "prediction :  ...when the wind at this moment comes to a sudden stop, you'll find more than ten million friends beside you.\n",
      "Real answer : Life is a burden for me. Nothing gives me any pleasure; I find only sadness in everything around me. It is very difficult because the ways of those with whom I live, and probably always shall live, are as different from mine as moonlight is from sunlight.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.840959906578064], 'recall': [0.8338808417320251], 'f1': [0.8374053835868835], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08823529411764706, 'rouge2': 0.0, 'rougeL': 0.0588235294117647, 'rougeLsum': 0.0588235294117647}\n",
      "bleu 1/2 : 0.03888603909688373 0.007284022497350465\n",
      "ppl : 56.227638244628906\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNARRATOR: He made friends with a family called Columbier, and would later write of his first flirtation with their daughter, Caroline.\\n\\n', 'answer': 'It will scarcely be considered credible, perhaps, but our whole business consisted in eating cherries together.', 'gold_tag': \"NAPOLEON V.O. had a flirtation with the Columbier's daughter, Caroline , NAPOLEON V.O. and Caroline spent time eating cherries together , NAPOLEON V.O. suggests a person with a young and playful personality\", 'last_speaker': 'NAPOLEON (V.O.)'}\n",
      "Last word -> NAPOLEON (V.O.) : \"It will scarcely be considered credible, perhaps, but our whole business consisted in eating cherries together.\"\n",
      "prediction :  Caroline\n",
      "Real answer : It will scarcely be considered credible, perhaps, but our whole business consisted in eating cherries together.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8217774629592896], 'recall': [0.8088710308074951], 'f1': [0.8152732253074646], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11753562.0\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNAPOLEON (V.O.): Soldiers, you are half-naked and badly clothed. The authorities find much fault with you and yet can give nothing. Your patience, your courage are admirable but you are not getting any fame. I will lead you into the must fruitful plains in the world -- rich provinces and great cities shall be your possessions, and then you will have wealth, honor and fame in full measure. ANIMATED MAP\\n\\n', 'answer': 'With the Italian campaign, Napoleon steps onto the stage as a figure of European importance. A dozen victories in as many months would be announced in dramatic and highly colored bulletins. The battles of the revolution had been so far mainly defensive. Now, there was revealed a new kind of offensive warfare such as had not been seen in Europe for centuries.', 'gold_tag': \"The NARRATOR is an objective observer , The NARRATOR provides historical context and commentary on Napoleon's actions and tactics , The NARRATOR is referencing the current period of the Italian campaign and the shift in warfare tactics\", 'last_speaker': 'NARRATOR'}\n",
      "Last word -> NARRATOR : \"With the Italian campaign, Napoleon steps onto the stage as a figure of European importance. A dozen victories in as many months would be announced in dramatic and highly colored bulletins. The battles of the revolution had been so far mainly defensive. Now, there was revealed a new kind of offensive warfare such as had not been seen in Europe for centuries.\"\n",
      "prediction :  The people of Vienna have become the most famous beggars on the face of the planet. They are starving. The authorities cannot find them work.\n",
      "Real answer : With the Italian campaign, Napoleon steps onto the stage as a figure of European importance. A dozen victories in as many months would be announced in dramatic and highly colored bulletins. The battles of the revolution had been so far mainly defensive. Now, there was revealed a new kind of offensive warfare such as had not been seen in Europe for centuries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8567442893981934], 'recall': [0.8366542458534241], 'f1': [0.8465800881385803], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1379310344827586, 'rouge2': 0.023529411764705885, 'rougeL': 0.11494252873563218, 'rougeLsum': 0.11494252873563218}\n",
      "bleu 1/2 : 0.05463304521211505 0.022763768838381267\n",
      "ppl : 33.86528015136719\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNARRATOR: making political decisions and treaties like a Roman Conqueror, enlarging his role to ruler of Italy. Only his tremendous success and ever increasing popularity prevented the Directory from replacing him.\\n\\n', 'answer': 'From that moment on, I foresaw what I might be. Already I felt the earth flee beneath me, as if I were being carried away up to the sky.', 'gold_tag': \"NAPOLEON V.O. perceives himself as a successful and popular ruler , NAPOLEON V.O. has aspirations of expanding his rule , NAPOLEON V.O.'s statement suggests a moment of realization about his potential, which is in the past from his perspective\", 'last_speaker': 'NAPOLEON (V.O.)'}\n",
      "Last word -> NAPOLEON (V.O.) : \"From that moment on, I foresaw what I might be. Already I felt the earth flee beneath me, as if I were being carried away up to the sky.\"\n",
      "prediction :  It is to the great merit and credit of the Directory to be acknowledged the first time during my conquest of Italy. And I would do well to remember that I conquered Italy, and not merely the territories and peoples of Tuscany, or the people of Umbria and Lombardy, or even of Sicily and Naples. I conquered that which is most sacred among peoples, that which is essential to their religion, politics and government...\n",
      "Real answer : From that moment on, I foresaw what I might be. Already I felt the earth flee beneath me, as if I were being carried away up to the sky.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8136071562767029], 'recall': [0.8319121599197388], 'f1': [0.8226578235626221], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15533980582524273, 'rouge2': 0.019801980198019802, 'rougeL': 0.0970873786407767, 'rougeLsum': 0.0970873786407767}\n",
      "bleu 1/2 : 0.09459459459459461 0.03599744941394482\n",
      "ppl : 19.65390396118164\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNARRATOR: Led by the warlike Queen Louisa, and her fashion-minded husband, King Frederich Wilhelm, the Prussians still believed themselves cast in the mold of Frederick the Great, and more than a match for Napoleon. The King had a special collection of 60 splendid uniforms, and was personally involved in the design of all the Prussian army uniforms.\\n\\n', 'answer': 'If the French army had been commanded at Jena and Auerstadt by a tailor, the King of Prussia would certainly have gained the day.', 'gold_tag': 'NAPOLEON V.O. is a historical figure, specifically a military leader , NAPOLEON V.O. references the Battle of Jena and Auerstadt, suggesting his role in this event and displaying his strategic thoughts , NAPOLEON V.O. shows a keen understanding of the role of appearances and presentation in warfare', 'last_speaker': 'NAPOLEON (V.O.)'}\n",
      "Last word -> NAPOLEON (V.O.) : \"If the French army had been commanded at Jena and Auerstadt by a tailor, the King of Prussia would certainly have gained the day.\"\n",
      "prediction :  \"His Highness, the King of Prussia, has, in his own palace, a collection of 60 splendid uniforms, and these uniforms have been selected as the insignia of the future corps of the Prussians.\"\n",
      "Real answer : If the French army had been commanded at Jena and Auerstadt by a tailor, the King of Prussia would certainly have gained the day.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8512433171272278], 'recall': [0.8501676917076111], 'f1': [0.8507051467895508], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3508771929824562, 'rouge2': 0.10909090909090909, 'rougeL': 0.2105263157894737, 'rougeLsum': 0.2105263157894737}\n",
      "bleu 1/2 : 0.2727272727272727 0.13055824196677338\n",
      "ppl : 23.505298614501953\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNARRATOR: On January 1st, 1814, France itself was invaded. Now, with a small army of raw recruits, Napoleon would have to face the powerful combination of England, Russia, Prussia and Austria, operating against him together, for the first time. The balance of numbers had tilted irretrievably against him.\\n\\n', 'answer': 'A year ago, the whole of Europe was marching alongside of us. Today,', 'gold_tag': 'NAPOLEON V.O. had an alliance with Europe , NAPOLEON V.O. refers to the shift in alliances over the past year', 'last_speaker': 'NAPOLEON (V.O.)'}\n",
      "Last word -> NAPOLEON (V.O.) : \"A year ago, the whole of Europe was marching alongside of us. Today,\"\n",
      "prediction :  He was the second most powerful country in the world.\n",
      "Real answer : A year ago, the whole of Europe was marching alongside of us. Today,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8605269193649292], 'recall': [0.8557237386703491], 'f1': [0.8581185936927795], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17391304347826086, 'rouge2': 0.0, 'rougeL': 0.08695652173913043, 'rougeLsum': 0.08695652173913043}\n",
      "bleu 1/2 : 0.1481636441363436 0.034922505831373\n",
      "ppl : 31.662643432617188\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLAROCHE: Once you get the sickness, it takes over your life. I started out just photographing 'em. Now look at me. It'll happen to you. You'll see.\\nORLEAN: I don't think so. I'm not prone to --\\nLAROCHE: Angraecum sesquipedale! Beauty! God! Darwin wrote about this one. Charles Darwin? Evolution guy? Hello?\\n\\n\", 'answer': 'I know who Darwin is.', 'gold_tag': 'ORLEAN is aware of Charles Darwin and his work', 'last_speaker': 'ORLEAN'}\n",
      "Last word -> ORLEAN : \"I know who Darwin is.\"\n",
      "prediction :  Come on. That's a good one. That's a good one. That's a good one.\n",
      "Real answer : I know who Darwin is.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.845931887626648], 'recall': [0.8576224446296692], 'f1': [0.8517370223999023], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5.077290058135986\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLAROCHE: See that nectary all the way down there? Darwin hypothesized a moth with a nose twelve inches long to pollinate it. Everyone thought he was a loon. Then, sure enough, they found this moth with a twelve inch proboscis -- proboscis means nose, by the way -- and --\\nORLEAN: I know what proboscis means.\\nLAROCHE: Every one of these flowers has a specific relationship with the insect that pollinates it. There's an orchid that looks exactly like this particular insect. So the bug humps the flower and\\nORLEAN: I get it.\\n\\n\", 'answer': \"That's called pseudo-copulation. These flowers are smart! You gotta fall in love with them. Once you learn anything about orchids, you'll devote your life to learning everything about them.\", 'gold_tag': 'LAROCHE has extensive knowledge about orchids and insects', 'last_speaker': 'LAROCHE'}\n",
      "Last word -> LAROCHE : \"That's called pseudo-copulation. These flowers are smart! You gotta fall in love with them. Once you learn anything about orchids, you'll devote your life to learning everything about them.\"\n",
      "prediction :  But if you take a look around, you'll see an odd pattern -- a pattern that never goes away. I haven't spent all this time on one insect just to be a complete moron. It's just that you've only spent a glance at anything. See, this is how it is -- I keep this little book with me. But instead of a little book, it's like a big box, right -- with all the pages spread out -- I've got\n",
      "Real answer : That's called pseudo-copulation. These flowers are smart! You gotta fall in love with them. Once you learn anything about orchids, you'll devote your life to learning everything about them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8121851682662964], 'recall': [0.8415526151657104], 'f1': [0.8266081213951111], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15789473684210525, 'rouge2': 0.017857142857142856, 'rougeL': 0.07017543859649124, 'rougeLsum': 0.07017543859649124}\n",
      "bleu 1/2 : 0.05000000000000001 0.007955572841757302\n",
      "ppl : 14.921436309814453\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLAROCHE: No shit I'm a fun character. Who's gonna play me?\\nORLEAN: I've got to write it first. Someone's gotta write the screenplay. Most things never get made. It's premature to --\\n\\n\", 'answer': 'I think I should play me.', 'gold_tag': 'LAROCHE expresses his desire to play himself , LAROCHE has an interest in acting', 'last_speaker': 'LAROCHE'}\n",
      "Last word -> LAROCHE : \"I think I should play me.\"\n",
      "prediction :   There's not a lot to read.\n",
      "Real answer : I think I should play me.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8598203659057617], 'recall': [0.878412663936615], 'f1': [0.8690170645713806], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 29.473934173583984\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nORLEAN: Laroche, can I ask you a personal question?\\n\\n', 'answer': \"We're not lost.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'LAROCHE'}\n",
      "Last word -> LAROCHE : \"We're not lost.\"\n",
      "prediction :  It depends on what.\n",
      "Real answer : We're not lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8427140712738037], 'recall': [0.8696659803390503], 'f1': [0.8559778928756714], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 281.83831787109375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLAROCHE: The jewel of the Fakahatchee.\\nORLEAN: I still don't get it. I mean, there it is. I can see it's pretty, but --\\n\\n\", 'answer': \"You'll get it.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'LAROCHE'}\n",
      "Last word -> LAROCHE : \"You'll get it.\"\n",
      "prediction :  So if you ever get it, I'll have just given you the world, the richest, most beautiful piece of land in the world.\n",
      "Real answer : You'll get it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8289191722869873], 'recall': [0.9103258848190308], 'f1': [0.8677173852920532], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2857142857142857, 'rouge2': 0.07692307692307691, 'rougeL': 0.21428571428571427, 'rougeLsum': 0.21428571428571427}\n",
      "bleu 1/2 : 0.043478260869565216 0.014058038927888336\n",
      "ppl : 20.291961669921875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFRANCES: And I can't understand how it can hurt to be honest, but the more I tried to explain --\\nLILLIAN: Don't listen to him, little sister. When you're proud of what you are, you don't refuse the label, understand?\\nFRANCES: Yes, Ma.\\n\\n\", 'answer': 'And you... should be proud. You won that contest and made a name for yourself.', 'gold_tag': 'LILLIAN pushes Frances to embrace pride in her achievements , FRANCES recently won a contest, demonstrating her potential and ambition', 'last_speaker': 'LILLIAN'}\n",
      "Last word -> LILLIAN : \"And you... should be proud. You won that contest and made a name for yourself.\"\n",
      "prediction :  Frances, don't be silly. God knows how I would feel if they called me that. It would be a disgrace.\n",
      "Real answer : And you... should be proud. You won that contest and made a name for yourself.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8625537157058716], 'recall': [0.8715869188308716], 'f1': [0.8670467734336853], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.10000000000000002 0.022941573387056175\n",
      "ppl : 27.427261352539062\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLILLIAN: ...and here's the one from Duluth. A war widow with five children. She works in a defense plant and she's very worried about you. I answered her that she shouldn't let worry over you affect her vital work; and that you'd be back on the silver screen in no time. And here's one from nice Mr. Zeiss. He says that...\\nFRANCES: Why are these all opened?\\nLILLIAN: Well, they needed immediate answers, Frances. It's good manners and good sense. You shouldn't be bothering yourself with these right now.\\nFRANCES: Then why did you bring them?\\nLILLIAN: It's your fan mail, little sister.\\nFRANCES: You kill me, Mama.\\nLILLIAN: What?\\n\\n\", 'answer': 'Go on...', 'gold_tag': 'Everyday Language', 'last_speaker': 'FRANCES'}\n",
      "Last word -> FRANCES : \"Go on...\"\n",
      "prediction :  If I haven't made myself clear, you're a very popular girl, Frances. And it's very kind of you to send me your fan mail. It's a lot of little caresses and little kisses and letters with sweet hearts all over. And it's very nice too.\n",
      "Real answer : Go on...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7803052663803101], 'recall': [0.7773505449295044], 'f1': [0.7788251042366028], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.509743690490723\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLILLIAN: Frances, play 'Flow Gently Sweet Afton'.\\nFRANCES: Oh Mama, I'm so... tired of that song.\\nLILLIAN: Please. I want you to. It would make me so happy. It's just a flow gently sweet Afton day. Life has been so good to me. Why, I have just about everything one could wish... but I still have\\nFRANCES: I think I need a little air.\\nLILLIAN: What's wrong?\\nFRANCES: Nothing. I think I'll just go out for awhile.\\nLILLIAN: Where are you going?\\nFRANCES: For a walk, Mama. Just a walk.\\nLILLIAN: How long will you be?\\nFRANCES: Not long.\\nLILLIAN: I'll have lunch ready by one.\\nFRANCES: I'll be back.\\nLILLIAN: At one. Promise?\\nFRANCES: Sure.\\nLILLIAN: Say you promise.\\nFRANCES: I promise I'll... I promise, Mama.\\nLILLIAN: You know, the surest way to lose an appetite, is to drink, little sister.\\nFRANCES: Yes, Mama.\\nLILLIAN: I don't want you drinking, Frances.\\n\\n\", 'answer': 'Yes, Mama.', 'gold_tag': \"FRANCES agrees with her mother's remarks about drinking , LILLIAN's persona shows a possessive nature over FRANCES\", 'last_speaker': 'FRANCES'}\n",
      "Last word -> FRANCES : \"Yes, Mama.\"\n",
      "prediction :  Yes ma.\n",
      "Real answer : Yes, Mama.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9259530305862427], 'recall': [0.9107421636581421], 'f1': [0.9182845950126648], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.5, 'rouge2': 0.0, 'rougeL': 0.5, 'rougeLsum': 0.5}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15194.8623046875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLILLIAN: Oh, just leave those things for now.\\nFRANCES: No, Mama, I'll take care of it. I'll wash them in the morning.\\nLILLIAN: You know, little sister, I never resented you for refusing to see me in the... the hospital. I knew you had to manage on your own before you could come back.\\nFRANCES: Thank you for understanding, Mama.\\nLILLIAN: Little sister, I don't want you to feel any rush to get back to work. I want you to rest... for a while anyway.\\nFRANCES: I will, I promise.\\n\\n\", 'answer': 'Good night, dear.', 'gold_tag': 'Everyday Language', 'last_speaker': 'LILLIAN'}\n",
      "Last word -> LILLIAN : \"Good night, dear.\"\n",
      "prediction :  I'd better stop. You should be at school with your friends. We'll have to have many more conversations. After all, I am nothing but your Mama's daughter, who'll be as old as a bear with a broken tooth in a long time.\n",
      "Real answer : Good night, dear.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8121739029884338], 'recall': [0.8669917583465576], 'f1': [0.8386880159378052], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.679250717163086\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKATIE: You're home.\\nOSBOURNE: Hang on to your hat, honey. I have some news. I----\\nKATIE: Did you pick up the cheeses?\\nOSBOURNE: Huh?\\nKATIE: Were they ready? I didn't know you were coming home this early.\\nOSBOURNE: The cheeses.\\nKATIE: I left a message for you to stop at Todaro's. The Magruders and the Pfarrers are coming over.\\nOSBOURNE: The Pfarrers? Ugh. I----what did Kathleen say?\\nKATIE: What?\\nOSBOURNE: When you left the message?\\nKATIE: She said. She would give you. The message.\\nOSBOURNE: Well she, I don't know, I guess we had bigger news today. My day didn't revolve arou----\\nKATIE: So you didn't get the cheeses.\\nOSBOURNE: Well, since I didn't get the message, no, I didn't get the cheeses. But hang on to your hat, I----\\nKATIE: Oh for fuck's sake, Ozzie, you mean I have to go out again? All right, well, you better get dressed.\\nOSBOURNE: Honey, we have to talk.\\n\\n\", 'answer': \"Not right now. They'll be here in, what, less than an hour.\", 'gold_tag': 'KATIE needs to prepare for guests  who are arriving in less than an hour', 'last_speaker': 'KATIE'}\n",
      "Last word -> KATIE : \"Not right now. They'll be here in, what, less than an hour.\"\n",
      "prediction :  I'm at home, I'm home, I've just finished making dinner. I've come over and I can't help but wonder, are all three of them on the way here? Is that Kathleen and the two girls? I'd love to know---\n",
      "Real answer : Not right now. They'll be here in, what, less than an hour.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8242659568786621], 'recall': [0.8564233779907227], 'f1': [0.8400370478630066], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.034482758620689655, 'rouge2': 0.0, 'rougeL': 0.034482758620689655, 'rougeLsum': 0.034482758620689655}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.931522369384766\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKATIE: You quit?!\\nOSBOURNE: Uh-huh.\\nKATIE: Well----Thank you for letting me know!\\nOSBOURNE: I tried to tell you this afternoon.\\nKATIE: You tried? You tried? And then---- what, the aphasia kicked in?\\nOSBOURNE: Our guests came. We----\\nKATIE: Why?! For fuck's sake, Ozzie!\\nOSBOURNE: I'm just----I don't know. I got so tired.\\nKATIE: You're tired.\\nOSBOURNE: Tired of swimming against the current.\\nKATIE: Uh-huh.\\nOSBOURNE: Independent thought is not only not valued there, they resist it, they fight it, the bureaucracy is positively----\\nKATIE: Did you get a pension, or severance or something, or----\\nOSBOURNE: I didn't retire you know, I, I quit. I don't want their benefits.\\nKATIE: But I suppose my benefits are all right, I suppose you can live with those, is that the idea?\\nOSBOURNE: It's not like that's the only way to make money.\\nKATIE: Yes? Yes? What're you gonna do?\\nOSBOURNE: I'll do some consulting.\\nKATIE: Consulting.\\nOSBOURNE: Yes, to help while I----I've always wanted to write.\\nKATIE: Write. Write what.\\n\\n\", 'answer': \"I've been thinking about it. A book, a sort of, sort of memoir.\", 'gold_tag': 'OSBOURNE plans to start writing a memoir', 'last_speaker': 'OSBOURNE'}\n",
      "Last word -> OSBOURNE : \"I've been thinking about it. A book, a sort of, sort of memoir.\"\n",
      "prediction :  If I do anything, I'll be writing, unless an earthquake strikes.\n",
      "Real answer : I've been thinking about it. A book, a sort of, sort of memoir.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8553128242492676], 'recall': [0.8532665967941284], 'f1': [0.8542885184288025], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307691, 'rouge2': 0.0, 'rougeL': 0.07692307692307691, 'rougeLsum': 0.07692307692307691}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 52.397682189941406\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nOSBOURNE: There's some clown----a couple of clowns ----somehow got a hold of my memoir----\\nKATIE: Your what?\\nOSBOURNE: Stole it or----I have no idea how they got it----\\nKATIE: Your what?\\nOSBOURNE: My memoir, the book I'm writing.\\nKATIE: Why in God's name would they think that's worth anything.\\n\\n\", 'answer': \"Well they----I... I've no idea how they got it.\", 'gold_tag': 'OSBOURNE is flustered and confused about how someone could have obtained it', 'last_speaker': 'OSBOURNE'}\n",
      "Last word -> OSBOURNE : \"Well they----I... I've no idea how they got it.\"\n",
      "prediction :  I'm sorry I don't want this to be a waste of your time, but there's something you should know about the memoir that I'm writing.\n",
      "Real answer : Well they----I... I've no idea how they got it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8416325449943542], 'recall': [0.8301127552986145], 'f1': [0.835832953453064], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1, 'rouge2': 0.0, 'rougeL': 0.1, 'rougeLsum': 0.1}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 8.536019325256348\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCATHY: Excuse me. Can I help you? Who are you?\\nRAYMOND: Ma'am, I'm sorry. My name's Raymond Deagan. I'm Otis Deagan's son. I've just been - taking over some of his jobs since he -\\nCATHY: You're Otis's son?\\nRAYMOND: Yes.\\nCATHY: Well I'm - terribly sorry for speaking to you in that manner. I didn't know who was in my yard.\\nRAYMOND: No need.\\nCATHY: How is your father? I knew he was in the hospital.\\nRAYMOND: Yes, I - My father passed away, I'm afraid.\\nCATHY: No! I had no idea! I'm so very sorry. Please accept our deepest condolences. Your father was a wonderful, dedicated man.\\n\\n\", 'answer': 'Thank you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'RAYMOND'}\n",
      "Last word -> RAYMOND : \"Thank you.\"\n",
      "prediction :  You sound like a very nice lady indeed.\n",
      "Real answer : Thank you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8508301973342896], 'recall': [0.8946834802627563], 'f1': [0.8722059726715088], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 65.53659057617188\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCATHY: Raymond!\\nRAYMOND: Mrs. Whitaker...\\nCATHY: Hi.\\nRAYMOND: Hello.\\nCATHY: Well, wouldn't you know it. I just received a call and suddenly everything's changed. Anyway. I just...\\n\\n\", 'answer': 'You changed your mind? Well good!', 'gold_tag': 'RAYMOND is understanding and receptive to changes', 'last_speaker': 'RAYMOND'}\n",
      "Last word -> RAYMOND : \"You changed your mind? Well good!\"\n",
      "prediction :  I am getting married tomorrow!\n",
      "Real answer : You changed your mind? Well good!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8478056788444519], 'recall': [0.8426198959350586], 'f1': [0.8452048301696777], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 82.84739685058594\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCATHY: It's lovely. What is it?\\nRAYMOND: It's called a Quaking Aspen. Fairly rare in these parts.\\nCATHY: It's beautiful. And you were right. What a perfectly lovely spot.\\nRAYMOND: Sometimes a little green, some fresh air, just helps put things back on the shelf. ‘Cause it sure can be a disheveling world out there, every now and again.\\nCATHY: I'll say it can. Is that a path?\\nRAYMOND: Looks like it.\\nCATHY: Oh let's have a peek.\\n\\n\", 'answer': 'Alright.', 'gold_tag': 'Everyday Language', 'last_speaker': 'RAYMOND'}\n",
      "Last word -> RAYMOND : \"Alright.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction : \n",
      "Real answer : Alright.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.0], 'recall': [0.0], 'f1': [0.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : nan\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: Says here they got slips in Honolulu. 325 a month. Utilities included. That's not bad. But I gotta get at least a forty footer. It'll handle rough water better and I'll need the room if I'm gonna live on it.\\nRODRIGUEZ: I don't know how you do it.\\nDIVINCI: What?\\nRODRIGUEZ: How you can think about Hawaii now?\\nDIVINCI: My heart's in Hawaii.\\nRODRIGUEZ: You never been there. How can your heart be there.\\nDIVINCI: You're tellin' me there's no place you'd rather be other than here?\\nRODRIGUEZ: No, I'm saying I just don't know how you can think about Hawaii right now.\\nDIVINCI: If I was in Hawaii right now, I wouldn't be thinking about here. See the difference?\\nRODRIGUEZ: No.\\nDIVINCI: Look, I'm not in Hawaii, I'm here. But I don't want to be here, I want to be in Hawaii. I can't be in Hawaii, therefore I think about it so as to not get depressed about being here.\\nRODRIGUEZ: But I'm here, I know I'm here, I don't like being here, but I can't be anyplace else because I look around and I see all this shit. How do you get around that?! That's what I'm asking.\\nDIVINCI: Focus.\\nRODRIGUEZ: Focus. It's time. No more Hawaii, okay? Focus on this.\\nDIVINCI: Aloha.\\n\\n\", 'answer': 'Aloha my ass.', 'gold_tag': 'Everyday Language', 'last_speaker': 'RODRIGUEZ'}\n",
      "Last word -> RODRIGUEZ : \"Aloha my ass.\"\n",
      "prediction :  What did the doctor say about my heart and my chest and my kidneys?\n",
      "Real answer : Aloha my ass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8366167545318604], 'recall': [0.8174119591712952], 'f1': [0.8269028663635254], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.07142857142857141 0.023440361546924773\n",
      "ppl : 42.15943145751953\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRODRIGUEZ: SHIT, FUCK, SHIT, JESUS CHRIST!\\nDIVINCI: Calm down!\\nRODRIGUEZ: WE'RE DEAD, WE'RE FUCKING DEAD!\\nDIVINCI: SHUT UP!\\nRODRIGUEZ: FUCK, FUCK, FUCK!\\nDIVINCI: STOP IT! YOU HEAR ME, RIGHT NOW, STOP IT!\\nRODRIGUEZ: GOD, GOD, THIS IS REALLY FUCKIN' OUT OF CONTROL! LET GO OF ME!\\n\\n\", 'answer': \"Shut up and listen to me! They could be watchin' us right now you asshole. So fuckin' shape up! You got it?! I want you to nod! Get the fuck up! Get in the car!\", 'gold_tag': 'DIVINCI is forceful, commanding, and assertive , DIVINCI indicates a potentially higher ranking position', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"Shut up and listen to me! They could be watchin' us right now you asshole. So fuckin' shape up! You got it?! I want you to nod! Get the fuck up! Get in the car!\"\n",
      "prediction :  I hear you, I hear you.\n",
      "Real answer : Shut up and listen to me! They could be watchin' us right now you asshole. So fuckin' shape up! You got it?! I want you to nod! Get the fuck up! Get in the car!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8578853011131287], 'recall': [0.812690258026123], 'f1': [0.8346764445304871], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14634146341463414, 'rouge2': 0.0, 'rougeL': 0.14634146341463414, 'rougeLsum': 0.14634146341463414}\n",
      "bleu 1/2 : 0.0013266573081177418 0.0004595675723784975\n",
      "ppl : 24.727794647216797\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: There's no fuckin' reason to panic.\\nRODRIGUEZ: No fuckin' reason to panic? Did you say no fuckin' reason to panic!\\nDIVINCI: Stop being an idiot! We're the cops on the case. It's our case. We are going to find the fuckin' killers.\\nRODRIGUEZ: WE'RE THE FUCKIN' KILLERS!\\n\\n\", 'answer': 'Since when does that matter?!', 'gold_tag': 'DIVINCI downplays the seriousness of their circumstances', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"Since when does that matter?!\"\n",
      "prediction :  \"It's all happening all at once. I'd hate to be stuck with you as an officer. And I think that a lot of the men are worried. Don't go out and party.\"\n",
      "Real answer : Since when does that matter?!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8170747756958008], 'recall': [0.8251473903656006], 'f1': [0.8210912346839905], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.049999999999999996, 'rouge2': 0.0, 'rougeL': 0.049999999999999996, 'rougeLsum': 0.049999999999999996}\n",
      "bleu 1/2 : 0.03125 0.010040241611281232\n",
      "ppl : 22.702810287475586\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: All they want is someone to go down for the crime, right? Do we care who goes down for the crime? Fuck no. As long as someone goes down for the crime. It's a slot that's gotta be filled.\\nRODRIGUEZ: We killed a cop, doesn't that bother you?\\nDIVINCI: Of course it bothers me. What d'you want me to do, turn myself in? Well I'm not. That's the risk we take everyday, somebody might pop us, especially undercover like that. So he got popped. It happens.\\nRODRIGUEZ: Not by other cops!\\nDIVINCI: I patted him down! He wasn't wearin' a wire, he had no badge, no gun, how was I supposed to know?! Look, I feel just as bad as you do, but we gotta start thinkin' about us here. The important thing is we don't lose control of the case. We can never lose control of the case. Whatever evidence there is goes through us. We lay down the trail. Make it nice and logical. We're the teachers and two and two can add up to five if it's our classroom.\\nRODRIGUEZ: What're you talkin' about, are you sayin' we stick somebody with this?\\nDIVINCI: Evidence points wherever we want it to point. Shit, we can provide so much evidence, even the asshole we pick will think he fuckin' killed him.\\nRODRIGUEZ: You got some asshole in mind?\\n\\n\", 'answer': \"Just don't worry. We'll find a killer. There's lots of 'em out there.\", 'gold_tag': 'DIVINCI takes control of situations and plans to manipulate evidence', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"Just don't worry. We'll find a killer. There's lots of 'em out there.\"\n",
      "prediction :  You got a buddy that's a cop, he said he killed the kid?\n",
      "Real answer : Just don't worry. We'll find a killer. There's lots of 'em out there.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.85235595703125], 'recall': [0.8540566563606262], 'f1': [0.8532055020332336], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0.07692307692307693 0.025318484177091663\n",
      "ppl : 57.7885856628418\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: He didn't have backup. You believe that?! Jesus what a dick.\\nRODRIGUEZ: I don't think we should criticize that particular decision of his.\\nDIVINCI: I don't care what the reasons are, you don't play Lone Fuckin' Ranger on a drug buy. You're just askin' for it. That's all I'm sayin'.\\nRODRIGUEZ: I don't trust those bastards. They're not waitin' for us. That's bullshit. They're runnin' their own investigation. I know it!\\nDIVINCI: Let 'em. The gun, the coke came from evidence. The car came from impound. So what's to find?\\nRODRIGUEZ: That's what I'm afraid of. There's nothing for them to find. We were too good.\\nDIVINCI: So what're you worried about?\\nRODRIGUEZ: Nobody is that fuckin' good.\\n\\n\", 'answer': 'Except us.', 'gold_tag': 'Divinci and Rodriguez share a past of conducting successful operations that involved the use of evidence and impounded cars', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"Except us.\"\n",
      "prediction :  Where are you planning on taking me now?\n",
      "Real answer : Except us.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8127821683883667], 'recall': [0.8869646787643433], 'f1': [0.8482546210289001], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 53.87767791748047\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: Is that any way to answer the phone?\\nRODRIGUEZ: Divinci, shit! It's quarter to six.\\nDIVINCI: I know what time it is, I'm not the one in bed. I need the photos of the scene.\\nRODRIGUEZ: Now?\\nDIVINCI: I got a suspect. But he can't remember all the details. He needs a little help. And I thought, since you're my partner, you might jump at the opportunity to lend me a fuckin' hand.\\nRODRIGUEZ: He doesn't remember last Friday?\\n\\n\", 'answer': \"He doesn't remember a lotta Fridays. Bring the shots and pick up a fifth of Vodka. Make it two.\", 'gold_tag': 'DIVINCI needs bottles of Vodka as soon as possible', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"He doesn't remember a lotta Fridays. Bring the shots and pick up a fifth of Vodka. Make it two.\"\n",
      "prediction :  Okay, good to see you.\n",
      "Real answer : He doesn't remember a lotta Fridays. Bring the shots and pick up a fifth of Vodka. Make it two.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8715328574180603], 'recall': [0.8382003307342529], 'f1': [0.8545415997505188], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 77.7574462890625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRODRIGUEZ: The Dunner gun, you used the fucking Dunner gun?!\\nDIVINCI: This is not my fuck up! Our shooting was supposed to be gang-related and unsolved! Only because we tagged a goddamn undercover cop do we need the fucking .44 for evidence! Otherwise, we never woulda needed it. So don't point your finger at me!\\nRODRIGUEZ: Alright, alright... But how are we supposed to explain how the same gun was used in two murder cases by two different killers when it was supposed to be in police custody?!\\n\\n\", 'answer': \"We don't explain it. It's not our fault they lost the evidence. Ballistics are already complete in Dunner's case. All we need is another gun.\", 'gold_tag': \"DIVINCI implies that the ballistics for Dunner's case have already been completed, suggesting that this event has occurred in the past and will not change\", 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"We don't explain it. It's not our fault they lost the evidence. Ballistics are already complete in Dunner's case. All we need is another gun.\"\n",
      "prediction :  The reason is because you's are fuckin' liars.\n",
      "Real answer : We don't explain it. It's not our fault they lost the evidence. Ballistics are already complete in Dunner's case. All we need is another gun.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8407306671142578], 'recall': [0.8390809297561646], 'f1': [0.8399049639701843], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.21621621621621623, 'rouge2': 0.0, 'rougeL': 0.10810810810810811, 'rougeLsum': 0.10810810810810811}\n",
      "bleu 1/2 : 0.029858242066679905 0.007137485028505504\n",
      "ppl : 140.4276123046875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRODRIGUEZ: We gotta put the right gun back.\\nDIVINCI: We can't put the right gun back! Without that gun, they won't convict Joe.\\nRODRIGUEZ: Without that gun they won't convict Clyde!\\nDIVINCI: I'm not worried about Clyde, I'm worried about us!\\nRODRIGUEZ: Look, Joe's never goin' to trial, right. He signed a goddamn confession! Like you said, this one is open and shut. Clyde's the one we gotta worry about. We can't let him go back on the street! He's a fuckin' psychopath. He'll kill somebody again.\\nDIVINCI: Shit. How the hell did that piece of puke know it wasn't his fuckin' gun?! I don't think he knows his own fuckin' mother, but he knows his fuckin' gun!\\n\\n\", 'answer': \"I don't think that's important right now.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'RODRIGUEZ'}\n",
      "Last word -> RODRIGUEZ : \"I don't think that's important right now.\"\n",
      "prediction :  Well, look. I don't want to put anything in him that makes him kill again, but I also don't want to give him the fucking keys to the fuckin' kingdom if we let him out.\n",
      "Real answer : I don't think that's important right now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8312664031982422], 'recall': [0.8633898496627808], 'f1': [0.8470236659049988], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17391304347826086, 'rouge2': 0.0909090909090909, 'rougeL': 0.17391304347826086, 'rougeLsum': 0.17391304347826086}\n",
      "bleu 1/2 : 0.057142857142857134 0.04099600308453938\n",
      "ppl : 15.180192947387695\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: Nobody can connect us to the evidence thing... we're clean there. The most important one is this DEA mess anyway. Once that's finished, we're completely in the clear.\\nRODRIGUEZ: You know we can't do it anymore.\\nDIVINCI: ...yeah, I guess.\\nRODRIGUEZ: No, we're through. That's it.\\nDIVINCI: Good while it lasted though. A hundred grand apiece. Not bad for a few nights work.\\nRODRIGUEZ: I just wanna get through this.\\nDIVINCI: We're gonna get through it. No evidence problems on this one.\\nRODRIGUEZ: I hope not... I don't know, Frank, lately I been thinkin'... maybe what we did wasn't such a good idea.\\nDIVINCI: Hey, we took out a few scumbags, that's it. Nobody's ever gonna miss those shitheels. They were all pieces of garbage. Not one of 'em had a sheet less than a mile long. Drugs, extortion, assault. They were all fuckin' guilty as hell and still on the street, you know that.\\nRODRIGUEZ: Except the cop.\\nDIVINCI: Yeah, except the cop. That's part of the job. Could just as easily have happened to you or me.\\nRODRIGUEZ: But we're cops, you know? We fucked up.\\nDIVINCI: We fucked up once. Once outa ten. That's not bad. I'm sorry, okay? I'm sorry. He was in the wrong place at the wrong time, what can I say. I'm not goin' down for it.\\nRODRIGUEZ: I know.\\nDIVINCI: Look, if we got paid a decent salary we wouldn't be tempted by this, right? And what happens when we retire? You think our pension's gonna take care of us? Shit no. We are on our own. I mean all I want in life is a goddamn fishing boat, a beach, a couple drinks and some Hawaiian fuckin' music. That ain't much for twenty years putting murdering assholes behind bars. I mean, the dealers, the pimps, the killers, they got no rules. We got all the fuckin' rules. It ain't fair. That's all I'm sayin', it ain't fair... For awhile, we made it fair. Quit thinkin' you're a bad guy. You're not a fuckin' bad guy. You made one mistake. Let it go.\\nRODRIGUEZ: Do you think we're corrupt?\\nDIVINCI: Hey, I never took a fuckin' bribe in my life.\\nRODRIGUEZ: Me either.\\nDIVINCI: Nobody ever bought me.\\nRODRIGUEZ: I know.\\nDIVINCI: No fuckin' way. Even the thought makes me sick. And what we did has nothing to do with being corrupt. It's two completely different things. Don't get 'em confused.\\nRODRIGUEZ: I guess you're right.\\nDIVINCI: I'm telling you. It's nothin' to do with corrupt.\\nRODRIGUEZ: I'm worried, that's all.\\nDIVINCI: Hey, you gotta worry a little. It's natural. Just don't lose your sense of humor.\\nRODRIGUEZ: My sense of humor, right.\\nDIVINCI: The problem with people is, nobody gives a shit about makin' the world a better place. You and me, I don't care what anybody says, we made the world a better place. No matter what happens. There are ten less drug dealin' assholes on the street today because of us. They're not plea bargainin' their way back onto the street, they're not clogging up the courts, and they're not costing the tax payers a fuckin' penny because they're not in prison. They were garbage. And there's nothin' wrong with takin' out the garbage.\\nRODRIGUEZ: So, you think you'll get back with Caroline?\\nDIVINCI: Shit. Nothin' I ever do is good enough, you know?\\nRODRIGUEZ: Never is, never was, never will be.\\nDIVINCI: Guess I gotta make the effort. It's gonna cost me if I don't.\\nRODRIGUEZ: Tell me about it. You know how much I got left.\\nDIVINCI: You're gonna think I'm an idiot, but... I like Cynthia. There's no bullshit with her. I just fuckin' like her.\\nRODRIGUEZ: I think you just like fuckin' her.\\n\\n\", 'answer': 'Yeah, that, too.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"Yeah, that, too.\"\n",
      "prediction :  I guess I'm just livin' on borrowed time. There's nothin' so far as I can see, I can hold on to. Nothin' like a fucking dream of a better life, you know?\n",
      "Real answer : Yeah, that, too.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8062070608139038], 'recall': [0.8697373867034912], 'f1': [0.8367681503295898], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13.958742141723633\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: -- when was the last time you saw him? -- Uh-huh -- And you haven't seen him since then?\\nRODRIGUEZ: We gotta talk.\\nDIVINCI: Just a second. Calm down. I heard. Clyde walked.\\nRODRIGUEZ: No! They're takin' Joe to trial. They found him mentally unable to plead so his attorney pleaded not\\nDIVINCI: You gotta be kiddin' me.\\n\\n\", 'answer': \"Yeah, that's me, I love to make people laugh. You hear the one about the two cops who popped the undercover DEA?\", 'gold_tag': 'RODRIGUEZ uses humor as a coping mechanism in stressful situations', 'last_speaker': 'RODRIGUEZ'}\n",
      "Last word -> RODRIGUEZ : \"Yeah, that's me, I love to make people laugh. You hear the one about the two cops who popped the undercover DEA?\"\n",
      "prediction :  I'm kiddin'. But I don't know why Joe's being tried.\n",
      "Real answer : Yeah, that's me, I love to make people laugh. You hear the one about the two cops who popped the undercover DEA?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8307573795318604], 'recall': [0.8480319976806641], 'f1': [0.8393058180809021], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.05555555555555555, 'rougeLsum': 0.05555555555555555}\n",
      "bleu 1/2 : 0.030119421191220207 0.010039807063740072\n",
      "ppl : 37.83916473388672\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRODRIGUEZ: -- but William McCall shunned the business world and turned his life to medicine, receiving his medical degree from Harvard in 1969. Once again he turned his back on the established norm and spent several years in Africa performing organ transplants for the poor. Jesus Christ, this is who you picked? A goddamn surgeon who performs organ transplants on poor Africans?!\\nDIVINCI: He was living in the fuckin' street! How the hell was I supposed to know he was a goddamn doctor?!\\nRODRIGUEZ: He's not a goddamn doctor! You picked a fuckin' Saint to pin a fuckin' murder on! When we pick 'em, we really fuckin' pick 'em. We shoulda just picked up the fuckin' Pope.\\nDIVINCI: -- he disappeared seven years ago on September 19 two weeks after the tragic death of his wife and two young children in a multiple vehicle accident. At the time it was assumed that he had returned to Africa, but that was never confirmed. What William McCall has been doing for seven years is now the mystery that the court will try to help unravel. Alright, alright, let's think here.\\nRODRIGUEZ: Are you asking me if I can think of something worse than what we've done that we can still do, or something worse that might happen to us if this all blows up and we are convicted and sent to jail and die in the electric chair and go to hell?\\nDIVINCI: Work with me here.\\nRODRIGUEZ: I'm sorry. I'm a little on edge. Would you repeat the question?\\nDIVINCI: Even if the doc walks, there's no evidence ties us to it. There's only one person who can connect us to Hudd.\\n\\n\", 'answer': \"Okay, fine, I don't wanna argue about it anymore. Let's just fuckin' kill her.\", 'gold_tag': \"RODRIGUEZ ultimately agrees to DIVINCI's plan for murder despite his fears\", 'last_speaker': 'RODRIGUEZ'}\n",
      "Last word -> RODRIGUEZ : \"Okay, fine, I don't wanna argue about it anymore. Let's just fuckin' kill her.\"\n",
      "prediction :  Okay, let me get this straight. This guy, this McCall, he lived with the Hudds and we killed him?\n",
      "Real answer : Okay, fine, I don't wanna argue about it anymore. Let's just fuckin' kill her.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8366422653198242], 'recall': [0.8568160533905029], 'f1': [0.8466090559959412], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11428571428571428, 'rouge2': 0.0, 'rougeL': 0.11428571428571428, 'rougeLsum': 0.11428571428571428}\n",
      "bleu 1/2 : 0.05263157894736841 0.017099639201419235\n",
      "ppl : 51.90889358520508\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: -- look, she's our witness, if she's in custody, somebody better tell me! Anything?\\nRODRIGUEZ: Nothin'. Nobody knows nothin'. The D.A. thinks she's gone. D.E.A. doesn't know shit.\\nDIVINCI: If she was bein' held by police, we'd know.\\nRODRIGUEZ: Unless she said somethin'.\\n\\n\", 'answer': \"If she said something we wouldn't be sittin' here. I think it's that lyin' piece of shit.\", 'gold_tag': 'DIVINCI has assertive language', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"If she said something we wouldn't be sittin' here. I think it's that lyin' piece of shit.\"\n",
      "prediction :  That's all right, no pressure, kid. You can take your time. We'll take care of you.\n",
      "Real answer : If she said something we wouldn't be sittin' here. I think it's that lyin' piece of shit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8520994782447815], 'recall': [0.8234208822250366], 'f1': [0.8375146985054016], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.21621621621621623, 'rouge2': 0.0, 'rougeL': 0.10810810810810811, 'rougeLsum': 0.10810810810810811}\n",
      "bleu 1/2 : 0.05871331642584224 0.01917568884665115\n",
      "ppl : 12.603189468383789\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: To justice in all its forms.\\nRODRIGUEZ: We're not home free yet.\\nDIVINCI: Without Ms Webb, there's no place they can go. We still got the confession, the gun, the ballistics... And I don't give a shit about all this African doctor crap... the man is a drunk and he's been a drunk for seven goddamn years. So lets have a drink for drunks. That's the thing about life. You control it or it controls you. Most people don't understand that. They try'n blame their fuck-ups on something or somebody else. But it's not like that. I don't wanna hear why your life's a mess. It's a mess cause you're a mess. That simple. They're waitin' to live happily ever after. But after what? After all the shit happens? Well, I got a clue for everybody, the shit never stops happening. So you deal with it or you get buried in it. I'm not talkin' about you, you know what I'm sayin' here.\\nRODRIGUEZ: Yeah.\\nDIVINCI: Life don't work in mysterious ways. There ain't no mystery to it. You just work it. And you don't take it too serious. You can't take it too serious otherwise you get fragile. And you can't be fragile and have any fuckin' fun.\\nRODRIGUEZ: You think I'm fragile?\\nDIVINCI: That's the first sign of trouble, when you start askin' other people.\\n\\n\", 'answer': '...I just wish I knew where the hell she was.', 'gold_tag': \"Rodriguez's concern about not knowing the whereabouts of Ms. Webb\", 'last_speaker': 'RODRIGUEZ'}\n",
      "Last word -> RODRIGUEZ : \"...I just wish I knew where the hell she was.\"\n",
      "prediction :  You're too kind. I'm just lucky, I guess.\n",
      "Real answer : ...I just wish I knew where the hell she was.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8886706829071045], 'recall': [0.8735900521278381], 'f1': [0.881065845489502], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3, 'rouge2': 0.0, 'rougeL': 0.3, 'rougeLsum': 0.3}\n",
      "bleu 1/2 : 0.19470019576785122 0.04654224884494861\n",
      "ppl : 14.718111991882324\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRODRIGUEZ: She didn't talk.\\nDIVINCI: Don't hold your breath.\\nRODRIGUEZ: You think she'll talk.\\nDIVINCI: I know she'll talk.\\nRODRIGUEZ: We'll make it look gang related.\\nDIVINCI: Problem is we're gonna need another gun.\\nRODRIGUEZ: The problem?! Have you forgotten? She's in fucking jail. That's the goddamn problem.\\n\\n\", 'answer': \"Since when is being in jail a guaranty of a long life? You just get a fuckin' gun.\", 'gold_tag': 'DIVINCI is pragmatic and task-oriented, focusing on what needs to be done to resolve the problems at hand', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"Since when is being in jail a guaranty of a long life? You just get a fuckin' gun.\"\n",
      "prediction :  She said he shot her and killed her. ... But I can't confirm that. ... The only lead I have is they got into a physical fight this morning. ... We're gonna give her a call. I need her to come to the station.\n",
      "Real answer : Since when is being in jail a guaranty of a long life? You just get a fuckin' gun.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8349008560180664], 'recall': [0.8303759098052979], 'f1': [0.8326321840286255], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09836065573770493, 'rouge2': 0.0, 'rougeL': 0.09836065573770493, 'rougeLsum': 0.09836065573770493}\n",
      "bleu 1/2 : 0.06818181818181818 0.012592155012732868\n",
      "ppl : 16.498876571655273\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: You get the gun?\\nRODRIGUEZ: I got it.\\nDIVINCI: Everything okay?\\nRODRIGUEZ: Are you kidding? We're going to kill a goddamn witness who's in fucking jail because we killed an undercover DEA agent. I'm sorry, but this kinda shit troubles me a little.\\nDIVINCI: Take off the dress and get back in the game. We gotta do what we gotta do.\\n\\n\", 'answer': \"Yeah. I know. Let's just get it over with.\", 'gold_tag': 'RODRIGUEZ is involved with criminal behavior', 'last_speaker': 'RODRIGUEZ'}\n",
      "Last word -> RODRIGUEZ : \"Yeah. I know. Let's just get it over with.\"\n",
      "prediction :  You want a gun? Get a gun.\n",
      "Real answer : Yeah. I know. Let's just get it over with.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8627399802207947], 'recall': [0.8492661714553833], 'f1': [0.8559500575065613], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 52.61912536621094\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRODRIGUEZ: This is the last time, Frank. The last time we kill somebody.\\nDIVINCI: Yeah, it's the last time.\\nRODRIGUEZ: This'll be eleven, Frank. Eleven is enough.\\nDIVINCI: I get the picture.\\nRODRIGUEZ: It was all okay until you shot Hudd.\\nDIVINCI: What's goin' on here? You mad at me or something?\\nRODRIGUEZ: It wasn't my idea to start killing people, Frank. That's all I'm sayin'. We're in this goddamn mess because you started killing people.\\nDIVINCI: Drug dealers don't qualify as people. Never did, never will. So what the hell's wrong with you tonight? You suddenly worried about where all the money went?\\n\\n\", 'answer': \"I'm just sick of it, that's all.\", 'gold_tag': 'RODRIGUEZ is growing weary of their activities', 'last_speaker': 'RODRIGUEZ'}\n",
      "Last word -> RODRIGUEZ : \"I'm just sick of it, that's all.\"\n",
      "prediction :  You can tell Hudd and the rest of the bunch you owe me, Frank.\n",
      "Real answer : I'm just sick of it, that's all.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8426551222801208], 'recall': [0.8592042922973633], 'f1': [0.8508492112159729], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913043, 'rouge2': 0.0, 'rougeL': 0.08695652173913043, 'rougeLsum': 0.08695652173913043}\n",
      "bleu 1/2 : 0.07142857142857141 0.023440361546924773\n",
      "ppl : 109.34839630126953\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRODRIGUEZ: What're you doin'?\\n\\n\", 'answer': 'I need some fresh air.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"I need some fresh air.\"\n",
      "prediction :  I'm going.\n",
      "Real answer : I need some fresh air.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9202381372451782], 'recall': [0.8853394389152527], 'f1': [0.9024515748023987], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 101.39031219482422\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRODRIGUEZ: Frank --\\nDIVINCI: Talk to me, okay? Just fuckin' talk to me.\\nRODRIGUEZ: I don't know... I owe some money. I don't know how I'm gonna pay it...\\nDIVINCI: You gambling again?\\nRODRIGUEZ: Yeah, yeah... I just couldn't... Frank... let's forget about this. Let's just get the fuck outa here. We got enough money, let's go. We'll get outa the country or something. What the hell're you doin'?!\\nDIVINCI: Take off your shirt.\\nRODRIGUEZ: What're you talkin' about?\\nDIVINCI: Just take off your shirt. If there's nothin' to worry about, then I'll apologize. But I'm not gonna argue. Take off your fuckin' shirt now.\\nRODRIGUEZ: What is this, you piece of shit?! You don't trust me?! Is that it?! YOU DON'T FUCKIN' TRUST ME AFTER ALL WE'VE BEEN THROUGH?!\\nDIVINCI: ...Take off your shirt.\\nRODRIGUEZ: Fuck you, you don't trust me.\\nDIVINCI: I'm askin' you one more time.\\nRODRIGUEZ: You wanna shoot me? Shoot me.\\n\\n\", 'answer': \"Okay, I'm sorry. You're right. I'm fuckin' nervous. Like you. Forget it. This thing... shit. Let's just get it over with.\", 'gold_tag': 'DIVINCI has a distrust or suspicion towards his counterpart, RODRIGUEZ', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"Okay, I'm sorry. You're right. I'm fuckin' nervous. Like you. Forget it. This thing... shit. Let's just get it over with.\"\n",
      "prediction :  You seem to think this is a game. You do not have to play, if you do not want to.\n",
      "Real answer : Okay, I'm sorry. You're right. I'm fuckin' nervous. Like you. Forget it. This thing... shit. Let's just get it over with.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8486621379852295], 'recall': [0.8532583713531494], 'f1': [0.8509540557861328], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1333333333333333, 'rouge2': 0.0, 'rougeL': 0.08888888888888889, 'rougeLsum': 0.08888888888888889}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.783040046691895\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: I'll just feel a whole lot better when she's dead. Then we're off the hook.\\nRODRIGUEZ: Right.\\nDIVINCI: YOU FUCKIN' RAT!\\nRODRIGUEZ: Yeah... yeah... I am, I'm a fuckin' rat... I traded you, Frank, I fuckin' traded you... Simms knows everything. Just fuckin' shoot me, get it the fuck over with! I DESERVE IT! I FUCKING DESERVE TO DIE!\\nDIVINCI: You're fuckin' right. ...Get out.\\nRODRIGUEZ: Frank --\\n\\n\", 'answer': \"Get outa the car NOW! This is why you can never -- ever -- lose your sense of fuckin' humor.\", 'gold_tag': \"DIVINCI's comment about retaining a sense of humor suggests he may cope with stress or adversity in a cynical way\", 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"Get outa the car NOW! This is why you can never -- ever -- lose your sense of fuckin' humor.\"\n",
      "prediction :  It's over, man.\n",
      "Real answer : Get outa the car NOW! This is why you can never -- ever -- lose your sense of fuckin' humor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8800837993621826], 'recall': [0.8154451251029968], 'f1': [0.8465323448181152], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 58.8576774597168\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: It's okay...you're going to be okay.\\nRENNIE: I want to go home. I want off this ship.\\n\\n\", 'answer': \"Me too. Let's go talk to my Dad.\", 'gold_tag': 'SEAN has a familial relationship with the person in authority onboard, his Dad', 'last_speaker': 'SEAN'}\n",
      "Last word -> SEAN : \"Me too. Let's go talk to my Dad.\"\n",
      "prediction :  Well, the first thing I have to warn you is they'll likely lock you up first. But no, really. It's better this way, even if some of the crew say it's wrong. No one can blame you for it.\n",
      "Real answer : Me too. Let's go talk to my Dad.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8427921533584595], 'recall': [0.8669753670692444], 'f1': [0.854712724685669], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0784313725490196, 'rouge2': 0.0, 'rougeL': 0.0392156862745098, 'rougeLsum': 0.0392156862745098}\n",
      "bleu 1/2 : 0.025641025641025644 0.00821440096816907\n",
      "ppl : 16.249677658081055\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRENNIE: Can he really take us home?\\nSEAN: Not completing a voyage is against everything he stands for. But I think I can convince him to call a Coast Guard cutter for you.\\nRENNIE: What about you?\\n\\n', 'answer': \"If I go with you, he'll never speak to me again. But I'm never going to live up to his expectations anyway...so maybe it's the right thing to do.\", 'gold_tag': \"SEAN struggles with living up to someone's expectations, presumably a figure of authority , SEAN is in a state of considering breaking free from some form of ongoing expectations\", 'last_speaker': 'SEAN'}\n",
      "Last word -> SEAN : \"If I go with you, he'll never speak to me again. But I'm never going to live up to his expectations anyway...so maybe it's the right thing to do.\"\n",
      "prediction :  (11:11) I'm on break. I'll be back on my ship soon enough.\n",
      "Real answer : If I go with you, he'll never speak to me again. But I'm never going to live up to his expectations anyway...so maybe it's the right thing to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8373476266860962], 'recall': [0.842896044254303], 'f1': [0.8401126861572266], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.043478260869565216, 'rougeL': 0.08333333333333333, 'rougeLsum': 0.08333333333333333}\n",
      "bleu 1/2 : 0.020210089552970725 0.006675172886333876\n",
      "ppl : 19.83507537841797\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: Rennie...??\\nRENNIE: The window... I don't understand what is happening to me...\\n\\n\", 'answer': \"It's gonna be okay...\", 'gold_tag': 'SEAN is a supportive presence , SEAN is a calming presence', 'last_speaker': 'SEAN'}\n",
      "Last word -> SEAN : \"It's gonna be okay...\"\n",
      "prediction :  You're not alone...\n",
      "Real answer : It's gonna be okay...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8710317015647888], 'recall': [0.8460773229598999], 'f1': [0.85837322473526], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 56.976959228515625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRENNIE: What is it??\\n\\n', 'answer': 'The power room...', 'gold_tag': 'Everyday Language', 'last_speaker': 'SEAN'}\n",
      "Last word -> SEAN : \"The power room...\"\n",
      "prediction :  Are you worried for her?\n",
      "Real answer : The power room...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8267489671707153], 'recall': [0.8287835121154785], 'f1': [0.8277649879455566], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 288.8167724609375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: Rule one, don't panic. Rule two, assess the damage and act accordingly...\\nRENNIE: Is the ship going to sink??\\nSEAN: I don't know. The emergency lights just kicked in... We'll be okay. I want you to wait by the lifeboats, just in case.\\nRENNIE: I'm not going near any lifeboat!\\nSEAN: But Rennie...\\n\\n\", 'answer': \"I'm not!!\", 'gold_tag': 'RENNIE displays fear towards lifeboats , RENNIE shows strong reluctance towards lifeboats', 'last_speaker': 'RENNIE'}\n",
      "Last word -> RENNIE : \"I'm not!!\"\n",
      "prediction :  Wait! I don't feel OK.\n",
      "Real answer : I'm not!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8638485670089722], 'recall': [0.8506441712379456], 'f1': [0.8571954965591431], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2222222222222222, 'rouge2': 0.0, 'rougeL': 0.2222222222222222, 'rougeLsum': 0.2222222222222222}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 80.81505584716797\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: Rennie...what'd they do to you??\\nRENNIE: Drugs... Then Jason came. He's here, Sean.\\n\\n\", 'answer': 'We have to find the others.', 'gold_tag': 'SEAN takes on a leadership role to find the others , SEAN has a present task to find the others', 'last_speaker': 'SEAN'}\n",
      "Last word -> SEAN : \"We have to find the others.\"\n",
      "prediction :  (laughs) What!\n",
      "Real answer : We have to find the others.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8141390085220337], 'recall': [0.849062442779541], 'f1': [0.8312340974807739], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 301.22821044921875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRENNIE: I was at school when they told me. 'Rennie, we have some very bad news... your parents have been killed in an auto accident.' It seems like everybody I care about ends up...\\nSEAN: Not this time.\\n\\n\", 'answer': \"Toby... What's wrong, boy?\", 'gold_tag': 'RENNIE has a pet named Toby', 'last_speaker': 'RENNIE'}\n",
      "Last word -> RENNIE : \"Toby... What's wrong, boy?\"\n",
      "prediction :  You do this to people.\n",
      "Real answer : Toby... What's wrong, boy?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8510965704917908], 'recall': [0.8316783905029297], 'f1': [0.8412754535675049], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 204.11422729492188\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: Run, Rennie...\\n\\n', 'answer': \"You never got me in the lake, Jason. And you're not going to get me now either.\", 'gold_tag': 'RENNIE is a brave individual , RENNIE is not easily intimidated , RENNIE showed a defiant stance against Jason', 'last_speaker': 'RENNIE'}\n",
      "Last word -> RENNIE : \"You never got me in the lake, Jason. And you're not going to get me now either.\"\n",
      "prediction :  I can't...\n",
      "Real answer : You never got me in the lake, Jason. And you're not going to get me now either.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8331310153007507], 'recall': [0.8181650042533875], 'f1': [0.8255802392959595], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 90.78096008300781\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAN DE: Your training begins tomorrow. For now, your shr fu will\\n\\n', 'answer': 'Great, just great.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DREW'}\n",
      "Last word -> DREW : \"Great, just great.\"\n",
      "prediction :  Yeah, sure.\n",
      "Real answer : Great, just great.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9172672629356384], 'recall': [0.8881875276565552], 'f1': [0.9024932980537415], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 310.96142578125\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDREW: Yeah, what's up with him?\\n\\n\", 'answer': 'Come with me...', 'gold_tag': 'Everyday Language', 'last_speaker': 'SAN DE'}\n",
      "Last word -> SAN DE : \"Come with me...\"\n",
      "prediction :  Oh, he's fine. You know, he's actually happy today.\n",
      "Real answer : Come with me...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8240950703620911], 'recall': [0.7974911332130432], 'f1': [0.8105748295783997], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 20.414377212524414\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDREW: I wouldn't have made it through without you. You once asked why I came here, why did you let me in?\\nSAN DE: Do you remember the story you heard about the monk who\\nDREW: Yes.\\nSAN DE: That monk was me.\\nDREW: Anything.\\nSAN DE: Before you leave for American, can you help at an international tournament in Beijing? The Shaolin temple has an entry, and he will be fighting men from all over the world I'd like you to be there.\\nDREW: No problem.\\n\\n\", 'answer': 'Now, a friend would like to see you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SAN DE'}\n",
      "Last word -> SAN DE : \"Now, a friend would like to see you.\"\n",
      "prediction :  Your parents won't say a word about it?\n",
      "Real answer : Now, a friend would like to see you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.853756308555603], 'recall': [0.8542020916938782], 'f1': [0.8539791107177734], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.12500000000000003 0.04225771273642583\n",
      "ppl : 71.82957458496094\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHENRY: You heard our broadcast.\\nJIM: Yes.\\nHENRY: We must be a disappointment. You were hoping for a full brigade. An army base, with helicopters and field hospitals.\\nJIM: We were hoping for...\\nHENRY: The answer to infection. Well, as I said, it's here. Though it may not be quite what you imagined.\\nJIM: I didn't know what to imagine, so... We just feel lucky to have found you.\\n\\n\", 'answer': \"You were lucky. The fire drove hundreds of infected out of Manchester. The surrounding area is teeming with them. But there's no need for you to worry. We're well protected here.\", 'gold_tag': \"HENRY indicates that there was a recent event where a fire drove hundreds of infected out of Manchester , HENRY is responsible for the group's safety\", 'last_speaker': 'HENRY'}\n",
      "Last word -> HENRY : \"You were lucky. The fire drove hundreds of infected out of Manchester. The surrounding area is teeming with them. But there's no need for you to worry. We're well protected here.\"\n",
      "prediction :  It gets worse every day. I'm going to get sick.\n",
      "Real answer : You were lucky. The fire drove hundreds of infected out of Manchester. The surrounding area is teeming with them. But there's no need for you to worry. We're well protected here.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8672436475753784], 'recall': [0.8559510707855225], 'f1': [0.8615604043006897], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.045454545454545456, 'rouge2': 0.0, 'rougeL': 0.045454545454545456, 'rougeLsum': 0.045454545454545456}\n",
      "bleu 1/2 : 0.012245642825298194 0.004081880941766065\n",
      "ppl : 24.91856575012207\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHENRY: And finally... ...meet Mailer. Mailer, Jim. Jim, Mailer. Got infected three days ago. Mitchell managed to knock him out cold. Got a chain around his neck.\\nJIM: You're keeping him alive?\\n\\n\", 'answer': \"The idea was to learn something about infection. Have him teach me. In a way. He's teaching me he'll never bake bread. Plant crops, raise livestock. He's telling me he's futureless. And eventually he'll tell me how long the infected take to starve to death. Dinner's at seven. Don't forget to tell the girls.\", 'gold_tag': 'HENRY is pragmatic and somewhat scientific in his approach to the infection , HENRY demonstrates a proactive mindset , HENRY implies a temporal aspect when mentioning the scheduled dinner at seven', 'last_speaker': 'HENRY'}\n",
      "Last word -> HENRY : \"The idea was to learn something about infection. Have him teach me. In a way. He's teaching me he'll never bake bread. Plant crops, raise livestock. He's telling me he's futureless. And eventually he'll tell me how long the infected take to starve to death. Dinner's at seven. Don't forget to tell the girls.\"\n",
      "prediction :  If you want to see him dead, go ahead. Let him go. It's what he deserves.\n",
      "Real answer : The idea was to learn something about infection. Have him teach me. In a way. He's teaching me he'll never bake bread. Plant crops, raise livestock. He's telling me he's futureless. And eventually he'll tell me how long the infected take to starve to death. Dinner's at seven. Don't forget to tell the girls.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8594930768013], 'recall': [0.8330743312835693], 'f1': [0.8460775017738342], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10256410256410256, 'rouge2': 0.0, 'rougeL': 0.10256410256410256, 'rougeLsum': 0.10256410256410256}\n",
      "bleu 1/2 : 0.011626811151332938 0.0026850970192156052\n",
      "ppl : 14.925926208496094\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHENRY: Drink?\\nJIM: Look. We're grateful. Very grateful for your protection, and just to have found other people. But if we're going to stay here with you, you're going to have to stop your men from -\\nHENRY: Who have you killed?\\nJIM: I haven't killed anyone.\\nHENRY: Since it began, who have you killed? You wouldn't be alive now if you hadn't killed somebody.\\nJIM: A boy. I killed a boy.\\nHENRY: A child?\\nJIM: Yes.\\nHENRY: But you had to. Otherwise he'd have killed you. Survival. I understand. I promised them women.\\nJIM: What?\\n\\n\", 'answer': 'Eight days ago I found Jones with his gun in this mouth. He said he was going to kill himself because there was no future. What could I say to him? We kill all the infected or wait until they starve nine men do except wait to die themselves? I moved us from the blockade, I set the radio broadcasting, and I promised them women. Because women mean children. And children mean a future.', 'gold_tag': 'Eight days ago, Henry found Jones with a gun in his mouth, contemplating suicide , Henry moved the group from the blockade and set the radio broadcasting', 'last_speaker': 'HENRY'}\n",
      "Last word -> HENRY : \"Eight days ago I found Jones with his gun in this mouth. He said he was going to kill himself because there was no future. What could I say to him? We kill all the infected or wait until they starve nine men do except wait to die themselves? I moved us from the blockade, I set the radio broadcasting, and I promised them women. Because women mean children. And children mean a future.\"\n",
      "prediction :  Jim. I'll ask again, Jim. Who do you trust?\n",
      "Real answer : Eight days ago I found Jones with his gun in this mouth. He said he was going to kill himself because there was no future. What could I say to him? We kill all the infected or wait until they starve nine men do except wait to die themselves? I moved us from the blockade, I set the radio broadcasting, and I promised them women. Because women mean children. And children mean a future.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8446821570396423], 'recall': [0.8206977248191833], 'f1': [0.8325172066688538], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.047619047619047616, 'rouge2': 0.0, 'rougeL': 0.047619047619047616, 'rougeLsum': 0.047619047619047616}\n",
      "bleu 1/2 : 8.11308885405331e-05 2.721212727773861e-05\n",
      "ppl : 40.78818893432617\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHANG: I am from a nearby Lamasery. My name is Chang.\\nCONWAY: And mine's Conway. You've no idea, sir, how unexpected and very welcome you are. My friends and I - and the lady in the plane - left Baskul night before last for Shanghai, but we suddenly found ourselves travelling in the opposite direction� At the mercy of a mad pilot. We'd be eternally grateful if you�\\nCHANG: Where is your mad pilot?\\nCONWAY: We were just going to bury him when you came along.\\nCHANG: Pardon me� instructions to take care of the pilot.\\nCONWAY: So, if you will be good enough to direct us to your Lamasery�\\n\\n\", 'answer': 'I shall consider it an honor to accompany you and your friends. You will need suitable clothes for the journey. It is not particularly far, but quite difficult.', 'gold_tag': 'CHANG takes on the role of guiding Conway and his friends to his Lamasery', 'last_speaker': 'CHANG'}\n",
      "Last word -> CHANG : \"I shall consider it an honor to accompany you and your friends. You will need suitable clothes for the journey. It is not particularly far, but quite difficult.\"\n",
      "prediction :  I'm Chang.\n",
      "Real answer : I shall consider it an honor to accompany you and your friends. You will need suitable clothes for the journey. It is not particularly far, but quite difficult.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8618899583816528], 'recall': [0.834944486618042], 'f1': [0.8482032418251038], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06451612903225806, 'rouge2': 0.0, 'rougeL': 0.06451612903225806, 'rougeLsum': 0.06451612903225806}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 273.0649719238281\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHANG: it. There are over two thousand people in the Valley besides those here in Shangri-La.\\nCONWAY: Who and what is Shangri-La? You?\\nCHANG: Goodness, no! Oh, yes.\\nCONWAY: Who, for instance?\\nCHANG: In time you will meet them all. There are some things, my dear Conway, I deeply regret I may not discuss.\\nCONWAY: You know, that's the fourth time you've said that today. You should have a record made of it.\\n\\n\", 'answer': 'Shall we go inside? I should so like to show you some of our rare treasures.', 'gold_tag': 'CHANG is affiliated with Shangri-La, possibly as a resident or someone with significant knowledge about it', 'last_speaker': 'CHANG'}\n",
      "Last word -> CHANG : \"Shall we go inside? I should so like to show you some of our rare treasures.\"\n",
      "prediction :  I have always felt that the fate of the world, and indeed a person as well if such an opportunity presents itself, was in the hands of the heart, of emotion, the way one thinks.\n",
      "Real answer : Shall we go inside? I should so like to show you some of our rare treasures.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8209395408630371], 'recall': [0.8566822409629822], 'f1': [0.8384301066398621], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0784313725490196, 'rouge2': 0.0, 'rougeL': 0.0784313725490196, 'rougeLsum': 0.0784313725490196}\n",
      "bleu 1/2 : 0.057142857142857134 0.012964074471043278\n",
      "ppl : 19.04204750061035\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHANG: At some time in the future you will have the pleasure of meeting her.\\n\\n', 'answer': 'Some man had better get ready to be very courteous to me.', 'gold_tag': 'CONWAY implies a future situation where he expects to be treated with courtesy', 'last_speaker': 'CONWAY'}\n",
      "Last word -> CONWAY : \"Some man had better get ready to be very courteous to me.\"\n",
      "prediction :  I don't think so. As an adult, you know how difficult change is.\n",
      "Real answer : Some man had better get ready to be very courteous to me.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8462250232696533], 'recall': [0.8436731100082397], 'f1': [0.844947099685669], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.22437286376953\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCONWAY: But Mr. Chang, all these things - books, instruments, sculpture - do you mean to say they were all brought in over those mountains by porters?\\nCHANG: They were.\\nCONWAY: Well, it must have taken� Centuries! Where did you get the money to pay for all those treasures?\\n\\n', 'answer': 'Of course we have no money as you know it. We do not buy or sell or seek personal fortunes because, well, because there is no uncertain future here for which to accumulate it.', 'gold_tag': \"CHANG lives in a society without conventional currency , Personal fortunes are not sought after in CHANG's society , The future is certain in CHANG's society\", 'last_speaker': 'CHANG'}\n",
      "Last word -> CHANG : \"Of course we have no money as you know it. We do not buy or sell or seek personal fortunes because, well, because there is no uncertain future here for which to accumulate it.\"\n",
      "prediction :  Who knows where they are?\n",
      "Real answer : Of course we have no money as you know it. We do not buy or sell or seek personal fortunes because, well, because there is no uncertain future here for which to accumulate it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8393998146057129], 'recall': [0.8055893182754517], 'f1': [0.8221471309661865], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 109.3291015625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCONWAY: That would suit me perfectly. I\\'m always broke. How did you pay for them?\\nCHANG: Our Valley is very rich in a metal called gold, which fortunately for us is valued very highly in the outside world. So we merely . . .\\nCONWAY: �buy and sell?\\nCHANG: Buy and - sell? No, no, pardon me, exchange\\nCONWAY: I see. Gold for ideas. You know Mr. Chang, there\\'s something so simple and naive about all of this that I suspect there has been a shrewd, guiding intelligence somewhere. Whose idea was it? How did it all start?\\nCHANG: That, my dear Conway, is the story of A Belgian priest by the name of Father Perrault, the first European to find this place, and a very great man indeed. He is responsible for everything you see here. He built Shangri-La, taught our natives, and began our collection of art. In fact, Shangri-La is Father Perrault. Oh, let me see - way back in 1713, I think it was, that Father Perrault stumbled It was typical of the man that, one leg being frozen, and of course there being no doctors here, he amputated the leg himself.\\nCONWAY: He amputated his own leg?\\nCHANG: Yes. Oddly enough, later, when he had learned to understand their language, the natives told him he could have saved his leg. It would have healed without amputation.\\nCONWAY: Well, they didn\\'t actually mean that.\\nCHANG: Yes, yes. They were very sincere about it too. You see, a perfect body in perfect health is the rule here. They\\'ve never known anything different. So what was true for them they thought would naturally be true for anyone else living here.\\nCONWAY: Well, is it?\\nCHANG: Rather astonishingly so, yes. And particularly Do you know when he and the natives were finished building Shangri-La, he was 108 years old and still very active, in spite of only having one leg?\\nCONWAY: 108 and still active?\\nCHANG: Forgive me. I should have told you it is quite common here to live to a very ripe old age. Climate, diet, mountain water, you might say. But we like to believe it is the absence of struggle in the way we live. In your countries, on the other hand, how often do you hear the expression, \"He worried himself to death?\" or, \"This thing or that killed him?\"\\nCONWAY: Very often.\\nCHANG: And very true. Your lives are therefore, Why, Mr. Conway, you surprise me!\\nCONWAY: I surprise you? Now that\\'s news.\\n\\n', 'answer': \"I mean, your amazement. I could have understood it in any of your companions, but you - who have dreamed and written so much about better worlds. Or is it that you fail to recognize one of your own dreams when you see it? Then everything is quite all right, isn't it?\", 'gold_tag': 'CONWAY is surprised at the long lifespan of people in the valley, although he has written about better worlds', 'last_speaker': 'CHANG'}\n",
      "Last word -> CHANG : \"I mean, your amazement. I could have understood it in any of your companions, but you - who have dreamed and written so much about better worlds. Or is it that you fail to recognize one of your own dreams when you see it? Then everything is quite all right, isn't it?\"\n",
      "prediction :  Well, it is an unusual experience for me to find someone so eager and so willing to learn from Shangri-La.\n",
      "Real answer : I mean, your amazement. I could have understood it in any of your companions, but you - who have dreamed and written so much about better worlds. Or is it that you fail to recognize one of your own dreams when you see it? Then everything is quite all right, isn't it?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8568048477172852], 'recall': [0.829940915107727], 'f1': [0.8431589603424072], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.136986301369863, 'rouge2': 0.0, 'rougeL': 0.10958904109589042, 'rougeLsum': 0.10958904109589042}\n",
      "bleu 1/2 : 0.050474129498663846 0.007323556439251554\n",
      "ppl : 35.675376892089844\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSLOANE: Cool.\\n\\n', 'answer': 'I think I see my Dad.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CAMERON'}\n",
      "Last word -> CAMERON : \"I think I see my Dad.\"\n",
      "prediction :  Let me know what you think -- what it's like to be inside an actual volcano.\n",
      "Real answer : I think I see my Dad.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8456733226776123], 'recall': [0.8777696490287781], 'f1': [0.8614225387573242], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09090909090909091, 'rouge2': 0.0, 'rougeL': 0.09090909090909091, 'rougeLsum': 0.09090909090909091}\n",
      "bleu 1/2 : 0.0625 0.02041241452319315\n",
      "ppl : 31.2995662689209\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCAMERON: What were you in a previous life?\\nSLOANE: I'm not sure but I think I know who Ferris was.\\nCAMERON: Hannibal.\\nSLOANE: From the A-Team?\\nCAMERON: No. The guy who rode the elephants into Switzerland.\\nSLOANE: I think if he was anybody, he was Magellan. You know, the guy who went around the world. I could see him ignoring popular belief and taking off on some impossible mission.\\n\\n\", 'answer': \"Yeah. As long as I've known him, everything works for him. There's nothing he can't handle. I can't handle anything. School, parents,\", 'gold_tag': 'CAMERON feels inadequate to handle life challenges , CAMERON struggles with school , CAMERON struggles with dealing with parents , Shared memories', 'last_speaker': 'CAMERON'}\n",
      "Last word -> CAMERON : \"Yeah. As long as I've known him, everything works for him. There's nothing he can't handle. I can't handle anything. School, parents,\"\n",
      "prediction :  Do you consider yourself brave?\n",
      "Real answer : Yeah. As long as I've known him, everything works for him. There's nothing he can't handle. I can't handle anything. School, parents,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8237742781639099], 'recall': [0.8266867399215698], 'f1': [0.8252279758453369], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 102.65941619873047\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSLOANE: The future's worse for a boy, isn't it? A girl can always bail out and have a baby and get some guy to support her.\\nCAMERON: That's a pretty grim thought.\\nSLOANE: True, but it's an option. No options is worse.\\nCAMERON: I don't know what I'm gonna do.\\nSLOANE: College.\\nCAMERON: Yeah, but to do what?\\nSLOANE: What are you interested in?\\nCAMERON: Nothing.\\nSLOANE: Me either.\\n\\n\", 'answer': 'What do you think Ferris is gonna do?', 'gold_tag': 'Everyday Language', 'last_speaker': 'CAMERON'}\n",
      "Last word -> CAMERON : \"What do you think Ferris is gonna do?\"\n",
      "prediction :  There's a whole new world waiting out there for my kind of guy.\n",
      "Real answer : What do you think Ferris is gonna do?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8502337336540222], 'recall': [0.8179473280906677], 'f1': [0.8337781429290771], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 21.94851303100586\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBAINES: Those 80 acres, that cross the stream, what do you think of them?\\nSTEWART: On your property?\\nBAINES: Yes\\nSTEWART: Good, flatish land with reliable water, why? I don't have money. What are you about?\\nBAINES: I'd like to make a swap.\\nSTEWART: What for?\\nBAINES: The piano.\\nSTEWART: The piano on the beach? Ada's piano? It's not marshy is it?\\nBAINES: No.\\nSTEWART: You'd have to organise it up here.\\nBAINES: Yes, I thought that.\\nSTEWART: Well Baines the music lover, I never would have known. Hidden talents George.\\nBAINES: I'll have to get lessons. It wouldn't be much use without them.\\n\\n\", 'answer': \"Yes, I suppose you would. Well Ada can play. I have it in a letter she plays well. She's been playing since she was 5 or6.\", 'gold_tag': 'STEWART knows Ada, her piano, and her musical talent, indicating a close relationship or awareness', 'last_speaker': 'STEWART'}\n",
      "Last word -> STEWART : \"Yes, I suppose you would. Well Ada can play. I have it in a letter she plays well. She's been playing since she was 5 or6.\"\n",
      "prediction :  ...And you're the one to tell me?\n",
      "Real answer : Yes, I suppose you would. Well Ada can play. I have it in a letter she plays well. She's been playing since she was 5 or6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8405965566635132], 'recall': [0.8358315825462341], 'f1': [0.8382073044776917], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05714285714285714, 'rouge2': 0.0, 'rougeL': 0.05714285714285714, 'rougeLsum': 0.05714285714285714}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 44.83278274536133\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTEWART: What do they want it for? They don't cultivate it, burn it back, anything. How do they even know it's theirs? as well mark it out.\\nBAINES: Yes, why not.\\nSTEWART: Ada says you're doing well with the piano? I'll have to come and hear you play. what do you play.\\nBAINES: Nothing just yet\\n\\n\", 'answer': 'No. Well I suppose it takes time.', 'gold_tag': 'Everyday Language', 'last_speaker': 'STEWART'}\n",
      "Last word -> STEWART : \"No. Well I suppose it takes time.\"\n",
      "prediction :  you've got to keep on practising for a while to learn to play the piano or anything else.\n",
      "Real answer : No. Well I suppose it takes time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8582522869110107], 'recall': [0.8796443939208984], 'f1': [0.8688167333602905], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.15262222290039\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTEWART: Put that away, on the floor. I look at you, at your face. I have had that face in my head hating it. But now I am here seeing it ... it\\'s nothing, you blink, you have your mark, you look at me through your eyes, yes. you are even scared of me Look at you! Has Ada ever spoken to you?\\nBAINES: You mean in signs?\\nSTEWART: No, words. You have never heard words?\\nBAINES: No, not words.\\nSTEWART: Never thought you heard words? She has spoken to me. I heard her voice. There was no sound, but I beard it here (he presses hand). Her voice was there in my head. I watched her lips, they did not make the words, yet the harder I listened the clearer I heard her, as clear as I hear you, as dear as I hear my own voice.\\nBAINES: Spoken words?\\nSTEWART: No, but her words are in my that it\\'s a trick, that I\\'m making it up. No, the words I heard, were her words.\\nBAINES: (suspiciously) What are they?\\nSTEWART: She said, \"I have to go, let me go, let Baines take me away, let him try and save me. I am frightened of my will, of what it might do it is so strange and strong\".\\nBAINES: You punished her wrongly, it was me, my fault.\\n\\n', 'answer': \"Understand me. I am here for her, for her I wonder that I don't wake, that I am not asleep to be here talking with you. I love her. But what is the use? She doesn't care for me. I wish her gone. I wish you gone. I want to wake and find it was a dream, that is what I want. I want to believe I am not this man. I want my self back; the one I know.\", 'gold_tag': 'STEWART expresses frustration and sadness', 'last_speaker': 'STEWART'}\n",
      "Last word -> STEWART : \"Understand me. I am here for her, for her I wonder that I don't wake, that I am not asleep to be here talking with you. I love her. But what is the use? She doesn't care for me. I wish her gone. I wish you gone. I want to wake and find it was a dream, that is what I want. I want to believe I am not this man. I want my self back; the one I know.\"\n",
      "prediction :  I punished her wrongly, it was me, my fault. She can not control her words, but she can control her voice. Let Baines try and save me, I have to get out.\n",
      "Real answer : Understand me. I am here for her, for her I wonder that I don't wake, that I am not asleep to be here talking with you. I love her. But what is the use? She doesn't care for me. I wish her gone. I wish you gone. I want to wake and find it was a dream, that is what I want. I want to believe I am not this man. I want my self back; the one I know.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8658664226531982], 'recall': [0.846726655960083], 'f1': [0.8561895489692688], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2631578947368421, 'rouge2': 0.03571428571428571, 'rougeL': 0.17543859649122806, 'rougeLsum': 0.17543859649122806}\n",
      "bleu 1/2 : 0.07670099255102274 0.023496262401094176\n",
      "ppl : 56.249122619628906\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK FURY: We should tell them to go back to sleep?\\nAGENT MARIA HILL: If we can't control the Tesseract's energy, there may not be a minimum safe\\nNICK FURY: I need you to make sure that PHASE 2\\nAGENT MARIA HILL: Sir, is that really a priority right now?\\nNICK FURY: Until such time as the world ends, we will act as though it intends to spin on. Clear out the tech below. Every piece of PHASE 2 on a truck and gone.\\n\\n\", 'answer': 'Yes, sir. With me.', 'gold_tag': 'AGENT MARIA HILL is subordinate to NICK FURY and follows his orders', 'last_speaker': 'AGENT MARIA HILL'}\n",
      "Last word -> AGENT MARIA HILL : \"Yes, sir. With me.\"\n",
      "prediction :  ...But what happened to the rest of our ship?\n",
      "Real answer : Yes, sir. With me.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8313567638397217], 'recall': [0.8303437232971191], 'f1': [0.8308498859405518], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 75.52047729492188\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nAGENT MARIA HILL: We're at lock, sir.\\n\\n\", 'answer': \"Good. Let's vanish.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'NICK FURY'}\n",
      "Last word -> NICK FURY : \"Good. Let's vanish.\"\n",
      "prediction :  All that's left to do here is check off your log.\n",
      "Real answer : Good. Let's vanish.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8251474499702454], 'recall': [0.8921920657157898], 'f1': [0.8573610782623291], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 44.64603805541992\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nAGENT MARIA HILL: Sir.\\nNICK FURY: Agent Hill?\\nAGENT MARIA HILL: Those cards, they were in Coulson's locker, not in his jacket.\\nNICK FURY: They needed the push. They found it. Get our communications back up, whatever you have to do. I want eyes on everything.\\n\\n\", 'answer': 'Yes, sir.', 'gold_tag': 'AGENT MARIA HILL is a subordinate to NICK FURY', 'last_speaker': 'AGENT MARIA HILL'}\n",
      "Last word -> AGENT MARIA HILL : \"Yes, sir.\"\n",
      "prediction :  I know.\n",
      "Real answer : Yes, sir.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8743525743484497], 'recall': [0.8408003449440002], 'f1': [0.8572482466697693], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 372.595947265625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK FURY: They'll come back.\\nAGENT MARIA HILL: You really sure about that?\\nNICK FURY: I am.\\nAGENT MARIA HILL: Why?\\n\\n\", 'answer': \"Because we'll need them to.\", 'gold_tag': 'NICK FURY indicates a future need for the implied group, suggesting a potential crisis or threat', 'last_speaker': 'NICK FURY'}\n",
      "Last word -> NICK FURY : \"Because we'll need them to.\"\n",
      "prediction :  ... Because of what's on the other side of the gate. It's the last battle, and we must win it.\n",
      "Real answer : Because we'll need them to.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8523492217063904], 'recall': [0.863284707069397], 'f1': [0.8577821254730225], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14814814814814814, 'rouge2': 0.0, 'rougeL': 0.14814814814814814, 'rougeLsum': 0.14814814814814814}\n",
      "bleu 1/2 : 0.05000000000000001 0.01622214211307625\n",
      "ppl : 16.509307861328125\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMANRAY: I'm starvin' like Marvin.\\nCHEEBA: My world famous, famous world Arroz con pollo will be ready very soon.\\nMANRAY: Hurry up, I wanna watch HBO.\\nCHEEBA: Did we get our bill yet?\\nMANRAY: I guess that will come with the rent, gas, and Con Ed bills, too.\\nCHEEBA: Ahh, the luxuries of life.\\nMANRAY: Yo, check it. This is good and all that but one day soon I want to have much Benjamins so I can have a nice crib and pay all my bills. You hear me.\\nCHEEBA: Chill, I'm the brains behind this outfit.\\nMANRAY: And I'm the feet.\\nCHEEBA: Yo, you gotta show some patience. You want me to snap my fingers and presto chango - you're an overnight sensation. Son, there is no such thing.\\n\\n\", 'answer': \"I'm tired of waiting.\", 'gold_tag': 'MANRAY is somewhat impatient', 'last_speaker': 'MANRAY'}\n",
      "Last word -> MANRAY : \"I'm tired of waiting.\"\n",
      "prediction :  I'd love to watch HBO.\n",
      "Real answer : I'm tired of waiting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9035525918006897], 'recall': [0.9020484089851379], 'f1': [0.9027998447418213], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1818181818181818, 'rouge2': 0.0, 'rougeL': 0.1818181818181818, 'rougeLsum': 0.1818181818181818}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 124.74498748779297\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHEEBA: Not this way. Out through the fire escape.\\n\\n', 'answer': 'My tap shoes.', 'gold_tag': 'MANRAY is a tap dancer , MANRAY is concerned about his tap shoes', 'last_speaker': 'MANRAY'}\n",
      "Last word -> MANRAY : \"My tap shoes.\"\n",
      "prediction :  I’ll look out!\n",
      "Real answer : My tap shoes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8156156539916992], 'recall': [0.8802036643028259], 'f1': [0.8466796875], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 216.96746826171875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMANRAY: We ran out without my shoes and the floor. I gotta get my stuff. What about our savings?\\n\\n', 'answer': 'Are you crazy? The joint is crawling with cops now. You wanna go to Rikers? Go to the hoosegow?', 'gold_tag': 'CHEEBA is risk-avoidant , CHEEBA suggests the immediate danger of encountering the police if they return to their previous location', 'last_speaker': 'CHEEBA'}\n",
      "Last word -> CHEEBA : \"Are you crazy? The joint is crawling with cops now. You wanna go to Rikers? Go to the hoosegow?\"\n",
      "prediction :  I don't know anything about the future. You can't. No one can.\n",
      "Real answer : Are you crazy? The joint is crawling with cops now. You wanna go to Rikers? Go to the hoosegow?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8582140207290649], 'recall': [0.8239787817001343], 'f1': [0.8407480716705322], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12121212121212122, 'rouge2': 0.0, 'rougeL': 0.12121212121212122, 'rougeLsum': 0.12121212121212122}\n",
      "bleu 1/2 : 0.0930058576283412 0.021721488589350173\n",
      "ppl : 10.583438873291016\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEMILIE: It's not a charade, all this?\\nSCHINDLER: A charade? How could it be a charade? There's no way I could have known this before, but there was always something missing. In every business I tried, I see now it wasn't me that was failing, it was this thing, this missing thing. Even if I'd known what it was, there's nothing I could have done about it, because you can't create this sort of thing. And it makes all the difference in the world between success and failure.\\nEMILIE: Luck.\\n\\n\", 'answer': 'War.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SCHINDLER'}\n",
      "Last word -> SCHINDLER : \"War.\"\n",
      "prediction :  No, not luck. There's this thing that brings together every single success. What you have to do is find the thing and go get it. Then you create your own success.\n",
      "Real answer : War.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8260458111763], 'recall': [0.9287291765213013], 'f1': [0.8743831515312195], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 26.32219886779785\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSCHINDLER: What?\\n\\n', 'answer': 'I feel like an old-fashioned couple. It feels good.', 'gold_tag': 'EMILIE enjoys the feeling of being in an old-fashioned couple', 'last_speaker': 'EMILIE'}\n",
      "Last word -> EMILIE : \"I feel like an old-fashioned couple. It feels good.\"\n",
      "prediction :  What do you mean?\n",
      "Real answer : I feel like an old-fashioned couple. It feels good.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8018220663070679], 'recall': [0.821406900882721], 'f1': [0.8114963173866272], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 69.61486053466797\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEMILIE: Should I stay?\\nSCHINDLER: It's a beautiful city.\\nEMILIE: Should I stay?\\nSCHINDLER: It's up to you. That's not it either.\\n\\n\", 'answer': \"No, it's up to you. Promise me no doorman or maitre 'd will presume I am anyone other than Mrs. Schindler... and I'll stay.\", 'gold_tag': \"EMILIE is the wife of Schindler , EMILIE wants to be recognized as Mrs. Schindler, not by her association with others like doormen or maitre 'd\", 'last_speaker': 'EMILIE'}\n",
      "Last word -> EMILIE : \"No, it's up to you. Promise me no doorman or maitre 'd will presume I am anyone other than Mrs. Schindler... and I'll stay.\"\n",
      "prediction :  Should I stay?\n",
      "Real answer : No, it's up to you. Promise me no doorman or maitre 'd will presume I am anyone other than Mrs. Schindler... and I'll stay.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.885481059551239], 'recall': [0.7968990802764893], 'f1': [0.8388580083847046], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13793103448275862, 'rouge2': 0.0, 'rougeL': 0.13793103448275862, 'rougeLsum': 0.13793103448275862}\n",
      "bleu 1/2 : 0.0003039606551848387 0.00011772345554331757\n",
      "ppl : 716.1742553710938\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJENNY: You sure this is your car?\\nTEENAGER: My grandmother's rich.\\nJENNY: Slow down, slow down.\\nTEENAGER: Geez, Mrs. Haydn, we just got going.\\nJENNY: I told you I'm looking for someone.\\nTEENAGER: In the cars, too?!\\nJENNY: I don't know where he is.\\nTEENAGER: This is going to be a real drag. I thought you wanted to go fast. They after you?\\nJENNY: What? No, of course not.\\n\\n\", 'answer': 'Would be kinda neat if they were. I think I could outrun them. Maybe get my picture in the papers.', 'gold_tag': 'The TEENAGER is excited about the possibility of being chased and having his picture taken , The excitement suggests a desire for thrill or attention', 'last_speaker': 'TEENAGER'}\n",
      "Last word -> TEENAGER : \"Would be kinda neat if they were. I think I could outrun them. Maybe get my picture in the papers.\"\n",
      "prediction :  And what if he sees you?\n",
      "Real answer : Would be kinda neat if they were. I think I could outrun them. Maybe get my picture in the papers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8592360615730286], 'recall': [0.8588539361953735], 'f1': [0.8590449094772339], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307691, 'rouge2': 0.0, 'rougeL': 0.07692307692307691, 'rougeLsum': 0.07692307692307691}\n",
      "bleu 1/2 : 0.01616199464406751 0.0055986791750362004\n",
      "ppl : 141.38870239257812\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTEENAGER: I'm telling you, you're going to find him at the roadblock, or right after, or not at all.\\nJENNY: If he didn't want to go through the roadblock, is there any other way to get to Vegas?\\nTEENAGER: Fly. The five-fifty. We already passed it. But it'll take him way out of\\nJENNY: Pull over. I've got to get back there.\\nTEENAGER: Why wouldn't he want to go through the roadblock?... What did you guys do?... I won't tell anybody.\\n\\n\", 'answer': \"It's easier not to tell if you don't know.\", 'gold_tag': \"JENNY's actions suggest she's a decisive, quick-thinking person\", 'last_speaker': 'JENNY'}\n",
      "Last word -> JENNY : \"It's easier not to tell if you don't know.\"\n",
      "prediction :  What did I do? Go to a party.\n",
      "Real answer : It's easier not to tell if you don't know.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8725289106369019], 'recall': [0.8435108065605164], 'f1': [0.8577744960784912], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473685, 'rouge2': 0.0, 'rougeL': 0.10526315789473685, 'rougeLsum': 0.10526315789473685}\n",
      "bleu 1/2 : 0.11031211282307446 0.03729230060020541\n",
      "ppl : 57.127586364746094\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTEENAGER: Wait. Could I have your autograph?\\nJENNY: Sure.\\nTEENAGER: I have nothing to do. I'd like to help you.\\n\\n\", 'answer': \"Don't worry. I'll be all right.\", 'gold_tag': 'JENNY is confident and independent', 'last_speaker': 'JENNY'}\n",
      "Last word -> JENNY : \"Don't worry. I'll be all right.\"\n",
      "prediction :  Okay, what do you want to know?\n",
      "Real answer : Don't worry. I'll be all right.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8223022222518921], 'recall': [0.8526477813720703], 'f1': [0.8372001051902771], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.764127731323242\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBARBARA: The markings he's made on my father's arms are from the pollen of the tule plant. The twigs have no significance other than they've been struck by lightning and are consequently appeals to the spirit of lightning. It's all entirely harmless, a religious ceremony, not a medical one.\\nBOCK: You don't seriously believe all that mumbo-jumbo will cure him?\\nBARBARA: On the other hand, it won't kill him, Doctor.\\nBOCK: Okay. Go ahead.\\nBARBARA: Thank you.\\nBOCK: Miss Drummond, are you still taking your father out?\\nBARBARA: Yes. I still have to arrange an ambulance service. Is there a phone around I could use?\\nBOCK: Use my office.\\n\\n\", 'answer': 'Thank you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BARBARA'}\n",
      "Last word -> BARBARA : \"Thank you.\"\n",
      "prediction :  He's in the same room as your father. He doesn't have a chance.\n",
      "Real answer : Thank you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8504270315170288], 'recall': [0.8824731111526489], 'f1': [0.8661537766456604], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 17.29676055908203\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBARBARA: Hello. I'd like to arrange an ambulance for one-thirty tomorrow afternoon... Thank you... ...Drummond, first name, Barbara. I'll pay cash... No, you're to pick up my father, Drummond, Edward, at the Manhattan Medical Center, Holly Pavilion, Room Eight-O-Six. It's a stretcher case. I presume you provide the stretcher. He's to be taken to American Airlines, Yes... No... Kennedy Airport, Flight Seven-Two-Nine to Yuma, Arizona. I'll accompany the patient... Yes, thank you.\\nBOCK: You believe in witchcraft, Miss Drummond?\\nBARBARA: I believe in everything, Doctor.\\nBOCK: Like a drink?\\n\\n\", 'answer': 'Yes. My father, you should know, was a very successful doctor in Boston, a member of the Harvard Medical Faculty. He was a widower, and I was his only child. He was not an especially religious man, a sober Methodist. One evening, seven years ago, he attended a Pentecostal meeting in', 'gold_tag': \"BARBARA's father, Edward Drummond, was a successful doctor from Boston and a member of the Harvard Medical Faculty , BARBARA's father passed away seven years ago\", 'last_speaker': 'BARBARA'}\n",
      "Last word -> BARBARA : \"Yes. My father, you should know, was a very successful doctor in Boston, a member of the Harvard Medical Faculty. He was a widower, and I was his only child. He was not an especially religious man, a sober Methodist. One evening, seven years ago, he attended a Pentecostal meeting in\"\n",
      "prediction :  No. You mean a drink to wash the taste of something off the palate? No. Now, I have my own taste. That's what I'm talking about. For the last quarter hour or so I have not touched anything, a drink. But I have thought over and over about your suggestion.\n",
      "Real answer : Yes. My father, you should know, was a very successful doctor in Boston, a member of the Harvard Medical Faculty. He was a widower, and I was his only child. He was not an especially religious man, a sober Methodist. One evening, seven years ago, he attended a Pentecostal meeting in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8387515544891357], 'recall': [0.8284813761711121], 'f1': [0.8335847854614258], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1747572815533981, 'rouge2': 0.0, 'rougeL': 0.13592233009708737, 'rougeLsum': 0.13592233009708737}\n",
      "bleu 1/2 : 0.13722781426294575 0.01656838158448903\n",
      "ppl : 18.111154556274414\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOCK: What the hell am I supposed to say to that, Miss Drummond? I'm sitting here boozing and, all of a sudden, you start telling me some demented story about your father's religious conversion.\\nBARBARA: No, no, you miss the point, Doctor. Not my father's conversion -- mine. You see, I had been hitting the acid pretty regularly at that time. I had achieved a few minor sensory deformities, some suicidal despairs, but nothing as wild as fluency in an obscure Apache dialect. I mean, like wow, man! I mean, here was living afflatus right before my eyes! Within a week, my father had closed his Beacon Hill practice and set out to start a mission in the Mexican mountains. And I turned in my S.D.S. card and my crash helmet and followed him. It was a disaster, at least for me. My father had received the revelation, not I. He stood gaunt on a mountain slope and preached the apocalypse to solemnly amused Indians. I masturbated a great deal. We lived in a grass wickiup and ate raw rabbit and crushed pi�on nuts. It was hideous. Within two months, I was back in Boston, a hollow shell and dizzy with dengue, disenchanted with everything. I turned to austerity, nursing school. I became haggard, driven and had shamelessly incestuous dreams about my father. I took up with some of the senior staff at the hospital. One of them, a portly psychiatrist, explained I was generated by an unresolved lust for my father. I apparently cracked up. One day, they found me walking to work naked and screaming obscenities. There was talk of institutionalizing me, so I packed a bag and went back to my father in the Sierra Madre Mountains. I've been there ever since. That's three years. My father is, of course, mad as a hatter. I watch over him and have been curiously content. You see, Doctor, I believe in everything.\\nBOCK: Now what was that all about, Miss Drummond?\\nBARBARA: I thought I was obvious as hell. I'm trying to tell you I have a thing for middle-aged men.\\nBOCK: I admire your candor.\\nBARBARA: You've been admiring a lot more than that.\\nBOCK: You're wasting your time. I've been impotent for years.\\nBARBARA: Rubbish.\\n\\n\", 'answer': 'What the hell\\'s wrong with being impotent? My God, you kids are more hung up on sex than the Victorians! I\\'ve got a son, twenty-three. I threw him out of the house last year. Pietistic little humbug. He preached universal love and despised everyone. He had a blanket contempt for the middle class, even its decencies. He detested my mother because she had petit bourgeois pride in her son the doctor. I cannot tell you how brutishly he ignored that rather good old lady. When she died, he didn\\'t even come to the funeral. He thought the chapel service an hypocrisy. His generation didn\\'t live with lies, he told me. \"Everybody lives with lies,\" I said. I grabbed him by his poncho, dragged him the', 'gold_tag': \"BOCK has a son who he threw out of his house last year , BOCK does not appreciate his son's disregard for their family's middle-class values\", 'last_speaker': 'BOCK'}\n",
      "Last word -> BOCK : \"What the hell's wrong with being impotent? My God, you kids are more hung up on sex than the Victorians! I've got a son, twenty-three. I threw him out of the house last year. Pietistic little humbug. He preached universal love and despised everyone. He had a blanket contempt for the middle class, even its decencies. He detested my mother because she had petit bourgeois pride in her son the doctor. I cannot tell you how brutishly he ignored that rather good old lady. When she died, he didn't even come to the funeral. He thought the chapel service an hypocrisy. His generation didn't live with lies, he told me. \"Everybody lives with lies,\" I said. I grabbed him by his poncho, dragged him the\"\n",
      "prediction :  I'm trying to tell you, I can't do it. I'm a sick old man who's lost all his capacity and I've never really thought about the problem, and now I can't. I'm just saying -- I'm just trying to say --\n",
      "Real answer : What the hell's wrong with being impotent? My God, you kids are more hung up on sex than the Victorians! I've got a son, twenty-three. I threw him out of the house last year. Pietistic little humbug. He preached universal love and despised everyone. He had a blanket contempt for the middle class, even its decencies. He detested my mother because she had petit bourgeois pride in her son the doctor. I cannot tell you how brutishly he ignored that rather good old lady. When she died, he didn't even come to the funeral. He thought the chapel service an hypocrisy. His generation didn't live with lies, he told me. \"Everybody lives with lies,\" I said. I grabbed him by his poncho, dragged him the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8261052370071411], 'recall': [0.8104987740516663], 'f1': [0.8182275295257568], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20338983050847456, 'rouge2': 0.022857142857142854, 'rougeL': 0.11299435028248588, 'rougeLsum': 0.11299435028248588}\n",
      "bleu 1/2 : 0.034580778647185784 0.0033381078038883074\n",
      "ppl : 9.901971817016602\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBARBARA: Right on.\\nBOCK: When I say impotent, I don't mean merely limp. Disagreeable as it may be for a woman, a man may sometimes lust for other things, something less transient than an erection, some sense of permanent worth. That's what medicine was for me, my reason for being. When I was thirty-four, Miss Drummond, I presented a paper that pioneered the whole goddam field of immunology. A breakthrough! I'm in all the textbooks. I happen to be an eminent man, Miss Drummond. And you want to know something, Miss Drummond? I don't give a goddam. When I say I'm impotent, I mean I've lost even my desire for work, which is a hell of a lot more primal a passion than sex. I've lost my raison d'etre, my purpose, the only thing I ever truly loved. It's all rubbish anyway. Transplants, antibodies, we manufacture genes, we can produce birth ectogenetically, we can practically clone people like carrots, and half the kids in this ghetto haven't even been inoculated for polio! We have assembled the most enormous medical establishment ever conceived, and people are sicker than ever! We cure nothing! We heal nothing! The whole goddam wretched the hell I'm talking about, do you?\\nBARBARA: Of course, I do.\\nBOCK: I'm tired, I'm terribly tired, Miss Drummond. And I hurt, and I've got nothing going for me anymore. Can you understand that?\\nBARBARA: Yes, of course.\\nBOCK: Then can you understand that the\\nBARBARA: Sounds to me like a familiar case of morbid menopause.\\nBOCK: Oh Christ.\\nBARBARA: Well, it's hard for me to take your despair very seriously, Doctor. You obviously enjoy it so much.\\nBOCK: Oh, bugger off. That's all I need now, clinical insights. Some cockamamie twenty-five-year-old... ...acidhead's going to reassure me about menopause now. Look, I'd like to be alone, so why don't you beat it? Close the door and turn off the lights on your way out.\\nBARBARA: Mr. Blacktree disapproves of my miniskirt, but it was the only thing I had to come to the city with. Back at the tribe, I wear ankle-length buckskin.\\nBOCK: Swell. Just close the door and turn off the lights. What're you shooting, Doc? Leave me alone...\\nBARBARA: Potassium. You take enough of this stuff, it'll kill you, Doc. It occurred to me that I might have read you wrong, that you really were suicidal. So I came back.\\n\\n\", 'answer': \"Who the hell asked you! Who the hell asked you! Leave me alone! Why the hell don't you leave me alone! Why didn't you let me do it? Who the hell asked you!\", 'gold_tag': 'BOCK is experiencing a deep existential crisis , BOCK is in a poor state of health, both physically and mentally , BOCK expresses his current state of impotence, not only in the sexual sense but also regarding his passion for his work , BOCK seems to be deeply unhappy and possibly suicidal in his present state', 'last_speaker': 'BOCK'}\n",
      "Last word -> BOCK : \"Who the hell asked you! Who the hell asked you! Leave me alone! Why the hell don't you leave me alone! Why didn't you let me do it? Who the hell asked you!\"\n",
      "prediction :  I'm no doctor, only a technician for the public health service. I'm an engineer, but you don't seem to get that in the medical department. It's an office job. You never get to see a patient. You come into a clean room... ...everything's ready before you.\n",
      "Real answer : Who the hell asked you! Who the hell asked you! Leave me alone! Why the hell don't you leave me alone! Why didn't you let me do it? Who the hell asked you!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8363741636276245], 'recall': [0.8042628765106201], 'f1': [0.8200042843818665], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20930232558139533, 'rouge2': 0.023809523809523815, 'rougeL': 0.16279069767441862, 'rougeLsum': 0.16279069767441862}\n",
      "bleu 1/2 : 0.08695652173913045 0.013900960937138312\n",
      "ppl : 16.836292266845703\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOCK: You wouldn't be awake.\\nBARBARA: What time is it?\\nBOCK: I swiped this for you out of the nurses' locker room. I'll make good on your dress. I'm afraid it's torn beyond repair. Buy yourself a new one or, if you like, give me your size and I'll send it on to you. But I want to talk to you about that.\\nBARBARA: Talk to me about what?\\nBOCK: About your father. You really shouldn't move him in his condition. I just had a look at his chart. There's no reason to presume brain damage. You know as well as I you can't predict anything in these instances. He could pull out of that coma at any time. I think you should let him stay here. I'll personally look after him.\\nBARBARA: Is this your way of saying you'd like me to stay in town a few more days?\\nBOCK: Well, that would be nice, too. What do you say, Miss Drummond?\\nBARBARA: I expect you can call me Barbara, considering you ravished me three times last night.\\nBOCK: Three times?\\nBARBARA: Oh, look at him, pretending he didn't count. You were as puffed up as a toad about it. Punched a couple of holes in your crusade for universal impotence, didn't it? I think we're on a first name basis by now. I'll call you Herb.\\nBOCK: Let's give your father a week, Barbara, what do you say?\\n\\n\", 'answer': \"No, I don't want my father in this hospital. I had a dream about this hospital. I dreamt this enormous starched white tile building suddenly erupted like\", 'gold_tag': \"BARBARA's father is in a coma , BARBARA is in charge of her father's care , BARBARA's temporal information: BARBARA's father is currently in the hospital and in a coma, this information is likely to change in the future\", 'last_speaker': 'BARBARA'}\n",
      "Last word -> BARBARA : \"No, I don't want my father in this hospital. I had a dream about this hospital. I dreamt this enormous starched white tile building suddenly erupted like\"\n",
      "prediction :  No no no... I can't go this time.\n",
      "Real answer : No, I don't want my father in this hospital. I had a dream about this hospital. I dreamt this enormous starched white tile building suddenly erupted like\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8558470606803894], 'recall': [0.8316832184791565], 'f1': [0.8435921669006348], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.21621621621621623, 'rouge2': 0.05714285714285714, 'rougeL': 0.21621621621621623, 'rougeLsum': 0.21621621621621623}\n",
      "bleu 1/2 : 0.023253622302665873 0.005558678929360516\n",
      "ppl : 48.95146942138672\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOCK: Look, you're not going. I love you, and I'm not going to let you go. Come on, let's start putting your father's things back. He's staying here. I'll find an apartment somewhere. I'm staying in a filthy little hotel room. We can't use that.\\nBARBARA: I can't make it here, Herb. I'll crack up. I cracked up once already. One week here, and I'd be running naked through the streets screaming again. I can retain my sanity only\\nBOCK: For God's sake, Barbara, you can't seriously see me living in a grass shack hunting jackrabbits for dinner? Be sensible for God's sake.\\nBARBARA: I am being sensible. What is it you're so afraid of leaving here? Your plastic home? Your conditioned air? Your synthetic clothes? Your instant\\nBOCK: You make it sound almost plausible.\\nBARBARA: I don't know why you even hesitate. What's holding you here? Is it your wife?\\nBOCK: No, that's all over. I suppose if I'm married to anything, it's this hospital. It's been my whole life. I just can't walk out on it as if it never mattered. I'm middle-class. Among us middle-class, love doesn't triumph over all. Responsibility does.\\nBARBARA: Herb, don't ask me to stay here with you, because I love you, and I will. And we'll both be destroyed. I've got the bill here to pay yet.\\n\\n\", 'answer': \"I'll come with you.\", 'gold_tag': 'BOCK is considering accompanying BARBARA', 'last_speaker': 'BOCK'}\n",
      "Last word -> BOCK : \"I'll come with you.\"\n",
      "prediction :  The bill? Really! You're still alive?\n",
      "Real answer : I'll come with you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8235486745834351], 'recall': [0.8633490204811096], 'f1': [0.8429792523384094], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 243.73599243164062\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTAYA: Did you always want to be a soldier?\\nCHRIS: I wanted to be a cowboy-- but I did that and I felt like I was meant for more.\\nTAYA: So you started rescuing girls from bars?\\nCHRIS: I rescued that bar from you. Do you like country music?\\nTAYA: Only when I'm depressed.\\nCHRIS: You want kids?\\nTAYA: Someday. My mom says I have a nose for picking the wrong men.\\nCHRIS: That's a shitty thing to tell a girl.\\nTAYA: I've proven her right.\\nCHRIS: But those wrong picks put you here. They made you who you are. And I like who you are.\\nTAYA: What happens when there's a real person on the other end of that gun?\\n\\n\", 'answer': \"I don't know... I just pray I can do my job if that day comes.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'CHRIS'}\n",
      "Last word -> CHRIS : \"I don't know... I just pray I can do my job if that day comes.\"\n",
      "prediction :  If you can look in the mirror when you get home, you'll feel fine.\n",
      "Real answer : I don't know... I just pray I can do my job if that day comes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8667235970497131], 'recall': [0.843660831451416], 'f1': [0.855036735534668], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12903225806451615, 'rouge2': 0.0, 'rougeL': 0.06451612903225808, 'rougeLsum': 0.06451612903225808}\n",
      "bleu 1/2 : 0.06650448426457305 0.02182444817914707\n",
      "ppl : 20.66063690185547\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRIS: You're trembling...\\nTAYA: I know. I don't...\\nCHRIS: We don't have to do this...\\n\\n\", 'answer': 'I want to. I do...', 'gold_tag': 'Everyday Language', 'last_speaker': 'TAYA'}\n",
      "Last word -> TAYA : \"I want to. I do...\"\n",
      "prediction :  I need help.\n",
      "Real answer : I want to. I do...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9118825197219849], 'recall': [0.873160719871521], 'f1': [0.8921016454696655], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0.17113903967753066 0.06628186505570068\n",
      "ppl : 162.07302856445312\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTAYA: I thought you were dead. I thought--\\n\\n', 'answer': \"Shh. I'm know. I'm so sorry.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'CHRIS'}\n",
      "Last word -> CHRIS : \"Shh. I'm know. I'm so sorry.\"\n",
      "prediction :  You're right, you were. (1)\n",
      "Real answer : Shh. I'm know. I'm so sorry.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8394232988357544], 'recall': [0.840093731880188], 'f1': [0.8397583365440369], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 51.648128509521484\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRIS: You're the most beautiful thing I've ever seen.\\nTAYA: I have an alien growing inside me-- And there's a strange man in my bedroom.\\nCHRIS: Our bedroom.\\nTAYA: Why isn't it on your finger?\\nCHRIS: If it catches the light...\\nTAYA: Your hands feel different.\\nCHRIS: They're mine. I swear...\\nTAYA: Why am I so fucking nervous?\\nCHRIS: I'm nervous too.\\nTAYA: No you're not. Don't lie.\\nCHRIS: I am... What if that little alien reaches out and grabs me?\\n\\n\", 'answer': 'Why are you so good with me.', 'gold_tag': 'Everyday Language', 'last_speaker': 'TAYA'}\n",
      "Last word -> TAYA : \"Why are you so good with me.\"\n",
      "prediction :  Is that normal?\n",
      "Real answer : Why are you so good with me.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8447009325027466], 'recall': [0.8527421355247498], 'f1': [0.8487024903297424], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 466.6203308105469\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRIS: You sabotaged me back there.\\nTAYA: What am I supposed to do. You're not talking. You act like it's all okay--\\nCHRIS: It is okay. I'm fine.\\nTAYA: You're not fine. Your blood pressure--\\nCHRIS: Babe, I'm driving down the freeway, it's sunny and 72 degrees. I'm fine. But there are people dying over there and I look around and it's like it's not even happening. It's barely on the news, no one talks about it. No one cares. And if I stay too long I'll forget about it too.\\nTAYA: Chris--\\nCHRIS: We're at war and I'm headed to the mall. I don't belong here. I can't help anybody-\\nTAYA: --it's happening--\\nCHRIS: Oh shit--\\nTAYA: What're you doing!\\nCHRIS: I'm going back.\\n\\n\", 'answer': \"--oh my god, you're crazy! You're fucking crazy you know that?\", 'gold_tag': \"TAYA appears frustrated and scared by CHRIS's decision to go back to war\", 'last_speaker': 'TAYA'}\n",
      "Last word -> TAYA : \"--oh my god, you're crazy! You're fucking crazy you know that?\"\n",
      "prediction :  I have to go back to the office.\n",
      "Real answer : --oh my god, you're crazy! You're fucking crazy you know that?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8587255477905273], 'recall': [0.7990405559539795], 'f1': [0.8278086185455322], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 28.235713958740234\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTAYA: Marc wrote that letter two weeks ago. Did he say any of that to you? Chris? I want to know what you thought of his letter...\\n\\n', 'answer': \"An AQI informant called in a tip. Biggles had just been shot. We were operating off emotion and-- we walked into an ambush. But that's not what killed him. That letter did. That letter killed Marc. He let go and he paid the price for it. (03.18.14) 92.\", 'gold_tag': \"CHRIS works in a high-risk, high-stress environment , CHRIS deals with informants and dangerous situations like ambushes , CHRIS operates on emotion , CHRIS has an opinion that emotional vulnerability can cost lives, as in Marc's case , CHRIS's temporal information\", 'last_speaker': 'CHRIS'}\n",
      "Last word -> CHRIS : \"An AQI informant called in a tip. Biggles had just been shot. We were operating off emotion and-- we walked into an ambush. But that's not what killed him. That letter did. That letter killed Marc. He let go and he paid the price for it. (03.18.14) 92.\"\n",
      "prediction :  It's not very personal...\n",
      "Real answer : An AQI informant called in a tip. Biggles had just been shot. We were operating off emotion and-- we walked into an ambush. But that's not what killed him. That letter did. That letter killed Marc. He let go and he paid the price for it. (03.18.14) 92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8206607103347778], 'recall': [0.8090745210647583], 'f1': [0.8148264288902283], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10714285714285714, 'rouge2': 0.037037037037037035, 'rougeL': 0.07142857142857142, 'rougeLsum': 0.07142857142857142}\n",
      "bleu 1/2 : 4.175425197561415e-06 1.5246497119199013e-06\n",
      "ppl : 110.36531829833984\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRIS: If something ever happened to me-- you'd meet someone else. You'd be alright.\\nTAYA: Do you want to die? Is that what it is?\\nCHRIS: No.\\nTAYA: Then tell me why do you do it. I want to understand.\\nCHRIS: I do it for you. To protect you.\\nTAYA: No you don't. I'm here. Your family is here. Your children have no father--\\nCHRIS: Without this, there's nothing.\\nTAYA: Bullshit. It's not about us anymore. You don't know when to quit. It's over- You did your part! We sacrificed enough. Let somebody else go--\\nCHRIS: I could never live with myself.\\nTAYA: You find a way! You have to. I need you to be human again. I need you here. If you leave again, we might not be here when you get back.\\n\\n\", 'answer': 'I know.', 'gold_tag': 'CHRIS is in a state of conflict about a potentially dangerous, upcoming deployment or mission', 'last_speaker': 'CHRIS'}\n",
      "Last word -> CHRIS : \"I know.\"\n",
      "prediction :  I have one more question. Are you okay with me getting out one more time?\n",
      "Real answer : I know.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8199144601821899], 'recall': [0.8709633350372314], 'f1': [0.8446683287620544], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.06666666666666667 0.02182178902359924\n",
      "ppl : 26.687694549560547\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEVAN: Are you okay?\\n\\n', 'answer': \"There it is. Let's go.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'TOMMY'}\n",
      "Last word -> TOMMY : \"There it is. Let's go.\"\n",
      "prediction :  Yes .\n",
      "Real answer : There it is. Let's go.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8235659599304199], 'recall': [0.8679409027099609], 'f1': [0.845171332359314], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24911.173828125\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEVAN: Crockett!!\\nTOMMY: Look what you made me do!\\nEVAN: What's wrong with you?! Kayleigh! Wake up!\\n\\n\", 'answer': \"Why don't you fucking kiss her, Prince Charming!\", 'gold_tag': 'TOMMY is aggressive', 'last_speaker': 'TOMMY'}\n",
      "Last word -> TOMMY : \"Why don't you fucking kiss her, Prince Charming!\"\n",
      "prediction :  I need you! I need your love, I need you! Give me a kiss! I need it now!\n",
      "Real answer : Why don't you fucking kiss her, Prince Charming!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8541362285614014], 'recall': [0.8332548141479492], 'f1': [0.843566358089447], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14814814814814814, 'rouge2': 0.0, 'rougeL': 0.14814814814814814, 'rougeLsum': 0.14814814814814814}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13.781238555908203\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOMMY: Listen to me good, Evan...\\n\\n', 'answer': \"I'll do whatever you want. You don't want me to ever see Kayleigh again, fine. Just let Crockett go. Besides, you kill him now and they'll stick you in juvy for sure. And I know you'd never leave your sister alone with your father. Oh fuck, Lenny, no!\", 'gold_tag': \"EVAN is willing to compromise and cares about people, expressing concern for Crockett and Lenny , EVAN has knowledge or understanding of his rights and the legal implications of Tommy's actions , EVAN knows about Tommy's family situation , EVAN and TOMMY share a troubling familiarity with TOMMY's home life\", 'last_speaker': 'EVAN'}\n",
      "Last word -> EVAN : \"I'll do whatever you want. You don't want me to ever see Kayleigh again, fine. Just let Crockett go. Besides, you kill him now and they'll stick you in juvy for sure. And I know you'd never leave your sister alone with your father. Oh fuck, Lenny, no!\"\n",
      "prediction :  You want to hurt my boy?\n",
      "Real answer : I'll do whatever you want. You don't want me to ever see Kayleigh again, fine. Just let Crockett go. Besides, you kill him now and they'll stick you in juvy for sure. And I know you'd never leave your sister alone with your father. Oh fuck, Lenny, no!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8504585027694702], 'recall': [0.8178673386573792], 'f1': [0.8338445425033569], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10344827586206896, 'rouge2': 0.03571428571428571, 'rougeL': 0.10344827586206896, 'rougeLsum': 0.10344827586206896}\n",
      "bleu 1/2 : 0.0004559409827772581 9.118819655545164e-05\n",
      "ppl : 306.1737060546875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOMMY: You forgot to put the toaster on the edge.\\nEVAN: But you, Kayleigh and Lenny like toast. And that's really all that matters now.\\n\\n\", 'answer': \"I'll get you changed. Visiting hours are almost up.\", 'gold_tag': 'TOMMY indicates that visiting hours are almost up', 'last_speaker': 'TOMMY'}\n",
      "Last word -> TOMMY : \"I'll get you changed. Visiting hours are almost up.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction : \n",
      "Real answer : I'll get you changed. Visiting hours are almost up.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.0], 'recall': [0.0], 'f1': [0.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : nan\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSALIERI: Herr Mozart, what brings you here?\\nMOZART: Your Excellency, you requested some specimens of my work. Here they are. I don't have to tell you how much I need your help. I truly appreciate your looking at these. I have pressures on me - financial pressures. As you know, I'm a married man now.\\nSALIERI: So you are. How is your pretty wife?\\nMOZART: She is well. She is - well, actually, I'm about to become a father! She only told me last night. You are the first to know.\\nSALIERI: I'm flattered. And congratulations to you, of course.\\nMOZART: So you see, this post is very important to me right now.\\nSALIERI: Why didn't you come to me yesterday, Mozart? This is a most painful situation. Yesterday I could have helped you. Today, I can't.\\nMOZART: Why? Here is the music. It's here. I am submitting it humbly. Isn't that what you wanted?\\nSALIERI: I have just come from the palace. The post has been filled.\\nMOZART: Filled? That's impossible! They haven't even seen my work. I need this post. Please, can't you help me? Please!\\nSALIERI: My dear Mozart, there is no one in the world I would rather help, but now it is too late.\\nMOZART: Whom did they choose?\\nSALIERI: Herr Sommer.\\nMOZART: Sommer? Herr Sommer? But the man's a fool! He's a total mediocrity.\\nSALIERI: No, no, no: he has yet to achieve\\nMOZART: But I can't lose this post, I simply can't! Excellency, please. Let's go to the palace, and you can explain to the Emperor that Herr Sommer is an awful choice. He could actually do musical harm to the Princess!\\nSALIERI: An implausible idea. Between you and me, no one in the world could do musical harm to the Princess Elizabeth.\\nMOZART: Look, I must have pupils. Without pupils I can't manage.\\nSALIERI: You don't mean to tell me you are living in poverty?\\nMOZART: No, but I'm broke. I'm always broke. I don't know why.\\nSALIERI: It has been said, my friend, that you are inclined to live somewhat above your means.\\nMOZART: How can anyone say that? We have no cook, no maid. We have no footman. Nothing at all!\\nSALIERI: How is that possible? You give concerts, don't you? I hear they are quite successful.\\nMOZART: They're stupendously successful. You can't get a seat. The only problem is none will hire me. They all want to hear me play, but they won't let me teach their daughters. As if I was some kind of fiend. I'm not a fiend!\\nSALIERI: Of course not.\\nMOZART: Do you have a daughter?\\nSALIERI: I'm afraid not.\\nMOZART: Well, could you lend me some money till you have one? Then I'll teach her for free. That's a promise. Oh, I'm sorry. I'm being silly. Papa's right - I should put a padlock on my mouth. Seriously, is there any chance you could manage a loan? Only for six months, eight at most. After that I'll be the richest man in Vienna. I'll pay you back double. Anything. Name your terms. I'm not joking. I'm working on something that's going to explode like a bomb all over Europe!\\nSALIERI: Ah, how exciting! Tell me more.\\nMOZART: I'd better not. It's a bit of a secret.\\nSALIERI: Come, come, Mozart; I'm interested. Truly.\\nMOZART: Actually, it's a big secret. Oh, this is delicious! What is it?\\nSALIERI: Cream cheese mixed with granulated al Mascarpone.\\nMOZART: Ah. Italian?\\nSALIERI: Forgive me. We all have patriotic feelings of some kind.\\nMOZART: Two thousand, two hundred florins is all I need A hundred? Fifty?\\nSALIERI: What exactly are you working on?\\nMOZART: I can't say. Really\\n\\n\", 'answer': \"I don't think you should become known in Vienna as a debtor, Mozart. However, I know a very distinguished gentleman I could recommend to you. And he has a daughter. Will that do?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SALIERI'}\n",
      "Last word -> SALIERI : \"I don't think you should become known in Vienna as a debtor, Mozart. However, I know a very distinguished gentleman I could recommend to you. And he has a daughter. Will that do?\"\n",
      "prediction :  Yes, yes. You have to try to wait a bit, you know. It's not so easy to give away two thousand florins like that. You've always been a great believer in saving.\n",
      "Real answer : I don't think you should become known in Vienna as a debtor, Mozart. However, I know a very distinguished gentleman I could recommend to you. And he has a daughter. Will that do?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.85019850730896], 'recall': [0.8486620783805847], 'f1': [0.8494295477867126], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23529411764705882, 'rouge2': 0.0, 'rougeL': 0.17647058823529413, 'rougeLsum': 0.17647058823529413}\n",
      "bleu 1/2 : 0.15144269288692877 0.02175992847656396\n",
      "ppl : 23.021793365478516\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOZART: Nine performances! Nine! That's all it's had - and withdrawn.\\nSALIERI: I know; it's outrageous. Still, if the public doesn't like one's work one has to accept the fact gracefully.\\nMOZART: But what is it they don't like?\\nSALIERI: Well, I can speak for the Emperor. You made too many demands on the royal ear. The poor man can't concentrate for more than an hour and you gave him four.\\nMOZART: What did you think of it yourself? Did you like it at all?\\nSALIERI: I think it's marvelous. Truly.\\nMOZART: It's the best opera yet written. I know it! Why didn't they come?\\nSALIERI: I think you overestimate our dear Viennese, my friend. Do you know you didn't even give them a good bang at the end of songs so they knew when to clap?\\nMOZART: I know, I know. Perhaps you should give me some lessons in that.\\nSALIERI: I wouldn't presume. All the same, if it wouldn't be imposing, I would like you to see my new piece. It would be a tremendous honour for me.\\nMOZART: Oh no, the honour would be all mine.\\nSALIERI: Grazie, mio caro, Wolfgang!\\n\\n\", 'answer': 'Grazie, a lei, Signor Antonio!', 'gold_tag': 'Everyday Language', 'last_speaker': 'MOZART'}\n",
      "Last word -> MOZART : \"Grazie, a lei, Signor Antonio!\"\n",
      "prediction :  The more there is the more there is to destroy.\n",
      "Real answer : Grazie, a lei, Signor Antonio!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8207274079322815], 'recall': [0.7747199535369873], 'f1': [0.7970603704452515], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 30.863086700439453\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOZART: What happened? Is it over?\\nSALIERI: I'm taking you home. You're not well.\\n\\n\", 'answer': 'No, no. I have to get back. I have -', 'gold_tag': 'MOZART has some health issues , MOZART has an immediate need or obligation to fulfill', 'last_speaker': 'MOZART'}\n",
      "Last word -> MOZART : \"No, no. I have to get back. I have -\"\n",
      "prediction :  Why didn't you tell me?\n",
      "Real answer : No, no. I have to get back. I have -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8235921859741211], 'recall': [0.8307212591171265], 'f1': [0.8271414041519165], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 31.980308532714844\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSALIERI: Thank you. Go.\\nMOZART: Papa! Papa!\\nSALIERI: Come now. Where is your wife?\\nMOZART: Not here! She's not well, either. She went to the Spa.\\nSALIERI: You mean she's not coming back?\\nMOZART: You're so good to me. Truly. Thank you.\\nSALIERI: No, please.\\nMOZART: I mean to come to my opera. You are the only colleague who did.\\nSALIERI: I would never miss anything that you had written. You must know that.\\nMOZART: This is only a vaudeville.\\nSALIERI: Oh no. It is a sublime piece. The grandest operone. I tell you, you are the greatest composer known to me.\\nMOZART: Do you mean that?\\nSALIERI: I do.\\nMOZART: I have bad fancies. I don't sleep well anymore. Then I drink too much, and think stupid things.\\nSALIERI: Are you ill?\\nMOZART: The doctor thinks I am. But -\\nSALIERI: What?\\nMOZART: I'm too young to be so sick.\\nSALIERI: Shall I answer it?\\nMOZART: No! No, it's him!\\nSALIERI: Who?\\nMOZART: The man. He's here.\\nSALIERI: What man?\\nMOZART: Tell him to go away. Tell him I'm still working on it. Don't let him in! Wait! Ask him if he'd give me some money now. Tell him if he would, that would help me finish it.\\nSALIERI: Finish what?\\n\\n\", 'answer': 'He knows. He knows!', 'gold_tag': 'Everyday Language', 'last_speaker': 'MOZART'}\n",
      "Last word -> MOZART : \"He knows. He knows!\"\n",
      "prediction :  Oh yes please. Please. I want him to go away.\n",
      "Real answer : He knows. He knows!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8779098391532898], 'recall': [0.8841716647148132], 'f1': [0.8810296058654785], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 64.15898132324219\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOZART: What happened?\\nSALIERI: He said to give you this. And if you finish the work by tomorrow night, he will pay you another hundred ducats.\\nMOZART: Another? But that's too soon! Tomorrow night? It's impossible! Did he say a hundred?\\nSALIERI: Yes. Can I - could I help you, in any way?\\nMOZART: Would you? Actually, you could.\\nSALIERI: My dear friend, it would be my greatest pleasure.\\nMOZART: But you'd have to swear not to tell a soul. I'm not allowed.\\nSALIERI: Of course.\\nMOZART: You know, it's all here in my head. It's just ready to be set down. But when I'm dizzy like this my eyes won't focus. I can't write.\\nSALIERI: Then, let us try together. I'd regard it as such an honour. Tell me, what is this work?\\n\\n\", 'answer': 'A Mass. A Mass for the Dead.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MOZART'}\n",
      "Last word -> MOZART : \"A Mass. A Mass for the Dead.\"\n",
      "prediction :  I have to finish this book! He won't have to pay.\n",
      "Real answer : A Mass. A Mass for the Dead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8508832454681396], 'recall': [0.8880273699760437], 'f1': [0.8690585494041443], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 45.49403381347656\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOZART: Do you want to rest a bit?\\nSALIERI: Oh no. I'm not tired at all.\\nMOZART: We'll stop for just a moment. Then we'll do the Lacrimosa.\\nSALIERI: I can keep going, I assure you. Shall we try?\\nMOZART: Would you stay with me while I sleep a little?\\nSALIERI: I'm not leaving you.\\nMOZART: I am so ashamed.\\nSALIERI: What for?\\n\\n\", 'answer': 'I was foolish. I thought you did not care for my work - or me. Forgive me. Forgive me!', 'gold_tag': \"MOZART believes he has been foolish for assuming Salieri didn't care for his work or him\", 'last_speaker': 'MOZART'}\n",
      "Last word -> MOZART : \"I was foolish. I thought you did not care for my work - or me. Forgive me. Forgive me!\"\n",
      "prediction :  Do you intend to give me a concert with no music?\n",
      "Real answer : I was foolish. I thought you did not care for my work - or me. Forgive me. Forgive me!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8657150864601135], 'recall': [0.8544521331787109], 'f1': [0.8600468039512634], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13793103448275862, 'rouge2': 0.0, 'rougeL': 0.13793103448275862, 'rougeLsum': 0.13793103448275862}\n",
      "bleu 1/2 : 0.04392955283543867 0.014569784396324328\n",
      "ppl : 81.90863800048828\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: I've decided it's impossible to properly say hello in this place\\nTOM: A jogger, huh?\\nANNIE: I don't jog, Mr. Booker. I run.\\nTOM: Lucky for you. The grizzlies around here only go for joggers.\\nANNIE: If I can survive rush hour, I figure I can handle grizzlies...\\nTOM: You sleeping all right in that house?\\nANNIE: I don't sleep all right anywhere. But the house is fine. Who's R.B.?\\nTOM: Sorry about that. I thought everything got cleared out. R.B. is my wife... ex-wife... Rachel. We used to live in that house together.\\nANNIE: I thought you lived in Chicago?\\nTOM: I thought you were an editor, not a reporter?\\nANNIE: I have a way with animals.\\nTOM: It's all right. He's young. Just hold out your hand a little lower so he can get the smell of you.\\nANNIE: Oh yes. I forgot. He's beautiful.\\nTOM: Why don't you ride anymore? Grace told me you used to ride when she was younger.\\nANNIE: She did? I don't know, really. No time mostly. I thought it was supposed to be spring. Are you shy, Mr. Booker?\\nTOM: Just polite. Well, maybe you'd like to try riding again, some time before you go home. Enjoy the day.\\nANNIE: You too. Shit.\\nTOM: Need a lift?\\n\\n\", 'answer': 'I can handle it!', 'gold_tag': 'Everyday Language', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"I can handle it!\"\n",
      "prediction :  What?\n",
      "Real answer : I can handle it!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8853646516799927], 'recall': [0.8228732347488403], 'f1': [0.8529759049415588], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5475.181640625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: Oh-oh. The answer's no.\\nTOM: You haven't heard the question yet. Truth is, you'd be doing me a favor. I got all these eager young colts need riding and poor old Rimrock here is feeling kind of left out...\\nANNIE: Poor thing.\\nTOM: He'd be grateful, he'd take real good care with you.\\nANNIE: Is this how you're going to make me pay my phone bill?\\n\\n\", 'answer': \"No, ma'am, I'm afraid that's extra.\", 'gold_tag': 'TOM may be the man in charge of a ranch or similar establishment', 'last_speaker': 'TOM'}\n",
      "Last word -> TOM : \"No, ma'am, I'm afraid that's extra.\"\n",
      "prediction :  I just put a few more miles on the Roadmaster and I'm off. You ready for this?\n",
      "Real answer : No, ma'am, I'm afraid that's extra.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8329216241836548], 'recall': [0.8108799457550049], 'f1': [0.8217529654502869], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14814814814814814, 'rouge2': 0.07999999999999999, 'rougeL': 0.14814814814814814, 'rougeLsum': 0.14814814814814814}\n",
      "bleu 1/2 : 0.0588235294117647 0.019174124721184262\n",
      "ppl : 32.719940185546875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOM: Relax our center... It's just sitting in a bucket.\\nANNIE: Yeah, it's been a while, but I... I remember the basic ideas...\\nTOM: OK. I'll stop talking then.\\nANNIE: Actually, I never rode Western. I'm sorry. Go ahead.\\nTOM: Well, he don't know that. Just sit the horse. Good... You have a nice seat.\\nANNIE: Thanks.\\nTOM: Feel good?\\nANNIE: Yeah.\\nTOM: You look all right. You want to pick it up a little?\\nANNIE: OK.\\n\\n\", 'answer': \"Watch your reins, he'll go with you, give him some room, let him do the work. Relax, don't grab him with your thighs, just so long as he can feel your body. You want to let it go some more?\", 'gold_tag': 'TOM guides ANNIE through horse riding', 'last_speaker': 'TOM'}\n",
      "Last word -> TOM : \"Watch your reins, he'll go with you, give him some room, let him do the work. Relax, don't grab him with your thighs, just so long as he can feel your body. You want to let it go some more?\"\n",
      "prediction :  I see. I mean, I've met people like you who do it for...\n",
      "Real answer : Watch your reins, he'll go with you, give him some room, let him do the work. Relax, don't grab him with your thighs, just so long as he can feel your body. You want to let it go some more?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8304891586303711], 'recall': [0.8292593359947205], 'f1': [0.82987380027771], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10714285714285714, 'rouge2': 0.0, 'rougeL': 0.10714285714285714, 'rougeLsum': 0.10714285714285714}\n",
      "bleu 1/2 : 0.01927926228371342 0.004487004106609252\n",
      "ppl : 30.07366371154785\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: It's a whole other world you have going on here. It just goes along, doing what it has to. And you're a part of it, you just wake up and, and there you are... And everything that seems like life or death some place else -- doesn't affect any of this one bit.\\nTOM: Lift your leg.\\nANNIE: How long did you live here with your wife?\\nTOM: Five years. My son was born here.\\nANNIE: Son?\\nTOM: Yeah. I haven't seen him in a while. He used to come to the ranch over summers, but then he started having friends and was going off to college, so... Good boy.\\nANNIE: How did you meet her?\\nTOM: College. In Illinois. She was playing the cello. I hadn't heard cello music growing up. She had the reddest hair, the bluest eyes. When she played, it was... She was the most beautiful thing I'd ever seen.\\nANNIE: Why didn't it work out?\\nTOM: She was never really happy here. She did the best she could. Grace told me you have a country house in Connecticut. Sounds like a beautiful place.\\nANNIE: It is. It's lovely.\\nTOM: Ever think of moving there full time?\\nANNIE: We did at one point. When we thought we'd have more children. And we after tried. We tried everything, but... wasn't meant to be.\\nTOM: I hear that! See, I knew she was never going to be a ranchest, but I wanted to try -- I thought maybe she'd give music lessons to the kids in town or at the school, maybe even recitals. My son would grow up here. Maybe have one or two more. I'd teach 'em what I could. They'd play with my brother's kids. All grow up together. And even if they all decided to go out into the world, they'd always know where home was -- cause we'd keep it for 'em...\\nANNIE: That's very important to you, isn't it? Home.\\nTOM: Yeah, I think it is. And I don't mean everybody's got to be married, have kids -- It's more like, knowing where you're from, where you belong, what feeds you, where you can go no matter what happens... Knowing what you're supposed to be doing while you're here.\\nANNIE: How did you find out all that?\\n\\n\", 'answer': 'I got lost.', 'gold_tag': 'Everyday Language', 'last_speaker': 'TOM'}\n",
      "Last word -> TOM : \"I got lost.\"\n",
      "prediction :  I used to get into books and read. I'd learn things I never thought I'd know, things like how to love, and do good, what the difference is between giving and taking... about being good, and being yourself. Things about the world and why it works, and why it so hard to get through that. There wasn't anything I was expecting once I started putting it all together. This world, no one really knows what's in store for them until they\n",
      "Real answer : I got lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8000457286834717], 'recall': [0.899368405342102], 'f1': [0.8468045592308044], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.022727272727272728, 'rouge2': 0.0, 'rougeL': 0.022727272727272728, 'rougeLsum': 0.022727272727272728}\n",
      "bleu 1/2 : 0.012345679012345675 0.00392837100659193\n",
      "ppl : 16.133989334106445\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOM: Everything under control?\\nANNIE: Not really. I'd forgotten how long it's been since I've done this. And I couldn't get any Parmesan cheese.\\nTOM: Just make yourself comfortable.\\nANNIE: I am comfortable.\\nTOM: Ha, ha... all right, well, uh I guess you can bring out the pasta.\\nANNIE: You missed a button.\\nTOM: Huh?\\n\\n\", 'answer': \"Thank you. Oh, good, Grace, would you bring in the bread... I'll get the salad and then we're all set.\", 'gold_tag': 'ANNIE is capable of organizing a meal', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"Thank you. Oh, good, Grace, would you bring in the bread... I'll get the salad and then we're all set.\"\n",
      "prediction :  It's all there.\n",
      "Real answer : Thank you. Oh, good, Grace, would you bring in the bread... I'll get the salad and then we're all set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8673418760299683], 'recall': [0.8173394203186035], 'f1': [0.841598629951477], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307693, 'rouge2': 0.0, 'rougeL': 0.07692307692307693, 'rougeLsum': 0.07692307692307693}\n",
      "bleu 1/2 : 0.001153125778821586 0.0004466036937458461\n",
      "ppl : 53.76933670043945\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOM: I won't apologize for this. And I won't hide it. Not for anybody.\\n\\n\", 'answer': \"I won't ask you to.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"I won't ask you to.\"\n",
      "prediction :  Why would you want to apologize?\n",
      "Real answer : I won't ask you to.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8342167139053345], 'recall': [0.8641793727874756], 'f1': [0.848933756351471], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.0, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0.16666666666666669 0.05773502691896258\n",
      "ppl : 109.828369140625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: Oh, God, what are we going to do? I'm supposed to --\\n\\n\", 'answer': \"Ssshhh... Stand still, Annie. Takes what we've got, just for now. Can you do that?\", 'gold_tag': 'TOM is calm and comforting , TOM is trying to reassure ANNIE in the middle of a crisis', 'last_speaker': 'TOM'}\n",
      "Last word -> TOM : \"Ssshhh... Stand still, Annie. Takes what we've got, just for now. Can you do that?\"\n",
      "prediction :  I can see it now- you can't work out why it's happening can you?, it just seems to have a way of coming at you through the same exact door every day on the same exact day. And if this is true, then the same thing could happen tomorrow, right?\n",
      "Real answer : Ssshhh... Stand still, Annie. Takes what we've got, just for now. Can you do that?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8116825819015503], 'recall': [0.8203054070472717], 'f1': [0.8159711956977844], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0303030303030303, 'rougeL': 0.08823529411764705, 'rougeLsum': 0.08823529411764705}\n",
      "bleu 1/2 : 0.04000000000000001 0.009035079029052514\n",
      "ppl : 17.181310653686523\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: Show me again.\\nTOM: Annie!\\n\\n', 'answer': 'One more time.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"One more time.\"\n",
      "prediction :  What was that about I had to pay you back?\n",
      "Real answer : One more time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8135000467300415], 'recall': [0.8648873567581177], 'f1': [0.838407039642334], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 67.80653381347656\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOM: I figured, whenever you decided to go, you'd be all set.\\nANNIE: How thoughtful of you. And what if I decide not to go? Leave me alone!\\nTOM: Annie, please...\\nANNIE: NO!... NO!... YOU DON'T DECIDE THIS!... NO!...\\nTOM: I don't know any other way, Annie.\\nANNIE: Why?\\nTOM: You think this is easy for me!? It's just happened this way sometimes. I can't explain it. But I look at you and see Grace and I see Robert, and no matter what you decide about him, I just know this is right. Your life isn't here and you know it.\\nANNIE: Then what have we been doing? I mean what was the point?\\nTOM: The point was to love each other.\\nANNIE: Why?\\n\\n\", 'answer': \"Because we had to... And I'll never stop loving you, Annie. Here. Where my life is. Annie...\", 'gold_tag': 'TOM is in a romantic relationship with ANNIE , TOM cares for ANNIE deeply and is willing to respect her decisions even when they cause him distress', 'last_speaker': 'TOM'}\n",
      "Last word -> TOM : \"Because we had to... And I'll never stop loving you, Annie. Here. Where my life is. Annie...\"\n",
      "prediction :  I know. I just knew you needed me. No matter how hard life gets, there will always be somebody you love who loves you unconditionally. And if that doesn't matter to you, who could understand or ever care about you?\n",
      "Real answer : Because we had to... And I'll never stop loving you, Annie. Here. Where my life is. Annie...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8503916263580322], 'recall': [0.8694138526916504], 'f1': [0.8597975373268127], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16949152542372883, 'rouge2': 0.0, 'rougeL': 0.1016949152542373, 'rougeLsum': 0.1016949152542373}\n",
      "bleu 1/2 : 0.075 0.013867504905630728\n",
      "ppl : 15.652286529541016\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOM: Annie?\\nANNIE: Can we go for one more ride?\\n\\n', 'answer': \"Sure. I'll saddle them up.\", 'gold_tag': 'TOM is capable of saddling horses , TOM is experienced with horse riding', 'last_speaker': 'TOM'}\n",
      "Last word -> TOM : \"Sure. I'll saddle them up.\"\n",
      "prediction :  What's going on? Annie, where are you?\n",
      "Real answer : Sure. I'll saddle them up.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8554632663726807], 'recall': [0.881721019744873], 'f1': [0.8683937191963196], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.156024932861328\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOM: What?\\nANNIE: I mean, why did you get\\nTOM: I got married because Betsy said we had to break up or get\\nANNIE: But when you met her, did you believe she was the only person for you? That in some mystical, I don't even know him. But say something, but\\nTOM: Yes, I did.\\n\\n\", 'answer': 'Thank you, Tom. I feel so much', 'gold_tag': 'ANNIE shows sensitivity', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"Thank you, Tom. I feel so much\"\n",
      "prediction :  Why don't you trust me? You're on cloud nine with that girl, right? I mean, she's good. Maybe you're just in love.\n",
      "Real answer : Thank you, Tom. I feel so much\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8346832394599915], 'recall': [0.8435885906219482], 'f1': [0.8391123414039612], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12121212121212123, 'rouge2': 0.0, 'rougeL': 0.12121212121212123, 'rougeLsum': 0.12121212121212123}\n",
      "bleu 1/2 : 0.04545454545454546 0.014712247158412498\n",
      "ppl : 12.149164199829102\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBENNY: Get your glove, c'mon.\\nSCOTTY: What's the big deal?\\n\\n\", 'answer': 'Nightgame!', 'gold_tag': 'Everyday Language', 'last_speaker': 'BENNY'}\n",
      "Last word -> BENNY : \"Nightgame!\"\n",
      "prediction :  Take it easy, it's not that serious.\n",
      "Real answer : Nightgame!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8089374303817749], 'recall': [0.8254337310791016], 'f1': [0.817102313041687], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 19.538787841796875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSCOTTY: Benny - wait. It's okay, it was my fault. I'll just take whatever I get. You don't have to do this.\\n\\n\", 'answer': \"Yeah I do, Smalls. I have to. ...Follow your heart, kid, and you'll never go wrong.\", 'gold_tag': \"Benny shows responsibility and leadership , Benny understands the importance of following one's heart , Benny inculcates a sense of wisdom and maturity\", 'last_speaker': 'BENNY'}\n",
      "Last word -> BENNY : \"Yeah I do, Smalls. I have to. ...Follow your heart, kid, and you'll never go wrong.\"\n",
      "prediction :  What do you think, Scott? Will the police need a warrant to get my fingerprints anyway?\n",
      "Real answer : Yeah I do, Smalls. I have to. ...Follow your heart, kid, and you'll never go wrong.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8490782976150513], 'recall': [0.8433539867401123], 'f1': [0.8462064862251282], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1818181818181818, 'rouge2': 0.0, 'rougeL': 0.12121212121212122, 'rougeLsum': 0.12121212121212122}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 48.666011810302734\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBENNY: OOOOH SSSSHIT!\\n\\n', 'answer': \"What're we waitin' for?! Let's go after 'em!\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SCOTTY'}\n",
      "Last word -> SCOTTY : \"What're we waitin' for?! Let's go after 'em!\"\n",
      "prediction :  Hey, what's going on?\n",
      "Real answer : What're we waitin' for?! Let's go after 'em!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8720171451568604], 'recall': [0.8289543390274048], 'f1': [0.8499406576156616], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.26666666666666666, 'rouge2': 0.0, 'rougeL': 0.26666666666666666, 'rougeLsum': 0.26666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.893192291259766\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSANTEN: What the hell's going on?\\nBOWMAN: Single event upsets. All over the board. Latch up. Free flow... We're gonna lose chips. Shut it down!\\nSANTEN: Shut it down?\\n\\n\", 'answer': \"Now! Everything! SEP, some kind of massive solar flare. Santen's shutting off every system he can get his hands... Proton flux. Multiple event upsets...\", 'gold_tag': 'BOWMAN indicates an immediate crisis , SANTEN is also involved in this immediate crisis', 'last_speaker': 'BOWMAN'}\n",
      "Last word -> BOWMAN : \"Now! Everything! SEP, some kind of massive solar flare. Santen's shutting off every system he can get his hands... Proton flux. Multiple event upsets...\"\n",
      "prediction :  You gotta listen to my side. I'll be there.\n",
      "Real answer : Now! Everything! SEP, some kind of massive solar flare. Santen's shutting off every system he can get his hands... Proton flux. Multiple event upsets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8523086309432983], 'recall': [0.8081971406936646], 'f1': [0.8296669721603394], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 52.606998443603516\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOWMAN: Radiation alert. Safe area. Go. You, too.\\nSANTEN: You need me here on the flight deck.\\n\\n', 'answer': 'I want one of us in charge back there.', 'gold_tag': 'BOWMAN has a position of authority , SANTEN is a subordinate to BOWMAN', 'last_speaker': 'BOWMAN'}\n",
      "Last word -> BOWMAN : \"I want one of us in charge back there.\"\n",
      "prediction :  We'll have to wait. You'll make it?\n",
      "Real answer : I want one of us in charge back there.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.845815896987915], 'recall': [0.869713306427002], 'f1': [0.8575981259346008], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 40.53257369995117\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSANTEN: Copy. We're okay, but the ship's hit bad.\\n\\n\", 'answer': \"... We're dead in the water... I can't run damage assessment. She's together now, but she might come apart at any moment. Change of plans. We're launching now. Suit up.\", 'gold_tag': \"BOWMAN is in charge and demonstrates leadership and decision-making skills , BOWMAN has knowledge in assessing damage and the state of the ship  , BOWMAN's occupation is related to spaceship operations , BOWMAN indicates a change of plans and an immediate launch, implying a situation that requires swift action and departure\", 'last_speaker': 'BOWMAN'}\n",
      "Last word -> BOWMAN : \"... We're dead in the water... I can't run damage assessment. She's together now, but she might come apart at any moment. Change of plans. We're launching now. Suit up.\"\n",
      "prediction :  Are you sure? The ship was okay before.\n",
      "Real answer : ... We're dead in the water... I can't run damage assessment. She's together now, but she might come apart at any moment. Change of plans. We're launching now. Suit up.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.853519082069397], 'recall': [0.8414822816848755], 'f1': [0.8474579453468323], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.04878048780487805, 'rouge2': 0.0, 'rougeL': 0.04878048780487805, 'rougeLsum': 0.04878048780487805}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 197.34193420410156\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOWMAN: You're talking to a class of second-graders from Iowa at 1430.\\nSANTEN: It's your turn to do the kiddies.\\nBOWMAN: Don't even try. You're up, and you know it. Besides, I outrank you. I could order you to do it.\\nSANTEN: ... Just 'cause they promote faster in the Navy...\\nBOWMAN: You gotta promote faster when you have the best people... 1430. With a smile on your face.\\nSANTEN: Pulling rank on me for the shower, too?\\n\\n\", 'answer': 'Not rank, gender. Ladies first.', 'gold_tag': 'BOWMAN is assertive and uses her authority when needed', 'last_speaker': 'BOWMAN'}\n",
      "Last word -> BOWMAN : \"Not rank, gender. Ladies first.\"\n",
      "prediction :  I'm sorry I didn't catch on to it sooner.\n",
      "Real answer : Not rank, gender. Ladies first.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.813870906829834], 'recall': [0.8505594730377197], 'f1': [0.8318108320236206], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.886899948120117\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMcCROSKEY: Grab hold of yourself! You've got to talk them down. You're the only chance they've got!\\n\\n\", 'answer': 'All right, Striker, now you listen to me and you listen close. Flying is no different than riding a bicycle...it just happens to be a lot harder to put baseball cards in the spokes. Now, if you just follow my instructions...', 'gold_tag': 'KRAMER has knowledge and experience in flying , KRAMER possibly has a background as a pilot', 'last_speaker': 'KRAMER'}\n",
      "Last word -> KRAMER : \"All right, Striker, now you listen to me and you listen close. Flying is no different than riding a bicycle...it just happens to be a lot harder to put baseball cards in the spokes. Now, if you just follow my instructions...\"\n",
      "prediction :  You've got to do it. You've got to take us all with you, I can't take their lives. I don't want to - but if they got to go, we've got to go with them.\n",
      "Real answer : All right, Striker, now you listen to me and you listen close. Flying is no different than riding a bicycle...it just happens to be a lot harder to put baseball cards in the spokes. Now, if you just follow my instructions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8373908400535583], 'recall': [0.8170357942581177], 'f1': [0.8270881175994873], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.14814814814814817, 'rougeLsum': 0.14814814814814817}\n",
      "bleu 1/2 : 0.09628119332763099 0.015445644412716347\n",
      "ppl : 8.315596580505371\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKRAMER: I don't understand it. He should have been in range ten minutes ago.\\n\\n\", 'answer': 'Gunderson, check the radar range. Anything yet?', 'gold_tag': 'McCROSKEY is in charge , McCROSKEY is giving orders to check the radar range , McCROSKEY holds a position of authority in the same field', 'last_speaker': 'McCROSKEY'}\n",
      "Last word -> McCROSKEY : \"Gunderson, check the radar range. Anything yet?\"\n",
      "prediction :  He told you.\n",
      "Real answer : Gunderson, check the radar range. Anything yet?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8603386878967285], 'recall': [0.8380100131034851], 'f1': [0.8490275144577026], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 686.2061157226562\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMcCROSKEY: Two more minutes! They could be miles off course.\\n\\n', 'answer': \"That's impossible. They're on instruments!\", 'gold_tag': 'KRAMER has knowledge of aircraft navigation systems', 'last_speaker': 'KRAMER'}\n",
      "Last word -> KRAMER : \"That's impossible. They're on instruments!\"\n",
      "prediction :  Not if their nav systems are working. Those things are very sophisticated.\n",
      "Real answer : That's impossible. They're on instruments!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8621262311935425], 'recall': [0.8645031452178955], 'f1': [0.8633130788803101], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 132.65782165527344\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMcCROSKEY: Rex, I've decided that the best thing to do is to foam the runway -- let him do a wheels-up landing. It'd be a lot simpler.\\nKRAMER: No, the risk of fire is too great. If she starts burning, you write off all those people who can't get out of there on their own power.\\nMcCROSKEY: Well that's better than writing them all off? Are you going to play God with a hundred and 38 lives?\\nKRAMER: No. A belly landing isn't all that simple. It takes a good pilot to keep from smearin' himself all over the runway.\\nMcCROSKEY: If Striker has the guts to try this, he deserves the best shot we can give him. We've gotta foam that runway.\\nKRAMER: His only shot's with the wheels down. I've seen foam tear a man's guts out.\\nMcCROSKEY: And if Striker goes to pieces?\\n\\n\", 'answer': \"That's a risk we'll just have to take.\", 'gold_tag': 'KRAMER is a risk-averse person who prioritizes safety above all', 'last_speaker': 'KRAMER'}\n",
      "Last word -> KRAMER : \"That's a risk we'll just have to take.\"\n",
      "prediction :  Alright, I give him foam.\n",
      "Real answer : That's a risk we'll just have to take.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.88358473777771], 'recall': [0.8370242714881897], 'f1': [0.8596745729446411], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1530.1905517578125\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMcCROSKEY: Ya know, this would be a tough landing for anyone to make. Maybe, if we hold them off for a bit we'll get a break in the weather.\\n\\n\", 'answer': \"All right, but let's wait until they reach the control area.\", 'gold_tag': 'KRAMER has a decision-making role in the conversation', 'last_speaker': 'KRAMER'}\n",
      "Last word -> KRAMER : \"All right, but let's wait until they reach the control area.\"\n",
      "prediction :  Good thought. Let's do this.\n",
      "Real answer : All right, but let's wait until they reach the control area.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8990435600280762], 'recall': [0.8756997585296631], 'f1': [0.887218177318573], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2222222222222222, 'rouge2': 0.12500000000000003, 'rougeL': 0.2222222222222222, 'rougeLsum': 0.2222222222222222}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 58.88252258300781\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKRAMER: Steve, I want every light you can get poured on that field.\\n\\n', 'answer': \"It's being done right now.\", 'gold_tag': \"McCROSKEY is carrying out KRAMER's order to illuminate the field\", 'last_speaker': 'McCROSKEY'}\n",
      "Last word -> McCROSKEY : \"It's being done right now.\"\n",
      "prediction :  The only light we have is on top of the power plant.\n",
      "Real answer : It's being done right now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8416107296943665], 'recall': [0.8588821887969971], 'f1': [0.8501588106155396], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 57.38011932373047\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMcCROSKEY: It sure is quiet out there.\\nKRAMER: Yeah -- too quiet.\\n\\n', 'answer': 'Looks like I picked the wrong week to quit sniffing glue.', 'gold_tag': 'McCROSKEY recently quit sniffing glue', 'last_speaker': 'McCROSKEY'}\n",
      "Last word -> McCROSKEY : \"Looks like I picked the wrong week to quit sniffing glue.\"\n",
      "prediction :  I'm calling in for a new ticket.\n",
      "Real answer : Looks like I picked the wrong week to quit sniffing glue.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8782116174697876], 'recall': [0.8651597499847412], 'f1': [0.8716368079185486], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473685, 'rouge2': 0.0, 'rougeL': 0.10526315789473685, 'rougeLsum': 0.10526315789473685}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 52.74391555786133\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKRAMER: Bring it down! Easy!\\n\\n', 'answer': \"Look at all those buttons! Oh that's beautiful! Just beautiful!\", 'gold_tag': 'McCROSKEY shows interest and admiration for complex machinery or technology , McCROSKEY is fascinated with the buttons', 'last_speaker': 'McCROSKEY'}\n",
      "Last word -> McCROSKEY : \"Look at all those buttons! Oh that's beautiful! Just beautiful!\"\n",
      "prediction :  Bring it down.\n",
      "Real answer : Look at all those buttons! Oh that's beautiful! Just beautiful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8701502680778503], 'recall': [0.8267884254455566], 'f1': [0.8479152917861938], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 908.8919677734375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKRAMER: Remember your brakes and switches! Get ready to flare it out! You're coming in too fast! Watch your speed!\\nMcCROSKEY: He's coming right at us!\\n\\n\", 'answer': \"You're coming in too hot! Put down full flaps! Watch your nose!\", 'gold_tag': 'KRAMER is knowledgeable about flying or landing a plane', 'last_speaker': 'KRAMER'}\n",
      "Last word -> KRAMER : \"You're coming in too hot! Put down full flaps! Watch your nose!\"\n",
      "prediction :  Take her slow. Don't speed up. Watch your speed.\n",
      "Real answer : You're coming in too hot! Put down full flaps! Watch your nose!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8894745111465454], 'recall': [0.8403376936912537], 'f1': [0.8642082214355469], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17391304347826086, 'rouge2': 0.09523809523809525, 'rougeL': 0.17391304347826086, 'rougeLsum': 0.17391304347826086}\n",
      "bleu 1/2 : 0.15922918012750872 0.11942188509563156\n",
      "ppl : 52.28293228149414\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICKY: ...you big fuckin' hick, you. Come here. Come here. Get him up. Come here.\\n\\n\", 'answer': 'Get up.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MARINO'}\n",
      "Last word -> MARINO : \"Get up.\"\n",
      "prediction :  This is just a big, stupid, stupid, stupid, stupid ass, that's what it is.\n",
      "Real answer : Get up.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7896962761878967], 'recall': [0.893949031829834], 'f1': [0.8385949730873108], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.519536018371582\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICKY: Come here, come here.\\nMARINO: Get up.\\n\\n', 'answer': 'You go over there right now and you apologize. You better hope he lets you back in.', 'gold_tag': 'NICKY is in a position of power , NICKY is concerned about a present situation where someone needs to be apologized to immediately', 'last_speaker': 'NICKY'}\n",
      "Last word -> NICKY : \"You go over there right now and you apologize. You better hope he lets you back in.\"\n",
      "prediction :  You should have this here, in your bedroom and not in the living room.\n",
      "Real answer : You go over there right now and you apologize. You better hope he lets you back in.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8613494634628296], 'recall': [0.8485850095748901], 'f1': [0.8549196124076843], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1935483870967742, 'rouge2': 0.0, 'rougeL': 0.1935483870967742, 'rougeLsum': 0.1935483870967742}\n",
      "bleu 1/2 : 0.1153025352864842 0.026755692780938665\n",
      "ppl : 37.63753890991211\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICKY: Be careful. Hey, come on. Get inside. Can you fuckin' believe that? Look at this motherfucker. I fucked up, Frankie. I fucked up good this time. Should have never started with this fuckin' broad.\\nMARINO: Take it easy. What could you do? I mean, she threw herself at you, right?\\n\\n\", 'answer': \"I'm in a bad fuckin' spot here. You know that? Bad fuckin' spot.\", 'gold_tag': \"NICKY is currently in a 'bad spot' , NICKY is currently in a problematic situation, caused by a recent event involving a woman\", 'last_speaker': 'NICKY'}\n",
      "Last word -> NICKY : \"I'm in a bad fuckin' spot here. You know that? Bad fuckin' spot.\"\n",
      "prediction :  Well, you know what? She deserves it all.\n",
      "Real answer : I'm in a bad fuckin' spot here. You know that? Bad fuckin' spot.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8505644798278809], 'recall': [0.8425242900848389], 'f1': [0.846525251865387], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.1, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0.0669076785648738 0.02261892368524442\n",
      "ppl : 63.773658752441406\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICKY: Dominick! Oh, Dominick. Oh, Dom. Frankie. Frankie, leave the kid alone. He's still breathin'. He's still breathin'. Leave him alone. Frankie.\\nMARINO: All right. Strip him.\\n\\n\", 'answer': \"No balls, you got no fuckin' balls. Oh, Dominick. Oh, Dom. Dominick. Dominick. Dominick.\", 'gold_tag': 'NICKY is aggressive', 'last_speaker': 'NICKY'}\n",
      "Last word -> NICKY : \"No balls, you got no fuckin' balls. Oh, Dominick. Oh, Dom. Dominick. Dominick. Dominick.\"\n",
      "prediction :  Strip him? What's gonna happen? If he's not dead, why would we strip him?\n",
      "Real answer : No balls, you got no fuckin' balls. Oh, Dominick. Oh, Dom. Dominick. Dominick. Dominick.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8313701748847961], 'recall': [0.842035174369812], 'f1': [0.8366686105728149], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 33.05766677856445\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAULSEN: Well, look, there isn't a ton of information here, but from what there is, I'd say that these two people here -- what are their names? Shanna and Ashley?\\nERIN: Right, I guess those are the kids --\\nPAULSEN: They've both got some immune system problem. Can't say what from, whether it's viral or genetic or what, but something's wrong. And these guys -- Donna and Peter --\\nERIN: Their parents, I'm pretty sure.\\n\\n\", 'answer': \"Well, from what this stuff says, I'd say they both have some form of cancer.\", 'gold_tag': 'PAULSEN is likely working in a field where medical knowledge is required', 'last_speaker': 'PAULSEN'}\n",
      "Last word -> PAULSEN : \"Well, from what this stuff says, I'd say they both have some form of cancer.\"\n",
      "prediction :  Donna, do you know when they had you kids?\n",
      "Real answer : Well, from what this stuff says, I'd say they both have some form of cancer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8613742589950562], 'recall': [0.8437464833259583], 'f1': [0.8524692058563232], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0.05704634655917688 0.019133926316149612\n",
      "ppl : 138.85665893554688\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: ... and when I realized our area's just as bad as Hinkley, I thought maybe my neighbors are all sick too. So I went and asked.\\nPAULSEN: You did?\\nERIN: Uh-huh. Spent the last few days knocking on doors. And you know what? They're not. I mean, they got problems, but none of this cancer stuff. And their pets are fine. So I don't know -- I just can't shake the feeling that it wasn't no multivitamin they put in the water.\\n\\n\", 'answer': \"Well, if you're talking about contamination, you're getting out of my area of expertise. Let me give you the name of a toxicologist friend of mine over at USC.\", 'gold_tag': 'Paulsen is outside his comfort zone regarding contamination and toxicology matters , Paulsen has connections, as evidenced by his suggestion to refer Erin to a toxicologist friend at USC', 'last_speaker': 'PAULSEN'}\n",
      "Last word -> PAULSEN : \"Well, if you're talking about contamination, you're getting out of my area of expertise. Let me give you the name of a toxicologist friend of mine over at USC.\"\n",
      "prediction :  There's no real explanation here. I tried asking some of my colleagues over at UC Davis, but they can't figure it out either.\n",
      "Real answer : Well, if you're talking about contamination, you're getting out of my area of expertise. Let me give you the name of a toxicologist friend of mine over at USC.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8684422969818115], 'recall': [0.864148736000061], 'f1': [0.8662902116775513], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17857142857142855, 'rouge2': 0.07407407407407407, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.1674742168678578 0.10830051676671404\n",
      "ppl : 15.951539039611816\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAULSEN: I gotta say, Erin -- first time I saw you, I did not peg you as the kind to go off and conduct her own epidemiological study.\\n\\n', 'answer': \"Don't go telling anyone. It'll ruin my reputation.\", 'gold_tag': 'ERIN values her reputation', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Don't go telling anyone. It'll ruin my reputation.\"\n",
      "prediction :  I had better not have that kind of impact on you.\n",
      "Real answer : Don't go telling anyone. It'll ruin my reputation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8594086170196533], 'recall': [0.883110523223877], 'f1': [0.8710983991622925], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 48.3859977722168\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIRECTOR: What can I do for you, Mr. Welles?\\nWELLES: Call me Tom.\\nDIRECTOR: Alright, Tom.\\nWELLES: What I'd like, very simply, is access to your archive. And, now I understand this isn't something you normally do for private citizens...\\nDIRECTOR: There are reasons for the way we do things here.\\nWELLES: Absolutely. Of course I'll abide by whatever decision you make, but I'd appreciate if you'll hear me out... Few days ago, I was contacted by a couple living in Philadelphia, a doctor and his wife. What happened was they picked up a young girl hitchhiking off 81, which heads into Philadelphia, started up a conversation with this girl, she looked homeless, seemed about eighteen maybe. They convinced her to let them buy her a meal in the city. Nice kid, mature, didn't have much to say, but they got a sense she's a runaway, so all through dinner the doctor's working on her, trying to convince her that at the very least she should pick up a telephone. Not surprisingly, she ate her food, excused herself... That's the last they saw her. The reason they came to me for help, the reason I'm coming to you, is we had a friend of mine in the department They want to see if I can I.D. this girl, somehow pass along a message to let the parents know the kid's alive, doing alright.\\nDIRECTOR: Why not go to the N.C.I.C. or N.C.M.E.C.?\\nWELLES: I figured you share information.\\nDIRECTOR: We do.\\nWELLES: For whatever reasons I thought you might be more receptive.\\nDIRECTOR: Why don't they come to me?\\nWELLES: This doctor and wife, they're nice people, but they don't want to get too involved. They're not trying to have the parents come looking for the girl either. You and I both know sometimes, not often, but sometimes there's real reasons why a kid'll run. Molestation, whatever. Besides that, the girl's probably eighteen, so she's legal.\\nDIRECTOR: I'm not so sure about this.\\nWELLES: They're putting themselves in place of this kid's parents and thinking they'd want to hear their girl's okay, even if that's all they hear.\\nDIRECTOR: I can give you my card, if your clients want to call me...\\nWELLES: They were pretty clear they didn't want this coming back on them.\\nDIRECTOR: Well, that's all I can do. Sorry.\\n\\n\", 'answer': \"Who knows... maybe she's already given her parents a call, right?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'WELLES'}\n",
      "Last word -> WELLES : \"Who knows... maybe she's already given her parents a call, right?\"\n",
      "prediction :  I won't lie and say it's not nerve-wracking to leave a kid in the dark about this, but there's people in the dark every day. The worst part is, they wait until the kid figures out on their own when it was too late.\n",
      "Real answer : Who knows... maybe she's already given her parents a call, right?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8284001350402832], 'recall': [0.8416202068328857], 'f1': [0.8349578380584717], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06666666666666667, 'rouge2': 0.0, 'rougeL': 0.06666666666666667, 'rougeLsum': 0.06666666666666667}\n",
      "bleu 1/2 : 0.02272727272727273 0.007270084086278819\n",
      "ppl : 14.498214721679688\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWELLES: Fuck.\\n\\n', 'answer': \"Excuse me... Tom, hold on... Listen, maybe I can help after all. Why don't you come on back in... we'll see what we can do.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'DIRECTOR'}\n",
      "Last word -> DIRECTOR : \"Excuse me... Tom, hold on... Listen, maybe I can help after all. Why don't you come on back in... we'll see what we can do.\"\n",
      "prediction :  Well, that was a disaster. I can’t believe this place. I swear the place smells like shit even when it’s not. Oh my God. My god, this place smells like shit even when it’s not.\n",
      "Real answer : Excuse me... Tom, hold on... Listen, maybe I can help after all. Why don't you come on back in... we'll see what we can do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8265405893325806], 'recall': [0.8191842436790466], 'f1': [0.822845995426178], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09230769230769231, 'rouge2': 0.031746031746031744, 'rougeL': 0.09230769230769231, 'rougeLsum': 0.09230769230769231}\n",
      "bleu 1/2 : 0.028571428571428577 0.009166984970282115\n",
      "ppl : 9.868012428283691\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIRECTOR: This is it. It's not much. (points at computers) We've got less than five percent on computer and we lose that funding in December. I'll have someone show it to you anyway. Other than that, I'm afraid it's the wet thumb method. Files are mostly by state and year of disappearance. We try to keep the children and adults separate. No eating or smoking in here, but\\nWELLES: Any good?\\nDIRECTOR: It's horrible, but it'll be your best friend after a few days. I hope you realize what kind of long shot you're chasing after.\\nWELLES: You're gonna be seeing a lot of me. You're sure you don't mind?\\n\\n\", 'answer': \"It's good what you're doing.\", 'gold_tag': 'WELLES indicates a strong commitment to his cause', 'last_speaker': 'DIRECTOR'}\n",
      "Last word -> DIRECTOR : \"It's good what you're doing.\"\n",
      "prediction :  Just a brief overview. It's up to you on how your time is spent. You'll learn all the latest methods of the trade; how to do the dirty work to the best advantage; and how to deal with people from all different backgrounds. It's all here... including the latest in electronic security. When it comes to getting the money out of the system, there will be no competition. There are a million of us here, but only one of you will graduate.\n",
      "Real answer : It's good what you're doing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8195866346359253], 'recall': [0.8531957864761353], 'f1': [0.8360535502433777], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06521739130434782, 'rouge2': 0.022222222222222223, 'rougeL': 0.06521739130434782, 'rougeLsum': 0.06521739130434782}\n",
      "bleu 1/2 : 0.01219512195121951 0.00388016830983099\n",
      "ppl : 14.014321327209473\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTARCK: The antennae array\\'s completely fried, we\\'ve got no radio, no laser, no highgain... No one\\'s going to be coming to help us.\\nMILLER: How much oh-two do we have?\\nSTARCK: Oxygen is not the problem.\\nMILLER: Carbon dioxide?\\nSTARCK: It\\'s building up with every breath we take. And the CO2 filters on the Event Horizon are shot.\\nMILLER: We can take the filters from the Clark...\\nSTARCK: I thought of that, with the filters from the Clark, we\\'ve got enough breathable air for twenty hours. After that, we\\'d better be on our way home.\\nMILLER: What about the life readings you picked up?\\nSTARCK: The Event Horizon sensors show the same thing: \"Bio-readings of indeterminate origin.\" Right before that wave hit the Clark, there was some kind of surge, right off the scale, but now it\\'s back to its previous levels. I don\\'t know, but whatever it is, it\\'s not the crew.\\n\\n', 'answer': \"So where is the rest of the crew? We've been over every inch of this ship and all we've found is blood. Dr. Weir? Any suggestions? What happened here?\", 'gold_tag': 'MILLER has the immediate concern of finding the rest of the crew and survival plans', 'last_speaker': 'MILLER'}\n",
      "Last word -> MILLER : \"So where is the rest of the crew? We've been over every inch of this ship and all we've found is blood. Dr. Weir? Any suggestions? What happened here?\"\n",
      "prediction :  Well, we've got to do our best to find any answers we can.\n",
      "Real answer : So where is the rest of the crew? We've been over every inch of this ship and all we've found is blood. Dr. Weir? Any suggestions? What happened here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8595526814460754], 'recall': [0.8512488007545471], 'f1': [0.8553805947303772], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17777777777777778, 'rouge2': 0.046511627906976744, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0.022466755668570322 0.007394714572768667\n",
      "ppl : 22.285053253173828\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTARCK: Miller...\\nMILLER: What is it, Starck?\\nSTARCK: ...I ran the bio-scan with the DNA/RNA filter. The results were bio-readings of indeterminate origin...\\nMILLER: \"...bio-readings of indeterminate origin,\" don\\'t you have anything useful to tell me?\\nSTARCK: I\\'ve got a theory.\\nMILLER: Go ahead.\\nSTARCK: There was a another surge in the bio- readings right before you... you saw what you saw. We picked up a similar readings right before the Clarke was damaged. What if there were a connection between the two? The gravity waves, the hallucination, all part of an defensive reaction, like an immune system...\\n\\n', 'answer': \"I don't need to hear this.\", 'gold_tag': \"MILLER displays skepticism and dismissiveness towards STARCK's theory\", 'last_speaker': 'MILLER'}\n",
      "Last word -> MILLER : \"I don't need to hear this.\"\n",
      "prediction :  You sound certain of this.\n",
      "Real answer : I don't need to hear this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8871505260467529], 'recall': [0.8632259368896484], 'f1': [0.875024676322937], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.1637461506155964 0.05789300674674099\n",
      "ppl : 446.2840270996094\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTARCK: You've got to listen...\\nMILLER: To what? What are you saying? This ship is alive?\\nSTARCK: I didn't say that, I said the bio- readings correspond to what happened to you, the ship is reacting to us...\\nMILLER: We're hanging on by our fingernails and you're giving me bullshit stories...\\nSTARCK: It's not bullshit, it's the only conclusion the data supports...\\nMILLER: Starck, do you know how crazy that sounds? It's impossible.\\nSTARCK: I know that.\\nMILLER: If you knew it was impossible, then why'd you waste my time?\\nSTARCK: I thought you wanted an answer. And that's the only one I have.\\nMILLER: What I want is to survive the next ten hours.\\nSTARCK: Nine hours and twenty-two minutes.\\n\\n\", 'answer': \"I'm going outside to work on the Clark. And Starck... don't tell anyone what you just told me. We've got enough to worry about.\", 'gold_tag': \"MILLER tasks himself with fixing 'the Clark'\", 'last_speaker': 'MILLER'}\n",
      "Last word -> MILLER : \"I'm going outside to work on the Clark. And Starck... don't tell anyone what you just told me. We've got enough to worry about.\"\n",
      "prediction :  What's wrong with you, anyway?\n",
      "Real answer : I'm going outside to work on the Clark. And Starck... don't tell anyone what you just told me. We've got enough to worry about.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.837948739528656], 'recall': [0.8155782222747803], 'f1': [0.826612114906311], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12121212121212122, 'rouge2': 0.0, 'rougeL': 0.12121212121212122, 'rougeLsum': 0.12121212121212122}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 32.803977966308594\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMILLER: Are you cold? You need something to warm you up?\\nJACKIE: You could torch the club so I don’t have to do this shit.\\nMILLER: Be prepared - it’s not as big a house as they thought. I think the weather kept people home.\\n\\n', 'answer': 'You sure it’s not the marquee? Reads like Night of the Living Dead.', 'gold_tag': 'JACKIE is a performer', 'last_speaker': 'JACKIE'}\n",
      "Last word -> JACKIE : \"You sure it’s not the marquee? Reads like Night of the Living Dead.\"\n",
      "prediction :  I’m ready - if its a deal I’m getting up in that shit.\n",
      "Real answer : You sure it’s not the marquee? Reads like Night of the Living Dead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8573629260063171], 'recall': [0.8365897536277771], 'f1': [0.8468489646911621], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 72.1383285522461\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACKIE: I’d try it on you but you have no sense of humor.\\nMILLER: No, I don’t.\\nJACKIE: I have never seen you laugh.\\nMILLER: No you haven’t.\\nJACKIE: How can that be? You represent comics.\\nMILLER: You just answered your own question. Can you imagine how fucking painful my life would be if I had to act like an audience with all my comics? “You laughed more at his joke, than ya did at mine” “You think he’s funny, he’s not funny”. So I don’t react to anyone and everyone feels equal.\\nJACKIE: And you call that personal management? Your father had affection for his clients.\\nMILLER: Which his clients didn’t have. He got you that TV show and you fired him.\\nJACKIE: It was a William Morris package deal. Your father understood.\\nMILLER: Just don’t talk to me about affection.\\nJACKIE: I don’t need your affection. You know what I need? I need to work. I want a New York club.\\n\\n', 'answer': 'Yeah, that’ll get you out of the hole you’re in - $30 a show at the', 'gold_tag': 'Everyday Language', 'last_speaker': 'MILLER'}\n",
      "Last word -> MILLER : \"Yeah, that’ll get you out of the hole you’re in - $30 a show at the\"\n",
      "prediction :  I was watching old newsreels of Hitler's campaign in early 1921. The Nazis were making a big show of their first ever big parade in Nuremberg. It was to celebrate Germany's victory over the Poles. Well, some German who was on the committee who organized the parade gave Hitler the title of commander. The word commander is the equivalent to general in Germany. And on the day of the parade, he was the man who made Hitler a general rather than a minor\n",
      "Real answer : Yeah, that’ll get you out of the hole you’re in - $30 a show at the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8073323965072632], 'recall': [0.8322286605834961], 'f1': [0.8195914626121521], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1176470588235294, 'rouge2': 0.02, 'rougeL': 0.09803921568627451, 'rougeLsum': 0.09803921568627451}\n",
      "bleu 1/2 : 0.07228915662650603 0.029691330061333544\n",
      "ppl : 13.569295883178711\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACKIE: I’m hot now. I’m viral. Your father knew how to take advantage of opportunities like this... “Millah the Killah” I used to call him.\\n\\n', 'answer': 'He loved when you called him that. It killed him when you stopped.', 'gold_tag': 'MILLER\\'s father loved being called \"Millah the Killah\" by JACKIE , Shared memories: JACKIE and MILLER share a memory of MILLER\\'s father, who used to be affectionately called ‘Millah the Killah’ by JACKIE', 'last_speaker': 'MILLER'}\n",
      "Last word -> MILLER : \"He loved when you called him that. It killed him when you stopped.\"\n",
      "prediction :  I never did that.\n",
      "Real answer : He loved when you called him that. It killed him when you stopped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8926995992660522], 'recall': [0.8599774837493896], 'f1': [0.8760330677032471], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.026349806140466083 0.009621588806014277\n",
      "ppl : 135.38475036621094\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACKIE: What am I a Rent-A-Comic?\\nMILLER: She’s a fan who runs a cable network.\\nJACKIE: There was a neon sign on her forehead that said “NO. You didn’t see it?\\nMILLER: There are new executives out there. You have to cultivate them. They say no this time, you come back with another idea.\\nJACKIE: I come back and tap dance some more for these fucking jerks without an ounce of talent between them. They’re gonna tell me what’s funny and what’s not?\\nMILLER: Being funny isn’t enough anymore. This sacrilegious remark stops Jackie cold.\\n\\n', 'answer': 'Now you’re fired.', 'gold_tag': 'JACKIE fired Miller', 'last_speaker': 'JACKIE'}\n",
      "Last word -> JACKIE : \"Now you’re fired.\"\n",
      "prediction :  What the hell did he say to you?\n",
      "Real answer : Now you’re fired.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8362516164779663], 'recall': [0.8677763938903809], 'f1': [0.8517223596572876], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 41.52958297729492\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMILLER: Over three million views in eight hours and it keeps climbing. You’re on Kimmel. You’re on Conan. Carol from RAW TV called me. She needs a host for a reality show pilot. They shoot on Monday in NY?\\nJACKIE: Monday? Why so fast?\\nMILLER: They had D’Angelo signed but he had to drop out last minute.\\nJACKIE: Why? He got a better deal?\\nMILLER: He’s got pancreatic cancer.\\n\\n', 'answer': 'Finally, I catch a fuckin’ break in this business.', 'gold_tag': 'JACKIE commented about finally catching a break , The language JACKIE uses suggests a direct and perhaps cynical personality', 'last_speaker': 'JACKIE'}\n",
      "Last word -> JACKIE : \"Finally, I catch a fuckin’ break in this business.\"\n",
      "prediction :  Oh, it’s not just that. I don’t think he understood the scope of the project or the commitment.\n",
      "Real answer : Finally, I catch a fuckin’ break in this business.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8614246845245361], 'recall': [0.8593284487724304], 'f1': [0.8603752255439758], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06896551724137932, 'rouge2': 0.0, 'rougeL': 0.06896551724137932, 'rougeLsum': 0.06896551724137932}\n",
      "bleu 1/2 : 0.05555555555555554 0.018077538151554672\n",
      "ppl : 16.864120483398438\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBB: What is this? What is this crowd here? We're charging admission?\\n\\n\", 'answer': 'Back away... give me some elbow', 'gold_tag': 'TILLEY values personal space , TILLEY is focused on a task, as indicated by the request for some elbow room', 'last_speaker': 'TILLEY'}\n",
      "Last word -> TILLEY : \"Back away... give me some elbow\"\n",
      "prediction :  Yes. You can get free admission if you come to see us at the next science fair.\n",
      "Real answer : Back away... give me some elbow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.841679573059082], 'recall': [0.8128610849380493], 'f1': [0.8270193338394165], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 33.56831741333008\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTILLEY: Yeah. You in there? Yeah. They got my license as well. Sorry to hear it. This is where my car used to be. Stolen? I.R.S. Fucking bandits! Bandits! Thieving sons of bitches!\\nBB: You need a ride uptown?\\nTILLEY: I could use one.\\n\\n', 'answer': 'Come on.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BB'}\n",
      "Last word -> BB : \"Come on.\"\n",
      "prediction :  Well I don't drive. I would go by myself but I don't want to be caught with no driver's license.\n",
      "Real answer : Come on.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8321017026901245], 'recall': [0.8872686624526978], 'f1': [0.8588001728057861], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 17.433137893676758\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTILLEY: Some bullshit commission, huh? Tell me, where's it written it the Constitution that says you can't hustle for money? Where's it written? It ain't like I went into an alley and hit a guy over the head with a brick and stole his money... not like I broke into somebody's house and stole his stuff. All I'm doing is selling... where's the crime in that?\\nBB: I don't know what the world's coming to.\\n\\n\", 'answer': \"You're telling me. I don't know what the world's coming to.\", 'gold_tag': \"TILLEY is defensive about his job or actions , TILLEY's job or actions involve the sales industry or hustling for money , TILLEY is skeptical about the current state of the world\", 'last_speaker': 'TILLEY'}\n",
      "Last word -> TILLEY : \"You're telling me. I don't know what the world's coming to.\"\n",
      "prediction :  [Laughing] I know! I was about to say they're going to tax you for having nice shit.\n",
      "Real answer : You're telling me. I don't know what the world's coming to.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8293510675430298], 'recall': [0.8698028326034546], 'f1': [0.8490954041481018], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.31250000000000006, 'rouge2': 0.0, 'rougeL': 0.1875, 'rougeLsum': 0.1875}\n",
      "bleu 1/2 : 0.0588235294117647 0.019174124721184262\n",
      "ppl : 38.62843322753906\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBB: You know what our big crime is? We're nickel and dime guys. We're small time hustlers. They got us because we're hustling nickels and dimes.\\nTILLEY: Nickels and dimes. You got a good point there, BB. You're right on the money with that kind of thinking.\\nBB: Gotta find a new business to get into.\\nTILLEY: New? Very hard to find something new to get into.\\nBB: Maybe... maybe not.\\n\\n\", 'answer': 'Better put on my thinking cap... not easy to think of something new.', 'gold_tag': 'Everyday Language', 'last_speaker': 'TILLEY'}\n",
      "Last word -> TILLEY : \"Better put on my thinking cap... not easy to think of something new.\"\n",
      "prediction :  You can go ahead with the rest. We'll finish the job at the hotel. I told you I'd help you get that money out of the hotel and out of your life.\n",
      "Real answer : Better put on my thinking cap... not easy to think of something new.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8461991548538208], 'recall': [0.8450517058372498], 'f1': [0.845625102519989], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0425531914893617, 'rouge2': 0.0, 'rougeL': 0.0425531914893617, 'rougeLsum': 0.0425531914893617}\n",
      "bleu 1/2 : 0.03125 0.010040241611281232\n",
      "ppl : 14.798113822937012\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSOL: Stop thinking, Max, just feel. Use your intuition. It's the only way to get into the flow. What did you think of Hamlet?\\nMAX: I didn't get to it.\\nSOL: It's been a month. You haven't taken a single break.\\nMAX: I'm so close, Sol. I'm so close but I just can't grab it.\\nSOL: Have you met the new fish my niece bought me? I named her Icarus. After you. My renegade pupil. You fly The more I see you, the more I see myself thirty years ago. My greatest pupil. Published at 16, Ph.D. at 20.\\nMAX: We'll see.\\nSOL: But life isn't just mathematics. I spent forty years looking for patterns in\\nMAX: You found things...\\n\\n\", 'answer': 'I found things, but not a pattern.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SOL'}\n",
      "Last word -> SOL : \"I found things, but not a pattern.\"\n",
      "prediction :  We should listen closer\n",
      "Real answer : I found things, but not a pattern.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8583431839942932], 'recall': [0.8619815707206726], 'f1': [0.8601585626602173], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3200.84716796875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMAX: Euclid crashed. I lost all my data, my hardware.\\nSOL: Your mainframe?\\nMAX: Burnt...\\nSOL: What happened?\\nMAX: I don't know, first I got these horrible picks. Then Euclid spits out some numbers. Never saw anything like it and then it fries. The whole machine just crashed.\\nSOL: You have a printout?\\nMAX: Of?\\nSOL: The picks, the number?\\nMAX: I threw it out.\\nSOL: What was the number it spit out?\\nMAX: I don't know, just a long string of digits.\\nSOL: How many?\\nMAX: I don't know.\\nSOL: What was it, a sixteen!? How many?\\nMAX: I don't know. Probably around two hundred. Why?\\nSOL: I dealt with some bugs back in my Pi days. I was wondering if it was similar to one I ran into. Have you met Archimedes. The one with the black spot. You see?\\nMAX: Yeah.\\nSOL: Remember Archimedes of Syracuse? The King asks Archimedes to determine if a present he's received was actually solid gold. Unsolved problem at the time. It tortures the great Greek mathematician for weeks. Insomnia haunts him and he for nights on end. Finally, his equally exhausted wife, with this genius, convinces him to take a bath, to relax. discovery. Now, what's the moral of the story.\\nMAX: That a breakthrough will come...\\n\\n\", 'answer': \"Wrong. The point of the story is the wife. Listen to your wife, she will give you perspective. Meaning, you need a break, Max, you have to take a bath, otherwise you'll get nowhere. There will be no order, only chaos. Go home and take a bath.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SOL'}\n",
      "Last word -> SOL : \"Wrong. The point of the story is the wife. Listen to your wife, she will give you perspective. Meaning, you need a break, Max, you have to take a bath, otherwise you'll get nowhere. There will be no order, only chaos. Go home and take a bath.\"\n",
      "prediction :  You have to understand what you're playing with.\n",
      "Real answer : Wrong. The point of the story is the wife. Listen to your wife, she will give you perspective. Meaning, you need a break, Max, you have to take a bath, otherwise you'll get nowhere. There will be no order, only chaos. Go home and take a bath.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8614485263824463], 'recall': [0.8427855372428894], 'f1': [0.8520147800445557], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14035087719298245, 'rouge2': 0.07272727272727272, 'rougeL': 0.14035087719298245, 'rougeLsum': 0.14035087719298245}\n",
      "bleu 1/2 : 0.0019087735547149904 0.0014428971814036012\n",
      "ppl : 23.849021911621094\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSOL: Max?\\nMAX: What's going on, Sol!?\\n\\n\", 'answer': \"Relax, it's early.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SOL'}\n",
      "Last word -> SOL : \"Relax, it's early.\"\n",
      "prediction :  I think something's happening there! Come on! We were just talking!\n",
      "Real answer : Relax, it's early.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8227525949478149], 'recall': [0.8661372661590576], 'f1': [0.8438876867294312], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 50.953861236572266\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSOL: Now, what\\'s up?\\nMAX: What\\'s the two hundred and sixteen number, Sol?\\nSOL: Excuse me?\\nMAX: You asked me if I had seen a two hundred and sixteen digit number, right?\\nSOL: Oh, you mean the bug. I found it working on Pi.\\nMAX: What do you mean by \"found it\"?\\nSOL: What\\'s this all about, Max?\\nMAX: Well, there\\'s these religious Jews who have...\\nSOL: Religious Jews?\\nMAX: Well, you know, Hassidim. I met one in the coffee shop. The guy\\'s a number theorist. The Torah is their data set. The thing is, they\\'re searching for a two\\nSOL: Really? What\\'s it mean to them?\\nMAX: They say they don\\'t know, but that\\'s crazy. I mean what are the odds...\\nSOL: It\\'s just a coincidence.\\nMAX: But hold on, there\\'s something else. You remember those strange picks I got.\\nSOL: Yesterday\\'s stock picks?\\nMAX: Right. Well, it turns out that they were correct. I hit two picks on the nose. Smack on the nose.\\nSOL: Hmmm.\\nMAX: Something\\'s going on, and it has to do with that No. it\\'s a pattern. A pattern is in that number\\n\\n', 'answer': 'Come with me.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SOL'}\n",
      "Last word -> SOL : \"Come with me.\"\n",
      "prediction :  What happens when you try to divide it by 127.7.\n",
      "Real answer : Come with me.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.821973443031311], 'recall': [0.855934739112854], 'f1': [0.8386104106903076], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 32.175697326660156\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSOL: Listen to me. The Ancient Japanese considered the Go simple and ordered, in fact, the possibilities of game play are endless. They say that no two Go games have ever been alike. Just like snowflakes. So, the Go board actually represents an extremely complex and chaotic universe. That is the truth of our world, Max. pattern.\\nMAX: But as a Go game progresses, the possibilities become smaller and smaller. The board does take on order. Soon, all moves are predictable. So, maybe, even though we're not sophisticated enough to be aware of it, there is an underlying order...a pattern, beneath every Go game. Maybe that pattern is like the pattern in the market, in the Torah. The two sixteen number.\\nSOL: That is insanity, Max.\\nMAX: Or maybe it's genius. I have to get that number.\\n\\n\", 'answer': \"Hold on, you have to slow down. You're losing it, you have to take a breath. Listen to yourself. You're connecting a computer bug I had, a computer bug you might have had, and some religious hogwash. If you want to find the number two sixteen in the world, you'll be able to pull it out of anywhere. Two\", 'gold_tag': \"Sol shows concern for Max's mental state, advising him to slow down , Max feels an immediate need to find the number 216\", 'last_speaker': 'SOL'}\n",
      "Last word -> SOL : \"Hold on, you have to slow down. You're losing it, you have to take a breath. Listen to yourself. You're connecting a computer bug I had, a computer bug you might have had, and some religious hogwash. If you want to find the number two sixteen in the world, you'll be able to pull it out of anywhere. Two\"\n",
      "prediction :  You don't remember your first day at the Go club? Your first meeting with the guy who changed your life.\n",
      "Real answer : Hold on, you have to slow down. You're losing it, you have to take a breath. Listen to yourself. You're connecting a computer bug I had, a computer bug you might have had, and some religious hogwash. If you want to find the number two sixteen in the world, you'll be able to pull it out of anywhere. Two\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8353663682937622], 'recall': [0.8309191465377808], 'f1': [0.833136796951294], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07228915662650602, 'rouge2': 0.0, 'rougeL': 0.07228915662650602, 'rougeLsum': 0.07228915662650602}\n",
      "bleu 1/2 : 0.014227407158651357 0.003263991054377284\n",
      "ppl : 29.181791305541992\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSOL: You're early. I was just studying our... What did you do to yourself?\\nMAX: You lied to me.\\nSOL: I thought you were going to take a break.\\nMAX: You found the two sixteen number in Pi, didn't you? You saw it. I saw it, Sol. I don't know what happened, but I know things. The market is going to crash. It's going to crash. It hasn't yet, but I know it will. I saw it, Sol. What is it, Sol? What's the number?\\nSOL: You have it?\\nMAX: It's in my head!\\nSOL: Okay, sit down. I gave up before I pinpointed it. But my guess is that certain problems cause computers to get stuck in a particular loop. The loop leads to meltdown, but their own structure. The computer has a sense of its own silicon nature and it In some ways...I guess...\\nMAX: Studying the pattern made Euclid conscious of itself. Before it died it spit out the number That consciousness is the number.\\nSOL: No, Max, it's only a nasty bug. A door in front of a cliff. You're driving yourself over the edge. You need to stop.\\nMAX: Stop? How can I stop? I'm this close.\\nSOL: The bug doesn't only destroy computers.\\nMAX: What are you saying?\\nSOL: Look what it did to your computer. Look what it's doing to you. It's killing you. Leave it\\nMAX: You were afraid of it. That's why you quit.\\nSOL: Max, I got burnt.\\nMAX: C'mon, Sol.\\nSOL: It caused my stroke.\\nMAX: That's bullshit. It's math, numbers, ideas. Mathematicians are suppose to be out on the edge. You taught me that!\\nSOL: Max, there's more than math! There's a whole world...\\nMAX: That's where discoveries happen. We have to go out there alone, all alone, no one can accompany us. We have to search the edge. We have to risk it all. But you ran from it. You're a coward.\\nSOL: Max, it's death!\\nMAX: You can't tell me what it is. You don't know You've retreated to your goldfish, to your books, to your Go, but you're not satisfied.\\nSOL: Get out! Max, get out!\\nMAX: I want to understand it. I want to know!\\n\\n\", 'answer': 'Out!', 'gold_tag': 'Everyday Language', 'last_speaker': 'SOL'}\n",
      "Last word -> SOL : \"Out!\"\n",
      "prediction :  Max\n",
      "Real answer : Out!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9367514848709106], 'recall': [0.8967422246932983], 'f1': [0.9163103103637695], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1257108.625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARTIE: Polly, why're y'doin' this?\\nPOLLY: I don't know.\\nARTIE: Angels? Be reasonable, Polly, it's rubbish. You've said it y'self. You'd be better off spendin' more time with the livin'.\\nPOLLY: Meaning?\\nARTIE: You know perfectly well what I mean. Your daughter needs you. Instead you sit around holdin' on t'...\\nPOLLY: You can't even say his name.\\nARTIE: Let me come with y'then. It'll be dark soon.\\n\\n\", 'answer': 'Thank you, I can manage.', 'gold_tag': 'Everyday Language', 'last_speaker': 'POLLY'}\n",
      "Last word -> POLLY : \"Thank you, I can manage.\"\n",
      "prediction :  Are you sure?\n",
      "Real answer : Thank you, I can manage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8326195478439331], 'recall': [0.8561689853668213], 'f1': [0.844230055809021], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 332.0350646972656\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPOLLY: Artie, did you knock...? What have you got there?\\n\\n', 'answer': \"Nothin'...\", 'gold_tag': 'ARTIE is secretive', 'last_speaker': 'ARTIE'}\n",
      "Last word -> ARTIE : \"Nothin'...\"\n",
      "prediction :  Are you calling Artie names? (I don't like the way she said it)\n",
      "Real answer : Nothin'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8178901672363281], 'recall': [0.81210857629776], 'f1': [0.8149891495704651], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 58.2064323425293\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPOLLY: Where are you going?\\n\\n', 'answer': \"T'find that reporter.\", 'gold_tag': 'ARTIE is planning to find a reporter, which is an immediate action', 'last_speaker': 'ARTIE'}\n",
      "Last word -> ARTIE : \"T'find that reporter.\"\n",
      "prediction :  I don't know.\n",
      "Real answer : T'find that reporter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8342122435569763], 'recall': [0.8567205667495728], 'f1': [0.8453166484832764], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 21.51224708557129\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPATRICK: Everything seems to be ok.\\nMICHELLE: Well, thank you. I appreciate it.\\nPATRICK: Please. I didn’t do shit- pardon my French. I almost had him. He just took off so fast... In school, I could do a mile in six-fifty.\\nMICHELLE: The other way to think of it is his speed was a testament to how scared he was of you.\\nPATRICK: Thank you for salvaging my pride.\\nMICHELLE: Anytime.\\nPATRICK: Well, if you see anything, hear anything, just give a holler.\\nMICHELLE: I’m a grandmother.\\n\\n', 'answer': 'Oh?...Congratulations.', 'gold_tag': 'Everyday Language', 'last_speaker': 'PATRICK'}\n",
      "Last word -> PATRICK : \"Oh?...Congratulations.\"\n",
      "prediction :  Yeah\n",
      "Real answer : Oh?...Congratulations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.824600338935852], 'recall': [0.8180941343307495], 'f1': [0.8213343620300293], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 7528537.5\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPATRICK: I didn’t want to disturb you but I just got home and saw all your\\nMICHELLE: That wouldn’t be good.\\nPATRICK: I know it probably sounds like I’m being chicken little or something but it'll amaze you what the winds can do up here.\\nMICHELLE: No, I’ve seen it. You should’ve been here in ‘99. It was like the\\nPATRICK: I believe it. You’re probably going to need a hand.\\nMICHELLE: Yes, probably. Thank you.\\nPATRICK: Your mother’s funeral was today?\\nMICHELLE: There was no service. We just...\\nPATRICK: I’m very sorry, Michelle.\\nMICHELLE: I never counted but I think there’s\\n\\n\", 'answer': 'The wind’s from the west. We’ll do that side.', 'gold_tag': 'PATRICK recently observed wind effects upon arriving home', 'last_speaker': 'PATRICK'}\n",
      "Last word -> PATRICK : \"The wind’s from the west. We’ll do that side.\"\n",
      "prediction :  It’s no big thing. Nothing ever is. It’ll happen again. And\n",
      "Real answer : The wind’s from the west. We’ll do that side.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8568159341812134], 'recall': [0.8809070587158203], 'f1': [0.868694543838501], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666669, 'rouge2': 0.0, 'rougeL': 0.16666666666666669, 'rougeLsum': 0.16666666666666669}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 26.625957489013672\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPATRICK: Any symptoms? Dizziness...?\\nMICHELLE: Oh, no, I’m fine. I think... Except my leg.\\n\\n', 'answer': 'You can take off the seat belt now.', 'gold_tag': \"PATRICK is in a position to help MICHELLE , PATRICK shows concern for MICHELLE's well-being , PATRICK directs MICHELLE's actions to alleviate her discomfort\", 'last_speaker': 'PATRICK'}\n",
      "Last word -> PATRICK : \"You can take off the seat belt now.\"\n",
      "prediction :  Hmm, leg. You must be tired.\n",
      "Real answer : You can take off the seat belt now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8518460988998413], 'recall': [0.8426775932312012], 'f1': [0.8472370505332947], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714288, 'rouge2': 0.0, 'rougeL': 0.14285714285714288, 'rougeLsum': 0.14285714285714288}\n",
      "bleu 1/2 : 0.11942188509563156 0.04136895450425726\n",
      "ppl : 277.71636962890625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPATRICK: You should probably go to the E.R.\\nMICHELLE: I don’t want any entanglements right now. I just want to go home. I’ll see my own doctor.\\n\\n', 'answer': 'It’s your call.', 'gold_tag': \"PATRICK is concerned about MICHELLE's health , PATRICK respects MICHELLE's decisions\", 'last_speaker': 'PATRICK'}\n",
      "Last word -> PATRICK : \"It’s your call.\"\n",
      "prediction :  You should probably visit the ER. Who will be the better doctor? You or her?\n",
      "Real answer : It’s your call.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8514817953109741], 'recall': [0.8635598421096802], 'f1': [0.8574783205986023], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 67.96489715576172\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPATRICK: Looks to me like maybe a hairline fracture. You need real treatment.\\nMICHELLE: Why did you do it?\\n\\n', 'answer': 'It was necessary.', 'gold_tag': 'Everyday Language', 'last_speaker': 'PATRICK'}\n",
      "Last word -> PATRICK : \"It was necessary.\"\n",
      "prediction :  I did it because he doesn’t have anyone.\n",
      "Real answer : It was necessary.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.854155421257019], 'recall': [0.9051665663719177], 'f1': [0.8789215087890625], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 46.03874206542969\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMISS STUBBS: Jenny. Again.\\n\\n', 'answer': \"Isn't it because Mr Rochester's blind?\", 'gold_tag': 'JENNY references Mr. Rochester, a character from Jane Eyre , JENNY is knowledgeable about literature , JENNY is well-read or studying literature', 'last_speaker': 'JENNY'}\n",
      "Last word -> JENNY : \"Isn't it because Mr Rochester's blind?\"\n",
      "prediction :  [She sits on a seat. The lights are low] Not again.\n",
      "Real answer : Isn't it because Mr Rochester's blind?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8401919603347778], 'recall': [0.8140016794204712], 'f1': [0.8268894553184509], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 106.7236557006836\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMISS STUBBS: Jenny, could I have a word?\\nJENNY: Of course.(To Hattie and Tina) I'll catch you up.\\nMISS STUBBS: You can do anything you want, Jenny. You know that. You're clever and you're pretty... But sometimes those things fight. I'm worried that at the moment clever\\nJENNY: What do you mean?\\nMISS STUBBS: I couldn't bear it if clever Jenny lost. It's because of people like you that I plough through illiterate essays by Sandra Lovell about her pony. And there aren't many of you, I can tell you. One every few years. Is your boyfriend interested in clever Jenny?\\nJENNY: I think so.\\nMISS STUBBS: Interested enough to let her do what she wants?\\nJENNY: He couldn't stop me.\\nMISS STUBBS: He might not have to stop you. That's what I'm trying to tell you.\\nJENNY: I'm not sure what you're trying to tell me.\\nMISS STUBBS: I'm telling you to go to Oxford. No matter what. Or you'll break my heart.\\nJENNY: Where did you go? Sorry? Where did you go? Which university?\\nMISS STUBBS: Girton. Cambridge.\\nJENNY: Oh.\\nMISS STUBBS: What does that mean? `Oh'?\\nJENNY: You're clever. And you're pretty. So presumably, Clever Miss Stubbs won. And here you are, reading all those pony essays. I don't know. These last few months, I've been to Paris, and to jazz clubs, and I've eaten in wonderful restaurants, and seen wonderful films, heard beautiful music...\\nMISS STUBBS: I'm sure you have. But I was filled up with beautiful things, books and music and conversation, in exactly the same way at Cambridge. And I didn't have to pay the same sort of price. Are you taking precautions, Jenny?\\nJENNY: It's nothing to do with that.\\nMISS STUBBS: Isn't it?\\nJENNY: Maybe our lives are always going to end up with pony essays. Or housework. And yes, maybe we'll go up to Oxford. But if we're all going to die the moment we graduate, maybe it's what we do before that counts.\\nMISS STUBBS: I'm sorry you think I'm dead.\\nJENNY: I don't think you're dead. But...\\n\\n\", 'answer': \"You'd better get to your next class.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MISS STUBBS'}\n",
      "Last word -> MISS STUBBS : \"You'd better get to your next class.\"\n",
      "prediction :  If you're just thinking about going to university in order to be clever, you should think about it. What is smart? I'd like to think that the smart thing is to do what makes sense to you. Your mother likes your brother a lot, she's very good at giving advice. And she's very good at remembering to read things to you. I do my very best to remember that it's not what you are that makes sense, it's what is\n",
      "Real answer : You'd better get to your next class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8077589273452759], 'recall': [0.8494759202003479], 'f1': [0.8280923366546631], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0851063829787234, 'rouge2': 0.0, 'rougeL': 0.0851063829787234, 'rougeLsum': 0.0851063829787234}\n",
      "bleu 1/2 : 0.025 0.00562543950463012\n",
      "ppl : 12.522440910339355\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJENNY: This is lovely. But it is. Really. I'd love to live somewhere like this.\\nMISS STUBBS: Oh, it's not hard. Go to Oxford and become a teacher and this is what you end up with.\\nJENNY: But all these books and pictures.... Yes, but...That's all you need, isn't it? Just a place to...I'm sorry I said those silly things. I didn't understand.\\nMISS STUBBS: Let's forget all about it.\\nJENNY: A Burne-Jones. What?\\nMISS STUBBS: You make it sound as though it's an original. Do you like him?\\nJENNY: Yes. I do. Still.\\nMISS STUBBS: Still? Gosh, you sound very old and wise.\\nJENNY: I feel old. But really not very wise. Miss Stubbs, I'm....I need your help.\\n\\n\", 'answer': \"I was so hoping that's what you were going to say.\", 'gold_tag': 'MISS STUBBS is willing to offer help', 'last_speaker': 'MISS STUBBS'}\n",
      "Last word -> MISS STUBBS : \"I was so hoping that's what you were going to say.\"\n",
      "prediction :  I have been told you were here.\n",
      "Real answer : I was so hoping that's what you were going to say.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8916690349578857], 'recall': [0.8607574105262756], 'f1': [0.8759406208992004], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3157894736842105, 'rouge2': 0.11764705882352942, 'rougeL': 0.3157894736842105, 'rougeLsum': 0.3157894736842105}\n",
      "bleu 1/2 : 0.24202205228903967 0.1509272666182457\n",
      "ppl : 66.5102310180664\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTYLER: Hey. It's Tyler.\\nALLY: Hi.\\nTYLER: You're going to stand me up. I can feel it in my bones. I'll be devastated.\\nALLY: No... I...I was just...\\nTYLER: You were just sitting around in your pajamas watching T.V.\\n\\n\", 'answer': \"No. I'm not watching T.V. I'm just...getting dressed. And I'm going to meet you at the place at..what time again? Right...yes. Eight...okay. Shit.\", 'gold_tag': 'ALLY is getting dressed for the meet-up , ALLY is preparing to meet TYLER at a predetermined location at eight', 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"No. I'm not watching T.V. I'm just...getting dressed. And I'm going to meet you at the place at..what time again? Right...yes. Eight...okay. Shit.\"\n",
      "prediction :  I was actually reading.\n",
      "Real answer : No. I'm not watching T.V. I'm just...getting dressed. And I'm going to meet you at the place at..what time again? Right...yes. Eight...okay. Shit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8791261315345764], 'recall': [0.8070510029792786], 'f1': [0.8415481448173523], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05714285714285715, 'rouge2': 0.0, 'rougeL': 0.05714285714285715, 'rougeLsum': 0.05714285714285715}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 446.43682861328125\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALLY: Really? I had a nice time.\\n\\n', 'answer': \"You had a nice time or you're having a nice time? Because if you're having one, why rush to end it?\", 'gold_tag': \"TYLER is inquiring about the current status of ALLY's enjoyment\", 'last_speaker': 'TYLER'}\n",
      "Last word -> TYLER : \"You had a nice time or you're having a nice time? Because if you're having one, why rush to end it?\"\n",
      "prediction :  Who said that?\n",
      "Real answer : You had a nice time or you're having a nice time? Because if you're having one, why rush to end it?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8526056408882141], 'recall': [0.8065581917762756], 'f1': [0.8289429545402527], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 262.03839111328125\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTYLER: Did I tell you I'm Caucasian?\\nALLY: Apparently. Can't we just stroll while I feed you ice cream with fireworks in the\\nTYLER: No. If I stop, he wins.\\nALLY: Who, the attendant?\\n\\n\", 'answer': 'No, the frigging Giant Panda.', 'gold_tag': \"TYLER's humor is more sarcastic and dry\", 'last_speaker': 'TYLER'}\n",
      "Last word -> TYLER : \"No, the frigging Giant Panda.\"\n",
      "prediction :  We were eating and drinking, what you were doing.\n",
      "Real answer : No, the frigging Giant Panda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8260430097579956], 'recall': [0.8342980146408081], 'f1': [0.8301500082015991], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 104.5973129272461\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALLY: I don't know what you're smiling about.\\nTYLER: I won.\\nALLY: Paying off the attendant is not winning... It's cheating.\\nTYLER: I just paid a premium to cut out the middle man. That's innovation. That's free market enterprising. That's what made America great.\\nALLY: Aha. By the way, what happened to your eye?\\nTYLER: Oh, it's nothing, just a bar fight.\\nALLY: How butch.\\nTYLER: I know. I'm practically a pirate.\\nALLY: Okay, Captain Morgan...\\nTYLER: You've got some serious timing. I'll walk you to the train.\\n\\n\", 'answer': \"I'll take a cab.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"I'll take a cab.\"\n",
      "prediction :  I'll walk you to the train.\n",
      "Real answer : I'll take a cab.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9209606051445007], 'recall': [0.9191555976867676], 'f1': [0.9200572371482849], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.2, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0.16666666666666669 0.05773502691896258\n",
      "ppl : 37.384952545166016\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTYLER: I know. But we have coasters.\\nALLY: I don't do coasters till the third date. Is that you?\\nTYLER: That's Michael. My brother.\\nALLY: He looks like you... or you look like him. Does he play around here?\\nTYLER: Not any more.\\nALLY: Do you play?\\nTYLER: It depends who you ask.\\nALLY: If I asked anybody?\\nTYLER: They'd say no. I try but it turns out you need talent.\\nALLY: So what talents do you actually have?\\nTYLER: Falconry. I come from a long line of falconers.\\nALLY: There's a lot of money in that.\\nTYLER: Well there is one thing...\\nALLY: What's that?\\n\\n\", 'answer': 'Our appetizer. It used to say \"In Case Of Asteroid\" but I took a shower and', 'gold_tag': 'Everyday Language', 'last_speaker': 'TYLER'}\n",
      "Last word -> TYLER : \"Our appetizer. It used to say \"In Case Of Asteroid\" but I took a shower and\"\n",
      "prediction :  The only thing I'm good at is talking.\n",
      "Real answer : Our appetizer. It used to say \"In Case Of Asteroid\" but I took a shower and\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8545629978179932], 'recall': [0.8420032262802124], 'f1': [0.8482366800308228], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.587234497070312\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALLY: So what kind of grade did you end up with from Vogelstein?\\nTYLER: I don't actually get grades. Beat. I'm not technically enrolled. I worked out an auditing thing.\\nALLY: Oh. And The Strand is not a significant career choice.\\nTYLER: I like the books. You don't have to help me, you know.\\nALLY: At the rate you're going, dish washing is going to be your life's vocation. I can say I knew you when. This is the playful, you get me all wet part? Right?\\nTYLER: You make it sound so cheap.\\nALLY: hundred times.\\nTYLER: I'm sorry. I didn't...\\n\\n\", 'answer': \"You know what never happens in this scene, Tyler-who-doesn't-really-go- to-school? Tyler-who-doesn't-really care-about-his-job? This. No, that usually never happens.\", 'gold_tag': \"ALLY is concerned about Tyler's future , TYLER is easy-going and does not engage in the usual life path\", 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"You know what never happens in this scene, Tyler-who-doesn't-really-go- to-school? Tyler-who-doesn't-really care-about-his-job? This. No, that usually never happens.\"\n",
      "prediction :  What did you do down there?\n",
      "Real answer : You know what never happens in this scene, Tyler-who-doesn't-really-go- to-school? Tyler-who-doesn't-really care-about-his-job? This. No, that usually never happens.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8305372595787048], 'recall': [0.7929735779762268], 'f1': [0.8113209009170532], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1081081081081081, 'rouge2': 0.0, 'rougeL': 0.05405405405405405, 'rougeLsum': 0.05405405405405405}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 69.30535125732422\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTYLER: Apologize.\\nALLY: Never. Your middle name is Keats? Your parents are pretentious as hell.\\nTYLER: Apologize.\\nALLY: I'd rather eat monkeys.\\nTYLER: I surrender! Oh my God, you're relentless.\\n\\n\", 'answer': 'Victory at all costs.', 'gold_tag': 'ALLY is competitive and displays a relentless pursuit of victory', 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"Victory at all costs.\"\n",
      "prediction :  I don't know why,\n",
      "Real answer : Victory at all costs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8229593634605408], 'recall': [0.8019507527351379], 'f1': [0.812319278717041], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18.193538665771484\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALLY: You like?\\nTYLER: Let's just skip dinner and I'll tell you how great you look in like eighteen different languages.\\nALLY: You just want to skip dinner. I got you a tie.\\nTYLER: I was going to make a joke about how I'm not prepared for the commitment of exchanging accessories and how neck wear especially is a slippery slope, but I should probably shut up and say thank you.\\n\\n\", 'answer': \"You're learning.\", 'gold_tag': 'ALLY has a thoughtful nature', 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"You're learning.\"\n",
      "prediction :  All right, I got your tie.\n",
      "Real answer : You're learning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8524534702301025], 'recall': [0.8905012607574463], 'f1': [0.8710620403289795], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 192.4957733154297\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALLY: Where are you going?\\nTYLER: I have something I've got to do.\\nALLY: Now?\\n\\n\", 'answer': 'Are you capable of taking care of yourself for an hour? Do you need me here every minute, or what?', 'gold_tag': 'Tyler is responsible enough to look after Ally , Tyler has to do something for the next hour', 'last_speaker': 'TYLER'}\n",
      "Last word -> TYLER : \"Are you capable of taking care of yourself for an hour? Do you need me here every minute, or what?\"\n",
      "prediction :  Yes, I've got to look at the camera.\n",
      "Real answer : Are you capable of taking care of yourself for an hour? Do you need me here every minute, or what?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8664014339447021], 'recall': [0.8278465270996094], 'f1': [0.8466852903366089], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 37.00456619262695\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALLY: He banged an Inuit! She's really nice. And smart. I don't get it. What's going on?\\nTYLER: Your dad was here.\\nALLY: What?\\nTYLER: When I got home.\\nALLY: I hate him!\\nTYLER: There's more. He knows me. Before I met you. He arrested me and Aidan. He gave me that gash over my eye.\\nALLY: I don't understand.\\nTYLER: I mouthed off to him. He ... responded. Then Aidan saw you guys together at school. Aidan suggested...I...introduced myself to you. Ally...\\nALLY: I'm going to be sick.\\nTYLER: Hey. Don't do that. What are you doing?\\nALLY: Do you realize what you've done?\\nTYLER: Yeah.\\nALLY: Did you think I would never find out? I mean, think about it. I had to find out eventually. You set it up that way.\\nTYLER: But it doesn't mean anything. I didn't mean to hurt you,\\n\\n\", 'answer': \"No. That's exactly what you meant to do.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"No. That's exactly what you meant to do.\"\n",
      "prediction :  That's a good one.\n",
      "Real answer : No. That's exactly what you meant to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8983007669448853], 'recall': [0.8637320399284363], 'f1': [0.8806772828102112], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2857142857142857, 'rouge2': 0.16666666666666666, 'rougeL': 0.2857142857142857, 'rougeLsum': 0.2857142857142857}\n",
      "bleu 1/2 : 0.09196986029286058 0.033582644728665616\n",
      "ppl : 26.200244903564453\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALLY: Using the little sister is dirty pool.\\nTYLER: Is it working? Beat.\\n\\n', 'answer': 'Maybe.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"Maybe.\"\n",
      "prediction :  This is just what I need. The world needs me, so I'll do it. I'll be the one who'll save us from the evil, and bring peace into the world.\n",
      "Real answer : Maybe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8282115459442139], 'recall': [0.9252766370773315], 'f1': [0.8740575909614563], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 10.445451736450195\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTYLER: Hey...Hey.\\nALLY: Hmmm.\\nTYLER: I'll be back in an hour. I have to stop by my dad's office.\\nALLY: Do you want french toast or pancakes for breakfast?\\nTYLER: Whichever tastes better a la mode.\\nALLY: Say hi to your dad for me.\\nTYLER: If I said I love you... what would you say?\\nALLY: I love you.\\n\\n\", 'answer': 'I love you too.', 'gold_tag': 'TYLER is in a romantic relationship with ALLY', 'last_speaker': 'TYLER'}\n",
      "Last word -> TYLER : \"I love you too.\"\n",
      "prediction :  Hey...Hey.\n",
      "Real answer : I love you too.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8425724506378174], 'recall': [0.8537909984588623], 'f1': [0.8481446504592896], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1802.8621826171875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Erin -- hi. Sorry you had to wait. Here, sit down, sit down.\\nERIN: Thanks a lot. I tell you, I never thought just standing would take it out of me, but ever since that shithead hit me, it feels like my whole body's put together wrong.\\n\\n\", 'answer': \"Jesus, you poor thing. Well, listen, you came to the right place. Whoever did this to you made one hell of a mistake, and you and me, we're gonna make him pay for it. Why don't you tell me what happened?\", 'gold_tag': 'ED likely has a professional occupation where he can help people seek justice or compensation , ERIN is currently suffering from the negative effects of a recent car crash', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Jesus, you poor thing. Well, listen, you came to the right place. Whoever did this to you made one hell of a mistake, and you and me, we're gonna make him pay for it. Why don't you tell me what happened?\"\n",
      "prediction :  Yeah, well... I mean, you're not the only one there - everybody's got problems - it's just nice not to be alone right now.\n",
      "Real answer : Jesus, you poor thing. Well, listen, you came to the right place. Whoever did this to you made one hell of a mistake, and you and me, we're gonna make him pay for it. Why don't you tell me what happened?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8445353507995605], 'recall': [0.8460450172424316], 'f1': [0.8452894687652588], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23529411764705885, 'rouge2': 0.0, 'rougeL': 0.14705882352941177, 'rougeLsum': 0.14705882352941177}\n",
      "bleu 1/2 : 0.08207738127923497 0.013256692994720331\n",
      "ppl : 16.50189781188965\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: ... Matthew's six, Katie's four, and Beth's just nine months. ... just wanna be a good mom, a nice person, a decent citizen. Just wanna take good care of my kids. You know?\\n\\n\", 'answer': 'Yeah. I know.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Yeah. I know.\"\n",
      "prediction :  Yeah. I think just about any mom would do the same thing. They're pretty much perfect, you know.\n",
      "Real answer : Yeah. I know.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.841215968132019], 'recall': [0.9316916465759277], 'f1': [0.884145200252533], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2727272727272727, 'rouge2': 0.09999999999999999, 'rougeL': 0.2727272727272727, 'rougeLsum': 0.2727272727272727}\n",
      "bleu 1/2 : 0.16666666666666669 0.0990147542976674\n",
      "ppl : 24.079784393310547\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: Open and shut? Open and fucking shut?\\nED: If you hadn't used profanity --\\nERIN: Oh, please, it was long over by then. God damn, he made me look like some cheap --\\nED: I told you the questions might get a little personal --\\nERIN: Bullshit. You told me I'd get half a million dollars. You told me I'd be set.\\nED: Okay -- let's try and settle down here.\\nERIN: Settle down? I got 74 bucks to my name, Mr. Masry! I can't afford to settle down!\\nED: I'm sorry, Erin.\\n\\n\", 'answer': \"Yeah? Well, fuck you. Sorry doesn't feed my kids.\", 'gold_tag': \"ERIN's fiery personality and frustration\", 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Yeah? Well, fuck you. Sorry doesn't feed my kids.\"\n",
      "prediction :  Open and shut? Open and fucking shut?\n",
      "Real answer : Yeah? Well, fuck you. Sorry doesn't feed my kids.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8054834604263306], 'recall': [0.8469476699829102], 'f1': [0.8256953358650208], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 131.5106658935547\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Erin! How's it going?\\nERIN: You never called me back. I left messages.\\nED: You did? Wow, sorry about that. Listen, Mario's a little not so bright. He seems to think that you said --\\nERIN: There's two things I can't stand, Mr. Masry. Being ignored, and being lied to. You did both.\\nED: I never lied. I may have miscalculated -- that happens sometimes, but --\\nERIN: You said things would be fine, and they're not.\\nED: I'm sorry about that. Really. But --\\nERIN: I don't need pity. I need a paycheck. And I've looked, but when you've spent the last six years raising babies, it's real hard to convince someone to give you a job that pays worth a damn. So I figure, since you're the one who said I was gonna be okay, you should be the one to hire me.\\nED: I'd love to help, Erin, but I'm sorry, I have a full staff right now, so --\\nERIN: Bullshit. If you had a full staff, you'd have time to return your damn phone calls.\\nED: Okay, look. If you really want to apply for a job here, you can do it the way everyone else does. Send in a r�sum�, make an --\\nERIN: I'm not everyone else, Mr. Masry. I'm someone you made promises to that you didn't deliver on. I trusted you. With my kids' well-being. Now, I'm smart, and I'm hard- working, and I'll do anything. But if you think I'm leaving here without a job, you got another thing coming.\\n\\n\", 'answer': 'No benefits.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"No benefits.\"\n",
      "prediction :  Hey, Ryan.\n",
      "Real answer : No benefits.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8852826356887817], 'recall': [0.9011066555976868], 'f1': [0.893124520778656], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 550.0281372070312\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: Mr. Masry?\\nED: Yeah?\\nERIN: I was wondering -- could you tell me who I'd talk to about maybe getting an advance on my paycheck? Just -- for the weekend.\\nED: Jane's the office manager. She handles payroll and petty cash. But she leaves early on Fridays.\\nERIN: Oh. Okay. That's okay.\\nED: Oh, for Christ's sake ... All I have is hundreds.\\nERIN: I don't wanna take your money, Mr. Masry.\\n\\n\", 'answer': \"Bullshit, you don't.\", 'gold_tag': 'ED is willing to help out', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Bullshit, you don't.\"\n",
      "prediction :  Yeah?\n",
      "Real answer : Bullshit, you don't.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8301366567611694], 'recall': [0.802963376045227], 'f1': [0.81632399559021], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 67594.546875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: How long's she been crying like that? ... Well, she's got that tooth coming in -- Give her a cold washcloth to suck on -- I gotta go -- there's a clean one in that bag -- I'll check back in a bit. Sorry. My kid --\\nED: Where's Anna?\\nERIN: Out to lunch with the girls.\\nED: Oh. Huh. Well, look, I got this file I need valued.\\nERIN: Oh. Okay.\\nED: You do know how to do that, don't you?\\nERIN: Yeah. I got it. No problem.\\nED: Good. You're a girl.\\nERIN: Excuse me?\\nED: How come you're not at lunch with the girls? You're a girl.\\n\\n\", 'answer': \"I guess I'm not the right kind.\", 'gold_tag': \"ERIN distinguishes herself from 'the girls' that ED refers to\", 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"I guess I'm not the right kind.\"\n",
      "prediction :  Are we ready for today's class?\n",
      "Real answer : I guess I'm not the right kind.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8550167083740234], 'recall': [0.8573712706565857], 'f1': [0.8561922907829285], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 56.513126373291016\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: What are you doing here?\\nED: I got an interesting call this afternoon. It was from a Dr. Frankel.\\nERIN: Oh, yeah?\\nED: He wanted you to know the legal limit for hexavalent chromium, is .05 parts per million. And that at the rate you mentioned, .58, it could be responsible for the cancers in that family you asked about. The Irvings.\\nERIN: Well, that was nice of him. Isn't it funny how some people go out of their way to help people and others just give 'em the ax?\\nED: Look, I'm sorry. You were gone. I just assumed you were off having fun.\\nERIN: Now, why in the hell would you assume that?\\nED: I don't know. Maybe cause you look like someone who has a lot of fun.\\nERIN: Boy, are you ever a shitty judge of people.\\nED: So what's the story on this thing? This cancer stuff?\\nERIN: You wanna know, you gotta hire me back. I got a lot of bills to pay.\\n\\n\", 'answer': 'Fine.', 'gold_tag': 'Ed has a job where he has control over hiring people', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Fine.\"\n",
      "prediction :  Yeah, you bet.\n",
      "Real answer : Fine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8250761032104492], 'recall': [0.9381409883499146], 'f1': [0.8779834508895874], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 209.0410614013672\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: But, PG&E told her about the chromium?\\nERIN: They told her something, but it can't have been too specific, cause I talked to her, and she sure didn't think her water was bad.\\nED: So what made you think it was?\\nERIN: It doesn't take a genius to look at those medical records and think something's wrong.\\nED: What medical records?\\nERIN: The ones in the box of files. The box of files? The one from your office? Boy, you musta really fine-tooth-combed it then, huh? And you fired me. Jesus.\\nED: That document you found, the one that says it was the bad chromium -- you didn't happen to make a copy did you?\\nERIN: Course I did.\\nED: Lemme see it, will you?\\nERIN: I want a raise. And benefits. Including dental.\\nED: Look, Erin, this is not the way I do business, this extortion nonsense. Okay. A 5% raise, and --\\nERIN: There's a lot of other places I could work.\\nED: A ten percent raise and benefits. But that's it. I'm drawing the line. This is the only thing you found?\\nERIN: So far. But that place is a pig sty. I wouldn't be surprised if there's more.\\n\\n\", 'answer': 'Find out.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Find out.\"\n",
      "prediction :  Yeah, I know, but it doesn't mean anything.\n",
      "Real answer : Find out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.830849289894104], 'recall': [0.8679695725440979], 'f1': [0.8490038514137268], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.724271774291992\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: It's Sinatra's world, we just live in it. Hello? ... Hi, babys. Baby's fine. Yes, I did. I did, too, you just didn't feel it. You think I could leave without kissing my babys? Okay, here you go. Bye-bye ... bye-bye ... no, you. Okay, together. Bye-bye.\\n\\n\", 'answer': 'Um -- you mind pulling over? Just -- for a second?', 'gold_tag': 'ERIN feels uncomfortable , ERIN needs some private space , ERIN requested to pull over', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Um -- you mind pulling over? Just -- for a second?\"\n",
      "prediction :  Oh, this is a nice one too...\n",
      "Real answer : Um -- you mind pulling over? Just -- for a second?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8479411005973816], 'recall': [0.7986690998077393], 'f1': [0.822567880153656], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.08067401742967989 0.02755542282313655\n",
      "ppl : 54.664031982421875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Hunh-uh. Absolutely not.\\nERIN: That's crazy -- why not?\\n\\n\", 'answer': \"Because I said no. Look -- the only reason PG&E's even talking to us is cause this is a quiet little real estate dispute. We add plaintiffs, and suddenly we're in the middle of a toxic tort -- with a statute problem -- against a massive utility. No, thank you.\", 'gold_tag': 'ED is possibly a lawyer or professional involved in real estate disputes', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Because I said no. Look -- the only reason PG&E's even talking to us is cause this is a quiet little real estate dispute. We add plaintiffs, and suddenly we're in the middle of a toxic tort -- with a statute problem -- against a massive utility. No, thank you.\"\n",
      "prediction :  I'm not sure how it'd even happen.\n",
      "Real answer : Because I said no. Look -- the only reason PG&E's even talking to us is cause this is a quiet little real estate dispute. We add plaintiffs, and suddenly we're in the middle of a toxic tort -- with a statute problem -- against a massive utility. No, thank you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8522688150405884], 'recall': [0.8315106630325317], 'f1': [0.8417617678642273], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06779661016949154, 'rouge2': 0.0, 'rougeL': 0.06779661016949154, 'rougeLsum': 0.06779661016949154}\n",
      "bleu 1/2 : 0.0003069679258442461 0.00010484950742849092\n",
      "ppl : 22.15473175048828\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: Okay, so here's what I'll do. I'll go on up to Ted and Rita Daniels -- two of the nicest people you'd ever hope to meet, who spend every single day watching their little girl fight like a dog against this cancer -- I'll tell them we can't help them cause you don't feel like working that hard.\\nED: It's not about working hard --\\nERIN: Bullshit.\\nED: -- It's about being realistic. Something like this, Erin -- it could take forever. They're a huge corporation. They'd completely bury us in paperwork. I'm just one guy with a shitty little P.I. firm.\\n\\n\", 'answer': '-- who happens to know they poisoned people and lied about it.', 'gold_tag': 'ERIN is a champion for the people', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"-- who happens to know they poisoned people and lied about it.\"\n",
      "prediction :  I know, too difficult,\n",
      "Real answer : -- who happens to know they poisoned people and lied about it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8257439136505127], 'recall': [0.819932222366333], 'f1': [0.8228278160095215], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 281.523193359375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: And this shit is bad news, Mr. Masry. Not only does it attack every organ of the body, it fucks with your DNA, too. That means these people's genes, and the genes of their kids, and the genes of their grandkids --\\n\\n\", 'answer': 'I know how DNA works, Erin --', 'gold_tag': 'ED is knowledgeable about DNA', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"I know how DNA works, Erin --\"\n",
      "prediction :  What kind of weird DNA is doing that?\n",
      "Real answer : I know how DNA works, Erin --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8423605561256409], 'recall': [0.8323941826820374], 'f1': [0.8373477458953857], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714288, 'rouge2': 0.0, 'rougeL': 0.14285714285714288, 'rougeLsum': 0.14285714285714288}\n",
      "bleu 1/2 : 0.12500000000000003 0.04225771273642583\n",
      "ppl : 166.85792541503906\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: We can get these people. With a little effort, I really think we can nail their asses to the wall.\\nED: Oh, you do? With all your legal expertise, you believe that?\\n\\n', 'answer': \"Okay, fine. I don't know shit about shit. But I know the difference -- -- BETWEEN RIGHT AND WRONG!\", 'gold_tag': 'ERIN admits her lack of legal expertise', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Okay, fine. I don't know shit about shit. But I know the difference -- -- BETWEEN RIGHT AND WRONG!\"\n",
      "prediction :  The truth is pretty, simple ... and I'm so ready for it. No more waiting for your pity parties or your ... pitying me. You know, when you say things like \"I hope that all goes well for you.\" It's as if you don't really care because you already know it will - because you, being so lovely and helpful, have already planned it out. And you think I'd be able to stand it. But that's not my concern\n",
      "Real answer : Okay, fine. I don't know shit about shit. But I know the difference -- -- BETWEEN RIGHT AND WRONG!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8160027861595154], 'recall': [0.8304327130317688], 'f1': [0.8231545686721802], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1818181818181818, 'rouge2': 0.020618556701030927, 'rougeL': 0.10101010101010101, 'rougeLsum': 0.10101010101010101}\n",
      "bleu 1/2 : 0.03797468354430379 0.006977498959044452\n",
      "ppl : 15.03950309753418\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Damn it. How many families we talking about here?\\nERIN: Four more. Eleven people. So far.\\nED: You think there's more?\\nERIN: Well -- I found one document at the water board that had a toxic test well reading from 1967. A hell of a lot of people have lived on that land since then.\\nED: This is a whole different ball game, Erin. A much bigger deal.\\nERIN: Kinda like David and what's-his-name?\\nED: Kinda like David and what's-his-name's whole fucking family. Okay, here's the deal -- if, and only if, you find me the evidence to back all this up -- I'll do it. I'll take it on.\\nERIN: You're doing the right thing, Mr. Masry.\\nED: Yeah, yeah. Remind me of that when I'm filing for bankruptcy.\\nERIN: Course, gathering evidence -- now, that's a big job. A hell of a lot bigger than just filing. I'm gonna be working a lot harder now, taking on a lot more responsibility ...\\nED: What now?\\n\\n\", 'answer': \"Another raise wouldn't hurt. And with all the time I'm gonna be spending on the road, I'll probably be needing my own cel phone, won't I?\", 'gold_tag': 'ERIN is not afraid to negotiate for a raise and additional resources for her work , ERIN anticipates needing more resources like a cell phone due to increased time spent on the road', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Another raise wouldn't hurt. And with all the time I'm gonna be spending on the road, I'll probably be needing my own cel phone, won't I?\"\n",
      "prediction :  What about the time when he was in his dad's office, looking for his papers -- and that piece of paper, that he needed to open a bank account. He just walked off, never came back. That's what happened. I was talking to some people over in our department -- just regular folks, not real officials, nothing special. Just about regular folks -- but I thought I'd let you know. I was wondering if you could get me their number.\n",
      "Real answer : Another raise wouldn't hurt. And with all the time I'm gonna be spending on the road, I'll probably be needing my own cel phone, won't I?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8217658996582031], 'recall': [0.8225194215774536], 'f1': [0.822142481803894], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10909090909090907, 'rouge2': 0.018518518518518517, 'rougeL': 0.09090909090909091, 'rougeLsum': 0.09090909090909091}\n",
      "bleu 1/2 : 0.025 0.017789201674120497\n",
      "ppl : 20.15934181213379\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Is that what I think it is?\\n\\n', 'answer': 'She lived on the plume. You never know.', 'gold_tag': 'ERIN has experience dealing with a case related to the plume area , ED and ERIN have worked on or discussed a case involving a person who lived on the plume', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"She lived on the plume. You never know.\"\n",
      "prediction :  It does look a lot like a phone booth to me.\n",
      "Real answer : She lived on the plume. You never know.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8458194136619568], 'recall': [0.8627781867980957], 'f1': [0.8542146682739258], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 40.8738899230957\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: They used the hex chrom here, in these cooling tanks, as an anti-corrosive. Then they dumped it here, in these six ponds.\\nED: I don't remember seeing any ponds up there.\\nERIN: They covered 'em over. And not too carefully either, cause you dig one inch under the surface, and the dirt is green as\\nED: And that's what caused the contamination?\\nERIN: It didn't help, but no. The real problem's on the bottom. See, according to this, they were supposed to line the ponds so this shit couldn't seep into the ground. But guess what --\\nED: They skipped that step.\\nERIN: I guess it was a little too inconvenient. So for fourteen years, this stuff flowed into the groundwater, free as you please.\\nED: Jesus. I don't even wanna ask what you did to make this Melendez guy talk.\\nERIN: For your information, Frank cares what was in those ponds 'cause he used to spend half his day wading around them. That was his job.\\nED: No shit.\\n\\n\", 'answer': 'No -- SHIT! SHIT! Hot! Hot! Hot! You ... asshole ...', 'gold_tag': 'Everyday Language', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"No -- SHIT! SHIT! Hot! Hot! Hot! You ... asshole ...\"\n",
      "prediction :  How long are we sitting around outside?\n",
      "Real answer : No -- SHIT! SHIT! Hot! Hot! Hot! You ... asshole ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8133485913276672], 'recall': [0.747628390789032], 'f1': [0.779105007648468], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 378.0323791503906\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Erin -- lemme tell you something. If I'da put three researchers on this, I wouldn't expect them to dig up all the information you got here. This is some damn good work.\\nERIN: Yeah? Then gimme another raise.\\nED: Hey, I got a staff to pay, plus rent, plus I haven't billed a minute of my time since I started on this case, so you can quit hitting me up like I'm rich or something.\\nERIN: Don't give me that. You're gonna get plenty rich off of this, Mr. 40 percent. We got those PG&E fuckers by the balls here.\\nED: We've got the PG&E fuckers in Hinkley by the balls. But nobody's getting rich unless we can pin this on the corporate PG&E fuckers in San Francisco.\\nERIN: What do you mean?\\nED: PG&E corporate is claiming they had no way of knowing what was going on in Hinkley.\\nERIN: Oh, they knew. They had to know.\\nED: Show me the document that proves that. Then they didn't know. And if they didn't know, we can't hit 'em for punitive damages. And punitive damages is where the money is.\\nERIN: Jesus Christ, Ed -- you know, the more I work on this thing, the more I realize what a crock of shit this legal system is. Here we got a company that poisoned a whole aquifer -- that built a pool for a town, then filled it with toxic water -- and we're the ones who've gotta bust our ass proving things? That's just not right.\\nED: I like this case.\\nERIN: Really? It makes me sick.\\nED: Me too. That's why I like it. It's been a long time since I had a case I cared about.\\nERIN: You didn't care about my case?\\nED: I would now. Hey. I like working with you.\\nERIN: Well, good, Ed. I like working with you too.\\n\\n\", 'answer': \"When'd you start calling me Ed?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"When'd you start calling me Ed?\"\n",
      "prediction :  If you wanna talk, any time you want to catch up, just call me.\n",
      "Real answer : When'd you start calling me Ed?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8466792106628418], 'recall': [0.8493960499763489], 'f1': [0.8480355143547058], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.19047619047619047, 'rouge2': 0.0, 'rougeL': 0.19047619047619047, 'rougeLsum': 0.19047619047619047}\n",
      "bleu 1/2 : 0.07142857142857141 0.023440361546924773\n",
      "ppl : 27.42043685913086\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: Jesus. They look like the Secret Service.\\n\\n', 'answer': \"They're trying to intimidate us. Tell them to wait in the conference room.\", 'gold_tag': 'ED is in a position of authority , ED directs ERIN on what to do', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"They're trying to intimidate us. Tell them to wait in the conference room.\"\n",
      "prediction :  They're not the Secret Service. They're the Secret Service.\n",
      "Real answer : They're trying to intimidate us. Tell them to wait in the conference room.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8753713369369507], 'recall': [0.8835970163345337], 'f1': [0.8794649839401245], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23999999999999996, 'rouge2': 0.08695652173913043, 'rougeL': 0.23999999999999996, 'rougeLsum': 0.23999999999999996}\n",
      "bleu 1/2 : 0.14248453076221212 0.03379317364116882\n",
      "ppl : 17.1185359954834\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Hey. A new plaintiff called, wants to meet you. I told him we'd be out there Thursday.\\nERIN: D'you get his name? Course not. Jesus, Ed --\\nED: He said he'd be at the gas station at six.\\n\\n\", 'answer': 'Boy, this job takes me to some of the best damn places, huh?', 'gold_tag': 'Everyday Language', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Boy, this job takes me to some of the best damn places, huh?\"\n",
      "prediction :  What do you think?\n",
      "Real answer : Boy, this job takes me to some of the best damn places, huh?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8224612474441528], 'recall': [0.8169595003128052], 'f1': [0.8197011947631836], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 48.49069595336914\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: Someone's following me.\\nED: What? Who?\\nERIN: Some guy in a truck -- he waited till I was alone, then he followed me, like, two miles. Jesus, I'm shaking. Get me a beer.\\nED: Beer, please. What kind of truck? He's gone. Did you get a license plate? Or a make?\\nERIN: No, Ed -- what with me running for my life, I didn't have time to check those things --\\nED: I was just asking. Are you all right?\\nERIN: Yeah. Yeah, I'm ... fine.\\n\\n\", 'answer': \"Jesus, you look like shit. When was the last time you had a decent night's sleep?\", 'gold_tag': 'ED is accommodating and considerate', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Jesus, you look like shit. When was the last time you had a decent night's sleep?\"\n",
      "prediction :  Are you OK, Erin? You looked upset.\n",
      "Real answer : Jesus, you look like shit. When was the last time you had a decent night's sleep?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8806174993515015], 'recall': [0.8569605946540833], 'f1': [0.8686279654502869], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.03949329237565206 0.013489527418631811\n",
      "ppl : 126.0315933227539\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Lock the door every which way you can. And if there's anything -- funny sound, whatever -- pound on the wall. I'll come right over.\\nERIN: I think you should know -- there's very few people in the world who don't piss me off 90 percent of the time. You're one of 'em.\\n\\n\", 'answer': \"I'm triple locking my door, so don't even think of trying to take advantage.\", 'gold_tag': 'ED is cautious and protective', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"I'm triple locking my door, so don't even think of trying to take advantage.\"\n",
      "prediction :  Do you have, like, one line where you think I're kind of okay, or where you want to do your scene?\n",
      "Real answer : I'm triple locking my door, so don't even think of trying to take advantage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8305742740631104], 'recall': [0.8520792722702026], 'f1': [0.8411893248558044], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2105263157894737, 'rouge2': 0.0, 'rougeL': 0.15789473684210525, 'rougeLsum': 0.15789473684210525}\n",
      "bleu 1/2 : 0.14285714285714285 0.026726124191242442\n",
      "ppl : 50.585758209228516\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: I want my fucking money --\\nED: I'm sorry, I'm gonna have to put you on hold for just one second here -- Do you mind?\\nERIN: Yeah, I mind. You bet your ass I mind.\\nED: Oh, Jesus. You wanna tell me what the problem is here, or --\\nERIN: It's my paycheck. Which I earned. Which I deserve. Which I shouldn't have to beg for. That fat-ass bitch won't give it to me.\\nED: Erin, you're a big girl. If you got a problem with Jane, work it out for yourself. I don't have time to deal with --\\nERIN: Fuck you. Make time. Cause I bust my ass for you. I watch everything else in my life go straight in the toilet, for you. And what do you do for me? Huh? You see the way I'm treated around here -- but have you ever stood up for me once? Have you ever mentioned to everyone what good work I'm doing? Have you ever bothered saying, hey, the best tits; she gets paid the most cause she's the best God damn employee I've ever had?\\nED: Is that what you want?\\nERIN: I want my paycheck. By the end of the day.\\nED: I'll see what I can do.\\n\\n\", 'answer': \"You might want to think real hard about the amount, too. My kids are sitting in the God damn parking lot right now, cause I still don't make enough to afford good child care. Makes me think about looking around for a job where I'm appreciated, for shit's sake.\", 'gold_tag': \"ERIN perceives herself as undervalued and underpaid , ERIN is a mother who struggles to provide for her children due to her financial situation , ERIN's job takes a significant toll on her personal life , ERIN experiences financial concerns and needs to make arrangements for child care\", 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"You might want to think real hard about the amount, too. My kids are sitting in the God damn parking lot right now, cause I still don't make enough to afford good child care. Makes me think about looking around for a job where I'm appreciated, for shit's sake.\"\n",
      "prediction :  I need to call my dad to make him understand what it is like to live with me. And what a pain it is to be your daughter.\n",
      "Real answer : You might want to think real hard about the amount, too. My kids are sitting in the God damn parking lot right now, cause I still don't make enough to afford good child care. Makes me think about looking around for a job where I'm appreciated, for shit's sake.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8533985018730164], 'recall': [0.8267761468887329], 'f1': [0.8398764133453369], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17500000000000002, 'rouge2': 0.0, 'rougeL': 0.15, 'rougeLsum': 0.15}\n",
      "bleu 1/2 : 0.08435117013232406 0.01214795691633062\n",
      "ppl : 15.870749473571777\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: Believe it or not, I would've been satisfied with just the check.\\nED: Well, you go threatening to leave, I can't take any chances. You're the only person around who understands what I'm doing. Things come up, I gotta know I got someone to turn to.\\nERIN: What kind of things come up?\\nED: Things like the head counsel for PG&E calling me with an offer. 20 million, plus attorney's fees. Take it or leave it.\\nERIN: Whoa. No shit.\\nED: It's about 50 thousand per plaintiff.\\nERIN: So what are you thinking?\\nED: I'm thinking ... I wish someone else had to make this decision. 50 thousand bucks is more than any other California toxic plaintiff has gotten. Ever. But ...\\nERIN: ... but it won't cover Annabelle Daniels's medical bills.\\nED: And it's less than pocket change for PG&E.\\nERIN: Do you think we'd do better by going to trial?\\nED: Maybe. but maybe not. We still don't have anything linking this to PG&E corporate. Plus, there's the statute problem. Plus, we're way short on manpower, so we'd need to bring on more lawyers ...\\nERIN: Plus, 40 percent of 20 million's a whole lot of money.\\nED: It's eight million dollars, Erin. Eight million dollars.\\nERIN: That's a fucking fortune, Ed. And you know I'm the last person on Earth to walk away from a big payday. But you and me didn't get into this to get rich. We did it cause we both have this voice in our heads saying, do the right thing; get these plaintiffs what they deserve -- the right to live and die in some kind of comfort and peace. If 50,000 isn't gonna buy that, then we gotta say no. Trust me. If you don't do the right thing for these people, getting that 6 million dollars is gonna feel like shit.\\n\\n\", 'answer': 'I knew I put up with your bullshit for a reason.', 'gold_tag': 'ED demonstrates a level of fear in being left to handle the case alone', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"I knew I put up with your bullshit for a reason.\"\n",
      "prediction :  0.6   0.8   1.0\n",
      "Real answer : I knew I put up with your bullshit for a reason.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8151774406433105], 'recall': [0.8394392728805542], 'f1': [0.8271304965019226], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13.799365997314453\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: Holy shit. Who do they represent, God?\\nED: Don't joke. They might. So do me a favor and behave yourself for once. Ed Masry to see Kurt Potter.\\n\\n\", 'answer': \"Scuse me, sir, you got a real nice ass, you know that? Oh, I'm sorry. Was that not what you meant by behaving myself?\", 'gold_tag': 'ERIN is a forthright and uninhibited individual , ERIN uses humor and flirtatious comments in formal settings', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Scuse me, sir, you got a real nice ass, you know that? Oh, I'm sorry. Was that not what you meant by behaving myself?\"\n",
      "prediction :  Is this a joke or did he really do that?\n",
      "Real answer : Scuse me, sir, you got a real nice ass, you know that? Oh, I'm sorry. Was that not what you meant by behaving myself?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.855133593082428], 'recall': [0.8194774389266968], 'f1': [0.8369258642196655], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11428571428571428, 'rouge2': 0.0, 'rougeL': 0.11428571428571428, 'rougeLsum': 0.11428571428571428}\n",
      "bleu 1/2 : 0.0493193927883213 0.011624692361541632\n",
      "ppl : 40.95785903930664\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: She insulted me!\\nED: Bullshit. It was a misunderstanding. But instead of handling it politely, instead of treating her with respect --\\nERIN: Why the fuck should I respect her?\\nED: Because that's how people treat each other!\\nERIN: Not in my world.\\nED: Gee, I wonder why.\\n\\n\", 'answer': \"Hey! You're my ride!\", 'gold_tag': 'ERIN is dependent on ED for transportation', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Hey! You're my ride!\"\n",
      "prediction :  How dare he say that!\n",
      "Real answer : Hey! You're my ride!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8502171039581299], 'recall': [0.8629820346832275], 'f1': [0.856552004814148], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 144.30699157714844\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: If you tell me to relax, I\\'m gonna kick your fucking head off --\\nED: Erin, it\\'s just a meeting.\\nERIN: People don\\'t fly down in their own god damn plane for \"just a meeting\" --\\nED: Look, you said you weren\\'t feeling great. I thought you should rest.\\nERIN: Bullshit. You\\'d drag me off my deathbed if it suited you.\\nED: Okay, look. It\\'s an important meeting. Kurt thought, if it was just lawyers --\\nERIN: Kurt thought? What about you? Do you think anymore?\\nED: Look, this is serious now. They\\'re talking serious money --\\nERIN: And, what, I\\'m not serious?\\nED: You\\'re emotional. You\\'re erratic. You say any God damn thing that comes into your head. And I\\'m not saying that\\'s bad. That can be great; that can be a lot of fun --\\nERIN: \"Fun?\" Jesus, \"fun?\" I kill myself for a year and a half, hand you the best case of your life on a God damn silver platter, remind you of why you became a lawyer in the first place, and you think of me as \"fun?\"\\nED: Okay, now you\\'re making this personal, and it isn\\'t --\\nERIN: Not personal? That\\'s my work in there, Ed. My sweat, my labor, my time. If that\\'s not personal, I don\\'t know what is. How dare you take that away from me.\\nED: No one\\'s taking anything --\\nERIN: Bullshit. You stuck me in Siberia dictating to some God damn steno clerk so you could finish this thing without me. After all I\\'ve done for you, that\\'s the thanks I get.\\nED: Don\\'t give me that. You\\'ve gotten plenty. You\\'ve been well-paid; you\\'ve gotten lots of perks ...\\n\\n', 'answer': 'Perks? Jesus -- perks? If this piece of shit is supposed to take the place of your respect, you can take it and shove it up your ass.', 'gold_tag': 'ERIN feels underappreciated and disrespected', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Perks? Jesus -- perks? If this piece of shit is supposed to take the place of your respect, you can take it and shove it up your ass.\"\n",
      "prediction :  If I'm not to \"get lots of perks,\" then what do I do? You wanna try me? -- You wanna try me? We'll try! How's that sound?\n",
      "Real answer : Perks? Jesus -- perks? If this piece of shit is supposed to take the place of your respect, you can take it and shove it up your ass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8329549431800842], 'recall': [0.8349733352661133], 'f1': [0.8339629769325256], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17857142857142858, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.14276154730389426 0.02300257517967063\n",
      "ppl : 26.536556243896484\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: Between 50 and 400 million, definitely?\\nED: Uh-huh.\\nERIN: And if you had to guess ...\\nED: With nothing linking it to the corporate offices yet, I'd say we'll end up on the lower end of that. Still a lot of money.\\nERIN: So why would PG&E offer it?\\nED: Because. They know the evidence; they know they're gonna lose a jury trial. Maybe they wouldn't lose 400 million bucks, but once you factor in all they'd spend on this case in the next ten years, it makes a lot of --\\nERIN: Wait, what do you mean, ten years?\\nED: Five years, maybe, for a trial. Double that for the appeal.\\nERIN: I'm sorry, are you saying that if this thing goes to trial, it'll be ten years before these plaintiffs see their money?\\nED: Hey, that's not so bad. Compare it to the Love Canal -- that was twenty years ago, and those people still haven't seen a dime. So in legal terms, ten years is --\\nERIN: Fuck legal terms. We're talking about human beings here. Sick people. A whole bunch of them are gonna be dead in ten years. They need their money now! We gotta get 'em to agree to the arbitration, Ed. We gotta get every damn one of those plaintiffs to --\\nED: I know. We're having a meeting, it's all set up --\\nERIN: When? Where?\\nED: Tuesday at seven, at the Hinkley firehouse.\\nERIN: Okay, good. I think I should be the one to tell 'em, cause they trust me more than --\\nED: You're not gonna be there.\\nERIN: The fuck I'm not. I don't care what the doctor says --\\nED: This isn't doctor's orders. It's mine. I'm saying you can't come.\\nERIN: Why not?\\nED: Because Kurt doesn't want to work with you. He thinks you're a loose cannon.\\nERIN: Fuck Kurt.\\nED: Erin --\\nERIN: No, I'm serious. You know what Kurt Potter is? He's the kind of guy who never would have taken this case in the first place. He's the kind of guy who would have sold these plaintiffs down the river when PG&E offered 20 million. He doesn't work like us, Ed. There's no little voice in his head telling him to do the right thing.\\n\\n\", 'answer': \"Don't come, Erin. I mean it. If you do, I'm gonna have to fire you. Just ... concentrate on getting well.\", 'gold_tag': 'Erin is currently unwell, as indicated by Ed telling her to concentrate on getting better', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Don't come, Erin. I mean it. If you do, I'm gonna have to fire you. Just ... concentrate on getting well.\"\n",
      "prediction :  We start the arbitration on Tuesday. I don't know why you're so damn stubborn about the damn thing.\n",
      "Real answer : Don't come, Erin. I mean it. If you do, I'm gonna have to fire you. Just ... concentrate on getting well.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.865763783454895], 'recall': [0.8718118071556091], 'f1': [0.868777334690094], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23809523809523808, 'rouge2': 0.05, 'rougeL': 0.14285714285714282, 'rougeLsum': 0.14285714285714282}\n",
      "bleu 1/2 : 0.09405352498784599 0.021640728223007746\n",
      "ppl : 33.80498123168945\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: Morning!\\nED: Erin? What are you --\\nERIN: You know what, Mr. Potter? I completely forgot your birthday this year. And seeing as how you've been so good to me, I think that is a terrible oversight. So what I been doing over the last few days is I've been putting together a present for you. 635. They all signed. Every single one.\\nED: Ho - ly - shit.\\n\\n\", 'answer': \"Oh, now don't get all jealous, Ed. I got a little something for you, too. Internal PG&E documents, all about the contamination. The one I like best says, and I'm paraphrasing here, but it says yes, the water's poisonous, but it'd be better for all involved if this matter wasn't discussed with the neighbors. It's to the\", 'gold_tag': \"Erin is involved in the same project as Ed , The project focuses on PG&E's internal documents about water contamination\", 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Oh, now don't get all jealous, Ed. I got a little something for you, too. Internal PG&E documents, all about the contamination. The one I like best says, and I'm paraphrasing here, but it says yes, the water's poisonous, but it'd be better for all involved if this matter wasn't discussed with the neighbors. It's to the\"\n",
      "prediction :  Yeah. Not bad. But this gift really blows it away. It's the Potter.\n",
      "Real answer : Oh, now don't get all jealous, Ed. I got a little something for you, too. Internal PG&E documents, all about the contamination. The one I like best says, and I'm paraphrasing here, but it says yes, the water's poisonous, but it'd be better for all involved if this matter wasn't discussed with the neighbors. It's to the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8716510534286499], 'recall': [0.8187217116355896], 'f1': [0.8443577289581299], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.02631578947368421, 'rougeL': 0.12820512820512822, 'rougeLsum': 0.12820512820512822}\n",
      "bleu 1/2 : 0.010427899912055078 0.0017161210230038036\n",
      "ppl : 74.28224182128906\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Hey! I don't know what to say.\\nERIN: Say you were wrong.\\nED: I was wrong.\\nERIN: Say you shortchanged me and you shortchanged yourself.\\nED: I did. Both.\\nERIN: Say you'd be the luckiest son of a bitch on Earth if I didn't up and quit over all this.\\nED: The luckiest son of a bitch in the universe, Erin. The luckiest son of a bitch in history. But I know you're not gonna quit on me.\\nERIN: How do you know that?\\n\\n\", 'answer': 'Cause you got a little voice in your head saying, do the right thing. Give him another chance.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Cause you got a little voice in your head saying, do the right thing. Give him another chance.\"\n",
      "prediction :  You're an angel.\n",
      "Real answer : Cause you got a little voice in your head saying, do the right thing. Give him another chance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8726068139076233], 'recall': [0.8417760729789734], 'f1': [0.8569141626358032], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0909090909090909, 'rouge2': 0.0, 'rougeL': 0.0909090909090909, 'rougeLsum': 0.0909090909090909}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 75.22005462646484\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKENNY: Yes, sir.\\nGREEN: Can I help you?\\nKENNY: Yes, sir. I need a room\\n\\n', 'answer': 'I think we can do that. Come in.', 'gold_tag': 'GREEN is likely an employee or owner of a business , GREEN is possibly associated with a hotel as they are able to provide a room', 'last_speaker': 'GREEN'}\n",
      "Last word -> GREEN : \"I think we can do that. Come in.\"\n",
      "prediction :  You are checking in. This is a 3 star non-smoking hotel....\n",
      "Real answer : I think we can do that. Come in.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8556614518165588], 'recall': [0.8713607788085938], 'f1': [0.8634397983551025], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1, 'rouge2': 0.0, 'rougeL': 0.1, 'rougeLsum': 0.1}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 46.25747299194336\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKENNY: Kenneth Fraser. Glad to meet you... My wire's been in the hospital so things might be a little dusty, but You're in music, I guess, aren't you? 'Cause my niece sings most of the day. That won't bother you, will it?\\nGREEN: I didn't think it would. She's calling herself L.A. Joan this- week. Last week it was Dakota. Guess if you have to change your name a state's as good as anything.\\nKENNY: She sure sings nice.\\nGREEN: My wife and I think so, but we're family. Your family's always good or bad depending on how you look at your family. What do you do, pick or sing?\\nKENNY: Oh... a little of both. Just thought I'd look around at Nashville for a while.\\nGREEN: When you run out or money, 'cause you will here, you can go sing at Bishop's Pub. They let you pass the hat. All these kids do that. Most every place doesn't want to bother with you.\\nKENNY: I'm not really a musician.\\nGREEN: Well, don't be shy. I got the address here. Anytime you need it. Room's twenty-five dollar! a week and you can have breakfast with me if you like.\\nKENNY: Suits me. Listen, do you know anything about cars?\\n\\n\", 'answer': \"A little. What do you need? Get ready. We're going to the hospital. we're going.\", 'gold_tag': \"GREEN has some knowledge about cars , KENNY's spouse is in the hospital\", 'last_speaker': 'GREEN'}\n",
      "Last word -> GREEN : \"A little. What do you need? Get ready. We're going to the hospital. we're going.\"\n",
      "prediction :  Is something wrong?\n",
      "Real answer : A little. What do you need? Get ready. We're going to the hospital. we're going.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8194042444229126], 'recall': [0.8377374410629272], 'f1': [0.8284693956375122], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 597.3021850585938\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGREEN: Sure... you're a fine boy, Ken, you\\nKENNY: Okay... you get to sleep. I'll see you in the morning. Good night.\\n\\n\", 'answer': 'Good night,', 'gold_tag': \"GREEN has a good opinion about KENNY's character\", 'last_speaker': 'GREEN'}\n",
      "Last word -> GREEN : \"Good night,\"\n",
      "prediction :  OK, good night.\n",
      "Real answer : Good night,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9130120873451233], 'recall': [0.8921158313751221], 'f1': [0.9024430513381958], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.8, 'rouge2': 0.6666666666666666, 'rougeL': 0.8, 'rougeLsum': 0.8}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 253.4626007080078\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARMAND FL�CHARD: Mademoiselle...\\nARABELLA DE CHAVILLE: Tiens, voil� le petit Chopin. A qui ?\\nARMAND FL�CHARD: A toi, mademoiselle.\\n\\n', 'answer': 'Et bien, allons-y, mon vieux.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ARABELLA DE CHAVILLE'}\n",
      "Last word -> ARABELLA DE CHAVILLE : \"Et bien, allons-y, mon vieux.\"\n",
      "prediction :  Mademoiselle Arabelle, madame.\n",
      "Real answer : Et bien, allons-y, mon vieux.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7994507551193237], 'recall': [0.7888250350952148], 'f1': [0.7941023707389832], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 7281.048828125\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARMAND FL�CHARD: Oh, mon billet.\\nARABELLA DE CHAVILLE: Et bien, Tarzan ?\\n\\n', 'answer': 'Travaillons... mademoiselle, travaillons.', 'gold_tag': 'ARMAND FLÉCHARD is involved in some kind of work or job', 'last_speaker': 'ARMAND FL�CHARD'}\n",
      "Last word -> ARMAND FL�CHARD : \"Travaillons... mademoiselle, travaillons.\"\n",
      "prediction :  Est-ce que tu peux prendre mon billet ? Je veux acheter des tickets pour aller dans la gare.\n",
      "Real answer : Travaillons... mademoiselle, travaillons.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7902291417121887], 'recall': [0.7852413654327393], 'f1': [0.7877273559570312], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.242341995239258\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARMAND FL�CHARD: Nous allons attaquer aujourd'hui l'allegretto amoroso. Mais � quoi pensez-vous donc ?\\nARABELLA DE CHAVILLE: Oh, � autre chose. Oh, c'est pas pr�t de m'arriver. D'ailleurs, je n'aimerais jamais qu'un homme d'action, un homme comme moi. Et � Montpaillard... ... il n'y a que des nouilles !\\nARMAND FL�CHARD: Merci beaucoup, mademoiselle. Je suis donc... une nouille.\\nARABELLA DE CHAVILLE: Mais vous �tes de Dijon.\\nARMAND FL�CHARD: Oui, enfin, c'est vite dit, �a.\\n\\n\", 'answer': \"Mais qu'est-ce qu'il y a ?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ARABELLA DE CHAVILLE'}\n",
      "Last word -> ARABELLA DE CHAVILLE : \"Mais qu'est-ce qu'il y a ?\"\n",
      "prediction :  ... Et pour le bon sens de la vie, vous lui fa�terez ce qu'il veut, vous lui fa�terez les autres... Pour l'allergie.\n",
      "Real answer : Mais qu'est-ce qu'il y a ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7739219069480896], 'recall': [0.8009418249130249], 'f1': [0.7872000932693481], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.12903225806451613, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0.04545454545454546 0.014712247158412498\n",
      "ppl : 36.18153381347656\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARMAND FL�CHARD: Au galop, mademoiselle, au galop !\\nARABELLA DE CHAVILLE: Monsieur Fl�chard, comme vous me traitez durement.\\nARMAND FL�CHARD: Oh, et tant pis.\\nARABELLA DE CHAVILLE: Tant mieux. J'aime quand vous �tes m�chant avec moi.\\nARMAND FL�CHARD: Oh !\\nARABELLA DE CHAVILLE: Vous �tes un homme, vous.\\nARMAND FL�CHARD: Non, je suis une nouille ! Allez vous-en... l� !\\nARABELLA DE CHAVILLE: Oh !... Je vais le dire � maman.\\n\\n\", 'answer': \"C'est �a, � votre maman, voil�. Bon...\", 'gold_tag': \"ARMAND FLÉCHARD seems unfazed by ARABELLA DE CHAVILLE's threats\", 'last_speaker': 'ARMAND FL�CHARD'}\n",
      "Last word -> ARMAND FL�CHARD : \"C'est �a, � votre maman, voil�. Bon...\"\n",
      "prediction :  Ah ! La femme.\n",
      "Real answer : C'est �a, � votre maman, voil�. Bon...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8623613119125366], 'recall': [0.8138614892959595], 'f1': [0.8374097347259521], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1806.92529296875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARMAND FL�CHARD: Pourquoi ?\\nARABELLA DE CHAVILLE: C'est mon secret. Vous �tes ivre, monsieur Fl�chard.\\n\\n\", 'answer': 'Mais... mais... Arabella... Mademoiselle ! Mais enfin, je... mais...', 'gold_tag': 'Everyday Language', 'last_speaker': 'ARMAND FL�CHARD'}\n",
      "Last word -> ARMAND FL�CHARD : \"Mais... mais... Arabella... Mademoiselle ! Mais enfin, je... mais...\"\n",
      "prediction :  Oh oui. C'est un peu l�t � ma part, mais vous avez perdu vos lunettes. Vous en ?\n",
      "Real answer : Mais... mais... Arabella... Mademoiselle ! Mais enfin, je... mais...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7941531538963318], 'recall': [0.7977921366691589], 'f1': [0.7959684729576111], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307691, 'rouge2': 0.0, 'rougeL': 0.07692307692307691, 'rougeLsum': 0.07692307692307691}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 77.08434295654297\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARABELLA DE CHAVILLE: C'est faux.\\nARMAND FL�CHARD: C'est moi qui ai ross� Parju !\\nARABELLA DE CHAVILLE: Vous ? Allons donc !\\nARMAND FL�CHARD: Tenez, la preuve !\\nARABELLA DE CHAVILLE: Je ne vous crois pas.\\nARMAND FL�CHARD: N'emp�che... L'homme qui vous aime dans l'ombre.\\nARABELLA DE CHAVILLE: Vous avez lu mes lettres.\\nARMAND FL�CHARD: C'est moi qui les ai �crites.\\nARABELLA DE CHAVILLE: Mais c'est vous ?\\nARMAND FL�CHARD: Oui.\\nARABELLA DE CHAVILLE: Mais pourquoi ?\\nARMAND FL�CHARD: Mais parce que je vous aime !\\nARABELLA DE CHAVILLE: Comment ?\\nARMAND FL�CHARD: Je vous aime !\\nARABELLA DE CHAVILLE: Quoi ?\\n\\n\", 'answer': 'Je vous aime !', 'gold_tag': 'ARMAND FLÉCHARD harbors feelings for ARABELLA DE CHAVILLE', 'last_speaker': 'ARMAND FL�CHARD'}\n",
      "Last word -> ARMAND FL�CHARD : \"Je vous aime !\"\n",
      "prediction :  Je vais tuer Amable.\n",
      "Real answer : Je vous aime !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8733465671539307], 'recall': [0.8630298376083374], 'f1': [0.8681575655937195], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0.25 0.09128709291752769\n",
      "ppl : 3094.091552734375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARMAND FL�CHARD: Oh oui, Arabella.\\nARABELLA DE CHAVILLE: Vous allez �tre mis en prison ?\\nARMAND FL�CHARD: Oui... Comment donc ? En prison ? Mais j'y vais.\\nARABELLA DE CHAVILLE: Vous feriez �a pour moi ?\\nARMAND FL�CHARD: Oui, Arabella.\\nARABELLA DE CHAVILLE: Tout de suite ?\\n\\n\", 'answer': \"J'y vais. J'y vais !\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ARMAND FL�CHARD'}\n",
      "Last word -> ARMAND FL�CHARD : \"J'y vais. J'y vais !\"\n",
      "prediction :  Oui �quoi ?\n",
      "Real answer : J'y vais. J'y vais !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8018232583999634], 'recall': [0.790577232837677], 'f1': [0.7961605191230774], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 19820.935546875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATHAN: Meditations on a Banana Slug was a delightful read.\\nLILA: Thank you so much. I love slugs. All slugs, not just banana slugs.\\nNATHAN: As do I.\\nLILA: They're so even keel. They forge ahead with slow determination. They don't get distracted or side-tracked. They don't care what they look like. They don't care that people look at\\nNATHAN: They don't seem to be especially ego driven, this is true.\\nLILA: You've got to respect that.\\nNATHAN: I have to say that I'm not there yet.\\nLILA: Where?\\nNATHAN: Slugdom. Sluggishness. Whatever you'd call it. I'm not there yet. I still have many human characteristics.\\nLILA: That's not necessarily a bad thing.\\nNATHAN: Yes. I suppose not. But still. One would like to move along. To move beyond.\\nLILA: I'm not sure we can escape our natures. Believe me I've tried. I'm not even so sure anymore that we should want to.\\nNATHAN: I love that you said that. It makes me feel a bit lighter. I've been rather heavy lately. Thinking about my childhood. Realizing how much a product I am of my upbringing. I've been seeing someone. A therapist.\\nLILA: You are a therapist, right?\\nNATHAN: No no. I'm a psychologist, but I do research. I'm a behaviorist. I work with animals. Mice at the moment.\\nLILA: I hope you don't perform any of those dreadful torture experiments, Nathan.\\nNATHAN: Heavens no. My work now is... Right now I'm teaching mice... well, table manners, to be candid.\\nLILA: How's it going?\\nNATHAN: Quite well, really. It's a lot of work. A lot of reinforcement, mostly positive. Right now I've gotten two of my subjects to use napkins. Tiny napkins of course.\\nLILA: Paper or cloth?\\nNATHAN: I hope you don't think me daft. It's important work. It's part of a larger sociological experiment. I'm federally funded.\\nLILA: What's the larger experiment?\\nNATHAN: It's my thesis that if table manners can be taught to mice, they can be taught to humans.\\nLILA: Going out on a limb, aren't you, Nathan?\\nNATHAN: The truth is most people don't have table manners today. And when the foundations of civilized society crumble and disappear, civilized society in its entirely follows closely at its heels.\\nLILA: I'm not sure.\\nNATHAN: Courtesy, decorum, manners, are all sadly lacking from our daily intercourse. Rudeness, vulgarity, meanness are the norm.\\nLILA: We are animals after all.\\n\\n\", 'answer': 'Ergo if I can teach table manners to mice, I can teach them to humans. If I can teach table manners to humans, I can save the world.', 'gold_tag': \"NATHAN is a behaviorist psychologist who works with animals, particularly mice , The goal of NATHAN's research project is to teach humans the same manners\", 'last_speaker': 'NATHAN'}\n",
      "Last word -> NATHAN : \"Ergo if I can teach table manners to mice, I can teach them to humans. If I can teach table manners to humans, I can save the world.\"\n",
      "prediction :  They aren't a product after all.\n",
      "Real answer : Ergo if I can teach table manners to mice, I can teach them to humans. If I can teach table manners to humans, I can save the world.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8417949676513672], 'recall': [0.8222072720527649], 'f1': [0.8318858742713928], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 84.66878509521484\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLILA: It looks wonderful.\\nNATHAN: You look wonderful. I'm on top of the world tonight, Lila. Work is going splendidly and my personal life is ...\\nLILA: Um-mmm. Oh Nathan, this salad is delish...\\nNATHAN: My God! The fork! The fork!\\nLILA: I'm sorry?\\nNATHAN: Tell her, Harold... It's just that... It's nothing. It's just that the outside fork is the\\nLILA: Oh, I'm sorry. I'm sorry, Nathan. I never really learned those things.\\nNATHAN: No biggie.\\nLILA: Boy, this is good!\\nNATHAN: I'm sorry that I became so upset.\\nLILA: No, I'm sorry. I'm really backward in certain areas.\\nNATHAN: It's only that I really enjoy your company and...\\nLILA: You do?\\nNATHAN: Yes, and...\\nLILA: You really enjoy my company?\\nNATHAN: Yes. Please don't talk with food in your mouth, Lila. Please. You're so pretty and it only mars your... I'm sorry. I'm being critical. It's just that I have some peculiarities, and...\\nLILA: I like you, too, Nathan.\\nNATHAN: You do?\\nLILA: Yeah But I have some peculiarities also.\\nNATHAN: I don't care. I don't care! Like what, for example?\\n\\n\", 'answer': 'Like nothing.', 'gold_tag': 'Everyday Language', 'last_speaker': 'LILA'}\n",
      "Last word -> LILA : \"Like nothing.\"\n",
      "prediction :  I'd like to see one of your paintings. You must be quite talented.\n",
      "Real answer : Like nothing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8448419570922852], 'recall': [0.8903897404670715], 'f1': [0.8670181035995483], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 19.942556381225586\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATHAN: Darling, did you bring the insect repellent lotion?\\nLILA: Yes, darling.\\nNATHAN: Oh, and the sun block?\\nLILA: Of course.\\nNATHAN: What SPF, sweetie? Perfectomundo! We are ready! Say, wouldn\\'t it be wonderful to have an insect repellent lotion that also worked as a sun block? Think of all the time one would save.\\nLILA: Yes, darling.\\nNATHAN: I think I\\'ll get Johannsen in chemistry on that. Oh! Did you bring the first aid kit?\\nLILA: Yes.\\nNATHAN: Flares?\\nLILA: Absolutely.\\nNATHAN: We could call it \"Quit Bugging Me, Sunny.\" Get it? Sunny. S-u-n-n-y.\\nLILA: That\\'s very funny.\\n\\n', 'answer': 'I love you so much.', 'gold_tag': 'NATHAN is in a loving relationship with Lila', 'last_speaker': 'NATHAN'}\n",
      "Last word -> NATHAN : \"I love you so much.\"\n",
      "prediction :  This would make a great gift for your Mom. What will you buy her?\n",
      "Real answer : I love you so much.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.852759838104248], 'recall': [0.8667959570884705], 'f1': [0.8597205877304077], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473682, 'rouge2': 0.0, 'rougeL': 0.10526315789473682, 'rougeLsum': 0.10526315789473682}\n",
      "bleu 1/2 : 0.07142857142857141 0.023440361546924773\n",
      "ppl : 30.602941513061523\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLILA: Did you see that?\\nNATHAN: What?\\nLILA: I don't know. Something.\\nNATHAN: A deer?\\nLILA: No. Too... upright. Might've been a person.\\nNATHAN: It might behoove us to turn back at this point.\\nLILA: Come on.\\n\\n\", 'answer': \"If it's a person, why should we go see it? It's not like it's nature or anything. It's just a person. Sometimes people who live in the woods don't want to be seen. They live in the woods because they're anti-social, Lila. We have to respect that. This is the way to get ticks, Lila. This is it. Bingo! Lyme Disease! You've hit the nail on the head here. Oh for God's sa...\", 'gold_tag': 'NATHAN expresses a desire for privacy , NATHAN shows knowledge about the habits of people who live in remote areas', 'last_speaker': 'NATHAN'}\n",
      "Last word -> NATHAN : \"If it's a person, why should we go see it? It's not like it's nature or anything. It's just a person. Sometimes people who live in the woods don't want to be seen. They live in the woods because they're anti-social, Lila. We have to respect that. This is the way to get ticks, Lila. This is it. Bingo! Lyme Disease! You've hit the nail on the head here. Oh for God's sa...\"\n",
      "prediction :  So, how many is enough?\n",
      "Real answer : If it's a person, why should we go see it? It's not like it's nature or anything. It's just a person. Sometimes people who live in the woods don't want to be seen. They live in the woods because they're anti-social, Lila. We have to respect that. This is the way to get ticks, Lila. This is it. Bingo! Lyme Disease! You've hit the nail on the head here. Oh for God's sa...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8441567420959473], 'recall': [0.7937849760055542], 'f1': [0.8181962966918945], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.02298850574712644, 'rouge2': 0.0, 'rougeL': 0.02298850574712644, 'rougeLsum': 0.02298850574712644}\n",
      "bleu 1/2 : 2.4809901599134267e-07 8.771624830659407e-08\n",
      "ppl : 86.02230072021484\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLILA: Who are you? You don't understand my language, do you? I take it back, you do understand my language. Oh God.\\nNATHAN: Oh my God! Is he dead? Please put something on. You'll catch cold. It's cold. What do you suppose he is, a survivalist?\\nLILA: I think he's feral.\\nNATHAN: Feral? Don't touch him! He might be diseased! He might... My God, rabies!\\nLILA: He looks perfectly fine.\\nNATHAN: I think we should go. Please. Before us, or whatever feral things do.\\nLILA: I don't understand you. This is fascinating and you just want to run away. I mean, here we have a human being totally uncontaminated by civilization, totally free, and all you want to do is run back to your...\\nNATHAN: Actually, I just had an amusing thought.\\nLILA: What?\\nNATHAN: Feral, huh? Totally uncontaminated?\\nLILA: Look at him. He doesn't understand\\nNATHAN: It's perfect!\\nLILA: Nathan, what the hell are you talking about?\\nNATHAN: Forget mice! Actually forget guinea pigs, cats, monkeys, and chimps also. I'm on to stage five: The human subject.\\nLILA: Oh no. You can't take him from his home, Nathan.\\nNATHAN: Don't you see? He's my Tabula Rasa, my Eliza Dolittle. He's my ticket to the top of the Behaviorist food chain. He's going to make me famous.\\nLILA: I won't allow you. It's wrong. He's happy here.\\nNATHAN: Is he, Lila? Is he happy living filthy and naked alone in this tick infested wilderness? Never to know the love of a good woman, never to revel in the pitter-patter of little feet, never to read Moby Dick, or marvel at a Monet, or just sit back after a day of hard but rewarding work, smoke a pipe, and wonder about the nature of reality.\\nLILA: You'd be taking away his freedom, Nathan.\\n\\n\", 'answer': \"Freedom's just another word for nothing left to lose, Lila, to quote Janet Jackson. Belonging to something, a person or a society, is a basic human craving. We are communal creatures. This poor soul has no one, nothing...\", 'gold_tag': 'Everyday Language', 'last_speaker': 'NATHAN'}\n",
      "Last word -> NATHAN : \"Freedom's just another word for nothing left to lose, Lila, to quote Janet Jackson. Belonging to something, a person or a society, is a basic human craving. We are communal creatures. This poor soul has no one, nothing...\"\n",
      "prediction :  You get it now, don't you?\n",
      "Real answer : Freedom's just another word for nothing left to lose, Lila, to quote Janet Jackson. Belonging to something, a person or a society, is a basic human craving. We are communal creatures. This poor soul has no one, nothing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8063539266586304], 'recall': [0.8160065412521362], 'f1': [0.8111515641212463], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 19.714744567871094\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATHAN: ...what is it that makes us human, if not the knowledge that we are indeed human? Think of this poor soul's education as the greatest gift we could bestow upon...\\nLILA: All right.\\n\\n\", 'answer': \"Great. Grab his feet. We'll throw him in the trunk.\", 'gold_tag': 'NATHAN is authoritative, giving instructions to LILA', 'last_speaker': 'NATHAN'}\n",
      "Last word -> NATHAN : \"Great. Grab his feet. We'll throw him in the trunk.\"\n",
      "prediction :  We’ve just gone through a difficult period in our collective evolution, in which we’ve learned to recognize each other’s uniqueness.\n",
      "Real answer : Great. Grab his feet. We'll throw him in the trunk.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8366496562957764], 'recall': [0.8810504674911499], 'f1': [0.8582761883735657], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1176470588235294, 'rouge2': 0.0, 'rougeL': 0.1176470588235294, 'rougeLsum': 0.1176470588235294}\n",
      "bleu 1/2 : 0.05000000000000001 0.01622214211307625\n",
      "ppl : 15.391034126281738\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLILA: Are you seeing somebody else, Nathan? I just have to know.\\nNATHAN: Of course not.\\nLILA: It would just be helpful to know.\\nNATHAN: No.\\nLILA: Because, you know, you seem so distant. And you work late every night. And we hardly ever have sex, and when we do, it's... I don't know. It feels different.\\nNATHAN: I'm just preoccupied.\\nLILA: Do you like my new look?\\nNATHAN: Yeah. It's nice. It's really good.\\nLILA: I'm trying, you know. I'm trying to be what you want. I want to be what you want, Nathan. All I want is to be what you want.\\nNATHAN: Shh. It's okay. It's okay, Lila. You're what I want. You know that. You're exactly what I want.\\nLILA: Really?\\nNATHAN: Sure. Of course.\\nLILA: Because I'm really trying, you know. Rosie says maybe only another two years of the elctrolysis.\\nNATHAN: That's great.\\nLILA: I've signed up for a ballet class. And look at my nails! A real girl!\\nNATHAN: That's great. It's a great color for you.\\n\\n\", 'answer': \"Oh, Nathan, let's have a baby!\", 'gold_tag': 'LILA is thinking about having a baby', 'last_speaker': 'LILA'}\n",
      "Last word -> LILA : \"Oh, Nathan, let's have a baby!\"\n",
      "prediction :  Nathan, what do you want?\n",
      "Real answer : Oh, Nathan, let's have a baby!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8651353716850281], 'recall': [0.8659545183181763], 'f1': [0.8655447363853455], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.1637461506155964 0.05789300674674099\n",
      "ppl : 136.6413116455078\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLILA: Oh! I didn't see you there, sneaky boy! You're like a boy sneaking in...\\nNATHAN: ...the back door of a movie theater. Yes, indeed.\\nLILA: You remember that from my book? I'm touched! What's wrong?\\nNATHAN: Nothing. Hard day. Gonna have a drink.\\nLILA: I'll make it. I'm so happy, Nathan! Everything's going to be so great! Scotch on the rocks, right? Just kidding. I know what you drink, mister. I know what you drink. Voila!\\nNATHAN: Thanks.\\nLILA: How's work?\\nNATHAN: Cruddy, okay? Are you satisfied?\\nLILA: No. I don't want your work to be cruddy.\\nNATHAN: My assistant quit today. Okay? He was highly valuable to the project.\\nLILA: Oh, baby. I'm sorry. Can't you hire somebody else?\\nNATHAN: I guess.\\nLILA: Hey! I could come work for you! I know I haven't been all that supportive of this project, but I've come around.\\nNATHAN: Have you?\\nLILA: Oh yes, baby! I think that this is a wonderful project you're doing, taking this poor unfortunate, uncivilized creature and turning him into a human being! What a wonderful wonderful compassionate man you are!\\nNATHAN: Really?\\nLILA: Yes! And I want to help. You won't have to pay me, and I was thinking of giving up that crazy nature writing anyway.\\nNATHAN: How come?\\nLILA: Who needs it? I have you and I have being a woman and I have thinking about womanly things! I love being a woman because...\\nNATHAN: Such as what womanly things?\\n\\n\", 'answer': \"Such as my man and how to please him! Such as making wonderful dinners for my man! Such as looking pretty for my man! And I'm writing an article on quilting for the Ladies Home Journal!\", 'gold_tag': 'LILA is enthusiastic about traditional gender roles , LILA is writing an article on quilting for the Ladies Home Journal', 'last_speaker': 'LILA'}\n",
      "Last word -> LILA : \"Such as my man and how to please him! Such as making wonderful dinners for my man! Such as looking pretty for my man! And I'm writing an article on quilting for the Ladies Home Journal!\"\n",
      "prediction :  Oh, I thought we were talking about this! Don't you want to talk about what you want to do? What have you to offer this world anyway?\n",
      "Real answer : Such as my man and how to please him! Such as making wonderful dinners for my man! Such as looking pretty for my man! And I'm writing an article on quilting for the Ladies Home Journal!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8259421586990356], 'recall': [0.8174830675125122], 'f1': [0.8216908574104309], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06153846153846154, 'rouge2': 0.0, 'rougeL': 0.03076923076923077, 'rougeLsum': 0.03076923076923077}\n",
      "bleu 1/2 : 0.02653819668791812 0.008551978820280986\n",
      "ppl : 16.471567153930664\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATHAN: Bravo to you, Puff!\\n\\n', 'answer': 'That was wonderful!', 'gold_tag': 'Everyday Language', 'last_speaker': 'LILA'}\n",
      "Last word -> LILA : \"That was wonderful!\"\n",
      "prediction :  Good luck, Nathan.\n",
      "Real answer : That was wonderful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8900508284568787], 'recall': [0.8685994148254395], 'f1': [0.8791942596435547], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 510.57037353515625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATHAN: I'm going to go down and check on Puff. See how he's holding up.\\nLILA: Should I come with?\\nNATHAN: Nah. You just relax. How's the book?\\nLILA: Ummm. It's good.\\n\\n\", 'answer': \"I won't be long.\", 'gold_tag': \"NATHAN's temporal information\", 'last_speaker': 'NATHAN'}\n",
      "Last word -> NATHAN : \"I won't be long.\"\n",
      "prediction :  How's the book?\n",
      "Real answer : I won't be long.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8187116980552673], 'recall': [0.8269330263137817], 'f1': [0.8228018283843994], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 162.00912475585938\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATHAN: Hey.\\nLILA: You were gone a long time.\\nNATHAN: Yeah. Puff and I got into a big, philosophical discussion. He\\'s really quite well read, considering he\\'s only been literate for a month now. He\\'s going to make us famous, Lila.\\nLILA: So he\\'s doing okay?\\nNATHAN: Seemed fine. Quiet evening enjoying\\nLILA: That\\'s funny because, you know, I just went and picked him up at some flophouse on the lower eastside. He called here when he ran out of his \"mad\" money after spending an entire evening drinking, watching strippers, and fucking a whore! Oh, and what did you do tonight, honey?\\nNATHAN: Shit.\\nLILA: And what did you do tonight, honey?\\nNATHAN: I\\'ve fallen in love with somebody else, Lila.\\nLILA: And what did you do tonight, honey?\\nNATHAN: I fucked her! Okay? I fucked her. I\\'m sorry. But that\\'s what the hell I did.\\nLILA: Do you know what I gave up to be with you?\\nNATHAN: Yes.\\nLILA: I gave up my soul, my beliefs. I gave up my body hair!\\nNATHAN: Yeah, well, I\\'m sorry. The human heart is a strange thing.\\nLILA: How the hell would you know anything about the human heart?\\nNATHAN: Lila...\\n\\n', 'answer': \"How's that for ladylike, Nathan.\", 'gold_tag': 'LILA is expressive', 'last_speaker': 'LILA'}\n",
      "Last word -> LILA : \"How's that for ladylike, Nathan.\"\n",
      "prediction :  Oh! You really love me, don't you?\n",
      "Real answer : How's that for ladylike, Nathan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8281537890434265], 'recall': [0.8196728229522705], 'f1': [0.8238914012908936], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 20.146892547607422\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTYLER: Next! Oh, no. What do you want?\\nUTAH: Shrimp and fries.\\nTYLER: I mean, what do you want? What are you doing hanging around here.\\nUTAH: I need you to teach me.\\nTYLER: Gimme a break. One shrimp and fries to go! Anything to drink?\\nUTAH: I'm serious.\\nTYLER: I can see that. But forget it. Stick to tennis, or whatever you're good at. Miniature golf. Here, your number's 37.\\nUTAH: Well, I'm just gonna go back out there till I catch on to it or break my neck.\\nTYLER: What is it? You all of a sudden got this bug you had to go surfing? This is a line, right?\\nUTAH: No, no. See, all my life I've done things for other people. In high school I played football because my old man expected me to. Then my parents always figured I'd go to law school, so I did. Football scholarship. Graduated Phi Beta Kappa--\\nTYLER: This gonna take long?\\nUTAH: Wait, so I'm a big hero to my folks, right? But two years ago they got killed in a car wreck and I just suddenly realized all my goals had been their goals. And I hadn't been living my own life. So I wanted something for myself. Something that maybe didn't make any sense. You know what I mean? I came out here from Ohio a month ago. Never saw the ocean before. I didn't think it would effect me so much. Like I'm drawn to it, or something. I want to do what you do. It's the truth.\\nTYLER: Tomorrow, 6 AM. Here. If you're a minute late I'm gone. And Stud... I didn't take you to raise. I can show you a few things but after that you're on your own. That'll be four fifty.\\n\\n\", 'answer': 'Keep the change, Teach.', 'gold_tag': 'Everyday Language', 'last_speaker': 'UTAH'}\n",
      "Last word -> UTAH : \"Keep the change, Teach.\"\n",
      "prediction :  I'm a hundred feet above the beach.\n",
      "Real answer : Keep the change, Teach.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8555049896240234], 'recall': [0.8550550937652588], 'f1': [0.8552799820899963], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.14285714285714285 0.048795003647426664\n",
      "ppl : 43.98386764526367\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nUTAH: Nice place.\\n\\n', 'answer': \"He rents it for the summer. Bodhi always gets some slick place and throws it open to every surf burnout around. Most a these guys can't keep a job. When the swell comes, they're gone, they have to ride.\", 'gold_tag': 'TYLER is aware that Bodhi rents a slick place every summer , TYLER is familiar with the habits of surfer burnouts , TYLER indicates that the event of Bodhi renting the house happens every summer', 'last_speaker': 'TYLER'}\n",
      "Last word -> TYLER : \"He rents it for the summer. Bodhi always gets some slick place and throws it open to every surf burnout around. Most a these guys can't keep a job. When the swell comes, they're gone, they have to ride.\"\n",
      "prediction :  That's a good looking apartment.\n",
      "Real answer : He rents it for the summer. Bodhi always gets some slick place and throws it open to every surf burnout around. Most a these guys can't keep a job. When the swell comes, they're gone, they have to ride.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8758458495140076], 'recall': [0.8268311023712158], 'f1': [0.8506329655647278], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0425531914893617, 'rouge2': 0.0, 'rougeL': 0.0425531914893617, 'rougeLsum': 0.0425531914893617}\n",
      "bleu 1/2 : 0.00022275502956896066 7.875579597581101e-05\n",
      "ppl : 67.85456848144531\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTYLER: You had enough?\\nUTAH: Yeah. I just want to sit out here for a minute.\\nTYLER: Look at you.\\nUTAH: What?\\nTYLER: Well, usually you have this sort of intense scowl of concentration, like you're doing this for a school project or something... I don't know, like something's driving you. See, it's gone. If I didn't know better I'd say you looked almost\\nUTAH: I... I don't know. I can't describe what I'm feeling.\\nTYLER: You don't have to. Those are cold.\\n\\n\", 'answer': 'Warm them up.', 'gold_tag': 'Everyday Language', 'last_speaker': 'UTAH'}\n",
      "Last word -> UTAH : \"Warm them up.\"\n",
      "prediction :  I just want to be alone after all this.\n",
      "Real answer : Warm them up.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8584397435188293], 'recall': [0.9019308090209961], 'f1': [0.8796480894088745], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 41.876487731933594\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nUTAH: Ouch.\\nTYLER: Betadyne doesn't hurt.\\nUTAH: You're kneeling on my hand.\\nTYLER: So what'd the other guy look like?\\nUTAH: Never saw him, was your basic hit and run.\\nTYLER: But you look like you been in a train wreck, how'd he just drive away? Johnny, what is it with you? You have that look again, it's like you're about to tell me something and then you don't... or you can't. What's going on? What? What do you want to tell me?\\n\\n\", 'answer': \"I'm glad you pulled me out of the water that day...\", 'gold_tag': 'UTAH recalls an incident where TYLER pulled him out of the water', 'last_speaker': 'UTAH'}\n",
      "Last word -> UTAH : \"I'm glad you pulled me out of the water that day...\"\n",
      "prediction :  Well, you have a 24 pack at the end of the day, after dinner. But you know your weight is going up and it's not from a muscle build.\n",
      "Real answer : I'm glad you pulled me out of the water that day...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8461649417877197], 'recall': [0.8627103567123413], 'f1': [0.8543575406074524], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.19047619047619044, 'rouge2': 0.05, 'rougeL': 0.19047619047619044, 'rougeLsum': 0.19047619047619044}\n",
      "bleu 1/2 : 0.10344827586206899 0.06078306738548309\n",
      "ppl : 23.089035034179688\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPOLLY: Elsie!\\nELSIE: Yes, Mum?\\nPOLLY: Elsie, where have you been?\\n\\n', 'answer': 'In the garden...', 'gold_tag': 'ELSIE was recently in the garden', 'last_speaker': 'ELSIE'}\n",
      "Last word -> ELSIE : \"In the garden...\"\n",
      "prediction :  I am here, mum. This is my family.\n",
      "Real answer : In the garden...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8544167280197144], 'recall': [0.8288007974624634], 'f1': [0.8414138555526733], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 55.872684478759766\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELSIE: I'm sorry, Joseph. It's all my fault. I didn't mean for any of this to happen...\\nPOLLY: What are you doing in here? This is Joseph's room! My Joseph's room!\\nELSIE: Mummy, you're hurting me!\\n\\n\", 'answer': \"I'm sorry...\", 'gold_tag': 'POLLY immediately shows remorse', 'last_speaker': 'POLLY'}\n",
      "Last word -> POLLY : \"I'm sorry...\"\n",
      "prediction :  You must be Joseph. Tell me you are well. Tell me I don't have to cry any more. Tell me ...\n",
      "Real answer : I'm sorry...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8256708979606628], 'recall': [0.8461835384368896], 'f1': [0.835801362991333], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08333333333333333, 'rouge2': 0.0, 'rougeL': 0.08333333333333333, 'rougeLsum': 0.08333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 25.79417610168457\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELSIE: Are they gone?\\n\\n', 'answer': \"On the contrary. They've asked to hear about the fairies.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'POLLY'}\n",
      "Last word -> POLLY : \"On the contrary. They've asked to hear about the fairies.\"\n",
      "prediction :  No, they will be back later.\n",
      "Real answer : On the contrary. They've asked to hear about the fairies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8561221361160278], 'recall': [0.8453834056854248], 'f1': [0.8507188558578491], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352942, 'rouge2': 0.0, 'rougeL': 0.11764705882352942, 'rougeLsum': 0.11764705882352942}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 105.86732482910156\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELSIE: I'm so sorry, Mum. We had to do it this way so you could see them. But they are real...they are.\\n\\n\", 'answer': 'I believe you.', 'gold_tag': \"POLLY's trust in her daughter is strong\", 'last_speaker': 'POLLY'}\n",
      "Last word -> POLLY : \"I believe you.\"\n",
      "prediction :  How are I a hero? You were the one that saw the evidence, so I had to do the dirty work. You did good.\n",
      "Real answer : I believe you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8405120372772217], 'recall': [0.8882297277450562], 'f1': [0.8637123107910156], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14814814814814814, 'rouge2': 0.0, 'rougeL': 0.14814814814814814, 'rougeLsum': 0.14814814814814814}\n",
      "bleu 1/2 : 0.041666666666666664 0.013459547551454133\n",
      "ppl : 38.95928955078125\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHELEN: Look. We can leave our coats over there. I want to get rid of this.\\nJENNY: I'm so sorry.\\nHELEN: That's OK. It's nice, isn't it?\\nJENNY: It's beautiful. Where did it come from?\\nHELEN: Oh, South Ken somewhere. This is...Well, it's good for this sort of concert, isn't it?\\nJENNY: Thank you.\\nHELEN: We should go shopping together one day, if you want.\\nJENNY: That would be nice. But South Ken... C'est beaucoup trop cher pour moi.\\nHELEN: Sorry?\\nJENNY: I just said....It was too expensive for me.\\nHELEN: No you didn't. You said something completely different.\\nJENNY: I just...Well, I said it in French.\\nHELEN: In French? Why?\\nJENNY: I don't know.\\nHELEN: Anyway. It's too expensive for me, too. We don't have to worry about that. If you want something\\n\\n\", 'answer': 'Why on earth would he want to take me shopping?', 'gold_tag': 'JENNY is unsure about why a person would want to take her shopping', 'last_speaker': 'JENNY'}\n",
      "Last word -> JENNY : \"Why on earth would he want to take me shopping?\"\n",
      "prediction :  Oh, it's great! Thank you so much.\n",
      "Real answer : Why on earth would he want to take me shopping?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8234870433807373], 'recall': [0.8087911009788513], 'f1': [0.8160728812217712], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.227816581726074\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHELEN: There. You'll do. You can keep it. I can only wear so many every day.\\nJENNY: Really? Thank you.\\nHELEN: What about tonight? Will you be needing a nightie? Or not?\\nJENNY: A nightie? Will we be sharing bedrooms?\\nHELEN: You're not sleeping with him?\\nJENNY: No. I'm...No.\\nHELEN: Good for you.\\nJENNY: Really? Do you think so?\\nHELEN: You're only sixteen. And you don't want to get into the family way, do you?\\nJENNY: Oh, I'd make sure that didn't happen. I'm going to do it when I'm seventeen. On my seventeenth birthday, hopefully.\\nHELEN: With David?\\nJENNY: Well...Golly. I suppose it will be with David, won't it?\\n\\n\", 'answer': \"When's your birthday? Oh, he'll be around in April. If that's what you want. Anyway. I'll find you a nightie.\", 'gold_tag': \"JENNY's seventeenth birthday is in April, which is when she plans to have sex for the first time\", 'last_speaker': 'HELEN'}\n",
      "Last word -> HELEN : \"When's your birthday? Oh, he'll be around in April. If that's what you want. Anyway. I'll find you a nightie.\"\n",
      "prediction :  Good night.\n",
      "Real answer : When's your birthday? Oh, he'll be around in April. If that's what you want. Anyway. I'll find you a nightie.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8924636244773865], 'recall': [0.8247506618499756], 'f1': [0.8572720885276794], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1615.0216064453125\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHELEN: Oh, it's always like this. There are millions of places I've never seen because I've been stuck in here.\\nJENNY: You never get out?\\n\\n\", 'answer': \"There's never anywhere to go in the places they stop.\", 'gold_tag': 'HELEN is dissatisfied with the places she gets to visit', 'last_speaker': 'HELEN'}\n",
      "Last word -> HELEN : \"There's never anywhere to go in the places they stop.\"\n",
      "prediction :  Well, I do. (She gets up form her chair and moves to her window.)\n",
      "Real answer : There's never anywhere to go in the places they stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8183044195175171], 'recall': [0.8509347438812256], 'f1': [0.8343006372451782], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0.07142857142857141 0.023440361546924773\n",
      "ppl : 45.28706359863281\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHELEN: They won\\'t be long. Either way.\\nJENNY: \"Either way\"?\\n\\n', 'answer': \"Sometimes they find something, sometimes they don't. And when they do find something, we usually have to leave quite quickly. They can be a bit naughty, sometimes. Anyway. It's nice to have company. I'm usually outside on my own.\", 'gold_tag': 'HELEN often finds herself outside alone , HELEN appreciates company , HELEN has a tolerant attitude towards naughtiness', 'last_speaker': 'HELEN'}\n",
      "Last word -> HELEN : \"Sometimes they find something, sometimes they don't. And when they do find something, we usually have to leave quite quickly. They can be a bit naughty, sometimes. Anyway. It's nice to have company. I'm usually outside on my own.\"\n",
      "prediction :  I'm about to go get my clothes.\n",
      "Real answer : Sometimes they find something, sometimes they don't. And when they do find something, we usually have to leave quite quickly. They can be a bit naughty, sometimes. Anyway. It's nice to have company. I'm usually outside on my own.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8664261102676392], 'recall': [0.8430694341659546], 'f1': [0.8545882105827332], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16, 'rouge2': 0.04166666666666667, 'rougeL': 0.12, 'rougeLsum': 0.12}\n",
      "bleu 1/2 : 0.004432788512836392 0.0008741576834515867\n",
      "ppl : 51.96991729736328\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWILLIE: Ready.\\n\\n', 'answer': 'Jesus.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"Jesus.\"\n",
      "prediction :  OK\n",
      "Real answer : Jesus.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9400529861450195], 'recall': [0.9699887633323669], 'f1': [0.9547863006591797], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 840594.625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMARCUS: How's it goin'?\\nWILLIE: I'm finished when I'm finished.\\nMARCUS: I'm goin' downstairs... I need a melon-bailer and a loofah.\\nWILLIE: Got it.\\n\\n\", 'answer': \"Fuck the loofah, let's go.\", 'gold_tag': 'MARCUS speaks in a directive manner', 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"Fuck the loofah, let's go.\"\n",
      "prediction :  Let's play a game of \"guess the melon\". Tell me what kind of melon it is, and I'll name one from the list.\n",
      "Real answer : Fuck the loofah, let's go.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8296997547149658], 'recall': [0.8662850856781006], 'f1': [0.8475977778434753], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1935483870967742, 'rouge2': 0.06896551724137931, 'rougeL': 0.12903225806451613, 'rougeLsum': 0.12903225806451613}\n",
      "bleu 1/2 : 0.043478260869565216 0.014058038927888336\n",
      "ppl : 9.734620094299316\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWILLIE: I gotta get a drink on. See ya tomorrow.\\nMARCUS: Just don't come in to work stinkin' of booze again.\\nWILLIE: Don't worry about me. Get going, you'll be late for your Wizard of Oz Candy Bar Guild thing.\\nMARCUS: Lollipop Guild, asshole. Jesus, two year olds flip me shit better'n you.\\nWILLIE: You tryin' to say something to me?\\n\\n\", 'answer': \"Yeah. I'm gonna stick my whole fist up your ass.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"Yeah. I'm gonna stick my whole fist up your ass.\"\n",
      "prediction :  You need to get off the phone. I've gotta pick up some more of this.\n",
      "Real answer : Yeah. I'm gonna stick my whole fist up your ass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8546593189239502], 'recall': [0.8616424202919006], 'f1': [0.8581367135047913], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14814814814814814, 'rouge2': 0.0, 'rougeL': 0.14814814814814814, 'rougeLsum': 0.14814814814814814}\n",
      "bleu 1/2 : 0.06666666666666667 0.02182178902359924\n",
      "ppl : 29.044635772705078\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMARCUS: That\\'s just the kinda shit that\\'s gonna get us pinched!\\nWILLIE: She said she was eighteen.\\nMARCUS: You promised no arcades! You said you\\'d only hustle Big & Tall!\\nWILLIE: Ah, it\\'s like shooting fish in a barrel -- there\\'s no sport,\\nMARCUS: How many times, you fuck? \"The bigger the store, the bigger the take.\" Well, we can\\'t work the big stores with your big fucking train wrecks!\\nWILLIE: You got some nerve you little shit ya! You my mom now?! You shat me out your womb, is that it? You gotta take care of me!? Well I can take care of myself and I don\\'t need no lectures! I know how to keep a low profile!\\nMARCUS: What the fuck is this?!\\nWILLIE: Mind your own fucking business.\\n\\n', 'answer': 'You cocksucker! ...EVER HEAR OF THE OPEN-BOTTLE LAW?! -- You dumb Dipshit Motherfucker!', 'gold_tag': \"MARCUS's language is indicative of a tough, possibly criminal, lifestyle\", 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"You cocksucker! ...EVER HEAR OF THE OPEN-BOTTLE LAW?! -- You dumb Dipshit Motherfucker!\"\n",
      "prediction :  Hey hey, what the fuck's going on here!?\n",
      "Real answer : You cocksucker! ...EVER HEAR OF THE OPEN-BOTTLE LAW?! -- You dumb Dipshit Motherfucker!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8557252287864685], 'recall': [0.805739164352417], 'f1': [0.8299802541732788], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09090909090909093, 'rouge2': 0.0, 'rougeL': 0.09090909090909093, 'rougeLsum': 0.09090909090909093}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 35.26494216918945\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWILLIE: No, I think it's a cop though. You think someone's onto us?\\nMARCUS: Is there anything in the room? Anything professional?\\nWILLIE: No. Clothes.\\n\\n\", 'answer': 'Just ditch. You got anywhere to sack out for a while?', 'gold_tag': 'WILLIE lives a transient lifestyle, indicated by his need to find a temporary place to stay , WILLIE is in a transient situation, needing to find a temporary place to hide', 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"Just ditch. You got anywhere to sack out for a while?\"\n",
      "prediction :  Maybe a business card or something of that sort. Something business-like?\n",
      "Real answer : Just ditch. You got anywhere to sack out for a while?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8485301733016968], 'recall': [0.865058183670044], 'f1': [0.8567144870758057], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913043, 'rouge2': 0.0, 'rougeL': 0.08695652173913043, 'rougeLsum': 0.08695652173913043}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 63.392940521240234\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWILLIE: GOD dammit!\\nMARCUS: You tear your ball again?\\nWILLIE: No, it's okay.\\n\\n\", 'answer': \"Let's do the other thing. There.\", 'gold_tag': 'Shared memories - MARCUS and WILLIE seem to have a shared history of WILLIE frequently experiencing a specific injury or medical condition', 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"Let's do the other thing. There.\"\n",
      "prediction :  Okay, what are we gonna do about this?\n",
      "Real answer : Let's do the other thing. There.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8652311563491821], 'recall': [0.8899599313735962], 'f1': [0.8774213790893555], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0.12500000000000003 0.04225771273642583\n",
      "ppl : 25.86846351623535\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWILLIE: I think I've turned a corner.\\nMARCUS: Yeah? You fucking Petites now?\\nWILLIE: No no. No; I beat the crap out of some kids today -- but, you know, for a purpose. It really made me feel pretty good about myself -- like I did something constructive for a change. Accomplished somethin'.\\n\\n\", 'answer': '...You need many years of therapy. Many, many, many, many, many... many fucking years of therapy.', 'gold_tag': 'MARCUS suggests WILLIE needs therapy , MARCUS might have some knowledge about mental health issues', 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"...You need many years of therapy. Many, many, many, many, many... many fucking years of therapy.\"\n",
      "prediction :  Did they actually <i>like</i> you?\n",
      "Real answer : ...You need many years of therapy. Many, many, many, many, many... many fucking years of therapy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7607678771018982], 'recall': [0.7767821550369263], 'f1': [0.7686916589736938], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913043, 'rouge2': 0.0, 'rougeL': 0.08695652173913043, 'rougeLsum': 0.08695652173913043}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 74.7089614868164\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWILLIE: 'Tendo it is. ...Everything I touch turns to shit\\n\\n\", 'answer': \"What are you, drinking Sterno now? 'Cause you're sounding like my Aunt Tilly right before she smeared her own shit on the bedroom walls and we had to lock her up and she spent the rest of her life with a shaved head and eating lunch through a tube up her nose... ...You better be in shape by this evening, fat man. After tonight, I don't give a shit. But this is the time to reach deep down and suck it up. ...Lovely boy.\", 'gold_tag': 'MARCUS has a somewhat antagonistic personality, often deriding and belittling WILLIE , MARCUS has experienced some familial distress, as evidenced by his story about his Aunt Tilly , MARCUS expects WILLIE to be in shape by that evening', 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"What are you, drinking Sterno now? 'Cause you're sounding like my Aunt Tilly right before she smeared her own shit on the bedroom walls and we had to lock her up and she spent the rest of her life with a shaved head and eating lunch through a tube up her nose... ...You better be in shape by this evening, fat man. After tonight, I don't give a shit. But this is the time to reach deep down and suck it up. ...Lovely boy.\"\n",
      "prediction :  It’s a nightmare. It’s what happens when you don’t know the price.'\n",
      "Real answer : What are you, drinking Sterno now? 'Cause you're sounding like my Aunt Tilly right before she smeared her own shit on the bedroom walls and we had to lock her up and she spent the rest of her life with a shaved head and eating lunch through a tube up her nose... ...You better be in shape by this evening, fat man. After tonight, I don't give a shit. But this is the time to reach deep down and suck it up. ...Lovely boy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.844197154045105], 'recall': [0.8091398477554321], 'f1': [0.826296865940094], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13861386138613863, 'rouge2': 0.0202020202020202, 'rougeL': 0.09900990099009901, 'rougeLsum': 0.09900990099009901}\n",
      "bleu 1/2 : 0.00041312536277772645 9.64852976186419e-05\n",
      "ppl : 23.27419090270996\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWILLIE: Barbie it is... ...That it?\\nMARCUS: Let's go. ...Oh Christ.\\n\\n\", 'answer': \"Let's do it.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'WILLIE'}\n",
      "Last word -> WILLIE : \"Let's do it.\"\n",
      "prediction :  What the hell?\n",
      "Real answer : Let's do it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8400229215621948], 'recall': [0.8770046830177307], 'f1': [0.858115553855896], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 247.55857849121094\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK FURY: How bad is it?\\n\\n', 'answer': \"That's the problem, sir. We don't know.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'AGENT PHIL COULSON'}\n",
      "Last word -> AGENT PHIL COULSON : \"That's the problem, sir. We don't know.\"\n",
      "prediction :  I don’t know. You need to come back here. (NICK FURY enters the room and sits at the desk) Do you have a flashlight?\n",
      "Real answer : That's the problem, sir. We don't know.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8223258256912231], 'recall': [0.8614745140075684], 'f1': [0.8414450883865356], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23529411764705882, 'rouge2': 0.125, 'rougeL': 0.1764705882352941, 'rougeLsum': 0.1764705882352941}\n",
      "bleu 1/2 : 0.08333333333333333 0.019034674690672018\n",
      "ppl : 27.70304298400879\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK FURY: Sound the general call. I want every living soul not working rescue looking for that brief case. Roger that. Coulson, get back to base. This is a LEVEL SEVEN. As of right now, we are at war.\\n\\n', 'answer': 'What do we do?', 'gold_tag': 'AGENT PHIL COULSON is a member of the team that responds to the LEVEL SEVEN alert , AGENT PHIL COULSON has a high-ranking role within the organization , AGENT PHIL COULSON is ordered to return to the base immediately', 'last_speaker': 'AGENT PHIL COULSON'}\n",
      "Last word -> AGENT PHIL COULSON : \"What do we do?\"\n",
      "prediction :  What now?\n",
      "Real answer : What do we do?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9083991646766663], 'recall': [0.8896802663803101], 'f1': [0.898942232131958], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.0, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0.18393972058572117 0.082260343798398\n",
      "ppl : 1000.1011962890625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nAGENT PHIL COULSON: Sorry, boss. They got rabbited.\\nNICK FURY: Just stay awake. EYES ON ME!\\nAGENT PHIL COULSON: No. I'm clocked out here.\\nNICK FURY: Not an option.\\n\\n\", 'answer': \"It's okay, boss. This was never going to work... if they didn't have something... to...\", 'gold_tag': \"AGENT PHIL COULSON indicates he is 'clocked out,' suggesting a deteriorating health condition or severe fatigue\", 'last_speaker': 'AGENT PHIL COULSON'}\n",
      "Last word -> AGENT PHIL COULSON : \"It's okay, boss. This was never going to work... if they didn't have something... to...\"\n",
      "prediction :  Do you have a gun?\n",
      "Real answer : It's okay, boss. This was never going to work... if they didn't have something... to...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.860478401184082], 'recall': [0.8082534074783325], 'f1': [0.8335486650466919], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0909090909090909, 'rouge2': 0.0, 'rougeL': 0.0909090909090909, 'rougeLsum': 0.0909090909090909}\n",
      "bleu 1/2 : 0.027067056647322542 0.009569649651041096\n",
      "ppl : 73.81143951416016\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDREW: This is ridiculous.\\n\\n', 'answer': 'Back to work.', 'gold_tag': 'Everyday Language', 'last_speaker': 'D.S.'}\n",
      "Last word -> D.S. : \"Back to work.\"\n",
      "prediction :  How can you say that? I’ve only seen the photos too – but you can’t show me, or else I’ll know you’re a faker and I’ll have a full and proper hearing about your whole mess; what do you know about my life or history of crimes I’ve committed?! I’m not going to ruin my life looking for this – I didn’t even know I was out here for this. This must be some kind of scam. You\n",
      "Real answer : Back to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7918068170547485], 'recall': [0.8609652519226074], 'f1': [0.8249391317367554], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.022988505747126436, 'rouge2': 0.0, 'rougeL': 0.022988505747126436, 'rougeLsum': 0.022988505747126436}\n",
      "bleu 1/2 : 0.012820512820512822 0.004080443192842739\n",
      "ppl : 16.68659210205078\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDREW: Cops! Somebody called the cops?!?\\n\\n', 'answer': \"Drew! Come with me to San De's chamber... Just Drew.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'D.S.'}\n",
      "Last word -> D.S. : \"Drew! Come with me to San De's chamber... Just Drew.\"\n",
      "prediction :  Cops on the roof here.\n",
      "Real answer : Drew! Come with me to San De's chamber... Just Drew.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8554171323776245], 'recall': [0.8119345903396606], 'f1': [0.8331089019775391], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1782.08447265625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nD.S.: Try to hit me here with your feet.\\n\\n', 'answer': 'With pleasure.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DREW'}\n",
      "Last word -> DREW : \"With pleasure.\"\n",
      "prediction :  You'll get hurt there when I step on you.\n",
      "Real answer : With pleasure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8424550294876099], 'recall': [0.8889137506484985], 'f1': [0.8650610446929932], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 82.26988220214844\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDREW: We've got to rebuild this?\\n\\n\", 'answer': 'No. Tear it down.', 'gold_tag': 'Everyday Language', 'last_speaker': 'D.S.'}\n",
      "Last word -> D.S. : \"No. Tear it down.\"\n",
      "prediction :  Yes, we will need to rebuild this from the ashes.\n",
      "Real answer : No. Tear it down.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8860007524490356], 'recall': [0.9091019034385681], 'f1': [0.8974027037620544], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 61.10089111328125\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDREW: I can't do it.\\n\\n\", 'answer': \"There is no can't, only won't.\", 'gold_tag': 'D.S. acts as a mentor or coach , D.S. believes in potential and motivation rather than accepting failure', 'last_speaker': 'D.S.'}\n",
      "Last word -> D.S. : \"There is no can't, only won't.\"\n",
      "prediction :  Is there anything I can do to help?\n",
      "Real answer : There is no can't, only won't.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8087180852890015], 'recall': [0.8155539035797119], 'f1': [0.812121570110321], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.375, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.485372543334961\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTACY: There... There's his car. I know he's at work tonight. He hasn't come into Swenson's since he called my house. My mother told him I was still at high school, after I told him I was nineteen. I guess I should tell him I'm fifteen.\\nLINDA: Don't you dare, you'll never hear from him again.\\nSTACY: Does Doug care that you're seventeen?\\nLINDA: Doug sees beyond that stuff to what the person inside is like. That's why I'm marrying him.\\nSTACY: If he ever calls again I'll say I'm eighteen.\\n\\n\", 'answer': 'Boy I am so glad to be through with all these games.', 'gold_tag': 'LINDA is a mature and straightforward person , LINDA dislikes playing games in relationships', 'last_speaker': 'LINDA'}\n",
      "Last word -> LINDA : \"Boy I am so glad to be through with all these games.\"\n",
      "prediction :  So what happened to you?\n",
      "Real answer : Boy I am so glad to be through with all these games.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8501591682434082], 'recall': [0.842739462852478], 'f1': [0.8464330434799194], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23529411764705882, 'rouge2': 0.0, 'rougeL': 0.23529411764705882, 'rougeLsum': 0.23529411764705882}\n",
      "bleu 1/2 : 0.0493193927883213 0.017437038542312454\n",
      "ppl : 103.43024444580078\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINDA: You've got to get used to working Christmas. People are always screaming and yelling... then they get home and they're all Christmasy.\\nSTACY: I think Christmas brings out the worst in people.\\nLINDA: I guess Ron hasn't called yet.\\nSTACY: Not since November.\\nLINDA: Stacy, it doesn't look good for the relationship.\\nSTACY: Don't you think it meant anything to him. Even if I am fifteen?\\nLINDA: Stacy. What does it matter? He's a stereo salesman. You want to marry him? You want to have kids with him? You want this guy to come home, fifty years old, and he's still got that little Pacific Stereo badge on? Come on.\\nSTACY: I should quit this job. I'm going to get so fat working here... nobody will ever take me out.\\nLINDA: Stacy. How many times do I have to tell you? You are really going to be beautiful... someday.\\nSTACY: Thanks a lot.\\n\\n\", 'answer': \"Hey -- Ron Johnson? It's his loss.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'LINDA'}\n",
      "Last word -> LINDA : \"Hey -- Ron Johnson? It's his loss.\"\n",
      "prediction :  OK, come on. Be reasonable.\n",
      "Real answer : Hey -- Ron Johnson? It's his loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8621925115585327], 'recall': [0.8444857597351074], 'f1': [0.8532472848892212], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 85.87242126464844\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTACY: What do you think of that guy who works at the theatre? You know, Mark Ratner.\\nLINDA: Oh, come on. What is he? Fifteen?\\nSTACY: Sixteen.\\n\\n', 'answer': 'Just watch out if he pulls up in a van, and then puts on a Led Zeppelin tape.', 'gold_tag': 'LINDA is aware of popular rock band Led Zeppelin , LINDA has a skeptical opinion about Mark, the guy who works at the theatre', 'last_speaker': 'LINDA'}\n",
      "Last word -> LINDA : \"Just watch out if he pulls up in a van, and then puts on a Led Zeppelin tape.\"\n",
      "prediction :  Okay... okay. You're right. That is kind of cute. He hasn't come home yet, right?\n",
      "Real answer : Just watch out if he pulls up in a van, and then puts on a Led Zeppelin tape.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8471578359603882], 'recall': [0.8436551094055176], 'f1': [0.8454028367996216], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05714285714285714, 'rouge2': 0.0, 'rougeL': 0.05714285714285714, 'rougeLsum': 0.05714285714285714}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.850788116455078\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTACY: I really thought he would show up. I waited... and waited... and waited...\\nLINDA: That little prick.\\nSTACY: Then I called his house, and his mother told me he was in the garage helping his father.\\nLINDA: That little prick.\\nSTACY: I paid for it and everything.\\nLINDA: There goes your stereo for another year. Mike Damone is a no-brain little prick. I'm not letting him get away with this.\\nSTACY: Don't do anything, Linda. I'd rather just forget about it. I don't even like the guy.\\n\\n\", 'answer': \"Stacy, he's not a guy. He's a little prick!\", 'gold_tag': 'LINDA shows animosity towards those who hurt her friends', 'last_speaker': 'LINDA'}\n",
      "Last word -> LINDA : \"Stacy, he's not a guy. He's a little prick!\"\n",
      "prediction :  I know a couple of guys who are not afraid to take a stand and fight you. So, I called some old friends of ours who use names like \"The Boss\" or \"Fatboy\", but I was too polite to ask their names. So, I don't know if they're going to come, but I need you not to worry about Mike.\"\n",
      "Real answer : Stacy, he's not a guy. He's a little prick!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8248281478881836], 'recall': [0.8566457033157349], 'f1': [0.8404358625411987], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0821917808219178, 'rouge2': 0.0, 'rougeL': 0.0547945205479452, 'rougeLsum': 0.0547945205479452}\n",
      "bleu 1/2 : 0.05000000000000001 0.009205746178983234\n",
      "ppl : 18.584896087646484\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: What was that?\\nYURI: Oh nothing.\\nJOHN: Tell me.\\nYURI: No. It is too judgmental.\\nJOHN: Tell me what he said.\\nYURI: He says why did you send to Russia for a wife. You are not ashamed of it? It's no surprise to want to love.\\nJOHN: No. It's not that.\\nYURI: Do you believe in love?\\nJOHN: I suppose it's... I mean define your terms.\\n\\n\", 'answer': \"It's very strange. How many people are truly themselves with their love? It is the greatest human disaster and it is never in the newspapers. There are no Marches Against Heartache, no Ministries Against Loneliness, no Concerts Against Disappointment. We look away. And still we know in secret that nothing is more important to us. The one thing we all share but don't say. Look John I will show you something. Here look, something beautiful from Russia. Here is Life, there, take it. Here is bread. Khylep. This is work. We all need this, here eat. Good. But we cannot survive with just work, so here is meat and blood. Myasa. This is family and country, flesh, strength, eat. But again this is not life. Here is joy and pain. Chyesnok. Without these life has no flavour, is too serious. Eat. But this vodka. Is love. Only this magic changes you inside. The moon and the stars and the sun. This is a love song, a soldier's song to his beloved -- Alexei, he's Afghanstya, a veteran of Afghanistan. He saw terrible things.\", 'gold_tag': 'YURI is thoughtful and philosophical , YURI is willing to share her culture and beliefs with JOHN', 'last_speaker': 'YURI'}\n",
      "Last word -> YURI : \"It's very strange. How many people are truly themselves with their love? It is the greatest human disaster and it is never in the newspapers. There are no Marches Against Heartache, no Ministries Against Loneliness, no Concerts Against Disappointment. We look away. And still we know in secret that nothing is more important to us. The one thing we all share but don't say. Look John I will show you something. Here look, something beautiful from Russia. Here is Life, there, take it. Here is bread. Khylep. This is work. We all need this, here eat. Good. But we cannot survive with just work, so here is meat and blood. Myasa. This is family and country, flesh, strength, eat. But again this is not life. Here is joy and pain. Chyesnok. Without these life has no flavour, is too serious. Eat. But this vodka. Is love. Only this magic changes you inside. The moon and the stars and the sun. This is a love song, a soldier's song to his beloved -- Alexei, he's Afghanstya, a veteran of Afghanistan. He saw terrible things.\"\n",
      "prediction :  Do you believe in it?\n",
      "Real answer : It's very strange. How many people are truly themselves with their love? It is the greatest human disaster and it is never in the newspapers. There are no Marches Against Heartache, no Ministries Against Loneliness, no Concerts Against Disappointment. We look away. And still we know in secret that nothing is more important to us. The one thing we all share but don't say. Look John I will show you something. Here look, something beautiful from Russia. Here is Life, there, take it. Here is bread. Khylep. This is work. We all need this, here eat. Good. But we cannot survive with just work, so here is meat and blood. Myasa. This is family and country, flesh, strength, eat. But again this is not life. Here is joy and pain. Chyesnok. Without these life has no flavour, is too serious. Eat. But this vodka. Is love. Only this magic changes you inside. The moon and the stars and the sun. This is a love song, a soldier's song to his beloved -- Alexei, he's Afghanstya, a veteran of Afghanistan. He saw terrible things.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8266462087631226], 'recall': [0.7797893285751343], 'f1': [0.8025344014167786], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.031413612565445025, 'rouge2': 0.0, 'rougeL': 0.020942408376963356, 'rougeLsum': 0.020942408376963356}\n",
      "bleu 1/2 : 1.3841285779600526e-16 3.460321444900132e-17\n",
      "ppl : 66.05847930908203\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nYURI: John. We can see you hiding. How is bank?\\nJOHN: Fine. I thought you were leaving today.\\n\\n', 'answer': \"To be indoors on such a day. It's crime.\", 'gold_tag': 'YURI enjoys outdoor activities', 'last_speaker': 'YURI'}\n",
      "Last word -> YURI : \"To be indoors on such a day. It's crime.\"\n",
      "prediction :  I'll talk to you later if you behave well. If not ... good bye.\n",
      "Real answer : To be indoors on such a day. It's crime.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8389608860015869], 'recall': [0.8673297762870789], 'f1': [0.852909505367279], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08333333333333333, 'rouge2': 0.0, 'rougeL': 0.08333333333333333, 'rougeLsum': 0.08333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 35.04963684082031\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: Hey.\\n\\n', 'answer': \"He's just having fun. He's maybe too strong you know...\", 'gold_tag': 'Everyday Language', 'last_speaker': 'YURI'}\n",
      "Last word -> YURI : \"He's just having fun. He's maybe too strong you know...\"\n",
      "prediction :  Yeah, I'd be there too!\n",
      "Real answer : He's just having fun. He's maybe too strong you know...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8254172205924988], 'recall': [0.8314566612243652], 'f1': [0.828425943851471], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 47.95749282836914\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nYURI: I understand. I'm so sorry\\nJOHN: You can stay tonight.\\nYURI: I have brought you trouble. Maybe I should have come alone.\\n\\n\", 'answer': 'Good night.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"Good night.\"\n",
      "prediction :  You've got to be kidding. That makes 480,000 Americans dead.\n",
      "Real answer : Good night.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8205517530441284], 'recall': [0.8815040588378906], 'f1': [0.8499365448951721], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.71968936920166\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: What are you doing?\\nYURI: John, I'm sorry. It's my fault.\\nJOHN: What's he doing? What the fuck are you doing? Leave her alone.\\nYURI: He says sit down. Or he'll cut her. Sit down please.\\nJOHN: Tell him to stop and let her go, and we'll talk. Put the fucking kettle down.\\nYURI: John.\\nJOHN: Put the fucking kettle down. Tell, Yuri, tell him put it down or I'm going to make him.\\nYURI: He says you scare him so much he must go to the toilet in his trousers. John, he is a soldier. A trained killer. We must do what he says.\\nJOHN: What? What does he want? What did he say? Tell me!\\nYURI: He says you are very sad ridiculous man. I don't agree of course. And that you must pay someone to have sex like a prostitute. Nadia is a prostitute. I'm sorry.\\nJOHN: What does he want. The Russian shithead. What do you want ?\\nYURI: He wants money.\\nJOHN: Tell him to put the kettle down and I'll give him money.\\nYURI: He wants a lot of money.\\nJOHN: I'll give him money. Tell him to put the...\\nYURI: He wants the money from your bank.\\nJOHN: I'll fuckin' give it to him! We'll go down there.\\nYURI: You don't understand. He wants all the money that is in your bank.\\nJOHN: I've got eight hundred pounds. Oh Jesus. Oh Jesus.\\nYURI: He is sure you can do this. Of course you can not.\\nJOHN: Oh Jesus. Of course I can't. Just leave her alone.\\nYURI: I'm so sorry.\\n\\n\", 'answer': 'Leave her alone.', 'gold_tag': 'JOHN shows a strong determination to protect', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"Leave her alone.\"\n",
      "prediction :  How many?\n",
      "Real answer : Leave her alone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8357905149459839], 'recall': [0.871058464050293], 'f1': [0.8530601263046265], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3032.510498046875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBITSEY: His prints were all over the kitchen, including one on the bag.\\nZACK: Half-a-thumb print.\\nBITSEY: Okay, half-a-thumb print.\\nZACK: Could have touched it before it was a murder weapon.\\nBITSEY: Do you fondle your friends' garbage bags?\\nZACK: Yeah, I get very touchy around household plastics. 'Hello, everybody -- ooooh, Tupperware.' Chill. I'm just saying the bag could have been out on the counter or something.\\nBITSEY: Hey, Zack?\\nZACK: Yeah.\\nBITSEY: He did it.\\nZACK: But the murder's way too fucking clumsy. And this guy's a major intellectual. Top of his Yale class, a Rhodes gig, tenured at 27, two books. He's an academic stud.\\nBITSEY: And, empirically speaking, a psychotic.\\nZACK: Look at his wife, she's a regular Grace Kelly. Old money svelte. Father was Ambassador to Spain --\\nBITSEY: Shit! The light's on again.\\nZACK: Ignore it. It's a rental.\\nBITSEY: Thanks, Zack. Do you smell anything?\\nZACK: No. Besides the guy's a flaming liberal.\\nBITSEY: A person's politics has nothing to do with their propensity to commit crime. Aren't we supposed to smell it if it's overheating?\\nZACK: Wrong, seventy-three percent of all serial killers vote republican.\\nBITSEY: Throw the cigarette out so we can smell. No! You'll stink up the car. Throw it out!\\nZACK: I'm not gonna fucking pollute.\\nBITSEY: Zack! We better pull off. Shit, this is so irritating.\\nZACK: How far to Huntsville?\\nBITSEY: Look.\\n\\n\", 'answer': \"'NEWS Magazine reporters Bitsy Bloom and Zack Stemmons entered the rest area with car trouble...\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ZACK'}\n",
      "Last word -> ZACK : \"'NEWS Magazine reporters Bitsy Bloom and Zack Stemmons entered the rest area with car trouble...\"\n",
      "prediction :  Fuck you!\n",
      "Real answer : 'NEWS Magazine reporters Bitsy Bloom and Zack Stemmons entered the rest area with car trouble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8351930975914001], 'recall': [0.7888748049736023], 'f1': [0.8113734126091003], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5426.2412109375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBITSEY: Try phone records, a net search.\\nZACK: Fucking better than watching you work. You think he's telling the truth?\\nBITSEY: Don't ask me that. I don't know. There is no truth, only perspectives.\\nZACK: Can't say that. If you say 'there is no truth,' you're claiming it's true that there is no truth -- it's a logical contradiction.\\nBITSEY: Working on our philosophy merit badge, Zack?\\nZACK: I, on the other hand, think Gale's telling the truth.\\nBITSEY: This you know telepathically?\\n\\n\", 'answer': \"It's just my perspective.\", 'gold_tag': 'ZACK trusts his intuition in determining the truth', 'last_speaker': 'ZACK'}\n",
      "Last word -> ZACK : \"It's just my perspective.\"\n",
      "prediction :  I can see the next step. Gale is telling you the truth.\n",
      "Real answer : It's just my perspective.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8603882789611816], 'recall': [0.8630889058113098], 'f1': [0.8617364764213562], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 98.27686309814453\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: Thirty-three o what?\\nBITSEY: Seven. 'Check out the crime scene in Austin.' You made it sound so close. Shit, two and half hours and that damn lig --\\n\\n\", 'answer': 'Bitsey.', 'gold_tag': \"Zack knows about Bitsey's assignment , Zack has a calming influence , Zack tries to pacify Bitsey when she gets exasperated\", 'last_speaker': 'ZACK'}\n",
      "Last word -> ZACK : \"Bitsey.\"\n",
      "prediction :  \"You made it sound so close, I can't believe it, I love it, thanks.\"\n",
      "Real answer : Bitsey.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.821272611618042], 'recall': [0.8422325849533081], 'f1': [0.8316205143928528], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 26.599687576293945\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBITSEY: It was in the case file.\\nZACK: Fuck, in her stomach? That's colder than Wisconsin.\\nBITSEY: Zack, open your vanity.\\nZACK: What?\\nBITSEY: The vanity mirror, pull it down. See that truck behind us?\\nZACK: Yeah.\\nBITSEY: Isn't that the cowboy from the rest area?\\nZACK: Same truck.\\nBITSEY: Weird coincidence, huh?\\n\\n\", 'answer': \"Coincidences are always weird, that's why they're coincidences.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ZACK'}\n",
      "Last word -> ZACK : \"Coincidences are always weird, that's why they're coincidences.\"\n",
      "prediction :  She's a little lost.\n",
      "Real answer : Coincidences are always weird, that's why they're coincidences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8797833323478699], 'recall': [0.8194476366043091], 'f1': [0.8485442996025085], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 69.47409057617188\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: Fuck. Hey.\\nBITSEY: For God's sake, Zack.\\nZACK: You're not a happy camper.\\nBITSEY: It's not a happy place.\\nZACK: Talked to the Austin prosecutor. Belyeu's a yokel. Prosecutor says he fucked up the penalty phase, says Gale probably would have gotten life on mitigating factors. Gale stuck with him, though, all through appeals, despite major pro bono offers.\\nBITSEY: What else?\\nZACK: Notta on Berlin, we pick up the money in Houston tonight, overheat light came on twice, and you're about to get a surprise.\\nBITSEY: I don't want a surprise.\\n\\n\", 'answer': 'Too late.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ZACK'}\n",
      "Last word -> ZACK : \"Too late.\"\n",
      "prediction :  That's fair...\n",
      "Real answer : Too late.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8181068301200867], 'recall': [0.9099438786506653], 'f1': [0.8615850210189819], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 209.34739685058594\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: This is mostly an Oklahoma caravan. I got stuck behind them on the way in. Execution's not for another 36 hours. It's gonna be a zoo. There's the P.R. guy.\\nBITSEY: What a life, waiting around for someone to die.\\nZACK: Fuck, look.\\n\\n\", 'answer': 'This is a little too coincidental.', 'gold_tag': \"BITSEY's outlook on life is somewhat cynical and detached\", 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"This is a little too coincidental.\"\n",
      "prediction :  This guy’s a fuckin' moron.\n",
      "Real answer : This is a little too coincidental.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8775249123573303], 'recall': [0.8597277402877808], 'f1': [0.8685351014137268], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.0, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0.3274923012311928 0.08187307530779821\n",
      "ppl : 86.75019836425781\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: 'Cause I couldn't see the license plate.\\nBITSEY: Forget it. What time is it?\\nZACK: 6:05. Why don't you have a watch?\\n\\n\", 'answer': \"It's a long story.\", 'gold_tag': 'BITSEY does not carry a watch , BITSEY has a significant story behind her not wearing one', 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"It's a long story.\"\n",
      "prediction :  I don't wear them.\n",
      "Real answer : It's a long story.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8822544813156128], 'recall': [0.8766582012176514], 'f1': [0.8794474601745605], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 42.09751892089844\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: What!?\\nBITSEY: It's open.\\nZACK: So? Maybe the maid forgot.\\n\\n\", 'answer': 'Look!', 'gold_tag': 'Everyday Language', 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"Look!\"\n",
      "prediction :  Yes! We have the right to live like normal people!\n",
      "Real answer : Look!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8465093374252319], 'recall': [0.9325010776519775], 'f1': [0.8874269723892212], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 50.22345733642578\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: I'll check the bathroom. Clear in here! Don't touch it! Fuck, Bitsey, there could have been prints.\\n\\n\", 'answer': 'Look.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"Look.\"\n",
      "prediction :  What did I do? How did they get it?\n",
      "Real answer : Look.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.829226016998291], 'recall': [0.9171041250228882], 'f1': [0.8709539771080017], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 31.9758243560791\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: Let's say Gale's right. Some sick- fuck-Agatha Christie-wannabe set him up, arranged like the perfect murder. Why send a magazine journalist proof a few hours before he's won? Doesn't make sense.\\nBITSEY: No, it's perfect. He knows News Magazine won't give the scoop to the dailies or nightly news, not after having paid for it. Probably guessed we wouldn't call the cops. And, most importantly, knows I'll tell Gale tomorrow.\\nZACK: Why does he give a shit?\\nBITSEY: Zack, what if Harraway's murder was just a means to getting Gale. I mean sending him through hell, a sick cat and mouse game. You kill the one person he has left. Make sure he sits six years on death row for the murder -- a place he's made a public career of loathing. And then just let him die, die knowing everyone will remember him with disgust. You destroy his loved ones, his life's work, his memory -- and you make him watch.\\nZACK: That's a lot of hate. You're talking beyond sadism. Then why release it?\\nBITSEY: If the mouse dies the game's over. Maybe the cat's enjoying himself. Or...\\nZACK: Or?\\nBITSEY: Imagine walking to the chamber knowing this exists.\\nZACK: The 'cat' is a fucking psychopath.\\n\\n\", 'answer': 'Yeah, but smart.', 'gold_tag': 'Bitsey is analytical', 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"Yeah, but smart.\"\n",
      "prediction :  The cat's a fucking psychopath.\n",
      "Real answer : Yeah, but smart.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8716758489608765], 'recall': [0.8789691925048828], 'f1': [0.8753073215484619], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 105.39848327636719\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBITSEY: Did you see the cowboy go in?\\nZACK: He went in Belyeu's building?\\nBITSEY: Into his office. Just saw him.\\nZACK: Fuck!\\nBITSEY: Follow him. Find out who he is, where he lives -- what he --\\nZACK: How are you gonna get to Ellis?\\n\\n\", 'answer': 'A taxi.', 'gold_tag': 'BITSEY suggests taking a taxi, implying she might be in a rush due to the urgency of the situation', 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"A taxi.\"\n",
      "prediction :  I know you, you're the one that got shot in the leg three weeks ago.\n",
      "Real answer : A taxi.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8379076719284058], 'recall': [0.8966264724731445], 'f1': [0.8662731647491455], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 20.046703338623047\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBITSEY: Zack! Wake up! Get up! Did you throw the towel on the floor?\\nZACK: What?\\nBITSEY: The towel on my bathroom floor. Did you put it there?\\nZACK: Yeah, I guess. It's a hotel room. What --\\nBITSEY: Do you do that at home?\\nZACK: No. Fuck, Bitsey. I'm sorry, it's not like it's --\\nBITSEY: Get up.\\nZACK: What the fuck's wrong with you?\\nBITSEY: Grab the T.V. I want to check something.\\nZACK: What?\\nBITSEY: We're taking a tour.\\nZACK: Where?\\n\\n\", 'answer': 'Austin. Get the T.V.', 'gold_tag': 'BITSEY could be staying at a hotel at the moment', 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"Austin. Get the T.V.\"\n",
      "prediction :  Zack! Wake up!\n",
      "Real answer : Austin. Get the T.V.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8200633525848389], 'recall': [0.8831528425216675], 'f1': [0.8504396080970764], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 745.0380249023438\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: Hairy.\\n\\n', 'answer': 'Come on.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"Come on.\"\n",
      "prediction :  Hey look\n",
      "Real answer : Come on.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8621279001235962], 'recall': [0.9055578708648682], 'f1': [0.8833093643188477], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11003.0029296875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBITSEY: ...Because of the Berlin thing, Constance knew the police would go whose life was shit anyway. But...\\nZACK: She was in love with him.\\n\\n', 'answer': \"I don't know. Something. They were close. She wouldn't want him dead.\", 'gold_tag': 'BITSEY engages in thoughtful dialogue about the situation involving Constance and the man she was close with', 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"I don't know. Something. They were close. She wouldn't want him dead.\"\n",
      "prediction :  ...you're not?\n",
      "Real answer : I don't know. Something. They were close. She wouldn't want him dead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8006146550178528], 'recall': [0.8259800672531128], 'f1': [0.8130995035171509], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 154.6263885498047\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBITSEY: Remember this thing about Dusty being a bull-horner, going to far?\\nZACK: Why he was fired from DeathWatch, and the A.C.L.U.\\nBITSEY: Right. Maybe the plan was for Dusty to release the tape after Gale's conviction, after a year or so. You know, force him to dry out, let him play the heroic victim, give him back his dignity. So, Dusty Wright's sitting on this tape, waiting, the only one who knows about it. And maybe good ole Dusty starts to think that an erroneous execution is a hell of a lot more politically useful than a last-minute save.\\nZACK: Which would only prove the system works.\\nBITSEY: Yeah. Almost martyrs don't count. What's one murder to stop thousands?\\nZACK: So he'll wait, release the whole tape after the execution.\\n\\n\", 'answer': 'Right. Somewhere he must have the original. What time is it?', 'gold_tag': 'BITSEY is possibly involved in investigative or strategy-based work', 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"Right. Somewhere he must have the original. What time is it?\"\n",
      "prediction :  We're not that kind of department.\n",
      "Real answer : Right. Somewhere he must have the original. What time is it?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8510832786560059], 'recall': [0.8512663245201111], 'f1': [0.8511747121810913], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 67.83635711669922\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBITSEY: Don't move from the booth. Call the second you see the truck. Remember, let it ring just once. Then get into the woods --\\nZACK: I know. Go.\\nBITSEY: Into the woods, Zack.\\n\\n\", 'answer': 'Go!', 'gold_tag': \"BITSEY and ZACK seem to have prior experience with this drill, as indicated by BITSEY's instructions and ZACK's quick understanding.\", 'last_speaker': 'ZACK'}\n",
      "Last word -> ZACK : \"Go!\"\n",
      "prediction :  Okay, hold on. Can you hear me? I got him. He's on the phone. It's gonna be okay.\n",
      "Real answer : Go!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8132333755493164], 'recall': [0.8317382335662842], 'f1': [0.8223816752433777], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.94579029083252\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBITSEY: Everyone! Wake up New York, the warden, the Governor, the goddamn Supreme Court death clerk! How far is it?\\nZACK: Took me 30 this afternoon. You've got 26, maybe more.\\n\\n\", 'answer': \"I'll make it.\", 'gold_tag': \"BITSEY's temporal information\", 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"I'll make it.\"\n",
      "prediction :  Let's go to the Governor. He'll say. \"Hey, you're in prison. You're not dead yet.\" The Supreme Court will do anything to help you. New York's biggest, oldest, meanest prison will be closed for business. We've taken care of that, and we'll take care of you. And we'll get you out this town in about two weeks.\n",
      "Real answer : I'll make it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8215538263320923], 'recall': [0.8822470307350159], 'f1': [0.8508193492889404], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.028985507246376812, 'rouge2': 0.0, 'rougeL': 0.028985507246376812, 'rougeLsum': 0.028985507246376812}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13.277792930603027\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBEN: You crying?\\nELENA: I'm just sad Ben -- I mean it was... you were, but, you know. I just don't know...\\nBEN: Whatever that means Elena -- And you complain about me not communicating... I thought it was --\\nELENA: No, I didn't mean to sound negative. It was -- But Ben. What is going to happen with us? Have you --\\nBEN: You have to bring this up now? What? Did I do something here? Is that it? Is it something I did?\\nELENA: I wasn't accusing you, Ben. It's just that we've got to be honest. Not just with ourselves, but with\\nBEN: Hell, I know. I -- I guess if you want to accuse me, you've got -- Oh hell! I've got to pick up Paul. I almost forgot.\\nELENA: You were saying?\\nBEN: Yikes -- I was hoping to wear this thing to the Halford's Friday.\\nELENA: That shirt?\\nBEN: What?\\n\\n\", 'answer': \"Leave it -- I'll wash it for you.\", 'gold_tag': 'Elena is willing to help Ben by washing his shirt for him', 'last_speaker': 'ELENA'}\n",
      "Last word -> ELENA : \"Leave it -- I'll wash it for you.\"\n",
      "prediction :  So, what happened to the big thing you told me about last week?\n",
      "Real answer : Leave it -- I'll wash it for you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8542925119400024], 'recall': [0.8361344337463379], 'f1': [0.8451159596443176], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809525, 'rouge2': 0.0, 'rougeL': 0.09523809523809525, 'rougeLsum': 0.09523809523809525}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 26.758045196533203\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELENA: The turkey in?\\n\\n', 'answer': 'Stuffed and baking.', 'gold_tag': 'BEN is involved in cooking , Cooking indicates his domestic side', 'last_speaker': 'BEN'}\n",
      "Last word -> BEN : \"Stuffed and baking.\"\n",
      "prediction :  Well, I can't seem to find it. Look, man, I didn't buy it.\n",
      "Real answer : Stuffed and baking.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8334841132164001], 'recall': [0.8516944646835327], 'f1': [0.8424909114837646], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18.470619201660156\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELENA: Oh lord. You think I'm so dense. And now you want to be seen with your dense wife at the cocktail party. You want to wear that with those pants at all. You want to wear that, and you want me to shake hands with your friends and accord me the respect of talking honestly about this... You don't\\nBEN: Sure I do. Do I know what loneliness feels like? Sure I do. I know a lot about it, if that's what you mean.\\n\\n\", 'answer': \"Benjamin. That's supposed to explain it?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ELENA'}\n",
      "Last word -> ELENA : \"Benjamin. That's supposed to explain it?\"\n",
      "prediction :  You don't get it. You don't know what it is to be alone and all alone.\n",
      "Real answer : Benjamin. That's supposed to explain it?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8504456877708435], 'recall': [0.8546649217605591], 'f1': [0.8525500893592834], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0.0625 0.02041241452319315\n",
      "ppl : 9.931099891662598\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROXANNE: Do you miss your home, Captain? Have you someone there?\\nWILLARD: No. Not really. I was discharged from the army four years ago. I went home, wasted some time, bought a Mustang Mach 1, drove it a week. Then I re-upped for another tour. No, everything I love is here.\\nROXANNE: Then you are like us. What will you do after the war?\\nWILLARD: I just follow my footsteps, one at a time, trying to answer the little questions and staying away from the big ones.\\nROXANNE: What's a big question?\\nWILLARD: Kurtz. I know you've heard of him.\\nROXANNE: Yes.\\nWILLARD: What did you hear?\\nROXANNE: That strange things.. terrible things have occured around this American, Kurtz.\\nWILLARD: What things?\\nROXANNE: Gaston would never tell me. It was asubject not to be spoken of, Captain.\\nWILLARD: Yes.\\nROXANNE: Did you know -- deeper in the jungle, upriver -- there are savages?\\nWILLARD: I know.\\n\\n\", 'answer': \"But Captain, I mean -- cannibals. What a pity, you don't drink. Since my husband died, there are so many things I must do alone.\", 'gold_tag': \"ROXANNE is a widow who has to do many things alone since her husband's death , WILLARD is sober and doesn't drink\", 'last_speaker': 'ROXANNE'}\n",
      "Last word -> ROXANNE : \"But Captain, I mean -- cannibals. What a pity, you don't drink. Since my husband died, there are so many things I must do alone.\"\n",
      "prediction :  I want to go, to escape.\n",
      "Real answer : But Captain, I mean -- cannibals. What a pity, you don't drink. Since my husband died, there are so many things I must do alone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8847314119338989], 'recall': [0.8417977094650269], 'f1': [0.8627307415008545], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06451612903225806, 'rouge2': 0.0, 'rougeL': 0.06451612903225806, 'rougeLsum': 0.06451612903225806}\n",
      "bleu 1/2 : 0.007023973918212732 0.0024331759394766186\n",
      "ppl : 97.18850708007812\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROXANNE: Are you warm, Captain?\\nWILLARD: The river is beautiful.\\n\\n', 'answer': 'I spend hours watching that river from my bedroom window. It fascinates me.', 'gold_tag': 'ROXANNE spends hours watching the river from her bedroom window , ROXANNE has a contemplative or introspective nature', 'last_speaker': 'ROXANNE'}\n",
      "Last word -> ROXANNE : \"I spend hours watching that river from my bedroom window. It fascinates me.\"\n",
      "prediction :  Yeah. I'm not sure what's wrong, but we should head back.\n",
      "Real answer : I spend hours watching that river from my bedroom window. It fascinates me.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8663870096206665], 'recall': [0.8558396697044373], 'f1': [0.8610811233520508], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307693, 'rouge2': 0.0, 'rougeL': 0.07692307692307693, 'rougeLsum': 0.07692307692307693}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.09331512451172\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROXANNE: I will fix you breakfast.\\nWILLARD: I'm afraid I won't have time -- I gotta --\\nROXANNE: Whe you reach the boat you will find that half your fifty calibre stores -- a case of grenades, a mortar and two M-16's and a case of clips are being transfered to us by your order.\\nWILLARD: So that's it.\\nROXANNE: You may think what you wish, Captain, but I like you very much.\\nWILLARD: What if I say no.\\n\\n\", 'answer': 'Then Philippe will have to kill all of you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROXANNE'}\n",
      "Last word -> ROXANNE : \"Then Philippe will have to kill all of you.\"\n",
      "prediction :  I am going to take this opportunity to ask if you might like to buy a yacht. You know, I need something that can go the distance.\n",
      "Real answer : Then Philippe will have to kill all of you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8492712378501892], 'recall': [0.8654458522796631], 'f1': [0.8572822213172913], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0.037037037037037035 0.01193524790065722\n",
      "ppl : 22.16252899169922\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMcCALEB: What do you got going tomorrow?\\nBUDDY: Same as always. egg.\\nMcCALEB: I need a driver for a few days. Ten bucks an hour plus meals.\\nBUDDY: What is it, an investigation?\\nMcCALEB: I’m looking for a driver, Buddy, not a partner.\\nBUDDY: Okay. I’m in. Whose car.\\nMcCALEB: We take yours, I pay for gas. We take mine, I sit in the back.\\nBUDDY: Right, cuz of your chest, right? Let’s take mine. too much of a chauffeur with you\\nMcCALEB: See you in the morning.\\n\\n', 'answer': 'You look tired, McCaleb. You should get some sleep.', 'gold_tag': 'McCALEB appears to be tired in the present', 'last_speaker': 'BUDDY'}\n",
      "Last word -> BUDDY : \"You look tired, McCaleb. You should get some sleep.\"\n",
      "prediction :  Oh, the day of my final exams. All the blood!\n",
      "Real answer : You look tired, McCaleb. You should get some sleep.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8448970913887024], 'recall': [0.8569910526275635], 'f1': [0.8509011268615723], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 88.60088348388672\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMcCALEB: Hey, Buddy! You’re working tomorrow. Six AM.\\n\\n', 'answer': 'Cool. Aww shit, Terry!', 'gold_tag': 'BUDDY works the early shift', 'last_speaker': 'BUDDY'}\n",
      "Last word -> BUDDY : \"Cool. Aww shit, Terry!\"\n",
      "prediction :  Yes.\n",
      "Real answer : Cool. Aww shit, Terry!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9706835150718689], 'recall': [0.848886251449585], 'f1': [0.9057084321975708], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2505.07666015625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBUDDY: Who wants to go to the desert anyhow?\\nMcCALEB: You go where the clues lead.\\n\\n', 'answer': 'Don’t any clues lead to the beach for crying out loud?!', 'gold_tag': 'BUDDY prefers going to the beach', 'last_speaker': 'BUDDY'}\n",
      "Last word -> BUDDY : \"Don’t any clues lead to the beach for crying out loud?!\"\n",
      "prediction :  I got it!\n",
      "Real answer : Don’t any clues lead to the beach for crying out loud?!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.826324462890625], 'recall': [0.8082166910171509], 'f1': [0.8171703219413757], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 235.66468811035156\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMcCALEB: Shit... What do you figure I owe you, Buddy?\\nBUDDY: Um, about two hundred or so.\\nMcCALEB: Sounds right.\\nBUDDY: You look like shit, Terry. You should take a nap or something.\\nMcCALEB: You take a check?\\nBUDDY: Sure.\\nMcCALEB: I’ll bring it over. Should I make it out to Buddy?\\nBUDDY: Jasper. Jasper Noone.\\nMcCALEB: I knew the Noone part.\\n\\n', 'answer': 'I look more like a Buddy than a Jasper, huh? Take a nap!', 'gold_tag': \"BUDDY is informal and casual, showing concern for McCALEB's health\", 'last_speaker': 'BUDDY'}\n",
      "Last word -> BUDDY : \"I look more like a Buddy than a Jasper, huh? Take a nap!\"\n",
      "prediction :  Good. Let’s make it official.\n",
      "Real answer : I look more like a Buddy than a Jasper, huh? Take a nap!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8713595867156982], 'recall': [0.842064380645752], 'f1': [0.8564615249633789], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 67.00318145751953\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLUKE: You ask me that counselor's making a mountain out of a molehill...\\nJACKIE: I'm worried.\\nLUKE: Me too.\\nJACKIE: Luke, I need to switch next Friday for Thursday, so why don't you take the weekend... ...that way you'll be there, and I'll pick up Monday, Tuesday, and Wednesday.\\nLUKE: Fine. But I wanted to take the kids to work with me on Wednesday so I'll take Wednesday, and you can pick up that Thursday, Friday after soccer, and Saturday before riding.\\nJACKIE: Easy enough.\\n\\n\", 'answer': 'Good...Well...Take care.', 'gold_tag': 'LUKE agrees to take the children on the upcoming weekend and on Wednesday', 'last_speaker': 'LUKE'}\n",
      "Last word -> LUKE : \"Good...Well...Take care.\"\n",
      "prediction :  But is it true what he's claiming? That there's a reason your brother is being deployed?\n",
      "Real answer : Good...Well...Take care.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.829445481300354], 'recall': [0.8292050957679749], 'f1': [0.829325258731842], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 44.946990966796875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACKIE: You know, you can come inside the house.\\nLUKE: Did you see the lawyer? Oh. Well...\\nJACKIE: Called him. We set an ap...\\nLUKE: Don't do this.\\nJACKIE: You're saying, don't make the kids a football, don't put them through a war. But I'm doing this for their well-being.\\nLUKE: Partly. But partly, you're mad. You know the kids aren't really in danger. This is about Rachel, and you're right, I'm disappointed in her learning curve, and...\\nJACKIE: Slugs. Have faster learning curves. Trees, even.\\nLUKE: I'm afraid she's going to walk.\\nJACKIE: And I'm supposed to care.\\nLUKE: About me, yeh. Like I care about you.\\nJACKIE: Like you cared about me three years ago?\\nLUKE: Hey. You kicked me out.\\nJACKIE: Maybe you should talk to your daughter, about why. She seems to have missed that part. Forget I said that.\\nLUKE: This thing with Rache. I need this. I don't want to lose her. And I will see to it that the kids don't suffer. Help me, huh? I'd do it for you.\\n\\n\", 'answer': \"One last chance, don't make me regret it... ...or you will, too.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'JACKIE'}\n",
      "Last word -> JACKIE : \"One last chance, don't make me regret it... ...or you will, too.\"\n",
      "prediction :  You're going to turn those kids against you and I'm not going to have that happen. I'm not going to have that happen, and I'm not going to lose you...I...I love you, Luke. I always loved you.\n",
      "Real answer : One last chance, don't make me regret it... ...or you will, too.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8379116058349609], 'recall': [0.8362860679626465], 'f1': [0.8370980024337769], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.03571428571428571, 'rouge2': 0.0, 'rougeL': 0.03571428571428571, 'rougeLsum': 0.03571428571428571}\n",
      "bleu 1/2 : 0.02702702702702703 0.008664587415167273\n",
      "ppl : 7.935913562774658\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACKIE: I thought a phone call was inappropriate. I could have taken you to that restaurant, but it would have been a waste of money. I know. I wouldn't know what to say. If it were you.\\nLUKE: We're going to win this.\\nJACKIE: Walk in the park. And thanks for the 'we'.\\nLUKE: You're not alone in this. You're not alone. Jesus, you're not alone, okay? What happens next?\\nJACKIE: I live or I die.\\nLUKE: Tell the kids together? Want Rache someplace else?\\n\\n\", 'answer': 'My compliments. On your learning curve.', 'gold_tag': 'LUKE receives compliments from Jackie regarding his learning curve', 'last_speaker': 'JACKIE'}\n",
      "Last word -> JACKIE : \"My compliments. On your learning curve.\"\n",
      "prediction :  We should tell the kids.\n",
      "Real answer : My compliments. On your learning curve.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8845553398132324], 'recall': [0.8957005143165588], 'f1': [0.8900930285453796], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 306.422119140625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHERRICK: You're early, Mr. Rus. Again, pick it up at bar twenty-four. Where were you, Mr. Rus?\\nRUS: Sorry.\\nHERRICK: And Miss Lubbers, could you find a key closer to the one the rest of us are using? Thank you. People, let's try to start together. Again, from bar twenty- four. Mr. Rus, if you would, please. Let's walk and talk. Mr. Rus, I thought you said you could read music.\\n\\n\", 'answer': \"I can, when it has words. This stuff's got no words. Herrick looks like he just crapped a pineapple.\", 'gold_tag': 'RUS struggles with reading music without words', 'last_speaker': 'RUS'}\n",
      "Last word -> RUS : \"I can, when it has words. This stuff's got no words. Herrick looks like he just crapped a pineapple.\"\n",
      "prediction :  (looking at his watch) It's quite late. I had to pay off a loan from my dad.\n",
      "Real answer : I can, when it has words. This stuff's got no words. Herrick looks like he just crapped a pineapple.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8485691547393799], 'recall': [0.8373247981071472], 'f1': [0.8429094552993774], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2105263157894737, 'rouge2': 0.0, 'rougeL': 0.15789473684210525, 'rougeLsum': 0.15789473684210525}\n",
      "bleu 1/2 : 0.10458938416503243 0.024106661926760035\n",
      "ppl : 22.017595291137695\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHERRICK: E - G - B - D - F... It's easy to remember. Every Good Boy Does Fine. F - A - C - E... Face, that's easy enough. Those are the notes.\\nRUS: It's like a code.\\n\\n\", 'answer': \"Exactly! And you have to know that code because it's telling you where to come in. Exactly!\", 'gold_tag': 'HERRICK has knowledge of reading musical notes', 'last_speaker': 'HERRICK'}\n",
      "Last word -> HERRICK : \"Exactly! And you have to know that code because it's telling you where to come in. Exactly!\"\n",
      "prediction :  Well, it is.\n",
      "Real answer : Exactly! And you have to know that code because it's telling you where to come in. Exactly!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8799830079078674], 'recall': [0.832019567489624], 'f1': [0.8553294539451599], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809525, 'rouge2': 0.0, 'rougeL': 0.09523809523809525, 'rougeLsum': 0.09523809523809525}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 196.20436096191406\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHERRICK: Just sing the notes on the page.\\nRUS: I sing like shit... sorry, Mr. Herrick. I sing like... you know.\\nHERRICK: I'm not auditioning you for the Metropolitan opera. Just sing the notes.\\nRUS: Okay.\\n\\n\", 'answer': \"That's a sharp. Go on.\", 'gold_tag': 'HERRICK is knowledgeable about singing and musical notation', 'last_speaker': 'HERRICK'}\n",
      "Last word -> HERRICK : \"That's a sharp. Go on.\"\n",
      "prediction :  Okay.\n",
      "Real answer : That's a sharp. Go on.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9375439286231995], 'recall': [0.8659644722938538], 'f1': [0.9003337621688843], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 6285.04248046875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRUS: Da-da-da-da-da-de-de-dum.. Herrick isn't really listening. Da-dum-da-dum-da-da-da... Da-da-dum-dum-de. BOOM! BOOM! Da-da-da-daah! Converted to PDF by www.screentalk.org 43. BOOM! Rus laughs and beats out a celebratory riff on the big drum.\\nHERRICK: All right, all right! I don't see any notation calling for improvisation, Mr. Rus.\\nRUS: I did it! Wow! Hey, Mr. Herrick I can play this shit! Sorry, play this drum.\\nHERRICK: Yes, Mr. Rus, you can. Maybe you don't know it, but you've also learned a new language. A whole new language.\\nRUS: Wow, I did. I have.\\nHERRICK: Maybe all you wanted to do was bang on something, but you, sir, have learned a language.\\nRUS: Yeah! Wait'll my dad hears this shit... sorry, stuff.\\n\\n\", 'answer': \"There's nothing to be sorry about, Mr. Rus. Herrick catches some of Rust enthusiasm.\", 'gold_tag': 'HERRICK is open-minded and appreciative of enthusiasm', 'last_speaker': 'HERRICK'}\n",
      "Last word -> HERRICK : \"There's nothing to be sorry about, Mr. Rus. Herrick catches some of Rust enthusiasm.\"\n",
      "prediction :  Yeah, you can bang on something with that. You're so quick with the new things.\n",
      "Real answer : There's nothing to be sorry about, Mr. Rus. Herrick catches some of Rust enthusiasm.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8642776012420654], 'recall': [0.8342937231063843], 'f1': [0.8490209579467773], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 59.06066131591797\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEEBAND: What are you doing up so late?\\nKURT: I... I’ve been out.\\n\\n', 'answer': 'Alcohol? Hardly conducive to good work. You should get to bed.', 'gold_tag': \"SEEBAND is concerned about KURT's potential consumption of alcohol and its impact on his work , KURT has been out late at night\", 'last_speaker': 'SEEBAND'}\n",
      "Last word -> SEEBAND : \"Alcohol? Hardly conducive to good work. You should get to bed.\"\n",
      "prediction :  Have you been out a lot?\n",
      "Real answer : Alcohol? Hardly conducive to good work. You should get to bed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.856518030166626], 'recall': [0.8549581170082092], 'f1': [0.8557373881340027], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352942, 'rouge2': 0.0, 'rougeL': 0.11764705882352942, 'rougeLsum': 0.11764705882352942}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 96.48641204833984\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKURT: Professor Seeband, about yesterday; of course I would never...\\n\\n', 'answer': 'You have a new subject. Me. For the directors’ gallery. (indicates a sketched portrait of Lenin) That style, more or less. We start tomorrow at four in the afternoon. In my office at the hospital.', 'gold_tag': 'SEEBAND is a professor and likely a director , SEEBAND works in an office at a hospital , SEEBAND has arranged a meeting with KURT for the next day at four in his office', 'last_speaker': 'SEEBAND'}\n",
      "Last word -> SEEBAND : \"You have a new subject. Me. For the directors’ gallery. (indicates a sketched portrait of Lenin) That style, more or less. We start tomorrow at four in the afternoon. In my office at the hospital.\"\n",
      "prediction :  Who were the speakers?\n",
      "Real answer : You have a new subject. Me. For the directors’ gallery. (indicates a sketched portrait of Lenin) That style, more or less. We start tomorrow at four in the afternoon. In my office at the hospital.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8412996530532837], 'recall': [0.8320156335830688], 'f1': [0.8366318941116333], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05128205128205128, 'rouge2': 0.0, 'rougeL': 0.05128205128205128, 'rougeLsum': 0.05128205128205128}\n",
      "bleu 1/2 : 0.00010768563514392188 3.932123432506473e-05\n",
      "ppl : 336.2634582519531\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKURT: An... abortion?\\nSEEBAND: If I do not remove the fetus she will not survive the pregnancy.\\nKURT: Here?\\nSEEBAND: We have a reputation to maintain.\\nKURT: Is it really the only way? Really?\\n\\n', 'answer': 'Are you doubting my professional ability? Would I put myself through something like this... and my daughter!... if it were not absolutely necessary?', 'gold_tag': 'SEEBAND prioritizes professional reputation , SEEBAND is potentially a parent to a female patient', 'last_speaker': 'SEEBAND'}\n",
      "Last word -> SEEBAND : \"Are you doubting my professional ability? Would I put myself through something like this... and my daughter!... if it were not absolutely necessary?\"\n",
      "prediction :  A-are you pregnant?\n",
      "Real answer : Are you doubting my professional ability? Would I put myself through something like this... and my daughter!... if it were not absolutely necessary?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8517872095108032], 'recall': [0.8077895641326904], 'f1': [0.8292051553726196], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14814814814814817, 'rouge2': 0.08, 'rougeL': 0.14814814814814817, 'rougeLsum': 0.14814814814814817}\n",
      "bleu 1/2 : 0.0004242112671132693 0.0001642963172803238\n",
      "ppl : 411.0784606933594\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOP #1: For God's sake, Tom, there's a monster in there! Call for assistance and tell them to bring guns.\\n\\n\", 'answer': 'Keep moving! Will you people', 'gold_tag': 'Everyday Language', 'last_speaker': 'COP #2'}\n",
      "Last word -> COP #2 : \"Keep moving! Will you people\"\n",
      "prediction :  Sir, I just got information about the monster. I am sending an Officer.\n",
      "Real answer : Keep moving! Will you people\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8399115800857544], 'recall': [0.8118700385093689], 'f1': [0.8256528377532959], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 134.96055603027344\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOP #1: There he is!\\n\\n', 'answer': \"It's that Spider-Man!\", 'gold_tag': 'Everyday Language', 'last_speaker': 'COP #2'}\n",
      "Last word -> COP #2 : \"It's that Spider-Man!\"\n",
      "prediction :  There's two in there.\n",
      "Real answer : It's that Spider-Man!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8829960823059082], 'recall': [0.8592596054077148], 'f1': [0.8709661364555359], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20000000000000004, 'rouge2': 0.0, 'rougeL': 0.20000000000000004, 'rougeLsum': 0.20000000000000004}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 91.77983093261719\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOP #2: He won't get away this time!\\nCOP #1: Hold your fire! He's got a girl.\\n\\n\", 'answer': \"Looks like he's got a hostage.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'COP #2'}\n",
      "Last word -> COP #2 : \"Looks like he's got a hostage.\"\n",
      "prediction :  He's got what?\n",
      "Real answer : Looks like he's got a hostage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8668015599250793], 'recall': [0.8787967562675476], 'f1': [0.8727579712867737], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.5454545454545454, 'rouge2': 0.4444444444444444, 'rougeL': 0.5454545454545454, 'rougeLsum': 0.5454545454545454}\n",
      "bleu 1/2 : 0.12262648039048077 0.04749303163563625\n",
      "ppl : 123.44308471679688\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWARDEN: I am wet.\\nKAREN: If you're looking for my husband, he isn't here.\\nWARDEN: And if I'm not looking for him?\\nKAREN: He still isn't here. If that does you any good.\\nWARDEN: Well, I'm looking for him. Do you know where he is?\\nKAREN: I haven't the slightest idea. Perhaps he's in town. I guess it was `in town' the way you put it, wasn't it? Or perhaps he's at the Club. Having a drink.\\nWARDEN: I got some papers it's important for him to sign. Today.\\nKAREN: I'll try phoning him at the Club for you.\\nWARDEN: I never like to disturb a man drinking.\\nKAREN: What is it you want, Sergeant?\\n\\n\", 'answer': \"I could use a drink myself right now. Bad. Anyway, I got a faint suspicion the Captain's `in town.' Ain't you going to ask me in? 28.\", 'gold_tag': 'WARDEN appreciates a good drink , WARDEN has an authoritative persona and a slight dry sense of humor , KAREN is a good host', 'last_speaker': 'WARDEN'}\n",
      "Last word -> WARDEN : \"I could use a drink myself right now. Bad. Anyway, I got a faint suspicion the Captain's `in town.' Ain't you going to ask me in? 28.\"\n",
      "prediction :  Well, we're going to go to the Club. I'm going to stay there until he shows up.\n",
      "Real answer : I could use a drink myself right now. Bad. Anyway, I got a faint suspicion the Captain's `in town.' Ain't you going to ask me in? 28.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8746405839920044], 'recall': [0.8361554741859436], 'f1': [0.8549651503562927], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.043478260869565216, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.09799524229446188 0.05831883409863456\n",
      "ppl : 16.078439712524414\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAREN: You're taking an awful chance, you know. My maid is liable to be home any time.\\nWARDEN: No she won't. Thursday's her day off.\\nKAREN: You think of everything, don't you, Sergeant?\\nWARDEN: I try. In my position you have to.\\nKAREN: Are these really important?\\nWARDEN: Yes. But not important they get signed today. Tomorrow's okay. I got carbons of those back at the office. So it won't be much work to fix them up.\\nKAREN: That's what I like about you, Sergeant. You have confidence. It's also what I dislike about you.\\nWARDEN: It's not confidence. It's honesty.\\nKAREN: Honesty? How did you acquire such an old-fashioned virtue?\\nWARDEN: I figgered out one day it was the shortest distance between two points.\\nKAREN: Well, he's clever as well as virile.\\nWARDEN: No -- it's just that I hate to see a beautiful woman goin all to waste.\\nKAREN: Waste, did you say? Now that's a subject I might tell you something about. There's we. And then there's waste. Positive and negative. The negative is sometimes more interesting... more evil. For example -- what about the house without a child? Tell me your thoughts, Sergeant.\\nWARDEN: You're going to cry.\\nKAREN: Not if I can help it.\\nWARDEN: Please don't cry... I can't stand to see somebody cry.\\nKAREN: What are you doing?\\nWARDEN: I'm leaving. Isn't that what you want?\\nKAREN: I don't know, Sergeant. To be honest, I don't know.\\nWARDEN: I know a beach near Diamond Head. Nobody ever goes there. The cars on the highway pass above and they never know it's there. You feel like you used to feel when you were a kid, hiding by yourself in a cave, watching the others hunting you.\\nKAREN: Maybe... why not?\\nWARDEN: How about Payday?\\nKAREN: You don't have to spend money on me, Sergeant.\\nWARDEN: I just like to have some on me when I take out a woman. Can you get away?\\nKAREN: Maybe.\\n\\n\", 'answer': \"I'll be in Kuhio Park. Say, nine o'clock. Payday.\", 'gold_tag': \"WARDEN has a meeting with KAREN at Kuhio Park on Payday at nine o'clock\", 'last_speaker': 'WARDEN'}\n",
      "Last word -> WARDEN : \"I'll be in Kuhio Park. Say, nine o'clock. Payday.\"\n",
      "prediction :  Do I strike you as the type to have a good time?\n",
      "Real answer : I'll be in Kuhio Park. Say, nine o'clock. Payday.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8271586894989014], 'recall': [0.8435958623886108], 'f1': [0.8352963924407959], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913043, 'rouge2': 0.0, 'rougeL': 0.08695652173913043, 'rougeLsum': 0.08695652173913043}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 29.227231979370117\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAREN: Why, hello. I didn't think you were coming.\\nWARDEN: Why not? I'm not late.\\nKAREN: No, I guess you're not. But then I came a little early. I must have been overanxious. You weren't overanxious though, were you? You got here right on the dot.\\nWARDEN: Maybe I'd of been early too only I stopped to get a drink.\\nKAREN: You certainly chose a savory spot for our meeting.\\nWARDEN: Would you rather it'd been the cocktail lounge of the Royal?\\nKAREN: No, but I've had five chances to be picked up in the last few minutes.\\nWARDEN: That's par for the course around here.\\nKAREN: Well, I don't care for it. I never went in much for back-alley loving.\\nWARDEN: Didn't you?\\nKAREN: You probably think I'm a tramp, don't you?\\nWARDEN: What makes you think I'd think that?\\nKAREN: Don't try to be gallant, Sergeant. If you think this is a mistake, come right out and say so.\\nWARDEN: Listen, what started all this, anyway? Why'm I shakin inside like a school kid out with teacher! Where'd I come up with a yen for of all things the Compny Commander's wife! And her actin like Lady Astor's horse all because I only got here on time!\\nKAREN: On the other hand, I've got a bathing suit under my dress.\\n\\n\", 'answer': 'Funny. I got one in a U-Drive-It parked around the corner.', 'gold_tag': 'Everyday Language', 'last_speaker': 'WARDEN'}\n",
      "Last word -> WARDEN : \"Funny. I got one in a U-Drive-It parked around the corner.\"\n",
      "prediction :  (a tad too eager) ... I'd like to find out how long it took you to get here.\n",
      "Real answer : Funny. I got one in a U-Drive-It parked around the corner.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8299362063407898], 'recall': [0.8576216697692871], 'f1': [0.843551754951477], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1935483870967742, 'rouge2': 0.0, 'rougeL': 0.12903225806451615, 'rougeLsum': 0.12903225806451615}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.956462860107422\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAREN: I hope the ocean's ice cold. I hope\\nWARDEN: Just so long's you melt afterwards.\\n\\n\", 'answer': 'I love the way you laugh.', 'gold_tag': 'KAREN values humor , WARDEN displays a witty nature', 'last_speaker': 'KAREN'}\n",
      "Last word -> KAREN : \"I love the way you laugh.\"\n",
      "prediction :  Cool\n",
      "Real answer : I love the way you laugh.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8460530638694763], 'recall': [0.8548836708068848], 'f1': [0.8504454493522644], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13912490.0\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAREN: Nobody ever kissed me that way... not really...\\nWARDEN: Nobody?\\nKAREN: No. Nobody.\\nWARDEN: Not even one? Out of all the many men you've been kissed by?\\nKAREN: Well, that will take some figuring. How many men do you think there've been?\\nWARDEN: I wouldn't know. Can't you even make me a rough estimate?\\nKAREN: Not without an adding machine. Do you have your adding machine with you?\\nWARDEN: No, I forgot to bring it.\\nKAREN: Then I guess you won't find out, will you?\\nWARDEN: Maybe I already know.\\nKAREN: What's the matter? What are you hinting at?\\nWARDEN: Why? Is there something to hint at?\\nKAREN: I don't know. Maybe a lot. Or maybe you just think there's a lot.\\nWARDEN: Maybe I do. Maybe there's been a long line of beach parties --\\nKAREN: You must be crazy -- !\\nWARDEN: Am I? Listen, baby, maybe not here. But what about when you and Holmes were at Fort Bliss?\\nKAREN: I had to go and forget you were a man -- with the same rotten filthy mind the rest of them have. For a minute I had to convince myself you were different --\\nWARDEN: Only it's true, ain't it?\\nKAREN: Yes, it's true! A part of it, some small part of whatever sewage you've been listening to. Some day perhaps you'll get all the story.\\nWARDEN: All what story?\\n\\n\", 'answer': \"You're getting to sound so much like a typical male. So you just sweat it out like a typical male.\", 'gold_tag': 'KAREN reveals defensiveness when her past is questioned', 'last_speaker': 'KAREN'}\n",
      "Last word -> KAREN : \"You're getting to sound so much like a typical male. So you just sweat it out like a typical male.\"\n",
      "prediction :  A part of your life -- a story you're not allowed to live. A story I thought I must live. Is it only a part of your story that I can't share?\n",
      "Real answer : You're getting to sound so much like a typical male. So you just sweat it out like a typical male.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8414702415466309], 'recall': [0.8558729290962219], 'f1': [0.848610520362854], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2222222222222222, 'rouge2': 0.038461538461538464, 'rougeL': 0.2222222222222222, 'rougeLsum': 0.2222222222222222}\n",
      "bleu 1/2 : 0.12500000000000003 0.020080483222562468\n",
      "ppl : 21.557994842529297\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAREN: All right. I've never told it to anyone before. But I think now is the time. I'll tell you the whole bloody messy thing. You can take it back to the barracks with you. I'd been married to Captain Dana E. Holmes two years. Only he was a First Lieutenant then. Back at Fort Bliss. We lived right on a little lake where we could fish and swim and be alone, our 'dream cottage'... I'm sure you must be able to picture it. It was off on a back road, four miles from the highway. Two miles from a neighbor and a telephone.... I hadn't been married long when I knew my husband was stepping out on me. But -- you get used to that. Your mother tells you that it's life, that i t happens to a lot of women. Of course, she doesn't tell you until after it happens. Then, by that time, you're pregnant. And at least you've something else to hope for. I think I was almost happy that night the pains began. Even though they were weeks too early, a whole month too on that dapper silk gabardine uniform he used to wear. He was going to an officer's 'seminar.' He was kidding me about false labor. I didn't think it was humorous. I told him to get home early, to bring the doctor with him. He smiled tenderly and told me about the psychic reactions of women to pregnancy. But never fear, he'd be back early. And maybe he would have... if the 'seminar' hadn't been with the hat-check girl in one of the night clubs.\\nWARDEN: Listen.\\nKAREN: He was only a little drunk when he came in... at five a.m. He looked alarmed when he saw me. I guess it was because of my screams. I was lying there on the floor, you see -- No, don't say anything. I'm not finished yet. Of course, the baby was dead. It was a boy. But they worked over me at the hospital and fixed me up fine. They even took my appendix out, too. They threw that in free. It was all fine.\\nWARDEN: Listen. Listen. Please.\\nKAREN: And, of course, one more thing no more children. Do you know what that means? You're not a woman. You're not anything. You're a gutted shell... Sure, I went out with some of the men after that. A few months of it. I'd been made dirty and I wanted to be clean. You can see that, can't you?... Anyway, I got my revenge on Dana. I kept on living with him.\\nWARDEN: The hateful, miserable --\\nKAREN: You hunt so hungrily for love... love, if you can find it, you think, might give things meaning again.\\nWARDEN: Listens Listen to me --\\n\\n\", 'answer': \"All right. I'm listening. I know. Until I met you I didn't think it was possible, either.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'KAREN'}\n",
      "Last word -> KAREN : \"All right. I'm listening. I know. Until I met you I didn't think it was possible, either.\"\n",
      "prediction :  And now I've got nothing -- I don't know you any more. I can't find out the man I was married to any more. I don't even know my old father any more --\n",
      "Real answer : All right. I'm listening. I know. Until I met you I didn't think it was possible, either.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8344097137451172], 'recall': [0.8666850328445435], 'f1': [0.8502411842346191], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2909090909090909, 'rouge2': 0.0, 'rougeL': 0.2545454545454545, 'rougeLsum': 0.2545454545454545}\n",
      "bleu 1/2 : 0.14705882352941177 0.021110016546037454\n",
      "ppl : 11.972183227539062\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAREN: You just love to shock people, don't you?! Where on earth did you learn to dance like that?\\n\\n\", 'answer': 'Believe it or not -- Chicago, Illinois.', 'gold_tag': 'WARDEN learned to dance in Chicago, Illinois', 'last_speaker': 'WARDEN'}\n",
      "Last word -> WARDEN : \"Believe it or not -- Chicago, Illinois.\"\n",
      "prediction :  It was a bit hard going at first. But the more I tried, the easier it got. A man was watching me and he liked my moves. Later, I became known as \"The Dancing Senator\". And then the world knew I was The Dancing Senator.\n",
      "Real answer : Believe it or not -- Chicago, Illinois.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8275041580200195], 'recall': [0.8252904415130615], 'f1': [0.8263958096504211], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0392156862745098, 'rouge2': 0.0, 'rougeL': 0.0392156862745098, 'rougeLsum': 0.0392156862745098}\n",
      "bleu 1/2 : 0.022222222222222227 0.007106690545187016\n",
      "ppl : 17.031314849853516\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOCTOR EINSTEIN: Hey, Johnny, down here, what do you think I find ?\\nJONATHAN: What ?\\nDOCTOR EINSTEIN: The Panama Canal. And it just fits Mister Spenalzo. See the hole he's digging. Four feet wide, six feet long. He just fits ! You'd think he knew we were bringing Mister Spenalzo along. That's hospitality.\\nJONATHAN: Rather a good joke on my aunts. They're living in a house with a body buried in the cellar.\\nDOCTOR EINSTEIN: Hey, how do we get him in here ?\\nJONATHAN: Yes, we can't just walk Mister Spenalzo in through the door. We'll bring the car up between the cemetery and the house, and after they've gone to bed, we'll bring Mister Spenalzo in through the window.\\n\\n\", 'answer': 'Hey, Johnny...', 'gold_tag': 'Everyday Language', 'last_speaker': 'DOCTOR EINSTEIN'}\n",
      "Last word -> DOCTOR EINSTEIN : \"Hey, Johnny...\"\n",
      "prediction :  But why is he digging in Panama ?\n",
      "Real answer : Hey, Johnny...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.824856162071228], 'recall': [0.8358984589576721], 'f1': [0.830340564250946], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 801.1834716796875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOCTOR EINSTEIN: Hey, Johnny, Johnny, come quick !\\nJONATHAN: What's the matter ?\\nDOCTOR EINSTEIN: You know that hole in the cellar ?\\nJONATHAN: Yes.\\n\\n\", 'answer': 'Well, we got an ace in the hole.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DOCTOR EINSTEIN'}\n",
      "Last word -> DOCTOR EINSTEIN : \"Well, we got an ace in the hole.\"\n",
      "prediction :  The time is now.\n",
      "Real answer : Well, we got an ace in the hole.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8561171889305115], 'recall': [0.8550366759300232], 'f1': [0.8555766344070435], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 84.87808990478516\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOCTOR EINSTEIN: This is all fixed up nice now. Nice and smooth like a lake. Oh, Johnny, bed feels good already. You know, we didn't get any sleep for forty-eight hours.\\nJONATHAN: You're forgetting, Doctor.\\n\\n\", 'answer': 'What ?', 'gold_tag': 'Everyday Language', 'last_speaker': 'DOCTOR EINSTEIN'}\n",
      "Last word -> DOCTOR EINSTEIN : \"What ?\"\n",
      "prediction :  Right. We don't have to move, now do we?\n",
      "Real answer : What ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8216826915740967], 'recall': [0.8118427991867065], 'f1': [0.8167331218719482], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 25.2706241607666\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJONATHAN: My brother, Mortimer. I just heard him upstairs.\\nDOCTOR EINSTEIN: No, no, no ! I am tired. You forget, I got to operate on your face tomorrow.\\nJONATHAN: (voice over. We just see his shadow on the wall behind You are going to operate tomorrow, Doctor. But tonight we are taking care of Mortimer.\\nDOCTOR EINSTEIN: No, but Johnny, not tonight ! I'm sleepy. We'll do it tomorrow. Or the next day.\\nJONATHAN: Look at me, Doctor. You can see that it's got to be done, can't you?\\nDOCTOR EINSTEIN: Yeah, I know that look.\\nJONATHAN: It's a little late to dissolve our partnership.\\nDOCTOR EINSTEIN: Okay, okay, Johnny, okay. We'll do it. But the quick way, huh ? The quick twist like in London.\\nJONATHAN: No, Doctor. I think this calls for something special. I think, perhaps, the Melbourne method.\\n\\n\", 'answer': 'Not the Melbourne method, please ! Two hours ! And then when it was all over, what ? The fellow in London was just as dead as the fellow in Melbourne.', 'gold_tag': 'DOCTOR EINSTEIN and JONATHAN have a shared history of performing operations together, as suggested by their references to the \"quick twist like in London\" and the \"Melbourne method. \".', 'last_speaker': 'DOCTOR EINSTEIN'}\n",
      "Last word -> DOCTOR EINSTEIN : \"Not the Melbourne method, please ! Two hours ! And then when it was all over, what ? The fellow in London was just as dead as the fellow in Melbourne.\"\n",
      "prediction :  (voice over. I think the Melbourne method is a little dangerous, but it will do for now.) Let me show you on my back.\n",
      "Real answer : Not the Melbourne method, please ! Two hours ! And then when it was all over, what ? The fellow in London was just as dead as the fellow in Melbourne.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8523707985877991], 'recall': [0.8428862690925598], 'f1': [0.8476019501686096], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1923076923076923, 'rouge2': 0.07999999999999999, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0.09337718753880407 0.05507086076385581\n",
      "ppl : 58.355525970458984\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nD.J.: His name is Ferris Mueller.\\n\\n', 'answer': 'Bueller. Ferris Bueller.', 'gold_tag': 'Everyday Language', 'last_speaker': 'FERRIS'}\n",
      "Last word -> FERRIS : \"Bueller. Ferris Bueller.\"\n",
      "prediction :  Well the truth is I-I tried to find something that would have to do with him.\n",
      "Real answer : Bueller. Ferris Bueller.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8000446557998657], 'recall': [0.821555495262146], 'f1': [0.8106574416160583], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 45.249881744384766\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nD.J.: Sorry about that.\\n\\n', 'answer': \"It's cool.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'FERRIS'}\n",
      "Last word -> FERRIS : \"It's cool.\"\n",
      "prediction :  Okay.\n",
      "Real answer : It's cool.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9381223917007446], 'recall': [0.8754082322120667], 'f1': [0.9056808948516846], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 6285.04248046875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nD.J.: He has an incredible story.\\n\\n', 'answer': \"I'm going to tell a massive lie here. It's going to by very thick and very steamy. I think radio's a facinating medium, it challenges the imagination. Unlike television which provides the images, radio... You know this. Anyway, it's always been a dream of mine to be on the radio. I have what I consider to be an excellent broadcast voice. I practise it in the bathroom all the time. I used to play records and do introductions to them. But I've never had the chance to sit behind a microphone and try it out for real. This is a 50,000 watt outlet. I'm going out to several million people so let me just say, I'm in a very pleasant groove right now. Well, Steve, you and your listeners are probably not going to believe this but...\", 'gold_tag': 'FERRIS is likely a young, aspiring radio broadcaster , FERRIS practices his broadcast voice and dreams of being on the radio , FERRIS tends to lie or exaggerate , FERRIS refers to his present state of being \"in a very pleasant groove\"', 'last_speaker': 'FERRIS'}\n",
      "Last word -> FERRIS : \"I'm going to tell a massive lie here. It's going to by very thick and very steamy. I think radio's a facinating medium, it challenges the imagination. Unlike television which provides the images, radio... You know this. Anyway, it's always been a dream of mine to be on the radio. I have what I consider to be an excellent broadcast voice. I practise it in the bathroom all the time. I used to play records and do introductions to them. But I've never had the chance to sit behind a microphone and try it out for real. This is a 50,000 watt outlet. I'm going out to several million people so let me just say, I'm in a very pleasant groove right now. Well, Steve, you and your listeners are probably not going to believe this but...\"\n",
      "prediction :  Where can I get a copy of that?\n",
      "Real answer : I'm going to tell a massive lie here. It's going to by very thick and very steamy. I think radio's a facinating medium, it challenges the imagination. Unlike television which provides the images, radio... You know this. Anyway, it's always been a dream of mine to be on the radio. I have what I consider to be an excellent broadcast voice. I practise it in the bathroom all the time. I used to play records and do introductions to them. But I've never had the chance to sit behind a microphone and try it out for real. This is a 50,000 watt outlet. I'm going out to several million people so let me just say, I'm in a very pleasant groove right now. Well, Steve, you and your listeners are probably not going to believe this but...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8317490816116333], 'recall': [0.7973775863647461], 'f1': [0.814200758934021], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0392156862745098, 'rouge2': 0.0, 'rougeL': 0.0392156862745098, 'rougeLsum': 0.0392156862745098}\n",
      "bleu 1/2 : 3.7241978670585916e-08 7.268889940274504e-09\n",
      "ppl : 27.934276580810547\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFERRIS: I was going to say I knew Springsteen's home phone number and I was going to give out the number of the New Jersey State Police but I thought I might get busted. After I got flunked in driver's ed for sideswiping a mail box, which was not in any way, shape or from my fault. I was putting out a cigarette, like I was told. It was weird. I'm so used to getting in a car and lighting up, because I'm not allowed to smoke at home, that I got in the driver's ed. car and spaced completely, pulled out of the lot, lit up a 'boro and Mrs. Heller looked at me like I'd just pulled a bunny out of my nose or something and I realized what the hell I was doing and I went to put it out and hit the mail box. Anyway, I was so pissed off at her reaction to the whole thing that I considered running an ad in a sleaze magazine for a school teacher that does phone sex and I was gonna use Mrs. Heller's home number but is cost too much. I took it again and passed. But I had to work at Burger King to get the cash to pay for the driver's ed. car. The car got fixed in auto shop for nothing and can't prove it? I'm in high school, remember?\\nD.J.: How did you get picked for this.\\n\\n\", 'answer': \"It's kind of a long story but I've been doing alot of programming for NASA.\", 'gold_tag': 'FERRIS does programming for NASA', 'last_speaker': 'FERRIS'}\n",
      "Last word -> FERRIS : \"It's kind of a long story but I've been doing alot of programming for NASA.\"\n",
      "prediction :  Well the thing that got me into this all is the fact that I knew, I actually knew that when we got our school schedule and it just happened to line up with the schedule for our drivers ed. class for our drivers ed. class, and that when we started working on the schedules I knew that my class was on this week and one of the days in the week was the day I was gonna get to kill Mrs. Heller.\n",
      "Real answer : It's kind of a long story but I've been doing alot of programming for NASA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8212757110595703], 'recall': [0.8564978837966919], 'f1': [0.8385171294212341], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08080808080808081, 'rouge2': 0.0, 'rougeL': 0.0606060606060606, 'rougeLsum': 0.0606060606060606}\n",
      "bleu 1/2 : 0.024390243902439022 0.005487386648053276\n",
      "ppl : 20.86052703857422\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK: How did you get all of this stuff into the country?\\nRAYMOND: This is America. There is nothing you can not buy.\\nNICK: So why all the secrecy? Why aren't you guys working with the US military?\\nRAYMOND: I am not permitted to speak of such things.\\nNICK: You said you wanted my trust, then I need yours.\\nRAYMOND: I am a patriot. I love my country. Can you understand that?\\nNICK: Sure.\\nRAYMOND: It is my job to protect my country. Sometimes I must even protect it from itself. From mistakes we have made. Mistakes that we do not want the world to know about.\\nNICK: Your talking about the nuclear testing in the Pacific.\\n\\n\", 'answer': 'Yes. This testing done by my country left a terrible mess. We are here to clean it up.', 'gold_tag': 'RAYMOND feels a responsibility toward his country', 'last_speaker': 'RAYMOND'}\n",
      "Last word -> RAYMOND : \"Yes. This testing done by my country left a terrible mess. We are here to clean it up.\"\n",
      "prediction :  Well as you can see, not every incident is public knowledge.\n",
      "Real answer : Yes. This testing done by my country left a terrible mess. We are here to clean it up.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8328145742416382], 'recall': [0.8767619132995605], 'f1': [0.854223370552063], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 66.78340911865234\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK: What's with the chewing gum?\\nRAYMOND: Makes us look more American.\\n\\n\", 'answer': 'Just let me do all the talking.', 'gold_tag': 'NICK is a leader or decision maker in their current scenario', 'last_speaker': 'NICK'}\n",
      "Last word -> NICK : \"Just let me do all the talking.\"\n",
      "prediction :  Well, he must be a regular old American.\n",
      "Real answer : Just let me do all the talking.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8535842895507812], 'recall': [0.8561052083969116], 'f1': [0.8548429012298584], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 117.87403869628906\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK: Three eggs. I thought there would be more.\\nRAYMOND: You were right.\\n\\n', 'answer': \"That can't be. That's got to be over twenty eggs.\", 'gold_tag': 'NICK scrutinizes the number of eggs', 'last_speaker': 'NICK'}\n",
      "Last word -> NICK : \"That can't be. That's got to be over twenty eggs.\"\n",
      "prediction :  You were? How many do you think we need?\n",
      "Real answer : That can't be. That's got to be over twenty eggs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8335543870925903], 'recall': [0.8476494550704956], 'f1': [0.8405428528785706], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 93.01316833496094\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK: Hey, it's me!\\n\\n\", 'answer': 'What happened?', 'gold_tag': 'Everyday Language', 'last_speaker': 'RAYMOND'}\n",
      "Last word -> RAYMOND : \"What happened?\"\n",
      "prediction :  You're not my mom.\n",
      "Real answer : What happened?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8406825065612793], 'recall': [0.83207106590271], 'f1': [0.8363546133041382], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 64.4334716796875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBUD: Lynn Wheeler. We haven't been properly introduced. I'm Detective Bud Carter.\\nLYNN: I know who you are.\\nBUD: You have a ride home?\\nLYNN: We took the bus.\\n\\n\", 'answer': \"Take a cab. 'You need anything...anything at all. Be sure to call me.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"Take a cab. 'You need anything...anything at all. Be sure to call me.\"\n",
      "prediction :  I heard about your accident. All the papers ran it.\n",
      "Real answer : Take a cab. 'You need anything...anything at all. Be sure to call me.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.870003342628479], 'recall': [0.84693843126297], 'f1': [0.8583159446716309], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08333333333333333, 'rouge2': 0.0, 'rougeL': 0.08333333333333333, 'rougeLsum': 0.08333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 139.93431091308594\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLYNN: It's Officer White, isn't it? Can I get you a drink?\\nBUD: Yeah, plain scotch.\\nLYNN: I was friendly with Sue Lefferts, but we weren't really friends. You know what I mean?\\nBUD: Are you sorry she's dead?\\nLYNN: Of course I am. What kind of question is that?\\nBUD: Have you ever heard of Dick Stensland?\\nLYNN: No I haven't. Do you know why Pierce is humoring you?\\nBUD: You use words like that, you might make me mad.\\nLYNN: Yes. But do you know?\\nBUD: Yeah I know. Patchett's running whores and judging by his address, probably something bigger on the side. He doesn't want any attention.\\nLYNN: That's right. Our motives are selfish, so we're cooperating.\\nBUD: Why was Susan Lefferts at the Nite Owl?\\nLYNN: I don't know. I never heard of the Nite Owl till today.\\nBUD: Did Lefferts have a boyfriend?\\nLYNN: Like I said we were friendly, not friends.\\nBUD: How'd she meet Patchett?\\nLYNN: Pierce meets people. Sue came on the bus with dreams of Hollywood. This is how they turned out. Thanks to Pierce, we still get to act a little.\\nBUD: Tell me about Patchett.\\nLYNN: He's waiting for you to mention mention.\\nBUD: You want some advice, Miss Bracken?\\nLYNN: It's Lynn.\\nBUD: Miss Bracken, don't ever try to fucking bribe me or threaten me or I'll have you and Patchett in shit up to your ears.\\nLYNN: I remember you from Christmas Eve. You have a thing for helping women, don't you, Officer White?\\nBUD: Maybe I'm just fucking curious.\\nLYNN: You say 'fuck' a lot.\\nBUD: You fuck for money.\\nLYNN: There's blood on your shirt. Is that an integral part of your job?\\nBUD: Yeah.\\nLYNN: Do you enjoy it?\\nBUD: When they deserve it.\\nLYNN: Did they deserve it today?\\nBUD: I'm not sure.\\nLYNN: But you did it anyway.\\nBUD: Yeah, just like the half dozen guys you screwed today.\\nLYNN: Actually, it was two. You're different, Officer White. You're the first man in five years who didn't tell me I look like Veronica Lake inside of a minute.\\nBUD: You look better than Veronica Lake. Now, Pierce Patchett.\\nLYNN: He takes a cut of our earnings and invests it for us. He makes us quit the life at thirty. He doesn't let us use narcotics and he doesn't abuse us. Can your policeman's mentality grasp those contradictions?\\nBUD: He had you cut to look like Veronica Lake?\\nLYNN: No. I'm really a brunette, but the rest is me. And that's all the news that's fit to print. It was nice meeting you, Officer.\\nBUD: Look. I want to see you again.\\nLYNN: Are you asking me for a date or an appointment?\\nBUD: I don't know.\\nLYNN: If it's a date I think you'd better tell me your first name because I --\\n\\n\", 'answer': 'Forget I asked. It was a mistake.', 'gold_tag': 'BUD has a direct and confrontational speaking style', 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"Forget I asked. It was a mistake.\"\n",
      "prediction :  What the fuck do you want me to say?\n",
      "Real answer : Forget I asked. It was a mistake.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8227224349975586], 'recall': [0.8802943229675293], 'f1': [0.8505352139472961], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.94973373413086\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLYNN: Did you forget some -- I wondered when you might ring the bell again, Officer White.\\nBUD: It's Bud.\\n\\n\", 'answer': \"You should see yourself. You look like you're ten years old. If you'd called first, I wouldn't look this ridiculous.\", 'gold_tag': 'LYNN might be somewhat self-conscious about her appearance , BUD potentially looks young for his age', 'last_speaker': 'LYNN'}\n",
      "Last word -> LYNN : \"You should see yourself. You look like you're ten years old. If you'd called first, I wouldn't look this ridiculous.\"\n",
      "prediction :  And look at the time.\n",
      "Real answer : You should see yourself. You look like you're ten years old. If you'd called first, I wouldn't look this ridiculous.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8928157687187195], 'recall': [0.8228318691253662], 'f1': [0.8563963770866394], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07142857142857142, 'rouge2': 0.0, 'rougeL': 0.07142857142857142, 'rougeLsum': 0.07142857142857142}\n",
      "bleu 1/2 : 0.00995741367357279 0.003520477365831486\n",
      "ppl : 156.31642150878906\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBUD: Who was that guy who was here earlier?\\nLYNN: It doesn't matter. All they get is Veronica Lake. You got the real Lynn Margaret Bracken... Where'd this come from?\\nBUD: When I was ten, my old man threw a bottle at my mother. I guess I got in the way.\\nLYNN: So you saved her.\\nBUD: Yeah. But not for long.\\nLYNN: Do you like being a cop, Bud?\\nBUD: I used to. What I do now is strong-arm. Sitting duck stuff... No, I don't like it. If I could work Homicide like a real detective... There's something wrong with the Nite Owl. That prick Exley shot the wrong guys. But they made him a hero and whoever killed my partner is still out there. In here I know it. But I can't prove it. I'm not a detective. I'm not smart enough. I'm just the guy they bring in to scare the other guy shitless.\\nLYNN: You found Patchett. You found me. You're smart enough. Be a detective if that's what you want.\\n\\n\", 'answer': 'That simple, huh?', 'gold_tag': \"BUD's current feelings and circumstances suggest he is poised to make career-related decisions in the imminent future\", 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"That simple, huh?\"\n",
      "prediction :  Who was that person?\n",
      "Real answer : That simple, huh?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8340641856193542], 'recall': [0.8384543061256409], 'f1': [0.8362535238265991], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 199.77679443359375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBUD: Did you talk to Exley?\\nLYNN: Come in out of the rain. In the morning we'll have both our stories for breakfast.\\nBUD: I want to know about Exley.\\nLYNN: He's the opposite of you. He's more like me. Cold, calculating.\\nBUD: How'd you get to know so much about him?\\nLYNN: Come in out of the rain, Bud.\\nBUD: You gonna tell me what happened with you and Exley?\\nLYNN: We talked.\\nBUD: So tell me about it.\\nLYNN: In the morning.\\nBUD: No. Now. You fucked him.\\n\\n\", 'answer': 'I thought I was helping you. I thought --', 'gold_tag': 'LYNN is secretive or protective', 'last_speaker': 'LYNN'}\n",
      "Last word -> LYNN : \"I thought I was helping you. I thought --\"\n",
      "prediction :  He knows you... He knows you're gonna go behind his back and blow it up.\n",
      "Real answer : I thought I was helping you. I thought --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8501584529876709], 'recall': [0.865427553653717], 'f1': [0.8577250838279724], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08333333333333333, 'rouge2': 0.0, 'rougeL': 0.08333333333333333, 'rougeLsum': 0.08333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 37.99229049682617\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHARRY: Empty. Go.\\nGIB: Harry Tasker wallet. Harry Tasker passport. Plane ticket stub, hotel receipt, Tasker. Two postcards of Lake Geneva. House keys. Souvenir snowing Swiss village.\\nHARRY: What's this for?\\nGIB: For Dana, schmuck. Bring your kid something. You know. The dad thing.\\nHARRY: Got it. Nice touch. Okay, pick me up at eight. The de-brief is at ten hundred.\\nGIB: Hey, hey, hey... what are we forgetting?\\nHARRY: What a team. See you at eight.\\n\\n\", 'answer': 'Yep. Sleep fast.', 'gold_tag': 'Everyday Language', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"Yep. Sleep fast.\"\n",
      "prediction :  Well, you're missing a passport, some tickets and you're about to go on the planet's most dangerous mission. Harry, come on!\n",
      "Real answer : Yep. Sleep fast.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8224545121192932], 'recall': [0.9061936140060425], 'f1': [0.8622958064079285], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.598962783813477\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: Kids. Ten seconds of joy. Thirty years of misery.\\nHARRY: She knows not to steal. I've taught her better than that.\\n\\n\", 'answer': \"Yeah, but you're not her parents, anymore, you and Helen. Her parents are Axl Rose and Madonna. The five minutes you spend a day with her can't compete with that kind of constant bombardment. You're outgunned, amigo.\", 'gold_tag': 'Gib is aware of popular culture figures like Axl Rose and Madonna , Shared memories', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"Yeah, but you're not her parents, anymore, you and Helen. Her parents are Axl Rose and Madonna. The five minutes you spend a day with her can't compete with that kind of constant bombardment. You're outgunned, amigo.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction : \n",
      "Real answer : Yeah, but you're not her parents, anymore, you and Helen. Her parents are Axl Rose and Madonna. The five minutes you spend a day with her can't compete with that kind of constant bombardment. You're outgunned, amigo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.0], 'recall': [0.0], 'f1': [0.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : nan\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: Twenty here, fifty there... I figured my wife's boyfriend was taking it.\\nHARRY: I thought you moved out.\\n\\n\", 'answer': \"Well . . . I moved back in. My lawyer said it would give me a better claim on the house in the property settlement. Don't change the subject... you owe me two hundred bucks.\", 'gold_tag': \"GIB's lawyer's advice has led him to move back in with his spouse , GIB plans to get a beneficial claim from the property settlement\", 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"Well . . . I moved back in. My lawyer said it would give me a better claim on the house in the property settlement. Don't change the subject... you owe me two hundred bucks.\"\n",
      "prediction :  I sure did! And he left all her stuff. Everything I can't have!\n",
      "Real answer : Well . . . I moved back in. My lawyer said it would give me a better claim on the house in the property settlement. Don't change the subject... you owe me two hundred bucks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8540767431259155], 'recall': [0.8421385288238525], 'f1': [0.8480656147003174], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0851063829787234, 'rouge2': 0.0, 'rougeL': 0.0851063829787234, 'rougeLsum': 0.0851063829787234}\n",
      "bleu 1/2 : 0.014161092357946473 0.004660986106335019\n",
      "ppl : 76.872802734375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: It's all set up... ghost phones and fax, all the usual stuff. You have a suite at the Marquis Hotel under Renquist. Okay, reality check. Go.\\n\\n\", 'answer': \"Hi, I'm Harry Renquist. I own a--\", 'gold_tag': 'HARRY is a business owner under the alias of Harry Renquist , HARRY will be taking on the persona of a business owner in the near future', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"Hi, I'm Harry Renquist. I own a--\"\n",
      "prediction :  I'm getting paid 300,000 or there abouts.\n",
      "Real answer : Hi, I'm Harry Renquist. I own a--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.821807861328125], 'recall': [0.8435856103897095], 'f1': [0.8325543403625488], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23529411764705882, 'rouge2': 0.13333333333333333, 'rougeL': 0.23529411764705882, 'rougeLsum': 0.23529411764705882}\n",
      "bleu 1/2 : 0.14285714285714285 0.048795003647426664\n",
      "ppl : 18.920557022094727\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: There's another guy, still in the car.\\n\\n\", 'answer': 'Stay on him.', 'gold_tag': 'HARRY is commanding , HARRY suggests a position of authority', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"Stay on him.\"\n",
      "prediction :  Yeah, I guess that's why I'm here. Who's he? Oh. So this isn't the date I was supposed to meet my girlfriend, right?\n",
      "Real answer : Stay on him.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.806605339050293], 'recall': [0.8754957318305969], 'f1': [0.8396399021148682], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.155574798583984\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: Copy that.\\n\\n', 'answer': 'And make it fast. My horse is getting tired.', 'gold_tag': \"HARRY seems to be in a hurry , HARRY's statement about the horse getting tired implies he may currently be on horseback\", 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"And make it fast. My horse is getting tired.\"\n",
      "prediction :  Yeah, I did it. This will work. We can make it work.\n",
      "Real answer : And make it fast. My horse is getting tired.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8852246403694153], 'recall': [0.8843624591827393], 'f1': [0.8847934007644653], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1904761904761905, 'rouge2': 0.10526315789473685, 'rougeL': 0.1904761904761905, 'rougeLsum': 0.1904761904761905}\n",
      "bleu 1/2 : 0.16666666666666669 0.12309149097933275\n",
      "ppl : 30.795839309692383\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: Hey, did that guy Harry chased last night call in to give himself up yet? Cause apparently that's the only way we're going to catch the son of a bitch --\\n\\n\", 'answer': 'Okay. Here she comes.', 'gold_tag': 'HARRY is observant , HARRY values the tactical aspect of his work', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"Okay. Here she comes.\"\n",
      "prediction :  [In background noises] Yes, yes he is GIB : And why does it call him 'son of a bitch', you think? -- [Harry exits]\n",
      "Real answer : Okay. Here she comes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.800861120223999], 'recall': [0.8896868228912354], 'f1': [0.8429403901100159], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 130.45127868652344\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHARRY: Look at the way the little punk is driving. He's all over the place. Look-- he hasn't signalled once.\\n\\n\", 'answer': \"Goddammit! That's outrageous.\", 'gold_tag': \"GIB is outraged , The cause of GIB's outrage is reckless driving\", 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"Goddammit! That's outrageous.\"\n",
      "prediction :  That's just the way he is. It's nothing. Harry's just a kid, don't you see? Not really like the rest of us.\n",
      "Real answer : Goddammit! That's outrageous.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8327631950378418], 'recall': [0.8316383361816406], 'f1': [0.8322004079818726], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333336, 'rouge2': 0.07142857142857142, 'rougeL': 0.13333333333333336, 'rougeLsum': 0.13333333333333336}\n",
      "bleu 1/2 : 0.04545454545454546 0.014712247158412498\n",
      "ppl : 12.781267166137695\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHARRY: So, you wanna play huh? You little--\\n\\n', 'answer': \"That's it. Get 'im Harry We'll teach that little puke not to signal.\", 'gold_tag': 'HARRY shows a willingness to fight', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"That's it. Get 'im Harry We'll teach that little puke not to signal.\"\n",
      "prediction :  I would like - to have my own opinion about what I can and cannot do.\n",
      "Real answer : That's it. Get 'im Harry We'll teach that little puke not to signal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8357625603675842], 'recall': [0.8389986157417297], 'f1': [0.8373774886131287], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06666666666666667, 'rouge2': 0.0, 'rougeL': 0.06666666666666667, 'rougeLsum': 0.06666666666666667}\n",
      "bleu 1/2 : 0.0625 0.02041241452319315\n",
      "ppl : 29.192529678344727\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: Ha! The little prick ditched you! That is so goddamn funny.\\nHARRY: Son of a bitch!\\n\\n', 'answer': 'Can we go to the office now, Mr. Superspy?', 'gold_tag': 'Everyday Language', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"Can we go to the office now, Mr. Superspy?\"\n",
      "prediction :  You did what?!! You don't think I will just leave you with that shit-head just because you want to get out some? You want to be a real man, Harry. You want to prove to all these other girls that you belong to him? Then be a real man. Take the fucking gold crown Harry! You get the crown and you can do anything you want!\n",
      "Real answer : Can we go to the office now, Mr. Superspy?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8083900213241577], 'recall': [0.8461723327636719], 'f1': [0.8268498182296753], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07792207792207792, 'rouge2': 0.0, 'rougeL': 0.051948051948051945, 'rougeLsum': 0.051948051948051945}\n",
      "bleu 1/2 : 0.030303030303030304 0.0068278874199891905\n",
      "ppl : 18.695158004760742\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: What's going on?\\nHARRY: Look, uh... I've got to talk to Helen about this thing with Dana. I'm just going to run in and see if she can get away for lunch.\\nGIB: You want me to just hang-- ?\\nHARRY: Just hang a minute.\\n\\n\", 'answer': \"I'll just hang then, shall I?\", 'gold_tag': 'GIB acts patiently and cooperatively', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"I'll just hang then, shall I?\"\n",
      "prediction :  How's your relationship with Helen?\n",
      "Real answer : I'll just hang then, shall I?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8283669948577881], 'recall': [0.805006206035614], 'f1': [0.8165194988250732], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 164.419921875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: You look like you got gut-kicked. What's the matter? You sick?\\nHARRY: He-- Helen. Helen-- it's Helen. It's Helen, Gib.\\nGIB: Something to do with Helen, is what I'm getting.\\nHARRY: She's having an affair.\\nGIB: Congratulations. Welcome to the club.\\nHARRY: It can't be. Not Helen.\\nGIB: Nobody believes it can happen to them.\\nHARRY: It can't be.\\nGIB: Same thing happened to me with wife two. I had no idea until I came home and the house was empty. I mean empty. She even took the ice-cube trays from the fridge. What kind of person would think of that?\\nHARRY: I still don't believe it.\\nGIB: Relax. Helen still loves you. She just wants this guy to bang her. It's nothing serious. You'll get used to it after a --\\nHARRY: STOP. CHEERING. ME. UP.\\n\\n\", 'answer': \"What'dya expect Harry? She's a flesh and blood woman. And you're never there. It was only a matter of time. I say we concentrate on work. That's how I always got through it whenever my life turned to dogshit. Let's catch some terrorists and then you can beat the crap out of them. You'll feel better. Women. Can't live with 'em. Can't kill 'em.\", 'gold_tag': 'GIB copes with marital issues by focusing on his job , GIB is cynical about relationships', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"What'dya expect Harry? She's a flesh and blood woman. And you're never there. It was only a matter of time. I say we concentrate on work. That's how I always got through it whenever my life turned to dogshit. Let's catch some terrorists and then you can beat the crap out of them. You'll feel better. Women. Can't live with 'em. Can't kill 'em.\"\n",
      "prediction :  Good talk, Georgie. You're all right, I guess.\n",
      "Real answer : What'dya expect Harry? She's a flesh and blood woman. And you're never there. It was only a matter of time. I say we concentrate on work. That's how I always got through it whenever my life turned to dogshit. Let's catch some terrorists and then you can beat the crap out of them. You'll feel better. Women. Can't live with 'em. Can't kill 'em.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8539328575134277], 'recall': [0.8192147612571716], 'f1': [0.8362135291099548], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07407407407407407, 'rouge2': 0.02531645569620253, 'rougeL': 0.07407407407407407, 'rougeLsum': 0.07407407407407407}\n",
      "bleu 1/2 : 0.00011398524569431456 3.8534046149930103e-05\n",
      "ppl : 62.38795852661133\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: Okay, she's turning on Seventeenth. Make a left, you should see her.\\n\\n\", 'answer': 'There she is.', 'gold_tag': \"HARRY displays his alertness , HARRY acts quickly upon GIB's instructions\", 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"There she is.\"\n",
      "prediction :  You know she doesn't like me.\n",
      "Real answer : There she is.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.87071293592453], 'recall': [0.9087542295455933], 'f1': [0.8893269896507263], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0.16666666666666669 0.05773502691896258\n",
      "ppl : 44.87101364135742\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: Guy's a spook!\\nHARRY: Yeah, but for who? *\\n\\n\", 'answer': 'He could be working her to get to you.', 'gold_tag': 'GIB is knowledgeable about intelligence operations , HARRY is likely a person of interest , Others may want to infiltrate HARRY , HARRY has something valuable or secret', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"He could be working her to get to you.\"\n",
      "prediction :  That's a lie!\n",
      "Real answer : He could be working her to get to you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8510387539863586], 'recall': [0.8641965389251709], 'f1': [0.8575671911239624], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 74.28396606445312\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHARRY: Shit! It's almost eight. * She's still at my house. *\\n\\n\", 'answer': 'The purse is still at the house.', 'gold_tag': 'Everyday Language', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"The purse is still at the house.\"\n",
      "prediction :  I wouldn't wait longer...\n",
      "Real answer : The purse is still at the house.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.838790237903595], 'recall': [0.8754667043685913], 'f1': [0.8567360639572144], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 169.8761749267578\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: You've reached a new low with this one. I can't believe you're crazy enough to use the room at the Marquis.\\nHARRY: Why not? You think I can afford a suite like that on my salary? Is Jean-Claude done yet? *\\n\\n\", 'answer': 'Not quite.', 'gold_tag': 'GIB suggests caution and prudence in operations', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"Not quite.\"\n",
      "prediction :  It's 89 degrees in the hallway.\n",
      "Real answer : Not quite.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8681236505508423], 'recall': [0.871871829032898], 'f1': [0.8699936866760254], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 45.55819320678711\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: I thought this look like your work.\\nHARRY: Let's go. I'll brief you in the air.\\n\\n\", 'answer': \"You're welcome.\", 'gold_tag': 'GIB suggests his job involves analysis or field observation', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"You're welcome.\"\n",
      "prediction :  Come on, come on. You really got to get it out. No matter what, I'm going to beat your ass if I gotta.\n",
      "Real answer : You're welcome.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8209794759750366], 'recall': [0.8480671048164368], 'f1': [0.8343034386634827], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07407407407407407, 'rouge2': 0.0, 'rougeL': 0.07407407407407407, 'rougeLsum': 0.07407407407407407}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.800952911376953\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: --you tell the son of bitch this is Bright Boy Alert. Repeat,\\nHARRY: ... the Coast Guard has to clear them back to a twenty mile radius. Anybody that can't make the minimum safe distance we need an airlift on, immediately--\\nGIB: I can get 3 Marine Corps Harriers here in about 12 minutes. They're on maneuvers out of Boca Chica.\\n\\n\", 'answer': \"Get 'em. I'll brief them on the way in.\", 'gold_tag': 'HARRY is able to request military support and brief them', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"Get 'em. I'll brief them on the way in.\"\n",
      "prediction :  ... I ain't going to listen to you! You're crazy! I'm gonna have that bastard put the boy across the river-- right now! Where you guys at? Come on up and have it! This isn't funny. This means war!\n",
      "Real answer : Get 'em. I'll brief them on the way in.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8145334720611572], 'recall': [0.8651669025421143], 'f1': [0.8390870094299316], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11538461538461536, 'rouge2': 0.0, 'rougeL': 0.07692307692307693, 'rougeLsum': 0.07692307692307693}\n",
      "bleu 1/2 : 0.05128205128205127 0.011616917255955381\n",
      "ppl : 24.603858947753906\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: ... well get the Highway Patrol to go through the streets and tell everybody on their damn loudspeakers. Just the basics... get away from windows, don't look at it... yeah--\\n\\n\", 'answer': 'Here they come. Roger, Mike Three Five, you are cleared to engage. Be advised, your targets have Stingers and light machine guns.', 'gold_tag': 'HARRY is in a position of command , HARRY potentially operates within a military or law enforcement setting , HARRY uses technical language and clear directives', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"Here they come. Roger, Mike Three Five, you are cleared to engage. Be advised, your targets have Stingers and light machine guns.\"\n",
      "prediction :  Are you ready?\n",
      "Real answer : Here they come. Roger, Mike Three Five, you are cleared to engage. Be advised, your targets have Stingers and light machine guns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8572326898574829], 'recall': [0.820976734161377], 'f1': [0.8387130498886108], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0.000592034515244793 0.00022929398179230649\n",
      "ppl : 139.25210571289062\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: What the hell are you?\\n\\n', 'answer': 'Interested? Follow the crow.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SKULL COWBOY'}\n",
      "Last word -> SKULL COWBOY : \"Interested? Follow the crow.\"\n",
      "prediction :  (looking at Eric) You are a zombie. A reanimated corpse, and the only way I can understand how it moves are not in any conventional sense of the word, I can understand it if you'll excuse me for saying it, I can understand how it moves by it simply not being in the conventional sense of the word.\n",
      "Real answer : Interested? Follow the crow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8040065765380859], 'recall': [0.8316113948822021], 'f1': [0.817575991153717], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.031746031746031744, 'rouge2': 0.0, 'rougeL': 0.031746031746031744, 'rougeLsum': 0.031746031746031744}\n",
      "bleu 1/2 : 0.01724137931034483 0.0054998212587135924\n",
      "ppl : 15.281291007995605\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSKULL COWBOY: Get it?\\nERIC: Leave me alone -- !\\n\\n', 'answer': 'Do something about it.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SKULL COWBOY'}\n",
      "Last word -> SKULL COWBOY : \"Do something about it.\"\n",
      "prediction :  Yeah, you leave me the hell alone. I had to kick you out a good bit earlier -- just a warning!\n",
      "Real answer : Do something about it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8262126445770264], 'recall': [0.8646923303604126], 'f1': [0.8450146317481995], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 60.115299224853516\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSKULL COWBOY: Glad to see you're finally with the program.\\nERIC: Bugger off to the graveyard, skull- face, I'm busy.\\nSKULL COWBOY: You work for the dead. Forget that, and you can forget it all.\\n\\n\", 'answer': 'Forget this. She always red red was her color.', 'gold_tag': 'ERIC has a connection with someone who loved the color red', 'last_speaker': 'ERIC'}\n",
      "Last word -> ERIC : \"Forget this. She always red red was her color.\"\n",
      "prediction :  And who are you?\n",
      "Real answer : Forget this. She always red red was her color.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8214699029922485], 'recall': [0.8382179737091064], 'f1': [0.8297594785690308], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 165.1239776611328\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSKULL COWBOY: Do this thing and you will be vulnerable. The blood will not return. No powers. No reunion. Nothing.\\nERIC: Fine with me.\\nSKULL COWBOY: You'll be alone.\\n\\n\", 'answer': \"I'm already alone.\", 'gold_tag': 'ERIC is in a state of isolation', 'last_speaker': 'ERIC'}\n",
      "Last word -> ERIC : \"I'm already alone.\"\n",
      "prediction :  You think I wouldn't think that you would?\n",
      "Real answer : I'm already alone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7959832549095154], 'recall': [0.857693612575531], 'f1': [0.8256869912147522], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 53.775882720947266\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: Don't waste my time.\\n\\n\", 'answer': \"Very well, it's your ass.\", 'gold_tag': 'SKULL COWBOY speaks in a direct, no-nonsense manner', 'last_speaker': 'SKULL COWBOY'}\n",
      "Last word -> SKULL COWBOY : \"Very well, it's your ass.\"\n",
      "prediction :  I see.\n",
      "Real answer : Very well, it's your ass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8811278343200684], 'recall': [0.8492595553398132], 'f1': [0.8649001717567444], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 602.51904296875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSWAY: Come back when you've learned how to drink, Billy --\\nMEMPHIS: See you're still stealing the sailors from the sea --\\n\\n\", 'answer': 'What are you doing here?', 'gold_tag': 'SWAY is familiar with MEMPHIS and is surprised at his presence', 'last_speaker': 'SWAY'}\n",
      "Last word -> SWAY : \"What are you doing here?\"\n",
      "prediction :   I won't give you anything, Billy, I'm only looking to build up my business -- you don't have to steal anything from me.\n",
      "Real answer : What are you doing here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8351657390594482], 'recall': [0.8363513946533203], 'f1': [0.8357581496238708], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06666666666666667, 'rouge2': 0.0, 'rougeL': 0.06666666666666667, 'rougeLsum': 0.06666666666666667}\n",
      "bleu 1/2 : 0.043478260869565216 0.014058038927888336\n",
      "ppl : 22.26987075805664\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMEMPHIS: Gosh, no. Lipstick? What next? Mascara, blush,\\nSWAY: Deodorant.\\nMEMPHIS: Wow. Bozo, the very sexy clown --\\nSWAY: So, you seeing anybody?\\nMEMPHIS: No. I had a girl. She was great. The problem is: great girls come along once every ten years. So I gotta wait another three years before I can even bother to look...\\nSWAY: She was so great, why'd you leave her?\\n\\n\", 'answer': 'Her parole officer strongly recommended it ...', 'gold_tag': 'MEMPHIS insinuates that he did not have a choice in ending that relationship as it was recommended by her parole officer', 'last_speaker': 'MEMPHIS'}\n",
      "Last word -> MEMPHIS : \"Her parole officer strongly recommended it ...\"\n",
      "prediction :  I found the perfect woman. So I left her. [pause]\n",
      "Real answer : Her parole officer strongly recommended it ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8505499958992004], 'recall': [0.8337379693984985], 'f1': [0.8420600295066833], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 45.55460739135742\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSWAY: What are you doing... ?\\nMEMPHIS: Seeing if you wanted to go for a ride?\\nSWAY: I can't. I got a back load of repairs and one of the mechanics called in sick and I haven't slept and-- (stops short; sees the new Eleanor Where to -- ?\\nMEMPHIS: I dunno. I know a place.\\nSWAY: This time it's for real?\\n\\n\", 'answer': 'Oh, yeah. For real, point-five.', 'gold_tag': \"MEMPHIS invites SWAY for a 'real' car ride\", 'last_speaker': 'MEMPHIS'}\n",
      "Last word -> MEMPHIS : \"Oh, yeah. For real, point-five.\"\n",
      "prediction :  (smiles)\n",
      "Real answer : Oh, yeah. For real, point-five.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8522515892982483], 'recall': [0.8300861120223999], 'f1': [0.8410228490829468], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1565.4556884765625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGWEN: Unbelievable.\\nJOSH: What?\\nGWEN: I'm reading a stupid article in a stupid magazine.\\nJOSH: If it's stupid, why read it? Yeah. She's a bore.\\nGWEN: She's breaking up with her husband of twenty years. Said a friend,\\nJOSH: Some poor tree gave its life so we could know that.\\n\\n\", 'answer': \"It's comforting, reading about these broken marriages.\", 'gold_tag': 'GWEN finds comfort in reading about broken marriages', 'last_speaker': 'GWEN'}\n",
      "Last word -> GWEN : \"It's comforting, reading about these broken marriages.\"\n",
      "prediction :  I think she was a waste of oxygen anyway.\n",
      "Real answer : It's comforting, reading about these broken marriages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8714146614074707], 'recall': [0.8724560141563416], 'f1': [0.8719350099563599], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 87.12943267822266\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOSH: Why?\\nGWEN: It's not enough for our marriage to succeed. Everyone else's must fail.\\nJOSH: Is this going to be one of those nights?\\nGWEN: What?\\nJOSH: One of those nights we talk.\\nGWEN: No. There's no need to talk, because there's no problem.\\nJOSH: I've been under a lot of stress.\\nGWEN: You don't have to apologize. There's nothing wrong with the slump we're going through. In fact, it's a good thing.\\nJOSH: How's that?\\nGWEN: Too much passion can ruin a marriage. Look at Eric and Sylvia. At the beginning, you couldn't pry them apart. They were joined at the genitals. And, then...total burn-out. A marriage cannot sustain that kind of intensity. It's good for people to grow bored with each other. That way, they can meet and fall in love again. In case you hadn't noticed...I'm trying to seduce you.\\nJOSH: I can feel that.\\nGWEN: You're welcome to reciprocate.\\nJOSH: I can't.\\nGWEN: It's alright.\\nJOSH: To seduce...to be seduced, there needs to be an element of surprise. I know all your moves. You know mine. How can there be any surprise?\\nGWEN: Rub my feet. I think we should have an affair.\\nJOSH: What?\\nGWEN: With each other.\\nJOSH: That makes no sense.\\nGWEN: You pick me up at a bar...\\nJOSH: And, what? Pretend I don't know you?\\nGWEN: Or we could meet at a hotel. I'll register under my maiden name.\\nJOSH: college boy.\\nGWEN: When I met you, you were a college boy.\\nJOSH: badly for her.\\nGWEN: Alright. Bad example. You can stop.\\nJOSH: Actors pretend. That's what they do. I'm not an actor. And I love you the way you are.\\nGWEN: I love you, too.\\nJOSH: Pretending to be strangers is not going to solve the problem. Beat.\\n\\n\", 'answer': 'Who said there was a problem?', 'gold_tag': 'Everyday Language', 'last_speaker': 'GWEN'}\n",
      "Last word -> GWEN : \"Who said there was a problem?\"\n",
      "prediction :  It's not time to celebrate just yet.\n",
      "Real answer : Who said there was a problem?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.847759485244751], 'recall': [0.8704543709754944], 'f1': [0.8589571118354797], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 19.560466766357422\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGWEN: You missed the on-ramp.\\nJOSH: I know.\\nGWEN: Why?\\n\\n', 'answer': 'Somewhere we need to go first.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JOSH'}\n",
      "Last word -> JOSH : \"Somewhere we need to go first.\"\n",
      "prediction : I don't know, what kind of person would miss an on-ramp?!\n",
      "Real answer : Somewhere we need to go first.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8027899265289307], 'recall': [0.854543924331665], 'f1': [0.8278588652610779], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 28.932296752929688\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGWEN: We don't have to do this tonight.\\nJOSH: Yes, we do.\\nGWEN: We can't go in here. Everything's different.\\n\\n\", 'answer': \"That's okay. We're different, too.\", 'gold_tag': 'JOSH is experiencing a change tonight', 'last_speaker': 'JOSH'}\n",
      "Last word -> JOSH : \"That's okay. We're different, too.\"\n",
      "prediction :  We can't do this.\n",
      "Real answer : That's okay. We're different, too.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8697739839553833], 'recall': [0.8790158033370972], 'f1': [0.8743704557418823], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 44.17261505126953\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGWEN: Sarah\\'s a very interesting girl. Did you know she\\'s training for the marathon?\\nJOSH: I don\\'t want to talk about Sarah.\\nGWEN: What do you want to talk about, then?\\nJOSH: I want to talk about me... ...and what a fool I\\'ve been. I thought if we came here tonight we could...start again.\\nGWEN: But I thought you were over this place. And, look...There\\'s nothing left. Not one remnant of our first date...anywhere. You\\'re supposed to wait--\\nJOSH: I can\\'t wait. I have to know. \"You are on the verge of success\"...in bed.\\nGWEN: \"You will have a change of plans\"...in bed. Hmm. That\\'s what I\\'ve heard.\\nJOSH: The last cookie. Go ahead.\\nGWEN: No. You open it.\\n\\n', 'answer': \"It's blank. No, it's perfect. Blank...no problems, no history, nothing...in bed.\", 'gold_tag': 'JOSH is the more serious and introspective of the two', 'last_speaker': 'JOSH'}\n",
      "Last word -> JOSH : \"It's blank. No, it's perfect. Blank...no problems, no history, nothing...in bed.\"\n",
      "prediction :  We need to open the cookies. It'll be a good reminder of those days. Remember when that was all we had? I remember our last meal together at that little diner; you had fries. You don't like fries? They were so hard I kept chewing until they were all gone.\n",
      "Real answer : It's blank. No, it's perfect. Blank...no problems, no history, nothing...in bed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8167641162872314], 'recall': [0.8404178023338318], 'f1': [0.8284221291542053], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.029850746268656716, 'rouge2': 0.0, 'rougeL': 0.029850746268656716, 'rougeLsum': 0.029850746268656716}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.82757568359375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOSH: By the way, I didn't get your name.\\nGWEN: What? Oh, my name. My name is Gail. Gail Bonds.\\nJOSH: Well, Gail, I'm not usually this forward on a first date, may I take you to my car and ravish you?\\nGWEN: Hmm. On one condition.\\nJOSH: What's that?\\nGWEN: That you tell me your name.\\n\\n\", 'answer': \"Oh, I thought everyone knew my name. I'm Bill Gates. Billionaire.\", 'gold_tag': 'JOSH introduces himself jokingly as Bill Gates , JOSH claims to be a billionaire', 'last_speaker': 'JOSH'}\n",
      "Last word -> JOSH : \"Oh, I thought everyone knew my name. I'm Bill Gates. Billionaire.\"\n",
      "prediction :  Gail, I am josh.\n",
      "Real answer : Oh, I thought everyone knew my name. I'm Bill Gates. Billionaire.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.847610592842102], 'recall': [0.852070689201355], 'f1': [0.8498347401618958], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.043443485862611285 0.01586331812240599\n",
      "ppl : 1176.3826904296875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGWEN: Is it true what they say, Bill, about billionaires? That all the wealth is just a way to compensate...for size?\\nJOSH: People are jealous.\\nGWEN: I can imagine. It must be so lonely at the top. What are you doing?\\nJOSH: What do you think I'm doing?\\nGWEN: We're not in a bed.\\n\\n\", 'answer': \"You shouldn't read fortune cookies too literally. ...Can anyone see us?...Is anyone looking?...Why should it bother you? You're alone...with your wife...That's the way it's supposed to be...You know every inch of her...every smell...every sigh...every freckle...the shape of her ass...the mole under her nipple...the whole history of her body...And, you know that if you really concentrate, you can succeed...in imagining...she's someone you don't know...\", 'gold_tag': 'JOSH is defensive about his wealth , JOSH is unfaithful, insinuating illicit activities', 'last_speaker': 'JOSH'}\n",
      "Last word -> JOSH : \"You shouldn't read fortune cookies too literally. ...Can anyone see us?...Is anyone looking?...Why should it bother you? You're alone...with your wife...That's the way it's supposed to be...You know every inch of her...every smell...every sigh...every freckle...the shape of her ass...the mole under her nipple...the whole history of her body...And, you know that if you really concentrate, you can succeed...in imagining...she's someone you don't know...\"\n",
      "prediction :  If you were the richest man in the room, would you try to sit at the table?\n",
      "Real answer : You shouldn't read fortune cookies too literally. ...Can anyone see us?...Is anyone looking?...Why should it bother you? You're alone...with your wife...That's the way it's supposed to be...You know every inch of her...every smell...every sigh...every freckle...the shape of her ass...the mole under her nipple...the whole history of her body...And, you know that if you really concentrate, you can succeed...in imagining...she's someone you don't know...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8452416658401489], 'recall': [0.7861489057540894], 'f1': [0.8146250247955322], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16, 'rouge2': 0.020408163265306124, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0.015720316857141484 0.002562098186640613\n",
      "ppl : 17.254648208618164\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOSH: You're right. We could use some more color in the living room.\\nGWEN: Yes?\\nJOSH: I said you're right.\\nGWEN: About what?\\nJOSH: About more color in the living room.\\n\\n\", 'answer': \"Oh. I'm glad you think so.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'GWEN'}\n",
      "Last word -> GWEN : \"Oh. I'm glad you think so.\"\n",
      "prediction :  I wouldn't know\n",
      "Real answer : Oh. I'm glad you think so.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8133939504623413], 'recall': [0.8310229778289795], 'f1': [0.8221139311790466], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 58.507266998291016\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJUDITH: Good morning Tom Quiney. A barrel of Huffcap ale and three flagons of Malmesey wine to be delivered to New Place if you would. On our account.\\nQUINEY: Your usual order and my usual reply. Marry me Judith. I would help bring back your smile.\\nJUDITH: Yes and every other maid in the county’s. You chase them all.\\nQUINEY: But I only ever propose to one.\\nJUDITH: I’d think you’d tire of it.\\n\\n', 'answer': 'I remember a girl. The prettiest and happiest in town. And I remember her laugh and I remember kiss chase. I’d like to see the woman that girl should have become. Because it surely isn’t you. All Is True - Shooting Script', 'gold_tag': \"QUINEY remembers JUDITH as the prettiest and happiest girl in town, her laughter, and playing 'kiss chase' together , QUINEY has a romantic vision of JUDITH\", 'last_speaker': 'QUINEY'}\n",
      "Last word -> QUINEY : \"I remember a girl. The prettiest and happiest in town. And I remember her laugh and I remember kiss chase. I’d like to see the woman that girl should have become. Because it surely isn’t you. All Is True - Shooting Script\"\n",
      "prediction :  I can take any woman, Judith, if I want to.\n",
      "Real answer : I remember a girl. The prettiest and happiest in town. And I remember her laugh and I remember kiss chase. I’d like to see the woman that girl should have become. Because it surely isn’t you. All Is True - Shooting Script\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8666427135467529], 'recall': [0.8314414620399475], 'f1': [0.8486772775650024], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1509433962264151, 'rouge2': 0.0, 'rougeL': 0.11320754716981132, 'rougeLsum': 0.11320754716981132}\n",
      "bleu 1/2 : 0.008152440795673243 0.0019215487232808008\n",
      "ppl : 120.99413299560547\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nQUINEY: A glass Miss Shakespeare? To toast this sunny morning?\\nJUDITH: I need no excuse for a glass of wine Mr. Quiney. Beat.\\nQUINEY: There is another pleasure, equally heady.\\nJUDITH: And plenty of country girls for you to get it with.\\nQUINEY: Your looks won’t last forever Jude.\\n\\n', 'answer': 'And I shall be glad when they’re gone because I shall be no more bothered by the likes of you.', 'gold_tag': 'JUDITH is bothered by QUINEY or similar types', 'last_speaker': 'JUDITH'}\n",
      "Last word -> JUDITH : \"And I shall be glad when they’re gone because I shall be no more bothered by the likes of you.\"\n",
      "prediction :  I like my body\n",
      "Real answer : And I shall be glad when they’re gone because I shall be no more bothered by the likes of you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8571221232414246], 'recall': [0.837496280670166], 'f1': [0.847195565700531], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0.004578909722183545 0.0016719814290797606\n",
      "ppl : 478.17132568359375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nQUINEY: You know that I am not a good man. There have been women. Many women.\\n\\n', 'answer': 'I have seen too little of life. You’ve seen too much. Between us perhaps we may begin again.', 'gold_tag': 'JUDITH has led a sheltered life , QUINEY acknowledges his moral shortcomings', 'last_speaker': 'JUDITH'}\n",
      "Last word -> JUDITH : \"I have seen too little of life. You’ve seen too much. Between us perhaps we may begin again.\"\n",
      "prediction :  What kind of woman?\n",
      "Real answer : I have seen too little of life. You’ve seen too much. Between us perhaps we may begin again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.818897008895874], 'recall': [0.8270999193191528], 'f1': [0.8229780197143555], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913043, 'rouge2': 0.0, 'rougeL': 0.08695652173913043, 'rougeLsum': 0.08695652173913043}\n",
      "bleu 1/2 : 0.007549345855579625 0.0027566313463393993\n",
      "ppl : 230.6244659423828\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJUDITH: I saw Margaret Wheeler in the Church today Tom.\\n\\n', 'answer': 'I know it Judith and I have confessed all to you. I can not undo what is done. All I can say is that her child and she will not want.', 'gold_tag': 'QUINEY has confessed a past mistake involving Margaret Wheeler and her child , QUINEY has revealed a level of responsibility', 'last_speaker': 'QUINEY'}\n",
      "Last word -> QUINEY : \"I know it Judith and I have confessed all to you. I can not undo what is done. All I can say is that her child and she will not want.\"\n",
      "prediction :  Who?\n",
      "Real answer : I know it Judith and I have confessed all to you. I can not undo what is done. All I can say is that her child and she will not want.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8178555965423584], 'recall': [0.7948111295700073], 'f1': [0.8061687350273132], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13011.365234375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOBB V.O.: It's cookin', Bud. It's cookin' fast.\\n\\n\", 'answer': \"Mike, I've got Edgar Bingham now. Just showed with two of his crew, for a sit down with Kay.\", 'gold_tag': 'BUD is involved in some kind of operation , BUD is currently dealing with Edgar Bingham and his crew', 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"Mike, I've got Edgar Bingham now. Just showed with two of his crew, for a sit down with Kay.\"\n",
      "prediction :  We're out of your old favorite?\n",
      "Real answer : Mike, I've got Edgar Bingham now. Just showed with two of his crew, for a sit down with Kay.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8163514137268066], 'recall': [0.8208819031715393], 'f1': [0.818610429763794], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07407407407407408, 'rouge2': 0.0, 'rougeL': 0.07407407407407408, 'rougeLsum': 0.07407407407407408}\n",
      "bleu 1/2 : 0.01909314066544796 0.006614057941723061\n",
      "ppl : 109.56363677978516\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOBB V.O.: Negative at Tibedaux's. Can't walk in. What's our move?\\n\\n\", 'answer': 'We wait.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"We wait.\"\n",
      "prediction :  We have to play it now, Cobb V.O.\n",
      "Real answer : We wait.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8382891416549683], 'recall': [0.8704086542129517], 'f1': [0.8540470004081726], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1818181818181818, 'rouge2': 0.0, 'rougeL': 0.1818181818181818, 'rougeLsum': 0.1818181818181818}\n",
      "bleu 1/2 : 0.12500000000000003 0.04225771273642583\n",
      "ppl : 170.84564208984375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBUD: It's Jesse...\\nCOBB V.O.: He's heading toward the alley, Bud. We take him down?\\nBUD: Let him go.\\nCOBB V.O.: What?!\\nBUD: Let him go.\\nCOBB V.O.: Bud, that's crazy! Jesse goes in first, can't let that happen.\\n\\n\", 'answer': \"That's exactly what we're gonna do! We got no way inside. Let Jesse go in hard and draw fire. He pushes Lucian out to us. Stand the fuck down. I'm on my way.\", 'gold_tag': 'BUD is authoritative, decisive, and strategic , BUD is a law enforcement officer or similar, given his command over the situation and terminology used', 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"That's exactly what we're gonna do! We got no way inside. Let Jesse go in hard and draw fire. He pushes Lucian out to us. Stand the fuck down. I'm on my way.\"\n",
      "prediction :  Yeah yeah, it's not like I've been here since forever, whatever.\n",
      "Real answer : That's exactly what we're gonna do! We got no way inside. Let Jesse go in hard and draw fire. He pushes Lucian out to us. Stand the fuck down. I'm on my way.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8355299830436707], 'recall': [0.8362380862236023], 'f1': [0.8358838558197021], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0816326530612245, 'rouge2': 0.0, 'rougeL': 0.0816326530612245, 'rougeLsum': 0.0816326530612245}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 26.120534896850586\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBLANCA: So how’s that thing?\\nMARIA: What thing?\\nBLANCA: Your job? What do you have to do?\\nMARIA: I told you not to talk about it.\\nBLANCA: Maria... Maria, look at me!\\nMARIA: What the hell are you doing?\\nBLANCA: I’m going to be a mule. I talked to Franklin and he arranged it.\\nMARIA: You what?\\nBLANCA: You heard me. Why not?\\nMARIA: Because you can’t... you won’t make it.\\nBLANCA: Well, I’m doing it. I already told them.\\nMARIA: Blanca, what the hell...?\\nBLANCA: It’s five thousand dollars, Maria. Do you know how much that is in pesos? I figured it out. It’s like ten million. I can buy my family a house with that.\\nMARIA: You can’t go.\\nBLANCA: You know what? I don’t need your permission. I can do what I want.\\nMARIA: Do you realize what you’re saying...? Blanca you have to tell them you’re not\\nBLANCA: No... Anyway, I can’t now. I already said yes.\\nMARIA: ...Do you know what you’re going to tell your family?\\n\\n', 'answer': 'Do you?', 'gold_tag': 'Everyday Language', 'last_speaker': 'BLANCA'}\n",
      "Last word -> BLANCA : \"Do you?\"\n",
      "prediction :  I’m not coming home from today. I’m going with an old friend to a town over and I’m not coming back. I’m staying here.\n",
      "Real answer : Do you?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8040478229522705], 'recall': [0.8306537866592407], 'f1': [0.8171342611312866], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13.448177337646484\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBLANCA: ...How are you doing?\\n\\n', 'answer': '...OK.... You?', 'gold_tag': 'Everyday Language', 'last_speaker': 'MARIA'}\n",
      "Last word -> MARIA : \"...OK.... You?\"\n",
      "prediction :  Fine. Why not?\n",
      "Real answer : ...OK.... You?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8769177198410034], 'recall': [0.8371959924697876], 'f1': [0.8565966486930847], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 342.1376647949219\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBLANCA: What are you doing?\\nMARIA: We can’t stay here?\\nBLANCA: What do you mean?\\nMARIA: Don’t you get it? They did something to Lucy? Everything’s totally fucked up. We have to get out of here before they come back.\\nBLANCA: But...\\n\\n', 'answer': 'Hurry up!!', 'gold_tag': 'Everyday Language', 'last_speaker': 'MARIA'}\n",
      "Last word -> MARIA : \"Hurry up!!\"\n",
      "prediction :  What?\n",
      "Real answer : Hurry up!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8697062730789185], 'recall': [0.7863094210624695], 'f1': [0.8259079456329346], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5475.181640625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMELANIE: What made it...\\n\\n', 'answer': \"It deliberately came down at you -- you're bleeding...\", 'gold_tag': 'MELANIE is currently bleeding', 'last_speaker': 'MITCH'}\n",
      "Last word -> MITCH : \"It deliberately came down at you -- you're bleeding...\"\n",
      "prediction :  You were at the beach.\n",
      "Real answer : It deliberately came down at you -- you're bleeding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8822742700576782], 'recall': [0.8281571865081787], 'f1': [0.8543595671653748], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2857142857142857, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.08986579282344431 0.03177235575108143\n",
      "ppl : 109.74031829833984\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMITCH: You\\'ll be able to find your way back, won\\'t you?\\nMELANIE: Oh, yes. Will I be seeing you again? San Francisco\\'s a long way from here.\\nMITCH: I\\'m in San Francisco five days a week. With a lot of time on my hands. I\\'d like to see you. Maybe we could go swimming or something. Mother tells me you like to swim.\\nMELANIE: How does Mother know what I like to do?\\nMITCH: I guess she and I read the same gossip columns.\\nMELANIE: Oh. That. Rome.\\nMITCH: Mmmm. I like to swim. We might get along very...\\nMELANIE: In case you\\'re interested, I was pushed into that fountain. Without any clothes on? With all my clothes on! The newspaper that ran the story happens to be a rival of my father\\'s paper. Anything they said...\\nMITCH: You were just a poor, innocent victim of circumstance, huh?\\nMELANIE: I\\'m neither poor nor innocent, but the truth of that particular...\\nMITCH: The truth is you were running around with a pretty wild crowd...\\nMELANIE: Yes, but...\\nMITCH: ...who didn\\'t much care for propriety or convention or...\\nMELANIE: Yes.\\nMITCH: ...the opinions of others, and you went right along with them, isn\\'t that the truth?\\nMELANIE: Yes, that\\'s the truth. But I was pushed into that fountain, and that\\'s the truth, too.\\nMITCH: Sure. Do you really know Annie Hayworth?\\nMELANIE: No. At least, I didn\\'t until I came up here.\\nMITCH: So you didn\\'t go to school together.\\nMELANIE: No.\\nMITCH: And you didn\\'t come up here to see her.\\nMELANIE: No.\\nMITCH: You were lying.\\nMELANIE: Yes, I was lying.\\nMITCH: Did you really write a letter to me? Or was that a lie, too?\\nMELANIE: I wrote the letter.\\nMITCH: What did it say?\\nMELANIE: It said, \"Dear Mr. Brenner, I think you need those lovebirds, after all. They may help your personality.\" That\\'s what it said.\\nMITCH: But you tore it up.\\nMELANIE: Yes.\\nMITCH: Why?\\nMELANIE: Because it seemed stupid and foolish.\\nMITCH: Like jumping into a fountain in Rome!\\nMELANIE: I told you what happened in Rome!\\nMITCH: Do you expect me to believe...?\\nMELANIE: I don\\'t give a damn what you believe!\\nMITCH: I\\'d still like to see you.\\nMELANIE: Why?\\nMITCH: I think it could be fun.\\nMELANIE: That might have been good enough in Rome last summer. But it\\'s not good enough now.\\nMITCH: It is for me.\\nMELANIE: But not for me.\\nMITCH: What do you want ?\\n\\n', 'answer': 'I thought you knew! I want to go through life laughing and beautiful and jumping into fountains naked! Good night!', 'gold_tag': 'MELANIE is known to be part of a wild crowd and disregards propriety and convention', 'last_speaker': 'MELANIE'}\n",
      "Last word -> MELANIE : \"I thought you knew! I want to go through life laughing and beautiful and jumping into fountains naked! Good night!\"\n",
      "prediction :  Do you want me to jump into the fountain again?\n",
      "Real answer : I thought you knew! I want to go through life laughing and beautiful and jumping into fountains naked! Good night!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8823518753051758], 'recall': [0.8439359664916992], 'f1': [0.8627164363861084], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.26666666666666666, 'rouge2': 0.0, 'rougeL': 0.26666666666666666, 'rougeLsum': 0.26666666666666666}\n",
      "bleu 1/2 : 0.14715177646857694 0.024525296078096157\n",
      "ppl : 61.203006744384766\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMITCH: It smelled of the fire.\\nMELANIE: It\\'s hard to believe anything at all happened yesterday, isn\\'t it? It\\'s so beautiful and still now. I think I\\'ve got it all figured out, by the way.\\nMITCH: Really? Tell me about it.\\nMELANIE: It\\'s an uprising.\\nMITCH: Of birds?\\nMELANIE: Certainly, of birds. It all started several months ago with a peasant sparrow up in the hills, a malcontent. He went around telling all the other sparrows that human beings weren\\'t fit to rule this planet, preaching wherever anyone would listen...\\nMITCH: Growing a beard...\\nMELANIE: Yes, of course, he had to have a beard! \\'Birds of the world, unite!\\' he kept saying, over and over...\\nMITCH: So they united.\\nMELANIE: Not at first. Oh yes, a few sparrows out for kicks...\\nMITCH: Well, they\\'ll go along with anything.\\nMELANIE: Sure. But eventually, even the more serious-minded birds began to listen. \"Why should humans rule?\" they asked themselves.\\nMITCH: Hear!\\nMELANIE: Why should we submit ourselves to their domination?\\nMITCH: Hear, hear!\\nMELANIE: And all the while, that sparrow was getting in his little messages. Birds of the world, unite!\\nMITCH: Take wing!\\nMELANIE: You have nothing to lose but your feathers.\\nMITCH: What it was, probably...\\nMELANIE: Mmm?\\nMITCH: They\\'re probably hungry, that\\'s all. This was a bad summer. They eat berries and... and nuts, you know, and the hills are all burned out, so\\nMELANIE: With my little sparrow leading team.\\nMITCH: It\\'s so damn quiet out there.\\nMELANIE: It was like that yesterday.\\nMITCH: What do you mean?\\nMELANIE: After the gulls attacked.\\nMITCH: I hadn\\'t thought of that. And then the swifts came.\\nMELANIE: It makes you feel as if they\\'re...\\n\\n', 'answer': \"No, they're having a meeting, Melanie. Your sparrow is standing on a soap box and...\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MITCH'}\n",
      "Last word -> MITCH : \"No, they're having a meeting, Melanie. Your sparrow is standing on a soap box and...\"\n",
      "prediction :  What was the point of the swifts? They're just swifts!\n",
      "Real answer : No, they're having a meeting, Melanie. Your sparrow is standing on a soap box and...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8474525213241577], 'recall': [0.8481442332267761], 'f1': [0.8477982878684998], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14814814814814814, 'rouge2': 0.08, 'rougeL': 0.14814814814814814, 'rougeLsum': 0.14814814814814814}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 43.2509651184082\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMELANIE: They were angry, Mitch. They came out of the chimney in fury. I had the feeling they wanted each and every one of us dead.\\nMITCH: Melanie, Melanie...\\nMELANIE: I'm frightened, Mitch.\\nMITCH: No, no...\\nMELANIE: I'm frightened and confused and I... I think I want to go back to San Francisco where there are buildings and... and concrete and...\\nMITCH: Melanie...\\n\\n\", 'answer': '...everything I know. Oh damn it, why did you have to walk into that shop?', 'gold_tag': 'MELANIE refers to a past event where MITCH walked into a shop which presumably led to their current predicament', 'last_speaker': 'MELANIE'}\n",
      "Last word -> MELANIE : \"...everything I know. Oh damn it, why did you have to walk into that shop?\"\n",
      "prediction :  This place, it's like walking on eggshells, you just need one jerk in the wrong place, and... and you're DEAD! Mitch? Mitch! Mitch! Mitch! Mitch! Mitch! Mitch! Mitch\n",
      "Real answer : ...everything I know. Oh damn it, why did you have to walk into that shop?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8087499141693115], 'recall': [0.8465100526809692], 'f1': [0.8271993398666382], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08888888888888888, 'rouge2': 0.0, 'rougeL': 0.08888888888888888, 'rougeLsum': 0.08888888888888888}\n",
      "bleu 1/2 : 0.03571428571428572 0.011501092655705905\n",
      "ppl : 13.057580947875977\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMITCH: That was Al on the phone. He wants me to meet him out at the Fawcett place. Says some detectives from Santa Rosa'll be there in a little while. Will you be all right here?\\n\\n\", 'answer': 'Yes. I was just taking her in some tea. Be careful. Please.', 'gold_tag': \"MELANIE is caring, as she was about to take someone tea , MELANIE's immediate plan is taking tea to someone , MELANIE is concerned for MITCH's safety\", 'last_speaker': 'MELANIE'}\n",
      "Last word -> MELANIE : \"Yes. I was just taking her in some tea. Be careful. Please.\"\n",
      "prediction :  I’m fine. I don’t know where Al’s going to take me.\n",
      "Real answer : Yes. I was just taking her in some tea. Be careful. Please.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8437373638153076], 'recall': [0.8688933253288269], 'f1': [0.8561305403709412], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307691, 'rouge2': 0.0, 'rougeL': 0.07692307692307691, 'rougeLsum': 0.07692307692307691}\n",
      "bleu 1/2 : 0.08300915602566021 0.027531022470118405\n",
      "ppl : 17.204404830932617\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMELANIE: When will they stop?\\nMITCH: I thought they'd have stopped by\\nMELANIE: What time is it?\\nMITCH: Almost two a.m.\\nMELANIE: You must be exhausted.\\n\\n\", 'answer': 'How about you? I wonder if Cathy fed them.', 'gold_tag': 'MITCH cares about his family , MITCH remembered to check if Cathy fed the birds', 'last_speaker': 'MITCH'}\n",
      "Last word -> MITCH : \"How about you? I wonder if Cathy fed them.\"\n",
      "prediction :  I'm not ready to give up my hobby yet.\n",
      "Real answer : How about you? I wonder if Cathy fed them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8673031330108643], 'recall': [0.8464511036872864], 'f1': [0.8567502498626709], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473685, 'rouge2': 0.0, 'rougeL': 0.10526315789473685, 'rougeLsum': 0.10526315789473685}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18.768848419189453\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMITCH: You should have left when you wanted to. You'd have been safe in San Francisco.\\nMELANIE: I don't want to be safe. I want to be with you.\\nMITCH: The power.\\nMELANIE: Mitch...\\nMITCH: Wait here. Don't move. We'd better light some of those lamps.\\nMELANIE: No... wait. Hold me.\\n\\n\", 'answer': \"I think they're easing off.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MITCH'}\n",
      "Last word -> MITCH : \"I think they're easing off.\"\n",
      "prediction :  No, I cannot have you under my protection. I cannot be the last man in the world until you find a home.\n",
      "Real answer : I think they're easing off.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.840863823890686], 'recall': [0.8574971556663513], 'f1': [0.8490990996360779], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07142857142857144, 'rouge2': 0.0, 'rougeL': 0.07142857142857144, 'rougeLsum': 0.07142857142857144}\n",
      "bleu 1/2 : 0.04545454545454546 0.014712247158412498\n",
      "ppl : 26.93757438659668\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMITCH: Here we go.\\n\\n', 'answer': 'Mitch!', 'gold_tag': 'Everyday Language', 'last_speaker': 'MELANIE'}\n",
      "Last word -> MELANIE : \"Mitch!\"\n",
      "prediction :  Yeah, I guess I always do that. I go back. I try to get to know you better.\n",
      "Real answer : Mitch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8244595527648926], 'recall': [0.8391187191009521], 'f1': [0.8317245244979858], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.412452697753906\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEMMETT: She married an old man, she's made a living on telling women they're too fat, she hawks her crap on the Home Shopping Network...\\nELLE: But maybe it's not what you think.\\nEMMETT: Bu t maybe it is-- . How do you figure?\\nELLE: Because people aren't always what they seem to be and you refuse to see that. Have a little faith. You might be surprised.\\nEMMETT: I can't believe you called me a butt- head. No one's called me a butt-head since ninth grade.\\n\\n\", 'answer': 'Maybe not to your face...', 'gold_tag': 'ELLE calling EMMETT a butt-head in the past', 'last_speaker': 'ELLE'}\n",
      "Last word -> ELLE : \"Maybe not to your face...\"\n",
      "prediction :  I thought you were the guy who gave me that stupid nickname.\n",
      "Real answer : Maybe not to your face...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8297311067581177], 'recall': [0.8065178394317627], 'f1': [0.8179597854614258], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 51.0197639465332\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELLE: I'll cover her -- parts.\\nEMMETT: Well, that's what we're trying to prove didn't happen. Do you have any reason to believe it did?\\nELLE: She's not!\\n\\n\", 'answer': \"Did your daughter ever say anything to you about Brooke and Heyworth's relationship? an infomercial? She said they humped like Much as it is for me, hearing you tell about it. Why do you say that? Ys. . . . e I didn't stick around long enough to watch him stick his swizzle stick in her that ' s where he was about to put it .\", 'gold_tag': 'EMMETT is trying to deduce facts and understand the situation', 'last_speaker': 'EMMETT'}\n",
      "Last word -> EMMETT : \"Did your daughter ever say anything to you about Brooke and Heyworth's relationship? an infomercial? She said they humped like Much as it is for me, hearing you tell about it. Why do you say that? Ys. . . . e I didn't stick around long enough to watch him stick his swizzle stick in her that ' s where he was about to put it .\"\n",
      "prediction :  Yeah, we all know that \"It was a cover-up to protect her.\"\n",
      "Real answer : Did your daughter ever say anything to you about Brooke and Heyworth's relationship? an infomercial? She said they humped like Much as it is for me, hearing you tell about it. Why do you say that? Ys. . . . e I didn't stick around long enough to watch him stick his swizzle stick in her that ' s where he was about to put it .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8512599468231201], 'recall': [0.8000807166099548], 'f1': [0.8248772025108337], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12987012987012986, 'rouge2': 0.0, 'rougeL': 0.07792207792207792, 'rougeLsum': 0.07792207792207792}\n",
      "bleu 1/2 : 0.002555192554286581 0.00048725610176622857\n",
      "ppl : 44.21149444580078\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELLE: I never trust a woman who's not blonde. Except for my friend Serena, but that's only because she's a blonde at heart. That's the whole reason I ' m starting the Blonde Legal Defense Fund. Blondes are discriminated against worldwide! Brooke's a blonde, and people are saying she's sleeping with the cheesy pool boy and shooting her husband. If she was a mousy brunette, it would be,\\nEMMETT: You're serious?\\nELLE: You should see the way I ' m treated in class! I'm a complete source of mockery. This is why the Blonde Legal Defense Fund is needed.\\nEMMETT: -- I can't.\\nELLE: discrimination! If she were a true blonde, she would've left the cheating bastard. Blondes don't let their husbands get fellated by brunettes and live to tell about it. caught him.\\nEMMETT: That's not really a topic that keeps me up at night -- but maybe it should.\\nELLE: Speaking of that �-- I bought you some seaweed cream while we were at the spa. The bags under your eyes. You're an better care of yourself.\\nEMMETT: I don't -- Do that stuff.\\nELLE: Well, you should --. I f you look good, you � feel good and if you feel good, you project joy into the world. Fine. Sorry I brought it up.\\nEMMETT: You really think I ' m attractive?\\n\\n\", 'answer': 'For a butt-head? Yes.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ELLE'}\n",
      "Last word -> ELLE : \"For a butt-head? Yes.\"\n",
      "prediction :  *smiles*\n",
      "Real answer : For a butt-head? Yes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7771592140197754], 'recall': [0.8143231272697449], 'f1': [0.7953071594238281], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2180.72509765625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEMMETT: Whoa -- Why? internship was a mistake. What're you talking about? You earned it-\\nELLE: I didn't earn anything. I got this\\nEMMETT: So now you're --? Going back to LA. Maybe I can fulfill my destiny as a useless bimbo and join the Swedish Bikini Team. No more navy blue suits. No more panty-hose. No more trying to be something I ' m not. What if you're trying to be something you are? The hell with Donovan. Stay.\\n\\n\", 'answer': \"Thanks for not treating me the way everyone else here does. Call me if you're ever in California.\", 'gold_tag': 'Elle is considering returning to Los Angeles , Elle reveals her struggle with conforming to a certain persona , Elle is contemplating leaving her current location and returning to LA', 'last_speaker': 'ELLE'}\n",
      "Last word -> ELLE : \"Thanks for not treating me the way everyone else here does. Call me if you're ever in California.\"\n",
      "prediction :  Well you should stay, but I should go. You're too nice for me, and I like that in men.\n",
      "Real answer : Thanks for not treating me the way everyone else here does. Call me if you're ever in California.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8607943058013916], 'recall': [0.8534955978393555], 'f1': [0.8571294546127319], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25641025641025644, 'rouge2': 0.05405405405405406, 'rougeL': 0.15384615384615385, 'rougeLsum': 0.15384615384615385}\n",
      "bleu 1/2 : 0.10526315789473682 0.024182541670333724\n",
      "ppl : 28.22800636291504\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTREVOR: Hey there, boy. You're a good dog. Yes, you are.\\nELLEN: Sorry for reacting the way I did back there.\\nTREVOR: Don't apologize. That's how most\\nELLEN: Didn't scare me. It just surprised me. ... Thanks for dinner. I had a good time.\\nTREVOR: You're welcome.\\nELLEN: Here... you need a little life in that place of yours.\\nTREVOR: ... Good night.\\n\\n\", 'answer': '... Night.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ELLEN'}\n",
      "Last word -> ELLEN : \"... Night.\"\n",
      "prediction :  Hello...? ... We are now in the same dimension, you?\n",
      "Real answer : ... Night.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8316745758056641], 'recall': [0.9057753086090088], 'f1': [0.8671448230743408], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0.10000000000000002 0.03333333333333335\n",
      "ppl : 223.73695373535156\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELLEN: ... I have to fly up there for a computer conference.\\nTREVOR: When's that?\\nELLEN: Day after tomorrow.\\n\\n\", 'answer': 'Never been to San Francisco.', 'gold_tag': 'TREVOR has never been to San Francisco', 'last_speaker': 'TREVOR'}\n",
      "Last word -> TREVOR : \"Never been to San Francisco.\"\n",
      "prediction :  You're going to do it.\n",
      "Real answer : Never been to San Francisco.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8654856085777283], 'recall': [0.8679859638214111], 'f1': [0.8667339086532593], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1818181818181818, 'rouge2': 0.0, 'rougeL': 0.1818181818181818, 'rougeLsum': 0.1818181818181818}\n",
      "bleu 1/2 : 0.2 0.07071067811865477\n",
      "ppl : 31.60930061340332\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTREVOR: If you want, I'll take care of Jack.\\nELLEN: I can't ask you to do that.\\n\\n\", 'answer': 'Sure you can.', 'gold_tag': 'Trevor is helpful and supportive', 'last_speaker': 'TREVOR'}\n",
      "Last word -> TREVOR : \"Sure you can.\"\n",
      "prediction :  How about this? How does this sound? I'll set up dinner at a fancy restaurant, you tell me about Jack.\n",
      "Real answer : Sure you can.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8213028907775879], 'recall': [0.8671197891235352], 'f1': [0.8435896635055542], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08333333333333333, 'rouge2': 0.0, 'rougeL': 0.08333333333333333, 'rougeLsum': 0.08333333333333333}\n",
      "bleu 1/2 : 0.05000000000000001 0.01622214211307625\n",
      "ppl : 29.233844757080078\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELLEN: ... These conferences mainly focus on software now.\\nTREVOR: Software sells.\\nELLEN: So, how's Jack?\\nTREVOR: ... Jack's good.\\nELLEN: And what about Trevor? Was Trevor a good boy, too?\\nTREVOR: What's that supposed to mean?\\nELLEN: Nothing...\\nTREVOR: Is that supposed to mean something?\\n\\n\", 'answer': 'Trevor...', 'gold_tag': 'Everyday Language', 'last_speaker': 'ELLEN'}\n",
      "Last word -> ELLEN : \"Trevor...\"\n",
      "prediction :  Well, there must be things of which you approve.\n",
      "Real answer : Trevor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8196873664855957], 'recall': [0.8455556631088257], 'f1': [0.8324205875396729], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 89.47402954101562\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTREVOR: Jack?\\n\\n', 'answer': 'Here, boy... here, Jack. Come to Mommy, sweetheart. ... Oh, my God. Jack?!', 'gold_tag': \"ELLEN calls to Jack like a mother to a child  , ELLEN shows concern when he doesn't respond\", 'last_speaker': 'ELLEN'}\n",
      "Last word -> ELLEN : \"Here, boy... here, Jack. Come to Mommy, sweetheart. ... Oh, my God. Jack?!\"\n",
      "prediction :  Who is this?\n",
      "Real answer : Here, boy... here, Jack. Come to Mommy, sweetheart. ... Oh, my God. Jack?!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8283256888389587], 'recall': [0.8076480627059937], 'f1': [0.8178561925888062], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 203.5897216796875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTREVOR: It's aspirin...\\nELLEN: ... I can't talk to you right now, Trevor. Please. I'm so upset I can't even drive. I just need some time alone.\\n\\n\", 'answer': \"I know about what's not fair. I left part of my lung in a damn hospital because some gangbanger didn't like the grade I gave him. Sometimes you do all the right things. You work hard in school... get a good job... pay your taxes. Things still go bad. I'm so sorry, Ellen.\", 'gold_tag': \"TREVOR is a hard-working individual , TREVOR has experienced a serious health issue due to violence , TREVOR possibly indicates he's a teacher , TREVOR's past includes a hospital stay where part of his lung was removed\", 'last_speaker': 'TREVOR'}\n",
      "Last word -> TREVOR : \"I know about what's not fair. I left part of my lung in a damn hospital because some gangbanger didn't like the grade I gave him. Sometimes you do all the right things. You work hard in school... get a good job... pay your taxes. Things still go bad. I'm so sorry, Ellen.\"\n",
      "prediction :  Why can't you drive?\n",
      "Real answer : I know about what's not fair. I left part of my lung in a damn hospital because some gangbanger didn't like the grade I gave him. Sometimes you do all the right things. You work hard in school... get a good job... pay your taxes. Things still go bad. I'm so sorry, Ellen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.82562255859375], 'recall': [0.8044478893280029], 'f1': [0.8148977160453796], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06557377049180328, 'rouge2': 0.0, 'rougeL': 0.06557377049180328, 'rougeLsum': 0.06557377049180328}\n",
      "bleu 1/2 : 1.1962793480322522e-06 4.368194559965586e-07\n",
      "ppl : 92.06372833251953\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELLEN: ... I'd like to apologize for the other night.\\nTREVOR: Shouldn't listen to me. I was half asleep.\\nELLEN: We really need to talk.\\nTREVOR: ... Not tonight. Have to finish some work...\\nELLEN: Tomorrow then? It's important to me.\\nTREVOR: ... Okay.\\n\\n\", 'answer': \"... How 'bout seven o'clock?\", 'gold_tag': \"ELLEN wants to have a talk with TREVOR by seven o'clock tomorrow\", 'last_speaker': 'ELLEN'}\n",
      "Last word -> ELLEN : \"... How 'bout seven o'clock?\"\n",
      "prediction :  Okay. So where we at?\n",
      "Real answer : ... How 'bout seven o'clock?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8602321743965149], 'recall': [0.8134851455688477], 'f1': [0.8362058401107788], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 139.81185913085938\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHEPARD: You want to go back inside?\\nWHITACRE: I think they might have it bugged. We're safer out here.\\nSHEPARD: Bugged? What?\\nWHITACRE: This used to be Dwayne Andreas' house, you know that?\\nSHEPARD: I'm aware of that.\\nWHITACRE: There are things I know, but if I decide to tell you what's going on, could I be prosecuted for it?\\n\\n\", 'answer': \"I can't provide you with immunity, but any information you tell me about your involvement in criminal activity would be discussed with\", 'gold_tag': 'SHEPARD is in a position of authority, possibly law enforcement or legal , SHEPARD cannot provide WHITACRE with immunity', 'last_speaker': 'SHEPARD'}\n",
      "Last word -> SHEPARD : \"I can't provide you with immunity, but any information you tell me about your involvement in criminal activity would be discussed with\"\n",
      "prediction :  There's nothing to tell...\n",
      "Real answer : I can't provide you with immunity, but any information you tell me about your involvement in criminal activity would be discussed with\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8129141330718994], 'recall': [0.8135450482368469], 'f1': [0.813229501247406], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07142857142857142, 'rouge2': 0.0, 'rougeL': 0.07142857142857142, 'rougeLsum': 0.07142857142857142}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 97.8786392211914\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWHITACRE: What if we just move your chair over here.\\n\\n', 'answer': 'Thatta boy, Mark.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SHEPARD'}\n",
      "Last word -> SHEPARD : \"Thatta boy, Mark.\"\n",
      "prediction :  Not at all.\n",
      "Real answer : Thatta boy, Mark.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.851760745048523], 'recall': [0.8558764457702637], 'f1': [0.8538135886192322], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 171.8991241455078\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWHITACRE: Look at that, look at Bob and Terry. Man, I'd love to be a fly on the wall for that one. I was good wasn't I? I seemed scared.\\n\\n\", 'answer': \"Remember what we told you, Mark: tell them that you're cooperating first thing and whatever you do, do not take one of their lawyers.\", 'gold_tag': 'SHEPARD is in a position of authority or mentorship , SHEPARD provides guidance and advice to WHITACRE , WHITACRE is possibly involved in some kind of legal situation , WHITACRE has an upcoming meeting or encounter with Bob and Terry , SHEPARD and WHITACRE have shared memories of discussing or preparing for similar situations', 'last_speaker': 'SHEPARD'}\n",
      "Last word -> SHEPARD : \"Remember what we told you, Mark: tell them that you're cooperating first thing and whatever you do, do not take one of their lawyers.\"\n",
      "prediction :  That is an excellent line of work\n",
      "Real answer : Remember what we told you, Mark: tell them that you're cooperating first thing and whatever you do, do not take one of their lawyers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8413242101669312], 'recall': [0.8296695947647095], 'f1': [0.8354562520980835], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.012594669908908207 0.004301898749003176\n",
      "ppl : 99.9083480834961\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHEPARD: Mark, you can't be here.\\nWHITACRE: They threw me out, Brian.\\nSHEPARD: You're jeopardizing everything.\\nWHITACRE: Tossed me out of ADM. I'm out.\\nSHEPARD: Not here, Mark-- on the phone we can set something up.\\nWHITACRE: You gotta help me.\\n\\n\", 'answer': 'If you need to talk, call me.', 'gold_tag': 'SHEPARD acts in a professional capacity', 'last_speaker': 'SHEPARD'}\n",
      "Last word -> SHEPARD : \"If you need to talk, call me.\"\n",
      "prediction :  You want to hear the bad news?\n",
      "Real answer : If you need to talk, call me.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8530129194259644], 'recall': [0.8585845232009888], 'f1': [0.8557896018028259], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2857142857142857, 'rouge2': 0.0, 'rougeL': 0.2857142857142857, 'rougeLsum': 0.2857142857142857}\n",
      "bleu 1/2 : 0.14285714285714285 0.048795003647426664\n",
      "ppl : 75.0289077758789\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIRK: Aren't you dead? I assume you are loitering here to learn what efficiency rating I plan to give your cadets.\\nSPOCK: I am understandably curious.\\nKIRK: They destroyed the simulator room and you with it.\\nSPOCK: The Kobayshi Maru scenario frequently wreaks havoc with students and equipment. As I recall you took the test three times yourself. Your final solution was, shall we say, unique?\\nKIRK: It had the virtue of never having been tried.\\nSPOCK: Yours was not a solution which would have occurred to a Vulcan mentality.\\nKIRK: So you said at the time. Speaking of which, your prot g 's first rare -- a trifle emotional --\\nSPOCK: She's half Romulan, Jim. The admixture makes her more volatile than -- me, for example.\\nKIRK: Than you. Yes, I see that. By\\nSPOCK: I know of your fondness for antiques.\\nKIRK: 'It was the best of times, it was the worst of times...' Message, Spock?\\nSPOCK: None of which I am consciously aware -- except, of course, happy birthday -- surely the best of times.\\nKIRK: Hrummm... and where are you off to, now?\\nSPOCK: The Enterprise. I must check in before your inspection. And you?\\nKIRK: Home.\\nSPOCK: Something oppresses you.\\n\\n\", 'answer': 'Something.', 'gold_tag': 'Everyday Language', 'last_speaker': 'KIRK'}\n",
      "Last word -> KIRK : \"Something.\"\n",
      "prediction :  What is it?\n",
      "Real answer : Something.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8415678143501282], 'recall': [0.9411358833312988], 'f1': [0.8885713219642639], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 85.16597747802734\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIRK: We've got a problem. Something may be wrong at Regula I. We've been ordered to investigate.\\nSPOCK: Regula I is a scientific research laboratory, if memory serves...\\nKIRK: I told Starfleet all we had was a boatload of children but we're the only ship in the quadrant. Spock: those cadets of yours -- how good are they? How will they respond under real pressure?\\nSPOCK: Like all living beings, Admiral each according to his gifts. The ship is yours.\\nKIRK: That won't be necessary: just take me to Regula I.\\nSPOCK: Excuse my presumption, but I do not agree. As a teacher on a training mission, I am content to command a Starship. If we are to go on actual duty, it is clear that the senior officer aboard must assume command.\\nKIRK: But it may be nothing; garbled communications. Why don't you...\\nSPOCK: You proceed from a false assumption. I am a Vulcan. I have no ego to bruise.\\nKIRK: You are going to remind me that logic alone dictates your actions.\\nSPOCK: I was going to remind you of nothing, least of all that which you know well. Your mistake, if I may be so bold, was promotion. Commanding a Starship is your first best destiny. Anything else is a waste of material.\\nKIRK: I would not presume to debate you.\\nSPOCK: That is wise. In any case, were I to invoke logic, logic clearly dictates that the needs of the many outweigh the needs of the few.\\nKIRK: Or the one.\\nSPOCK: You are my superior officer. You are also my friend. I have been and always shall be yours.\\nKIRK: Will you accompany me to the bridge?\\n\\n\", 'answer': \"I'd best talk with Mr. Scott, first so that he may, in his own words, explain the situation to his cadets.\", 'gold_tag': \"SPOCK's temporal information\", 'last_speaker': 'SPOCK'}\n",
      "Last word -> SPOCK : \"I'd best talk with Mr. Scott, first so that he may, in his own words, explain the situation to his cadets.\"\n",
      "prediction :  Yes, Kirk, to my vessel.\n",
      "Real answer : I'd best talk with Mr. Scott, first so that he may, in his own words, explain the situation to his cadets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8748766183853149], 'recall': [0.8464181423187256], 'f1': [0.8604121208190918], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07407407407407407, 'rouge2': 0.0, 'rougeL': 0.07407407407407407, 'rougeLsum': 0.07407407407407407}\n",
      "bleu 1/2 : 0.008152440795673243 0.002882323084921202\n",
      "ppl : 860.0585327148438\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSPOCK: They knew just where to hit us.\\nKIRK: WHO? Who knew just where to hit us? And why?\\nSPOCK: One thing is certain; we cannot escape on auxiliary power.\\nKIRK: Visual! phasers --\\nSPOCK: Too late --\\n\\n', 'answer': 'Hang on!', 'gold_tag': 'KIRK is a determined character', 'last_speaker': 'KIRK'}\n",
      "Last word -> KIRK : \"Hang on!\"\n",
      "prediction :  What is that thing? A bird!\n",
      "Real answer : Hang on!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8160533905029297], 'recall': [0.8430032730102539], 'f1': [0.8293094038963318], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 111.69694519042969\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIRK: What IS working around here?\\nSPOCK: Not much, Admiral. We have partial main power...\\nKIRK: That's it?\\n\\n\", 'answer': 'Best we could do in two hours.', 'gold_tag': 'Spock can work under time pressure , Spock was given two hours to perform a task', 'last_speaker': 'SPOCK'}\n",
      "Last word -> SPOCK : \"Best we could do in two hours.\"\n",
      "prediction :  Kirk, we get no reports...\n",
      "Real answer : Best we could do in two hours.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8549749851226807], 'recall': [0.8684294819831848], 'f1': [0.8616496920585632], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.13406400920712788 0.04739878501170794\n",
      "ppl : 1180.984130859375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIRK: Then I'm coming with you.\\nSPOCK: I would cite regulation, but I know you will simply ignore it.\\n\\n\", 'answer': \"See, we're getting to know each other.\", 'gold_tag': 'Shared understanding that Kirk often ignores regulations', 'last_speaker': 'KIRK'}\n",
      "Last word -> KIRK : \"See, we're getting to know each other.\"\n",
      "prediction :  What has Starfleet issued regulations about?\n",
      "Real answer : See, we're getting to know each other.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8408013582229614], 'recall': [0.8484982252120972], 'f1': [0.8446322679519653], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 970.6597290039062\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSPOCK: What you refer to as the \"Red Matter located Captain Pike.\\nKIRK: Is he alive?\\nSPOCK: Unknown.\\n\\n', 'answer': \"Let's move.\", 'gold_tag': 'KIRK takes on a leadership role , KIRK is in a command position', 'last_speaker': 'KIRK'}\n",
      "Last word -> KIRK : \"Let's move.\"\n",
      "prediction :  If he's dead, we have to find out -- and in time for a funeral at home station.\n",
      "Real answer : Let's move.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8230962753295898], 'recall': [0.8664891123771667], 'f1': [0.8442354798316956], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809525, 'rouge2': 0.0, 'rougeL': 0.09523809523809525, 'rougeLsum': 0.09523809523809525}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 44.689109802246094\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROHEIM: . that look on her face, you know the and it's not even me, my body. Some guy, this good-looking guy... he looks like the Marlboro Man, only shirtless. And so... the Marlboro Man's running his banging her... and her knees... by her ears, you know? And that look on her face. That look.\\nHORUS: Roheim.\\nROHEIM: Bitch.\\nHORUS: Come on.\\n\\n\", 'answer': 'Walk with me.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROHEIM'}\n",
      "Last word -> ROHEIM : \"Walk with me.\"\n",
      "prediction :  Look at how she's laughing. At the thought. Of him.\n",
      "Real answer : Walk with me.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8709887266159058], 'recall': [0.8755727410316467], 'f1': [0.8732747435569763], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 46.1622314453125\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROHEIM: They're going to can me.\\nHORUS: No one's canning anyone. No one saw us... watch your step... leave.\\n\\n\", 'answer': 'Should be an extra key over the door.', 'gold_tag': 'ROHEIM expresses awareness of the environment by mentioning the location of the key', 'last_speaker': 'ROHEIM'}\n",
      "Last word -> ROHEIM : \"Should be an extra key over the door.\"\n",
      "prediction :  I'll show the council you'll back down to us. I told you, if I have to face you in council, I will show you the way of the council. I mean, you guys have been with the same people, so when it's time you come here to me, that's it, that's time and I'll show you the way of our fathers and the way we were. So we'll go home, and they won't be\n",
      "Real answer : Should be an extra key over the door.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8008412718772888], 'recall': [0.8472621440887451], 'f1': [0.8233978748321533], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.04444444444444444, 'rouge2': 0.0, 'rougeL': 0.02222222222222222, 'rougeLsum': 0.02222222222222222}\n",
      "bleu 1/2 : 0.02702702702702703 0.006084679506313998\n",
      "ppl : 14.108485221862793\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHORUS: You're going to be okay?\\nROHEIM: I don't know. You might have solo act tomorrow night.\\nHORUS: Get some sleep.\\nROHEIM: You're a good man, Horus.\\nHORUS: I have to get home, now. I'll call.\\n\\n\", 'answer': 'You know what Olga said before she walked out on me? Her last words to me. She turned at the front door. Looked around the room and she says, \"keep it clean.\" That\\'s it, can you believe it? Then out But like a.shmuck,.I keep the place spotless... in case she walks through that door one day. I don\\'t think she\\'s coming back.', 'gold_tag': 'ROHEIM keeps his place clean in case she comes back, highlighting his lingering hopes', 'last_speaker': 'ROHEIM'}\n",
      "Last word -> ROHEIM : \"You know what Olga said before she walked out on me? Her last words to me. She turned at the front door. Looked around the room and she says, \"keep it clean.\" That's it, can you believe it? Then out But like a.shmuck,.I keep the place spotless... in case she walks through that door one day. I don't think she's coming back.\"\n",
      "prediction :  I was kind of thinking of joining you and the others back home for a nice reunion.\n",
      "Real answer : You know what Olga said before she walked out on me? Her last words to me. She turned at the front door. Looked around the room and she says, \"keep it clean.\" That's it, can you believe it? Then out But like a.shmuck,.I keep the place spotless... in case she walks through that door one day. I don't think she's coming back.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8544947504997253], 'recall': [0.8107688426971436], 'f1': [0.8320577144622803], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714288, 'rouge2': 0.0, 'rougeL': 0.09523809523809523, 'rougeLsum': 0.09523809523809523}\n",
      "bleu 1/2 : 0.016672780383657982 0.0027173307494639666\n",
      "ppl : 48.81730651855469\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHORUS: Jesus, Aaron. I don't want you to be here.\\n\\n\", 'answer': 'I need a drink.', 'gold_tag': 'ROHEIM is in need of an alcoholic beverage , This need possibly implies stress or a need to relax', 'last_speaker': 'ROHEIM'}\n",
      "Last word -> ROHEIM : \"I need a drink.\"\n",
      "prediction :  Why?\n",
      "Real answer : I need a drink.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8673676252365112], 'recall': [0.872180700302124], 'f1': [0.8697675466537476], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 8849.7822265625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGELA: Wait, hold the door! Going down?\\n\\n', 'answer': 'Not if I can help it.', 'gold_tag': 'JOHN demonstrates a preference for avoiding the downward direction', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"Not if I can help it.\"\n",
      "prediction :  Wait\n",
      "Real answer : Not if I can help it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8275472521781921], 'recall': [0.7677107453346252], 'f1': [0.7965067625045776], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5696637.0\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGELA: I saw you at --\\nJOHN: -- I remember.\\nANGELA: And --\\nJOHN: Yeah.\\nANGELA: I'd like to ask you a few\\nJOHN: I'm not really in the talking mood right now.\\nANGELA: Could you just listen then?\\nJOHN: Always a catch...\\nANGELA: My sister was murdered last week.\\nJOHN: Sorry to hear...\\nANGELA: Dodson? You don't remember her? You sure?\\nJOHN: She look anything like you? I would've remembered.\\nANGELA: Then last Tuesday she just decided to step off the roof.\\nJOHN: I thought you said she was murdered? You'd be surprised at what people\\nANGELA: Look, I know I'm not making much sense -- hell I'm not really sure what I'm doing here... I just feel -- the circles you travel in -- the occult, demonology, exorcisms... I believe someone got to her, Mr. Constantine, brainwashed her into stepping off that roof. Some kind of legion or cult. Well I thought with your background and experience, you could at least point me in the right direction.\\nJOHN: Yeah, okay. Sure.\\nANGELA: My sister always talked about a world better than this. Heaven as some call it. She wasn't afraid of dying because she knew it was waiting for her. What everyone fails to grasp is that if she had really taken her own life --\\nJOHN: -- she would have committed a mortal sin and her soul would have gone straight to Hell where it would never feel love or compassion or anything but pain again as the master himself rips her apart over and over for the rest of eternity. That about right?\\nANGELA: You're not the only one afraid of Hell.\\n\\n\", 'answer': 'Oh shit...', 'gold_tag': 'Everyday Language', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"Oh shit...\"\n",
      "prediction :  Are you?\n",
      "Real answer : Oh shit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8420349955558777], 'recall': [0.8201894760131836], 'f1': [0.8309686183929443], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1458.9237060546875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: The cat too?\\nANGELA: Yeah, why...?\\n\\n', 'answer': 'Why, do you have any?', 'gold_tag': 'Everyday Language', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"Why, do you have any?\"\n",
      "prediction :  It has to have something to do with my ex.\n",
      "Real answer : Why, do you have any?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8139528632164001], 'recall': [0.8248412013053894], 'f1': [0.8193608522415161], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.26666666666666666, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0.2 0.04714045207910317\n",
      "ppl : 31.663713455200195\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: So I took things into my own hands and I found a way out.\\nANGELA: You attempted suicide.\\n\\n', 'answer': 'I never attempt anything.', 'gold_tag': 'JOHN has familiarity with life-threatening situations', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"I never attempt anything.\"\n",
      "prediction :  I'm not trying to die, Angela . The doctors say I've got months. And I've already had one of the most expensive months of my whole life with this visit. I mean they don't know if my cancer's getting better or worse, so I better get used to it. It's been the worse month of my life and I'm already getting used to it.\n",
      "Real answer : I never attempt anything.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8052210807800293], 'recall': [0.8717341423034668], 'f1': [0.8371585607528687], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.027027027027027025, 'rouge2': 0.0, 'rougeL': 0.027027027027027025, 'rougeLsum': 0.027027027027027025}\n",
      "bleu 1/2 : 0.015625000000000007 0.004980119205559976\n",
      "ppl : 11.726683616638184\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: cocky, peddles their influence or hijacks a soul -- I deport their scaly ass right back to Hell. I don't get them all but maybe enough to insure my retirement. Well, what would you do if you were sentenced to a prison where half the inmates were put there by you?\\nANGELA: Why you? I mean many go to Hell, why were you able to escape?\\nJOHN: I don't know.\\nANGELA: God has a plan for all of us.\\nJOHN: Not for me.\\n\\n\", 'answer': 'Detective Dodson here.', 'gold_tag': 'ANGELA is a detective who introduced Detective Dodson', 'last_speaker': 'ANGELA'}\n",
      "Last word -> ANGELA : \"Detective Dodson here.\"\n",
      "prediction :  I have to go.\n",
      "Real answer : Detective Dodson here.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8564233183860779], 'recall': [0.799436092376709], 'f1': [0.8269490599632263], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 88.04386901855469\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGELA: She'd tell everyone about things she said she saw. Crazy things. Things that hadn't happened yet. She'd scare my mother to death, talking on and on about Revelations and the end of the world. Then one day she just stopped... never said another word.\\n\\n\", 'answer': \"So you put her in here. Angela doesn't need to be reminded. It hurts even more now.\", 'gold_tag': \"JOHN is empathetic and understanding about ANGELA's situation , JOHN shows concern for ANGELA's emotional state\", 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"So you put her in here. Angela doesn't need to be reminded. It hurts even more now.\"\n",
      "prediction :  Do you think she's okay?\n",
      "Real answer : So you put her in here. Angela doesn't need to be reminded. It hurts even more now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8484760522842407], 'recall': [0.8444048166275024], 'f1': [0.846435546875], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08333333333333333, 'rouge2': 0.0, 'rougeL': 0.08333333333333333, 'rougeLsum': 0.08333333333333333}\n",
      "bleu 1/2 : 0.018143590657882503 0.006414727994630807\n",
      "ppl : 49.81509780883789\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGELA: There is no 14h act in Corinthians. John's face goes pale --\\n\\n\", 'answer': 'I need a church.', 'gold_tag': 'John demonstrates a sense of urgency , John is oriented towards religious places', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"I need a church.\"\n",
      "prediction :  Oh. I get you. That's why there's no place 14-hearse.\n",
      "Real answer : I need a church.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8475313186645508], 'recall': [0.8969327211380005], 'f1': [0.8715324997901917], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.10000000000000002 0.03333333333333335\n",
      "ppl : 46.30514144897461\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: 13:29. 13:30 -- Here... Corinthians 14:01... 'The sins of the father would only be exceeded by the ego of the son.' why I couldn't place it... not a normal possession... But he can't cross over -- impossible for the son to cross over...\\nANGELA: Whose son? God's?\\n\\n\", 'answer': 'No. The other one. Lucifer had a son too.', 'gold_tag': 'JOHN is knowledgeable, particularly in religious text and supernatural phenomenon', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"No. The other one. Lucifer had a son too.\"\n",
      "prediction : 00:15 Oh.. the Son of God. Right? That... 16:01 16:01 Jesus said -- the Son of God cannot be taken and 16:06 can't be taken into the grave. And... and you know what I's mean, right? It's an obvious thing when you think of it. And you know what He's saying?\n",
      "Real answer : No. The other one. Lucifer had a son too.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7841764688491821], 'recall': [0.8711303472518921], 'f1': [0.8253695368766785], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05970149253731343, 'rouge2': 0.0, 'rougeL': 0.05970149253731343, 'rougeLsum': 0.05970149253731343}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.252408027648926\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: been in the presence of the Creator either. That goes double for us -- God's most prized creations. Mammon would be the last demon we'd ever want crossing over.\\nANGELA: that's what you said.\\nJOHN: Some psychic with the chops to reach all the way to Hell and the grit to withstand whatever shit she'd pull out. But even a bridge wouldn't help Mammon. Because to cross over, the myth says he'd still need the one thing he could never get. Divine assistance. The help of God. Impossible? Sure it's impossible. That's what makes it so dangerous. These things exist to break the rules, to find the loopholes. If the past is any indication, then the future isn't on our side.\\n\\n\", 'answer': \"She knew. That's why she killed sense... John, she sacrificed herself to beat him. John nods. Your point? Why is she in Hell?\", 'gold_tag': 'ANGELA is inquisitive and rational', 'last_speaker': 'ANGELA'}\n",
      "Last word -> ANGELA : \"She knew. That's why she killed sense... John, she sacrificed herself to beat him. John nods. Your point? Why is she in Hell?\"\n",
      "prediction :  so, basically there's no hope for us?\n",
      "Real answer : She knew. That's why she killed sense... John, she sacrificed herself to beat him. John nods. Your point? Why is she in Hell?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.845048189163208], 'recall': [0.8378884792327881], 'f1': [0.8414531350135803], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0625, 'rouge2': 0.0, 'rougeL': 0.0625, 'rougeLsum': 0.0625}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 59.63328552246094\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: Hey, Beeman? Beeman?!\\nANGELA: Maybe he's not here.\\nJOHN: He's always here.\\nANGELA: What?\\nJOHN: Oh Jesus, no --\\nANGELA: Oh God --\\nJOHN: Who are you?! Answer me!! Goddamit -- reveal yourself! I summon you! ... this is my fault... I sent them in... I sent them right to their deaths... a damn one-man plague.\\nANGELA: John, you need a doctor.\\n\\n\", 'answer': \"I've seen a goddamn doctor!! Get away from me!! Stay the hell away -- Please --\", 'gold_tag': 'John refuses medical help, indicating a negative past experience with health care, or a stubborn personality', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"I've seen a goddamn doctor!! Get away from me!! Stay the hell away -- Please --\"\n",
      "prediction :  Beeman!\n",
      "Real answer : I've seen a goddamn doctor!! Get away from me!! Stay the hell away -- Please --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8206226825714111], 'recall': [0.8175579309463501], 'f1': [0.8190874457359314], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18140.884765625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGELA: But you knew that already, didn't you? You see something in me... I need to understand -- Why not?\\nJOHN: Because you open up to that world, you're inviting whatever's out there back in. That's what happened to Isabel. No, she embraced her gift while you denied yours and that denial is exactly why you're still alive. Stick with me, that'll change. And I don't need another ghost following me around.\\nANGELA: Dammit, John -- they killed my sister! I can't let them get away with that. Even if it means going down the same path she did. Now if you won't help me get there, I'll find my own way. But I won't run. Never. The two stand there -- locked in this moment.\\n\\n\", 'answer': \"You do this, there's no turning back. You see them -- they see you. Understand?\", 'gold_tag': 'JOHN views himself as a protector to ANGELA', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"You do this, there's no turning back. You see them -- they see you. Understand?\"\n",
      "prediction :  And that is the moment we all share. The moment your brother came out of the room. And when the darkness was on you, I wanted to keep you safe . I didn't know how, and it's why I followed you -- I followed. I followed because I wanted to help you. I want you to see things like I did. I never knew I could -- be this certain way before, but now I've tasted it . You want to keep that. You don\n",
      "Real answer : You do this, there's no turning back. You see them -- they see you. Understand?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8284502029418945], 'recall': [0.8479598164558411], 'f1': [0.8380914926528931], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12121212121212122, 'rouge2': 0.0, 'rougeL': 0.10101010101010101, 'rougeLsum': 0.10101010101010101}\n",
      "bleu 1/2 : 0.0588235294117647 0.00836827408755723\n",
      "ppl : 17.122461318969727\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGELA: Why water?\\nJOHN: It's the universal conduit. Lubricates the transition from one plane to another. Now ask me if there's water in Hell. Normally only a portion of the body has to be suspended but you wanted the crash course...\\nANGELA: What will I see? His eyes say it all. Enough. Lie down? For how long?\\n\\n\", 'answer': 'Last chance... Take a deep one.', 'gold_tag': \"JOHN is patient and careful , JOHN gives Angela a 'last chance' before proceeding\", 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"Last chance... Take a deep one.\"\n",
      "prediction :  I have to leave now.\n",
      "Real answer : Last chance... Take a deep one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8717656135559082], 'recall': [0.8641213774681091], 'f1': [0.8679265975952148], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 69.40071868896484\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGELA: All those people... so sad... ... I've always known... where the bad guys are... where to aim, when to duck... it's not luck... I've always known...\\n\\n\", 'answer': 'Angela?', 'gold_tag': 'Everyday Language', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"Angela?\"\n",
      "prediction :  Oh. I hear. Now.\n",
      "Real answer : Angela?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8908125162124634], 'recall': [0.8648961782455444], 'f1': [0.8776630759239197], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 223.17413330078125\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: That half-breed tipped my scales when he started killing my friends. I'm just adding a little counterweight.\\nANGELA: What about me? I can't stay here forever.\\n\\n\", 'answer': \"You're staying in the car.\", 'gold_tag': 'JOHN is authoritative by dictating where ANGELA should stay', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"You're staying in the car.\"\n",
      "prediction :  You always do what's best for people. Well, it's easy for you to speak like that 'cause your people are here. And while we're talking... You've got another half-breed with you. His name's Angel. He's good for business. I've got a bad feeling about him. You know what they say about angels?\n",
      "Real answer : You're staying in the car.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8109625577926636], 'recall': [0.8658056259155273], 'f1': [0.8374871611595154], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0606060606060606, 'rouge2': 0.0, 'rougeL': 0.0606060606060606, 'rougeLsum': 0.0606060606060606}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.961304664611816\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGELA: Something's coming...\\nJOHN: What happened to staying in the car?\\nANGELA: You were in danger.\\n\\n\", 'answer': \"Well now there's a premonition.\", 'gold_tag': \"JOHN is surprised at ANGELA's intervention\", 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"Well now there's a premonition.\"\n",
      "prediction :  Did something happen...?\n",
      "Real answer : Well now there's a premonition.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8721909523010254], 'recall': [0.8635066747665405], 'f1': [0.8678271174430847], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 4381.99609375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: soldier's spear. It matches that child's drawing John removed from the fridge -- now lying on his seat. Then you know what this spear would mean to a demon trying to cross over. She doesn't. Mammon needed divine assistance -- how's the blood of God's only son? Not quite. Twins. Here we go --\\nANGELA: What is that?\\nJOHN: Hang on --\\nANGELA: I lost it. He's down --\\n\\n\", 'answer': \"He's not down. Gimme your phone.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"He's not down. Gimme your phone.\"\n",
      "prediction :  No -- no, let me go. This is your son, right? The one who's been asking and praying for you. We need you alive so we can go to Hell with Mammon.\n",
      "Real answer : He's not down. Gimme your phone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8277535438537598], 'recall': [0.8706135749816895], 'f1': [0.8486427664756775], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10256410256410256, 'rouge2': 0.0, 'rougeL': 0.05128205128205128, 'rougeLsum': 0.05128205128205128}\n",
      "bleu 1/2 : 0.03125 0.010040241611281232\n",
      "ppl : 33.7104377746582\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKING KARL: Hi! I'm Karl, and Welcome to my\\nEMMET: For Kreativity...\\nKING KARL: Exaktly!\\nEMMET: Why did you build all this stuff?\\n\\n\", 'answer': 'Well...Why not?', 'gold_tag': 'KING KARL exhibits a whimsical and free-spirited nature with his response of \"Why not?\" to Emmet\\'s question', 'last_speaker': 'KING KARL'}\n",
      "Last word -> KING KARL : \"Well...Why not?\"\n",
      "prediction :  I like making stuff, but sometimes my creations\n",
      "Real answer : Well...Why not?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8274590969085693], 'recall': [0.8198221921920776], 'f1': [0.8236229419708252], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 97.93363189697266\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKING KARL: If you can conceive it, we will achieve it. Build anything whenever you feel it.\\nEMMET: You know we really don't have time--\\n\\n\", 'answer': 'Invent a game, like Roller Cricket. Or buy Bullfighting Tennis tickets...', 'gold_tag': 'KING KARL encourages building and inventing games', 'last_speaker': 'KING KARL'}\n",
      "Last word -> KING KARL : \"Invent a game, like Roller Cricket. Or buy Bullfighting Tennis tickets...\"\n",
      "prediction :  --and a deadline, either. Just do it. Make the tools, if you want to build a ship, use what you need. What can't you do?\n",
      "Real answer : Invent a game, like Roller Cricket. Or buy Bullfighting Tennis tickets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8332105278968811], 'recall': [0.8357594013214111], 'f1': [0.8344830274581909], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05405405405405406, 'rouge2': 0.0, 'rougeL': 0.05405405405405406, 'rougeLsum': 0.05405405405405406}\n",
      "bleu 1/2 : 0.04000000000000001 0.012909944487358061\n",
      "ppl : 39.84416961669922\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKING KARL: Make any idea thought or spoken. Rules were meant to be broken!\\n\\n', 'answer': 'No, rules were meant to be followed.', 'gold_tag': 'EMMET believes in following the rules', 'last_speaker': 'EMMET'}\n",
      "Last word -> EMMET : \"No, rules were meant to be followed.\"\n",
      "prediction :  I made a mistake..\n",
      "Real answer : No, rules were meant to be followed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8849244117736816], 'recall': [0.8651227951049805], 'f1': [0.8749115467071533], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 180.75682067871094\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBIZZLEBEK: I've read your stories. They're fantastic.\\nKAFKA: I don't know what you could have read.\\nBIZZLEBEK: Just what you've published.\\nKAFKA: -- In magazines nobody reads.\\nBIZZLEBEK: I read the one about the penal colony.\\nKAFKA: Did you?\\n\\n\", 'answer': \"The needles inscribing the judgement into the flesh of the man. Very good. If I could sculpt as well as that, I'd be quite proud of myself.\", 'gold_tag': 'BIZZLEBEK aspires to be a sculptor', 'last_speaker': 'BIZZLEBEK'}\n",
      "Last word -> BIZZLEBEK : \"The needles inscribing the judgement into the flesh of the man. Very good. If I could sculpt as well as that, I'd be quite proud of myself.\"\n",
      "prediction :  The Penal colony.\n",
      "Real answer : The needles inscribing the judgement into the flesh of the man. Very good. If I could sculpt as well as that, I'd be quite proud of myself.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.891973078250885], 'recall': [0.8347669839859009], 'f1': [0.8624224066734314], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06451612903225806, 'rouge2': 0.0, 'rougeL': 0.06451612903225806, 'rougeLsum': 0.06451612903225806}\n",
      "bleu 1/2 : 0.00011182087596750395 4.33080390380468e-05\n",
      "ppl : 4585.5703125\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBIZZLEBEK: Where are your friends?\\n\\n', 'answer': 'Good question. Who are my friends ... would also be of interest.', 'gold_tag': 'KAFKA questions the nature of his friends , KAFKA questions the identity of his friends', 'last_speaker': 'KAFKA'}\n",
      "Last word -> KAFKA : \"Good question. Who are my friends ... would also be of interest.\"\n",
      "prediction :  They are there in the restaurant\n",
      "Real answer : Good question. Who are my friends ... would also be of interest.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8644999861717224], 'recall': [0.8506720662117004], 'f1': [0.8575302958488464], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352942, 'rouge2': 0.0, 'rougeL': 0.11764705882352942, 'rougeLsum': 0.11764705882352942}\n",
      "bleu 1/2 : 0.0613132401952404 0.021239529438966134\n",
      "ppl : 326.02496337890625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAFKA: Gabriela was right -- it's easier for me to understand suicide. I'm a practicing suicide.\\nBIZZLEBEK: -- In what sense?\\nKAFKA: Bachelorhood is just the slow form. The bachelor doesn't sew seeds. Only the moment matters. The space he occupies grows smaller and smaller -- until the only space right for him is his coffin.\\nBIZZLEBEK: These strange stories you write -- they come naturally, do they?\\nKAFKA: Naturally? -- that's not the word I would have chosen.\\nBIZZLEBEK: Where do you get your ideas? Only joking -- I'm just joking. Let's go to a brothel then, Kafka, come on.\\nKAFKA: I haven't got the energy. I mean, I have to conserve my energy.\\nBIZZLEBEK: Why do you work in that hideous insurance office? -- dealing with people who fall off ladders. Now take me -- I make my living as a stone mason. It's not my art -- but it's the tools of my art. You could be -- a journalist.\\nKAFKA: That would be even worse -- it would be a compromise.\\nBIZZLEBEK: Success or nothing?\\n\\n\", 'answer': \"No -- not even success. My writing is not for making a living -- it's for living. Not for other people, it's for me. ... I'm the exile. Gabriela was right about that too.\", 'gold_tag': 'KAFKA\\'s writing is not for making a living, but for living , KAFKA refers to himself as an \"exile\"', 'last_speaker': 'KAFKA'}\n",
      "Last word -> KAFKA : \"No -- not even success. My writing is not for making a living -- it's for living. Not for other people, it's for me. ... I'm the exile. Gabriela was right about that too.\"\n",
      "prediction :  No...\n",
      "Real answer : No -- not even success. My writing is not for making a living -- it's for living. Not for other people, it's for me. ... I'm the exile. Gabriela was right about that too.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8398914337158203], 'recall': [0.8058245778083801], 'f1': [0.8225054144859314], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05714285714285715, 'rouge2': 0.0, 'rougeL': 0.05714285714285715, 'rougeLsum': 0.05714285714285715}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24607.076171875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAFKA: You work in the cemetery.\\nBIZZLEBEK: A man must eat -- And drink.\\n\\n', 'answer': 'The Castle cemetery.', 'gold_tag': \"KAFKA's persona - KAFKA knows about the specific site, KAFKA's persona - KAFKA is detail-oriented\", 'last_speaker': 'KAFKA'}\n",
      "Last word -> KAFKA : \"The Castle cemetery.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction : \n",
      "Real answer : The Castle cemetery.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.0], 'recall': [0.0], 'f1': [0.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : nan\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBIZZLEBEK: Are you sure you wouldn't prefer going through official channels?\\nKAFKA: Official channels -- a lot of good they've done me. My only hope is to approach the officials personally.\\nBIZZLEBEK: -- I'm flattered, of course, to be considered a friend -- even without knowing all the details. (Kafka doesn't take -- To see such determination is reward enough for me.\\nKAFKA: The Kafka men are famous for it, you know. Delivering meat barefoot in the depths of winter, picking up sacks of flour with their teeth -- -- Oh, yes, determination runs in the family.\\nBIZZLEBEK: There is one thing I'd like you to tell me.\\nKAFKA: I'm trying to find things out myself -- that's the whole point.\\nBIZZLEBEK: What made you think I'd be able to get you into the Castle?\\nKAFKA: The cemetery is nearer the Castle than anywhere else -- wasn't it part of the Castle originally? -- I always assumed there'd be a gate or something. Isn't there?\\n\\n\", 'answer': 'In a manner of speaking.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BIZZLEBEK'}\n",
      "Last word -> BIZZLEBEK : \"In a manner of speaking.\"\n",
      "prediction :  No, the Castle has no gate. -- It's only that my cousin's nephew's wife's cousin's cousin has a gate. And no, I don't know where.\n",
      "Real answer : In a manner of speaking.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8083317279815674], 'recall': [0.8267645239830017], 'f1': [0.8174441456794739], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05714285714285715, 'rouge2': 0.0, 'rougeL': 0.05714285714285715, 'rougeLsum': 0.05714285714285715}\n",
      "bleu 1/2 : 0.04000000000000001 0.012909944487358061\n",
      "ppl : 18.513402938842773\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBIZZLEBEK: I was restoring some stones here in the upper section one day -- and I found this.\\nKAFKA: An empty tomb?\\nBIZZLEBEK: A cenotaph -- a monument to someone whose remains ended up elsewhere. But look -- The Castle gates were blockaded in the time of the great plague -- it's an escape route. Don't get stuck.\\nKAFKA: Not a chance. I'm the thinnest person I know. -- You appreciate my writing.\\nBIZZLEBEK: Yes.\\nKAFKA: Will you do me a favor then?\\nBIZZLEBEK: Another one?\\nKAFKA: If I don't see you later -- go to my house and find my notebooks -- and destroy them. All my manuscripts -- just burn them. Please.\\nBIZZLEBEK: What an extraordinary request!\\nKAFKA: It's my last and final one.\\nBIZZLEBEK: Then its authority is in doubt.\\nKAFKA: A true friend would do it.\\n\\n\", 'answer': 'Not necessarily. A wife would.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BIZZLEBEK'}\n",
      "Last word -> BIZZLEBEK : \"Not necessarily. A wife would.\"\n",
      "prediction :  Good morning, Dr. Kafka.\n",
      "Real answer : Not necessarily. A wife would.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8649399280548096], 'recall': [0.8710637092590332], 'f1': [0.867991030216217], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 205.3004150390625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDAVID: No way... I think. we \"ve met. You need a better line than that or I\\'ll have to assume you\\'re a pervert who likes to stare at Your skirt was so short I couldn\\'t help it.\\nWOMAN: Dress.\\nDAVID: Skirt, dress, same thing.\\nWOMAN: If you\\'re a pervert, yeah. All\\nDAVID: So do shorts, dear.\\nWOMAN: Yeah, but there\\'s that pesky piece of fabric right here that interferes with your fantasy life. Wake me when you have a good come back to that.\\nDAVID: I have one but, unlike you, I wouldn\\'t say it in public.\\nWOMAN: Pussy.\\nDAVID: Hello...? Hello? The line cut.\\nWOMAN: you pretty much have it maxed out?\\nDAVID: You\\'re relentless.\\nWOMAN: I never sleep through the night. I catch up on the bus. You going to run again?\\nDAVID: I just started a new job, today.\\nWOMAN: I saw your concession speech. I heard Bill Clinton called it the best political speech he\\'s seen in\\nDAVID: Something got into me. What\\'s the deal with you and argyles?\\nWOMAN: What\\'s the deal with you and boring shades of blue?\\nDAVID: At least my clothes match.\\nWOMAN: That\\'s easy if you. restrict yourself to one color.\\nDAVID: The belt and shoes are black.\\nWOMAN: Variety is the spice of .life .\\n\\n', 'answer': \"There you` go with the platitudes again. I guess it wasn't the ch mpagne . Hello? Hello?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'DAVID'}\n",
      "Last word -> DAVID : \"There you` go with the platitudes again. I guess it wasn't the ch mpagne . Hello? Hello?\"\n",
      "prediction :  Well we've gotten your attention. Now , what's the deal with you and me being so . . .\n",
      "Real answer : There you` go with the platitudes again. I guess it wasn't the ch mpagne . Hello? Hello?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.848432183265686], 'recall': [0.8279469013214111], 'f1': [0.8380643725395203], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17647058823529413, 'rouge2': 0.0, 'rougeL': 0.058823529411764705, 'rougeLsum': 0.058823529411764705}\n",
      "bleu 1/2 : 0.15789473684210523 0.029617443887954613\n",
      "ppl : 29.292903900146484\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWOMAN: Your phone sucks. Don't guys like you get special phones that actually work in the middle of the biggest city in the country?\\n\\n\", 'answer': 'Depends what the telecom lobby thinks of your voting record.', 'gold_tag': 'DAVID is likely a political figure or lawmaker , DAVID made a comment about a voting record impacting the quality of telecommunications he receives', 'last_speaker': 'DAVID'}\n",
      "Last word -> DAVID : \"Depends what the telecom lobby thinks of your voting record.\"\n",
      "prediction :  I did buy a new phone when I moved, though.\n",
      "Real answer : Depends what the telecom lobby thinks of your voting record.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8691840171813965], 'recall': [0.8455837965011597], 'f1': [0.8572215437889099], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 46.33884811401367\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDAVID: I'll pay for the damage.\\nWOMAN: Hope your new job pays better than your old one.\\nDAVID: Give me your number and I'll send you a check.\\nWOMAN: God, that is smooth. Spill coffee on me then ask for my number. Just let me spill some on you and we'll be even.\\nDAVID: It's my first day at the office!\\nWOMAN: Tell your boss some crazy chick dumped coffee on you on the MI. It's New York; he'll understand.\\nDAVID: No!\\nWOMAN: Come on. Just a little.\\nDAVID: You're crazy. Actually crazy. He's not here! Who was that? What is this, third grade?\\n\\n\", 'answer': \"You forgot what that was like, didn't you? How fun it was... Oh my God! How do you stand it? There. We're even. Sturdy little fucker, isn't it? By the way, I'm Elise.\", 'gold_tag': 'WOMAN is bold and spontaneous , WOMAN is not afraid to stand her ground and engage in playful banter', 'last_speaker': 'WOMAN'}\n",
      "Last word -> WOMAN : \"You forgot what that was like, didn't you? How fun it was... Oh my God! How do you stand it? There. We're even. Sturdy little fucker, isn't it? By the way, I'm Elise.\"\n",
      "prediction :  I have no idea what you're talking about. But it's nothing to do with him. I don't know what you're talking about, either.\n",
      "Real answer : You forgot what that was like, didn't you? How fun it was... Oh my God! How do you stand it? There. We're even. Sturdy little fucker, isn't it? By the way, I'm Elise.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8436745405197144], 'recall': [0.8168584108352661], 'f1': [0.830049991607666], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.1875, 'rougeLsum': 0.1875}\n",
      "bleu 1/2 : 0.05629612105077489 0.01287111147310488\n",
      "ppl : 5.87537956237793\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: And what if I don't want to give up on her?\\nROB: You don't call.\\nMIKE: But you said I shouldn't call if I wanted to give up on her.\\nROB: Right.\\nMIKE: So I don't call either way.\\nROB: Right.\\nMIKE: So what's the difference?\\nROB: The only difference between giving up and not giving up is if you take her back when she wants to come back. See, you can't do anything to make her want to come back. You can only do things to make her not want to come back.\\nMIKE: So the only difference is if I forget about her or pretend to forget about her.\\nROB: Right.\\nMIKE: Well that sucks.\\nROB: It sucks.\\nMIKE: So it's almost a retroactive decision. So I could, like, let's say, forget about her and when she comes back make like I just pretended to forget about her.\\nROB: Right...or more likely the opposite.\\nMIKE: Right... Wait, what do you mean?\\nROB: I mean first you'll pretend not to care, not call - whatever, and then, eventually, you really won't care.\\nMIKE: Unless she comes back first.\\nROB: Ah, see, that's the thing. Somehow they don't come back until you really don't care anymore.\\nMIKE: There's the rub.\\nROB: There's the rub.\\nMIKE: Thanks, man. Sorry we always talk about the same thing all the time...\\nROB: Hey man, don't sweat it.\\nMIKE: ...It's just that you've been there. Rob, I just want you to know, you're the only one I can talk to about her.\\n\\n\", 'answer': 'Thanks. Thanks, man.', 'gold_tag': \"ROB listens to Mike's worries\", 'last_speaker': 'ROB'}\n",
      "Last word -> ROB : \"Thanks. Thanks, man.\"\n",
      "prediction :  Your mind is made up.\n",
      "Real answer : Thanks. Thanks, man.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8462551832199097], 'recall': [0.89339280128479], 'f1': [0.8691853880882263], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 109.71504211425781\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROB: I don't think I'm gonna take it.\\nMIKE: I's a gig.\\nROB: I mean, I need the money.\\nMIKE: You're an actor. Find the Zen in the role.\\nROB: It's definitely a step back for me.\\nMIKE: Look, there's not much of a call for Shakespeare in this town.\\nROB: There's just something about being\\nMIKE: What do you want? You're tall.\\nROB: Do you realize how hard it's going to be to tell my parents? I still haven't told them I didn't get the pilot.\\nMIKE: You tested over a month ago. I'm sure they figured it out by now.\\n\\n\", 'answer': 'It\\'s like \"Hi, Mom. I\\'m not going to be starring in that sit-com and, oh by the way, I\\'m Goofy. Send more money.\"', 'gold_tag': 'ROB is afraid of disappointing his parents', 'last_speaker': 'ROB'}\n",
      "Last word -> ROB : \"It's like \"Hi, Mom. I'm not going to be starring in that sit-com and, oh by the way, I'm Goofy. Send more money.\"\"\n",
      "prediction :  I’ve got something.\n",
      "Real answer : It's like \"Hi, Mom. I'm not going to be starring in that sit-com and, oh by the way, I'm Goofy. Send more money.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8822161555290222], 'recall': [0.8238328099250793], 'f1': [0.8520255088806152], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06451612903225806, 'rouge2': 0.0, 'rougeL': 0.06451612903225806, 'rougeLsum': 0.06451612903225806}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 80.91272735595703\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: Haven't you noticed I didn't mention Michelle once today?\\nROB: I didn't want to say anything.\\nMIKE: Why?\\nROB: I don't know. It's like not talking to\\nMIKE: What? Like, you didn't want to jinx it?\\nROB: Kinda.\\nMIKE: I don't talk about her that much.\\nROB: Oh no?\\nMIKE: I didn't mention her once today.\\nROB: Well, until now. Tend the pin.\\nMIKE: The only reason I mentioned her at all is to say that I'm not going to talk about her anymore. I thought you'd appreciate that.\\nROB: I do. Good for you, man.\\nMIKE: I've decided to get out there. Go ahead. Play it out. I'm not making any more excuses for myself.\\nROB: Good to hear, Mikey.\\nMIKE: You want to hit the town tonight?\\nROB: I shouldn't, Mike, it's a weeknight.\\nMIKE: What do you have? A Pluto call back?\\nROB: Sure. Kick me when I'm down.\\nMIKE: Count 'em up.\\nROB: I'll give you an eight.\\nMIKE: What'd you get?\\nROB: An eight.\\nMIKE: Looks like we're in a dead heat after one hole. This is turning into quite a rivalry.\\n\\n\", 'answer': 'You better replace the pin, Chi-Chi. The natives look restless.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROB'}\n",
      "Last word -> ROB : \"You better replace the pin, Chi-Chi. The natives look restless.\"\n",
      "prediction :  What are you doing here?\n",
      "Real answer : You better replace the pin, Chi-Chi. The natives look restless.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8269957304000854], 'recall': [0.8335993885993958], 'f1': [0.8302844166755676], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12500000000000003, 'rouge2': 0.0, 'rougeL': 0.12500000000000003, 'rougeLsum': 0.12500000000000003}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 46.57502365112305\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROB: So, if the party starts at eight, why are\\nMIKE: To get a drink before we meet the guys for a bite at eleven.\\nROB: Oh. Where is this place?\\nMIKE: It's one of these. For some reason, cool bars in L.A. have to be very hard to find and have no signs out front.\\nROB: That doesn't sound too good for business.\\nMIKE: It's kinda like a speakeasy kind of thing. It's kinda cool. It's like you're in on some kind of secret. You tell a chick you've been some place, it's like bragging that you know how to find it. The only way you could know where a place is is if someone who knows brought you there. You have to have someone come before. There is a direct line connecting you back to the original, unequivocally cool, club patrons. It's kinda like Judaism...\\nROB: Sounds more like Aids...\\n\\n\", 'answer': \"... That's probably a more appropriate analogy.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MIKE'}\n",
      "Last word -> MIKE : \"... That's probably a more appropriate analogy.\"\n",
      "prediction :  What's that supposed to be?\n",
      "Real answer : ... That's probably a more appropriate analogy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.839464008808136], 'recall': [0.8565537929534912], 'f1': [0.8479228019714355], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.30769230769230765, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 30.613462448120117\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMELVIN: That's some face they left hanging on you. You look like...\\nSIMON: Could you take it just a little easy, Mr. Udall? Thank you. Verdell... sweetheart? By the way, thanks for saving me.\\nMELVIN: I called. I never touched you. I didn't leave my name or nothing.\\n\\n\", 'answer': 'Verdell? Hi, sweetheart.', 'gold_tag': 'SIMON shows affection for Verdell', 'last_speaker': 'SIMON'}\n",
      "Last word -> SIMON : \"Verdell? Hi, sweetheart.\"\n",
      "prediction :  Yeah, about that--\n",
      "Real answer : Verdell? Hi, sweetheart.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7935916185379028], 'recall': [0.8271432518959045], 'f1': [0.8100201487541199], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 569.8502197265625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSIMON: Hello?... yes... sure... finally, huh? Why, \"finally\"? Because I called you so many times. Maybe Oh, boy... I was hoping it was something like that. You didn\\'t get one of them, huh? \\'Cause I mean it wasn\\'t only your office -- it was your home, hotel and the cigar club you like in San Francisco. No -- Sarcastic... Of course. I believe you. No, don\\'t fire anyone... Please. Maybe I\\'m wrong about the 20 times. Take a breath... So, you miss me a little? Hey, strike the question -- How\\'s the case going? Really. Fantastic. I didn\\'t hear. I haven\\'t been watching. Great. Just great. I\\'m so happy. Whoopie! Me? Well, I\\'m mending. No, I look fine. Well, some of the damage might still be noticeable if you look closely... Carl, I need some help and you\\'re the logical one to turn to. No! Not \\'cause I blame you for you can ever think that. No, I\\'m I guess because you hired the guy who did this you think... No, I am a sarcastic person. Well, if you must know, the reason I said you were the logical person is because you always told me how you thought I was this great person who made you feel good about humanity and everything. You do remembering saying that? Well, whew. Okay, so Carl. I hate asking but this money thing is ridiculously serious... \"Will you please loan me money? I will pay you back. I will give you whatever percentage of my income I don\\'t absolutely need until I do. It will take a while. But I don\\'t know what I\\'ll do if you say\"... that. I understand... yes... No, I do. But you know, you know -- you didn\\'t even ask how much, Carl? Well, Frank has no right to discuss how much I\\'m in hock... no, you\\'re right -- not the point. So... what have you been up to??? Uh-huh... Oh, the group show... how was it? Well, I\\'m not surprised that there\\'s that much talent around... great... Look -- gotta go... no, you shouldn\\'t feel that way at all... take care, you, too... you, too... Good-bye. Pal o\\' mine.\\nMELVIN: Maybe I\\'ll bring him some food by.\\nSIMON: Thank you for walking him. If you\\'ll excuse me I\\'m not feeling so well.\\nMELVIN: It smells like shit in here?\\nSIMON: Go away.\\nMELVIN: That cleaning woman doesn\\'t...\\nSIMON: Please, just leave.\\nMELVIN: Where are all your queer party friends?\\nSIMON: Get out. Nothing worse than having to feel this way in front of you?\\nMELVIN: Nellie, you\\'re a disgrace to depression.\\nSIMON: Rot in hell, Melvin.\\nMELVIN: No need to stop being a lady... quit worrying -- you\\'ll be back on your knees in no time.\\nSIMON: Is this fun for you? Well, you lucky devil... It just gets better and better. I am losing my apartment and Frank wants me to promise to paint hotter subjects and to beg my parents, who haven\\'t called, for help... and I won\\'t. And I don\\'t want to paint anymore. So the life I was trying for is over. The life I had is gone and I am feeling so damn sorry for myself that it is difficult to breathe. Right times for you -- terrified... Terrified... Lucky you, you\\'re here for rock bottom... me wallowing in self-pity in front of you, you absolute horror of a human being...\\nMELVIN: Well, I\\'ll do one thing for you that might cheer you up.\\nSIMON: Get out.\\nMELVIN: Don\\'t piss on a gift, tough guy. You want to know why the dog prefers me... it\\'s not affection. It\\'s a trick. I carry bacon in my pocket.\\nSIMON: Oh, my gosh.\\nMELVIN: Now we\\'ll both call him.\\nSIMON: Come on, sweetheart...\\nMELVIN: Yo, yo, yo...\\nSIMON: Would you leave now, please?\\n\\n', 'answer': \"Stupid dog. I don't get it.\", 'gold_tag': \"Melvin is insensitive and tactless, using derogatory terms and exhibiting a lack of empathy for Simon's situation , Melvin takes care of Simon's dog\", 'last_speaker': 'MELVIN'}\n",
      "Last word -> MELVIN : \"Stupid dog. I don't get it.\"\n",
      "prediction :  They'd never talk about me...\n",
      "Real answer : Stupid dog. I don't get it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8359994888305664], 'recall': [0.8667165637016296], 'f1': [0.8510809540748596], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 153.2182159423828\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMELVIN: I took a chance you were up. I brought you Chinese soup.\\nSIMON: Thanks.\\nMELVIN: I have never been so tired in my life. Okay, if I sit here?\\nSIMON: Got any easier questions?\\nMELVIN: I haven't been sleeping. I haven't been clear or felt like myself. I'm in trouble. Some son of a bitch is burning my bridges behind my back... But the tiredness -- boy... Not just sleepy.\\nSIMON: But sick -- nauseous -- where everything looks distorted and\\n\\n\", 'answer': \"Yeah... I'm glad we did this. Good talking to you.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MELVIN'}\n",
      "Last word -> MELVIN : \"Yeah... I'm glad we did this. Good talking to you.\"\n",
      "prediction :  Are you sick as well?\n",
      "Real answer : Yeah... I'm glad we did this. Good talking to you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8170756101608276], 'recall': [0.8305859565734863], 'f1': [0.8237753510475159], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12500000000000003, 'rouge2': 0.0, 'rougeL': 0.12500000000000003, 'rougeLsum': 0.12500000000000003}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 142.15109252929688\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMELVIN: Can I ask you a personal question? Do you ever get an erection for a woman?\\nSIMON: Melvin...\\nMELVIN: Wouldn't your lie be a lot easier if you were not...\\nSIMON: You consider your life easy.\\n\\n\", 'answer': 'I give you that one... Nice packing.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MELVIN'}\n",
      "Last word -> MELVIN : \"I give you that one... Nice packing.\"\n",
      "prediction :  Can I ask you a personal question? Do you ever get an erection for a woman?\n",
      "Real answer : I give you that one... Nice packing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8363322019577026], 'recall': [0.8437432050704956], 'f1': [0.8400213718414307], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17391304347826086, 'rouge2': 0.0, 'rougeL': 0.17391304347826086, 'rougeLsum': 0.17391304347826086}\n",
      "bleu 1/2 : 0.12500000000000003 0.028867513459481287\n",
      "ppl : 18.96800422668457\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSIMON: Thank you, Melvin. You overwhelm me.\\nMELVIN: They did a nice job... Cozy, huh?\\nSIMON: I love you.\\n\\n', 'answer': \"I'll tell you, buddy, I'd be the luckiest guy alive if that did it for me.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MELVIN'}\n",
      "Last word -> MELVIN : \"I'll tell you, buddy, I'd be the luckiest guy alive if that did it for me.\"\n",
      "prediction :  (a couple of months pass) I'm working hard for a good year this year. I need to know this is going to be a good year. I need to feel like you're in my corner with it. (Melvin kisses her)\n",
      "Real answer : I'll tell you, buddy, I'd be the luckiest guy alive if that did it for me.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8393412828445435], 'recall': [0.8471945524215698], 'f1': [0.8432496786117554], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0.05000000000000001 0.011322770341445961\n",
      "ppl : 20.17217445373535\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSIMON: It's Carol.\\nMELVIN: Here. Take the dog.\\n\\n\", 'answer': 'Good luck.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SIMON'}\n",
      "Last word -> SIMON : \"Good luck.\"\n",
      "prediction :  Yes. I will. I will. Thank you.\n",
      "Real answer : Good luck.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8574379682540894], 'recall': [0.8906170129776001], 'f1': [0.8737126588821411], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 28.50046730041504\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMELVIN: You going to come talk to me or not?\\nSIMON: I\\'m coming. What did she say?\\nMELVIN: I\\'m a great guy -- \"extraordinary\"... ... and she doesn\\'t want contact with me. I\\'m dying here.\\nSIMON: Because... ... you love her?\\nMELVIN: No... and you\\'re supposed to be sensitive and sharp.\\nSIMON: Okay... you tell me why --\\nMELVIN: I don\\'t know... Let me sleep on it and figure it out. Because I\\'m stuck! Can\\'t go back to what I had... She\\'s evicted me from my life.\\nSIMON: Did you like it that much?\\nMELVIN: It was better than this... Look, you, I\\'m very intelligent. If you\\'re going to give me advice or conversation or consolation or hope, you got to be better than you\\'re doing. If you can\\'t be at least momentarily interesting than shut the hell up. I\\'m drowning and you\\'re describing water.\\nSIMON: Picking on me won\\'t help.\\nMELVIN: Well, if that\\'s true then I\\'m really in trouble.\\nSIMON: But you know where you\\'re lucky?\\nMELVIN: Absolutely not.\\nSIMON: You know who you want. I\\'ll take your seat any day. So do something... don\\'t sleep on it... go over there. I don\\'t think anybody should ever sleep on anything -- it\\'s not always good\\nMELVIN: Hey... I\\'m charged here. But she might kill me for showing up this late.\\nSIMON: Then get in your jammies and I\\'ll read you a story... I think you\\'ve got a chance. The only real enemy you have is her ability to think logically -- the best thing you have going for you is your willingness to humiliate yourself if it gives you one chance in whatever -- so go catch her off- guard.\\nMELVIN: Okay. Thanks a lot. Here I go.\\nSIMON: What\\'s wrong?\\n\\n', 'answer': 'I forgot to lock the door.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MELVIN'}\n",
      "Last word -> MELVIN : \"I forgot to lock the door.\"\n",
      "prediction :  Nothing.\n",
      "Real answer : I forgot to lock the door.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9414211511611938], 'recall': [0.8615247011184692], 'f1': [0.8997026085853577], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 17029.697265625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLARDNER: You always say that. You always say that. I'm telling you, you never met the man.\\nMCCULLERS: Seventeen months ago I was posting a walk in Lisbon, and he was there. He never saw me. But I saw him, though.\\nLARDNER: Lisbon?\\nMCCULLERS: In Portugal, yes.\\nLARDNER: Here's the news: He hasn't been in Portugal since '90. I know that from the file. Why don't you read the file, man?\\nMCCULLERS: In fact, I think I talked with him, in Bonn.\\n\\n\", 'answer': \"You always say that. You always have to know everybody. Why don't I just take the weekend off and let you kill him. Since you two are so close.\", 'gold_tag': \"LARDNER and MCCULLERS frequently argue about MCCULLERS's supposed acquaintance with the individuals in question\", 'last_speaker': 'LARDNER'}\n",
      "Last word -> LARDNER : \"You always say that. You always have to know everybody. Why don't I just take the weekend off and let you kill him. Since you two are so close.\"\n",
      "prediction :  I'm with you right now.\n",
      "Real answer : You always say that. You always have to know everybody. Why don't I just take the weekend off and let you kill him. Since you two are so close.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8600798845291138], 'recall': [0.8447282314300537], 'f1': [0.8523349761962891], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0.0016459494098040061 0.0005819309945812043\n",
      "ppl : 32.74341583251953\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLARDNER: Well?\\nMCCULLERS: I don't think so.\\nLARDNER: Well, remember when Frysal's men paid off the Deejay in Cairo to announce a bogus press conference in the --\\nMCCULLERS: --Nooo--\\nLARDNER: --Yes. And the Munich Olympics in '72. A local radio station started broadcasting news of the massacre two minutes before it happened.\\nMCCULLERS: That's strictly B�ader-Meinhof stuff.\\nLARDNER: It was the PLO.\\n\\n\", 'answer': 'Whatever.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MCCULLERS'}\n",
      "Last word -> MCCULLERS : \"Whatever.\"\n",
      "prediction :  Is that going to be a problem?\n",
      "Real answer : Whatever.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8346803188323975], 'recall': [0.9281543493270874], 'f1': [0.8789390921592712], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 41.731170654296875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMCCULLERS: I wish he'd do his job already so we could do our job.\\nLARDNER: We can't do our job unless he does his job.\\nMCCULLERS: Why don't we just do his job then, so we can do our job, and get the fuck out of here.\\nLARDNER: Do his job? I'm not a cold-blooded killer.\\nMCCULLERS: Wait a minute--\\nLARDNER: -Look. You want to kill a Good Guy, but not be a Bad Guy, you wait until a Bad Guy kills the Good Guy, and then you come in and kill the Bad Guy, and then you're the Good Guy.\\nMCCULLERS: So if we do his job, we're the bad guys. If we do our job, we're the good guys.\\n\\n\", 'answer': 'Yup.', 'gold_tag': 'LARDNER takes out bad guys as a good guy', 'last_speaker': 'LARDNER'}\n",
      "Last word -> LARDNER : \"Yup.\"\n",
      "prediction :  You've gotta be kidding, you don't understand the game. I've been doing this a long time. I saw the bad guy coming a long way back, and I had to do a good job of killing him.\n",
      "Real answer : Yup.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8091182112693787], 'recall': [0.8672274351119995], 'f1': [0.8371656537055969], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.257776260375977\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMCCULLERS: Looks like someone keeps trying to do our job for us.\\nLARDNER: If he does our job, he's our job.\\n\\n\", 'answer': 'I get it.', 'gold_tag': 'MCCULLERS shares LARDNER\\'s professional space , The use of terms like \"our job\" signals that they share some professional responsibility', 'last_speaker': 'MCCULLERS'}\n",
      "Last word -> MCCULLERS : \"I get it.\"\n",
      "prediction :  What's that?\n",
      "Real answer : I get it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8279412984848022], 'recall': [0.8657479286193848], 'f1': [0.8464226722717285], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 64.52029418945312\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLARDNER: Did you see Blank in there?\\nMCCULLERS: No...\\n\\n', 'answer': 'Good. For a second there I thought we were in trouble.', 'gold_tag': \"LARDNER's perceived threat from Blank's presence will become irrelevant once they ascertain Blank's absence , MCCULLERS's initial ignorance about Blank's presence becomes irrelevant after LARDNER's clarification\", 'last_speaker': 'LARDNER'}\n",
      "Last word -> LARDNER : \"Good. For a second there I thought we were in trouble.\"\n",
      "prediction :  Ok, I’m leaving.\n",
      "Real answer : Good. For a second there I thought we were in trouble.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8882455229759216], 'recall': [0.8839696645736694], 'f1': [0.8861024975776672], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 80.36962127685547\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDAN: Dan Soulsby.\\nMARTIN: Martin. Nice to meet you.\\nDAN: Where you heading to?\\nMARTIN: Away from here. Pisswater.\\n\\n', 'answer': \"At least it's cold pisswater. Here's to getting away. That was bad. It's gonna take all day to get another bus here.\", 'gold_tag': 'DAN shows a sense of humor even in less ideal situations , DAN implies that the wait for the next bus will be all day', 'last_speaker': 'DAN'}\n",
      "Last word -> DAN : \"At least it's cold pisswater. Here's to getting away. That was bad. It's gonna take all day to get another bus here.\"\n",
      "prediction :  Drink or drive, you decide.\n",
      "Real answer : At least it's cold pisswater. Here's to getting away. That was bad. It's gonna take all day to get another bus here.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8416033983230591], 'recall': [0.822170615196228], 'f1': [0.8317735195159912], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 350.694091796875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMARTIN: You have a license?\\nDAN: Had one. They took it away.\\nMARTIN: I got one. Let's go.\\n\\n\", 'answer': \"See that? They're all fake.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'DAN'}\n",
      "Last word -> DAN : \"See that? They're all fake.\"\n",
      "prediction :  They are not the only ones in the world. It is my right to choose. I get to decide if I want to share my freedom. It is a choice that you made, and now it is up to me.\n",
      "Real answer : See that? They're all fake.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8308693170547485], 'recall': [0.8315646648406982], 'f1': [0.8312168121337891], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913045, 'rouge2': 0.0, 'rougeL': 0.04347826086956522, 'rougeLsum': 0.04347826086956522}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.340144157409668\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMARTIN: You take a hockey puck in the face?\\nDAN: A fist. My stepdad socked me. I flew across the room and dented the sheetrock in the kitchen. My mom saw everything and still took his side.\\nMARTIN: You got cracked good.\\nDAN: I hate that guy. Two hundred pounds of worthless grease.\\nMARTIN: Why'd he hit you?\\nDAN: I wrecked his sixty-five Mustang and his boat in the same week. His babies. I totaled them.\\nMARTIN: I would have popped you too.\\nDAN: It was worth it. But I didn't deserve the tour in hell. Don't ever go to military school if you can help it. It sucks. I jumped the wall two days ago.\\nMARTIN: You going back?\\nDAN: I'm done with that racket. I'm going to Seattle and playing music.\\nMARTIN: I know some chords.\\n\\n\", 'answer': \"Think you can learn drums? I'm the next Billy Squire. Krokus will be opening for me one day. Shit.\", 'gold_tag': 'DAN aims to be a drummer', 'last_speaker': 'DAN'}\n",
      "Last word -> DAN : \"Think you can learn drums? I'm the next Billy Squire. Krokus will be opening for me one day. Shit.\"\n",
      "prediction :  I'm not sure if I can trust him. It's a very bad move to not let a stranger come into your home. I understand. I'm sorry.\n",
      "Real answer : Think you can learn drums? I'm the next Billy Squire. Krokus will be opening for me one day. Shit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8511891961097717], 'recall': [0.8414509296417236], 'f1': [0.8462921380996704], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12244897959183673, 'rouge2': 0.0425531914893617, 'rougeL': 0.12244897959183673, 'rougeLsum': 0.12244897959183673}\n",
      "bleu 1/2 : 0.07692307692307693 0.017541160386140592\n",
      "ppl : 13.531054496765137\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFERGUS: You all right?\\nJUDE: Fucking animal.\\nFERGUS: You don't know that.\\nJUDE: Fucking do. I had him all over me.\\nFERGUS: Tough work, that.\\nJUDE: Someone's got to do it. Nah, it was a breeze. Just thought of you. And you know what, Fergus? One of you made me want it...\\n\\n\", 'answer': 'Which one?', 'gold_tag': 'Everyday Language', 'last_speaker': 'FERGUS'}\n",
      "Last word -> FERGUS : \"Which one?\"\n",
      "prediction :  What's that mean?\n",
      "Real answer : Which one?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8436688184738159], 'recall': [0.8780220746994019], 'f1': [0.8605027198791504], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 59.657745361328125\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJUDE: Hello, stranger. You vanished. What was it, Fergus? Did you blow the gaff on us or did you just fuck up?\\nFERGUS: Leave me alone, Jude.\\nJUDE: No. That's the last thing I'll do. You never asked what happened.\\nFERGUS: I heard.\\nJUDE: Eddie and Tinker died.\\nFERGUS: I know.\\nJUDE: Maguire and me got out by the skin of our teeth. No thanks to you.... What you think of the hair?\\nFERGUS: Suits you.\\nJUDE: Aye, I was sick of being blond. Needed a tougher look, if you know what I mean. Fuck me, Fergus. Am I to take it that's a no? We had a court-martial in your absence. They wanted to put a bullet in your head. I pleaded for clemency. Said we should find out what happened first. So what did happen?\\nFERGUS: He ran. I couldn't shoot him in the back. I tried to catch him. He made it to the road and got hit by a Saracen.\\nJUDE: So you did fuck up.\\nFERGUS: Yes.\\nJUDE: But you know what the thing is, Fergus?\\nFERGUS: No, what is the thing?\\nJUDE: You vanished quite effectively. Became Mister Nobody. And you've no idea how useful that could be.\\nFERGUS: What do you mean?\\nJUDE: We've got some plans here. And we'll need a Mister Nobody to execute them.\\nFERGUS: No way, Jude. I'm out.\\nJUDE: You're never out, Fergus. Maybe you don't care whether you die or not. But consider the girl, Fergus. The wee black chick.\\nFERGUS: Leave her out of this.\\nJUDE: Jesus, Fergus, you're a walking cliche. You know we won't leave her out of this. But I'm glad to see you care. And I must admit I'm curious.\\nFERGUS: What the fuck do you know, Jude?\\nJUDE: You fucking tell me, boy --\\nFERGUS: She's nobody. She likes me.\\n\\n\", 'answer': \"So I suppose a fuck is out of the question. Keep your head down, Fergus. No You'll be hearing from us. Keep the faith.\", 'gold_tag': 'JUDE is manipulative as she attempts to leverage FERGUS\\' care for \"the wee black chick\" to coerce him into cooperation', 'last_speaker': 'JUDE'}\n",
      "Last word -> JUDE : \"So I suppose a fuck is out of the question. Keep your head down, Fergus. No You'll be hearing from us. Keep the faith.\"\n",
      "prediction :  Awww, now, now. It's no skin off my nose if you take one for the team.\n",
      "Real answer : So I suppose a fuck is out of the question. Keep your head down, Fergus. No You'll be hearing from us. Keep the faith.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8421579599380493], 'recall': [0.8570654392242432], 'f1': [0.8495463132858276], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714282, 'rouge2': 0.0, 'rougeL': 0.14285714285714282, 'rougeLsum': 0.14285714285714282}\n",
      "bleu 1/2 : 0.03790816623203959 0.01238075524708008\n",
      "ppl : 17.015260696411133\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJUDE: You a handyman, Fergie?\\nFERGUS: I take pride in my work.\\n\\n', 'answer': 'I sincerely hope so. Tools of the trade. And forget about the girl.', 'gold_tag': \"JUDE is a discerning individual who values professionalism , JUDE could have some connection to FERGUS's work\", 'last_speaker': 'JUDE'}\n",
      "Last word -> JUDE : \"I sincerely hope so. Tools of the trade. And forget about the girl.\"\n",
      "prediction :  Do you have a toolbox?\n",
      "Real answer : I sincerely hope so. Tools of the trade. And forget about the girl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8639674186706543], 'recall': [0.8526140451431274], 'f1': [0.8582531809806824], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 100.58392333984375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHELEN: Oh -- hello--\\nKLAATU: May I see you for a minute?\\nHELEN: I -- I was Just going to lunch.\\nKLAATU: May I walk out with you?\\n\\n', 'answer': 'Mrs. Benson speaking. Oh, hello...', 'gold_tag': 'HELEN uses formal language, indicating a professional or educated background', 'last_speaker': 'HELEN'}\n",
      "Last word -> HELEN : \"Mrs. Benson speaking. Oh, hello...\"\n",
      "prediction :  That's fine.\n",
      "Real answer : Mrs. Benson speaking. Oh, hello...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8547307252883911], 'recall': [0.8597303628921509], 'f1': [0.8572232723236084], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 70.56001281738281\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKLAATU: I saw Bobby this morning before he went to school--\\nHELEN: Yes--?\\nKLAATU: I want to know what he told you last night.\\nHELEN: I -- I didn't really pay much attention--\\n\\n\", 'answer': 'Did you believe what he told you? I have a reason for asking this -- a very important reason.', 'gold_tag': \"KLAATU shows concern for Bobby's actions and the implications of his conversations\", 'last_speaker': 'KLAATU'}\n",
      "Last word -> KLAATU : \"Did you believe what he told you? I have a reason for asking this -- a very important reason.\"\n",
      "prediction :  -- what? (If the above dialogue, the response to the second option must be different)\n",
      "Real answer : Did you believe what he told you? I have a reason for asking this -- a very important reason.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.845435619354248], 'recall': [0.8487799167633057], 'f1': [0.8471044898033142], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0625, 'rouge2': 0.0, 'rougeL': 0.0625, 'rougeLsum': 0.0625}\n",
      "bleu 1/2 : 0.05106188922430991 0.016713926606989293\n",
      "ppl : 141.2675323486328\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHELEN: What is it you want?\\nKLAATU: Before I ask you to be honest with me, perhaps I should be completely honest with you--\\nHELEN: What happened?\\nKLAATU: What time is it?\\nHELEN: Just twelve.\\nKLAATU: We'll be stuck here for a little while -- about thirty minutes.\\nHELEN: We could try pushing the other buttons. I have a flashlight in my purse.\\nKLAATU: It won't work.\\nHELEN: Why not?\\nKLAATU: You see -- the electricity's been neutralized -- all over the world.\\n\\n\", 'answer': \"Bobby was telling the truth -- wasn't he?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'HELEN'}\n",
      "Last word -> HELEN : \"Bobby was telling the truth -- wasn't he?\"\n",
      "prediction :  You were the first to realize the implications.\n",
      "Real answer : Bobby was telling the truth -- wasn't he?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8872337341308594], 'recall': [0.8365087509155273], 'f1': [0.8611249327659607], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.12500000000000003 0.04225771273642583\n",
      "ppl : 105.36029052734375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKLAATU: --I've already told you more than I told Professor Barnhardt, because my life, in a sense, is in your hands. I thought if you knew the facts you'd appreciate the importance of my not being -- apprehended, -- before the meeting tonight.\\nHELEN: Yes, of course. Of course I do. You hold great hope for this meeting.\\nKLAATU: I can see no other hope for your planet. If the meeting should fail, then I'm afraid there is no hope. It must be twelve-thirty.\\n\\n\", 'answer': 'Yes -- Just exactly.', 'gold_tag': 'Everyday Language', 'last_speaker': 'HELEN'}\n",
      "Last word -> HELEN : \"Yes -- Just exactly.\"\n",
      "prediction :  Eleven-thirty\n",
      "Real answer : Yes -- Just exactly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7627289295196533], 'recall': [0.8049430251121521], 'f1': [0.783267617225647], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 9243.74609375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHELEN: Where are you going now?\\nKLAATU: Back to the boardinghouse. I'll be safe there for the afternoon -- and I can keep an eye on Bobby. He's the only other person who knows anything about--\\nHELEN: No, wait a minute -- there's someone else.\\nKLAATU: Who?\\n\\n\", 'answer': \"Tom... He was there last night when Bobby told me what he saw. Of course, he doesn't know anything definite. He'd talk to me first, anyway, before-- We can't take that chance. I'll get in touch with him right away and make sure.\", 'gold_tag': 'HELEN has a close relationship with a person named Tom', 'last_speaker': 'HELEN'}\n",
      "Last word -> HELEN : \"Tom... He was there last night when Bobby told me what he saw. Of course, he doesn't know anything definite. He'd talk to me first, anyway, before-- We can't take that chance. I'll get in touch with him right away and make sure.\"\n",
      "prediction :  He's your friend.\n",
      "Real answer : Tom... He was there last night when Bobby told me what he saw. Of course, he doesn't know anything definite. He'd talk to me first, anyway, before-- We can't take that chance. I'll get in touch with him right away and make sure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8509913682937622], 'recall': [0.821648120880127], 'f1': [0.8360623717308044], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0392156862745098, 'rouge2': 0.0, 'rougeL': 0.0392156862745098, 'rougeLsum': 0.0392156862745098}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 78.79364013671875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKLAATU: I'm sure Barnhardt can arrange to hide me until the meeting.\\nHELEN: Where is the meeting going to be?\\n\\n\", 'answer': 'At the ship.', 'gold_tag': 'KLAATU is soon going to attend a meeting', 'last_speaker': 'KLAATU'}\n",
      "Last word -> KLAATU : \"At the ship.\"\n",
      "prediction :  A warehouse.\n",
      "Real answer : At the ship.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9336491823196411], 'recall': [0.926976203918457], 'f1': [0.9303007125854492], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 6604.80224609375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKLAATU: Hello.\\nHELEN: I -- I thought you were--\\nKLAATU: I was.\\nHELEN: You mean he has the power of life and death?\\nKLAATU: No -- that is a power reserved to This technique, in certain cases, can re-stimulate life for a limited period. It's a refinement of scientific principles known to your own people.\\nHELEN: But how -- how long--?\\n\\n\", 'answer': 'How long will I live? That no one can say.', 'gold_tag': 'KLAATU has had his life re-stimulated for an indeterminate time period', 'last_speaker': 'KLAATU'}\n",
      "Last word -> KLAATU : \"How long will I live? That no one can say.\"\n",
      "prediction :  Until the heart has strengthened to support that power, it will be a very, very short period.\n",
      "Real answer : How long will I live? That no one can say.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8501441478729248], 'recall': [0.8552180528640747], 'f1': [0.8526735901832581], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14814814814814817, 'rouge2': 0.0, 'rougeL': 0.07407407407407408, 'rougeLsum': 0.07407407407407408}\n",
      "bleu 1/2 : 0.0588235294117647 0.019174124721184262\n",
      "ppl : 78.98514556884766\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLERK: Twelve gauge. You need shells? Moss\\nMOSS: Uh-huh. Double ought.\\nCLERK: They'll give you a wallop.\\nMOSS: You have camping supplies?\\nCLERK: Tent poles.\\nMOSS: Uh-huh.\\nCLERK: You already have the tent?\\nMOSS: Somethin' like that.\\nCLERK: Well you give me the model number of the tent I can order you the poles.\\nMOSS: Never mind. I want a tent.\\nCLERK: What kind of tent?\\nMOSS: The kind with the most poles.\\nCLERK: Well I guess that'd be our ten-foot backyard Per-Gola. You can stand up in it. Well, some people could stand up in it. Six foot clearance at the ridge. You might just could.\\n\\n\", 'answer': \"Let me have that one. Where's the nearest hardware store?\", 'gold_tag': 'MOSS has a need for camping supplies', 'last_speaker': 'MOSS'}\n",
      "Last word -> MOSS : \"Let me have that one. Where's the nearest hardware store?\"\n",
      "prediction :  Uh-huh.\n",
      "Real answer : Let me have that one. Where's the nearest hardware store?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8041415214538574], 'recall': [0.8365483283996582], 'f1': [0.8200249075889587], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 226.30734252929688\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOSS: One room, one night.\\nCLERK: That's twenty-six dollars.\\nMOSS: You on all night?\\nCLERK: Yessir, be here til ten tomorrow morning.\\nMOSS: For you. I ain't asking you to do anything illegal.\\nCLERK: I'm waitin' to hear your description of that.\\n\\n\", 'answer': \"There's somebody lookin' for me. Not police. Just call me if anyone else checks in tonight.\", 'gold_tag': 'MOSS is not being sought after by the police , MOSS is being sought after by an unidentified person', 'last_speaker': 'MOSS'}\n",
      "Last word -> MOSS : \"There's somebody lookin' for me. Not police. Just call me if anyone else checks in tonight.\"\n",
      "prediction :  You're on duty this summer?\n",
      "Real answer : There's somebody lookin' for me. Not police. Just call me if anyone else checks in tonight.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8370339870452881], 'recall': [0.8325639367103577], 'f1': [0.8347930312156677], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 143.82781982421875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLERK: How those Larries holdin' up?\\nMOSS: Good. I need everything else.\\nCLERK: Okay.\\nMOSS: You get a lot of people come in here with no clothes on?\\n\\n\", 'answer': \"No sir, it's unusual.\", 'gold_tag': 'CLERK works in a place where they sell or lend clothes', 'last_speaker': 'CLERK'}\n",
      "Last word -> CLERK : \"No sir, it's unusual.\"\n",
      "prediction :  Yeah\n",
      "Real answer : No sir, it's unusual.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8223121166229248], 'recall': [0.8076931238174438], 'f1': [0.8149371147155762], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 7528537.5\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMICHAEL: There's a lot I can't tell you, Tom. I know that's upset you in the past; and you've felt that it was because of some lack of trust or confidence. But it is because I do trust you that I've kept so much secret from you. It's precisely that at this moment, you are the only one that I can completely trust. In time, you'll understand everything.\\nHAGEN: But your people... Neri... Rocco; you don't think...\\nMICHAEL: No, I have confidence in their loyalty... but this is life and death, and Tom, you are my brother.\\nHAGEN: Mikey, I hoped...\\nMICHAEL: No Tom, just listen. All my people are businessmen; their loyalty is based on that. One thing I learned from my father is to try to think as the people around you think...and on that basis, anything is possible. Fredo has a good heart, but he is weak...and stupid, and stupid people are the most dangerous of all. I've kept you out of things, Tom, because I've always known that your instincts were legitimate, and I wanted you to know very little of things that would make you an accomplice, for your own protection. I never blamed you for the setbacks the family took under Sonny; I know you were in a position of limited power, and you did your best to advise and caution him. What I am saying is that now, for how long I do not know, you will be the Don. If what I think has happened is true; I will leave tonight, and absolutely no one will know how to contact me. And even you are not to try to reach me unless it is absolutely necessary. I give you complete power: over Neri... Fredo, everyone. I am trusting you with the lives of my wife and children, and the future of this family, solely resting on your judgment and talent. ...But Tom, you must know that I do this only because I believe you are the only one who is capable of taking over for me. I've prepared this; have had it for over a month. It won't explain everything; but indicates where I will be, so in a sense, it is my life. Also, there are three tasks that must be executed immediately. Pop would have given those to Luca -- You knew Pop as well as anyone, act as though you were him. It discusses Kay as well; that will be the most difficult. The men who tried to kill me tonight, will never leave the estate.\\nHAGEN: Will we...be able to get who ordered it out of them?\\nMICHAEL: I don't think so. Unless I'm very wrong...they're already dead. Killed by someone inside...very frightened that they botched it. That's why I am going to disappear in a few minutes, and leave everything to you.\\nHAGEN: But if you're wrong...\\n\\n\", 'answer': \"If I'm wrong... ...I don't think I'm wrong. Yes.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MICHAEL'}\n",
      "Last word -> MICHAEL : \"If I'm wrong... ...I don't think I'm wrong. Yes.\"\n",
      "prediction :  Yes,...this is wrong. And the more I think about it, the more I believe that Sonny would have chosen the other...he had planned for this...\n",
      "Real answer : If I'm wrong... ...I don't think I'm wrong. Yes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8409590721130371], 'recall': [0.8719221949577332], 'f1': [0.8561607003211975], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2564102564102564, 'rouge2': 0.0, 'rougeL': 0.20512820512820512, 'rougeLsum': 0.20512820512820512}\n",
      "bleu 1/2 : 0.07999999999999999 0.01825741858350553\n",
      "ppl : 39.58269119262695\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMICHAEL: Do you think they have somebody to back up Cicci?\\n\\n', 'answer': \"No. But if they do have somebody, you'll do three years for perjury if you give them so much as a wrong middle name. Michael, take the Fifth all the way, that way you can't get into trouble.\", 'gold_tag': 'HAGEN is a cautious and knowledgeable character , HAGEN is able to provide advice on legal matters , MICHAEL is involved in legal trouble , MICHAEL is facing an imminent legal situation', 'last_speaker': 'HAGEN'}\n",
      "Last word -> HAGEN : \"No. But if they do have somebody, you'll do three years for perjury if you give them so much as a wrong middle name. Michael, take the Fifth all the way, that way you can't get into trouble.\"\n",
      "prediction :  No, I don't think so. Not with this little army of them.\n",
      "Real answer : No. But if they do have somebody, you'll do three years for perjury if you give them so much as a wrong middle name. Michael, take the Fifth all the way, that way you can't get into trouble.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8348674774169922], 'recall': [0.8200139403343201], 'f1': [0.8273740410804749], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15094339622641512, 'rouge2': 0.0, 'rougeL': 0.07547169811320756, 'rougeLsum': 0.07547169811320756}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 26.35854148864746\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMICHAEL: Al, get me a wet towel. Does Kay know I'm back? Did the boy get something from me for Christmas?\\nHAGEN: I took care of it.\\nMICHAEL: What was it, so I'll know.\\nHAGEN: A little care he can ride in with an electric motor.\\nMICHAEL: Fellas, can you wait outside a minute? Where's my brother?\\nHAGEN: Roth got out on a private boat. He's in a hospital in Miami. Had a stroke but he's recovered okay. Bussetta's dead.\\nMICHAEL: I asked about Fredo?\\nHAGEN: The new government arrested him, held him for a couple of days with a lot of the other casino people, including Roth's brother, Sam. The American Embassy arranged flights for citizens; I'm not sure, but I\\nMICHAEL: I want you to reach Fredo. I know he's scared, but have one of our people reach him. Assure him that there will be no reprisals. Tell him that I know Roth misled him.\\nHAGEN: My information is that Fredo thought it was a kidnapping. Roth assured him nothing would happen to you.\\nMICHAEL: They can come in now.\\nHAGEN: Wait... there's something else.\\nMICHAEL: Alright. Go on, tell me.\\nHAGEN: Kay had a miscarriage; she lost the baby.\\nMICHAEL: Was it a boy or a girl?\\nHAGEN: Mike, at three and a half...\\nMICHAEL: What is it, can't you give me straight answers anymore!\\nHAGEN: It was a boy.\\nMICHAEL: And Kay...she's all right?\\nHAGEN: She took the Senate Investigation worse.\\nMICHAEL: Does she blame it on me? The baby?\\n\\n\", 'answer': \"I don't know.\", 'gold_tag': 'HAGEN is an informed individual', 'last_speaker': 'HAGEN'}\n",
      "Last word -> HAGEN : \"I don't know.\"\n",
      "prediction :  We don't know what it is.\n",
      "Real answer : I don't know.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8936322331428528], 'recall': [0.9351711869239807], 'f1': [0.9139299988746643], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.5454545454545454, 'rouge2': 0.4444444444444444, 'rougeL': 0.5454545454545454, 'rougeLsum': 0.5454545454545454}\n",
      "bleu 1/2 : 0.16666666666666669 0.05773502691896258\n",
      "ppl : 19.21445083618164\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMICHAEL: Christ, Tom; I needed more time with him. I really needed him.\\nHAGEN: Did he give you his politicians?\\nMICHAEL: Not all...I needed another four months and I would have had them all. I guess you've figured it all out?\\nHAGEN: How will they come at you?\\nMICHAEL: I know now. I'll make them call me Don.\\nHAGEN: Have you agreed on a meeting?\\n\\n\", 'answer': \"A week from tonight. In Brooklyn on Tessio's ground, where I'll be safe. But after the Baptism. I've decided to stand as godfather to Connie's baby.\", 'gold_tag': \"MICHAEL has an important meeting lined up a week from the conversation , MICHAEL has a significant role in Connie's baby's baptism as the godfather\", 'last_speaker': 'MICHAEL'}\n",
      "Last word -> MICHAEL : \"A week from tonight. In Brooklyn on Tessio's ground, where I'll be safe. But after the Baptism. I've decided to stand as godfather to Connie's baby.\"\n",
      "prediction :   Tom, can you please sit here on the right? I'll give a call in while you sit right here.\n",
      "Real answer : A week from tonight. In Brooklyn on Tessio's ground, where I'll be safe. But after the Baptism. I've decided to stand as godfather to Connie's baby.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8229873180389404], 'recall': [0.8336078524589539], 'f1': [0.828263521194458], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.24, 'rouge2': 0.041666666666666664, 'rougeL': 0.12, 'rougeLsum': 0.12}\n",
      "bleu 1/2 : 0.10923565662166056 0.020490112560187432\n",
      "ppl : 37.63534927368164\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: They have everything we ordered?\\nPJ: Glocks, Uzis, Tec-9s...\\nSEAN: What the hell is that?\\nPJ: Oh, my hair? Shondra just did it. What? You hate it?\\nSEAN: No. I just think it's a choice my character would have made.\\nPJ: Don't go there, Sean. You're just jealous you didn't think of it first.\\n\\n\", 'answer': 'Whatever.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SEAN'}\n",
      "Last word -> SEAN : \"Whatever.\"\n",
      "prediction :  Are you sure the Glocks are here?\n",
      "Real answer : Whatever.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.820443868637085], 'recall': [0.9302842617034912], 'f1': [0.8719183802604675], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 180.97381591796875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: Okay, got the gangsta wear. What's so funny?\\nPJ: That wig, man! I didn't know this was Halloween. Bring me back some candy!\\n\\n\", 'answer': 'Whatever.', 'gold_tag': 'SEAN possibly indicates a more serious personality', 'last_speaker': 'SEAN'}\n",
      "Last word -> SEAN : \"Whatever.\"\n",
      "prediction :  I was not expecting <i>that</i>.\n",
      "Real answer : Whatever.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.762710452079773], 'recall': [0.9381797909736633], 'f1': [0.8413941264152527], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 44.1241340637207\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPJ: Nope, you're not convincing me. Remember your core character. You're an oppressed black man from\\nSEAN: Yeah, I know, I'm having trouble finding this one. Lemme try it again. Gimme your ride, punk, or I will dust yo ass!\\n\\n\", 'answer': \"Add a 'beeyotch' and I think you're there.\", 'gold_tag': 'PJ plays the role of a coach or guide for acting', 'last_speaker': 'PJ'}\n",
      "Last word -> PJ : \"Add a 'beeyotch' and I think you're there.\"\n",
      "prediction :  What? What the fuck, man. You got your ride or what?\n",
      "Real answer : Add a 'beeyotch' and I think you're there.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8227411508560181], 'recall': [0.8207101821899414], 'f1': [0.8217244148254395], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09999999999999999, 'rouge2': 0.0, 'rougeL': 0.09999999999999999, 'rougeLsum': 0.09999999999999999}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 53.790077209472656\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: What's next?\\nPJ: How about... number three?\\n\\n\", 'answer': \"Yeah, perfect. Let's take it to another level, my man.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SEAN'}\n",
      "Last word -> SEAN : \"Yeah, perfect. Let's take it to another level, my man.\"\n",
      "prediction :  Okay, so... 1. What's in 3...\n",
      "Real answer : Yeah, perfect. Let's take it to another level, my man.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8562705516815186], 'recall': [0.8611749410629272], 'f1': [0.8587157726287842], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 57.728328704833984\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: How much did you have to give this guy, anyway? What are you talking about? When you set this thing up yesterday, what did you pay?\\nPJ: I thought you set it up.\\nSEAN: You mean the owner doesn't know this is all fake?\\nPJ: Oh damn.\\nSEAN: Get in there! He could get shot!\\n\\n\", 'answer': \"I'm not going in there! You go in there!\", 'gold_tag': 'PJ refuses to approach the owner of the establishment', 'last_speaker': 'PJ'}\n",
      "Last word -> PJ : \"I'm not going in there! You go in there!\"\n",
      "prediction :  I know that.\n",
      "Real answer : I'm not going in there! You go in there!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8856886625289917], 'recall': [0.8303235769271851], 'f1': [0.8571130037307739], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 185.90574645996094\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nINSPECTOR: Kafka -- is that your real name?\\nKAFKA: Yes. Yes, of course -- why wouldn't it be?\\nINSPECTOR: When was the last time you saw Mr. Raban?\\nKAFKA: Wednesday. We left the office together.\\nINSPECTOR: Did you go anywhere afterwards -- to have a drink perhaps?\\nKAFKA: No, we said goodbye outside the building. He went off, as usual, toward his house.\\nINSPECTOR: Your office is the Workmen's --\\nKAFKA: -- Accident and Compensation Association.\\nINSPECTOR: Where you've been employed for seven years.\\nKAFKA: Eight -- and seven months.\\nINSPECTOR: Engaged in the manufacture and distribution of ... pills and so forth.\\nKAFKA: Well -- other departments are, yes.\\nINSPECTOR: Would you describe your relationship with the dead man as close?\\nKAFKA: Yes. Since he came to the office, almost three years ago, we've been quite good friends. How was Eduard ...\\nINSPECTOR: He was found in the River. Could he swim?\\nKAFKA: I don't know.\\nINSPECTOR: Was he depressed?\\nKAFKA: No. He didn't seem to be. Do you think he drowned himself?\\nINSPECTOR: Grown men don't normally fall into the river, do they?\\nKAFKA: No, I suppose not.\\nINSPECTOR: He might have had a drink or two, despite what you think.\\nKAFKA: Can I ask -- how you found me?\\nINSPECTOR: His landlady knew of no other friends to refer us to.\\nKAFKA: I don't think he really had any. He had no family either.\\nINSPECTOR: We know that.\\nKAFKA: He wasn't a lonely man, though.\\nINSPECTOR: What makes you think so?\\n\\n\", 'answer': '... Just a perception.', 'gold_tag': 'Everyday Language', 'last_speaker': 'KAFKA'}\n",
      "Last word -> KAFKA : \"... Just a perception.\"\n",
      "prediction : I think he was a little bit nervous about it all, but he had no one. Not many friends, but he had so many letters!\n",
      "Real answer : ... Just a perception.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8457860946655273], 'recall': [0.8709067106246948], 'f1': [0.8581625819206238], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07142857142857142, 'rouge2': 0.0, 'rougeL': 0.07142857142857142, 'rougeLsum': 0.07142857142857142}\n",
      "bleu 1/2 : 0.04000000000000001 0.012909944487358061\n",
      "ppl : 25.201990127563477\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nINSPECTOR: I don't usually involve myself with you people in the Old Quarter -- but the River runs its own course. It won't be the last time it deposits its unwanted debris on my doorstep.\\nKAFKA: Probably not.\\nINSPECTOR: Anyway, I'd like you to reflect that in me you have -- I won't say a friend, because we're complete fencers, of course -- from distinctly incompatible social classes -- but to some extent, shall we say, an interested third party.\\nKAFKA: I'll bear that in mind.\\n\\n\", 'answer': '-- Should you happen upon anything that might be relevant.', 'gold_tag': 'Everyday Language', 'last_speaker': 'INSPECTOR'}\n",
      "Last word -> INSPECTOR : \"-- Should you happen upon anything that might be relevant.\"\n",
      "prediction :  Well, you'll find me on the road to your town the moment I hear there's some new business worth taking advantage of. I'm sure there is.\n",
      "Real answer : -- Should you happen upon anything that might be relevant.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8411655426025391], 'recall': [0.848198652267456], 'f1': [0.8446674346923828], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05263157894736842, 'rouge2': 0.0, 'rougeL': 0.05263157894736842, 'rougeLsum': 0.05263157894736842}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 26.380319595336914\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nINSPECTOR: You said she was extremely upset. People who are extremely upset -- Kafka -- are given to disappearing in a hurry. They go and calm down for a day or so and then they come back.\\nKAFKA: But that's just my point -- she was more than upset, she was livid. She slammed every door on her way downstairs -- except that one. I was just behind her and I didn't even hear that one shut -- not at all.\\nINSPECTOR: That's not what I call conclusive evidence of an abduction.\\n\\n\", 'answer': \"If someone was waiting here in the hallway to spirit her away, wouldn't they have shut the door as quietly\", 'gold_tag': 'KAFKA shows concern over the disappearance of a woman , KAFKA is assertive in expressing his perspective', 'last_speaker': 'KAFKA'}\n",
      "Last word -> KAFKA : \"If someone was waiting here in the hallway to spirit her away, wouldn't they have shut the door as quietly\"\n",
      "prediction :  But how do I explain that without violating the law?\n",
      "Real answer : If someone was waiting here in the hallway to spirit her away, wouldn't they have shut the door as quietly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8619331121444702], 'recall': [0.8333727121353149], 'f1': [0.8474123477935791], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06451612903225806, 'rouge2': 0.0, 'rougeL': 0.06451612903225806, 'rougeLsum': 0.06451612903225806}\n",
      "bleu 1/2 : 0.03678794411714424 0.012262648039048083\n",
      "ppl : 67.69734191894531\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nINSPECTOR: Why would someone want to kidnap this woman -- the name is Rossmann?\\nKAFKA: You told me to contact you if anything relevant came up -- Gabriela is relevant. When I spoke to you before I didn't know she'd been seeing Eduard.\\nINSPECTOR: That's been noted. But where does it lead us? Unless you have something more to add.\\nKAFKA: She's missing. I went to her house and she hadn't returned there.\\n\\n\", 'answer': \"She lost her job today. Just between you and me, I'd probably go away and brood a bit myself.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'INSPECTOR'}\n",
      "Last word -> INSPECTOR : \"She lost her job today. Just between you and me, I'd probably go away and brood a bit myself.\"\n",
      "prediction :  Why didn't she get back from school? Is that possible?\n",
      "Real answer : She lost her job today. Just between you and me, I'd probably go away and brood a bit myself.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.844226598739624], 'recall': [0.8274899125099182], 'f1': [0.8357744812965393], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06451612903225806, 'rouge2': 0.0, 'rougeL': 0.06451612903225806, 'rougeLsum': 0.06451612903225806}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 50.463897705078125\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAFKA: Maybe it's true then what she said.\\nINSPECTOR: What did she say?\\nKAFKA: That the police may have allegiance to something other than truth. -- She didn't think Eduard committed suicide. Any more than I do. She was convinced of it.\\n\\n\", 'answer': \"I'm going to say something, and I hope it's quite clear because I won't be repeating it. We don't have to hunt for criminals. We're drawn towards them. The guilty show us the way.\", 'gold_tag': 'INSPECTOR is likely a law enforcement officer , INSPECTOR has a somewhat cynical view of his job , INSPECTOR indicates that the guilty are drawn to them, rather than the police needing to seek out crime', 'last_speaker': 'INSPECTOR'}\n",
      "Last word -> INSPECTOR : \"I'm going to say something, and I hope it's quite clear because I won't be repeating it. We don't have to hunt for criminals. We're drawn towards them. The guilty show us the way.\"\n",
      "prediction :  What did she say?\n",
      "Real answer : I'm going to say something, and I hope it's quite clear because I won't be repeating it. We don't have to hunt for criminals. We're drawn towards them. The guilty show us the way.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8556667566299438], 'recall': [0.8289023637771606], 'f1': [0.8420719504356384], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.04651162790697674, 'rouge2': 0.0, 'rougeL': 0.04651162790697674, 'rougeLsum': 0.04651162790697674}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 136.3125457763672\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGALE: You broke the lock.\\nDEWEY: You broke my heart.\\nGALE: What are we looking for?\\nDEWEY: A bloody knife. A ghost mask. Something like that?\\nGALE: Can we turn the light on?\\nDEWEY: That's not the way it's done. And it's sexier in the dark.\\nGALE: Dewey, you and I would never make it.\\nDEWEY: Maybe not. But think about the sex. As frustrated as I am...\\nGALE: ... and as lonely as I am...\\nDEWEY: We'd break some furniture.\\nGALE: Tell you what. We get through this one. And we'll take out a hotel room. Over here with the light.\\nDEWEY: They're roomates.\\nGALE: And Joel's pre-med.\\nDEWEY: The sorority girl was gutted with autopsy precision.\\nGALE: Shit! It's both of them. The first murders were to throw us - using the same names as Woodsboro. But they've moved on - they're getting closer to Sidney. They're not looking for a Himbry or a Tatum to kill. They're looking for the new Tatum.\\n\\n\", 'answer': 'Hallie?', 'gold_tag': 'Everyday Language', 'last_speaker': 'DEWEY'}\n",
      "Last word -> DEWEY : \"Hallie?\"\n",
      "prediction :  Now I know that you and I aren't that close, and what you did to my brother, we'll never see eye to eye. But just to be clear. I've spent my whole life looking for the perfect woman. And you, right now, you're that woman.\n",
      "Real answer : Hallie?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7971076965332031], 'recall': [0.7893345355987549], 'f1': [0.7932020425796509], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 10.259525299072266\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGALE: Ssshh! What was that?\\nDEWEY: Let's find out.\\nGALE: This is all too familiar.\\n\\n\", 'answer': 'Over here.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DEWEY'}\n",
      "Last word -> DEWEY : \"Over here.\"\n",
      "prediction :  It had to happen this way, I suppose.\n",
      "Real answer : Over here.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8430286645889282], 'recall': [0.883810818195343], 'f1': [0.8629381656646729], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 37.391780853271484\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDEWEY: Gale! Gale!\\n\\n', 'answer': 'NOOOOOOO!', 'gold_tag': 'Everyday Language', 'last_speaker': 'GALE'}\n",
      "Last word -> GALE : \"NOOOOOOO!\"\n",
      "prediction :  Yes, what is it? I was about to take out the garbage.\n",
      "Real answer : NOOOOOOO!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8322161436080933], 'recall': [0.7869114279747009], 'f1': [0.808929979801178], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 40.287540435791016\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDEWEY: They found another note?\\nGALE: Uh-huh. Another News clipping. Another one about Sid's mom. Dewey, whether we like it or not it looks like we're going to have to go back into our past.\\nDEWEY: You mean OUR past as in Me and Sid. This has nothing to do with you Gale.\\nGALE: This has everything to do with me Dewey. I was the one who brought the nation's attention to this shit anyway. I'll be damned if I'm gonna sit around and pass on the buck again.\\nDEWEY: Do you really mean it this time Gale?\\nGALE: Yes. Look, let's get something straight Dewey, I got into this shit cause the police came looking for ME. Not cause I'm out to make the SUNRISE STUDIOS SLASHINGS.\\nDEWEY: Why would the police come to you?\\nGALE: Again, I am the author of the definitive book on the Woodsboro murders.! What about you?\\nDEWEY: What about me?\\nGALE: You said you'd never leave Woodsboro, 'The only place that's real!' But now you're here. Not with me. Dewey, I took care of you. I waited until you were well. I couldn't stay there, I mean, it's like dog years, one year in Woodsboro is like seven everywhere else.\\nDEWEY: So it's off to London for a week? New York for a month? L.A Forever?\\nGALE: It was fucking '60 Minutes II'! I couldn't say no! I could've been the next Diane Sawyer!\\nDEWEY: What's wrong with just being Gale Weathers? I liked her!\\nGALE: It didn't work Dewey. We tried, we're different.\\nDEWEY: You used to say that was our strength.\\nGALE: Dewey, you're not just here because of that second rate K-Mart, straight-to-video version of me, are you?\\nDEWEY: Brace yourself, Gale, all of this is actually not About you.\\nGALE: All of what Dewey? You do know something, don't you?\\nDEWEY: Off the record.\\nGALE: Always.\\nDEWEY: Two months ago, the Woodsboro police got a call from a woman who said she was with 'Stab 3'. She wanted to see the file on Sid, for research.\\nGALE: And?\\nDEWEY: The boys said no. She wouldn't give her name. A month later, the station gets broken into, the file room ransacked.\\nGALE: Someone stole Sid's file?\\nDEWEY: I already removed it. I think someone on the film was trying to find Sid, and that's the only reason I came here. To make do a little private investigating of my own and make sure no one here was planning anything.\\nGALE: I'm sorry, this is too good!\\nDEWEY: What part of 'Off the record' don't you understand?\\nGALE: Right. Sorry. Do you think he did it?\\nDEWEY: I've got my suspicions but still, nothing you say can ever make me take my eyes off one person.\\nGALE: And who is that?\\nDEWEY: Jennifer needs me.\\nGALE: Jennifer?! Wait, where are you going off to?\\n\\n\", 'answer': \"I'm on duty.\", 'gold_tag': 'DEWEY is committed to his job and is portrayed as someone who is sensitive and cares about others', 'last_speaker': 'DEWEY'}\n",
      "Last word -> DEWEY : \"I'm on duty.\"\n",
      "prediction :  You see this? This is what's called a \"shot list\". It's a detailed accounting of the people involved in the project. This is what they need. To know how many people, and how they look and what kind of camera we need, whether it's a point and shoot or a full film camera.\n",
      "Real answer : I'm on duty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8160693645477295], 'recall': [0.8770214319229126], 'f1': [0.8454482555389404], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.824409484863281\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDEWEY: Sheriff just radioed me. I'm gonna check out a possible lead. Thought you might like to join me.\\nGALE: What kind of lead?\\nDEWEY: A car was spotted in the bushes a little ways up the road.\\nGALE: I'd love to. If you're sure it's alright?\\nDEWEY: Ma'am, I am the Deputy of this town.\\nGALE: Can I bring Kenny?\\nDEWEY: NO! I mean...I should probably take just you.\\n\\n\", 'answer': \"I'll be back.\", 'gold_tag': 'GALE will return after joining DEWEY in checking out his lead', 'last_speaker': 'GALE'}\n",
      "Last word -> GALE : \"I'll be back.\"\n",
      "prediction :  I'm thinking about taking Kenny, your son.\n",
      "Real answer : I'll be back.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8619493246078491], 'recall': [0.8780948519706726], 'f1': [0.8699471950531006], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 121.59587860107422\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGALE: So is Dewey your real name?\\nDEWEY: Dwight. Dewey was something I got stuck with a long time ago.\\nGALE: I like it. It's... sexy.\\nDEWEY: Nah... it's just this town's way of not taking me serious.\\nGALE: What about Gale Weathers? I sound like a meteorologist... People treat me like the Antichrist of television journalism.\\nDEWEY: I don't think you're so bad.\\n\\n\", 'answer': 'Are all the local boys as sweet as you?', 'gold_tag': 'Everyday Language', 'last_speaker': 'GALE'}\n",
      "Last word -> GALE : \"Are all the local boys as sweet as you?\"\n",
      "prediction :  I have no idea what you're doing down there.\n",
      "Real answer : Are all the local boys as sweet as you?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8455454111099243], 'recall': [0.8349599838256836], 'f1': [0.8402193188667297], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473685, 'rouge2': 0.0, 'rougeL': 0.10526315789473685, 'rougeLsum': 0.10526315789473685}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.767040252685547\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDEWEY: You okay?\\nGALE: What's that?\\nDEWEY: Looks like a car. Shit. It's Neil Prescott's car.\\nGALE: Sidney's father?\\n\\n\", 'answer': \"We gotta get back. Jesus. He's here. What the fuck is he doing here?\", 'gold_tag': 'DEWEY potentially works in a field that demands quick response times and analytical skills , GALE might be less experienced in high-stake, tense situations compared to Dewey', 'last_speaker': 'DEWEY'}\n",
      "Last word -> DEWEY : \"We gotta get back. Jesus. He's here. What the fuck is he doing here?\"\n",
      "prediction :  If that's the car, he's dead. Sidney's friends were in there with him.\n",
      "Real answer : We gotta get back. Jesus. He's here. What the fuck is he doing here?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8580892086029053], 'recall': [0.874184250831604], 'f1': [0.8660619854927063], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.19354838709677422, 'rouge2': 0.0689655172413793, 'rougeL': 0.19354838709677422, 'rougeLsum': 0.19354838709677422}\n",
      "bleu 1/2 : 0.07122777528017817 0.023443930918208206\n",
      "ppl : 34.41203308105469\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDEWEY: I'll call for backup.\\n\\n\", 'answer': \"I'll get my camera. Kenny! Camera! Quick! Kenny? Dewey? Dewey? Where are you?\", 'gold_tag': 'GALE shows assertive behavior , GALE is involved in the reporting or media industry , GALE intends to get a camera and gives a directive to Kenny', 'last_speaker': 'GALE'}\n",
      "Last word -> GALE : \"I'll get my camera. Kenny! Camera! Quick! Kenny? Dewey? Dewey? Where are you?\"\n",
      "prediction :  You've GOT to be kidding!\n",
      "Real answer : I'll get my camera. Kenny! Camera! Quick! Kenny? Dewey? Dewey? Where are you?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8036469221115112], 'recall': [0.8097525238990784], 'f1': [0.806688129901886], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1, 'rouge2': 0.0, 'rougeL': 0.1, 'rougeLsum': 0.1}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 28.836828231811523\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHADOW: You could've crispered half your company with that little stunt, but more importantly you wrecked the physical evidence I use to prove it's arson. You've made my day longer, Probie. Go home and think about that.\\nBRIAN: Uh, I'm Brian McCaffrey. Your new assistant.\\nSHADOW: Your Dennis' kid. I work alone. Are you still here?\\nBRIAN: Get used to me, Inspector. I'm not going anywhere.\\nSHADOW: Then go find a corner. I don't want you in my way.\\nBRIAN: I think we should get something straight here. I was assigned to this office by the city.\\nSHADOW: Look, I knew your father, he had a helluva reputation on this job. But that don't mean you get any slack. Swayzak sends you down here, okay, I gotta eat you, that's the rules and I got nothing to say about that. But Swayzak or no, you live with me. Step out of line, and I don't care who knows you, I'll swing the hammer. You think you're the first?\\nBRIAN: Where are you going?\\n\\n\", 'answer': 'Pest control.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SHADOW'}\n",
      "Last word -> SHADOW : \"Pest control.\"\n",
      "prediction :  This is what we do.\n",
      "Real answer : Pest control.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8584979176521301], 'recall': [0.8616971969604492], 'f1': [0.8600946068763733], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 33.696407318115234\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRIAN: \"Trychtichlorate is a binary structured --\"\\nSHADOW: -- Go to the bottom. Under heat properties.\\nBRIAN: \"During heat episodes of 2000 Kelvin or higher, Trych breaks down and dissipates. Will consume magnesium\".\\nSHADOW: Ever burned magnesium? It\\'s so hot Son of a bitch tears \\'em apart just to eat the oxygen. Wouldn\\'t take much at all to melt ten gauge wire. Problem\\'s burnt magnesium leaves a powder trace -- unless you could find something that would eat its residue.\\nBRIAN: Trychticholorate. Then Swayzak can announce Seagrave was a murder.\\nSHADOW: Look, it isn\\'t proof, okay? Someone may have put the chemical in the outlet, but we found it as a vapor\\nBRIAN: And the putty around the door?\\nSHADOW: Even if it was used to seal the air off, that doesn\\'t explain why someone would go to the trouble of a backdraft. A gun\\'s a helluva lot easier\\nBRIAN: But the right guess on this is arson.\\nSHADOW: I don\\'t guess.\\nBRIAN: Some people say you don\\'t do much of anything when it comes to this case.\\n\\n', 'answer': \"I don't work for them, either.\", 'gold_tag': \"SHADOW doesn't appreciate some other people's critique of his work\", 'last_speaker': 'SHADOW'}\n",
      "Last word -> SHADOW : \"I don't work for them, either.\"\n",
      "prediction :  Who else was there at Seagrave's death? Anybody you'd know? How about your crew - maybe there were a few more there. It would be good to get a list of the gang's usual people, if you had one.\n",
      "Real answer : I don't work for them, either.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8254165649414062], 'recall': [0.8633016347885132], 'f1': [0.843934178352356], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.060277938842773\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHADOW: Take the top off. Go ahead. Take it off.\\nBRIAN: Jesus!\\nSHADOW: That's it! Oh, that son of a bitch, he's different, goddamn it! You see what this tells us, huh? Our killer doesn't love fire!\\nBRIAN: What?\\nSHADOW: I got it after we talked to Ronald. Torches. Want to fry the whole goddamn world. But the fires that killed those guys never really burned up much. -- The burns were all lit in outlets surrounded by double firebreaks in the walls. And he made his burns backdrafts.\\nBRIAN: But he killed these guys.\\nSHADOW: But he could have killed everybody there. The firebreaks kept it from spreading in the wall. The backdraft blew out the flame. That's it. That's the reason.\\nBRIAN: What reason?\\nSHADOW: Why backdrafts. Whoever fried Seagrave and Cosgrove went to a helluva lot of trouble to make sure they died by fire, but also made sure the fire blew itself out.\\nBRIAN: That's why the sealant on the doors... So what have we got, a torch with a conscience?\\nSHADOW: No, we have a stone killer trying to make a point.\\nBRIAN: Are you going public with this?\\n\\n\", 'answer': \"No. Do that and I guarantee you'll scare him off. I don't want him running away.\", 'gold_tag': 'SHADOW is responsible for guiding and teaching Brian', 'last_speaker': 'SHADOW'}\n",
      "Last word -> SHADOW : \"No. Do that and I guarantee you'll scare him off. I don't want him running away.\"\n",
      "prediction :  No son. But I've had to think it through for a little bit. Because even he can't explain to me, exactly what he wanted. What do I need to do to make him go quietly? To make him accept that the firebreaks and the backdrafts were necessary, even though it made my family suffer.\n",
      "Real answer : No. Do that and I guarantee you'll scare him off. I don't want him running away.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8364948034286499], 'recall': [0.8703463077545166], 'f1': [0.8530848622322083], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.24324324324324326, 'rouge2': 0.0, 'rougeL': 0.13513513513513514, 'rougeLsum': 0.13513513513513514}\n",
      "bleu 1/2 : 0.09259259259259259 0.013217526428635742\n",
      "ppl : 26.171764373779297\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRIAN: Hey boss, Dekom Trust is owned by Pan Illinois... which is majority controlled by Lakeside Dynamics... which is a division of Windy City Ventures... who's partners are... Alan Seagrave, Donald Cosgrove, and Jeffrey Holcomb.\\n\\n\", 'answer': 'Son of a bitch. They knew each other.', 'gold_tag': 'SHADOW is quick at coming to conclusions', 'last_speaker': 'SHADOW'}\n",
      "Last word -> SHADOW : \"Son of a bitch. They knew each other.\"\n",
      "prediction :  I do not know...\n",
      "Real answer : Son of a bitch. They knew each other.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8004714846611023], 'recall': [0.8157351016998291], 'f1': [0.8080312013626099], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 135.74156188964844\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRIAN: So Seagrave and Holcomb were accountants...\\nSHADOW: And Cosgrove. Coppers figured he laundered money for the mob before getting into real estate. They weren't very high on Seagrave, either.\\nBRIAN: Nice bunch of guys.\\n\\n\", 'answer': \"Who all ended up wearing candles for faces... Swayzak's up to his ass in this We need to get a look at his files.\", 'gold_tag': \"SHADOW implies a need to immediately investigate Swayzak's files\", 'last_speaker': 'SHADOW'}\n",
      "Last word -> SHADOW : \"Who all ended up wearing candles for faces... Swayzak's up to his ass in this We need to get a look at his files.\"\n",
      "prediction :  Seagrave & Co. ran a tight ship.\n",
      "Real answer : Who all ended up wearing candles for faces... Swayzak's up to his ass in this We need to get a look at his files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8258861303329468], 'recall': [0.8202919363975525], 'f1': [0.823079526424408], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06451612903225806, 'rouge2': 0.0, 'rougeL': 0.06451612903225806, 'rougeLsum': 0.06451612903225806}\n",
      "bleu 1/2 : 0.012594669908908207 0.004301898749003176\n",
      "ppl : 133.40501403808594\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHADOW: Well Brian, I guess you can say it's arson now...\\nBRIAN: How ya feeling? Did you pull me out?\\nSHADOW: Yeah.\\nBRIAN: Did I say thanks?\\nSHADOW: No.\\nBRIAN: Just wondering.\\nSHADOW: I hate hospitals. You're so... so goddamn useless...\\nBRIAN: So what do you want me to do?\\n\\n\", 'answer': \"I've been lying here hours... just thinking... We're close... We're not looking in the right place, Brian. This one knows us and we're not looking in the right place...\", 'gold_tag': 'Shadow has been lying and thinking for hours, indicating dedication to solving their case , Shadow shows signs of perseverance and resolve', 'last_speaker': 'SHADOW'}\n",
      "Last word -> SHADOW : \"I've been lying here hours... just thinking... We're close... We're not looking in the right place, Brian. This one knows us and we're not looking in the right place...\"\n",
      "prediction :  I heard your brother is a lawyer. Can you get him to talk to you?\n",
      "Real answer : I've been lying here hours... just thinking... We're close... We're not looking in the right place, Brian. This one knows us and we're not looking in the right place...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8762414455413818], 'recall': [0.8433027267456055], 'f1': [0.8594565987586975], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.041666666666666664, 'rouge2': 0.0, 'rougeL': 0.041666666666666664, 'rougeLsum': 0.041666666666666664}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 25.237382888793945\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHADOW: Your brother was a good man.\\nBRIAN: Yeah.\\nSHADOW: Another couple of good men get burned up for their city? Is that how it's going to read? You're the only one that knows.\\nBRIAN: Like it never happened...\\n\\n\", 'answer': 'Want to help me with something?', 'gold_tag': \"SHADOW is in a position to seek BRIAN's help\", 'last_speaker': 'SHADOW'}\n",
      "Last word -> SHADOW : \"Want to help me with something?\"\n",
      "prediction :  Look at those old soldiers. What were you thinking?\n",
      "Real answer : Want to help me with something?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8324520587921143], 'recall': [0.8228148221969604], 'f1': [0.8276053667068481], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 89.67752075195312\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWEBSTER: All I want is the money, Benedict. Just give me what's mine and you can go back to stealing cars and screwing your best friend's wife. Pack it in, Vince, you're only wasting time -- I don't give a damn about you, just the money -- He's reloaded during this -- moving forward as we... Vince, if you don't cut this horseshit I may have to hurt you.\\n\\n\", 'answer': 'Leave my brother alone!', 'gold_tag': 'JULIUS is protective , JULIUS is protective of his brother', 'last_speaker': 'JULIUS'}\n",
      "Last word -> JULIUS : \"Leave my brother alone!\"\n",
      "prediction :  Don't worry, you won't have to.\n",
      "Real answer : Leave my brother alone!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8471094369888306], 'recall': [0.8590595126152039], 'f1': [0.8530426025390625], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13.384500503540039\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWEBSTER: Just exactly who are you?\\nJULIUS: Vincent's twin brother -- we're in this together.\\nWEBSTER: Keep your hands that way.\\n\\n\", 'answer': \"Don't be nervous -- I hate violence and I never carry guns.\", 'gold_tag': 'JULIUS dislikes violence , JULIUS never carries guns', 'last_speaker': 'JULIUS'}\n",
      "Last word -> JULIUS : \"Don't be nervous -- I hate violence and I never carry guns.\"\n",
      "prediction :  I need this money for some medical research I've been doing with--\n",
      "Real answer : Don't be nervous -- I hate violence and I never carry guns.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8476439118385315], 'recall': [0.8525525331497192], 'f1': [0.8500910997390747], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16, 'rouge2': 0.0, 'rougeL': 0.16, 'rougeLsum': 0.16}\n",
      "bleu 1/2 : 0.08333333333333333 0.027524094128159027\n",
      "ppl : 82.11492156982422\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWEBSTER: 'Shakespeare's Collected Works'?... 'The Mind of Confucius'?... 'Advanced Quantum Mechanics'?... What is this shit?\\nJULIUS: I needed something to read on the airplane.\\n\\n\", 'answer': 'Yeah, well your flying days are over...', 'gold_tag': 'WEBSTER implies that JULIUS will not be flying anymore in the foreseeable future', 'last_speaker': 'WEBSTER'}\n",
      "Last word -> WEBSTER : \"Yeah, well your flying days are over...\"\n",
      "prediction :  I have a copy of Shakespeare's Collected Works. But I was hoping to find something by Confucius, or maybe advanced quantum mechanics.\n",
      "Real answer : Yeah, well your flying days are over...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8201748132705688], 'recall': [0.8356374502182007], 'f1': [0.827833890914917], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 46.10697937011719\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKICHIJIRO: After I saw you and Padre Garupe for the first time...I thought...I started to believe...that God might take me back. Because in...in my dreams, the fire was no longer so bright.\\nRODRIGUES: Jesus said, \"Every one therefore that shall confess me before men, I will also confess him before my Father who is in heaven. But he that shall deny me before men, I will also deny him before my Father who is in heaven.\" Do you want me to hear your confession now?\\n\\n', 'answer': 'Bless me, Father, for I have sinned.', 'gold_tag': 'Everyday Language', 'last_speaker': 'KICHIJIRO'}\n",
      "Last word -> KICHIJIRO : \"Bless me, Father, for I have sinned.\"\n",
      "prediction :  My soul is restless. Every night I pray to God for salvation. But my soul grows so tired that I think I must go to...where souls are saved. I want to be there. There seems to be no place like that.\n",
      "Real answer : Bless me, Father, for I have sinned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8328120112419128], 'recall': [0.8573468327522278], 'f1': [0.8449013829231262], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08163265306122448, 'rouge2': 0.0, 'rougeL': 0.08163265306122448, 'rougeLsum': 0.08163265306122448}\n",
      "bleu 1/2 : 0.048780487804878044 0.011043152607484655\n",
      "ppl : 19.52991485595703\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKICHIJIRO: Why did you come here, Padre? This place is dangerous. Where are you going?\\nRODRIGUES: Nowhere.\\nKICHIJIRO: We must be careful. There’s a price of three hundred pieces of silver for you.\\nRODRIGUES: Three hundred...Judas got only thirty.\\n\\n', 'answer': 'There are Kirishitans in other places. Not far. We can hide there. I will take care of you. Rodrigues says nothing.', 'gold_tag': \"KICHIJIRO is aware of local happenings , KICHIJIRO's association with Padre RODRIGUES\", 'last_speaker': 'KICHIJIRO'}\n",
      "Last word -> KICHIJIRO : \"There are Kirishitans in other places. Not far. We can hide there. I will take care of you. Rodrigues says nothing.\"\n",
      "prediction :  Where is the rest of the money?\n",
      "Real answer : There are Kirishitans in other places. Not far. We can hide there. I will take care of you. Rodrigues says nothing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8618282675743103], 'recall': [0.8543314933776855], 'f1': [0.8580635190010071], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07142857142857142, 'rouge2': 0.0, 'rougeL': 0.07142857142857142, 'rougeLsum': 0.07142857142857142}\n",
      "bleu 1/2 : 0.01933361189094467 0.006603685639156038\n",
      "ppl : 44.558311462402344\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKICHIJIRO: We won't reach the village today if we can not walk faster. Are you all right, Padre? You seem tired.\\nRODRIGUES: Just...no, I'm all right. Just so thirsty. The fish was so salty.\\nKICHIJIRO: I will find you some water. Keep walking.\\nRODRIGUES: No, that's all right, I...I thirst.\\nKICHIJIRO: Our Lord said that.\\nRODRIGUES: Yes. I mean...I ate so much of that fish. You made me.\\nKICHIJIRO: For strength.\\nRODRIGUES: Lord, hear me. My foot is on the path, but I don't know where it leads. Please, Lord, lead me. Give me Your hand...\\n\\n\", 'answer': 'I am sorry, Padre. I thought something was wrong. But never mind. There is a stream just nearby. You can drink as much as you like.', 'gold_tag': 'KICHIJIRO is attentive and caring', 'last_speaker': 'KICHIJIRO'}\n",
      "Last word -> KICHIJIRO : \"I am sorry, Padre. I thought something was wrong. But never mind. There is a stream just nearby. You can drink as much as you like.\"\n",
      "prediction :  No, Padre. We won't reach the village today if we can't walk faster.\n",
      "Real answer : I am sorry, Padre. I thought something was wrong. But never mind. There is a stream just nearby. You can drink as much as you like.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8873302340507507], 'recall': [0.8707884550094604], 'f1': [0.8789815902709961], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0975609756097561, 'rouge2': 0.0, 'rougeL': 0.0975609756097561, 'rougeLsum': 0.0975609756097561}\n",
      "bleu 1/2 : 0.028298418551649412 0.009314149810376485\n",
      "ppl : 52.343502044677734\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLARICE: Good afternoon... I wonder if you could help me. I'm looking for Mrs. Lippman's family?\\n\\n\", 'answer': \"They don't live here anymore.\", 'gold_tag': \"Mr. Gumb has knowledge about Mrs. Lippman's family's current residence status , This suggests a familiarity with them or their former residence\", 'last_speaker': 'MR. GUMB'}\n",
      "Last word -> MR. GUMB : \"They don't live here anymore.\"\n",
      "prediction :  Yes, she's in the hospital. (Mr. Gumb's phone rings) Can I take that?\n",
      "Real answer : They don't live here anymore.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8368517160415649], 'recall': [0.8570733070373535], 'f1': [0.8468418121337891], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 28.5687313079834\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLARICE: Excuse me, but I really do need to talk to you. This was Mrs. Lippman's house. Did you know her?\\n\\n\", 'answer': \"Just briefly. What's the problem, Officer?\", 'gold_tag': 'MR. GUMB had some interaction with Mrs. Lippman , CLARICE is a law enforcement officer, identified as \"Officer\" by MR. GUMB', 'last_speaker': 'MR. GUMB'}\n",
      "Last word -> MR. GUMB : \"Just briefly. What's the problem, Officer?\"\n",
      "prediction :  I don't think so. I can't.\n",
      "Real answer : Just briefly. What's the problem, Officer?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8530697226524353], 'recall': [0.862901508808136], 'f1': [0.8579574823379517], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.351611137390137\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLARICE: I'm investigating the death of Fredrica Bimmel. Who are you, please? Mr. Gordon, did you know Fredrica when she worked for Mrs. Lippman?\\n\\n\", 'answer': \"No. Wait... Was she a great, fat person? I may have seen her, I'm not sure...\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MR. GUMB'}\n",
      "Last word -> MR. GUMB : \"No. Wait... Was she a great, fat person? I may have seen her, I'm not sure...\"\n",
      "prediction :  Mrs. Lippman has been dead for four years. I did know Fredrica Bimmel when Fredrica worked for my wife. But I got the information to me through old newspapers, because I knew Fredrica from when we were both at college. But that's another story.\n",
      "Real answer : No. Wait... Was she a great, fat person? I may have seen her, I'm not sure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8309916257858276], 'recall': [0.8356863856315613], 'f1': [0.8333324790000916], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06451612903225806, 'rouge2': 0.0, 'rougeL': 0.06451612903225806, 'rougeLsum': 0.06451612903225806}\n",
      "bleu 1/2 : 0.02272727272727273 0.007270084086278819\n",
      "ppl : 39.8862190246582\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMR. GUMB: Mrs. Lippman had a son, maybe he could help you. I have his card somewhere. Do you mind stepping inside, while I looks for it?\\n\\n', 'answer': 'Thanks.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CLARICE'}\n",
      "Last word -> CLARICE : \"Thanks.\"\n",
      "prediction :  I have to see her.\n",
      "Real answer : Thanks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8749743103981018], 'recall': [0.9469174146652222], 'f1': [0.9095253944396973], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 94.07807922363281\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOLLY (v.o.): We had our bad moments, like any couple. Kit accused me of only being along for the ride,while at times I wished he'd fall in the river and drown, so I could watch.\\nKIT: Take a break. Red... Life of Riley, huh?\\n\\n\", 'answer': 'Mostly. though. we got along fine and stayed in love.', 'gold_tag': 'HOLLY v.o. stays in love , Shared memories between HOLLY v.o. and KIT', 'last_speaker': 'HOLLY (v.o.)'}\n",
      "Last word -> HOLLY (v.o.) : \"Mostly. though. we got along fine and stayed in love.\"\n",
      "prediction :  You never liked the term 'victim' much. Even when you wanted to apologize to me, you said you'd taken a leaf from the book of 'victim' in order to justify your actions. You said you were your own victim .\n",
      "Real answer : Mostly. though. we got along fine and stayed in love.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8244374394416809], 'recall': [0.8736714124679565], 'f1': [0.8483406901359558], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.04000000000000001, 'rouge2': 0.0, 'rougeL': 0.04000000000000001, 'rougeLsum': 0.04000000000000001}\n",
      "bleu 1/2 : 0.025 0.008006407690254359\n",
      "ppl : 17.61054039001465\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOLLY (v.o.): For days afterward I lived in dread. At times I wished I could fall asleep and be taken off to some magical land, but this never happened.\\n\\n', 'answer': 'Holly!', 'gold_tag': 'Everyday Language', 'last_speaker': 'KIT'}\n",
      "Last word -> KIT : \"Holly!\"\n",
      "prediction :  So when did you finally meet and fall in love with your wife?\n",
      "Real answer : Holly!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8151286244392395], 'recall': [0.8273200392723083], 'f1': [0.8211790919303894], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.35802459716797\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOLLY (v.o.): We needed supplies, so we went to a rich man's house. Kit figured it'd be safer and quicker than shopping in the downtown... A maid came to the door.\\nKIT: Hi, I come to check the meter. My tools are in here. Oh, this Is Holly. She's from Texas.\\nHOLLY (v.o.): Later we found out she was deaf and we hadn't even known it.\\n\\n\", 'answer': 'Excuse me.', 'gold_tag': 'Everyday Language', 'last_speaker': 'KIT'}\n",
      "Last word -> KIT : \"Excuse me.\"\n",
      "prediction :  The first person who showed an authentic smile was Kit. I am so happy to meet you! You look very nice! Are you a maid? My name is Holly . I am from Texas. It's okay if I check your meter? You said you might charge me $0.60.\n",
      "Real answer : Excuse me.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8094543218612671], 'recall': [0.833245575428009], 'f1': [0.8211776614189148], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.039215686274509796, 'rouge2': 0.0, 'rougeL': 0.039215686274509796, 'rougeLsum': 0.039215686274509796}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 28.4049072265625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: You want to try that handgun against this rifle, go ahead.\\n\\n', 'answer': 'Some day you might have to face me without a gun.', 'gold_tag': 'CORBETT believes he could potentially best ERIC in a face-to-face confrontation , The confrontation would be without firearms', 'last_speaker': 'CORBETT'}\n",
      "Last word -> CORBETT : \"Some day you might have to face me without a gun.\"\n",
      "prediction :  I can't do nothing about the man on the truck.\n",
      "Real answer : Some day you might have to face me without a gun.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8675568103790283], 'recall': [0.8708289861679077], 'f1': [0.8691898584365845], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 42.340484619140625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: How the hell were they smart enough to find us?\\nCORBETT: Smart? Sure. That's why I'm sitting in this plane and they're down there blowing me kisses. Been driving long?\\nERIC: I needed a pilot's license to take the job here, so I got one in six weeks.\\nCORBETT: That makes the flight more interesting. See the blood? Pack of wolves took down a moose. Greedy, gut-ripping sons of bitches. I'd kill the last wolf on earth, right in front of the President of the U.S. Stinking, cowardly predator, the wolf.\\nERIC: Sounds like professional jealousy.\\n\\n\", 'answer': \"Hunting and trapping was a damn fine life. Me and Mitchell, Bob and LeMalle, we were teams. I'd always go with Mitchell. Good man, Mitchell. I'd let Bob worry about goddamn LeMalle. We'd hire a plane in October. On the way to a dirt airstrip somewhere, we'd drop supplies. We'd land, tell the pilot to come back for us a few days before Christmas.\", 'gold_tag': 'CORBETT has a background in hunting and trapping , CORBETT worked in teams with individuals named Mitchell, Bob, and LeMalle', 'last_speaker': 'CORBETT'}\n",
      "Last word -> CORBETT : \"Hunting and trapping was a damn fine life. Me and Mitchell, Bob and LeMalle, we were teams. I'd always go with Mitchell. Good man, Mitchell. I'd let Bob worry about goddamn LeMalle. We'd hire a plane in October. On the way to a dirt airstrip somewhere, we'd drop supplies. We'd land, tell the pilot to come back for us a few days before Christmas.\"\n",
      "prediction :  And a good pilot will know when to cut corners. But that's something a government spy wouldn't know. Let's call in some backup.\n",
      "Real answer : Hunting and trapping was a damn fine life. Me and Mitchell, Bob and LeMalle, we were teams. I'd always go with Mitchell. Good man, Mitchell. I'd let Bob worry about goddamn LeMalle. We'd hire a plane in October. On the way to a dirt airstrip somewhere, we'd drop supplies. We'd land, tell the pilot to come back for us a few days before Christmas.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8354159593582153], 'recall': [0.8139841556549072], 'f1': [0.8245607614517212], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16842105263157894, 'rouge2': 0.0, 'rougeL': 0.12631578947368421, 'rougeLsum': 0.12631578947368421}\n",
      "bleu 1/2 : 0.03656495543138742 0.005287283819873442\n",
      "ppl : 34.39166259765625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: Stay put!\\nCORBETT: You got the belly to look me in the eye and pull the trigger?\\nERIC: Be no different than shooting a rabid dog. Next time you want to kill yourself, don't include me.\\nCORBETT: I took the odds on getting down in one piece, and I made it. Now we're in my territory.\\nERIC: With light clothing and no supplies, this is nobody's territory.\\nCORBETT: You sound like the tourists. Know-it-alls who read about survival in a magazine. Fuck you. You won't make it off this mountain.\\nERIC: Let's go.\\nCORBETT: I'm not gonna carry you out of here.\\nERIC: That's right. You're not.\\nCORBETT: Look, take these cuffs off. We need to work together.\\n\\n\", 'answer': \"Forget it. Last time I checked the flight plan, we were forty miles northeast of Devil's Cauldron. Southwest is that way. No sense waiting for a goddamn taxi.\", 'gold_tag': 'ERIC referenced a \"flight plan\" , ERIC mentions their current location and direction', 'last_speaker': 'ERIC'}\n",
      "Last word -> ERIC : \"Forget it. Last time I checked the flight plan, we were forty miles northeast of Devil's Cauldron. Southwest is that way. No sense waiting for a goddamn taxi.\"\n",
      "prediction :  Stay close. Stay together.\n",
      "Real answer : Forget it. Last time I checked the flight plan, we were forty miles northeast of Devil's Cauldron. Southwest is that way. No sense waiting for a goddamn taxi.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8964131474494934], 'recall': [0.8258377909660339], 'f1': [0.8596794009208679], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 183.27244567871094\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: It'll be interesting, trying to build a fire without any wood.\\nCORBETT: Welcome to the environment, Mr. Ecology. Out here, one mistake is all you get. Why in hell you care enough about me to die taking me in?\\n\\n\", 'answer': \"I don't plan on dying.\", 'gold_tag': 'ERIC is determined and confident', 'last_speaker': 'ERIC'}\n",
      "Last word -> ERIC : \"I don't plan on dying.\"\n",
      "prediction :  I'm from the Environment Commission. We're building a massive wind farm in the forest. That's gonna be a lot of birds. What happens to them?\n",
      "Real answer : I don't plan on dying.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.837255597114563], 'recall': [0.8596464395523071], 'f1': [0.8483032584190369], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.058823529411764705, 'rouge2': 0.0, 'rougeL': 0.058823529411764705, 'rougeLsum': 0.058823529411764705}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 19.956518173217773\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: We'll stop here, dig out a snow shelter.\\n\\n\", 'answer': \"Snow shelter. Okay. You dig. I'll have a little sit-down. Even in the drifts, this snow's too powdery to make a shelter. When you're done jerking around, reach down the back of my coat.\", 'gold_tag': 'CORBETT is tired and possibly older or less physically fit than ERIC , CORBETT requested to sit while ERIC digs , CORBETT is knowledgeable about snow shelters , CORBETT pointed out that the snow is too powdery to build one', 'last_speaker': 'CORBETT'}\n",
      "Last word -> CORBETT : \"Snow shelter. Okay. You dig. I'll have a little sit-down. Even in the drifts, this snow's too powdery to make a shelter. When you're done jerking around, reach down the back of my coat.\"\n",
      "prediction :  You don't want to camp inside a shelter, because you will have less space with the snow in it. It gets pretty much packed in there.\n",
      "Real answer : Snow shelter. Okay. You dig. I'll have a little sit-down. Even in the drifts, this snow's too powdery to make a shelter. When you're done jerking around, reach down the back of my coat.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8585262298583984], 'recall': [0.847027063369751], 'f1': [0.8527379035949707], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2769230769230769, 'rouge2': 0.031746031746031744, 'rougeL': 0.18461538461538463, 'rougeLsum': 0.18461538461538463}\n",
      "bleu 1/2 : 0.16964803398269643 0.022335201533141166\n",
      "ppl : 31.2751522064209\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORBETT: Still quite a hike to Devil's Cauldron. Days. A long stretch to go without sleep, my friend. You can hide behind that pistol for now, but take your eyes off me long enough to sneeze --\\n\\n\", 'answer': '-- Turn around.', 'gold_tag': 'ERIC commands CORBETT to turn around', 'last_speaker': 'ERIC'}\n",
      "Last word -> ERIC : \"-- Turn around.\"\n",
      "prediction :  Just give me the damn thing.\n",
      "Real answer : -- Turn around.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8510054349899292], 'recall': [0.8706150650978088], 'f1': [0.8606985211372375], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 97.94441986083984\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: We're not sitting here 'til November. There's a cargo plane coming to Devil's Cauldron in four days, and I'm putting you on it.\\nCORBETT: We get wet, we freeze to death in a couple hours.\\nERIC: I've been on ice like this when I was a kid, skating. Spread your weight, keep moving. Go on.\\nCORBETT: Be my guest.\\nERIC: I'm right behind you.\\nCORBETT: Wait 'til I'm across! Most dangerous thing in the world: A regular Joe, in over his head. You trying to prove how tough you are for me, or for yourself?\\nERIC: It wasn't my idea to crash the plane.\\nCORBETT: Let's camp. There's grayling under this ice. I'll snare some for dinner.\\nERIC: We've got another two hours of daylight.\\n\\n\", 'answer': 'Pushing it is flat wrong. All you prove is your ignorance about breaking trail.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CORBETT'}\n",
      "Last word -> CORBETT : \"Pushing it is flat wrong. All you prove is your ignorance about breaking trail.\"\n",
      "prediction :  You look for something to kill, and die.\n",
      "Real answer : Pushing it is flat wrong. All you prove is your ignorance about breaking trail.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8465545177459717], 'recall': [0.8379065990447998], 'f1': [0.8422083258628845], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09090909090909091, 'rouge2': 0.0, 'rougeL': 0.09090909090909091, 'rougeLsum': 0.09090909090909091}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 109.49052429199219\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORBETT: Have to backtrack, find another way down.\\nERIC: Forget it. It would take days.\\n\\n', 'answer': 'Going to be a bit of a challenge with handcuffs on.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CORBETT'}\n",
      "Last word -> CORBETT : \"Going to be a bit of a challenge with handcuffs on.\"\n",
      "prediction :  You’ve got time.\n",
      "Real answer : Going to be a bit of a challenge with handcuffs on.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8666850328445435], 'recall': [0.855934739112854], 'f1': [0.8612763285636902], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 92.29166412353516\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: Too bad we're heading west.\\nCORBETT: There's a snowmobile. Inside a day we could be on the Yukon. I got money there. Remember that five thousand? Make it ten. Be smart. Take it and walk away.\\nERIC: You don't get it, do you? Stop!\\nCORBETT: Nothing personal. Just wanted to see what you'd do. Have to get these wet things off.\\nERIC: You're not going to slow us down! Keep moving!\\n\\n\", 'answer': \"Inside of three hours you'd be dragging my dead carcass.\", 'gold_tag': 'CORBETT predicts that in less than three hours, he could slow them down to the point of death due to his wet clothes', 'last_speaker': 'CORBETT'}\n",
      "Last word -> CORBETT : \"Inside of three hours you'd be dragging my dead carcass.\"\n",
      "prediction :  Why are we going back? You've got all ten thousand?\n",
      "Real answer : Inside of three hours you'd be dragging my dead carcass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8292450904846191], 'recall': [0.8386026620864868], 'f1': [0.8338976502418518], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09090909090909091, 'rouge2': 0.0, 'rougeL': 0.09090909090909091, 'rougeLsum': 0.09090909090909091}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 145.13453674316406\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: Stay awake! You want to go\\nCORBETT: If that means freeze my balls off, no thanks. I'll be okay. Told you I'm fine!\\nERIC: How many do you see?\\nCORBETT: What?! Fuck off. Save yourself.\\nERIC: You don't feel cold?\\nCORBETT: It's a spring day...\\nERIC: Wake up, goddammit! You've got classic hypothermia -- crankiness, fatigue, can't feel your coldness. Worst thing you can do is fade out. One more thing -- this doesn't mean we're going steady. Stay still.\\nCORBETT: Where's my ELT?\\nERIC: Emergency transmitter? All your gear is back at Wilder's.\\nCORBETT: You got one?\\nERIC: It was blown up with the plane.\\nCORBETT: Too bad. We'd be out of here in a few hours.\\nERIC: How? Nobody this far north monitors that frequency until avalanche season. Besides, I'm surprised a tough guy like you uses fancy electronics.\\nCORBETT: I'm surprised a flat-ender like you knows cold-weather remedies.\\nERIC: Read a lot of adventure stories when I was a kid...\\nCORBETT: I'm hungry. Go kill me some dinner.\\nERIC: An appetite. Maybe you won't die after all.\\n\\n\", 'answer': 'Hate to disappoint you.', 'gold_tag': 'CORBETT has a tough, resilient personality and a resistant attitude towards authority', 'last_speaker': 'CORBETT'}\n",
      "Last word -> CORBETT : \"Hate to disappoint you.\"\n",
      "prediction :  Do you want to go to the airport?\n",
      "Real answer : Hate to disappoint you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.848825216293335], 'recall': [0.8633012175559998], 'f1': [0.8560019731521606], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.12500000000000003 0.04225771273642583\n",
      "ppl : 24.691381454467773\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORBETT: Talk to that good-looking girl of yours?\\nERIC: You broke the radio, remember?\\nCORBETT: I'm sure she's fine. Seemed like a clever kid. You were real resourceful out there. Got me thinking of this perimeter man, froze all his fingers one winter. So he hacked the tips off and sharpened the exposed bones. Gets along better than ever. Yeah, maybe I underestimated you.\\nERIC: I liked you better frozen. You didn't talk so much.\\nCORBETT: You're damn lucky, glimpsing this country before it's ruined, gone for good. You saw wonders you'd only dreamed of. That alone makes you different than the sorry bastards back where you came from, because you have dreamt them. Remember that demon in the gut? Sometimes it's nothing more than wondering if the so-called civilized life has bred the balls and brains out of you. That's what you want out of this, isn't it?\\n\\n\", 'answer': 'All I want want is you in jail --', 'gold_tag': 'ERIC is focused on getting Corbett into jail', 'last_speaker': 'ERIC'}\n",
      "Last word -> ERIC : \"All I want want is you in jail --\"\n",
      "prediction :  The whole country is being put back to how it was.\n",
      "Real answer : All I want want is you in jail --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8337451815605164], 'recall': [0.8284395337104797], 'f1': [0.8310838341712952], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473685, 'rouge2': 0.0, 'rougeL': 0.10526315789473685, 'rougeLsum': 0.10526315789473685}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 60.28529739379883\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORBETT: Could've told you no one would help... Maybe you can talk sense into your boyfriend.\\nERIC: Shut up!\\nCORBETT: Either way, you better clear out. I don't want anyone innocent getting harmed.\\n\\n\", 'answer': \"We're moving. Let's go.\", 'gold_tag': \"ERIC had an immediate response to CORBETT's comment\", 'last_speaker': 'ERIC'}\n",
      "Last word -> ERIC : \"We're moving. Let's go.\"\n",
      "prediction :  Are you sure about that? There are 16-year-olds over here.\n",
      "Real answer : We're moving. Let's go.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8358867764472961], 'recall': [0.8851723670959473], 'f1': [0.8598238825798035], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.270755767822266\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORBETT: They know I'm here. I don't say something, they'll plow this town under. You willing to accept that responsibility?\\nERIC: Say you're okay. Tell them I'll kill you if they rush us.\\n\\n\", 'answer': 'Bob?', 'gold_tag': 'Everyday Language', 'last_speaker': 'CORBETT'}\n",
      "Last word -> CORBETT : \"Bob?\"\n",
      "prediction :  I know what you're doing. You want to kill every man in town. It's exactly what they told me. This is a test. Will that do?\n",
      "Real answer : Bob?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8078157901763916], 'recall': [0.857059895992279], 'f1': [0.8317095041275024], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18.800853729248047\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: How come you didn't let him shoot me?\\nCORBETT: Like I said, I'd still be up on that mountain, frozen solid, it wasn't for you.\\nERIC: We'll get you to a hospital, soon as we get to Fairbanks.\\nCORBETT: So they can patch me up and put me in a cage? Forget it. Meyerling's right -- I'm a dinosaur. Greedy bastards like him, it's their turn with this land. Put me in the woods, let me live or die on my own. Look down there, tell me what any of this matters. Struggles of men get swallowed by the bigness. Soon there won't be a trace of our troubles... or us.\\n\\n\", 'answer': \"You're wrong. Everything we do leaves its mark. You said it yourself -- there are hundred- year-old footprints in the tundra.\", 'gold_tag': 'ERIC has a more optimistic outlook compared to CORBETT, believing that everything leaves its mark', 'last_speaker': 'ERIC'}\n",
      "Last word -> ERIC : \"You're wrong. Everything we do leaves its mark. You said it yourself -- there are hundred- year-old footprints in the tundra.\"\n",
      "prediction :  But your friend was here to save you.\n",
      "Real answer : You're wrong. Everything we do leaves its mark. You said it yourself -- there are hundred- year-old footprints in the tundra.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8538553714752197], 'recall': [0.8397559523582458], 'f1': [0.8467469215393066], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06666666666666667, 'rouge2': 0.0, 'rougeL': 0.06666666666666667, 'rougeLsum': 0.06666666666666667}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 127.19056701660156\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMITCHELL: Accident Investigation. Detective Mitchell.\\nLISA: Hi, my name-is Lisa Cohen. I was a witness in a bus accident case a few weeks ago...\\nMITCHELL: Yeah, hi, Lisa, what can I do for you?\\nLISA: Well, this is probably gonna sound a little weird, but are you allowed to tell me how to get in touch with that woman's family? I'm obviously probably too late to go to the funeral, but I really wanted to send some flowers or something.\\nMITCHELL: Yeah, I can --\\nLISA: Or is that like classified information?\\nMITCHELL: No no. Family's been notified...Lemme see what I got.\\nLISA: She mentioned she had a daughter...\\nMITCHELL: Lemme just... OK: I don't have anything for a daughter. The only contact I have is a cousin, Abigail Berwitz. I got a number in Arizona...\\nLISA: So did you have the trial, or whatever? Or did you make the -- did they have a ruling yet?\\nMITCHELL: Yes. It was, uh, No Criminality found. OK?\\nLISA: No Criminality.\\nMITCHELL: Right.\\nLISA: Wow. That's a -- great system you got. OK. Wow.\\nMITCHELL: OK?\\n\\n\", 'answer': 'Yeah.', 'gold_tag': 'Everyday Language', 'last_speaker': 'LISA'}\n",
      "Last word -> LISA : \"Yeah.\"\n",
      "prediction :  I think these things are real. They have purpose. And they work for something. And as long as they're doing that, then all is right with the world...And that's why, you know, I don't think I can ever be a robot. That's like not a person. I mean they're so-- they're really alive, you know?\n",
      "Real answer : Yeah.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7948750257492065], 'recall': [0.9158496260643005], 'f1': [0.8510849475860596], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.501646041870117\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMITCHELL: So now you're sayin' he ran the light.\\nLISA: Yes. He wasn't even looking at the road. And I was definitely trying to get his attention...\\nMITCHELL: No, I get the picture. So you're flirtin' with this guy, he's wavin' at you, he runs the light, hits the decedent, she dies on the scene...the both of youse lie to me on both of your statements, and then somewheres in there you turn around, decide the guy belongs in jail. That right? That about right?\\nLISA: I don't have any control over if he goes to jail or not. I certainly have my hopes. I just want to set the record straight, so that if he gets away with this I won't have been a part of it.\\nMITCHELL: And what do you think I should do with you? Just gimme•a clue. 'cause I'm just a little bit lost over here...:\\nLISA: Do whatever you want. I know what I did.\\nMITCHELL: OK. Well. Before we do anything, Lisa, anybody will tell you that just because he ran a red light is not a criminal offence.\\nLISA: Even if he kills someone?\\nMITCHELL: Even if you cause an accidental death, that's right. For this to be a criminal offense, the law says you need two aggravating circumstances. Like he ran a red light and he was speeding. Or he ran a red light and he was --\\nLISA: So he's not liable to be prosecuted for manslaughter? Or second degree murder?\\nMITCHELL: No. He could be charged with reckless driving, and fillip' out a false police report. Which, that's no joke --\\nLISA: That's unbelievable! What does he have to do? Kill her on purpose?\\nMITCHELL: Yes. Because that's the definition of murder. Killin' somebody on purpose. You're not sayin' he ran her over on purpose, are you?\\nLISA: No.\\nMITCHELL: All, right, look. Lemme take another statement, and, uh...We'11 look into it,\\nLISA: You're kidding.\\nMITCHELL: No. I'll go over it with my sergeant, probably pull this guy in again. Reinterview him. Put a little pressure on him. See what he says.\\n\\n\", 'answer': 'Thank you...! Thank you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'LISA'}\n",
      "Last word -> LISA : \"Thank you...! Thank you.\"\n",
      "prediction :  And, and, what about, you know --\n",
      "Real answer : Thank you...! Thank you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7794872522354126], 'recall': [0.8345792293548584], 'f1': [0.8060930371284485], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 88.00093078613281\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMITCHELL: Detective Mitchell.\\nLISA: Oh, hi, it's Lisa Cohen calling.\\nMITCHELL: Hi Lisa, what can I do for you?\\nLISA: Well, I was just wondering what ever happened, if anything, with the case. You said you might re-interview the bus driver...\\nMITCHELL: Yes, we did:.We brought him back in --\\nLISA: You did? What happened?\\nMITCHELL: Well, he basically stuck to his original representation, and that was pretty much it. I brought it up with my sergeant, but he agrees with me we still don't have enough to charge this guy, so there's really not a lot more we can do at this point.\\nLISA: But how did you ask the questions?\\nMITCHELL: Excuse me?\\nLISA: He's obviously not gonna change his statement if you just ask him like really politely: Why would he? We already know he's a liar.\\nMITCHELL: Hey, you know, Lisa, in the old days we'd just throw him in the back with a rubber hose and we'd get whatever answer we want out of him. But fortunately we don't do that kind of thing anymore --\\nLISA: Yeah, not to white people.\\nMITCHELL: Excuse me?\\nLISA: You don't do it to white people. Anyway, I'm not saying you --\\nMITCHELL: We don't do it to who?\\nLISA: Oh my God...\\nMITCHELL: First of all, I don't know why you're bringin' the guy's race into it. There's forty thousand cops in this city --\\nLISA: Yes, thank you, yes.\\nMITCHELL: -- and I hate to disillusion you, but most of 'em are pretty good guys, just tryin' to do their job. Bottom line is the DA's not gonna take this case. (Pause) Now you could talk to my sergeant if you want to, but --\\n\\n\", 'answer': 'Yes, I would.', 'gold_tag': 'Everyday Language', 'last_speaker': 'LISA'}\n",
      "Last word -> LISA : \"Yes, I would.\"\n",
      "prediction :  No, thank you. I'm gonna hang up now.\n",
      "Real answer : Yes, I would.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8361716866493225], 'recall': [0.8917528390884399], 'f1': [0.8630682826042175], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.935420989990234\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRISTY: A convent? They put me in a convent? What's the problem? Wasn't there any more room in Hell?\\nMOTHER SUPERIOR: What is your full name? Your Christian name?\\nCHRISTY: Mother Theresa. Gandhi. Don't you understand? This is all a mistake. I'm the good guy. I'm the witness. And I'm being punished!\\nMOTHER SUPERIOR: Your name?\\nCHRISTY: Christy. Christy Van Cartier.\\nMOTHER SUPERIOR: Enough joking.\\nCHRISTY: That's my real name! Currently I'm a singer. Sort of.\\nMOTHER SUPERIOR: Very well.\\nCHRISTY: Oh my God. This isn't happening, tell me this isn't happening. It's a nightmare, I'm back at St. Anne's!\\nMOTHER SUPERIOR: St. Anne's?\\nCHRISTY: Parochial school. Akron. St. Android's.\\nMOTHER SUPERIOR: You were unhappy?\\nCHRISTY: I was expelled! When I was fifteen?\\nMOTHER SUPERIOR: The reason?\\nCHRISTY: Beats me! What do you think? Smoking! Heavy petting, without a chaperone. Heavy petting, with the chaperone. And wearing a black bra, under my uniform. The demon bra. You see? You see? I have to get out of here I have to make a phone call. Don't you get it? I'm in a convent! You're a nun!\\nMOTHER SUPERIOR: Sit down.\\nCHRISTY: What?\\nMOTHER SUPERIOR: Sit. Miss Van Cartier.\\nCHRISTY: What?\\nMOTHER SUPERIOR: Your cigarette -- out. It has come to pass.\\nCHRISTY: What?\\nMOTHER SUPERIOR: I joined this convent some thirty years ago. At that time, the world knew some measure of peace. And hope. Our order was a beacon of hospitality, to families, to children, to a neighborhood filled with promise. And, as the years have passed, I have watched that promise destroyed. Drugs. Gangs. so I have made this convent an oasis, a retreat from horror.\\nCHRISTY: Are you talking about me?\\nMOTHER SUPERIOR: And all those like you.\\nCHRISTY: You mean black people?\\nMOTHER SUPERIOR: Absolutely not. I mean the wicked. The heedless. And their Las Vegas concubines.\\nCHRISTY: What's a concubine?\\nMOTHER SUPERIOR: Check your driver's license.\\nCHRISTY: Fine. Got it. Look, the way I see it, I'm stuck here, right? I mean, I'm here or I'm target practice. So here's the deal -- I don't bug you, you don't bug me. I'll catch up on some sleep, watch some tube, lay back and lay low. So just get me a key and show me to my room, and do not disturb. Capisce?\\nMOTHER SUPERIOR: Of course. But it's almost lunch.\\nCHRISTY: Cool. Is there a menu? Or buffet?\\nMOTHER SUPERIOR: Before we do, you might like to freshen up. And you'll certainly want to change\\n\\n\", 'answer': 'had on since the night Deal.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CHRISTY'}\n",
      "Last word -> CHRISTY : \"had on since the night Deal.\"\n",
      "prediction :  This would never happen in Hell. I would be right here. With you.\n",
      "Real answer : had on since the night Deal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8457251787185669], 'recall': [0.8501306772232056], 'f1': [0.8479222059249878], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 49.069435119628906\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRISTY: No! No! I can't do this!\\nMOTHER SUPERIOR: Normally dressed, you are a sore thumb, and you endanger us all. While you are here, you will conduct yourself as a nun. Only I shall know who, and what, you truly are. You will not disrupt the convent. You will not influence the Sisters with your colorful street talk. You will draw no attention to yourself in any way.\\nCHRISTY: But look at rites Look at this! I'm a nun! I'm invisible! I'm a penguin!\\nMOTHER SUPERIOR: As of now, and until you leave, you are\\n\\n\", 'answer': 'Mary Clarence? Like a guy? Like a dumb guy?', 'gold_tag': 'Everyday Language', 'last_speaker': 'CHRISTY'}\n",
      "Last word -> CHRISTY : \"Mary Clarence? Like a guy? Like a dumb guy?\"\n",
      "prediction :  You'd better go.\n",
      "Real answer : Mary Clarence? Like a guy? Like a dumb guy?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8118543028831482], 'recall': [0.8237195014953613], 'f1': [0.8177438378334045], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 98.66117095947266\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOTHER SUPERIOR: Clarence Loyola. There are three vows that every nun must accept. The vow of poverty...\\nCHRISTY: No problem.\\nMOTHER SUPERIOR: The vow of obedience.\\nCHRISTY: Like to who?\\nMOTHER SUPERIOR: And the vow of chastity.\\n\\n', 'answer': \"I'm outta here.\", 'gold_tag': 'CHRISTY indicates a lack of religious conviction or perhaps a more rebellious nature', 'last_speaker': 'CHRISTY'}\n",
      "Last word -> CHRISTY : \"I'm outta here.\"\n",
      "prediction :  Who the hell is this?\n",
      "Real answer : I'm outta here.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8195335865020752], 'recall': [0.8597028851509094], 'f1': [0.8391377925872803], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 74.46952056884766\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRISTY: Is this all the food I get?\\nMOTHER SUPERIOR: Yes. Until breakfast.\\nCHRISTY: That's tomorrow! Don't you have any snacks? Machines?\\nMOTHER SUPERIOR: This shall be your cell, Mary Clarence.\\nCHRISTY: My what?\\n\\n\", 'answer': 'Your cell. Your room.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MOTHER SUPERIOR'}\n",
      "Last word -> MOTHER SUPERIOR : \"Your cell. Your room.\"\n",
      "prediction :  The cell. Mary Clarence.\n",
      "Real answer : Your cell. Your room.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9279961585998535], 'recall': [0.9323776960372925], 'f1': [0.9301817417144775], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0.25 0.09128709291752769\n",
      "ppl : 4154.3291015625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOTHER SUPERIOR: A balloon and a banana! Tell me, Mary Clarence, what were you thinking?\\nCHRISTY: Those girls were asking questions. They\\'ve got it rough. I wish somebody had talked to me about that stuff when was their age. I wish somebody would talk to me about it now.\\nMOTHER SUPERIOR: This is a convent, not a clinic. We offer moral guidance, not hardware.\\nCHRISTY: Have you been out in those streets? Do you know what those kids are up against? You should help them!\\nMOTHER SUPERIOR: We are nuns. We seek solutions through\\nCHRISTY: Sometimes it\\'s not enough!\\nMOTHER SUPERIOR: You are correct. Sometimes prayer alone cannot help a situation. Such as your own, for example. How do you feel about physical labor?\\nCHRISTY: It never solves anything.\\nMOTHER SUPERIOR: Do your recall the words of Saint Peter, in Ecciesiastes 1:27? He spoke unto a wastrel youth. He said, \"Take up thy task, and know ye the path of contentment.\"\\nCHRISTY: In English?\\n\\n', 'answer': 'How to put it... ah, Of course, Mary Clarence. \"No pain, no gain.\"', 'gold_tag': 'MOTHER SUPERIOR uses religious texts to guide others', 'last_speaker': 'MOTHER SUPERIOR'}\n",
      "Last word -> MOTHER SUPERIOR : \"How to put it... ah, Of course, Mary Clarence. \"No pain, no gain.\"\"\n",
      "prediction :  ...in England.\n",
      "Real answer : How to put it... ah, Of course, Mary Clarence. \"No pain, no gain.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8641891479492188], 'recall': [0.8059753775596619], 'f1': [0.8340677618980408], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1242.8402099609375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRISTY: I'm sorry, I'm not a weaver!\\nMOTHER SUPERIOR: Months of work, and the loom, absolutely ruined!\\n\\n\", 'answer': \"Look, this isn't my kind of thing! I wasn't cut out to make little tapestries, or knit little sweaters! I don't do that! I'm a star!\", 'gold_tag': 'CHRISTY does not enjoy craft activities such as knitting or making tapestries', 'last_speaker': 'CHRISTY'}\n",
      "Last word -> CHRISTY : \"Look, this isn't my kind of thing! I wasn't cut out to make little tapestries, or knit little sweaters! I don't do that! I'm a star!\"\n",
      "prediction :  What do you mean?\n",
      "Real answer : Look, this isn't my kind of thing! I wasn't cut out to make little tapestries, or knit little sweaters! I don't do that! I'm a star!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7997859716415405], 'recall': [0.7710283398628235], 'f1': [0.7851439118385315], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.058823529411764705, 'rouge2': 0.0, 'rougeL': 0.058823529411764705, 'rougeLsum': 0.058823529411764705}\n",
      "bleu 1/2 : 0.0010216928596160166 0.00037306948403576754\n",
      "ppl : 69.61486053466797\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFOLEY: Call everyone in - every car patrol, beat cop, off-duty, too! Pull 'em in, close every street! Now! I'm gonna do what Gordon never could.\\nBLAKE: What's that?\\nFOLEY: I'm gonna take down the Batman.\\n\\n\", 'answer': 'Sir, what about the armed robbers?', 'gold_tag': 'BLAKE is a police officer , BLAKE shows concern for ongoing crimes', 'last_speaker': 'BLAKE'}\n",
      "Last word -> BLAKE : \"Sir, what about the armed robbers?\"\n",
      "prediction :  What is that supposed to mean?\n",
      "Real answer : Sir, what about the armed robbers?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.858802080154419], 'recall': [0.8795403838157654], 'f1': [0.8690475225448608], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 42.318817138671875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFOLEY: Negative! Stay on the Batman!\\nBLAKE: But he's getting away!\\n\\n\", 'answer': 'Who do you want to catch? Some robber, or the son-of-a-bitch who killed Harvey Dent?', 'gold_tag': \"FOLEY believes Batman is responsible for Harvey Dent's death\", 'last_speaker': 'FOLEY'}\n",
      "Last word -> FOLEY : \"Who do you want to catch? Some robber, or the son-of-a-bitch who killed Harvey Dent?\"\n",
      "prediction :  Stay on him!\n",
      "Real answer : Who do you want to catch? Some robber, or the son-of-a-bitch who killed Harvey Dent?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8439286351203918], 'recall': [0.8232322335243225], 'f1': [0.8334519267082214], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2747.90185546875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFOLEY: Foley.\\nBLAKE: It's a trap! Pull everyone out! with explosives - There's a ring around the tunnels - they're gonna blow it and trap the cops underground!\\n\\n\", 'answer': \"Pull out! Pull 'em out!\", 'gold_tag': \"FOLEY is in a position of authority and is quick to act upon receiving critical information , FOLEY has the ability to deploy or withdraw personnel in dangerous situations , FOLEY's temporal information - FOLEY's response to BLAKE's warning indicates that they are in a time-critical situation\", 'last_speaker': 'FOLEY'}\n",
      "Last word -> FOLEY : \"Pull out! Pull 'em out!\"\n",
      "prediction :  No, no! Pull out your people, you can all escape! All of you, don't get hurt!\n",
      "Real answer : Pull out! Pull 'em out!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8354833126068115], 'recall': [0.8649249076843262], 'f1': [0.8499492406845093], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1818181818181818, 'rouge2': 0.1, 'rougeL': 0.1818181818181818, 'rougeLsum': 0.1818181818181818}\n",
      "bleu 1/2 : 0.0625 0.02041241452319315\n",
      "ppl : 36.70744705200195\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBLAKE: Foley?\\nFOLEY: Jesus, Blake! Every cop in the city's down in those tunnels!\\n\\n\", 'answer': 'Not every cop...', 'gold_tag': 'Blake is a police officer , Blake and Foley share the experience of being police officers dealing with a crisis in the city', 'last_speaker': 'BLAKE'}\n",
      "Last word -> BLAKE : \"Not every cop...\"\n",
      "prediction :  11,733, is that enough for you? The 79th Precinct?\n",
      "Real answer : Not every cop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8081783056259155], 'recall': [0.845629096031189], 'f1': [0.8264796733856201], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 46.21240997314453\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFRANK: Morning, Jim.\\nJIM: Morning.\\n\\n', 'answer': 'Listen, have you got a minute?', 'gold_tag': 'Everyday Language', 'last_speaker': 'FRANK'}\n",
      "Last word -> FRANK : \"Listen, have you got a minute?\"\n",
      "prediction :  And how are you feeling today?\n",
      "Real answer : Listen, have you got a minute?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8682733178138733], 'recall': [0.8676229119300842], 'f1': [0.8679479956626892], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.16666666666666669 0.05773502691896258\n",
      "ppl : 78.98401641845703\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFRANK: We lost water pressure three weeks ago. For a while, I thought we'd be okay with the water in the other flats. The cistern and tanks. But it vanishes so quick you wouldn't believe. You drink it, it\\nJIM: They're all empty...\\nFRANK: It hasn't rained in over a week. You can set up a plastic sheet to catch dew and condensation. Trap it somehow. I saw it on TV once and I've been experimenting, but I can't get it to work, and... you don't happen to... You'd never think it. Needing rain so badly... Not in fucking England... Jim, we don't have enough water for\\nJIM: Right.\\n\\n\", 'answer': \"No. It's not what you think.\", 'gold_tag': \"FRANK's comments reveal a sense of frustration and desperation\", 'last_speaker': 'FRANK'}\n",
      "Last word -> FRANK : \"No. It's not what you think.\"\n",
      "prediction :  We got this. We made the right decision to build this. We got the proper foundations, proper water supply.\n",
      "Real answer : No. It's not what you think.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8507413864135742], 'recall': [0.8488583564758301], 'f1': [0.8497987985610962], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 45.61374282836914\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFRANK: HOLD ON! Fuck.\\nJIM: The world's worst place to get a flat.\\n\\n\", 'answer': \"Agreed. I think we'd better do this quick.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'FRANK'}\n",
      "Last word -> FRANK : \"Agreed. I think we'd better do this quick.\"\n",
      "prediction :  Here is your fucking place! Fuck you!\n",
      "Real answer : Agreed. I think we'd better do this quick.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8227159380912781], 'recall': [0.8406364321708679], 'f1': [0.8315796256065369], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 183.50523376464844\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJIM: Jesus Christ. We're never going to be able to get out of London.\\n\\n\", 'answer': \"Don't you worry about that. I've sat twenty years in this seat. I've got my routes.\", 'gold_tag': \"FRANK has been in the same job for twenty years , FRANK mentions routes , FRANK's job is likely as a bus or taxi driver\", 'last_speaker': 'FRANK'}\n",
      "Last word -> FRANK : \"Don't you worry about that. I've sat twenty years in this seat. I've got my routes.\"\n",
      "prediction :  Well, this looks like you're going to have to wait for those cars to arrive.\n",
      "Real answer : Don't you worry about that. I've sat twenty years in this seat. I've got my routes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8438674807548523], 'recall': [0.8494679927825928], 'f1': [0.84665846824646], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11428571428571428, 'rouge2': 0.0, 'rougeL': 0.05714285714285714, 'rougeLsum': 0.05714285714285714}\n",
      "bleu 1/2 : 0.06236713233544119 0.020414436057463375\n",
      "ppl : 23.459869384765625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFRANK: Hey.\\nJIM: What...\\nFRANK: Shh. You're having a bad dream, that's all.\\n\\n\", 'answer': 'Okay, Dad.', 'gold_tag': 'JIM is possibly Frank\\'s son, as implied by his response \"Okay, Dad\" , FRANK is possibly older , Jim refers to FRANK as \\'Dad\\'', 'last_speaker': 'JIM'}\n",
      "Last word -> JIM : \"Okay, Dad.\"\n",
      "prediction :  *yawn* I'm just going to work and then home again.\n",
      "Real answer : Okay, Dad.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8149699568748474], 'recall': [0.8824225664138794], 'f1': [0.8473560214042664], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 30.71849822998047\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJIM: Here you go, Frank. This is how you catch dew. I'm covered in the fucking stuff.\\n\\n\", 'answer': \"Okay. Let's get rolling. If we make good time, we'll be there before midday.\", 'gold_tag': 'FRANK wants to reach their destination before midday', 'last_speaker': 'FRANK'}\n",
      "Last word -> FRANK : \"Okay. Let's get rolling. If we make good time, we'll be there before midday.\"\n",
      "prediction :  Do you want to get it on the road with me, Jim?\n",
      "Real answer : Okay. Let's get rolling. If we make good time, we'll be there before midday.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8666090965270996], 'recall': [0.8606510162353516], 'f1': [0.8636198043823242], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07142857142857144, 'rouge2': 0.0, 'rougeL': 0.07142857142857144, 'rougeLsum': 0.07142857142857144}\n",
      "bleu 1/2 : 0.07054014374088449 0.023298642673655674\n",
      "ppl : 44.37327194213867\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTODD: It... grabbed me. It was just like Miss Harmon said. I couldn't believe it. But there it was, the camps, the uniforms, the ...the way they saluted each other. But what am I telling you for? You know more about this stuff than anybody.\\nDUSSANDER: Yes, what are you telling me for?\\nTODD: Then last year I wrote my big term paper on Dachau. I got an A+. It was the only A+ she gave. I mean I always do real well. A's on everything. That's why I'm accelerated.\\nDUSSANDER: Accelerated?\\nTODD: You know, accelerated. I skipped two grades, second and ninth. I didn't need them. That's why I'm already a junior.\\nDUSSANDER: I see...\\n\\n\", 'answer': \"Some kids resent me for it. That's not important. Anyway, my paper really floored my history teacher. I guess because I got through all those books without throwing up. But I learned something. I learned that when you talk about the camps now, you have to remember to sound really disgusted. I mean, you can't just say what happened like the magazines did and leave it at that. If I tried that the teacher would have freaked and called my parents in.\", 'gold_tag': 'TODD wrote an A+ term paper on Dachau , TODD understands the sensitivities of discussing concentration camps and adjusts his tone accordingly', 'last_speaker': 'TODD'}\n",
      "Last word -> TODD : \"Some kids resent me for it. That's not important. Anyway, my paper really floored my history teacher. I guess because I got through all those books without throwing up. But I learned something. I learned that when you talk about the camps now, you have to remember to sound really disgusted. I mean, you can't just say what happened like the magazines did and leave it at that. If I tried that the teacher would have freaked and called my parents in.\"\n",
      "prediction :  ...and my uncle?\n",
      "Real answer : Some kids resent me for it. That's not important. Anyway, my paper really floored my history teacher. I guess because I got through all those books without throwing up. But I learned something. I learned that when you talk about the camps now, you have to remember to sound really disgusted. I mean, you can't just say what happened like the magazines did and leave it at that. If I tried that the teacher would have freaked and called my parents in.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8374929428100586], 'recall': [0.8190574645996094], 'f1': [0.8281726241111755], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.04597701149425287, 'rouge2': 0.0, 'rougeL': 0.04597701149425287, 'rougeLsum': 0.04597701149425287}\n",
      "bleu 1/2 : 1.220274085705462e-12 4.726101211745736e-13\n",
      "ppl : 1616.1131591796875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTODD: I\\'ve never seen anyone drink bourbon with McDonald\\'s before. ...So, How did the stuff get to Patin?\\nDUSSANDER: In railroad cars marked \"Medical Supplies.\" It came in long crates that looked like coffins.\\nTODD: That\\'s fitting. Was it always Zyklon-B?\\nDUSSANDER: No, from time to time we would be sent something else. Experimental gases. The High Command was always interested in improving efficiency. Once they sent us a gas code-named \"Pegasus.\" A nerve gas. Thank God they never sent it again. It...\\nTODD: It what?\\nDUSSANDER: It didn\\'t work very well. It was quite boring.\\nTODD: Bullshit. You\\'re lying. What did it do?\\nDUSSANDER: It killed them. What do you think it did, made them walk on water? It killed them.\\nTODD: Tell me. Tell me.\\nDUSSANDER: I won\\'t. I refuse. Where are my cigarettes?\\nTODD: What did it do?\\nDUSSANDER: It made them dance.\\nTODD: Dance?\\nDUSSANDER: Like Zyklon-B, it came in through the shower heads. After a few seconds the prisoners began to leap about. Some were screaming. Most of them were laughing. They began to vomit and to... to defecate helplessly.\\nTODD: You mean they... they... shit themselves? ...Woah.\\nDUSSANDER: They began to twitch all over and make high, strange sounds in their throats. At last they collapsed and just lay there on the concrete, twitching and yodeling, with blood streaming from their noses. But I lied to you, boy. It didn\\'t kill them. Either because it wasn\\'t strong enough or because we couldn\\'t bring ourselves to wait that long. I suppose it was that. I sent five men in with rifles to end their agonies. These were five men I trusted. It would have looked bad on my record to have wasted so many cartridges at a time when the Fuehrer had declared every cartridge a national resource. I was always given high marks for efficiency.\\nTODD: Yeah, I bet.\\nDUSSANDER: How do you eat this crap everyday?\\nTODD: Why didn\\'t you just do the job yourself? You carried a gun, didn\\'t you?\\nDUSSANDER: I was the commandant of the camp.\\nTODD: So you never killed anybody?\\nDUSSANDER: The entire world was at war, boy. People died.\\nTODD: That\\'s not a real answer. I\\'m asking about you.\\nDUSSANDER: Boy, I was a soldier in a position of power. You don\\'t get to be there by selling ...girl scout\\'s cookies.\\nTODD: I know what the SS was, Dussander. Who are you talking to? It was a bunch of dumb, rich kids who bought their way into the service so they wouldn\\'t have to go fight on the front.\\nDUSSANDER: That\\'s enough for today, boy. I beg you. I\\'m tired.\\n\\n', 'answer': 'Yeah, fine. That was good story though. You always tell them good, once I get you started.', 'gold_tag': 'TODD is interested in war history, particularly the operations of the SS', 'last_speaker': 'TODD'}\n",
      "Last word -> TODD : \"Yeah, fine. That was good story though. You always tell them good, once I get you started.\"\n",
      "prediction :  I hope they got you.\n",
      "Real answer : Yeah, fine. That was good story though. You always tell them good, once I get you started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8829610347747803], 'recall': [0.8443745374679565], 'f1': [0.8632367849349976], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1818181818181818, 'rouge2': 0.0, 'rougeL': 0.1818181818181818, 'rougeLsum': 0.1818181818181818}\n",
      "bleu 1/2 : 0.018143590657882503 0.006414727994630807\n",
      "ppl : 211.57781982421875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDUSSANDER: What for?\\nTODD: Just to be safe.\\nDUSSANDER: To hell with this. You open it.\\nTODD: Oh, relax, old man. Sit down and open it.\\nDUSSANDER: You wrapped it yourself, I see. Pete's Quality Costume Clothiers - Serving You Since 1976.\\nTODD: Go ahead, try it on.\\nDUSSANDER: Are you out of your mind, boy? What makes you think I would put something like that on?\\nTODD: I thought you'd like it --\\nDUSSANDER: Like it? My God, you're a bigger fool than I thought. Maybe I'll put it on and do a little shopping downtown. Is that what you thought? You stupid, boy. You... You know, you are correct. I am the stupid one. For months I have suffered your indignities. I have exposed my past to you while watching you stuff your face with those wretched hamburgers. I have stocked my refrigerator with Coca Cola and ding dongs. All for you, I have done these things and I'm tired of it. But because I value my life and my freedom, what's left of it anyway, I do them. But I'll die before I put this thing on, you fucking piss-ant.\\nTODD: That's enough. You don't get to talk to me like that.\\nDUSSANDER: I should smash you.\\nTODD: Do it. Please. Indignities? What you've suffered with me is nothing compared to what the Israelis would do to you. Remember what happened to Eichmann? You forget that, I think. And, you know, that's my fault. I have let you forget. You have gotten comfortable with this situation. Well, don't you for one minute ever forget who holds the cards here. Don't you ever forget that envelope under my mattress. I tried to do this the nice way, I tried to do something to please you, but you don't want it. So fine, we'll do it the hard way. You will put this on because I want to see you in it. Now strip.\\n\\n\", 'answer': 'I hope you go to hell --', 'gold_tag': 'DUSSANDER values his freedom and life', 'last_speaker': 'DUSSANDER'}\n",
      "Last word -> DUSSANDER : \"I hope you go to hell --\"\n",
      "prediction :  Do I have to do what you want?\n",
      "Real answer : I hope you go to hell --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8312356472015381], 'recall': [0.8321101665496826], 'f1': [0.831672728061676], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.42857142857142855, 'rouge2': 0.0, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0.375 0.07319250547114\n",
      "ppl : 44.21181869506836\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTODD: You what?\\nDUSSANDER: I told him you were getting back on track by your own accord. I gave him my word. If you get even one flunk card--\\nTODD: Are you out of your fucking mind? I'm going to get three or four flunk cards. I failed an economics test today, so there's another\\nDUSSANDER: Boy, it was the best I could do without arousing suspicion.\\nTODD: I could have done better myself --\\nDUSSANDER: Well you didn't, did you? This is the way it is and now you are upset because the only way you can make things right is to work.\\nTODD: You're insane. I'm upset because it can't be done.\\nDUSSANDER: It can. And it will. You will work.\\nTODD: I don't take orders from you. Maybe you've forgotten --\\nDUSSANDER: Listen, boy. Before today it was possible, just barely possible, that you could have denounced me and come out clean yourself. The way your nerves have been lately I don't think so, but never mind that. It was - at least technically possible. But now things have changed. Today I impersonated your grandfather, one Victor Bowden. And it was you who arranged the meeting. What would people make of that? If things come out now... perhaps you were right, your age and a good attorney might keep you out of jail, but you would be humiliated, boy, publicly. You would be infamous. Your parents too. Do you know what such a scandal would do to them? To you? Think about that.\\nTODD: You fucker.\\nDUSSANDER: It's a done deal, boy. If you don't like it, you can discuss it at family counselling.\\nTODD: God! I wish... I wish --\\nDUSSANDER: Never mind your wishes. Your wishes make me sick. All I want to hear is that you understand the situation.\\nTODD: Look, you gotta believe me. There is no way in hell that I can pull myself out of a half year slide in a couple of weeks. I wish I could, but we're just going to have to think of something else.\\nDUSSANDER: Boy, the time for discussion is over. This is the way it is. You are going to work. And I am going to be right here with you.\\n\\n\", 'answer': 'What are you talking about?', 'gold_tag': 'Everyday Language', 'last_speaker': 'TODD'}\n",
      "Last word -> TODD : \"What are you talking about?\"\n",
      "prediction :  It's a done deal. I think you're probably right, you know. I think everything would be better, I could just - but what - I can't decide.\n",
      "Real answer : What are you talking about?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.7979593276977539], 'recall': [0.8234558701515198], 'f1': [0.8105071783065796], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12121212121212122, 'rouge2': 0.0, 'rougeL': 0.06060606060606061, 'rougeLsum': 0.06060606060606061}\n",
      "bleu 1/2 : 0.037037037037037035 0.01193524790065722\n",
      "ppl : 20.16913604736328\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDUSSANDER: Come over right away, boy. I'm having a heart attack, a bad one, I think. I understand that you cannot talk, but you can listen. I cannot call 911... at least not yet. There is quite a mess here. I need help... and that means you need help.\\nTODD: Well if you put it that way --\\nDUSSANDER: Tell your parents I've had a letter, an important letter, and I need you to read it to me.\\nTODD: Yeah, sure. I'll be right there.\\n\\n\", 'answer': 'Now we see what you are made of, boy.', 'gold_tag': \"DUSSANDER's temporal information: DUSSANDER is currently having a heart attack, and there is a mess that he needs cleaned up in his home\", 'last_speaker': 'DUSSANDER'}\n",
      "Last word -> DUSSANDER : \"Now we see what you are made of, boy.\"\n",
      "prediction :  Well, this is the last thing you'll care for. I was going to give it to you in person if a bit of time had not brought you here. It is an extraordinary letter, and I know it. It may have you thinking... it may have the world thinking... that I am mad at you, that I betrayed you.\n",
      "Real answer : Now we see what you are made of, boy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.818199872970581], 'recall': [0.8465230464935303], 'f1': [0.8321205377578735], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.057971014492753624, 'rouge2': 0.0, 'rougeL': 0.057971014492753624, 'rougeLsum': 0.057971014492753624}\n",
      "bleu 1/2 : 0.016949152542372878 0.005405800292019179\n",
      "ppl : 20.22266960144043\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDUSSANDER: Hurry up, for God's sake.\\nTODD: Don't you die on me, you old bastard. Not now.\\nDUSSANDER: I think we're okay.\\nTODD: Me too.\\nDUSSANDER: Call an ambulance. What are you talking about? For God's sake, boy...\\nTODD: I want the key and I want to know where the bank is.\\n\\n\", 'answer': 'Hillcrest Savings on Domingo Avenue. The key is behind the clock on the mantle piece.', 'gold_tag': 'DUSSANDER has a key to Hillcrest Savings on Domingo Avenue , DUSSANDER keeps the key hidden behind a clock on the mantle piece', 'last_speaker': 'DUSSANDER'}\n",
      "Last word -> DUSSANDER : \"Hillcrest Savings on Domingo Avenue. The key is behind the clock on the mantle piece.\"\n",
      "prediction :  You can get the key from me.\n",
      "Real answer : Hillcrest Savings on Domingo Avenue. The key is behind the clock on the mantle piece.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8918588161468506], 'recall': [0.8320796489715576], 'f1': [0.8609327673912048], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.1, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0.09111615923542012 0.022006643185771023\n",
      "ppl : 79.45957946777344\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nINDY: We cannot afford to take mythology at face value. Next week: \"Egyptology.\" Starting with the excavation of Naukratis by Blinders Petrie in 1885. I will be in my office if anybody\\'s got any problems for the next hour and a half. Marcus! I did it!\\nBRODY: You\\'ve got itl\\nINDY: You know how long I\\'ve been looking for that?!\\nBRODY: All your life.\\nINDY: All my life!\\nBRODY: Well done, Indy. Very well done, indeed This will find a place of honor in our Spanish collection.\\nINDY: We can discuss my honorarium over dinner and champagne tonight. Your treat.\\n\\n', 'answer': 'Yes. My treat.', 'gold_tag': 'BRODY is on friendly, celebratory terms with INDY, willing to treat him to dinner and champagne', 'last_speaker': 'BRODY'}\n",
      "Last word -> BRODY : \"Yes. My treat.\"\n",
      "prediction :  You know what I call this? The best day of my life.\n",
      "Real answer : Yes. My treat.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8155430555343628], 'recall': [0.9046769738197327], 'f1': [0.8578007221221924], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.148927688598633\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nINDY: Dad? He's an academic A bookworm. He's not a field mans Dad? Dad?\\nBRODY: What has the old fool got himself into now?\\nINDY: I don't know. But whatever it is, he's in over his head! Dad?\\nBRODY: It's today's mail. And it's been opened.\\nINDY: Mail! That's it, Marcus! Venice, Italy!\\nBRODY: What is it?\\nINDY: clue he ever followed. Every discovery he made. A complete record of his search for the Holy Grail. This is his whole life. Why would he have sent this to me?\\nBRODY: I don't know. But someone must want it pretty badly.\\nINDY: Do you believe, Marcus? Do you believe the Grail actually exists?\\nBRODY: The search for the Cup of Christ is the search for the divine in all of us. But if you want facts, Indy, I have none to give you. At my age, I'm prepared to take a few things on faith.\\nINDY: Call Donovan, Marcus. Tell him I'll take that ticket to Venice now.\\n\\n\", 'answer': \"I'll tell him we'll take two.\", 'gold_tag': 'BRODY is a collaborator and is willing to accompany INDY on his journey', 'last_speaker': 'BRODY'}\n",
      "Last word -> BRODY : \"I'll tell him we'll take two.\"\n",
      "prediction :  Indy, what do you know about the Holy Grail?\n",
      "Real answer : I'll tell him we'll take two.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.8393226265907288], 'recall': [0.846880316734314], 'f1': [0.8430845141410828], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 47.76873779296875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nINDY: How\\'s the head?\\nBRODY: It\\'s better, now I\\'ve seen this. It\\'s the name of a city. \"Alexandretta?\" Hmmm...\\nINDY: The Knights of the First Crusade laid siege to the city of Alexandretta for over a year. The entire city was destroyed. The present city of Iskenderun is built on its ruins. Marcus� you remember what the Grail Tablet said. \"Across the desert and through the mountain to the But where exactly?\\nBRODY: Your father would know. Your father did know. Look. He made a map. He must have pieced it together from clues scattered through the whole history of the Grail Quest. Now, he knew there was a city with an oasis due east. Here. He knew the course turned south through the desert to a river, and the river led into the mountains. Here. Straight to the canyon. He knew everything except where to begin, the name of the city.\\nINDY: Alexandretta. Now we know.\\nBRODY: Yes. Now we know.\\nINDY: Marcus, get hold of Sallah. Tell him to meet you in Iskenderun.\\nBRODY: What about you?\\n\\n', 'answer': \"I'm going after Dad.\", 'gold_tag': 'INDY has an immediate plan to pursue his father', 'last_speaker': 'INDY'}\n",
      "Last word -> INDY : \"I'm going after Dad.\"\n",
      "prediction : I'm not going out.\n",
      "Real answer : I'm going after Dad.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.9300894141197205], 'recall': [0.9238990545272827], 'f1': [0.9269838929176331], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.6, 'rouge2': 0.25, 'rougeL': 0.6, 'rougeLsum': 0.6}\n",
      "bleu 1/2 : 0.5 0.12909944487358058\n",
      "ppl : 28.1750431060791\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRODY: I've got to talk to you.\\nINDY: This isn't really a good time.\\nBRODY: Indy, it's important.\\n\\n\", 'answer': 'All right. Come on in.', 'gold_tag': 'Everyday Language', 'last_speaker': 'INDY'}\n",
      "Last word -> INDY : \"All right. Come on in.\"\n",
      "prediction :  I know. I'm sorry.\n",
      "Real answer : All right. Come on in.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.884502649307251], 'recall': [0.8905899524688721], 'f1': [0.887535810470581], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 26.082244873046875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRODY: They want you to go for it. And they'll pay.\\nINDY: Good work, Marcus. I had a feeling this would happen. And, of course, the Museum gets the Ark when we're done.\\nBRODY: Of course.\\nINDY: Okay, here's the way it's gonna be. First, I'll high-tail it to Shanghai and get the piece from General Hok. Then I think I know where I can find Ravenwood. If only I can get -\\nBRODY: General Hok's a tough customer. They don't call him the Wild Boar for Japanese.\\n\\n\", 'answer': \"I'll worry about that when the time comes. My only hope is to find the Well of the Souls before the Nazis do.\", 'gold_tag': 'INDY is knowledgeable, mentioning the Ark, General Hok, and the Well of Souls', 'last_speaker': 'INDY'}\n",
      "Last word -> INDY : \"I'll worry about that when the time comes. My only hope is to find the Well of the Souls before the Nazis do.\"\n",
      "prediction :  Okay, I've got Ravenwood's location; so I'll bring him to you, Marcus. You and me together.\n",
      "Real answer : I'll worry about that when the time comes. My only hope is to find the Well of the Souls before the Nazis do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.865412712097168], 'recall': [0.8595024347305298], 'f1': [0.8624475002288818], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13953488372093023, 'rouge2': 0.04878048780487805, 'rougeL': 0.13953488372093023, 'rougeLsum': 0.13953488372093023}\n",
      "bleu 1/2 : 0.08070606580348652 0.018638267526751434\n",
      "ppl : 45.05147933959961\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELENA: You have a great future as a driver. If they don't arrest you first!!\\nSALVATORE: That's nothing to do with it, it's the car that's still being run in...\\nELENA: SO now how do we get home?\\n\\n\", 'answer': 'Hello, Dr Mendola...Hem...', 'gold_tag': 'SALVATORE is familiar with Dr. Mendola', 'last_speaker': 'SALVATORE'}\n",
      "Last word -> SALVATORE : \"Hello, Dr Mendola...Hem...\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m bleu_eval \u001b[38;5;241m=\u001b[39m evaluate\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbleu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m json_data:\n\u001b[0;32m----> 6\u001b[0m     bert_score, rough_score, bleu_1, bleu_2, infer_sentence, ppl \u001b[38;5;241m=\u001b[39m evaluation_chat_system(\u001b[38;5;241m2\u001b[39m, prompt ,model, tokenizer,device, bertscore_eval, rouge_eval, bleu_eval)\n\u001b[1;32m      7\u001b[0m     bert\u001b[38;5;241m.\u001b[39mappend(bert_score)\n\u001b[1;32m      8\u001b[0m     rough\u001b[38;5;241m.\u001b[39mappend(rough_score)\n",
      "Cell \u001b[0;32mIn[53], line 39\u001b[0m, in \u001b[0;36mevaluation_chat_system\u001b[0;34m(num, prompt, model, tokenizer, device, bert_eval, rough_eval, bleu_eval)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLast word -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperson\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mutterance\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     38\u001b[0m input_ \u001b[38;5;241m=\u001b[39m tokenizer(input__, return_tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)     \n\u001b[0;32m---> 39\u001b[0m output \u001b[38;5;241m=\u001b[39m generate(model,tokenizer,\n\u001b[1;32m     40\u001b[0m                               input_,\n\u001b[1;32m     41\u001b[0m                               num_beams\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     42\u001b[0m                               num_return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     43\u001b[0m                               max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     47\u001b[0m response \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mreplace(input__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     48\u001b[0m response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Model/SHARE/Refactorizing/training/utils/model_utils.py:188\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(model, tokenizer, inputs, num_beams, num_beam_groups, do_sample, num_return_sequences, max_new_tokens)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(model,\n\u001b[1;32m    180\u001b[0m              tokenizer,\n\u001b[1;32m    181\u001b[0m              inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m              num_return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    186\u001b[0m              max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m--> 188\u001b[0m     generate_ids \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(inputs\u001b[38;5;241m.\u001b[39minput_ids,\n\u001b[1;32m    189\u001b[0m                                   num_beams\u001b[38;5;241m=\u001b[39mnum_beams,\n\u001b[1;32m    190\u001b[0m                                   num_beam_groups\u001b[38;5;241m=\u001b[39mnum_beam_groups,\n\u001b[1;32m    191\u001b[0m                                   do_sample\u001b[38;5;241m=\u001b[39mdo_sample,\n\u001b[1;32m    192\u001b[0m                                   num_return_sequences\u001b[38;5;241m=\u001b[39mnum_return_sequences,\n\u001b[1;32m    193\u001b[0m                                   max_new_tokens\u001b[38;5;241m=\u001b[39mmax_new_tokens)\n\u001b[1;32m    195\u001b[0m     result \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(generate_ids,\n\u001b[1;32m    196\u001b[0m                                     skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    197\u001b[0m                                     clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/peft/peft_model.py:1190\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1189\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1190\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1192\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/transformers/generation/utils.py:1671\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1664\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1665\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1666\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1667\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1668\u001b[0m     )\n\u001b[1;32m   1670\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1671\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[1;32m   1672\u001b[0m         input_ids,\n\u001b[1;32m   1673\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[1;32m   1674\u001b[0m         logits_warper\u001b[38;5;241m=\u001b[39mlogits_warper,\n\u001b[1;32m   1675\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[1;32m   1676\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m   1677\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[1;32m   1678\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[1;32m   1679\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1680\u001b[0m     )\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1683\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1685\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1686\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1691\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1692\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/transformers/generation/utils.py:2460\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2457\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2459\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2460\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\n\u001b[1;32m   2461\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs,\n\u001b[1;32m   2462\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2463\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   2464\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   2465\u001b[0m )\n\u001b[1;32m   2467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2468\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/transformers/models/gemma/modeling_gemma.py:1119\u001b[0m, in \u001b[0;36mGemmaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1116\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1119\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1120\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1121\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1122\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1123\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1124\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1125\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1126\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1127\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1128\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1129\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m   1130\u001b[0m )\n\u001b[1;32m   1132\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1133\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/transformers/models/gemma/modeling_gemma.py:912\u001b[0m, in \u001b[0;36mGemmaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    901\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    902\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    903\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    909\u001b[0m         cache_position,\n\u001b[1;32m    910\u001b[0m     )\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 912\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[1;32m    913\u001b[0m         hidden_states,\n\u001b[1;32m    914\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask,\n\u001b[1;32m    915\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m    916\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m    917\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    918\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    919\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m    920\u001b[0m     )\n\u001b[1;32m    922\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/transformers/models/gemma/modeling_gemma.py:666\u001b[0m, in \u001b[0;36mGemmaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    665\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 666\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[1;32m    667\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    669\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/transformers/models/gemma/modeling_gemma.py:187\u001b[0m, in \u001b[0;36mGemmaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(x))\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:797\u001b[0m, in \u001b[0;36mLinear8bitLt.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m x\u001b[38;5;241m.\u001b[39mdtype:\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 797\u001b[0m out \u001b[38;5;241m=\u001b[39m bnb\u001b[38;5;241m.\u001b[39mmatmul(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate)\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mhas_fp16_weights:\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mCB \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mCxB \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    801\u001b[0m         \u001b[38;5;66;03m# we converted 8-bit row major to turing/ampere format in the first inference pass\u001b[39;00m\n\u001b[1;32m    802\u001b[0m         \u001b[38;5;66;03m# we no longer need the row-major weight\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:556\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(A, B, out, state, threshold, bias)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threshold \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    555\u001b[0m     state\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m=\u001b[39m threshold\n\u001b[0;32m--> 556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MatMul8bitLt\u001b[38;5;241m.\u001b[39mapply(A, B, out, bias, state)\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/torch/autograd/function.py:598\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    602\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:395\u001b[0m, in \u001b[0;36mMatMul8bitLt.forward\u001b[0;34m(ctx, A, B, out, bias, state)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_igemmlt:\n\u001b[1;32m    394\u001b[0m     C32A, SA \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mtransform(CA, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 395\u001b[0m     out32, Sout32 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39migemmlt(C32A, state\u001b[38;5;241m.\u001b[39mCxB, SA, state\u001b[38;5;241m.\u001b[39mSB)\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m bias\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;66;03m# we apply the fused bias here\u001b[39;00m\n\u001b[1;32m    398\u001b[0m         output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmm_dequant(out32, Sout32, SCA, state\u001b[38;5;241m.\u001b[39mSCB, bias\u001b[38;5;241m=\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/COMEDY/lib/python3.11/site-packages/bitsandbytes/functional.py:2328\u001b[0m, in \u001b[0;36migemmlt\u001b[0;34m(A, B, SA, SB, out, Sout, dtype)\u001b[0m\n\u001b[1;32m   2326\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m formatB \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol_ampere\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mint32:\n\u001b[0;32m-> 2328\u001b[0m         has_error \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mcigemmlt_ampere_32(ptr, m, n, k, ptrA, ptrB, ptrC, ptrRowScale, lda, ldb, ldc)\n\u001b[1;32m   2329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2330\u001b[0m         has_error \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mcigemmlt_ampere_8(ptr, m, n, k, ptrA, ptrB, ptrC, ptrRowScale, lda, ldb, ldc)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bertscore_eval = load(\"bertscore\")\n",
    "rouge_eval = evaluate.load('rouge')\n",
    "bleu_eval = evaluate.load(\"bleu\")\n",
    "\n",
    "for prompt in json_data:\n",
    "    bert_score, rough_score, bleu_1, bleu_2, infer_sentence, ppl = evaluation_chat_system(2, prompt ,model, tokenizer,device, bertscore_eval, rouge_eval, bleu_eval)\n",
    "    bert.append(bert_score)\n",
    "    rough.append(rough_score)\n",
    "    bleu_1_list.append(bleu_1)\n",
    "    bleu_2_list.append(bleu_2)\n",
    "    infer.append(infer_sentence)\n",
    "    ppl_list.append(ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5898b12a-5d5c-442b-b8a5-3991efcd748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean(tensor_list):\n",
    "    # Move tensors to CPU and convert to numpy arrays\n",
    "    cpu_tensors = [t.cpu().numpy() for t in tensor_list]\n",
    "    # Calculate the mean\n",
    "    mean_value = np.mean(cpu_tensors)\n",
    "    return mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c9cb3ed2-9f5e-4c58-8a97-96e5bb94a94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      11553.602\n",
       "1       16.77277\n",
       "2      395.32742\n",
       "3      35.409416\n",
       "4      1100.4786\n",
       "         ...    \n",
       "661    23.148928\n",
       "662    47.768738\n",
       "663    28.175043\n",
       "664    26.082245\n",
       "665     45.05148\n",
       "Length: 666, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.Series([i.cpu().numpy() for i in ppl_list]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a1d6c140-e180-47fc-bc83-4f22a8878e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPL : nan, \n",
      "BertScore : 0.8401927087937031 \n",
      "rouge1 : 0.08406581663518085 \n",
      "rouge2 : 0.010053239872923192 \n",
      "rougeL : 0.07480809852389264 \n",
      "rougeLsum : 0.07480809852389264, \n",
      "bleu : 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ber = [i['precision'][0] for i in bert]\n",
    "\n",
    "rouge1 = np.mean([i['rouge1'] for i in rough])\n",
    "\n",
    "rouge2 = np.mean([i['rouge2'] for i in rough])\n",
    "\n",
    "rougeL = np.mean([i['rougeL'] for i in rough])\n",
    "\n",
    "rougeLsum = np.mean([i['rougeLsum'] for i in rough])\n",
    "\n",
    "mean_bleu = np.mean([i['bleu'] for i in bleu])\n",
    "\n",
    "print(f'PPL : {calculate_mean(ppl_list)}, \\nBertScore : {np.mean(ber)} \\nrouge1 : {rouge1} \\nrouge2 : {rouge2} \\nrougeL : {rougeL} \\nrougeLsum : {rougeLsum}, \\nbleu : {mean_bleu}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c0953c8b-23b8-4cf5-afad-8304aa19d37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0278158717434742"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(bleu_1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675fdb58-3472-469b-ab93-e60f7b35e79e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
