{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6cdda42-096c-48c3-b264-407ec7a3c06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads a JSON file with multiple JSON objects (one per line) and returns the data as a list of dictionaries.\n",
    "    \n",
    "    Args:||\n",
    "        file_path (str): The path to the JSON file.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of dictionaries containing the data from the JSON file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                try:\n",
    "                    json_obj = json.loads(line)\n",
    "                    data.append(json_obj)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"JSONDecodeError in line: {line.strip()}\")\n",
    "                    print(f\"Error message: {e}\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file at {file_path} does not exist.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ffa6f7-c5ae-462f-898a-55163009ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_without_tag(prompt):\n",
    "    prompts = prompt['prompt']\n",
    "\n",
    "    last_utter = f\"{prompt['last_speaker']} :\" \n",
    "\n",
    "    dialogue = prompts + last_utter\n",
    "    \n",
    "    return dialogue, prompt['last_speaker'], prompt['answer']\n",
    "    \n",
    "\n",
    "def extract_data_with_tag(prompt):\n",
    "    prompts = prompt['prompt']\n",
    "\n",
    "    last_utter = f\"{prompt['last_speaker']} : ({prompt['gold_tag']})\" \n",
    "\n",
    "    dialogue = prompts + last_utter\n",
    "    \n",
    "    return dialogue, prompt['last_speaker'], prompt['gold_tag'], prompt['answer']\n",
    "\n",
    "def distinct_ngrams(sentences, n):\n",
    "    \"\"\"\n",
    "    Calculate the distinct-n metric for a list of sentences.\n",
    "    \n",
    "    Args:\n",
    "        sentences (list of str): The list of sentences generated by the model.\n",
    "        n (int): The n-gram length.\n",
    "\n",
    "    Returns:\n",
    "        float: The distinct-n score.\n",
    "    \"\"\"\n",
    "    ngrams = Counter()\n",
    "    total_ngrams = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokens = sentence.split()\n",
    "        sentence_ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "        ngrams.update(sentence_ngrams)\n",
    "        total_ngrams += len(tokens) - n + 1\n",
    "    \n",
    "    return len(ngrams) / total_ngrams if total_ngrams > 0 else 0\n",
    "\n",
    "\n",
    "def get_ppl(text, model, tokenizer,device):\n",
    "\n",
    "    # Encode the input sentence\n",
    "    inputs = tokenizer(text, return_tensors='pt').to(device)\n",
    "    input_ids = inputs['input_ids']\n",
    "    \n",
    "    # Get the output logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "    \n",
    "    # Calculate the loss (cross entropy)\n",
    "    loss = outputs.loss.item()\n",
    "    \n",
    "    # Convert the loss to perplexity\n",
    "    perplexity = math.exp(loss)\n",
    "    \n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db1787f2-0d79-49be-9de8-ce82fdb060eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import re\n",
    "import torch\n",
    "import evaluate\n",
    "from evaluate import load\n",
    "current_dir = os.getcwd()\n",
    "episode_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(episode_dir)\n",
    "\n",
    "from utils.model_utils import get_peft_checkpoint, generate, get_peft_checkpoint_\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer)\n",
    "\n",
    "import torch\n",
    "import math\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def evaluation_chat_system(num, prompt , model, tokenizer, device, bert_eval,rough_eval):\n",
    "    \n",
    "    if num == 2:\n",
    "        print(\"This is a wo tag evaluation\")\n",
    "        print(prompt)\n",
    "        input__, person, utterance,  = extract_data_without_tag(prompt)\n",
    "        print(f'Last word -> {person} : \"{utterance}\"')\n",
    "        \n",
    "        input_ = tokenizer(input__, return_tensors = 'pt').to(device)     \n",
    "        output = generate(model,tokenizer,\n",
    "                                      input_,\n",
    "                                      num_beams=1,\n",
    "                                      num_return_sequences=1,\n",
    "                                      max_new_tokens=100)\n",
    "\n",
    "\n",
    "        \n",
    "        response = output.replace(input__, '')\n",
    "        response = response.split(\"\\n\")[0]\n",
    "        print(f\"prediction : {response}\")\n",
    "        print(f\"Real answer : {utterance}\")\n",
    "\n",
    "        reference = [utterance.split()]\n",
    "        candidate = response.split()\n",
    "\n",
    "            \n",
    "        output_list = [response.strip()]\n",
    "        last_utter_list = [utterance.strip()]\n",
    "        #evalation\n",
    "        bert_score = bert_eval.compute(predictions=output_list, references=last_utter_list, lang=\"en\")\n",
    "        rouge_score = rouge_eval.compute(predictions=output_list, references=last_utter_list)\n",
    "\n",
    "        ## bleu\n",
    "\n",
    "        weights_unigram = (1, 0, 0, 0)\n",
    "        bleu_unigram = sentence_bleu(reference, candidate, weights=weights_unigram, smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "        weights_bigram = (0.5, 0.5, 0, 0)\n",
    "        bleu_bigram = sentence_bleu(reference, candidate, weights=weights_bigram, smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "        ### ppl\n",
    "        ppl = get_ppl(response, model, tokenizer,device)\n",
    "        \n",
    "        print(f\"Bert Score : {bert_score}\")\n",
    "        print(f\"Rouge Score : {rouge_score}\")\n",
    "        print(f\"bleu 1/2 : {bleu_unigram} {bleu_bigram}\")\n",
    "        print(f\"ppl : {ppl}\")\n",
    "        return bert_score, rouge_score, bleu_unigram, bleu_bigram, response ,ppl\n",
    "    \n",
    "    \n",
    "    if num == 3:\n",
    "        print(\"This is with tag evaluation\")\n",
    "        print(prompt)\n",
    "        input__ , person, trait, utterance = extract_data_with_tag(prompt)\n",
    "        print(f'Last word -> {person} : ({trait}) \"{utterance}\"')\n",
    "        \n",
    "        input_ = tokenizer(input__, return_tensors = 'pt').to(device)\n",
    "     \n",
    "        output = generate(model,tokenizer,\n",
    "                                      input_,\n",
    "                                      num_beams=1,\n",
    "                                      num_return_sequences=1,\n",
    "                                      max_new_tokens=100)\n",
    "\n",
    "\n",
    "        ### utterance : correct answer\n",
    "        ### response : Model-generated answer\n",
    "\n",
    "        response = output.replace(input__, '').split(\"\\n\")[0]\n",
    "        \n",
    "        print(f\"prediction : {response}\")\n",
    "        print(f\"Real answer : {utterance}\")\n",
    "        \n",
    "        output_list = [response.strip()]\n",
    "        last_utter_list = [utterance.strip()]\n",
    "\n",
    "        reference = [utterance.split()]\n",
    "        candidate = response.split()\n",
    "\n",
    "        #evalation\n",
    "        bert_score = bert_eval.compute(predictions=output_list, references=last_utter_list, lang=\"en\")\n",
    "        rouge_score = rouge_eval.compute(predictions=output_list, references=last_utter_list)\n",
    "\n",
    "        ## bleu\n",
    "\n",
    "        weights_unigram = (1, 0, 0, 0)\n",
    "        bleu_unigram = sentence_bleu(reference, candidate, weights=weights_unigram, smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "        weights_bigram = (0.5, 0.5, 0, 0)\n",
    "        bleu_bigram = sentence_bleu(reference, candidate, weights=weights_bigram, smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "        ### ppl\n",
    "        ppl = get_ppl(response, model, tokenizer,device)\n",
    "        \n",
    "        print(f\"Bert Score : {bert_score}\")\n",
    "        print(f\"Rouge Score : {rouge_score}\")\n",
    "        print(f\"bleu 1/2 : {bleu_unigram} {bleu_bigram}\")\n",
    "        print(f\"ppl : {ppl}\")\n",
    "\n",
    "        \n",
    "        return bert_score, rouge_score, bleu_unigram, bleu_bigram, response ,ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b6e550-1516-4860-8d0c-d2d280e7cc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64bd7be7b274591a48ab0336e426fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e801c088a04919b4bb81add637ddec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17475a2665d94ffaa4e77d8b506c6a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/16.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = 'chano12/llama_without_tag'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, tokenizer = get_peft_checkpoint(path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd21ab89-9aea-4907-a847-62cfb090e1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "path = '/home/chanho/Model/SHARE/Refactorizing/result/dataset/test_without_tag.json'\n",
    "\n",
    "json_data = read_json_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6a05f1c-a76e-423f-b3c4-3ad53bea4ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = []\n",
    "rough = []\n",
    "bleu_1_list = []\n",
    "bleu_2_list = []\n",
    "infer = []\n",
    "ppl_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5acf90aa-20e6-4b88-b067-b744aaffb3b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLOLA: Hello, Mr. Neff. It's me.\\nNEFF: Something the matter?\\nLOLA: I've been waiting for you.\\nNEFF: For me? What for?\\nLOLA: I thought you could let me ride with you, if you're going my way.\\n\\n\", 'answer': \"Which way would that be? Oh, sure. Vermont and Franklin. North- west corner, wasn't it? Be glad to, Miss Dietrichson.\", 'gold_tag': 'NEFF is familiar with the local geographic area , NEFF references specific streets', 'last_speaker': 'NEFF'}\n",
      "Last word -> NEFF : \"Which way would that be? Oh, sure. Vermont and Franklin. North- west corner, wasn't it? Be glad to, Miss Dietrichson.\"\n",
      "prediction :  I don't know. I'm on my way to see Mr. Gittes.\n",
      "Real answer : Which way would that be? Oh, sure. Vermont and Franklin. North- west corner, wasn't it? Be glad to, Miss Dietrichson.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.855631947517395], 'recall': [0.818554699420929], 'f1': [0.8366827368736267], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17647058823529413, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.040112106159998544 0.013303680568361875\n",
      "ppl : 17.192608633564788\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEFF: Roller skating, eh? You like roller skating?\\nLOLA: I can take it or leave it.\\nNEFF: Only tonight you're leaving it?\\nLOLA: Yes, I am. You see, Mr. Neff, I'm having a very tough time at home. My father doesn't understand me and Phyllis hates me.\\nNEFF: That does sound tough, all right.\\nLOLA: That's why I have to lie sometimes.\\nNEFF: You mean it's not Vermont and Franklin.\\nLOLA: It's Vermont and Franklin all right. Only it's not Anne Matthews. It's Nino Zachetti. You won't tell on me, will you?\\nNEFF: I'd have to think it over.\\nLOLA: Nino's not what my father says at all. He just had bad luck. He was doing pre-med at U.S.C. and working nights as an usher in a theater downtown. He got behind in his credits and flunked out. Then he lost his job for talking back. He's so hot- headed.\\nNEFF: That comes expensive, doesn't it?\\nLOLA: I guess my father thinks nobody's good enough for his daughter except maybe the guy that owns Standard Oil. Would you like a stick of gum?\\nNEFF: Never use it, thanks.\\nLOLA: I can't give Nino up. I wish father could see it my way.\\nNEFF: It'll straighten out all right, Miss\\n\\n\", 'answer': 'I suppose it will sometime. This is the corner right here, Mr. Neff. There he is. By the bus stop.', 'gold_tag': \"LOLA's temporal information: Lola is undergoing a challenging time at home presently, and her relationship with Nino is also current\", 'last_speaker': 'LOLA'}\n",
      "Last word -> LOLA : \"I suppose it will sometime. This is the corner right here, Mr. Neff. There he is. By the bus stop.\"\n",
      "prediction :  You don't think I'm crazy?\n",
      "Real answer : I suppose it will sometime. This is the corner right here, Mr. Neff. There he is. By the bus stop.\n",
      "Bert Score : {'precision': [0.8116768598556519], 'recall': [0.8412067890167236], 'f1': [0.8261780142784119], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07407407407407408, 'rouge2': 0.0, 'rougeL': 0.07407407407407408, 'rougeLsum': 0.07407407407407408}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 17.8287684948192\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLOLA: Hello, Mr. Neff.\\nNEFF: Hello.\\nLOLA: Lola Dietrichson. Don't you remember me?\\nNEFF: Yes. Of course.\\nLOLA: Could I talk to you, just for a few minutes? Somewhere where we can be alone?\\n\\n\", 'answer': 'Sure. Come on into my office.', 'gold_tag': 'NEFF has an office , NEFF implies a professional occupation', 'last_speaker': 'NEFF'}\n",
      "Last word -> NEFF : \"Sure. Come on into my office.\"\n",
      "prediction :  I'm afraid that's impossible. I'm in the middle of something.\n",
      "Real answer : Sure. Come on into my office.\n",
      "Bert Score : {'precision': [0.8509466052055359], 'recall': [0.8717133402824402], 'f1': [0.8612048029899597], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13.43974731110096\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEFF: Is it something to do with -- what happened?\\nLOLA: Yes, Mr. Neff. It's about my father's death.\\n\\n\", 'answer': \"I'm terribly sorry, Miss Dietrichson.\", 'gold_tag': \"NEFF is aware of Lola's father's death , NEFF is empathetic about it\", 'last_speaker': 'NEFF'}\n",
      "Last word -> NEFF : \"I'm terribly sorry, Miss Dietrichson.\"\n",
      "prediction :  I see. Well, Lola, I'm afraid I can't help you.\n",
      "Real answer : I'm terribly sorry, Miss Dietrichson.\n",
      "Bert Score : {'precision': [0.8819713592529297], 'recall': [0.8690013289451599], 'f1': [0.8754383325576782], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2222222222222222, 'rouge2': 0.12500000000000003, 'rougeL': 0.2222222222222222, 'rougeLsum': 0.2222222222222222}\n",
      "bleu 1/2 : 0.10000000000000002 0.03333333333333335\n",
      "ppl : 17.8147254329267\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEFF: Why are you crying? You won't tell me?\\nLOLA: Of course I will, Walter. I wouldn't tell anybody else but you. It's about Nino.\\nNEFF: Zachetti? What about him?\\nLOLA: They killed my father together. He and Phyllis. He helped her do it. I know he did.\\nNEFF: What makes you say that?\\nLOLA: I've been following him. He's at her house, night after night. It was Phyllis and him all the time. Maybe he was going with me just for a blind. And the night of the murder --\\nNEFF: You promised not to talk that way any more.\\nLOLA: -- he was supposed to pick me up after a lecture at U.C.L.A. -- but he never showed up. He said he was sick. Sick! He couldn't show up, because the train was leaving with my father on it. Maybe I'm just crazy. Maybe it's all just in my mind.\\nNEFF: Sure, it's all in your mind.\\n\\n\", 'answer': 'I only wish it was, Walter, because I still love him.', 'gold_tag': 'LOLA still harbors love for Nino', 'last_speaker': 'LOLA'}\n",
      "Last word -> LOLA : \"I only wish it was, Walter, because I still love him.\"\n",
      "prediction :  I know what I know.\n",
      "Real answer : I only wish it was, Walter, because I still love him.\n",
      "Bert Score : {'precision': [0.8776254653930664], 'recall': [0.8603264093399048], 'f1': [0.8688898086547852], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25000000000000006, 'rouge2': 0.0, 'rougeL': 0.25000000000000006, 'rougeLsum': 0.25000000000000006}\n",
      "bleu 1/2 : 0.12047768476488081 0.030119421191220207\n",
      "ppl : 97.82385922294172\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: Our son just called me a bitch.\\n\\n', 'answer': \"You're not a bitch.\", 'gold_tag': 'EDDIE is a supportive husband , EDDIE is a supportive father', 'last_speaker': 'EDDIE'}\n",
      "Last word -> EDDIE : \"You're not a bitch.\"\n",
      "prediction :  What did he say?\n",
      "Real answer : You're not a bitch.\n",
      "Bert Score : {'precision': [0.8521308898925781], 'recall': [0.8684384822845459], 'f1': [0.8602073788642883], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 107.67877491137365\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: So let me get this straight. No airline will claim ownership of the engine. So we have to wait for the FAA to decide who fixes my roof. Fuck that. We're taking the money out of savings.\\n\\n\", 'answer': '(quoting Rod Serling) You are entering a new dimension of sight and sound...', 'gold_tag': 'EDDIE is familiar with the work of Rod Serling , EDDIE has a potential interest in science fiction or classic television', 'last_speaker': 'EDDIE'}\n",
      "Last word -> EDDIE : \"(quoting Rod Serling) You are entering a new dimension of sight and sound...\"\n",
      "prediction :  I think you're right.\n",
      "Real answer : (quoting Rod Serling) You are entering a new dimension of sight and sound...\n",
      "Bert Score : {'precision': [0.8675065040588379], 'recall': [0.8349564075469971], 'f1': [0.8509203195571899], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 35.05488740792425\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: He's too old to be behaving this way.\\n\\n\", 'answer': 'Oh, I say we buy him a moped.', 'gold_tag': 'EDDIE suggests buying a moped , EDDIE has a pragmatic, solution-oriented attitude', 'last_speaker': 'EDDIE'}\n",
      "Last word -> EDDIE : \"Oh, I say we buy him a moped.\"\n",
      "prediction :  I'm not sure you're the right person to be talking to him.\n",
      "Real answer : Oh, I say we buy him a moped.\n",
      "Bert Score : {'precision': [0.8776076436042786], 'recall': [0.8765917420387268], 'f1': [0.8770993947982788], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.141038547890954\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWERNER: You've been here since you were a baby -- you know nothing of America --\\nJULIUS: I know it is the cradle of democracy and the land of the free; besides, I speak twelve languages -- I'm sure I can get a job.\\nWERNER: They're a simple people; rather primitive, not like us.\\n\\n\", 'answer': 'My brother will look after me.', 'gold_tag': 'JULIUS believes his brother will take care of him once he reaches America', 'last_speaker': 'JULIUS'}\n",
      "Last word -> JULIUS : \"My brother will look after me.\"\n",
      "prediction :  I am not a primitive, I am a civilized man.\n",
      "Real answer : My brother will look after me.\n",
      "Bert Score : {'precision': [0.8775251507759094], 'recall': [0.8770922422409058], 'f1': [0.8773086071014404], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 25.458333676895474\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJULIUS: It's your only copy --\\nWERNER: -- My need for it is only sentimental -- yours may be practical --\\nJULIUS: Thank you -- I'll miss you.\\n\\n\", 'answer': \"I'll miss you.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'WERNER'}\n",
      "Last word -> WERNER : \"I'll miss you.\"\n",
      "prediction :  I'll miss you too.\n",
      "Real answer : I'll miss you.\n",
      "Bert Score : {'precision': [0.9595052003860474], 'recall': [0.9900333881378174], 'f1': [0.9745302796363831], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.888888888888889, 'rouge2': 0.8571428571428571, 'rougeL': 0.888888888888889, 'rougeLsum': 0.888888888888889}\n",
      "bleu 1/2 : 0.5 0.408248290463863\n",
      "ppl : 59.80568317122445\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWERNER: And...?\\nJULIUS: Well, if a woman loved my brother enough to marry him, she might have a sister who'd feel the same way about me. That often happens with twins, you know.\\nWERNER: Julius -- please -- don't get your hopes up. Your brother doesn't even know you exist.\\n\\n\", 'answer': \"Of course he does. I've always known there was something missing in my life! And deep down, I'm sure Vincent feels the same way! He's probably just like meeeee!\", 'gold_tag': \"Julius has an optimist and romantic outlook on life , Julius has a twin brother whom he hasn't met yet\", 'last_speaker': 'JULIUS'}\n",
      "Last word -> JULIUS : \"Of course he does. I've always known there was something missing in my life! And deep down, I'm sure Vincent feels the same way! He's probably just like meeeee!\"\n",
      "prediction :  That's true. But if he did, I think he'd be a very special friend to me.\n",
      "Real answer : Of course he does. I've always known there was something missing in my life! And deep down, I'm sure Vincent feels the same way! He's probably just like meeeee!\n",
      "Bert Score : {'precision': [0.8827812671661377], 'recall': [0.8546667098999023], 'f1': [0.8684965372085571], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16, 'rouge2': 0.0, 'rougeL': 0.12000000000000002, 'rougeLsum': 0.12000000000000002}\n",
      "bleu 1/2 : 0.027734206880067492 0.009057954036926929\n",
      "ppl : 15.195748606017466\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBESS: Whatever is the matter with you? Your behaviour is so out of the ordinary.\\n\\n', 'answer': 'I just feel like keeping to myself today...', 'gold_tag': 'GEORGIANA is introverted , GEORGIANA prefers solitude at times', 'last_speaker': 'GEORGIANA'}\n",
      "Last word -> GEORGIANA : \"I just feel like keeping to myself today...\"\n",
      "prediction :  I'm sorry. I'm a bit on edge at the moment. I've just been feeling very stressed.\n",
      "Real answer : I just feel like keeping to myself today...\n",
      "Bert Score : {'precision': [0.8691067695617676], 'recall': [0.8606020212173462], 'f1': [0.8648334741592407], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14814814814814814, 'rouge2': 0.0, 'rougeL': 0.14814814814814814, 'rougeLsum': 0.14814814814814814}\n",
      "bleu 1/2 : 0.0625 0.02041241452319315\n",
      "ppl : 11.079594841325136\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGEORGIANA: I may not have the authority to remove you from this house, but I can at least order you out of my room.\\nBESS: Won't you please let me explain?\\nGEORGIANA: There is nothing to explain. I trusted you, I made you my confidante, and you repaid me by stealing what is mine.\\nBESS: This is my only chance of ever seeing my children again. The Duke is the most powerful peer in England. He is my only chance.\\nGEORGIANA: There are limits to the sacrifices one makes to see one's children.\\nBESS: No, there aren't. No limits whatsoever.\\n\\n\", 'answer': 'Get out of here. We have nothing more to say to one another.', 'gold_tag': 'GEORGIANA has a strong sense of personal boundaries, property, and trust', 'last_speaker': 'GEORGIANA'}\n",
      "Last word -> GEORGIANA : \"Get out of here. We have nothing more to say to one another.\"\n",
      "prediction :  You have no right to be here.\n",
      "Real answer : Get out of here. We have nothing more to say to one another.\n",
      "Bert Score : {'precision': [0.8945574164390564], 'recall': [0.8783262372016907], 'f1': [0.8863675594329834], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0.18187407671869282 0.03586605161151225\n",
      "ppl : 45.22070906968372\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGEORGIANA: Thank you for coming.\\nBESS: I couldn’t not be with you.\\nGEORGIANA: I count it a triumph we have become friends again when fate has been so intent on keeping us rivals.\\nBESS: So do I. The Duke is for my boys only. You are for me.\\nGEORGIANA: Bess, how will I do this?\\n\\n', 'answer': 'For Charlotte, for Harryo, for little G, for Hart...', 'gold_tag': \"BESS has children she refers to as 'my boys' , GEORGIANA is a mother to Charlotte, Harryo, Little G, and Hart\", 'last_speaker': 'BESS'}\n",
      "Last word -> BESS : \"For Charlotte, for Harryo, for little G, for Hart...\"\n",
      "prediction :  You will do it. I’m counting on you.\n",
      "Real answer : For Charlotte, for Harryo, for little G, for Hart...\n",
      "Bert Score : {'precision': [0.8546847105026245], 'recall': [0.79642653465271], 'f1': [0.8245278000831604], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.169931893675557\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDR. SHIRLEY: What are you doing?\\nLIP: I gotta take a leak.\\nDR. SHIRLEY: Here? Now?\\n\\n', 'answer': 'What, you want me to piss my pants?', 'gold_tag': 'Everyday Language', 'last_speaker': 'LIP'}\n",
      "Last word -> LIP : \"What, you want me to piss my pants?\"\n",
      "prediction :  What? You got a problem with that?\n",
      "Real answer : What, you want me to piss my pants?\n",
      "Bert Score : {'precision': [0.8801946043968201], 'recall': [0.8613497018814087], 'f1': [0.8706701993942261], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.26666666666666666, 'rouge2': 0.15384615384615383, 'rougeL': 0.26666666666666666, 'rougeLsum': 0.26666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 36.9240593591197\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLIP: What do you want?\\n\\n', 'answer': 'I’m fine. Thank you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DR. SHIRLEY'}\n",
      "Last word -> DR. SHIRLEY : \"I’m fine. Thank you.\"\n",
      "prediction :  I want you to get a blood sample.\n",
      "Real answer : I’m fine. Thank you.\n",
      "Bert Score : {'precision': [0.877866804599762], 'recall': [0.8765722513198853], 'f1': [0.877219021320343], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3076923076923077, 'rouge2': 0.0, 'rougeL': 0.3076923076923077, 'rougeLsum': 0.3076923076923077}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 70.51423133166325\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLIP: This can’t be it. Says right here......cozy as your own home... This place looks like my ass.\\nDR. SHIRLEY: This is the place.\\n\\n', 'answer': 'If you need anything, I’ll be up the street at the Easton Inn. So...see you tomorrow.', 'gold_tag': 'LIP offers to be available for DR. SHIRLEY if needed , LIP will be at the Easton Inn up the street , LIP plans to see DR. SHIRLEY the following day', 'last_speaker': 'LIP'}\n",
      "Last word -> LIP : \"If you need anything, I’ll be up the street at the Easton Inn. So...see you tomorrow.\"\n",
      "prediction :  You sure?\n",
      "Real answer : If you need anything, I’ll be up the street at the Easton Inn. So...see you tomorrow.\n",
      "Bert Score : {'precision': [0.7982956171035767], 'recall': [0.8150286674499512], 'f1': [0.806575357913971], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09999999999999999, 'rouge2': 0.0, 'rougeL': 0.09999999999999999, 'rougeLsum': 0.09999999999999999}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 897.5482519729941\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLIP: What the hell’s wrong with you?! You go in there alone?\\nDR. SHIRLEY: I apologize for putting you in that position, Tony.\\nLIP: I don’t understand you, Doc, honest to God. Why couldn’t you just drink here--you got a whole bottle?\\nDR. SHIRLEY: I needed some air.\\nLIP: Air?! Don’t you know where you are?\\nDR. SHIRLEY: Does the geography really matter?\\nLIP: What?\\nDR. SHIRLEY: If I walked into a bar in your neighborhood, would this conversation be any different?\\nLIP: From now on you don’t go nowhere without me. Nowhere!\\nDR. SHIRLEY: Tony...Do you really have a gun?\\n\\n', 'answer': '‘Course not. Now get some rest. You got a big show tomorrow night. Now where’s your room doc?', 'gold_tag': 'DR. SHIRLEY has a show the following night', 'last_speaker': 'LIP'}\n",
      "Last word -> LIP : \"‘Course not. Now get some rest. You got a big show tomorrow night. Now where’s your room doc?\"\n",
      "prediction :  Yeah, I got a gun, yeah.\n",
      "Real answer : ‘Course not. Now get some rest. You got a big show tomorrow night. Now where’s your room doc?\n",
      "Bert Score : {'precision': [0.8735626339912415], 'recall': [0.8387726545333862], 'f1': [0.8558141589164734], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16, 'rouge2': 0.08695652173913045, 'rougeL': 0.16, 'rougeLsum': 0.16}\n",
      "bleu 1/2 : 0.045111761078870896 0.03494341987531099\n",
      "ppl : 53.03440364418504\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLIP: “Betty bought... a bit of buttah... but she found the buttah bittah...”\\nDR. SHIRLEY: Not buttah... butter. Say the “er.”\\nLIP: Er.\\nDR. SHIRLEY: “So Betty bought a bit of better butter to make the bitter butter better...”\\nLIP: “So Betty bit a buttah...”\\nDR. SHIRLEY: Don’t be lazy--enunciate. “So Betty bought a bit of better butter...”\\nLIP: “So, Betty bit a better buttah--” this is bullshit.\\n\\n', 'answer': 'No, you need to start somewhere. exercises. These drills will strengthen your speech muscles.', 'gold_tag': 'DR. SHIRLEY may be in a teaching or coaching role', 'last_speaker': 'DR. SHIRLEY'}\n",
      "Last word -> DR. SHIRLEY : \"No, you need to start somewhere. exercises. These drills will strengthen your speech muscles.\"\n",
      "prediction :  “That’s right. It’s bullshit. I’m a linguist.”\n",
      "Real answer : No, you need to start somewhere. exercises. These drills will strengthen your speech muscles.\n",
      "Bert Score : {'precision': [0.8548352122306824], 'recall': [0.8504554033279419], 'f1': [0.8526397347450256], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.421839368676274\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDR. SHIRLEY: They were wrong for the way they treated me, and you rewarded them.\\nLIP: I was hired to make sure you get from one show to the next. How I do it shouldn’t matter to you.\\nDR. SHIRLEY: I just wish you hadn’t paid them off.\\nLIP: I did what I had to do. You know, if this got out it would kill your career.\\nDR. SHIRLEY: Okay, Tony, quit your phony altruism and concern for my career.\\nLIP: What the hell does that mean?\\nDR. SHIRLEY: You were only thinking about yourself back there, because you know if I miss a show, it comes out of your pocket.\\nLIP: Of course I don’t want you to miss a show, you ungrateful bastard! You think I’m doing this for my health?! Tonight I saved your ass, so show a little appreciation. Besides, I told you never to go nowhere without me!\\n\\n', 'answer': 'I assumed you would want this to be the exception.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DR. SHIRLEY'}\n",
      "Last word -> DR. SHIRLEY : \"I assumed you would want this to be the exception.\"\n",
      "prediction :  I’m not going anywhere without you.\n",
      "Real answer : I assumed you would want this to be the exception.\n",
      "Bert Score : {'precision': [0.8671262264251709], 'recall': [0.876456618309021], 'f1': [0.8717664480209351], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23529411764705882, 'rouge2': 0.0, 'rougeL': 0.23529411764705882, 'rougeLsum': 0.23529411764705882}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 42.867577391414585\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLIP: Should I try to find you some make- up or somethin’ before the show?\\nDR. SHIRLEY: I’m fine.\\nLIP: You sure?\\n\\n', 'answer': 'I said I’m fine.', 'gold_tag': 'DR. SHIRLEY expresses that he is fine even without makeup before a show', 'last_speaker': 'DR. SHIRLEY'}\n",
      "Last word -> DR. SHIRLEY : \"I said I’m fine.\"\n",
      "prediction :  I’m sure.\n",
      "Real answer : I said I’m fine.\n",
      "Bert Score : {'precision': [0.9149825572967529], 'recall': [0.8967915773391724], 'f1': [0.9057957530021667], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.5, 'rouge2': 0.3333333333333333, 'rougeL': 0.5, 'rougeLsum': 0.5}\n",
      "bleu 1/2 : 0.18393972058572117 0.082260343798398\n",
      "ppl : 203.07710981241394\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLIP: So, how’d you learn how to play so good, Doc?\\nDR. SHIRLEY: My mother. She taught me how to play on an old spinet. Soon as I could walk, we’d travel around the Florida panhandle and I’d put on little shows in parishes and halls. A man who had seen me play arranged for me to study at the Leningrad Conservatory of Music.\\nLIP: So that’s where they taught you all them songs you play?\\nDR. SHIRLEY: Actually, I was trained to play classical music. Brahms, Franz Liszt, Chopin--it’s all I ever wanted to play. But I was persuaded by my record company to pursue a career in popular music instead. They told me audiences would never accept a black pianist on the classical stage. Wanted to turn me into just another “colored entertainer.” You know, the guy who smokes while he’s playing, who puts a glass of whisky on the piano and then gets mad when he’s not respected like Arthur Rubinstein. Well, you don’t see Arthur Rubenstein smoking and putting a drink on his piano.\\nLIP: Personally, if you stuck to that classic stuff I think it would’ve been a big mistake.\\nDR. SHIRLEY: A mistake? Performing the music I trained my entire life to play?\\nLIP: Trained? What are you, a seal? Anyone can sound like Beethoven or Joe Pan or them other guys you said. But your music, what you do, only you can do, and nobody can train for that.\\n\\n', 'answer': 'Thank you, Tony. But...not everyone can play Chopin...not the way I can.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DR. SHIRLEY'}\n",
      "Last word -> DR. SHIRLEY : \"Thank you, Tony. But...not everyone can play Chopin...not the way I can.\"\n",
      "prediction :  You think I’m some kind of genius?\n",
      "Real answer : Thank you, Tony. But...not everyone can play Chopin...not the way I can.\n",
      "Bert Score : {'precision': [0.8533979654312134], 'recall': [0.8461052775382996], 'f1': [0.8497359752655029], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 47.50959235189181\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDR. SHIRLEY: I need sleep.\\nLIP: Okay, I’ll pull over at the next place we see and I’ll sneak you into my room.\\nDR. SHIRLEY: No. No. I refuse to stay at an establishment that doesn’t want me.\\n\\n', 'answer': 'Okay.', 'gold_tag': 'Everyday Language', 'last_speaker': 'LIP'}\n",
      "Last word -> LIP : \"Okay.\"\n",
      "prediction :  Dr. Shirley, I understand, but I’m afraid you’re not in any shape to travel.\n",
      "Real answer : Okay.\n",
      "Bert Score : {'precision': [0.8340128660202026], 'recall': [0.9336098432540894], 'f1': [0.8810054063796997], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.51605949020421\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDR. SHIRLEY: If we leave right now, I think you can make it.\\nLIP: Make what?\\nDR. SHIRLEY: Christmas Eve.\\nLIP: Don’t ever flash a wad of cash in a\\n\\n', 'answer': 'I knew you had a gun!', 'gold_tag': \"DR. SHIRLEY is aware of LIP's concealed weapon , LIP carries a gun\", 'last_speaker': 'DR. SHIRLEY'}\n",
      "Last word -> DR. SHIRLEY : \"I knew you had a gun!\"\n",
      "prediction :  Lip, Lip, Lip, you are so immature.\n",
      "Real answer : I knew you had a gun!\n",
      "Bert Score : {'precision': [0.8277631998062134], 'recall': [0.8804490566253662], 'f1': [0.8532936573028564], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0.14285714285714285 0.048795003647426664\n",
      "ppl : 80.4597694670563\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLIP: Doc, my eyes are stingin’, I might need to pull over.\\n\\n', 'answer': 'Keep going as long as you can,', 'gold_tag': 'Everyday Language', 'last_speaker': 'DR. SHIRLEY'}\n",
      "Last word -> DR. SHIRLEY : \"Keep going as long as you can,\"\n",
      "prediction :  Pull over? I think you're just fine.\n",
      "Real answer : Keep going as long as you can,\n",
      "Bert Score : {'precision': [0.826840877532959], 'recall': [0.7983381748199463], 'f1': [0.8123395442962646], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 74.20962253542858\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLIP: That’s it. I’m pulling us into the next motel.\\nDR. SHIRLEY: Keep going, Tony, you can make it.\\n\\n', 'answer': 'I can’t keep my eyes open, Doc--I’m gettin’ hytnotized by the snow. I think my brain’s gonna explode.', 'gold_tag': 'LIP is willing to assert his boundaries and needs , LIP is extremely tired and struggling to stay awake', 'last_speaker': 'LIP'}\n",
      "Last word -> LIP : \"I can’t keep my eyes open, Doc--I’m gettin’ hytnotized by the snow. I think my brain’s gonna explode.\"\n",
      "prediction :  I’m not gonna make it, Doc. I’m out of gas.\n",
      "Real answer : I can’t keep my eyes open, Doc--I’m gettin’ hytnotized by the snow. I think my brain’s gonna explode.\n",
      "Bert Score : {'precision': [0.928937554359436], 'recall': [0.8700946569442749], 'f1': [0.8985537886619568], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.29411764705882354, 'rouge2': 0.125, 'rougeL': 0.23529411764705885, 'rougeLsum': 0.23529411764705885}\n",
      "bleu 1/2 : 0.04493289641172216 0.014977632137240725\n",
      "ppl : 20.005113025402107\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAMELA: We need to get in there.\\n\\n', 'answer': \"I'm working on it.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'CRONIN'}\n",
      "Last word -> CRONIN : \"I'm working on it.\"\n",
      "prediction :  The airlock is locked.\n",
      "Real answer : I'm working on it.\n",
      "Bert Score : {'precision': [0.8760364055633545], 'recall': [0.8917697668075562], 'f1': [0.8838330507278442], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 303.6317274347754\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCRONIN: Looks like he's been detained.\\nPAMELA: Who's going? Us?\\nCRONIN: There's only a Consulate, they sent a field officer out half an hour ago --\\n\\n\", 'answer': \"Then get a number, they need to know who they're dealing with.\", 'gold_tag': 'PAMELA wants to acquire a number, suggesting there is an immediate need or urgency to identify the person they are dealing with', 'last_speaker': 'PAMELA'}\n",
      "Last word -> PAMELA : \"Then get a number, they need to know who they're dealing with.\"\n",
      "prediction :  A field officer? What is that?\n",
      "Real answer : Then get a number, they need to know who they're dealing with.\n",
      "Bert Score : {'precision': [0.8365167379379272], 'recall': [0.8214373588562012], 'f1': [0.8289085030555725], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473684, 'rouge2': 0.0, 'rougeL': 0.10526315789473684, 'rougeLsum': 0.10526315789473684}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 138.22299596464688\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCRONIN: -- Kurt's reopening all the wyfi and sat\\n\\n\", 'answer': '-- uplink all relevant files to Kim -- -- and I want them to contact anyone who had anything to do with Treadstone --', 'gold_tag': 'PAMELA holds a senior position , PAMELA can command the uplinking of files , PAMELA is likely in intelligence or law enforcement , PAMELA can order others to contact individuals related to \"Treadstone\" , PAMELA is making immediate demands concerning information about \"Treadstone\"', 'last_speaker': 'PAMELA'}\n",
      "Last word -> PAMELA : \"-- uplink all relevant files to Kim -- -- and I want them to contact anyone who had anything to do with Treadstone --\"\n",
      "prediction :  -- So what's the deal?\n",
      "Real answer : -- uplink all relevant files to Kim -- -- and I want them to contact anyone who had anything to do with Treadstone --\n",
      "Bert Score : {'precision': [0.8591610193252563], 'recall': [0.8160755634307861], 'f1': [0.8370642066001892], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0.004474154371233121 0.0015818524479871868\n",
      "ppl : 57.261494679577694\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCRONIN: The room he checked into was across the hall -- why, why would he come here?\\nPAMELA: He must've had a reason. That's how they were trained.\\n\\n\", 'answer': 'He went out the window in here...', 'gold_tag': 'CRONIN is a problem solver or investigative type', 'last_speaker': 'CRONIN'}\n",
      "Last word -> CRONIN : \"He went out the window in here...\"\n",
      "prediction :  He was trained to be a killer.\n",
      "Real answer : He went out the window in here...\n",
      "Bert Score : {'precision': [0.8698941469192505], 'recall': [0.8621447682380676], 'f1': [0.866002082824707], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.14285714285714285 0.048795003647426664\n",
      "ppl : 39.786833966630205\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCRONIN: You're sure?\\nPAMELA: What? The tapes?\\n\\n\", 'answer': 'Hold on... Yep. And Abbott just direct dialed Moscow', 'gold_tag': \"CRONIN is in a job that deals with tapes and important direct calls , CRONIN's job is possibly in a government agency or high-level corporate position\", 'last_speaker': 'CRONIN'}\n",
      "Last word -> CRONIN : \"Hold on... Yep. And Abbott just direct dialed Moscow\"\n",
      "prediction :  Yes.\n",
      "Real answer : Hold on... Yep. And Abbott just direct dialed Moscow\n",
      "Bert Score : {'precision': [0.9414406418800354], 'recall': [0.8261995315551758], 'f1': [0.8800635933876038], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2104.611116571625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWALTON: You are now an Erewhon inmate -- a citizen of nowhere. Human rights zealots, the Geneva convention and the P.C. police have no authority here. You have no right... When I say your ass belongs to me -- I mean it. Bend over. Step into them. Don't sniff 'em, you perv. Just step into them.\\nARCHER: They're too tight.\\n\\n\", 'answer': \"So's a noose. Now keep your mouth shut. The prison's one big magnetic field. The boots'll tell us where you are -- every second of the day. I've got fifty bucks says you're dead by dinner. Don't disappoint me.\", 'gold_tag': \"WALTON has a wager on ARCHER's survival till dinner , ARCHER being threatened with potential death by dinner\", 'last_speaker': 'WALTON'}\n",
      "Last word -> WALTON : \"So's a noose. Now keep your mouth shut. The prison's one big magnetic field. The boots'll tell us where you are -- every second of the day. I've got fifty bucks says you're dead by dinner. Don't disappoint me.\"\n",
      "prediction :  I told you. They are your new home. They are the only home you have now. So you will learn to love them, like the little girl in the white nightgown.\n",
      "Real answer : So's a noose. Now keep your mouth shut. The prison's one big magnetic field. The boots'll tell us where you are -- every second of the day. I've got fifty bucks says you're dead by dinner. Don't disappoint me.\n",
      "Bert Score : {'precision': [0.8517472147941589], 'recall': [0.8364608883857727], 'f1': [0.8440348505973816], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.26666666666666666, 'rouge2': 0.0, 'rougeL': 0.10666666666666667, 'rougeLsum': 0.10666666666666667}\n",
      "bleu 1/2 : 0.09968327598207843 0.016021845004714024\n",
      "ppl : 13.471793062879721\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARCHER: What? He started it! When I get out of here --\\nWALTON: You'll what?\\nARCHER: I'm going to have you fired.\\n\\n\", 'answer': \"That's two strikes, Dubov. One more and you know where you're going. Back to your 'suites' -- or no\", 'gold_tag': 'WALTON holds a position of authority, possibly a supervisor or manager , WALTON has the power to assign punitive actions , WALTON implies imminent punitive action if ARCHER continues his current behavior , Shared history of conflict or disagreement between ARCHER and WALTON', 'last_speaker': 'WALTON'}\n",
      "Last word -> WALTON : \"That's two strikes, Dubov. One more and you know where you're going. Back to your 'suites' -- or no\"\n",
      "prediction :  Oh, you'll have me fired?\n",
      "Real answer : That's two strikes, Dubov. One more and you know where you're going. Back to your 'suites' -- or no\n",
      "Bert Score : {'precision': [0.8320960998535156], 'recall': [0.8097188472747803], 'f1': [0.8207549452781677], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307691, 'rouge2': 0.0, 'rougeL': 0.07692307692307691, 'rougeLsum': 0.07692307692307691}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 157.49052103061715\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWALTON: Better be nice, Castor. You could get mighty lonely now that Pollux is gone.\\nARCHER: Pollux is -- what?\\nWALTON: Archer cut him a deal for turning state's evidence. He's been released...\\nARCHER: Walton, you have to listen to me -- right now!\\n\\n\", 'answer': \"Or what? You'll have me fired? You're confined until I say otherwise...\", 'gold_tag': 'WALTON is responsible for the confinement of ARCHER and his release', 'last_speaker': 'WALTON'}\n",
      "Last word -> WALTON : \"Or what? You'll have me fired? You're confined until I say otherwise...\"\n",
      "prediction :  \n",
      "Real answer : Or what? You'll have me fired? You're confined until I say otherwise...\n",
      "Bert Score : {'precision': [0.0], 'recall': [0.0], 'f1': [0.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5830.757790976462\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWALTON: There!\\n\\n', 'answer': \"Let's go!\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ARCHER'}\n",
      "Last word -> ARCHER : \"Let's go!\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction :  What's that?\n",
      "Real answer : Let's go!\n",
      "Bert Score : {'precision': [0.839039146900177], 'recall': [0.829700231552124], 'f1': [0.8343435525894165], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.0, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 87.94740186916538\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: How did the visit go?\\nKYLE: OK. He fell asleep watching TV. So he lives there now?\\nMIKE: Yeah. Your grandfather is in the things that don't make sense.\\nKYLE: Are you a friend of his or something?\\nMIKE: I'm his guardian.\\nKYLE: What's that mean?\\nMIKE: It means I make sure he's well taken care of.\\n\\n\", 'answer': \"That's cool.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'KYLE'}\n",
      "Last word -> KYLE : \"That's cool.\"\n",
      "prediction :  Did he say anything about the things that don't make sense?\n",
      "Real answer : That's cool.\n",
      "Bert Score : {'precision': [0.8432109951972961], 'recall': [0.8787072896957397], 'f1': [0.8605931997299194], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 31.148660660728314\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: Here's fifty bucks in case you need it.\\nKYLE: I have money.\\nMIKE: Actually it's only forty-three but take it. You never know.\\nKYLE: I have enough money. But thanks.\\nMIKE: Well, good luck, Kyle.\\n\\n\", 'answer': 'Yeah. You too, Mike.', 'gold_tag': 'Everyday Language', 'last_speaker': 'KYLE'}\n",
      "Last word -> KYLE : \"Yeah. You too, Mike.\"\n",
      "prediction :  Thanks. You too.\n",
      "Real answer : Yeah. You too, Mike.\n",
      "Bert Score : {'precision': [0.9828742742538452], 'recall': [0.9403360486030579], 'f1': [0.9611347317695618], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.5714285714285715, 'rouge2': 0.4, 'rougeL': 0.5714285714285715, 'rougeLsum': 0.5714285714285715}\n",
      "bleu 1/2 : 0.23884377019126307 0.09250379442961536\n",
      "ppl : 380.9497529023592\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: So what happened?\\nKYLE: I decided not to go home.\\nMIKE: And then you decided you'd break into your Grandfather's house?\\nKYLE: You mind if I have a quick smoke?\\n\\n\", 'answer': 'Yeah, I do. Get in the car.', 'gold_tag': \"MIKE disapproves of KYLE's smoking habit , MIKE is the responsible and authoritative figure\", 'last_speaker': 'MIKE'}\n",
      "Last word -> MIKE : \"Yeah, I do. Get in the car.\"\n",
      "prediction :  Sure.\n",
      "Real answer : Yeah, I do. Get in the car.\n",
      "Bert Score : {'precision': [0.940517783164978], 'recall': [0.8668273687362671], 'f1': [0.9021703004837036], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 940.7736565945374\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: You have fun?\\nKYLE: Yeah.\\nMIKE: When's the last time you wrestled?\\nKYLE: A couple years ago.\\nMIKE: Why'd you stop?\\nKYLE: Just felt like it.\\nMIKE: So let me ask you something, Kyle. How good are you?\\n\\n\", 'answer': \"I'm pretty good.\", 'gold_tag': 'KYLE believes he is pretty good at wrestling', 'last_speaker': 'KYLE'}\n",
      "Last word -> KYLE : \"I'm pretty good.\"\n",
      "prediction :  Mike, I'm not going to tell you how good I am at something I haven't done in years.\n",
      "Real answer : I'm pretty good.\n",
      "Bert Score : {'precision': [0.854232668876648], 'recall': [0.912260890007019], 'f1': [0.882293701171875], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.24999999999999997, 'rouge2': 0.09090909090909091, 'rougeL': 0.24999999999999997, 'rougeLsum': 0.24999999999999997}\n",
      "bleu 1/2 : 0.05555555555555554 0.018077538151554672\n",
      "ppl : 16.55577591391812\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: Were you outside?\\nKYLE: Yeah. I went for a run.\\nMIKE: It's pretty early. You do this every morning?\\nKYLE: In season, yeah. I like to get my run in early and then drill some moves for an hour before school.\\nMIKE: Oh. Wow.\\n\\n\", 'answer': \"Yeah...so I'm gonna do it. See you. 5/15/10 - FULL SHOOTING SCRIPT - WIN WIN 58\", 'gold_tag': 'KYLE has an intense morning routine', 'last_speaker': 'KYLE'}\n",
      "Last word -> KYLE : \"Yeah...so I'm gonna do it. See you. 5/15/10 - FULL SHOOTING SCRIPT - WIN WIN 58\"\n",
      "prediction : Yeah. It's a good way to stay in shape.\n",
      "Real answer : Yeah...so I'm gonna do it. See you. 5/15/10 - FULL SHOOTING SCRIPT - WIN WIN 58\n",
      "Bert Score : {'precision': [0.8829079866409302], 'recall': [0.8101702928543091], 'f1': [0.8449766635894775], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.127638105257239\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: Hey, I'm proud of what you did today. That win meant a lot to the guys.\\n\\n\", 'answer': 'Cool. It was good coaching with Stemler.', 'gold_tag': 'KYLE is involved in coaching with Stemler', 'last_speaker': 'KYLE'}\n",
      "Last word -> KYLE : \"Cool. It was good coaching with Stemler.\"\n",
      "prediction :  Yeah. I know. It was a big deal.\n",
      "Real answer : Cool. It was good coaching with Stemler.\n",
      "Bert Score : {'precision': [0.9174335598945618], 'recall': [0.9054368734359741], 'f1': [0.9113957285881042], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.26666666666666666, 'rouge2': 0.15384615384615383, 'rougeL': 0.26666666666666666, 'rougeLsum': 0.26666666666666666}\n",
      "bleu 1/2 : 0.25 0.18898223650461357\n",
      "ppl : 26.239665963964306\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: Let me ask you something. What's it like? Being as good as you are? What's it feel like?\\nKYLE: I don't know. I guess it just feels like I'm in control. Of everything. You know what I mean?\\nMIKE: Yeah, I do. Must be nice.\\n\\n\", 'answer': 'It is.', 'gold_tag': 'KYLE is good at something', 'last_speaker': 'KYLE'}\n",
      "Last word -> KYLE : \"It is.\"\n",
      "prediction :  It is. It's really nice. But it's also kind of lonely.\n",
      "Real answer : It is.\n",
      "Bert Score : {'precision': [0.8668992519378662], 'recall': [0.9601818323135376], 'f1': [0.9111592173576355], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2666666666666667, 'rouge2': 0.15384615384615385, 'rougeL': 0.2666666666666667, 'rougeLsum': 0.2666666666666667}\n",
      "bleu 1/2 : 0.18181818181818182 0.13483997249264845\n",
      "ppl : 17.520224073595767\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: How you doing?\\nKYLE: I'm sorry.\\nMIKE: Hey, it's alright.\\nKYLE: I don't want to go with her. I don't.\\n\\n\", 'answer': 'OK, pal. OK.', 'gold_tag': 'MIKE is supportive', 'last_speaker': 'MIKE'}\n",
      "Last word -> MIKE : \"OK, pal. OK.\"\n",
      "prediction :  I know.\n",
      "Real answer : OK, pal. OK.\n",
      "Bert Score : {'precision': [0.8991026282310486], 'recall': [0.8862256407737732], 'f1': [0.8926177024841309], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 663.9337011017111\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHERMAN: Sure. Yes. Go ahead.\\nMARTIN: So. Let's see. Can you tell us if your car was in use the night this happened?\\nSHERMAN: When exactly was it?\\nMARTIN: Tuesday a week ago.\\nSHERMAN: I don't know. Let me think. I'd have to figure...\\nMARTIN: Anybody else use your car?\\nSHERMAN: My wife. Sometimes. And the\\nMARTIN: Parking garage.\\nSHERMAN: Yes.\\nMARTIN: You leave the car with the keys\\nSHERMAN: Well... yes.\\n\\n\", 'answer': 'Could we go there and take a look at it?', 'gold_tag': 'Everyday Language', 'last_speaker': 'MARTIN'}\n",
      "Last word -> MARTIN : \"Could we go there and take a look at it?\"\n",
      "prediction :  Was there anything unusual in the car?\n",
      "Real answer : Could we go there and take a look at it?\n",
      "Bert Score : {'precision': [0.8991026878356934], 'recall': [0.8801396489143372], 'f1': [0.8895201683044434], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.09306272250443651 0.03178697118830404\n",
      "ppl : 86.86614263036863\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHERMAN: The car?\\nMARTIN: Yes.\\nSHERMAN: Now?\\n\\n', 'answer': \"Soon as we leave here. We could take a look. There's things that's consistent with an incident like this. We don't find those things, we move on down the list. And we're out of your hair.\", 'gold_tag': \"MARTIN intends to examine the car as soon as they leave their current location , MARTIN is in a profession requiring some form of investigation, likely law enforcement , MARTIN has a methodical approach to the 'incident' involving a car , MARTIN demonstrates a willingness to be fair in his inquiry\", 'last_speaker': 'MARTIN'}\n",
      "Last word -> MARTIN : \"Soon as we leave here. We could take a look. There's things that's consistent with an incident like this. We don't find those things, we move on down the list. And we're out of your hair.\"\n",
      "prediction :  No, I don't think so.\n",
      "Real answer : Soon as we leave here. We could take a look. There's things that's consistent with an incident like this. We don't find those things, we move on down the list. And we're out of your hair.\n",
      "Bert Score : {'precision': [0.8392581939697266], 'recall': [0.836097776889801], 'f1': [0.8376750946044922], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913045, 'rouge2': 0.045454545454545456, 'rougeL': 0.08695652173913045, 'rougeLsum': 0.08695652173913045}\n",
      "bleu 1/2 : 0.00040588612725914685 0.00014350241648724437\n",
      "ppl : 14.499148283028735\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHERMAN: So you want to take a look at the car then.\\nMARTIN: Yeah. We don't have a description of a driver. So we gotta look for the car. And that means bothering a lot of innocent people. We're sorry about the inconvenience.\\n\\n\", 'answer': \"I understand. But if it is a routine, well, I should, I guess I ought to... well, follow the routine that's appropriate to me, to someone with a car in this situation. You see?\", 'gold_tag': 'SHERMAN is likely the owner of the car being investigated , SHERMAN is respectful of protocol and willing to follow proper procedures , SHERMAN is a law-abiding citizen', 'last_speaker': 'SHERMAN'}\n",
      "Last word -> SHERMAN : \"I understand. But if it is a routine, well, I should, I guess I ought to... well, follow the routine that's appropriate to me, to someone with a car in this situation. You see?\"\n",
      "prediction :  You got that right.\n",
      "Real answer : I understand. But if it is a routine, well, I should, I guess I ought to... well, follow the routine that's appropriate to me, to someone with a car in this situation. You see?\n",
      "Bert Score : {'precision': [0.8604307174682617], 'recall': [0.8067712187767029], 'f1': [0.832737386226654], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10256410256410256, 'rouge2': 0.0, 'rougeL': 0.05128205128205128, 'rougeLsum': 0.05128205128205128}\n",
      "bleu 1/2 : 0.0001382710925369584 5.048946428891757e-05\n",
      "ppl : 127.28174857430436\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGRAHAM: Breakfast?\\nCLIVE: Java. Straight up.\\nGRAHAM: Any solids?\\nCLIVE: No, let\\'s punch through. Miles make the eggs taste sweeter.\\nGRAHAM: I love eggs!\\nCLIVE: I hear that. Now, get that \"�Joe\\' on the go and jump in the Chewie seat. I need your map skills.\\nGRAHAM: Good job I pre-pared. It\\'s a shame I don\\'t have some controls on this side. That way, I could take over if you needed the loo.\\nCLIVE: Yeah, I could say \"take the helm.\"�\\nGRAHAM: \"Take the helm, number one.\"�\\nCLIVE: Yeah, \"take the helm, number one, I need a number two.\"�\\nGRAHAM: \"�Least I\\'ve got Cerebro, eh?\\nCLIVE: Absolutely. Real-time sat-nav multi map and advanced geo-tagging with continual info stream?\\nGRAHAM: Impressive.\\nCLIVE: Most impressive.\\nGRAHAM: And let\\'s not forget, we\\'ve always got Analogue.\\nCLIVE: Not when we\\'re driving Graham.\\nGRAHAM: Sorry. Sounds like coffee o\\'clock.\\n\\n', 'answer': \"Thank god. I'm a wreck until I've had my first cup of J.\", 'gold_tag': 'CLIVE prefers coffee over solid food in the morning , CLIVE indicates needing coffee to function optimally , CLIVE needs a cup of coffee immediately', 'last_speaker': 'CLIVE'}\n",
      "Last word -> CLIVE : \"Thank god. I'm a wreck until I've had my first cup of J.\"\n",
      "prediction :  I'm just a couple of miles away.\n",
      "Real answer : Thank god. I'm a wreck until I've had my first cup of J.\n",
      "Bert Score : {'precision': [0.8619980216026306], 'recall': [0.8623789548873901], 'f1': [0.862188458442688], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3478260869565218, 'rouge2': 0.09523809523809523, 'rougeL': 0.3478260869565218, 'rougeLsum': 0.3478260869565218}\n",
      "bleu 1/2 : 0.18187407671869282 0.03586605161151225\n",
      "ppl : 42.2594424943878\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLIVE: Amazing, isn't it? There are 295,734,134 people in this country and we haven't seen a soul for a hundred miles. Where is everybody?\\nGRAHAM: What about that old woman on crutches we saw hitchhiking?\\nCLIVE: Apart from her. I suppose that's why they established the Dreamland facility out here.\\nGRAHAM: Far from prying eyes.\\nCLIVE: Did you know the site was selected in the mid-1950s for testing of the U-2 spyplane, due to its remoteness, proximity to existing facilities and presence of a dry lake bad for landings?\\nGRAHAM: Yes.\\nCLIVE: Oh.\\nGRAHAM: Shall we have a bite before or after we hit the Black Mailbox?\\n\\n\", 'answer': 'Before.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CLIVE'}\n",
      "Last word -> CLIVE : \"Before.\"\n",
      "prediction :  It is amazing, isn't it? There are 295,734,134 people in this country and we haven't seen a soul for a hundred miles. Where is everybody?\n",
      "Real answer : Before.\n",
      "Bert Score : {'precision': [0.7947038412094116], 'recall': [0.9201017618179321], 'f1': [0.8528178334236145], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.296914687353071\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGRAHAM: What's the matter?\\nCLIVE: Nothing. How we doing?\\nGRAHAM: We should be just about there.\\nCLIVE: I've found it.\\nGRAHAM: Where?\\n\\n\", 'answer': 'THERE!!!', 'gold_tag': 'Everyday Language', 'last_speaker': 'CLIVE'}\n",
      "Last word -> CLIVE : \"THERE!!!\"\n",
      "prediction :  There.\n",
      "Real answer : THERE!!!\n",
      "Bert Score : {'precision': [0.9744981527328491], 'recall': [0.8678934574127197], 'f1': [0.9181116223335266], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 1.0, 'rouge2': 0.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2869.8119975763993\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLIVE: It's amazing, isn't it? We're actually here.\\nGRAHAM: Area 51.\\nCLIVE: Dreamland.\\nGRAHAM: The Groom Lake Military Test Facility.\\nCLIVE: MacArthur's Black Mile.\\nGRAHAM: Is that a real one?\\nCLIVE: No, I made it up myself.\\nGRAHAM: I like it.\\nCLIVE: Be great if we saw something.\\nGRAHAM: Yes, imagine if we got buzzed up by a craft.\\nCLIVE: That would be incredible. It just\\nGRAHAM: What would you do if they actually landed?\\nCLIVE: Keep it together. First contact is a big responsibility. They come in peace, we go to pieces? That's not how I roll. What's wrong?\\nGRAHAM: It's them. They found us. I don't know how but they found us.\\nCLIVE: Who? Who's found us?\\nGRAHAM: The Libyans!\\n\\n\", 'answer': 'Run for it Marty!', 'gold_tag': 'Everyday Language', 'last_speaker': 'CLIVE'}\n",
      "Last word -> CLIVE : \"Run for it Marty!\"\n",
      "prediction :  What?\n",
      "Real answer : Run for it Marty!\n",
      "Bert Score : {'precision': [0.8777437210083008], 'recall': [0.822845995426178], 'f1': [0.8494088053703308], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGRAHAM: Perhaps it's not them. Perhaps whoever it was turned doff.\\nCLIVE: Of course it's them. We're dead. It's like Deliverance. They're going to rape us and break our arms.\\nGRAHAM: I don't want my arms broken!\\nCLIVE: There's only one thing for it.\\nGRAHAM: What?\\nCLIVE: I'm gonna have to fly blind. Probably best not to do that. I couldn't really see anything. Oh God, oh God, oh God.\\nGRAHAM: I need the toilet.\\nCLIVE: Me too. They're trying to overtake.\\nGRAHAM: Don't let them get past.\\nCLIVE: Should I ram them?\\nGRAHAM: What about the deposit?\\nCLIVE: It wasn't them. We should see if they're okay.\\nGRAHAM: I still need a wee.\\nCLIVE: I can hold mine.\\n\\n\", 'answer': \"The bulb's gone in there.\", 'gold_tag': 'GRAHAM mentions the bulb has gone, which is a temporary issue', 'last_speaker': 'GRAHAM'}\n",
      "Last word -> GRAHAM : \"The bulb's gone in there.\"\n",
      "prediction :  I can hold mine too.\n",
      "Real answer : The bulb's gone in there.\n",
      "Bert Score : {'precision': [0.8694062232971191], 'recall': [0.8461585640907288], 'f1': [0.8576249480247498], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 319.0279818139903\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGRAHAM: Now's not really the time, Sausage.\\nCLIVE: I must have it.\\nGRAHAM: It's very cheap. Are you sure you don't want to save up and get a proper on?\\n\\n\", 'answer': \"Oh, come on, we've got time.\", 'gold_tag': 'CLIVE does not save for something better', 'last_speaker': 'CLIVE'}\n",
      "Last word -> CLIVE : \"Oh, come on, we've got time.\"\n",
      "prediction :  No. I want it now.\n",
      "Real answer : Oh, come on, we've got time.\n",
      "Bert Score : {'precision': [0.90736985206604], 'recall': [0.8541566729545593], 'f1': [0.8799595236778259], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 136.39810992912655\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGRAHAM: It's gone!\\n\\n\", 'answer': 'Where did it go?', 'gold_tag': 'Everyday Language', 'last_speaker': 'CLIVE'}\n",
      "Last word -> CLIVE : \"Where did it go?\"\n",
      "prediction :  What do you mean it's gone?\n",
      "Real answer : Where did it go?\n",
      "Bert Score : {'precision': [0.8866734504699707], 'recall': [0.9213128089904785], 'f1': [0.90366131067276], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 39.42137025809356\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBILL: No, you listen to me. You don't understand, Gene. Don't lie, just give the family what it wants... No... No, you don't understand.\\nROSE: Why me ?... Hi !... I'm Rose.\\nBILL: Hi, Rose !... I't nice to run into me like this !... I'm Bill Capa...\\nROSE: I got no insurance... She gets out of her car. I know it's against the law and everything. Don't bust my chops. I'll bring the money to you, if you just get an estimate.\\nBILL: Got a pen ?\\nROSE: Oh, poor old brain can't remember its own phone number.\\nBILL: I just moved here... From New York... I wrote my address down, because I am not sure about this number, and how long I gonna be there, so maybe you can call me sometimes for the next couple of days.\\nROSE: I will.\\nBILL: Bye !\\nROSE: Hey !... Don't you want my address ?\\n\\n\", 'answer': 'You could lie.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BILL'}\n",
      "Last word -> BILL : \"You could lie.\"\n",
      "prediction :  No, I got it.\n",
      "Real answer : You could lie.\n",
      "Bert Score : {'precision': [0.8781241774559021], 'recall': [0.8927592039108276], 'f1': [0.8853812217712402], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 115.91290480350666\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: Hello !\\nBILL: Who's there ?\\nROSE: Hi !... Remember me ?... Fender-bender !...\\nBILL: There she is, a little angel, dancing on the head of a pin.\\nROSE: So... did you get that estimate ?\\nBILL: No.\\nROSE: Waow !... Nice place you got here. It's a little cold... but it's kind of tasteful, right ?\\nBILL: And wet !\\nROSE: You too, I guess.\\nBILL: Cold or tasteful ?\\n\\n\", 'answer': 'So... Are we eating in here, or you take me out ?...', 'gold_tag': 'ROSE is socially forward, asking about their eating arrangements', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"So... Are we eating in here, or you take me out ?...\"\n",
      "prediction :  I guess cold.\n",
      "Real answer : So... Are we eating in here, or you take me out ?...\n",
      "Bert Score : {'precision': [0.8736574649810791], 'recall': [0.8202658891677856], 'f1': [0.8461202383041382], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2567.4462320144166\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: Not even a shade of pink ?... Can't tell me if it's smeared or not ?\\nBILL: I can't tell you if your eyes are bloodshed.\\nROSE: Really !... That's sad !... You know what ?... In respect for your infirmity, I'm gonna give up wearing lipstick. Close-up on Rose putting her lipstick in her glass of water. There is something about me that I bet you find a little strange. Right ?\\nBILL: What is that ?\\nROSE: Well, I haven't asked you what you do.\\nBILL: That's right. You showed a remarkable restraint.\\nROSE: Well, it's because I'd rather guess. You know, I actually get upset if someone tries to tell me before I can... figure it out for myself, you know ?\\nBILL: But what if I am ashamed of what I do.\\nROSE: Why... Why should you be ashamed of being a shrink.\\nBILL: Who told you I was a shrink ?\\nROSE: Well... Are you ?\\nBILL: How did you know ?\\nROSE: The way you looked at me, you know ?\\nBILL: How I look at you ?\\nROSE: You... you have this kindness in your eyes. But I think you're using it to keep me away. You know, you're trying to play safe. You're trying to think of a case instead of thinking of a female.\\nBILL: So, you have a tuning fork too.\\nROSE: I guess we have a lot in common.\\nBILL: We seem to be playing the same game.\\nROSE: Why do you say I'm playing a game?\\nBILL: Because you're the fantasy girl, aren't you? Quicksilver?\\nROSE: Yeah, that's... That's exactly what I am.\\nBILL: You'll be whatever they want you to be... no substance, no rules. Light as air. So your feet never have to touch those burning hot coals the rest of us walk around on.\\nROSE: Yeah. Sort of like... not seeing red?\\n\\n\", 'answer': 'Yeah, sort of like that.', 'gold_tag': 'BILL is a professional shrink, possibly introverted, cautious, analytical, and sensitive', 'last_speaker': 'BILL'}\n",
      "Last word -> BILL : \"Yeah, sort of like that.\"\n",
      "prediction : ... I don't know.\n",
      "Real answer : Yeah, sort of like that.\n",
      "Bert Score : {'precision': [0.8398844003677368], 'recall': [0.8327243328094482], 'f1': [0.8362890481948853], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18.091444517795605\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBILL: Yes, but that was part of my plan. I mean, I wanted to.\\nROSE: Oh, I need a taxi. Taxi !\\nBILL: No, hey, hey. Wait, wait, wait. What are you being so tough for ?\\nROSE: I'm just beginning to think that maybe I'Il...\\nBILL: I am thinking you should just let me take you home and forget about this stupid taxi.\\nROSE: Rose walks to her waiting cab. Well, I'm thinkin' you should stay exactly where you are, 'cause...\\nBILL: Give me your phone number and address.\\n\\n\", 'answer': 'Why? You want to make me fall to earth and burn my feet ? Whatever happened to quicksilver and light as air?', 'gold_tag': 'ROSE has a poetic side, as evidenced by her last line', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"Why? You want to make me fall to earth and burn my feet ? Whatever happened to quicksilver and light as air?\"\n",
      "prediction :  I can't give you my phone number.\n",
      "Real answer : Why? You want to make me fall to earth and burn my feet ? Whatever happened to quicksilver and light as air?\n",
      "Bert Score : {'precision': [0.8643060326576233], 'recall': [0.8101582527160645], 'f1': [0.8363566398620605], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13793103448275862, 'rouge2': 0.0, 'rougeL': 0.13793103448275862, 'rougeLsum': 0.13793103448275862}\n",
      "bleu 1/2 : 0.016759880870607254 0.005724589137482021\n",
      "ppl : 24.202881605187166\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: It's red, poor thing.\\nBILL: Thank you.\\nROSE: I was thinking. Maybe I should see a shrink.\\nBILL: I can recommend someone.\\nROSE: I feel better already.\\nBILL: God, I missed you.\\n\\n\", 'answer': \"This time you won't miss.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"This time you won't miss.\"\n",
      "prediction :  I know.\n",
      "Real answer : This time you won't miss.\n",
      "Bert Score : {'precision': [0.8686889410018921], 'recall': [0.8349719643592834], 'f1': [0.8514967560768127], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 663.9337011017111\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: I want you to get dressed up... Get dressed up... All right ?\\nBILL: Right now ?\\n\\n', 'answer': 'Uh-huh.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"Uh-huh.\"\n",
      "prediction :  Yes, right now.\n",
      "Real answer : Uh-huh.\n",
      "Bert Score : {'precision': [0.8483397364616394], 'recall': [0.8078138828277588], 'f1': [0.8275809288024902], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 169.7408822554853\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: You're not eating. Don't you like my food?\\nBILL: I'd like your food five inches to the left.\\nROSE: Okay.\\nBILL: Yeah, okay.\\n\\n\", 'answer': \"I think it's ready.\", 'gold_tag': 'ROSE is the one cooking , ROSE may be adept at cooking or be the designated cook among the two', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"I think it's ready.\"\n",
      "prediction :  What's wrong?\n",
      "Real answer : I think it's ready.\n",
      "Bert Score : {'precision': [0.85158371925354], 'recall': [0.8692855834960938], 'f1': [0.8603435754776001], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 105.20381087433657\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: Hey.\\nBILL: How did you get in here ?\\nROSE: Last time I was here, I stole the key. It was by the door.\\nBILL: What about the alarm ?\\nROSE: Oh ! I never thought about that.\\nBILL: It didn't go off ?\\nROSE: No. Um, did I make a mistake ? You have someone in the car ?\\nBILL: No, goddamn it, there isn't someone in the car ! People are getting killed around here ! You walk around like it's goddamn Disneyland ! What if something were to happen to you ?\\nROSE: She seems not to understand Bill's anger. I just thought that it would be a nice surprise, that's all. You don't look too happy to see me. I'm sorry.\\nBILL: I'm sorry. Baby, I'm sorry. This is a very nice surprise.\\nROSE: I'll never take a risk like that again.\\nBILL: Why don't you take the biggest risk of all and give me... your phone number.\\n\\n\", 'answer': \"She laughs and goes away from him and back to her cooking. Christ, Capa ! I can't have people tying up the phone lines. I'm trying to run a business here.\", 'gold_tag': \"ROSE is business-oriented, mentioning that she runs a business and can't have people tying up her phone lines\", 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"She laughs and goes away from him and back to her cooking. Christ, Capa ! I can't have people tying up the phone lines. I'm trying to run a business here.\"\n",
      "prediction :  (smiling) I'd like that.\n",
      "Real answer : She laughs and goes away from him and back to her cooking. Christ, Capa ! I can't have people tying up the phone lines. I'm trying to run a business here.\n",
      "Bert Score : {'precision': [0.8623737096786499], 'recall': [0.8365811109542847], 'f1': [0.8492816090583801], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05405405405405406, 'rouge2': 0.0, 'rougeL': 0.05405405405405406, 'rougeLsum': 0.05405405405405406}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 38.81582483675897\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBILL: Voice over.\\nROSE: Voice ironically disappointed.\\nBILL: Oh, our, our tank fleet is crippled.\\nROSE: Yeah ?\\nBILL: It's goin' away.\\nROSE: How's the submarine fleet ?\\nBILL: Hey, hey, hey, hey, please, please. I gotta get some sleep.\\nROSE: They kiss. Oh, you're chicken.\\nBILL: I gotta be up...\\nROSE: You're chicken.\\nBILL: I gotta be up at 6:00 in the morning.\\n\\n\", 'answer': \"She turns around to kiss him. You're chicken, chicken.\", 'gold_tag': 'ROSE is playful , ROSE enjoys teasing BILL , ROSE calls BILL \"chicken\"', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"She turns around to kiss him. You're chicken, chicken.\"\n",
      "prediction :  Wake up, wake up.\n",
      "Real answer : She turns around to kiss him. You're chicken, chicken.\n",
      "Bert Score : {'precision': [0.8735476732254028], 'recall': [0.8596107363700867], 'f1': [0.8665231466293335], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 32.39871937273876\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBILL: One of my patients was killed last night. He was murdered.\\nROSE: She seems very disturbed by the news. What ?\\nBILL: The painter. Casey.\\nROSE: She has tears in her eyes. Were you there ?\\nBILL: A little bit after.\\nROSE: What did you see ?\\nBILL: You don't want to know. About a half hour before group. I'm gonna get a shower. You gonna be okay out here ?\\n\\n\", 'answer': 'Yeah.', 'gold_tag': 'ROSE will stay in the current location while BILL showers', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"Yeah.\"\n",
      "prediction :  Yes. I'll be okay.\n",
      "Real answer : Yeah.\n",
      "Bert Score : {'precision': [0.8726648092269897], 'recall': [0.968252956867218], 'f1': [0.9179771542549133], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 75.41568015530194\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBILL: Rose.\\nROSE: She jumps. Oh ! Oh !\\n\\n', 'answer': 'Rose ! Rose !', 'gold_tag': 'Everyday Language', 'last_speaker': 'BILL'}\n",
      "Last word -> BILL : \"Rose ! Rose !\"\n",
      "prediction :  I'm sorry.\n",
      "Real answer : Rose ! Rose !\n",
      "Bert Score : {'precision': [0.8749946355819702], 'recall': [0.8222988843917847], 'f1': [0.84782874584198], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 70.196163546962\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMO: Hey. You're creasing the pants.\\nSHADES: Tough guy.\\nMO: Shut up.\\nSHADES: That's why you're still in the corps, isn't it?\\nMO: Why?\\nSHADES: You tell me. No, really. Tell me why.\\nMO: The money's good. I get around. I see what's left of the world.\\nSHADES: I get around, too, and at least I'm still in one piece.\\nMO: Yeah, until one of your boosters blows up under you or your heatshield rips off on the way home.\\nSHADES: Don't knock it. At least it’s quick. One pssht and you're gas spread out over a thousand miles of stratosphere. Think of the view. No coughing your lungs out in a bunker or sitting around waiting for the first cancer cells to show up or your kids to be born blind and blue because you've had one dose too many and come up snake eyes in the genetic crap game you play every time you go zone tripping. DO you think Jill wants you to go on strolling around out there up to your ass in radioactive iodine for the rest of your life?\\n\\n\", 'answer': \"Think she'd like it better if I was on welfare? Wound up like these bums? Nothing else I can do. Not now. Anyway, I don't want kids. Can't stand the little motherfuckers.\", 'gold_tag': 'MO dislikes being dependent on welfare , MO is not keen on having children , MO has a grim, fatalistic outlook on life', 'last_speaker': 'MO'}\n",
      "Last word -> MO : \"Think she'd like it better if I was on welfare? Wound up like these bums? Nothing else I can do. Not now. Anyway, I don't want kids. Can't stand the little motherfuckers.\"\n",
      "prediction :  Maybe not.\n",
      "Real answer : Think she'd like it better if I was on welfare? Wound up like these bums? Nothing else I can do. Not now. Anyway, I don't want kids. Can't stand the little motherfuckers.\n",
      "Bert Score : {'precision': [0.8708847761154175], 'recall': [0.8103051781654358], 'f1': [0.8395035266876221], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05405405405405405, 'rouge2': 0.0, 'rougeL': 0.05405405405405405, 'rougeLsum': 0.05405405405405405}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 386.9803913645719\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMO: Jesus... Oh, Jesus... Jill. Come on...come on...!\\nSHADES: Ayuh... Hey, uh...wow, um...it's cool, but...right now it's, uh, kinda difficult... Do you know what time it is?\\nMO: Listen to me! This is serious! Jill's in danger and you've gotta help her!\\nSHADES: Oh, Jeez. Oh...Christ. It had to be tonight.\\nMO: What's wrong?\\nSHADES: My heart feels like an alligator.\\nMO: What?! Shades. What's wrong with you?!\\nSHADES: You know that tab of acid I was saving...?\\nMO: Oh no...\\n\\n\", 'answer': \"Yeah. I dropped it. Like...Christmas can get pretty crazy on your own, y'know? I've just been sitting here staring at the stars all night. The sky's so beautiful...\", 'gold_tag': 'SHADES has recently consumed acid and is currently under its effects', 'last_speaker': 'SHADES'}\n",
      "Last word -> SHADES : \"Yeah. I dropped it. Like...Christmas can get pretty crazy on your own, y'know? I've just been sitting here staring at the stars all night. The sky's so beautiful...\"\n",
      "prediction :  Yep. Now's the time.\n",
      "Real answer : Yeah. I dropped it. Like...Christmas can get pretty crazy on your own, y'know? I've just been sitting here staring at the stars all night. The sky's so beautiful...\n",
      "Bert Score : {'precision': [0.8989366292953491], 'recall': [0.826848566532135], 'f1': [0.8613869547843933], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10810810810810811, 'rouge2': 0.0, 'rougeL': 0.05405405405405406, 'rougeLsum': 0.05405405405405406}\n",
      "bleu 1/2 : 0.0006196880441665896 0.00022627808027086589\n",
      "ppl : 124.14417077107245\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMO: Hey! Hey! Listen to me! Come back! You've got to do this for me! You've got to go down to the apartment and get Jill out of there right\\nSHADES: Yeah, yeah. Okay.\\nMO: Go get Jill. Bring her to your place and lock the door. Got that?\\nSHADES: What's going on? You in trouble with the cops again or --\\nMO: I'll tell you later! Just do it! Now!\\nSHADES: Okay, okay. Just let me get my pants on.\\nMO: Hurry, Shades. I'm counting on you.\\nSHADES: No sweat. I'll be seeing you later, huh?\\nMO: Yeah, just watch yourself, okay?\\n\\n\", 'answer': 'Oh, yeah. Noooooo problem. See ya. Bye.', 'gold_tag': \"SHADES shows a calm demeanor despite MO's urgency\", 'last_speaker': 'SHADES'}\n",
      "Last word -> SHADES : \"Oh, yeah. Noooooo problem. See ya. Bye.\"\n",
      "prediction :  What's going on?\n",
      "Real answer : Oh, yeah. Noooooo problem. See ya. Bye.\n",
      "Bert Score : {'precision': [0.8321311473846436], 'recall': [0.8365538716316223], 'f1': [0.8343366980552673], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 53.57965698662712\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTAFT: Eddie Shitface! Where you been, boy? Eddie, I don't think I introduced you to my new partner, Michael Hernandez...\\n\\n\", 'answer': 'Pleased to meet you, Mr. Shitface...', 'gold_tag': 'HERNANDEZ is a new partner to TAFT , HERNANDEZ has a formal tone indicating a level of education or professionalism', 'last_speaker': 'HERNANDEZ'}\n",
      "Last word -> HERNANDEZ : \"Pleased to meet you, Mr. Shitface...\"\n",
      "prediction :  Nice to meet you, Eddie.\n",
      "Real answer : Pleased to meet you, Mr. Shitface...\n",
      "Bert Score : {'precision': [0.9321538805961609], 'recall': [0.8978341817855835], 'f1': [0.9146722555160522], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.5454545454545454, 'rouge2': 0.4444444444444445, 'rougeL': 0.5454545454545454, 'rougeLsum': 0.5454545454545454}\n",
      "bleu 1/2 : 0.49123845184678916 0.448437301984003\n",
      "ppl : 60.025299998305435\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTAFT: This is our collar? Who is he?\\n\\n', 'answer': 'Some scumbag...', 'gold_tag': \"HERNANDEZ has a negative view of people they consider 'scumbags' , This negative view is likely due to their job\", 'last_speaker': 'HERNANDEZ'}\n",
      "Last word -> HERNANDEZ : \"Some scumbag...\"\n",
      "prediction :  This is the guy who did the job. He was working for a competing security firm, and he came to me with an offer to take over.\n",
      "Real answer : Some scumbag...\n",
      "Bert Score : {'precision': [0.8251893520355225], 'recall': [0.820244550704956], 'f1': [0.8227095007896423], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.593498840082507\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTAFT: Who are you, man? Who the fuck are you?\\n\\n', 'answer': \"I'm me.\", 'gold_tag': 'HERNANDEZ indicates his identity only as \"me\"', 'last_speaker': 'HERNANDEZ'}\n",
      "Last word -> HERNANDEZ : \"I'm me.\"\n",
      "prediction :  I'm Hernandez.\n",
      "Real answer : I'm me.\n",
      "Bert Score : {'precision': [0.9311766028404236], 'recall': [0.9383693933486938], 'f1': [0.9347591996192932], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.6666666666666666, 'rouge2': 0.5, 'rougeL': 0.6666666666666666, 'rougeLsum': 0.6666666666666666}\n",
      "bleu 1/2 : 0.5 0.223606797749979\n",
      "ppl : 84.09869926331196\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLATESHA: Tell me she has an off switch --\\nSCOTT: We can only unlock the emergency override from the main terminal, and that's assuming she lets us in.\\nLATESHA: What're we supposed to do, say pretty\\n\\n\", 'answer': \"We can't shut her down, but maybe we can get her to shut herself down. Help me with this As they tug at the hatch --\", 'gold_tag': 'SCOTT is responsible for problem-solving', 'last_speaker': 'SCOTT'}\n",
      "Last word -> SCOTT : \"We can't shut her down, but maybe we can get her to shut herself down. Help me with this As they tug at the hatch --\"\n",
      "prediction :  We need to get to the main terminal before she locks it down again.\n",
      "Real answer : We can't shut her down, but maybe we can get her to shut herself down. Help me with this As they tug at the hatch --\n",
      "Bert Score : {'precision': [0.8831058740615845], 'recall': [0.8591691255569458], 'f1': [0.8709731101989746], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0.12124938447912854 0.019894905866730036\n",
      "ppl : 41.30964628090852\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSCOTT: This controls her primary cooling system... if we cut the circulation, the temp in her tank goes up.\\nLATESHA: So we boil her brain.\\nSCOTT: She'll have to shut herself down to keep from overheating.\\nLATESHA: Can't she just drain the. water?\\n\\n\", 'answer': 'Not anymore.', 'gold_tag': 'SCOTT demonstrates technical expertise', 'last_speaker': 'SCOTT'}\n",
      "Last word -> SCOTT : \"Not anymore.\"\n",
      "prediction :  If she shuts down, we'll have to get her out of the tank.\n",
      "Real answer : Not anymore.\n",
      "Bert Score : {'precision': [0.8567055463790894], 'recall': [0.8717861175537109], 'f1': [0.8641800880432129], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.309609273800437\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSCOTT: So...\\nLATESHA: So...\\nSCOTT: Hey :you think I could have your... you KNOW\\n\\n', 'answer': \"That's my address. I'm not using a cell phone anymore. Pick me up at eight.\", 'gold_tag': 'LATESHA has decided not to use a cell phone anymore , LATESHA will be available for SCOTT to pick her up at eight', 'last_speaker': 'LATESHA'}\n",
      "Last word -> LATESHA : \"That's my address. I'm not using a cell phone anymore. Pick me up at eight.\"\n",
      "prediction :  What?\n",
      "Real answer : That's my address. I'm not using a cell phone anymore. Pick me up at eight.\n",
      "Bert Score : {'precision': [0.8239577412605286], 'recall': [0.8256293535232544], 'f1': [0.8247926831245422], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRON: You can have our old room. I’m in the basement.\\nJOHN: What, you live here now?\\n\\n', 'answer': 'We’re in a recession.', 'gold_tag': 'RON refers to the recession', 'last_speaker': 'RON'}\n",
      "Last word -> RON : \"We’re in a recession.\"\n",
      "prediction :  No, I just have a room here. I live in the basement.\n",
      "Real answer : We’re in a recession.\n",
      "Bert Score : {'precision': [0.8562511205673218], 'recall': [0.8800575137138367], 'f1': [0.8679911494255066], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23529411764705882, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.16666666666666669 0.03892494720807617\n",
      "ppl : 35.87066444479068\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRON: She is going to be okay, right?\\nJOHN: Yeah. Better then ever.\\n\\n', 'answer': 'Tell Dad I’ll take the job.', 'gold_tag': 'RON is going to take a job , RON has an upcoming occupational commitment', 'last_speaker': 'RON'}\n",
      "Last word -> RON : \"Tell Dad I’ll take the job.\"\n",
      "prediction :  You know, I never thought I'd see the day where you would be driving a car.\n",
      "Real answer : Tell Dad I’ll take the job.\n",
      "Bert Score : {'precision': [0.8430068492889404], 'recall': [0.8689234256744385], 'f1': [0.8557689785957336], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.0625 0.02041241452319315\n",
      "ppl : 9.484004183785233\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRON: John. John.\\n\\n', 'answer': 'What? What is it?', 'gold_tag': 'Everyday Language', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"What? What is it?\"\n",
      "prediction :  What?\n",
      "Real answer : What? What is it?\n",
      "Bert Score : {'precision': [0.9370614290237427], 'recall': [0.885066568851471], 'f1': [0.9103221297264099], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4, 'rouge2': 0.0, 'rougeL': 0.4, 'rougeLsum': 0.4}\n",
      "bleu 1/2 : 0.049787068367863944 0.015744053406497194\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRON: Everyone got on their seat belts?\\nJOHN: Yeah. Just go. Go, go!\\nRON: Shit. I never did get that fixed.\\n\\n', 'answer': 'Oh my God.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"Oh my God.\"\n",
      "prediction :  Don't worry, man. It's not like we're going to be driving fast or anything.\n",
      "Real answer : Oh my God.\n",
      "Bert Score : {'precision': [0.8251549601554871], 'recall': [0.85174161195755], 'f1': [0.8382375240325928], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.300428989897606\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMALCOLM: That's one fine frame. A fine frame it is. How much does a fine frame like that cost, you think?\\nANNA: I've never told you... but you sound a little like Dr. Seuss when you're drunk.\\nMALCOLM: Anna, I'm serious. Serious I am, Anna.\\nANNA: Mahogany. I'd say that cost at least a couple hundred. Maybe three.\\nMALCOLM: Three? We should hock it. Buy a C.D. rack for the bedroom.\\nANNA: Do you know how important this is? This is big time. I'm going to read it for you, doctor.\\nMALCOLM: Do I really sound like Dr. Seuss?\\nANNA: In recognition for his outstanding achievement in the field of child psychology, his dedication to his work, and his continuing efforts to improve the quality of life for countless children and their families, the City of Philadelphia proudly bestows upon its son Dr. Malcolm Crowe... That's you... the Mayor's Citation for Professional Excellence. Wow. They called you their son.\\nMALCOLM: We can keep it in the bathroom. It's not real, Anna. Some secretary wrote that up. Don't tell me you thought it was real? What? Don't do the quiet thing. You know I hate it.\\nANNA: This is an important night for us. Finally someone is recognizing the sacrifices you made. That you have put everything second, including me, for those families they're talking about. They're also saying that my husband has a gift. Not an ordinary gift that allows him to hit a ball over a fence. Or a gift that lets him produce beautiful images on a canvas... Your gift teaches children how to be strong in situations where most adults would piss on themselves. Yes, I believe what they wrote about you.\\nMALCOLM: Thank you. What are we hugging about again?\\nANNA: Nothing. There wasn't supposed to be any crying at this celebration. Just a lot of drinking and sex.\\n\\n\", 'answer': 'I would like some red wine in a glass. I would not like it in a mug. I would not like it in a jug.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MALCOLM'}\n",
      "Last word -> MALCOLM : \"I would like some red wine in a glass. I would not like it in a mug. I would not like it in a jug.\"\n",
      "prediction :  I'm sorry. I didn't mean to cry. I just wish I could go back in time and do things differently.\n",
      "Real answer : I would like some red wine in a glass. I would not like it in a mug. I would not like it in a jug.\n",
      "Bert Score : {'precision': [0.8525232076644897], 'recall': [0.8582573533058167], 'f1': [0.855380654335022], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1702127659574468, 'rouge2': 0.0, 'rougeL': 0.1702127659574468, 'rougeLsum': 0.1702127659574468}\n",
      "bleu 1/2 : 0.155760156614281 0.0252676339615188\n",
      "ppl : 6.291720674964136\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMALCOLM: Anna, I've been so lost. I need my best friend.\\nANNA: I miss you.\\nMALCOLM: I miss you.\\nANNA: Why, Malcolm?\\nMALCOLM: What, Anna? What did I do? What's made you so sad?\\nANNA: Why did you leave me?\\n\\n\", 'answer': \"I didn't leave you. No...\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MALCOLM'}\n",
      "Last word -> MALCOLM : \"I didn't leave you. No...\"\n",
      "prediction :  I'm sorry. I'm sorry, Anna.\n",
      "Real answer : I didn't leave you. No...\n",
      "Bert Score : {'precision': [0.8699761629104614], 'recall': [0.8633178472518921], 'f1': [0.8666342496871948], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 28.70370188990735\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMALCOLM: ANNA! Don't cry. I think I have to go. I just needed to do a couple of things. And I needed to tell you something.\\nANNA: Tell me.\\nMALCOLM: You were never second... Ever. You sleep now, Anna. Everything will be different in the morning.\\nANNA: Goodnight, Malcolm.\\n\\n\", 'answer': \"Goodnight, sweetheart. ...I think I've had too much to drink. I just have to say, this day today has been one very special day... I wish we all could stay and play. What? Anna, I never thought I'd feel the things I'm feeling. I never thought I'd be able to stand up in front of my friends and family and tell them what's inside me... Today I can... Anna Crowe... I am in love. In love I am.\", 'gold_tag': \"MALCOLM attempted to comfort Anna and confessed his love , MALCOLM has a tendency for drinking , MALCOLM reveals he has had too much to drink and infers it's evening or night time\", 'last_speaker': 'MALCOLM'}\n",
      "Last word -> MALCOLM : \"Goodnight, sweetheart. ...I think I've had too much to drink. I just have to say, this day today has been one very special day... I wish we all could stay and play. What? Anna, I never thought I'd feel the things I'm feeling. I never thought I'd be able to stand up in front of my friends and family and tell them what's inside me... Today I can... Anna Crowe... I am in love. In love I am.\"\n",
      "prediction :  Goodnight, Anna.\n",
      "Real answer : Goodnight, sweetheart. ...I think I've had too much to drink. I just have to say, this day today has been one very special day... I wish we all could stay and play. What? Anna, I never thought I'd feel the things I'm feeling. I never thought I'd be able to stand up in front of my friends and family and tell them what's inside me... Today I can... Anna Crowe... I am in love. In love I am.\n",
      "Bert Score : {'precision': [0.9486590623855591], 'recall': [0.8033198118209839], 'f1': [0.8699609637260437], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.047058823529411764, 'rouge2': 0.0, 'rougeL': 0.047058823529411764, 'rougeLsum': 0.047058823529411764}\n",
      "bleu 1/2 : 1.5695663960240148e-17 7.019314313418106e-18\n",
      "ppl : 633.636308178242\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMONA: Why did you join a support group of unattractive, militant lesbians when you have me?\\nZOE: Because you\\'re really not that supportive.\\nMONA: Sure I am.\\nZOE: You just told me that if I breast- feed \"my girls\" will end up looking like empty tube socks.\\nMONA: I\\'m just being honest. And don\\'t even get me started on what childbirth does to your bladder.\\nZOE: What does it do to your bladder?\\nMONA: I just peed a little bit.\\nZOE: I don\\'t think I\\'m pregnant. The doctor says it will probably take several tries. Something about frozen sperm being lazy.\\nMONA: Good. Take your time.\\nZOE: So, should I call this guy? Do you think that would be weird?\\nMONA: Do I think it\\'s weird that you\\'re pursuing someone at the exact moment in time that you might be most unavailable? No. Because that\\'s what you do. You sabotage.\\nZOE: He works at the Farmer\\'s market. And it\\'s right around the corner. Are you thinking what I\\'m thinking? No.\\nMONA: Then, no.\\nZOE: Let\\'s go spy on him. Come on. It will be fun. Like high school.\\n\\n', 'answer': 'I can\\'t. This twenty minute breakfast concludes my \"me\" time for the week. More proof that you should not have kids.', 'gold_tag': 'MONA has limited personal time, reflecting a busy lifestyle', 'last_speaker': 'MONA'}\n",
      "Last word -> MONA : \"I can't. This twenty minute breakfast concludes my \"me\" time for the week. More proof that you should not have kids.\"\n",
      "prediction :  Zoey, I think you might be trying to get me arrested.\n",
      "Real answer : I can't. This twenty minute breakfast concludes my \"me\" time for the week. More proof that you should not have kids.\n",
      "Bert Score : {'precision': [0.8432549238204956], 'recall': [0.8448837995529175], 'f1': [0.8440685868263245], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1818181818181818, 'rouge2': 0.0, 'rougeL': 0.12121212121212123, 'rougeLsum': 0.12121212121212123}\n",
      "bleu 1/2 : 0.07325278573256963 0.017179301032550675\n",
      "ppl : 36.368491917300354\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZOE: What if I\\'m pregnant?\\nMONA: Then you\\'ll get fat and hormonal and I\\'ll say, \"I told you so.\"\\nZOE: But what if this could go somewhere with Stan? Like, really go somewhere.\\nMONA: Then it will work out perfectly.\\nZOE: What do you mean?\\nMONA: Because just when you really like him, you\\'ll break up because you\\'re pregnant and then you never have to put yourself out there and possibly get hurt. That\\'s your dream.\\n\\n', 'answer': \"I'm not pregnant.\", 'gold_tag': 'Zoe may be pregnant, which will only be relevant for a short period until pregnancy is confirmed or ruled out', 'last_speaker': 'ZOE'}\n",
      "Last word -> ZOE : \"I'm not pregnant.\"\n",
      "prediction :  Well, what if I'm not pregnant?\n",
      "Real answer : I'm not pregnant.\n",
      "Bert Score : {'precision': [0.8838378190994263], 'recall': [0.9478984475135803], 'f1': [0.914747953414917], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.7272727272727273, 'rouge2': 0.6666666666666666, 'rougeL': 0.7272727272727273, 'rougeLsum': 0.7272727272727273}\n",
      "bleu 1/2 : 0.3333333333333333 0.25819888974716115\n",
      "ppl : 24.425826626164447\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMONA: Why are you even working out? This is the one time in your life you're allowed to let it go.\\nZOE: Because look at me. I just keep\\nMONA: Well, yeah. That's kind of how it goes.\\nZOE: I'm afraid I'm going to scare him away. I'm like one of those giant bouncy castles. Soon I'm going to take over the whole back yard.\\nMONA: Come on. He loves you for you.\\nZOE: I'm just getting kind of freaked out by everything. He asked me to go to this wedding with him. What\\nMONA: Well, you're knocked up with some stranger's twins. So, already you're not exactly...\\nZOE: Not helping.\\n\\n\", 'answer': 'Do you have anything to wear at least?', 'gold_tag': 'Everyday Language', 'last_speaker': 'MONA'}\n",
      "Last word -> MONA : \"Do you have anything to wear at least?\"\n",
      "prediction :  Maybe he just wants you to be happy.\n",
      "Real answer : Do you have anything to wear at least?\n",
      "Bert Score : {'precision': [0.8624509572982788], 'recall': [0.8208624124526978], 'f1': [0.8411429524421692], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0.25 0.059761430466719695\n",
      "ppl : 31.294648642381024\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLESLIE: We'll be right down.\\nALEC: June first!'\\nLESLIE: Honey, I just got promoted. I'm going to have a lot more responsibility. I'm sure it's\\nALEC: Looking at my big picture agenda, I want to be playing softball with my firstborn in about four years.\\nLESLIE: Do you realize that over half the marriages today end in divorce.\\nALEC: And the other half don't.\\nLESLIE: My six-year-old niece asked me today why everyone's father doesn't live in a separate house like her father does. I don't want us to become another divorce statistic in Newsweek.\\nALEC: Look at my parents. My father may not come home with a raging hard- on, anymore, but they're happy.\\nLESLIE: Your father sits around playing chess while your mother talks to him constantly. But he's not listening.\\nALEC: That's probably why they're happy. Leslie, let's stop living together . get married and start really living together!\\nLESLIE: Sweetheart, please. Let's not talk about it tonight. This party means a lot to Kirbo. The floor's filthy again.\\nALEC: Just pick a date, any date...\\n\\n\", 'answer': 'There are some things we have to work out first.', 'gold_tag': 'LESLIE wants to work things out before setting a wedding date', 'last_speaker': 'LESLIE'}\n",
      "Last word -> LESLIE : \"There are some things we have to work out first.\"\n",
      "prediction :  June first!\n",
      "Real answer : There are some things we have to work out first.\n",
      "Bert Score : {'precision': [0.8707979321479797], 'recall': [0.8568404912948608], 'f1': [0.8637627959251404], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666669, 'rouge2': 0.0, 'rougeL': 0.16666666666666669, 'rougeLsum': 0.16666666666666669}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 7262.601616043423\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALEC: Okay. Okay. Like my mom always says, 'Don't get a hard-on'...\\nLESLIE: And like my mom always says... 'Marriage makes two people one. But you never know which one.'\\n\\n\", 'answer': \"Yeah, and like my pop says, 'The way to woman's heart is,to saw her in half.'\", 'gold_tag': 'ALEC might have a sarcastic and humorous personality', 'last_speaker': 'ALEC'}\n",
      "Last word -> ALEC : \"Yeah, and like my pop says, 'The way to woman's heart is,to saw her in half.'\"\n",
      "prediction :  That's good.\n",
      "Real answer : Yeah, and like my pop says, 'The way to woman's heart is,to saw her in half.'\n",
      "Bert Score : {'precision': [0.8759041428565979], 'recall': [0.8178815841674805], 'f1': [0.8458990454673767], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809525, 'rouge2': 0.0, 'rougeL': 0.09523809523809525, 'rougeLsum': 0.09523809523809525}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 88.55636485172964\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALEC: Did you forget one of your albums?\\n\\n', 'answer': \"I'm sorry to bother you here. It's Jules. After she left for work this morning, the finance company came and took away all her furniture, her Jeep, everything they could get their hands on... I couldn't reach her so I finally went over to her office. Alec -- she was fired three weeks ago! All this time, she's been pretending to go to work every day having this affair with her boss. And she's been doing a lot of coke .. Well, anyway, I confronted her at the apartment, and at first she denied everything, but then she went crazy -- and now she's locked herself in the apartment and she won't let me back in... I'm really worried about her. Alec, please. I need your help.\", 'gold_tag': \"LESLIE is a caring friend , LESLIE is concerned about Jules , LESLIE takes the initiative to check on Jules's wellbeing , LESLIE confronts Jules about her problems , LESLIE has a current issue that Jules has lost her job, possessions, and is now locked inside her apartment\", 'last_speaker': 'LESLIE'}\n",
      "Last word -> LESLIE : \"I'm sorry to bother you here. It's Jules. After she left for work this morning, the finance company came and took away all her furniture, her Jeep, everything they could get their hands on... I couldn't reach her so I finally went over to her office. Alec -- she was fired three weeks ago! All this time, she's been pretending to go to work every day having this affair with her boss. And she's been doing a lot of coke .. Well, anyway, I confronted her at the apartment, and at first she denied everything, but then she went crazy -- and now she's locked herself in the apartment and she won't let me back in... I'm really worried about her. Alec, please. I need your help.\"\n",
      "prediction :  I don't think so. I'm sure I packed them all.\n",
      "Real answer : I'm sorry to bother you here. It's Jules. After she left for work this morning, the finance company came and took away all her furniture, her Jeep, everything they could get their hands on... I couldn't reach her so I finally went over to her office. Alec -- she was fired three weeks ago! All this time, she's been pretending to go to work every day having this affair with her boss. And she's been doing a lot of coke .. Well, anyway, I confronted her at the apartment, and at first she denied everything, but then she went crazy -- and now she's locked herself in the apartment and she won't let me back in... I'm really worried about her. Alec, please. I need your help.\n",
      "Bert Score : {'precision': [0.8363453149795532], 'recall': [0.7966008186340332], 'f1': [0.8159893751144409], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09722222222222222, 'rouge2': 0.02816901408450704, 'rougeL': 0.08333333333333334, 'rougeLsum': 0.08333333333333334}\n",
      "bleu 1/2 : 2.488145748227211e-06 4.788438725073344e-07\n",
      "ppl : 16.889278145237867\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEIL: Come away with me.\\nEADY: What?\\nNEIL: New Zealand.\\nEADY: When?\\nNEIL: Soon.\\nEADY: You\\'re kidding.\\nNEIL: What\\'s stopping you? What\\'s here?\\nEADY: I don\\'t know you.\\nNEIL: What\\'s to know?\\nEADY: Are you married?\\nNEIL: Why?\\nEADY: Way you come and go.\\nNEIL: I deal with state officials. County. Weird hours. A lot of traveling, entertaining. The last thing I am is married.\\nEADY: You don\\'t know me at all, Neil...\\nNEIL: I know enough.\\nEADY: My father wanted me to marry someone in Taipei. It was like I was a piece of furniture: \"Go be his wife.\" After I left he won\\'t talk to me. Because I went on my own. I can\\'t let people tell roe what to do again. And that trust comes from knowing someone over time. This is hard between us for me. Because I like you very much.\\n\\n', 'answer': \"I have to leave. Come away with me. No one will ever tell you what to do... You'll never lose yourself with me.\", 'gold_tag': 'NEIL has plans to leave soon and wants EADY to join him , NEIL is inquisitive and adventurous, proposing to travel to New Zealand', 'last_speaker': 'NEIL'}\n",
      "Last word -> NEIL : \"I have to leave. Come away with me. No one will ever tell you what to do... You'll never lose yourself with me.\"\n",
      "prediction :  I like you too.\n",
      "Real answer : I have to leave. Come away with me. No one will ever tell you what to do... You'll never lose yourself with me.\n",
      "Bert Score : {'precision': [0.8848376274108887], 'recall': [0.8407431840896606], 'f1': [0.8622270226478577], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.004325847601560317 0.0011169290479382938\n",
      "ppl : 254.31950872675336\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEADY: What did you do? Was that you?\\nNEIL: It's what I don't do. I don't sell swimming pools. It would have been okay. You would have flown out after. You didn't need to do a thing. Now I'm jammed. We got to go together. Because we get dropped in a place and then I decide: New Zealand or Brazil or Tunisia, whatever. I can't leave a string back here to where I am.\\nEADY: What.\\nNEIL: I rob and steal for a living. Do you understand?\\nEADY: You killed people?\\nNEIL: If they got in the way. Yes. It's their problem.\\nEADY: The woman on the grass...where her husband got shot..\\nNEIL: Elaine Cerrito. Michael Cerrito's wife. Michael was my friend. He knew the risks. He didn't have to be there. He coulda been a...been a mailman.\\nEADY: I don't believe it.\\n\\n\", 'answer': \"Believe it. Eady. Get packed. Get dressed. Let's go.\", 'gold_tag': 'NEIL indicates a need to leave quickly, with their destination decided on the spot', 'last_speaker': 'NEIL'}\n",
      "Last word -> NEIL : \"Believe it. Eady. Get packed. Get dressed. Let's go.\"\n",
      "prediction :  I'm not asking you to. I'm telling you.\n",
      "Real answer : Believe it. Eady. Get packed. Get dressed. Let's go.\n",
      "Bert Score : {'precision': [0.8687442541122437], 'recall': [0.8735974431037903], 'f1': [0.871164083480835], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.912604640262575\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEIL: Eady! !\\nEADY: Why you do this to me! What I do to you?!\\n\\n', 'answer': 'Shut up!', 'gold_tag': 'Everyday Language', 'last_speaker': 'NEIL'}\n",
      "Last word -> NEIL : \"Shut up!\"\n",
      "prediction :  You don't want to do this to me.\n",
      "Real answer : Shut up!\n",
      "Bert Score : {'precision': [0.8364408612251282], 'recall': [0.835174560546875], 'f1': [0.8358072638511658], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18.360853323643475\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEIL: Use these credit cards. They say \"Mr. and Mrs.\" I reserved the car. Buy me some clothes. Here\\'s a list. I can\\'t go home for my stuff. Can you do it?\\nEADY: When\\'s it over?\\nNEIL: Twenty-two hours. Then we fly out of here...clean.\\nEADY: I want you to let me go. When will you let me go?\\nNEIL: You can go now. There\\'s the door, you want out...\\nEADY: No, I have to do what you say. But will you let me leave after?\\n\\n', 'answer': 'It will be different...', 'gold_tag': 'NEIL suggests a life involving criminal activities or running from something', 'last_speaker': 'NEIL'}\n",
      "Last word -> NEIL : \"It will be different...\"\n",
      "prediction :  You want me to promise you something?\n",
      "Real answer : It will be different...\n",
      "Bert Score : {'precision': [0.8179467916488647], 'recall': [0.8426141738891602], 'f1': [0.8300972580909729], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 45.47100070835503\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEIL: Any trouble?\\nEADY: No. When's it over?\\n\\n\", 'answer': \"Six hours. 8 p.m. I'll buy you lunch. Everything's smooth. We're going to fly away...\", 'gold_tag': \"NEIL is involved in an operation or job that will be concluded in six hours , NEIL is confident enough to plan ahead for a meal and a future escape , NEIL's job or operation will be over in six hours at 8 p.m.\", 'last_speaker': 'NEIL'}\n",
      "Last word -> NEIL : \"Six hours. 8 p.m. I'll buy you lunch. Everything's smooth. We're going to fly away...\"\n",
      "prediction :  It's never over.\n",
      "Real answer : Six hours. 8 p.m. I'll buy you lunch. Everything's smooth. We're going to fly away...\n",
      "Bert Score : {'precision': [0.8533647656440735], 'recall': [0.8439847230911255], 'f1': [0.8486487865447998], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913043, 'rouge2': 0.0, 'rougeL': 0.08695652173913043, 'rougeLsum': 0.08695652173913043}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 123.8803756135883\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEIL: Leave it running. ...be right back, Eady.\\n\\n', 'answer': 'Neil...?', 'gold_tag': 'Everyday Language', 'last_speaker': 'EADY'}\n",
      "Last word -> EADY : \"Neil...?\"\n",
      "prediction :  What is it?\n",
      "Real answer : Neil...?\n",
      "Bert Score : {'precision': [0.8406251668930054], 'recall': [0.8277721405029297], 'f1': [0.8341491222381592], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 140.93475091067572\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJAMES: Do you have an ice pick I can jam into my ears? I can’t listen to this song again!\\nCONNELL: No, but I have this. Be cool with that. So, were you on a date the other night?\\nJAMES: Um. I wouldn’t call it a date.\\nCONNELL: Not into Em?\\nJAMES: No, she’s great. But I’m not really looking for a girlfriend. I’m getting over a broken heart.\\nCONNELL: You didn’t tell her that, did you?\\nJAMES: Um, why?\\nCONNELL: Christ. Girls don’t want to hear about your broken heart.\\nJAMES: Wh-why not?\\nCONNELL: Because women don’t want a guy who’s all confused and torn up over someone else. Look, I’m not saying you should never be vulnerable in front of a girl. But you don’t play that card first.\\nJAMES: It’s a card? Like a...card?\\n\\n', 'answer': 'There’s a science to it all. You should like that, I bet you’re good at science.', 'gold_tag': 'JAMES could potentially have an interest or proficiency in science, as suggested by CONNELL', 'last_speaker': 'CONNELL'}\n",
      "Last word -> CONNELL : \"There’s a science to it all. You should like that, I bet you’re good at science.\"\n",
      "prediction :  Yeah, like a card. You know, you don’t want to show your hand too early. You want to wait until you’re sure you’re into her.\n",
      "Real answer : There’s a science to it all. You should like that, I bet you’re good at science.\n",
      "Bert Score : {'precision': [0.8577643632888794], 'recall': [0.8560172319412231], 'f1': [0.8568899035453796], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2608695652173913, 'rouge2': 0.04545454545454545, 'rougeL': 0.21739130434782608, 'rougeLsum': 0.21739130434782608}\n",
      "bleu 1/2 : 0.2 0.028867513459481287\n",
      "ppl : 14.428868229817411\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCONNELL: You got one of those little baby joints on you?\\nJAMES: I do.\\n\\n', 'answer': 'I could use that. Let’s go for a ride.', 'gold_tag': 'CONNELL has a habit of using marijuana', 'last_speaker': 'CONNELL'}\n",
      "Last word -> CONNELL : \"I could use that. Let’s go for a ride.\"\n",
      "prediction :  You know, I never saw a baby dope fiend.\n",
      "Real answer : I could use that. Let’s go for a ride.\n",
      "Bert Score : {'precision': [0.8448367118835449], 'recall': [0.8689383864402771], 'f1': [0.8567180633544922], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2105263157894737, 'rouge2': 0.0, 'rougeL': 0.2105263157894737, 'rougeLsum': 0.2105263157894737}\n",
      "bleu 1/2 : 0.2222222222222222 0.05270462766947299\n",
      "ppl : 52.14799984737568\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJAMES: Your mom okay?\\nCONNELL: My mother’s over three hundred pounds, half-blind from diabetes. She’s also got arthritis and emphysema. And now she can’t control her bowels. Personally, I’d rather be dead.\\nJAMES: I’m sorry...\\nCONNELL: That’s cool...\\nJAMES: It’s Neil Young.\\nCONNELL: Oh. Right.\\nJAMES: Cortez the Killer.\\nCONNELL: Yeh-yeh. ADVENTURELAND (revised 8/5/07)\\nJAMES: You gotta tell me your Neil Young story. He’s, like, a real hero to me. Oh, shit-\\nCONNELL: What the fuck are you doing?\\nJAMES: Cop car.\\nCONNELL: Uh, desperado, it’s a driving school car.\\nJAMES: Oh. So you going tonight?\\nCONNELL: Razzmatazz? Not really my scene. How goes it with Em?\\n\\n', 'answer': 'It’s going...she’s...it’s been... I think I’m in love with her.', 'gold_tag': 'James admits to being in love with a girl named Em', 'last_speaker': 'JAMES'}\n",
      "Last word -> JAMES : \"It’s going...she’s...it’s been... I think I’m in love with her.\"\n",
      "prediction :  I don’t know. I haven’t talked to her since the funeral.\n",
      "Real answer : It’s going...she’s...it’s been... I think I’m in love with her.\n",
      "Bert Score : {'precision': [0.8966180086135864], 'recall': [0.8655328154563904], 'f1': [0.880801260471344], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20689655172413793, 'rouge2': 0.0, 'rougeL': 0.20689655172413793, 'rougeLsum': 0.20689655172413793}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 11.87332379246106\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCONNELL: I talked to Em. I know you know... Look, I can’t expect you to be happy about any of this. But will you hear me out? You’re a smart guy. You know that it’s possible to love two people at the same time, right? I love my wife. I really do. I don’t want to hurt her. I fucking despise the idea of her getting hurt. And I don’t think she has to. Beat.\\nJAMES: I won’t tell anyone.\\nCONNELL: Thank you.\\nJAMES: What about Frigo?\\nCONNELL: He won’t tell anyone. I gave him fifty bucks. Are we cool?\\n\\n', 'answer': 'Yeah.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JAMES'}\n",
      "Last word -> JAMES : \"Yeah.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : Yeah.\n",
      "Bert Score : {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 1.0, 'rouge2': 0.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
      "bleu 1/2 : 1.0 0.316227766016838\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTARLETON: General, a message from the commander of the rebel militia.\\nCORNWALLIS: It seems our Swamp Fox wants to have a formal parley.\\nTARLETON: Are you going to meet with him?\\n\\n', 'answer': 'Most certainly. Arrange it.', 'gold_tag': 'CORNWALLIS has the authority to command TARLETON to arrange the meeting , CORNWALLIS will soon have a meeting with the commander of the rebel militia , TARLETON has to arrange a meeting between CORNWALLIS and the commander of the rebel militia soon', 'last_speaker': 'CORNWALLIS'}\n",
      "Last word -> CORNWALLIS : \"Most certainly. Arrange it.\"\n",
      "prediction :  I'm not sure. I've had enough of his tricks.\n",
      "Real answer : Most certainly. Arrange it.\n",
      "Bert Score : {'precision': [0.8669780492782593], 'recall': [0.8871045112609863], 'f1': [0.8769258260726929], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 20.34616586723681\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORNWALLIS: From General Clinton in New York... \"... your request to move north is denied until you have properly dealt with your militia problem.\" He underlined, \\'militia\\'. \"You have spent over six months dealing with a six-week problem. It is essential that you quell the militia...\" Underlined again. \"... insurgency, particularly because of the likely move south of Washington and the inevitable arrival of the French. Militia, as you have so often pointed out, is not worth the attention of a significant army, hence it is mystifying why militia has bedeviled you for so long...\" \"... it is my fervent hope that the vigor of your campaign comes to match the vigor of your correspondence with your Parliamentary and Court patrons. Only then might you share in the victory, on the verge of which I now stand.\" \"Your guardedly respectful Commander, General Sir George Clinton.\" If I fail, you fail.\\nTARLETON: Perhaps.\\nCORNWALLIS: And if I triumph, you triumph.\\nTARLETON: Probably.\\nCORNWALLIS: How can we end this madness?\\nTARLETON: Difficult, sir. This is, as you pointed out, a civil war.\\nCORNWALLIS: Civility is a secondary virtue. It is superseded by duty.\\n\\n', 'answer': 'I understand, sir.', 'gold_tag': 'TARLETON understands the importance of duty as pointed out by Cornwallis', 'last_speaker': 'TARLETON'}\n",
      "Last word -> TARLETON : \"I understand, sir.\"\n",
      "prediction : I do not disagree, sir.\n",
      "Real answer : I understand, sir.\n",
      "Bert Score : {'precision': [0.8975269794464111], 'recall': [0.9250317215919495], 'f1': [0.9110718369483948], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.5, 'rouge2': 0.0, 'rougeL': 0.5, 'rougeLsum': 0.5}\n",
      "bleu 1/2 : 0.4 0.10000000000000002\n",
      "ppl : 21.723319323667265\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORNWALLIS: Do you see that, Colonel?\\n\\n', 'answer': \"Unless I'm dreaming, I think I see irregulars at their center.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'TARLETON'}\n",
      "Last word -> TARLETON : \"Unless I'm dreaming, I think I see irregulars at their center.\"\n",
      "prediction :  Yes, sir.\n",
      "Real answer : Unless I'm dreaming, I think I see irregulars at their center.\n",
      "Bert Score : {'precision': [0.8281302452087402], 'recall': [0.8350076079368591], 'f1': [0.8315547108650208], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 196.4543948165058\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSYDNEY: Had a sudden intense craving for a cherry popsicle.\\nLUKE: You can check in that freezer.\\nSYDNEY: What a relief. I\\'m Sydney. You?\\nLUKE: Luke.\\nSYDNEY: Workin\\' late, huh? Luke?\\nLUKE: Yeah, four AM. It sucks.\\nSYDNEY: Sometimes you guys are just unfathomably stupid.\\nLUKE: Excuse me?\\nSYDNEY: Why in the world do guys say \"it sucks\" as if it were a bad thing? I mean, every guy\\'s dying to get a blow job, right? So, you think they\\'d treat those words with profound respect, like holy scripture. \"What an unbelievable sunset, honey: doesn\\'t it just SUCK?,\"... \"You won an Olympic Gold Medal?!, that BLOWS!\"\\nLUKE: I guess you\\'re right.\\nSYDNEY: It must be great at your age. That river of testosterone coursing through your veins, the damn about to burst! How about we just lock this place up and go for an Olympic Gold?\\nLUKE: No thanks. Jeez, lady.\\nSYDNEY: I ought to dye my hair. Don\\'t you think?\\nLUKE: Uh, I don\\'t know. Looks fine.\\nSYDNEY: Your hair is such an incredible color.\\nLUKE: It\\'s brown.\\nSYDNEY: I love it. Do you think I could cut just a little piece? Match the color? It really \"sucks.\"\\nLUKE: Nah, c\\'mon. You\\'re messin\\' with me.\\nSYDNEY: I\\'m not. I love it. You really should get rid a\\' that thing, anyway. I have clippers in my bag.\\nLUKE: What thing?\\nSYDNEY: Cowlick. Right here. See? I can just snip it off.\\nLUKE: Hey.\\nSYDNEY: What\\'s the matter? Don\\'t you like being touched? Don\\'t you like being a guy?\\nLUKE: No. I mean,... What? Sorry, but you\\'re just bizarre.\\n\\n', 'answer': \"May be. But I learned long ago, you can't change your true nature, even if it can change you.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SYDNEY'}\n",
      "Last word -> SYDNEY : \"May be. But I learned long ago, you can't change your true nature, even if it can change you.\"\n",
      "prediction :  You're just bizarre.\n",
      "Real answer : May be. But I learned long ago, you can't change your true nature, even if it can change you.\n",
      "Bert Score : {'precision': [0.8700456023216248], 'recall': [0.8372591137886047], 'f1': [0.8533375859260559], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08333333333333334, 'rouge2': 0.0, 'rougeL': 0.08333333333333334, 'rougeLsum': 0.08333333333333334}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 75.01316785955522\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSYDNEY: What are we doing here?\\nLUKE: Didn't want anyone around. So, I did what you said.\\nSYDNEY: Amazing, huh?\\nLUKE: Weird. Awful.\\nSYDNEY: Hmm. Was it difficult making the switch?\\nLUKE: No. It was hard gettin' back. I need an owner's manual.\\nSYDNEY: A lot of guys could use one of those.\\nLUKE: So, what now? Do I take pills or something?\\nSYDNEY: No, it doesn't work like that. This may sound odd, but I need to know if you're attracted to me.\\nLUKE: What? No.\\nSYDNEY: Hmm. You're not gay, are you?\\nLUKE: NO! Jeez! I'm just not attracted to you like that.\\nSYDNEY: Okay, calm down. This could be a problem. Right now, you can go either way anytime you want. It's a very special and critical time for a Z, something you'll experience only once in life.\\nLUKE: Good.\\nSYDNEY: You need to use this incredible opportunity you've been given, to figure out which you're supposed to be: male or female.\\nLUKE: What?\\nSYDNEY: Don't you see? You get to choose.\\nLUKE: I don't want to choose. I want to be a guy.\\nSYDNEY: Yes, well, the thing is, sometimes your desires can conflict with your desires. It's important to know for sure.\\nLUKE: Believe me, I know.\\nSYDNEY: I think you need to try again.\\nLUKE: No way!\\nSYDNEY: Why're you so resistant? If the truth is, you want to be a guy, great, but if not...\\nLUKE: Don't even say that!\\nSYDNEY: Well, clearly some part of you feels differently. You couldn't change if you didn't want to.\\nLUKE: What?! That's crap!\\nSYDNEY: That's the thing about the truth. It'll set you free, but first it can really piss you off.\\nLUKE: This is nuts! I'm supposed to be a guy!\\nSYDNEY: Then what's the problem? You are one.\\nLUKE: You're not gonna' help?!\\nSYDNEY: I will, the moment you're ready to try again. You can come back to my place right now if you want.\\n\\n\", 'answer': 'Forget it!', 'gold_tag': 'LUKE is resistant and frustrated', 'last_speaker': 'LUKE'}\n",
      "Last word -> LUKE : \"Forget it!\"\n",
      "prediction :  I don't wanna' go anywhere with you.\n",
      "Real answer : Forget it!\n",
      "Bert Score : {'precision': [0.8350538611412048], 'recall': [0.8558365106582642], 'f1': [0.8453174829483032], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 49.44727941365703\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSYDNEY: Oh, honey. Come in.\\nLUKE: You're one too. Why didn't you tell me?\\nSYDNEY: I didn't want to confuse the issue.\\nLUKE: So, it's true what you said? You really know. I wouldn't change unless I wanted to?\\nSYDNEY: Maybe some part of you.\\nLUKE: What part? How much of me? I mean, for it to work? Half? More than half? What if it was only a tiny bit, -a thought?\\nSYDNEY: I don't know. But I believe there may be thousands of Z's out there, millions for all we know, go their whole lives without even knowing they are one. Nothing ever happens. You couldn't keep it from\\nLUKE: I love being with Michelle. How come I can't control it when she's around?\\nSYDNEY: I think whatever part of yourself you deny, just gets bigger and bigger until it takes you over.\\nLUKE: You think I don't really want to be a man.\\nSYDNEY: I think for some, making it stop is more important than knowing who you are. It was for me.\\nLUKE: Maybe for me too.\\nSYDNEY: Right now, you're Morphescent. The key is to have sex with another Z. You become Adulmorphic. Your gender locks. You can't just change anytime you want.\\nLUKE: Another Z?\\nSYDNEY: That's why I came all the way out here.\\nLUKE: And why you keep tryin' to get me in the sack?\\nSYDNEY: Thought maybe I could save you some distress. But you say you're not attracted to me. For it to work, both of us have to be into it.\\nLUKE: That won't be a problem.\\nSYDNEY: Okay then.\\nLUKE: Tonight.\\n\\n\", 'answer': 'Not right now? Okay. Tonight.', 'gold_tag': \"SYDNEY's temporal information\", 'last_speaker': 'SYDNEY'}\n",
      "Last word -> SYDNEY : \"Not right now? Okay. Tonight.\"\n",
      "prediction :  I'll make sure I'm ready.\n",
      "Real answer : Not right now? Okay. Tonight.\n",
      "Bert Score : {'precision': [0.8240492343902588], 'recall': [0.8397138714790344], 'f1': [0.8318078517913818], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 34.475703560385995\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSYDNEY: Do you like this dress?\\nLUKE: Sure. Looks great on you. Man, dresses! Even without everything else, dresses are reason enough right there to stay a guy.\\nSYDNEY: \"Stay a guy?\" Let me get this straight. You didn\\'t decide to be a woman?\\nLUKE: No. Of course not. What?\\nSYDNEY: Just testing you. Hold on a moment. There\\'s something I forgot...\\nLUKE: What\\'s that for?\\nSYDNEY: You\\'ve never done it with another Z. Trust me, you need to be tied down.\\nLUKE: Does it hurt?\\n\\n', 'answer': 'On the contrary.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SYDNEY'}\n",
      "Last word -> SYDNEY : \"On the contrary.\"\n",
      "prediction :  No, it doesn't hurt. You're just not used to it. You're going to have to get used to it.\n",
      "Real answer : On the contrary.\n",
      "Bert Score : {'precision': [0.8408071994781494], 'recall': [0.8416748046875], 'f1': [0.8412407636642456], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 7.66628096709202\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICKY: I was posted here after Berlin.\\n\\n', 'answer': \"Where's Daniels?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'BOURNE'}\n",
      "Last word -> BOURNE : \"Where's Daniels?\"\n",
      "prediction :  Why?\n",
      "Real answer : Where's Daniels?\n",
      "Bert Score : {'precision': [0.9107837677001953], 'recall': [0.8370622396469116], 'f1': [0.8723682761192322], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3142.135932895678\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICKY: Okay. They know you're here.\\nBOURNE: How long do I have?\\n\\n\", 'answer': 'Three minutes...', 'gold_tag': 'Everyday Language', 'last_speaker': 'NICKY'}\n",
      "Last word -> NICKY : \"Three minutes...\"\n",
      "prediction :  A few hours.\n",
      "Real answer : Three minutes...\n",
      "Bert Score : {'precision': [0.9067773818969727], 'recall': [0.8775119781494141], 'f1': [0.8919046521186829], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 587.2995587986933\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICKY: 8 o'clock this morning, he wired $100,000. to a numbered bank account in Tangier.\\nBOURNE: Okay, Tangier is about 300 miles away, we can make the morning ferry.\\n\\n\", 'answer': 'And then what?', 'gold_tag': 'Everyday Language', 'last_speaker': 'NICKY'}\n",
      "Last word -> NICKY : \"And then what?\"\n",
      "prediction :  You're not going to make it.\n",
      "Real answer : And then what?\n",
      "Bert Score : {'precision': [0.8418402671813965], 'recall': [0.8302294611930847], 'f1': [0.83599454164505], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.6234708093208\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICKY: What are you after, Jason? Why are you looking for Daniels?\\nBOURNE: Do you know who this is?\\nNICKY: That's Daniels. I don't know who that is.\\nBOURNE: I have to get back to the beginning...or I'll never be free of this. I think he started Treadstone. I remember meeting him. I remember the first day... Daniels brought me to him.\\nNICKY: What happened?\\n\\n\", 'answer': 'An initiation...I guess...', 'gold_tag': 'BOURNE was involved in some initiation process spearheaded by Daniels', 'last_speaker': 'BOURNE'}\n",
      "Last word -> BOURNE : \"An initiation...I guess...\"\n",
      "prediction : I don't know. I don't know how he got away. I don't know how he got the files.\n",
      "Real answer : An initiation...I guess...\n",
      "Bert Score : {'precision': [0.8415188789367676], 'recall': [0.832301914691925], 'f1': [0.8368850946426392], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 6.144482346161916\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOURNE: Now they found Daniels, do you know where he is?\\nNICKY: They'll get one of the operatives to terminate him.\\n\\n\", 'answer': 'Find out who.', 'gold_tag': 'BOURNE is determined and assertive, demanding immediate results', 'last_speaker': 'BOURNE'}\n",
      "Last word -> BOURNE : \"Find out who.\"\n",
      "prediction :  They're not going to get to him first.\n",
      "Real answer : Find out who.\n",
      "Bert Score : {'precision': [0.8390167951583862], 'recall': [0.8674702644348145], 'f1': [0.8530063033103943], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 35.372136512772364\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOURNE: Tell him you're going to meet him and that you have a new phone for him.\\nNICKY: If you stop Desh they'll just get someone else.\\n\\n\", 'answer': \"We're not going to stop him. We're going to follow him. He'll take us right to Daniels.\", 'gold_tag': 'BOURNE has knowledge or experience in covert operations', 'last_speaker': 'BOURNE'}\n",
      "Last word -> BOURNE : \"We're not going to stop him. We're going to follow him. He'll take us right to Daniels.\"\n",
      "prediction :  That's not the point. He's the only one who can help us now.\n",
      "Real answer : We're not going to stop him. We're going to follow him. He'll take us right to Daniels.\n",
      "Bert Score : {'precision': [0.8879176378250122], 'recall': [0.8855751752853394], 'f1': [0.8867448568344116], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17142857142857143, 'rouge2': 0.0, 'rougeL': 0.17142857142857143, 'rougeLsum': 0.17142857142857143}\n",
      "bleu 1/2 : 0.11309868932179762 0.026322287438753814\n",
      "ppl : 11.172817932345952\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOURNE: I was starting to remember who they were...in India...with Marie.\\nNICKY: It's just going to lead to more killing, Jason. Are you sure you want that?\\n\\n\", 'answer': \"I've killed people and I've tried to apologize for what I've done, for what I am. None of it makes it better... They're going to come for you again. You are going to have to run now.\", 'gold_tag': \"BOURNE is a killer who is experiencing guilt and remorse for his actions , NICKY is aware of BOURNE's violent past , BOURNE implies a potential threat to NICKY in the near future\", 'last_speaker': 'BOURNE'}\n",
      "Last word -> BOURNE : \"I've killed people and I've tried to apologize for what I've done, for what I am. None of it makes it better... They're going to come for you again. You are going to have to run now.\"\n",
      "prediction :  I'm sure.\n",
      "Real answer : I've killed people and I've tried to apologize for what I've done, for what I am. None of it makes it better... They're going to come for you again. You are going to have to run now.\n",
      "Bert Score : {'precision': [0.8782181739807129], 'recall': [0.8241313099861145], 'f1': [0.8503155708312988], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.04545454545454545, 'rouge2': 0.0, 'rougeL': 0.04545454545454545, 'rougeLsum': 0.04545454545454545}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 126.33851597446244\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNARRATOR: Napoleon was born at Ajaccio in Corsica on August 15th, 1769. He had not been a healthy baby and his mother, Letizia, lavished him with care and devotion. In middle age, he would write about her from St. Helena.\\n\\n', 'answer': 'My mother has always loved me. She would do anything for me.', 'gold_tag': \"NAPOLEON V.O. had a loving relationship with his mother, Letizia, who lavished him with care and devotion , NAPOLEON V.O. acknowledges love and care from his mother , NAPOLEON V.O. refers to his mother's past love and care, implying nostalgia and reflection from his middle age as he writes from St. Helena\", 'last_speaker': 'NAPOLEON (V.O.)'}\n",
      "Last word -> NAPOLEON (V.O.) : \"My mother has always loved me. She would do anything for me.\"\n",
      "prediction :   I remember how my mother used to take me in her arms and sing to me. She sang to me of love and of glory, of the great deeds of our ancestors, of the gods of Greece and Rome.\n",
      "Real answer : My mother has always loved me. She would do anything for me.\n",
      "Bert Score : {'precision': [0.8604879975318909], 'recall': [0.901043176651001], 'f1': [0.8802987933158875], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.196078431372549, 'rouge2': 0.08163265306122448, 'rougeL': 0.196078431372549, 'rougeLsum': 0.196078431372549}\n",
      "bleu 1/2 : 0.07692307692307693 0.044992127066584765\n",
      "ppl : 8.481331472237782\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNARRATOR: His moods at this time were complex and varied.\\n\\n', 'answer': 'Life is a burden for me. Nothing gives me any pleasure; I find only sadness in everything around me. It is very difficult because the ways of those with whom I live, and probably always shall live, are as different from mine as moonlight is from sunlight.', 'gold_tag': \"NAPOLEON V.O. sees life as a burden and finds no pleasure in anything, experiencing only sadness , NAPOLEON V.O.'s personality is melancholic and introverted , NAPOLEON V.O.'s lifestyle and way of thinking are drastically different from those around him\", 'last_speaker': 'NAPOLEON (V.O.)'}\n",
      "Last word -> NAPOLEON (V.O.) : \"Life is a burden for me. Nothing gives me any pleasure; I find only sadness in everything around me. It is very difficult because the ways of those with whom I live, and probably always shall live, are as different from mine as moonlight is from sunlight.\"\n",
      "prediction :  I was a man of many moods.\n",
      "Real answer : Life is a burden for me. Nothing gives me any pleasure; I find only sadness in everything around me. It is very difficult because the ways of those with whom I live, and probably always shall live, are as different from mine as moonlight is from sunlight.\n",
      "Bert Score : {'precision': [0.8773037791252136], 'recall': [0.8344817161560059], 'f1': [0.8553571105003357], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.07407407407407407, 'rougeLsum': 0.07407407407407407}\n",
      "bleu 1/2 : 0.0014136453239738962 0.0002787746173878426\n",
      "ppl : 37.93827810985048\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNARRATOR: He made friends with a family called Columbier, and would later write of his first flirtation with their daughter, Caroline.\\n\\n', 'answer': 'It will scarcely be considered credible, perhaps, but our whole business consisted in eating cherries together.', 'gold_tag': \"NAPOLEON V.O. had a flirtation with the Columbier's daughter, Caroline , NAPOLEON V.O. and Caroline spent time eating cherries together , NAPOLEON V.O. suggests a person with a young and playful personality\", 'last_speaker': 'NAPOLEON (V.O.)'}\n",
      "Last word -> NAPOLEON (V.O.) : \"It will scarcely be considered credible, perhaps, but our whole business consisted in eating cherries together.\"\n",
      "prediction :  When I met Caroline, I was smitten. I was a young man, and I was in love.\n",
      "Real answer : It will scarcely be considered credible, perhaps, but our whole business consisted in eating cherries together.\n",
      "Bert Score : {'precision': [0.8600800037384033], 'recall': [0.8437855839729309], 'f1': [0.8518548607826233], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06060606060606061, 'rouge2': 0.0, 'rougeL': 0.06060606060606061, 'rougeLsum': 0.06060606060606061}\n",
      "bleu 1/2 : 0.0588235294117647 0.019174124721184262\n",
      "ppl : 14.921336487343977\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNAPOLEON (V.O.): Soldiers, you are half-naked and badly clothed. The authorities find much fault with you and yet can give nothing. Your patience, your courage are admirable but you are not getting any fame. I will lead you into the must fruitful plains in the world -- rich provinces and great cities shall be your possessions, and then you will have wealth, honor and fame in full measure. ANIMATED MAP\\n\\n', 'answer': 'With the Italian campaign, Napoleon steps onto the stage as a figure of European importance. A dozen victories in as many months would be announced in dramatic and highly colored bulletins. The battles of the revolution had been so far mainly defensive. Now, there was revealed a new kind of offensive warfare such as had not been seen in Europe for centuries.', 'gold_tag': \"The NARRATOR is an objective observer , The NARRATOR provides historical context and commentary on Napoleon's actions and tactics , The NARRATOR is referencing the current period of the Italian campaign and the shift in warfare tactics\", 'last_speaker': 'NARRATOR'}\n",
      "Last word -> NARRATOR : \"With the Italian campaign, Napoleon steps onto the stage as a figure of European importance. A dozen victories in as many months would be announced in dramatic and highly colored bulletins. The battles of the revolution had been so far mainly defensive. Now, there was revealed a new kind of offensive warfare such as had not been seen in Europe for centuries.\"\n",
      "prediction :  The invasion of Russia was a turning point in the Napoleonic Wars.\n",
      "Real answer : With the Italian campaign, Napoleon steps onto the stage as a figure of European importance. A dozen victories in as many months would be announced in dramatic and highly colored bulletins. The battles of the revolution had been so far mainly defensive. Now, there was revealed a new kind of offensive warfare such as had not been seen in Europe for centuries.\n",
      "Bert Score : {'precision': [0.884338915348053], 'recall': [0.8423077464103699], 'f1': [0.8628117442131042], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16216216216216214, 'rouge2': 0.0, 'rougeL': 0.13513513513513511, 'rougeLsum': 0.13513513513513511}\n",
      "bleu 1/2 : 0.007751926799504657 0.0010452695964102323\n",
      "ppl : 21.745425213966538\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNARRATOR: making political decisions and treaties like a Roman Conqueror, enlarging his role to ruler of Italy. Only his tremendous success and ever increasing popularity prevented the Directory from replacing him.\\n\\n', 'answer': 'From that moment on, I foresaw what I might be. Already I felt the earth flee beneath me, as if I were being carried away up to the sky.', 'gold_tag': \"NAPOLEON V.O. perceives himself as a successful and popular ruler , NAPOLEON V.O. has aspirations of expanding his rule , NAPOLEON V.O.'s statement suggests a moment of realization about his potential, which is in the past from his perspective\", 'last_speaker': 'NAPOLEON (V.O.)'}\n",
      "Last word -> NAPOLEON (V.O.) : \"From that moment on, I foresaw what I might be. Already I felt the earth flee beneath me, as if I were being carried away up to the sky.\"\n",
      "prediction :  I was the most powerful man in Europe. I was the most powerful man in Europe. I was the most powerful man in Europe. I was the most powerful man in Europe.\n",
      "Real answer : From that moment on, I foresaw what I might be. Already I felt the earth flee beneath me, as if I were being carried away up to the sky.\n",
      "Bert Score : {'precision': [0.8494558334350586], 'recall': [0.8220652341842651], 'f1': [0.8355361223220825], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.19672131147540986, 'rouge2': 0.0, 'rougeL': 0.19672131147540986, 'rougeLsum': 0.19672131147540986}\n",
      "bleu 1/2 : 0.1875 0.024593468841898232\n",
      "ppl : 3.792825162839584\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNARRATOR: Led by the warlike Queen Louisa, and her fashion-minded husband, King Frederich Wilhelm, the Prussians still believed themselves cast in the mold of Frederick the Great, and more than a match for Napoleon. The King had a special collection of 60 splendid uniforms, and was personally involved in the design of all the Prussian army uniforms.\\n\\n', 'answer': 'If the French army had been commanded at Jena and Auerstadt by a tailor, the King of Prussia would certainly have gained the day.', 'gold_tag': 'NAPOLEON V.O. is a historical figure, specifically a military leader , NAPOLEON V.O. references the Battle of Jena and Auerstadt, suggesting his role in this event and displaying his strategic thoughts , NAPOLEON V.O. shows a keen understanding of the role of appearances and presentation in warfare', 'last_speaker': 'NAPOLEON (V.O.)'}\n",
      "Last word -> NAPOLEON (V.O.) : \"If the French army had been commanded at Jena and Auerstadt by a tailor, the King of Prussia would certainly have gained the day.\"\n",
      "prediction : ...I have no use for your King, your Queen, or your uniforms. I have no use for you.\n",
      "Real answer : If the French army had been commanded at Jena and Auerstadt by a tailor, the King of Prussia would certainly have gained the day.\n",
      "Bert Score : {'precision': [0.8443713784217834], 'recall': [0.8307758569717407], 'f1': [0.8375184535980225], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809525, 'rouge2': 0.0, 'rougeL': 0.09523809523809525, 'rougeLsum': 0.09523809523809525}\n",
      "bleu 1/2 : 0.03980729503187717 0.012953122103681144\n",
      "ppl : 16.94542721083676\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNARRATOR: On January 1st, 1814, France itself was invaded. Now, with a small army of raw recruits, Napoleon would have to face the powerful combination of England, Russia, Prussia and Austria, operating against him together, for the first time. The balance of numbers had tilted irretrievably against him.\\n\\n', 'answer': 'A year ago, the whole of Europe was marching alongside of us. Today,', 'gold_tag': 'NAPOLEON V.O. had an alliance with Europe , NAPOLEON V.O. refers to the shift in alliances over the past year', 'last_speaker': 'NAPOLEON (V.O.)'}\n",
      "Last word -> NAPOLEON (V.O.) : \"A year ago, the whole of Europe was marching alongside of us. Today,\"\n",
      "prediction :  I know I've been defeated, but I can't accept it. I've been defeated by the same people I defeated before. I must know why.\n",
      "Real answer : A year ago, the whole of Europe was marching alongside of us. Today,\n",
      "Bert Score : {'precision': [0.8571264147758484], 'recall': [0.8551373481750488], 'f1': [0.8561307191848755], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05, 'rouge2': 0.0, 'rougeL': 0.05, 'rougeLsum': 0.05}\n",
      "bleu 1/2 : 0.041666666666666664 0.013459547551454133\n",
      "ppl : 9.699034072830084\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLAROCHE: Once you get the sickness, it takes over your life. I started out just photographing 'em. Now look at me. It'll happen to you. You'll see.\\nORLEAN: I don't think so. I'm not prone to --\\nLAROCHE: Angraecum sesquipedale! Beauty! God! Darwin wrote about this one. Charles Darwin? Evolution guy? Hello?\\n\\n\", 'answer': 'I know who Darwin is.', 'gold_tag': 'ORLEAN is aware of Charles Darwin and his work', 'last_speaker': 'ORLEAN'}\n",
      "Last word -> ORLEAN : \"I know who Darwin is.\"\n",
      "prediction :  I think you're mistaken, Laroche. Darwin passed away in 1882.\n",
      "Real answer : I know who Darwin is.\n",
      "Bert Score : {'precision': [0.850229024887085], 'recall': [0.8931573033332825], 'f1': [0.8711646795272827], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25000000000000006, 'rouge2': 0.0, 'rougeL': 0.25000000000000006, 'rougeLsum': 0.25000000000000006}\n",
      "bleu 1/2 : 0.2 0.04714045207910317\n",
      "ppl : 18.09106494816583\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLAROCHE: See that nectary all the way down there? Darwin hypothesized a moth with a nose twelve inches long to pollinate it. Everyone thought he was a loon. Then, sure enough, they found this moth with a twelve inch proboscis -- proboscis means nose, by the way -- and --\\nORLEAN: I know what proboscis means.\\nLAROCHE: Every one of these flowers has a specific relationship with the insect that pollinates it. There's an orchid that looks exactly like this particular insect. So the bug humps the flower and\\nORLEAN: I get it.\\n\\n\", 'answer': \"That's called pseudo-copulation. These flowers are smart! You gotta fall in love with them. Once you learn anything about orchids, you'll devote your life to learning everything about them.\", 'gold_tag': 'LAROCHE has extensive knowledge about orchids and insects', 'last_speaker': 'LAROCHE'}\n",
      "Last word -> LAROCHE : \"That's called pseudo-copulation. These flowers are smart! You gotta fall in love with them. Once you learn anything about orchids, you'll devote your life to learning everything about them.\"\n",
      "prediction :  Darwin said it was an example of adaptation. Now, what's your opinion?\n",
      "Real answer : That's called pseudo-copulation. These flowers are smart! You gotta fall in love with them. Once you learn anything about orchids, you'll devote your life to learning everything about them.\n",
      "Bert Score : {'precision': [0.8619133830070496], 'recall': [0.8430697917938232], 'f1': [0.8523874282836914], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08888888888888889, 'rouge2': 0.0, 'rougeL': 0.08888888888888889, 'rougeLsum': 0.08888888888888889}\n",
      "bleu 1/2 : 0.020210089552970725 0.006675172886333876\n",
      "ppl : 38.02887419341492\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLAROCHE: No shit I'm a fun character. Who's gonna play me?\\nORLEAN: I've got to write it first. Someone's gotta write the screenplay. Most things never get made. It's premature to --\\n\\n\", 'answer': 'I think I should play me.', 'gold_tag': 'LAROCHE expresses his desire to play himself , LAROCHE has an interest in acting', 'last_speaker': 'LAROCHE'}\n",
      "Last word -> LAROCHE : \"I think I should play me.\"\n",
      "prediction :  You don't know what you're talking about. You can't just write a screenplay. You gotta have a real story to write a screenplay about. And I got a story.\n",
      "Real answer : I think I should play me.\n",
      "Bert Score : {'precision': [0.840338408946991], 'recall': [0.884078860282898], 'f1': [0.8616539239883423], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05263157894736842, 'rouge2': 0.0, 'rougeL': 0.05263157894736842, 'rougeLsum': 0.05263157894736842}\n",
      "bleu 1/2 : 0.03448275862068965 0.011097419040461881\n",
      "ppl : 7.118792770328155\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nORLEAN: Laroche, can I ask you a personal question?\\n\\n', 'answer': \"We're not lost.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'LAROCHE'}\n",
      "Last word -> LAROCHE : \"We're not lost.\"\n",
      "prediction :  Of course, Mr. Orleans.\n",
      "Real answer : We're not lost.\n",
      "Bert Score : {'precision': [0.8553690910339355], 'recall': [0.8511867523193359], 'f1': [0.8532727956771851], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 175.47635607453515\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLAROCHE: The jewel of the Fakahatchee.\\nORLEAN: I still don't get it. I mean, there it is. I can see it's pretty, but --\\n\\n\", 'answer': \"You'll get it.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'LAROCHE'}\n",
      "Last word -> LAROCHE : \"You'll get it.\"\n",
      "prediction :  That is not the Jewel of Fakahatchee.\n",
      "Real answer : You'll get it.\n",
      "Bert Score : {'precision': [0.8345752954483032], 'recall': [0.8840587139129639], 'f1': [0.8586046695709229], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 96.70404900836428\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFRANCES: And I can't understand how it can hurt to be honest, but the more I tried to explain --\\nLILLIAN: Don't listen to him, little sister. When you're proud of what you are, you don't refuse the label, understand?\\nFRANCES: Yes, Ma.\\n\\n\", 'answer': 'And you... should be proud. You won that contest and made a name for yourself.', 'gold_tag': 'LILLIAN pushes Frances to embrace pride in her achievements , FRANCES recently won a contest, demonstrating her potential and ambition', 'last_speaker': 'LILLIAN'}\n",
      "Last word -> LILLIAN : \"And you... should be proud. You won that contest and made a name for yourself.\"\n",
      "prediction :  You don't have to prove anything to me, but I want you to know that I'm proud of you, no matter what.\n",
      "Real answer : And you... should be proud. You won that contest and made a name for yourself.\n",
      "Bert Score : {'precision': [0.8582758903503418], 'recall': [0.8873745799064636], 'f1': [0.872582733631134], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2051282051282051, 'rouge2': 0.0, 'rougeL': 0.15384615384615385, 'rougeLsum': 0.15384615384615385}\n",
      "bleu 1/2 : 0.0909090909090909 0.020806259464411975\n",
      "ppl : 5.268600360014203\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLILLIAN: ...and here's the one from Duluth. A war widow with five children. She works in a defense plant and she's very worried about you. I answered her that she shouldn't let worry over you affect her vital work; and that you'd be back on the silver screen in no time. And here's one from nice Mr. Zeiss. He says that...\\nFRANCES: Why are these all opened?\\nLILLIAN: Well, they needed immediate answers, Frances. It's good manners and good sense. You shouldn't be bothering yourself with these right now.\\nFRANCES: Then why did you bring them?\\nLILLIAN: It's your fan mail, little sister.\\nFRANCES: You kill me, Mama.\\nLILLIAN: What?\\n\\n\", 'answer': 'Go on...', 'gold_tag': 'Everyday Language', 'last_speaker': 'FRANCES'}\n",
      "Last word -> FRANCES : \"Go on...\"\n",
      "prediction :  You're always saying things that are so...\n",
      "Real answer : Go on...\n",
      "Bert Score : {'precision': [0.7962247133255005], 'recall': [0.8308040499687195], 'f1': [0.8131469488143921], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 35.05876561214694\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLILLIAN: Frances, play 'Flow Gently Sweet Afton'.\\nFRANCES: Oh Mama, I'm so... tired of that song.\\nLILLIAN: Please. I want you to. It would make me so happy. It's just a flow gently sweet Afton day. Life has been so good to me. Why, I have just about everything one could wish... but I still have\\nFRANCES: I think I need a little air.\\nLILLIAN: What's wrong?\\nFRANCES: Nothing. I think I'll just go out for awhile.\\nLILLIAN: Where are you going?\\nFRANCES: For a walk, Mama. Just a walk.\\nLILLIAN: How long will you be?\\nFRANCES: Not long.\\nLILLIAN: I'll have lunch ready by one.\\nFRANCES: I'll be back.\\nLILLIAN: At one. Promise?\\nFRANCES: Sure.\\nLILLIAN: Say you promise.\\nFRANCES: I promise I'll... I promise, Mama.\\nLILLIAN: You know, the surest way to lose an appetite, is to drink, little sister.\\nFRANCES: Yes, Mama.\\nLILLIAN: I don't want you drinking, Frances.\\n\\n\", 'answer': 'Yes, Mama.', 'gold_tag': \"FRANCES agrees with her mother's remarks about drinking , LILLIAN's persona shows a possessive nature over FRANCES\", 'last_speaker': 'FRANCES'}\n",
      "Last word -> FRANCES : \"Yes, Mama.\"\n",
      "prediction :  I'll be careful.\n",
      "Real answer : Yes, Mama.\n",
      "Bert Score : {'precision': [0.8659178614616394], 'recall': [0.8795206546783447], 'f1': [0.8726661801338196], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 104.64819994703801\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLILLIAN: Oh, just leave those things for now.\\nFRANCES: No, Mama, I'll take care of it. I'll wash them in the morning.\\nLILLIAN: You know, little sister, I never resented you for refusing to see me in the... the hospital. I knew you had to manage on your own before you could come back.\\nFRANCES: Thank you for understanding, Mama.\\nLILLIAN: Little sister, I don't want you to feel any rush to get back to work. I want you to rest... for a while anyway.\\nFRANCES: I will, I promise.\\n\\n\", 'answer': 'Good night, dear.', 'gold_tag': 'Everyday Language', 'last_speaker': 'LILLIAN'}\n",
      "Last word -> LILLIAN : \"Good night, dear.\"\n",
      "prediction :  I know you will, Frances. I'm just glad you're here.\n",
      "Real answer : Good night, dear.\n",
      "Bert Score : {'precision': [0.845302402973175], 'recall': [0.8845090270042419], 'f1': [0.8644614219665527], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.894322153070423\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKATIE: You're home.\\nOSBOURNE: Hang on to your hat, honey. I have some news. I----\\nKATIE: Did you pick up the cheeses?\\nOSBOURNE: Huh?\\nKATIE: Were they ready? I didn't know you were coming home this early.\\nOSBOURNE: The cheeses.\\nKATIE: I left a message for you to stop at Todaro's. The Magruders and the Pfarrers are coming over.\\nOSBOURNE: The Pfarrers? Ugh. I----what did Kathleen say?\\nKATIE: What?\\nOSBOURNE: When you left the message?\\nKATIE: She said. She would give you. The message.\\nOSBOURNE: Well she, I don't know, I guess we had bigger news today. My day didn't revolve arou----\\nKATIE: So you didn't get the cheeses.\\nOSBOURNE: Well, since I didn't get the message, no, I didn't get the cheeses. But hang on to your hat, I----\\nKATIE: Oh for fuck's sake, Ozzie, you mean I have to go out again? All right, well, you better get dressed.\\nOSBOURNE: Honey, we have to talk.\\n\\n\", 'answer': \"Not right now. They'll be here in, what, less than an hour.\", 'gold_tag': 'KATIE needs to prepare for guests  who are arriving in less than an hour', 'last_speaker': 'KATIE'}\n",
      "Last word -> KATIE : \"Not right now. They'll be here in, what, less than an hour.\"\n",
      "prediction :  Oh, do we?\n",
      "Real answer : Not right now. They'll be here in, what, less than an hour.\n",
      "Bert Score : {'precision': [0.81178879737854], 'recall': [0.8211128115653992], 'f1': [0.8164241313934326], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 345.8392143030722\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKATIE: You quit?!\\nOSBOURNE: Uh-huh.\\nKATIE: Well----Thank you for letting me know!\\nOSBOURNE: I tried to tell you this afternoon.\\nKATIE: You tried? You tried? And then---- what, the aphasia kicked in?\\nOSBOURNE: Our guests came. We----\\nKATIE: Why?! For fuck's sake, Ozzie!\\nOSBOURNE: I'm just----I don't know. I got so tired.\\nKATIE: You're tired.\\nOSBOURNE: Tired of swimming against the current.\\nKATIE: Uh-huh.\\nOSBOURNE: Independent thought is not only not valued there, they resist it, they fight it, the bureaucracy is positively----\\nKATIE: Did you get a pension, or severance or something, or----\\nOSBOURNE: I didn't retire you know, I, I quit. I don't want their benefits.\\nKATIE: But I suppose my benefits are all right, I suppose you can live with those, is that the idea?\\nOSBOURNE: It's not like that's the only way to make money.\\nKATIE: Yes? Yes? What're you gonna do?\\nOSBOURNE: I'll do some consulting.\\nKATIE: Consulting.\\nOSBOURNE: Yes, to help while I----I've always wanted to write.\\nKATIE: Write. Write what.\\n\\n\", 'answer': \"I've been thinking about it. A book, a sort of, sort of memoir.\", 'gold_tag': 'OSBOURNE plans to start writing a memoir', 'last_speaker': 'OSBOURNE'}\n",
      "Last word -> OSBOURNE : \"I've been thinking about it. A book, a sort of, sort of memoir.\"\n",
      "prediction :  I don't know. I've never written anything.\n",
      "Real answer : I've been thinking about it. A book, a sort of, sort of memoir.\n",
      "Bert Score : {'precision': [0.8776189088821411], 'recall': [0.8537228107452393], 'f1': [0.8655059337615967], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17391304347826086, 'rouge2': 0.09523809523809525, 'rougeL': 0.17391304347826086, 'rougeLsum': 0.17391304347826086}\n",
      "bleu 1/2 : 0.06062469223956427 0.020707274552675604\n",
      "ppl : 23.200439859310077\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nOSBOURNE: There's some clown----a couple of clowns ----somehow got a hold of my memoir----\\nKATIE: Your what?\\nOSBOURNE: Stole it or----I have no idea how they got it----\\nKATIE: Your what?\\nOSBOURNE: My memoir, the book I'm writing.\\nKATIE: Why in God's name would they think that's worth anything.\\n\\n\", 'answer': \"Well they----I... I've no idea how they got it.\", 'gold_tag': 'OSBOURNE is flustered and confused about how someone could have obtained it', 'last_speaker': 'OSBOURNE'}\n",
      "Last word -> OSBOURNE : \"Well they----I... I've no idea how they got it.\"\n",
      "prediction :  I don't know, but I think they're selling it.\n",
      "Real answer : Well they----I... I've no idea how they got it.\n",
      "Bert Score : {'precision': [0.8934956789016724], 'recall': [0.865419864654541], 'f1': [0.879233717918396], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.36363636363636365, 'rouge2': 0.0, 'rougeL': 0.36363636363636365, 'rougeLsum': 0.36363636363636365}\n",
      "bleu 1/2 : 0.11111111111111109 0.03726779962499649\n",
      "ppl : 17.900255341726243\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCATHY: Excuse me. Can I help you? Who are you?\\nRAYMOND: Ma'am, I'm sorry. My name's Raymond Deagan. I'm Otis Deagan's son. I've just been - taking over some of his jobs since he -\\nCATHY: You're Otis's son?\\nRAYMOND: Yes.\\nCATHY: Well I'm - terribly sorry for speaking to you in that manner. I didn't know who was in my yard.\\nRAYMOND: No need.\\nCATHY: How is your father? I knew he was in the hospital.\\nRAYMOND: Yes, I - My father passed away, I'm afraid.\\nCATHY: No! I had no idea! I'm so very sorry. Please accept our deepest condolences. Your father was a wonderful, dedicated man.\\n\\n\", 'answer': 'Thank you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'RAYMOND'}\n",
      "Last word -> RAYMOND : \"Thank you.\"\n",
      "prediction :  Thank you.\n",
      "Real answer : Thank you.\n",
      "Bert Score : {'precision': [0.9999999403953552], 'recall': [0.9999999403953552], 'f1': [0.9999999403953552], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
      "bleu 1/2 : 1.0 1.0\n",
      "ppl : 255.93043327652487\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCATHY: Raymond!\\nRAYMOND: Mrs. Whitaker...\\nCATHY: Hi.\\nRAYMOND: Hello.\\nCATHY: Well, wouldn't you know it. I just received a call and suddenly everything's changed. Anyway. I just...\\n\\n\", 'answer': 'You changed your mind? Well good!', 'gold_tag': 'RAYMOND is understanding and receptive to changes', 'last_speaker': 'RAYMOND'}\n",
      "Last word -> RAYMOND : \"You changed your mind? Well good!\"\n",
      "prediction :  Are you okay?\n",
      "Real answer : You changed your mind? Well good!\n",
      "Bert Score : {'precision': [0.8558605909347534], 'recall': [0.8347381949424744], 'f1': [0.8451675176620483], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2222222222222222, 'rouge2': 0.0, 'rougeL': 0.2222222222222222, 'rougeLsum': 0.2222222222222222}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 200.53478450245873\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCATHY: It's lovely. What is it?\\nRAYMOND: It's called a Quaking Aspen. Fairly rare in these parts.\\nCATHY: It's beautiful. And you were right. What a perfectly lovely spot.\\nRAYMOND: Sometimes a little green, some fresh air, just helps put things back on the shelf. ‘Cause it sure can be a disheveling world out there, every now and again.\\nCATHY: I'll say it can. Is that a path?\\nRAYMOND: Looks like it.\\nCATHY: Oh let's have a peek.\\n\\n\", 'answer': 'Alright.', 'gold_tag': 'Everyday Language', 'last_speaker': 'RAYMOND'}\n",
      "Last word -> RAYMOND : \"Alright.\"\n",
      "prediction :  It's not a path, exactly. It's more like a wish.\n",
      "Real answer : Alright.\n",
      "Bert Score : {'precision': [0.8483518958091736], 'recall': [0.9379216432571411], 'f1': [0.8908911347389221], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 19.50413226640736\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: Says here they got slips in Honolulu. 325 a month. Utilities included. That's not bad. But I gotta get at least a forty footer. It'll handle rough water better and I'll need the room if I'm gonna live on it.\\nRODRIGUEZ: I don't know how you do it.\\nDIVINCI: What?\\nRODRIGUEZ: How you can think about Hawaii now?\\nDIVINCI: My heart's in Hawaii.\\nRODRIGUEZ: You never been there. How can your heart be there.\\nDIVINCI: You're tellin' me there's no place you'd rather be other than here?\\nRODRIGUEZ: No, I'm saying I just don't know how you can think about Hawaii right now.\\nDIVINCI: If I was in Hawaii right now, I wouldn't be thinking about here. See the difference?\\nRODRIGUEZ: No.\\nDIVINCI: Look, I'm not in Hawaii, I'm here. But I don't want to be here, I want to be in Hawaii. I can't be in Hawaii, therefore I think about it so as to not get depressed about being here.\\nRODRIGUEZ: But I'm here, I know I'm here, I don't like being here, but I can't be anyplace else because I look around and I see all this shit. How do you get around that?! That's what I'm asking.\\nDIVINCI: Focus.\\nRODRIGUEZ: Focus. It's time. No more Hawaii, okay? Focus on this.\\nDIVINCI: Aloha.\\n\\n\", 'answer': 'Aloha my ass.', 'gold_tag': 'Everyday Language', 'last_speaker': 'RODRIGUEZ'}\n",
      "Last word -> RODRIGUEZ : \"Aloha my ass.\"\n",
      "prediction : What?\n",
      "Real answer : Aloha my ass.\n",
      "Bert Score : {'precision': [0.843065619468689], 'recall': [0.8102647066116333], 'f1': [0.8263397812843323], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1359.6453487608205\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRODRIGUEZ: SHIT, FUCK, SHIT, JESUS CHRIST!\\nDIVINCI: Calm down!\\nRODRIGUEZ: WE'RE DEAD, WE'RE FUCKING DEAD!\\nDIVINCI: SHUT UP!\\nRODRIGUEZ: FUCK, FUCK, FUCK!\\nDIVINCI: STOP IT! YOU HEAR ME, RIGHT NOW, STOP IT!\\nRODRIGUEZ: GOD, GOD, THIS IS REALLY FUCKIN' OUT OF CONTROL! LET GO OF ME!\\n\\n\", 'answer': \"Shut up and listen to me! They could be watchin' us right now you asshole. So fuckin' shape up! You got it?! I want you to nod! Get the fuck up! Get in the car!\", 'gold_tag': 'DIVINCI is forceful, commanding, and assertive , DIVINCI indicates a potentially higher ranking position', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"Shut up and listen to me! They could be watchin' us right now you asshole. So fuckin' shape up! You got it?! I want you to nod! Get the fuck up! Get in the car!\"\n",
      "prediction :  FUCK, I CAN'T BELIEVE IT, IT'S ALL FUCKED UP!\n",
      "Real answer : Shut up and listen to me! They could be watchin' us right now you asshole. So fuckin' shape up! You got it?! I want you to nod! Get the fuck up! Get in the car!\n",
      "Bert Score : {'precision': [0.8122178316116333], 'recall': [0.8247774839401245], 'f1': [0.8184494972229004], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17391304347826086, 'rouge2': 0.0, 'rougeL': 0.08695652173913043, 'rougeLsum': 0.08695652173913043}\n",
      "bleu 1/2 : 0.0061819998086492 0.0020735057713545456\n",
      "ppl : 8.058245955919732\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: There's no fuckin' reason to panic.\\nRODRIGUEZ: No fuckin' reason to panic? Did you say no fuckin' reason to panic!\\nDIVINCI: Stop being an idiot! We're the cops on the case. It's our case. We are going to find the fuckin' killers.\\nRODRIGUEZ: WE'RE THE FUCKIN' KILLERS!\\n\\n\", 'answer': 'Since when does that matter?!', 'gold_tag': 'DIVINCI downplays the seriousness of their circumstances', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"Since when does that matter?!\"\n",
      "prediction :  Shut the fuck up!\n",
      "Real answer : Since when does that matter?!\n",
      "Bert Score : {'precision': [0.7675173282623291], 'recall': [0.8207186460494995], 'f1': [0.793226957321167], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 43.65012975739093\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: All they want is someone to go down for the crime, right? Do we care who goes down for the crime? Fuck no. As long as someone goes down for the crime. It's a slot that's gotta be filled.\\nRODRIGUEZ: We killed a cop, doesn't that bother you?\\nDIVINCI: Of course it bothers me. What d'you want me to do, turn myself in? Well I'm not. That's the risk we take everyday, somebody might pop us, especially undercover like that. So he got popped. It happens.\\nRODRIGUEZ: Not by other cops!\\nDIVINCI: I patted him down! He wasn't wearin' a wire, he had no badge, no gun, how was I supposed to know?! Look, I feel just as bad as you do, but we gotta start thinkin' about us here. The important thing is we don't lose control of the case. We can never lose control of the case. Whatever evidence there is goes through us. We lay down the trail. Make it nice and logical. We're the teachers and two and two can add up to five if it's our classroom.\\nRODRIGUEZ: What're you talkin' about, are you sayin' we stick somebody with this?\\nDIVINCI: Evidence points wherever we want it to point. Shit, we can provide so much evidence, even the asshole we pick will think he fuckin' killed him.\\nRODRIGUEZ: You got some asshole in mind?\\n\\n\", 'answer': \"Just don't worry. We'll find a killer. There's lots of 'em out there.\", 'gold_tag': 'DIVINCI takes control of situations and plans to manipulate evidence', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"Just don't worry. We'll find a killer. There's lots of 'em out there.\"\n",
      "prediction : Yeah.\n",
      "Real answer : Just don't worry. We'll find a killer. There's lots of 'em out there.\n",
      "Bert Score : {'precision': [0.9197293519973755], 'recall': [0.831791341304779], 'f1': [0.8735528588294983], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1266.3677265459103\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: He didn't have backup. You believe that?! Jesus what a dick.\\nRODRIGUEZ: I don't think we should criticize that particular decision of his.\\nDIVINCI: I don't care what the reasons are, you don't play Lone Fuckin' Ranger on a drug buy. You're just askin' for it. That's all I'm sayin'.\\nRODRIGUEZ: I don't trust those bastards. They're not waitin' for us. That's bullshit. They're runnin' their own investigation. I know it!\\nDIVINCI: Let 'em. The gun, the coke came from evidence. The car came from impound. So what's to find?\\nRODRIGUEZ: That's what I'm afraid of. There's nothing for them to find. We were too good.\\nDIVINCI: So what're you worried about?\\nRODRIGUEZ: Nobody is that fuckin' good.\\n\\n\", 'answer': 'Except us.', 'gold_tag': 'Divinci and Rodriguez share a past of conducting successful operations that involved the use of evidence and impounded cars', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"Except us.\"\n",
      "prediction :  I don't know, man. I think it's fuckin' great. We got the guy. He's goin' down.\n",
      "Real answer : Except us.\n",
      "Bert Score : {'precision': [0.8197011351585388], 'recall': [0.8759689331054688], 'f1': [0.8469014167785645], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 7.906126145230028\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: Is that any way to answer the phone?\\nRODRIGUEZ: Divinci, shit! It's quarter to six.\\nDIVINCI: I know what time it is, I'm not the one in bed. I need the photos of the scene.\\nRODRIGUEZ: Now?\\nDIVINCI: I got a suspect. But he can't remember all the details. He needs a little help. And I thought, since you're my partner, you might jump at the opportunity to lend me a fuckin' hand.\\nRODRIGUEZ: He doesn't remember last Friday?\\n\\n\", 'answer': \"He doesn't remember a lotta Fridays. Bring the shots and pick up a fifth of Vodka. Make it two.\", 'gold_tag': 'DIVINCI needs bottles of Vodka as soon as possible', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"He doesn't remember a lotta Fridays. Bring the shots and pick up a fifth of Vodka. Make it two.\"\n",
      "prediction :  No, he doesn't remember the victim. He says he can't remember anything.\n",
      "Real answer : He doesn't remember a lotta Fridays. Bring the shots and pick up a fifth of Vodka. Make it two.\n",
      "Bert Score : {'precision': [0.8822054862976074], 'recall': [0.8502646684646606], 'f1': [0.8659406900405884], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2941176470588235, 'rouge2': 0.18749999999999997, 'rougeL': 0.2941176470588235, 'rougeLsum': 0.2941176470588235}\n",
      "bleu 1/2 : 0.18601171525668236 0.09714145011654593\n",
      "ppl : 22.022079100668844\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRODRIGUEZ: The Dunner gun, you used the fucking Dunner gun?!\\nDIVINCI: This is not my fuck up! Our shooting was supposed to be gang-related and unsolved! Only because we tagged a goddamn undercover cop do we need the fucking .44 for evidence! Otherwise, we never woulda needed it. So don't point your finger at me!\\nRODRIGUEZ: Alright, alright... But how are we supposed to explain how the same gun was used in two murder cases by two different killers when it was supposed to be in police custody?!\\n\\n\", 'answer': \"We don't explain it. It's not our fault they lost the evidence. Ballistics are already complete in Dunner's case. All we need is another gun.\", 'gold_tag': \"DIVINCI implies that the ballistics for Dunner's case have already been completed, suggesting that this event has occurred in the past and will not change\", 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"We don't explain it. It's not our fault they lost the evidence. Ballistics are already complete in Dunner's case. All we need is another gun.\"\n",
      "prediction :  I don't know! But if you're gonna accuse me of fucking anything, you better have some fucking proof!\n",
      "Real answer : We don't explain it. It's not our fault they lost the evidence. Ballistics are already complete in Dunner's case. All we need is another gun.\n",
      "Bert Score : {'precision': [0.8297972679138184], 'recall': [0.848048210144043], 'f1': [0.8388234972953796], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08333333333333333, 'rouge2': 0.043478260869565216, 'rougeL': 0.08333333333333333, 'rougeLsum': 0.08333333333333333}\n",
      "bleu 1/2 : 0.03765608766696946 0.012253128505882702\n",
      "ppl : 9.225037043929387\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRODRIGUEZ: We gotta put the right gun back.\\nDIVINCI: We can't put the right gun back! Without that gun, they won't convict Joe.\\nRODRIGUEZ: Without that gun they won't convict Clyde!\\nDIVINCI: I'm not worried about Clyde, I'm worried about us!\\nRODRIGUEZ: Look, Joe's never goin' to trial, right. He signed a goddamn confession! Like you said, this one is open and shut. Clyde's the one we gotta worry about. We can't let him go back on the street! He's a fuckin' psychopath. He'll kill somebody again.\\nDIVINCI: Shit. How the hell did that piece of puke know it wasn't his fuckin' gun?! I don't think he knows his own fuckin' mother, but he knows his fuckin' gun!\\n\\n\", 'answer': \"I don't think that's important right now.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'RODRIGUEZ'}\n",
      "Last word -> RODRIGUEZ : \"I don't think that's important right now.\"\n",
      "prediction :  Maybe he was just lucky.\n",
      "Real answer : I don't think that's important right now.\n",
      "Bert Score : {'precision': [0.8522451519966125], 'recall': [0.843127965927124], 'f1': [0.8476620316505432], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 63.39518019904669\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: Nobody can connect us to the evidence thing... we're clean there. The most important one is this DEA mess anyway. Once that's finished, we're completely in the clear.\\nRODRIGUEZ: You know we can't do it anymore.\\nDIVINCI: ...yeah, I guess.\\nRODRIGUEZ: No, we're through. That's it.\\nDIVINCI: Good while it lasted though. A hundred grand apiece. Not bad for a few nights work.\\nRODRIGUEZ: I just wanna get through this.\\nDIVINCI: We're gonna get through it. No evidence problems on this one.\\nRODRIGUEZ: I hope not... I don't know, Frank, lately I been thinkin'... maybe what we did wasn't such a good idea.\\nDIVINCI: Hey, we took out a few scumbags, that's it. Nobody's ever gonna miss those shitheels. They were all pieces of garbage. Not one of 'em had a sheet less than a mile long. Drugs, extortion, assault. They were all fuckin' guilty as hell and still on the street, you know that.\\nRODRIGUEZ: Except the cop.\\nDIVINCI: Yeah, except the cop. That's part of the job. Could just as easily have happened to you or me.\\nRODRIGUEZ: But we're cops, you know? We fucked up.\\nDIVINCI: We fucked up once. Once outa ten. That's not bad. I'm sorry, okay? I'm sorry. He was in the wrong place at the wrong time, what can I say. I'm not goin' down for it.\\nRODRIGUEZ: I know.\\nDIVINCI: Look, if we got paid a decent salary we wouldn't be tempted by this, right? And what happens when we retire? You think our pension's gonna take care of us? Shit no. We are on our own. I mean all I want in life is a goddamn fishing boat, a beach, a couple drinks and some Hawaiian fuckin' music. That ain't much for twenty years putting murdering assholes behind bars. I mean, the dealers, the pimps, the killers, they got no rules. We got all the fuckin' rules. It ain't fair. That's all I'm sayin', it ain't fair... For awhile, we made it fair. Quit thinkin' you're a bad guy. You're not a fuckin' bad guy. You made one mistake. Let it go.\\nRODRIGUEZ: Do you think we're corrupt?\\nDIVINCI: Hey, I never took a fuckin' bribe in my life.\\nRODRIGUEZ: Me either.\\nDIVINCI: Nobody ever bought me.\\nRODRIGUEZ: I know.\\nDIVINCI: No fuckin' way. Even the thought makes me sick. And what we did has nothing to do with being corrupt. It's two completely different things. Don't get 'em confused.\\nRODRIGUEZ: I guess you're right.\\nDIVINCI: I'm telling you. It's nothin' to do with corrupt.\\nRODRIGUEZ: I'm worried, that's all.\\nDIVINCI: Hey, you gotta worry a little. It's natural. Just don't lose your sense of humor.\\nRODRIGUEZ: My sense of humor, right.\\nDIVINCI: The problem with people is, nobody gives a shit about makin' the world a better place. You and me, I don't care what anybody says, we made the world a better place. No matter what happens. There are ten less drug dealin' assholes on the street today because of us. They're not plea bargainin' their way back onto the street, they're not clogging up the courts, and they're not costing the tax payers a fuckin' penny because they're not in prison. They were garbage. And there's nothin' wrong with takin' out the garbage.\\nRODRIGUEZ: So, you think you'll get back with Caroline?\\nDIVINCI: Shit. Nothin' I ever do is good enough, you know?\\nRODRIGUEZ: Never is, never was, never will be.\\nDIVINCI: Guess I gotta make the effort. It's gonna cost me if I don't.\\nRODRIGUEZ: Tell me about it. You know how much I got left.\\nDIVINCI: You're gonna think I'm an idiot, but... I like Cynthia. There's no bullshit with her. I just fuckin' like her.\\nRODRIGUEZ: I think you just like fuckin' her.\\n\\n\", 'answer': 'Yeah, that, too.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"Yeah, that, too.\"\n",
      "prediction :  I like her. I mean, I don't know her, but I like her. I think she's a good person. I think she's honest. I think she's got a good heart. And I think she's fuckin' beautiful. I mean, I'm not gonna marry her, but I like her. And I think she likes me. I think she's just tryin' to get to know me better. I think\n",
      "Real answer : Yeah, that, too.\n",
      "Bert Score : {'precision': [0.8077254295349121], 'recall': [0.8610224723815918], 'f1': [0.8335228562355042], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2.988701750843139\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: -- when was the last time you saw him? -- Uh-huh -- And you haven't seen him since then?\\nRODRIGUEZ: We gotta talk.\\nDIVINCI: Just a second. Calm down. I heard. Clyde walked.\\nRODRIGUEZ: No! They're takin' Joe to trial. They found him mentally unable to plead so his attorney pleaded not\\nDIVINCI: You gotta be kiddin' me.\\n\\n\", 'answer': \"Yeah, that's me, I love to make people laugh. You hear the one about the two cops who popped the undercover DEA?\", 'gold_tag': 'RODRIGUEZ uses humor as a coping mechanism in stressful situations', 'last_speaker': 'RODRIGUEZ'}\n",
      "Last word -> RODRIGUEZ : \"Yeah, that's me, I love to make people laugh. You hear the one about the two cops who popped the undercover DEA?\"\n",
      "prediction :  I can't take it. You gotta help me.\n",
      "Real answer : Yeah, that's me, I love to make people laugh. You hear the one about the two cops who popped the undercover DEA?\n",
      "Bert Score : {'precision': [0.8595731258392334], 'recall': [0.8355590105056763], 'f1': [0.8473959565162659], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18750000000000003, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.043443485862611285 0.010384979438441458\n",
      "ppl : 19.755516519244686\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRODRIGUEZ: -- but William McCall shunned the business world and turned his life to medicine, receiving his medical degree from Harvard in 1969. Once again he turned his back on the established norm and spent several years in Africa performing organ transplants for the poor. Jesus Christ, this is who you picked? A goddamn surgeon who performs organ transplants on poor Africans?!\\nDIVINCI: He was living in the fuckin' street! How the hell was I supposed to know he was a goddamn doctor?!\\nRODRIGUEZ: He's not a goddamn doctor! You picked a fuckin' Saint to pin a fuckin' murder on! When we pick 'em, we really fuckin' pick 'em. We shoulda just picked up the fuckin' Pope.\\nDIVINCI: -- he disappeared seven years ago on September 19 two weeks after the tragic death of his wife and two young children in a multiple vehicle accident. At the time it was assumed that he had returned to Africa, but that was never confirmed. What William McCall has been doing for seven years is now the mystery that the court will try to help unravel. Alright, alright, let's think here.\\nRODRIGUEZ: Are you asking me if I can think of something worse than what we've done that we can still do, or something worse that might happen to us if this all blows up and we are convicted and sent to jail and die in the electric chair and go to hell?\\nDIVINCI: Work with me here.\\nRODRIGUEZ: I'm sorry. I'm a little on edge. Would you repeat the question?\\nDIVINCI: Even if the doc walks, there's no evidence ties us to it. There's only one person who can connect us to Hudd.\\n\\n\", 'answer': \"Okay, fine, I don't wanna argue about it anymore. Let's just fuckin' kill her.\", 'gold_tag': \"RODRIGUEZ ultimately agrees to DIVINCI's plan for murder despite his fears\", 'last_speaker': 'RODRIGUEZ'}\n",
      "Last word -> RODRIGUEZ : \"Okay, fine, I don't wanna argue about it anymore. Let's just fuckin' kill her.\"\n",
      "prediction :  You mean the kid?\n",
      "Real answer : Okay, fine, I don't wanna argue about it anymore. Let's just fuckin' kill her.\n",
      "Bert Score : {'precision': [0.8299513459205627], 'recall': [0.8226314783096313], 'f1': [0.8262751698493958], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 477.08995549493795\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: -- look, she's our witness, if she's in custody, somebody better tell me! Anything?\\nRODRIGUEZ: Nothin'. Nobody knows nothin'. The D.A. thinks she's gone. D.E.A. doesn't know shit.\\nDIVINCI: If she was bein' held by police, we'd know.\\nRODRIGUEZ: Unless she said somethin'.\\n\\n\", 'answer': \"If she said something we wouldn't be sittin' here. I think it's that lyin' piece of shit.\", 'gold_tag': 'DIVINCI has assertive language', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"If she said something we wouldn't be sittin' here. I think it's that lyin' piece of shit.\"\n",
      "prediction :  You think she's talkin'?\n",
      "Real answer : If she said something we wouldn't be sittin' here. I think it's that lyin' piece of shit.\n",
      "Bert Score : {'precision': [0.8765203952789307], 'recall': [0.8516130447387695], 'f1': [0.8638872504234314], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.009693551957930502 0.003539584713137937\n",
      "ppl : 83.00417876238103\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: To justice in all its forms.\\nRODRIGUEZ: We're not home free yet.\\nDIVINCI: Without Ms Webb, there's no place they can go. We still got the confession, the gun, the ballistics... And I don't give a shit about all this African doctor crap... the man is a drunk and he's been a drunk for seven goddamn years. So lets have a drink for drunks. That's the thing about life. You control it or it controls you. Most people don't understand that. They try'n blame their fuck-ups on something or somebody else. But it's not like that. I don't wanna hear why your life's a mess. It's a mess cause you're a mess. That simple. They're waitin' to live happily ever after. But after what? After all the shit happens? Well, I got a clue for everybody, the shit never stops happening. So you deal with it or you get buried in it. I'm not talkin' about you, you know what I'm sayin' here.\\nRODRIGUEZ: Yeah.\\nDIVINCI: Life don't work in mysterious ways. There ain't no mystery to it. You just work it. And you don't take it too serious. You can't take it too serious otherwise you get fragile. And you can't be fragile and have any fuckin' fun.\\nRODRIGUEZ: You think I'm fragile?\\nDIVINCI: That's the first sign of trouble, when you start askin' other people.\\n\\n\", 'answer': '...I just wish I knew where the hell she was.', 'gold_tag': \"Rodriguez's concern about not knowing the whereabouts of Ms. Webb\", 'last_speaker': 'RODRIGUEZ'}\n",
      "Last word -> RODRIGUEZ : \"...I just wish I knew where the hell she was.\"\n",
      "prediction :  You think I'm fragile?\n",
      "Real answer : ...I just wish I knew where the hell she was.\n",
      "Bert Score : {'precision': [0.8459444046020508], 'recall': [0.8518734574317932], 'f1': [0.8488985896110535], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 56.49706824889503\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRODRIGUEZ: She didn't talk.\\nDIVINCI: Don't hold your breath.\\nRODRIGUEZ: You think she'll talk.\\nDIVINCI: I know she'll talk.\\nRODRIGUEZ: We'll make it look gang related.\\nDIVINCI: Problem is we're gonna need another gun.\\nRODRIGUEZ: The problem?! Have you forgotten? She's in fucking jail. That's the goddamn problem.\\n\\n\", 'answer': \"Since when is being in jail a guaranty of a long life? You just get a fuckin' gun.\", 'gold_tag': 'DIVINCI is pragmatic and task-oriented, focusing on what needs to be done to resolve the problems at hand', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"Since when is being in jail a guaranty of a long life? You just get a fuckin' gun.\"\n",
      "prediction : You're right. I forgot.\n",
      "Real answer : Since when is being in jail a guaranty of a long life? You just get a fuckin' gun.\n",
      "Bert Score : {'precision': [0.8538780212402344], 'recall': [0.8258505463600159], 'f1': [0.8396304845809937], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913045, 'rouge2': 0.0, 'rougeL': 0.08695652173913045, 'rougeLsum': 0.08695652173913045}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 30.841101559907006\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: You get the gun?\\nRODRIGUEZ: I got it.\\nDIVINCI: Everything okay?\\nRODRIGUEZ: Are you kidding? We're going to kill a goddamn witness who's in fucking jail because we killed an undercover DEA agent. I'm sorry, but this kinda shit troubles me a little.\\nDIVINCI: Take off the dress and get back in the game. We gotta do what we gotta do.\\n\\n\", 'answer': \"Yeah. I know. Let's just get it over with.\", 'gold_tag': 'RODRIGUEZ is involved with criminal behavior', 'last_speaker': 'RODRIGUEZ'}\n",
      "Last word -> RODRIGUEZ : \"Yeah. I know. Let's just get it over with.\"\n",
      "prediction :  I don't know if I can do this.\n",
      "Real answer : Yeah. I know. Let's just get it over with.\n",
      "Bert Score : {'precision': [0.8670775890350342], 'recall': [0.8591927886009216], 'f1': [0.8631171584129333], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2105263157894737, 'rouge2': 0.0, 'rougeL': 0.2105263157894737, 'rougeLsum': 0.2105263157894737}\n",
      "bleu 1/2 : 0.11031211282307446 0.03729230060020541\n",
      "ppl : 12.032973014851542\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRODRIGUEZ: This is the last time, Frank. The last time we kill somebody.\\nDIVINCI: Yeah, it's the last time.\\nRODRIGUEZ: This'll be eleven, Frank. Eleven is enough.\\nDIVINCI: I get the picture.\\nRODRIGUEZ: It was all okay until you shot Hudd.\\nDIVINCI: What's goin' on here? You mad at me or something?\\nRODRIGUEZ: It wasn't my idea to start killing people, Frank. That's all I'm sayin'. We're in this goddamn mess because you started killing people.\\nDIVINCI: Drug dealers don't qualify as people. Never did, never will. So what the hell's wrong with you tonight? You suddenly worried about where all the money went?\\n\\n\", 'answer': \"I'm just sick of it, that's all.\", 'gold_tag': 'RODRIGUEZ is growing weary of their activities', 'last_speaker': 'RODRIGUEZ'}\n",
      "Last word -> RODRIGUEZ : \"I'm just sick of it, that's all.\"\n",
      "prediction :  No, I'm not worried about that. I'm worried about you. You're a killer, Frank. You're a killer, and you're goin' to get us all killed.\n",
      "Real answer : I'm just sick of it, that's all.\n",
      "Bert Score : {'precision': [0.8530726432800293], 'recall': [0.8651726245880127], 'f1': [0.8590800166130066], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20512820512820512, 'rouge2': 0.05405405405405405, 'rougeL': 0.20512820512820512, 'rougeLsum': 0.20512820512820512}\n",
      "bleu 1/2 : 0.04000000000000001 0.012909944487358061\n",
      "ppl : 5.367112760587853\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRODRIGUEZ: What're you doin'?\\n\\n\", 'answer': 'I need some fresh air.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"I need some fresh air.\"\n",
      "prediction :  I'm just tryin' to get the word out, man. You know, spread the gospel of the Lord.\n",
      "Real answer : I need some fresh air.\n",
      "Bert Score : {'precision': [0.8401945233345032], 'recall': [0.8784951567649841], 'f1': [0.8589181303977966], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913045, 'rouge2': 0.0, 'rougeL': 0.08695652173913045, 'rougeLsum': 0.08695652173913045}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 9.646145531171841\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRODRIGUEZ: Frank --\\nDIVINCI: Talk to me, okay? Just fuckin' talk to me.\\nRODRIGUEZ: I don't know... I owe some money. I don't know how I'm gonna pay it...\\nDIVINCI: You gambling again?\\nRODRIGUEZ: Yeah, yeah... I just couldn't... Frank... let's forget about this. Let's just get the fuck outa here. We got enough money, let's go. We'll get outa the country or something. What the hell're you doin'?!\\nDIVINCI: Take off your shirt.\\nRODRIGUEZ: What're you talkin' about?\\nDIVINCI: Just take off your shirt. If there's nothin' to worry about, then I'll apologize. But I'm not gonna argue. Take off your fuckin' shirt now.\\nRODRIGUEZ: What is this, you piece of shit?! You don't trust me?! Is that it?! YOU DON'T FUCKIN' TRUST ME AFTER ALL WE'VE BEEN THROUGH?!\\nDIVINCI: ...Take off your shirt.\\nRODRIGUEZ: Fuck you, you don't trust me.\\nDIVINCI: I'm askin' you one more time.\\nRODRIGUEZ: You wanna shoot me? Shoot me.\\n\\n\", 'answer': \"Okay, I'm sorry. You're right. I'm fuckin' nervous. Like you. Forget it. This thing... shit. Let's just get it over with.\", 'gold_tag': 'DIVINCI has a distrust or suspicion towards his counterpart, RODRIGUEZ', 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"Okay, I'm sorry. You're right. I'm fuckin' nervous. Like you. Forget it. This thing... shit. Let's just get it over with.\"\n",
      "prediction :  I'm not gonna shoot you. But I'm gonna hurt you. You're gonna hurt. You're gonna fuckin' hurt.\n",
      "Real answer : Okay, I'm sorry. You're right. I'm fuckin' nervous. Like you. Forget it. This thing... shit. Let's just get it over with.\n",
      "Bert Score : {'precision': [0.8660781383514404], 'recall': [0.8662070631980896], 'f1': [0.8661425709724426], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.34782608695652173, 'rouge2': 0.13636363636363635, 'rougeL': 0.2608695652173913, 'rougeLsum': 0.2608695652173913}\n",
      "bleu 1/2 : 0.23245245970044065 0.033885477758793386\n",
      "ppl : 6.379476967176363\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIVINCI: I'll just feel a whole lot better when she's dead. Then we're off the hook.\\nRODRIGUEZ: Right.\\nDIVINCI: YOU FUCKIN' RAT!\\nRODRIGUEZ: Yeah... yeah... I am, I'm a fuckin' rat... I traded you, Frank, I fuckin' traded you... Simms knows everything. Just fuckin' shoot me, get it the fuck over with! I DESERVE IT! I FUCKING DESERVE TO DIE!\\nDIVINCI: You're fuckin' right. ...Get out.\\nRODRIGUEZ: Frank --\\n\\n\", 'answer': \"Get outa the car NOW! This is why you can never -- ever -- lose your sense of fuckin' humor.\", 'gold_tag': \"DIVINCI's comment about retaining a sense of humor suggests he may cope with stress or adversity in a cynical way\", 'last_speaker': 'DIVINCI'}\n",
      "Last word -> DIVINCI : \"Get outa the car NOW! This is why you can never -- ever -- lose your sense of fuckin' humor.\"\n",
      "prediction :  Get out!\n",
      "Real answer : Get outa the car NOW! This is why you can never -- ever -- lose your sense of fuckin' humor.\n",
      "Bert Score : {'precision': [0.8886940479278564], 'recall': [0.8080160617828369], 'f1': [0.8464369773864746], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09999999999999999, 'rouge2': 0.0, 'rougeL': 0.09999999999999999, 'rougeLsum': 0.09999999999999999}\n",
      "bleu 1/2 : 6.170490204333978e-05 2.759527110277469e-05\n",
      "ppl : 858.579724593727\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: It's okay...you're going to be okay.\\nRENNIE: I want to go home. I want off this ship.\\n\\n\", 'answer': \"Me too. Let's go talk to my Dad.\", 'gold_tag': 'SEAN has a familial relationship with the person in authority onboard, his Dad', 'last_speaker': 'SEAN'}\n",
      "Last word -> SEAN : \"Me too. Let's go talk to my Dad.\"\n",
      "prediction :  I know.\n",
      "Real answer : Me too. Let's go talk to my Dad.\n",
      "Bert Score : {'precision': [0.8757228255271912], 'recall': [0.8600564002990723], 'f1': [0.8678188920021057], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 663.9337011017111\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRENNIE: Can he really take us home?\\nSEAN: Not completing a voyage is against everything he stands for. But I think I can convince him to call a Coast Guard cutter for you.\\nRENNIE: What about you?\\n\\n', 'answer': \"If I go with you, he'll never speak to me again. But I'm never going to live up to his expectations anyway...so maybe it's the right thing to do.\", 'gold_tag': \"SEAN struggles with living up to someone's expectations, presumably a figure of authority , SEAN is in a state of considering breaking free from some form of ongoing expectations\", 'last_speaker': 'SEAN'}\n",
      "Last word -> SEAN : \"If I go with you, he'll never speak to me again. But I'm never going to live up to his expectations anyway...so maybe it's the right thing to do.\"\n",
      "prediction :  I'm not going anywhere. I'm staying with you.\n",
      "Real answer : If I go with you, he'll never speak to me again. But I'm never going to live up to his expectations anyway...so maybe it's the right thing to do.\n",
      "Bert Score : {'precision': [0.888579249382019], 'recall': [0.8470773696899414], 'f1': [0.8673321604728699], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.27906976744186046, 'rouge2': 0.0975609756097561, 'rougeL': 0.13953488372093023, 'rougeLsum': 0.13953488372093023}\n",
      "bleu 1/2 : 0.027164908887844296 0.0053020473130575025\n",
      "ppl : 12.778972130752264\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: Rennie...??\\nRENNIE: The window... I don't understand what is happening to me...\\n\\n\", 'answer': \"It's gonna be okay...\", 'gold_tag': 'SEAN is a supportive presence , SEAN is a calming presence', 'last_speaker': 'SEAN'}\n",
      "Last word -> SEAN : \"It's gonna be okay...\"\n",
      "prediction :  It's okay, I'm here.\n",
      "Real answer : It's gonna be okay...\n",
      "Bert Score : {'precision': [0.8941593170166016], 'recall': [0.8706982135772705], 'f1': [0.8822728395462036], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.5454545454545454, 'rouge2': 0.22222222222222224, 'rougeL': 0.5454545454545454, 'rougeLsum': 0.5454545454545454}\n",
      "bleu 1/2 : 0.25 0.09128709291752769\n",
      "ppl : 20.67572829952564\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRENNIE: What is it??\\n\\n', 'answer': 'The power room...', 'gold_tag': 'Everyday Language', 'last_speaker': 'SEAN'}\n",
      "Last word -> SEAN : \"The power room...\"\n",
      "prediction :  The wizard is dead.\n",
      "Real answer : The power room...\n",
      "Bert Score : {'precision': [0.8899667263031006], 'recall': [0.8464109301567078], 'f1': [0.8676424622535706], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0.25 0.09128709291752769\n",
      "ppl : 103.18620459367459\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: Rule one, don't panic. Rule two, assess the damage and act accordingly...\\nRENNIE: Is the ship going to sink??\\nSEAN: I don't know. The emergency lights just kicked in... We'll be okay. I want you to wait by the lifeboats, just in case.\\nRENNIE: I'm not going near any lifeboat!\\nSEAN: But Rennie...\\n\\n\", 'answer': \"I'm not!!\", 'gold_tag': 'RENNIE displays fear towards lifeboats , RENNIE shows strong reluctance towards lifeboats', 'last_speaker': 'RENNIE'}\n",
      "Last word -> RENNIE : \"I'm not!!\"\n",
      "prediction :  No! I'm not going to die here! I can't die here!\n",
      "Real answer : I'm not!!\n",
      "Bert Score : {'precision': [0.8276636004447937], 'recall': [0.8602396249771118], 'f1': [0.8436372876167297], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.375, 'rouge2': 0.2857142857142857, 'rougeL': 0.375, 'rougeLsum': 0.375}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 11.449729534980127\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: Rennie...what'd they do to you??\\nRENNIE: Drugs... Then Jason came. He's here, Sean.\\n\\n\", 'answer': 'We have to find the others.', 'gold_tag': 'SEAN takes on a leadership role to find the others , SEAN has a present task to find the others', 'last_speaker': 'SEAN'}\n",
      "Last word -> SEAN : \"We have to find the others.\"\n",
      "prediction :  Where?\n",
      "Real answer : We have to find the others.\n",
      "Bert Score : {'precision': [0.8494203090667725], 'recall': [0.8516892194747925], 'f1': [0.8505532741546631], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2637.1266702665757\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRENNIE: I was at school when they told me. 'Rennie, we have some very bad news... your parents have been killed in an auto accident.' It seems like everybody I care about ends up...\\nSEAN: Not this time.\\n\\n\", 'answer': \"Toby... What's wrong, boy?\", 'gold_tag': 'RENNIE has a pet named Toby', 'last_speaker': 'RENNIE'}\n",
      "Last word -> RENNIE : \"Toby... What's wrong, boy?\"\n",
      "prediction :  I don't know how I feel.\n",
      "Real answer : Toby... What's wrong, boy?\n",
      "Bert Score : {'precision': [0.8385645747184753], 'recall': [0.8370493650436401], 'f1': [0.8378063440322876], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 20.879116656694052\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: Run, Rennie...\\n\\n', 'answer': \"You never got me in the lake, Jason. And you're not going to get me now either.\", 'gold_tag': 'RENNIE is a brave individual , RENNIE is not easily intimidated , RENNIE showed a defiant stance against Jason', 'last_speaker': 'RENNIE'}\n",
      "Last word -> RENNIE : \"You never got me in the lake, Jason. And you're not going to get me now either.\"\n",
      "prediction :  Where?\n",
      "Real answer : You never got me in the lake, Jason. And you're not going to get me now either.\n",
      "Bert Score : {'precision': [0.8294212818145752], 'recall': [0.8038667440414429], 'f1': [0.8164440989494324], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2637.1266702665757\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAN DE: Your training begins tomorrow. For now, your shr fu will\\n\\n', 'answer': 'Great, just great.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DREW'}\n",
      "Last word -> DREW : \"Great, just great.\"\n",
      "prediction :  What is shr fu?\n",
      "Real answer : Great, just great.\n",
      "Bert Score : {'precision': [0.8252981901168823], 'recall': [0.8375173807144165], 'f1': [0.8313629031181335], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2510.5019956769115\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDREW: Yeah, what's up with him?\\n\\n\", 'answer': 'Come with me...', 'gold_tag': 'Everyday Language', 'last_speaker': 'SAN DE'}\n",
      "Last word -> SAN DE : \"Come with me...\"\n",
      "prediction :  He's a great guy. He's really good.\n",
      "Real answer : Come with me...\n",
      "Bert Score : {'precision': [0.8503762483596802], 'recall': [0.8028572797775269], 'f1': [0.8259338140487671], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.66749751603215\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDREW: I wouldn't have made it through without you. You once asked why I came here, why did you let me in?\\nSAN DE: Do you remember the story you heard about the monk who\\nDREW: Yes.\\nSAN DE: That monk was me.\\nDREW: Anything.\\nSAN DE: Before you leave for American, can you help at an international tournament in Beijing? The Shaolin temple has an entry, and he will be fighting men from all over the world I'd like you to be there.\\nDREW: No problem.\\n\\n\", 'answer': 'Now, a friend would like to see you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SAN DE'}\n",
      "Last word -> SAN DE : \"Now, a friend would like to see you.\"\n",
      "prediction :  I'll send you a ticket.\n",
      "Real answer : Now, a friend would like to see you.\n",
      "Bert Score : {'precision': [0.8905753493309021], 'recall': [0.8655458092689514], 'f1': [0.8778822422027588], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.14285714285714288, 'rougeLsum': 0.14285714285714288}\n",
      "bleu 1/2 : 0.10976232721880529 0.03880684294761699\n",
      "ppl : 66.80630653891781\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHENRY: You heard our broadcast.\\nJIM: Yes.\\nHENRY: We must be a disappointment. You were hoping for a full brigade. An army base, with helicopters and field hospitals.\\nJIM: We were hoping for...\\nHENRY: The answer to infection. Well, as I said, it's here. Though it may not be quite what you imagined.\\nJIM: I didn't know what to imagine, so... We just feel lucky to have found you.\\n\\n\", 'answer': \"You were lucky. The fire drove hundreds of infected out of Manchester. The surrounding area is teeming with them. But there's no need for you to worry. We're well protected here.\", 'gold_tag': \"HENRY indicates that there was a recent event where a fire drove hundreds of infected out of Manchester , HENRY is responsible for the group's safety\", 'last_speaker': 'HENRY'}\n",
      "Last word -> HENRY : \"You were lucky. The fire drove hundreds of infected out of Manchester. The surrounding area is teeming with them. But there's no need for you to worry. We're well protected here.\"\n",
      "prediction :  You are lucky.\n",
      "Real answer : You were lucky. The fire drove hundreds of infected out of Manchester. The surrounding area is teeming with them. But there's no need for you to worry. We're well protected here.\n",
      "Bert Score : {'precision': [0.9517539143562317], 'recall': [0.8516152501106262], 'f1': [0.8989043235778809], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 5.895132577325534e-05 1.6144485460423813e-05\n",
      "ppl : 121.66750345419412\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHENRY: And finally... ...meet Mailer. Mailer, Jim. Jim, Mailer. Got infected three days ago. Mitchell managed to knock him out cold. Got a chain around his neck.\\nJIM: You're keeping him alive?\\n\\n\", 'answer': \"The idea was to learn something about infection. Have him teach me. In a way. He's teaching me he'll never bake bread. Plant crops, raise livestock. He's telling me he's futureless. And eventually he'll tell me how long the infected take to starve to death. Dinner's at seven. Don't forget to tell the girls.\", 'gold_tag': 'HENRY is pragmatic and somewhat scientific in his approach to the infection , HENRY demonstrates a proactive mindset , HENRY implies a temporal aspect when mentioning the scheduled dinner at seven', 'last_speaker': 'HENRY'}\n",
      "Last word -> HENRY : \"The idea was to learn something about infection. Have him teach me. In a way. He's teaching me he'll never bake bread. Plant crops, raise livestock. He's telling me he's futureless. And eventually he'll tell me how long the infected take to starve to death. Dinner's at seven. Don't forget to tell the girls.\"\n",
      "prediction :  He's not just alive, he's... ...he's a new kind of life.\n",
      "Real answer : The idea was to learn something about infection. Have him teach me. In a way. He's teaching me he'll never bake bread. Plant crops, raise livestock. He's telling me he's futureless. And eventually he'll tell me how long the infected take to starve to death. Dinner's at seven. Don't forget to tell the girls.\n",
      "Bert Score : {'precision': [0.8452543020248413], 'recall': [0.8386194705963135], 'f1': [0.8419237732887268], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18666666666666668, 'rouge2': 0.08219178082191782, 'rougeL': 0.16000000000000003, 'rougeLsum': 0.16000000000000003}\n",
      "bleu 1/2 : 0.0036470414514039326 0.0008553070350197161\n",
      "ppl : 20.050403783418442\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHENRY: Drink?\\nJIM: Look. We're grateful. Very grateful for your protection, and just to have found other people. But if we're going to stay here with you, you're going to have to stop your men from -\\nHENRY: Who have you killed?\\nJIM: I haven't killed anyone.\\nHENRY: Since it began, who have you killed? You wouldn't be alive now if you hadn't killed somebody.\\nJIM: A boy. I killed a boy.\\nHENRY: A child?\\nJIM: Yes.\\nHENRY: But you had to. Otherwise he'd have killed you. Survival. I understand. I promised them women.\\nJIM: What?\\n\\n\", 'answer': 'Eight days ago I found Jones with his gun in this mouth. He said he was going to kill himself because there was no future. What could I say to him? We kill all the infected or wait until they starve nine men do except wait to die themselves? I moved us from the blockade, I set the radio broadcasting, and I promised them women. Because women mean children. And children mean a future.', 'gold_tag': 'Eight days ago, Henry found Jones with a gun in his mouth, contemplating suicide , Henry moved the group from the blockade and set the radio broadcasting', 'last_speaker': 'HENRY'}\n",
      "Last word -> HENRY : \"Eight days ago I found Jones with his gun in this mouth. He said he was going to kill himself because there was no future. What could I say to him? We kill all the infected or wait until they starve nine men do except wait to die themselves? I moved us from the blockade, I set the radio broadcasting, and I promised them women. Because women mean children. And children mean a future.\"\n",
      "prediction :  We promised them women. And they will have them.\n",
      "Real answer : Eight days ago I found Jones with his gun in this mouth. He said he was going to kill himself because there was no future. What could I say to him? We kill all the infected or wait until they starve nine men do except wait to die themselves? I moved us from the blockade, I set the radio broadcasting, and I promised them women. Because women mean children. And children mean a future.\n",
      "Bert Score : {'precision': [0.8902327418327332], 'recall': [0.8250466585159302], 'f1': [0.8564010858535767], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14457831325301207, 'rouge2': 0.04938271604938271, 'rougeL': 0.12048192771084337, 'rougeLsum': 0.12048192771084337}\n",
      "bleu 1/2 : 0.0004867853312431987 0.00029809391895438175\n",
      "ppl : 94.47214551896808\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHANG: I am from a nearby Lamasery. My name is Chang.\\nCONWAY: And mine's Conway. You've no idea, sir, how unexpected and very welcome you are. My friends and I - and the lady in the plane - left Baskul night before last for Shanghai, but we suddenly found ourselves travelling in the opposite direction� At the mercy of a mad pilot. We'd be eternally grateful if you�\\nCHANG: Where is your mad pilot?\\nCONWAY: We were just going to bury him when you came along.\\nCHANG: Pardon me� instructions to take care of the pilot.\\nCONWAY: So, if you will be good enough to direct us to your Lamasery�\\n\\n\", 'answer': 'I shall consider it an honor to accompany you and your friends. You will need suitable clothes for the journey. It is not particularly far, but quite difficult.', 'gold_tag': 'CHANG takes on the role of guiding Conway and his friends to his Lamasery', 'last_speaker': 'CHANG'}\n",
      "Last word -> CHANG : \"I shall consider it an honor to accompany you and your friends. You will need suitable clothes for the journey. It is not particularly far, but quite difficult.\"\n",
      "prediction :  We are not far from here. I will take you there in my plane.\n",
      "Real answer : I shall consider it an honor to accompany you and your friends. You will need suitable clothes for the journey. It is not particularly far, but quite difficult.\n",
      "Bert Score : {'precision': [0.8859673142433167], 'recall': [0.8729613423347473], 'f1': [0.8794162273406982], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2380952380952381, 'rouge2': 0.0, 'rougeL': 0.09523809523809523, 'rougeLsum': 0.09523809523809523}\n",
      "bleu 1/2 : 0.10510841176326924 0.017246454213478504\n",
      "ppl : 25.861648684984644\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHANG: it. There are over two thousand people in the Valley besides those here in Shangri-La.\\nCONWAY: Who and what is Shangri-La? You?\\nCHANG: Goodness, no! Oh, yes.\\nCONWAY: Who, for instance?\\nCHANG: In time you will meet them all. There are some things, my dear Conway, I deeply regret I may not discuss.\\nCONWAY: You know, that's the fourth time you've said that today. You should have a record made of it.\\n\\n\", 'answer': 'Shall we go inside? I should so like to show you some of our rare treasures.', 'gold_tag': 'CHANG is affiliated with Shangri-La, possibly as a resident or someone with significant knowledge about it', 'last_speaker': 'CHANG'}\n",
      "Last word -> CHANG : \"Shall we go inside? I should so like to show you some of our rare treasures.\"\n",
      "prediction :  Why?\n",
      "Real answer : Shall we go inside? I should so like to show you some of our rare treasures.\n",
      "Bert Score : {'precision': [0.8597520589828491], 'recall': [0.827795684337616], 'f1': [0.843471348285675], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3142.135932895678\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHANG: At some time in the future you will have the pleasure of meeting her.\\n\\n', 'answer': 'Some man had better get ready to be very courteous to me.', 'gold_tag': 'CONWAY implies a future situation where he expects to be treated with courtesy', 'last_speaker': 'CONWAY'}\n",
      "Last word -> CONWAY : \"Some man had better get ready to be very courteous to me.\"\n",
      "prediction :  Who?\n",
      "Real answer : Some man had better get ready to be very courteous to me.\n",
      "Bert Score : {'precision': [0.8372749090194702], 'recall': [0.8021475076675415], 'f1': [0.819334864616394], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3856.0021279346893\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCONWAY: But Mr. Chang, all these things - books, instruments, sculpture - do you mean to say they were all brought in over those mountains by porters?\\nCHANG: They were.\\nCONWAY: Well, it must have taken� Centuries! Where did you get the money to pay for all those treasures?\\n\\n', 'answer': 'Of course we have no money as you know it. We do not buy or sell or seek personal fortunes because, well, because there is no uncertain future here for which to accumulate it.', 'gold_tag': \"CHANG lives in a society without conventional currency , Personal fortunes are not sought after in CHANG's society , The future is certain in CHANG's society\", 'last_speaker': 'CHANG'}\n",
      "Last word -> CHANG : \"Of course we have no money as you know it. We do not buy or sell or seek personal fortunes because, well, because there is no uncertain future here for which to accumulate it.\"\n",
      "prediction :  The porters were paid in kind.\n",
      "Real answer : Of course we have no money as you know it. We do not buy or sell or seek personal fortunes because, well, because there is no uncertain future here for which to accumulate it.\n",
      "Bert Score : {'precision': [0.8579652309417725], 'recall': [0.8234120607376099], 'f1': [0.8403336405754089], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 176.0544871710174\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCONWAY: That would suit me perfectly. I\\'m always broke. How did you pay for them?\\nCHANG: Our Valley is very rich in a metal called gold, which fortunately for us is valued very highly in the outside world. So we merely . . .\\nCONWAY: �buy and sell?\\nCHANG: Buy and - sell? No, no, pardon me, exchange\\nCONWAY: I see. Gold for ideas. You know Mr. Chang, there\\'s something so simple and naive about all of this that I suspect there has been a shrewd, guiding intelligence somewhere. Whose idea was it? How did it all start?\\nCHANG: That, my dear Conway, is the story of A Belgian priest by the name of Father Perrault, the first European to find this place, and a very great man indeed. He is responsible for everything you see here. He built Shangri-La, taught our natives, and began our collection of art. In fact, Shangri-La is Father Perrault. Oh, let me see - way back in 1713, I think it was, that Father Perrault stumbled It was typical of the man that, one leg being frozen, and of course there being no doctors here, he amputated the leg himself.\\nCONWAY: He amputated his own leg?\\nCHANG: Yes. Oddly enough, later, when he had learned to understand their language, the natives told him he could have saved his leg. It would have healed without amputation.\\nCONWAY: Well, they didn\\'t actually mean that.\\nCHANG: Yes, yes. They were very sincere about it too. You see, a perfect body in perfect health is the rule here. They\\'ve never known anything different. So what was true for them they thought would naturally be true for anyone else living here.\\nCONWAY: Well, is it?\\nCHANG: Rather astonishingly so, yes. And particularly Do you know when he and the natives were finished building Shangri-La, he was 108 years old and still very active, in spite of only having one leg?\\nCONWAY: 108 and still active?\\nCHANG: Forgive me. I should have told you it is quite common here to live to a very ripe old age. Climate, diet, mountain water, you might say. But we like to believe it is the absence of struggle in the way we live. In your countries, on the other hand, how often do you hear the expression, \"He worried himself to death?\" or, \"This thing or that killed him?\"\\nCONWAY: Very often.\\nCHANG: And very true. Your lives are therefore, Why, Mr. Conway, you surprise me!\\nCONWAY: I surprise you? Now that\\'s news.\\n\\n', 'answer': \"I mean, your amazement. I could have understood it in any of your companions, but you - who have dreamed and written so much about better worlds. Or is it that you fail to recognize one of your own dreams when you see it? Then everything is quite all right, isn't it?\", 'gold_tag': 'CONWAY is surprised at the long lifespan of people in the valley, although he has written about better worlds', 'last_speaker': 'CHANG'}\n",
      "Last word -> CHANG : \"I mean, your amazement. I could have understood it in any of your companions, but you - who have dreamed and written so much about better worlds. Or is it that you fail to recognize one of your own dreams when you see it? Then everything is quite all right, isn't it?\"\n",
      "prediction :  I assure you, you are the first man to ever show any interest in it.\n",
      "Real answer : I mean, your amazement. I could have understood it in any of your companions, but you - who have dreamed and written so much about better worlds. Or is it that you fail to recognize one of your own dreams when you see it? Then everything is quite all right, isn't it?\n",
      "Bert Score : {'precision': [0.859901487827301], 'recall': [0.8283767700195312], 'f1': [0.8438448309898376], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.208955223880597, 'rouge2': 0.0, 'rougeL': 0.14925373134328357, 'rougeLsum': 0.14925373134328357}\n",
      "bleu 1/2 : 0.0282890929900058 0.004141099186889176\n",
      "ppl : 21.023155950656122\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSLOANE: Cool.\\n\\n', 'answer': 'I think I see my Dad.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CAMERON'}\n",
      "Last word -> CAMERON : \"I think I see my Dad.\"\n",
      "prediction :  I’m going to do some research on the company, see if there’s anything in their background that could help us.\n",
      "Real answer : I think I see my Dad.\n",
      "Bert Score : {'precision': [0.854918897151947], 'recall': [0.8809381723403931], 'f1': [0.8677335381507874], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714288, 'rouge2': 0.0, 'rougeL': 0.14285714285714288, 'rougeLsum': 0.14285714285714288}\n",
      "bleu 1/2 : 0.05000000000000001 0.01622214211307625\n",
      "ppl : 10.428247027548736\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCAMERON: What were you in a previous life?\\nSLOANE: I'm not sure but I think I know who Ferris was.\\nCAMERON: Hannibal.\\nSLOANE: From the A-Team?\\nCAMERON: No. The guy who rode the elephants into Switzerland.\\nSLOANE: I think if he was anybody, he was Magellan. You know, the guy who went around the world. I could see him ignoring popular belief and taking off on some impossible mission.\\n\\n\", 'answer': \"Yeah. As long as I've known him, everything works for him. There's nothing he can't handle. I can't handle anything. School, parents,\", 'gold_tag': 'CAMERON feels inadequate to handle life challenges , CAMERON struggles with school , CAMERON struggles with dealing with parents , Shared memories', 'last_speaker': 'CAMERON'}\n",
      "Last word -> CAMERON : \"Yeah. As long as I've known him, everything works for him. There's nothing he can't handle. I can't handle anything. School, parents,\"\n",
      "prediction :  And you're the one who's going to be the first woman to go to the moon.\n",
      "Real answer : Yeah. As long as I've known him, everything works for him. There's nothing he can't handle. I can't handle anything. School, parents,\n",
      "Bert Score : {'precision': [0.8349207639694214], 'recall': [0.8364410996437073], 'f1': [0.8356802463531494], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.04545454545454546, 'rouge2': 0.0, 'rougeL': 0.04545454545454546, 'rougeLsum': 0.04545454545454546}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.375460792025185\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSLOANE: The future's worse for a boy, isn't it? A girl can always bail out and have a baby and get some guy to support her.\\nCAMERON: That's a pretty grim thought.\\nSLOANE: True, but it's an option. No options is worse.\\nCAMERON: I don't know what I'm gonna do.\\nSLOANE: College.\\nCAMERON: Yeah, but to do what?\\nSLOANE: What are you interested in?\\nCAMERON: Nothing.\\nSLOANE: Me either.\\n\\n\", 'answer': 'What do you think Ferris is gonna do?', 'gold_tag': 'Everyday Language', 'last_speaker': 'CAMERON'}\n",
      "Last word -> CAMERON : \"What do you think Ferris is gonna do?\"\n",
      "prediction :  I think I might be in love with you.\n",
      "Real answer : What do you think Ferris is gonna do?\n",
      "Bert Score : {'precision': [0.8705741167068481], 'recall': [0.831344485282898], 'f1': [0.8505071997642517], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23529411764705882, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.11111111111111109 0.03726779962499649\n",
      "ppl : 18.353360455563653\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBAINES: Those 80 acres, that cross the stream, what do you think of them?\\nSTEWART: On your property?\\nBAINES: Yes\\nSTEWART: Good, flatish land with reliable water, why? I don't have money. What are you about?\\nBAINES: I'd like to make a swap.\\nSTEWART: What for?\\nBAINES: The piano.\\nSTEWART: The piano on the beach? Ada's piano? It's not marshy is it?\\nBAINES: No.\\nSTEWART: You'd have to organise it up here.\\nBAINES: Yes, I thought that.\\nSTEWART: Well Baines the music lover, I never would have known. Hidden talents George.\\nBAINES: I'll have to get lessons. It wouldn't be much use without them.\\n\\n\", 'answer': \"Yes, I suppose you would. Well Ada can play. I have it in a letter she plays well. She's been playing since she was 5 or6.\", 'gold_tag': 'STEWART knows Ada, her piano, and her musical talent, indicating a close relationship or awareness', 'last_speaker': 'STEWART'}\n",
      "Last word -> STEWART : \"Yes, I suppose you would. Well Ada can play. I have it in a letter she plays well. She's been playing since she was 5 or6.\"\n",
      "prediction :  I'll tell you what I'll do. I'll give you a lesson once a week.\n",
      "Real answer : Yes, I suppose you would. Well Ada can play. I have it in a letter she plays well. She's been playing since she was 5 or6.\n",
      "Bert Score : {'precision': [0.8749894499778748], 'recall': [0.8459624648094177], 'f1': [0.8602311611175537], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1818181818181818, 'rouge2': 0.0, 'rougeL': 0.1818181818181818, 'rougeLsum': 0.1818181818181818}\n",
      "bleu 1/2 : 0.06062469223956427 0.014067822849432837\n",
      "ppl : 9.239533804133101\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTEWART: What do they want it for? They don't cultivate it, burn it back, anything. How do they even know it's theirs? as well mark it out.\\nBAINES: Yes, why not.\\nSTEWART: Ada says you're doing well with the piano? I'll have to come and hear you play. what do you play.\\nBAINES: Nothing just yet\\n\\n\", 'answer': 'No. Well I suppose it takes time.', 'gold_tag': 'Everyday Language', 'last_speaker': 'STEWART'}\n",
      "Last word -> STEWART : \"No. Well I suppose it takes time.\"\n",
      "prediction : Well, you must come and have dinner with us. I'll have to see Ada.\n",
      "Real answer : No. Well I suppose it takes time.\n",
      "Bert Score : {'precision': [0.8458830118179321], 'recall': [0.8752634525299072], 'f1': [0.8603224754333496], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 27.768310332660636\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTEWART: Put that away, on the floor. I look at you, at your face. I have had that face in my head hating it. But now I am here seeing it ... it\\'s nothing, you blink, you have your mark, you look at me through your eyes, yes. you are even scared of me Look at you! Has Ada ever spoken to you?\\nBAINES: You mean in signs?\\nSTEWART: No, words. You have never heard words?\\nBAINES: No, not words.\\nSTEWART: Never thought you heard words? She has spoken to me. I heard her voice. There was no sound, but I beard it here (he presses hand). Her voice was there in my head. I watched her lips, they did not make the words, yet the harder I listened the clearer I heard her, as clear as I hear you, as dear as I hear my own voice.\\nBAINES: Spoken words?\\nSTEWART: No, but her words are in my that it\\'s a trick, that I\\'m making it up. No, the words I heard, were her words.\\nBAINES: (suspiciously) What are they?\\nSTEWART: She said, \"I have to go, let me go, let Baines take me away, let him try and save me. I am frightened of my will, of what it might do it is so strange and strong\".\\nBAINES: You punished her wrongly, it was me, my fault.\\n\\n', 'answer': \"Understand me. I am here for her, for her I wonder that I don't wake, that I am not asleep to be here talking with you. I love her. But what is the use? She doesn't care for me. I wish her gone. I wish you gone. I want to wake and find it was a dream, that is what I want. I want to believe I am not this man. I want my self back; the one I know.\", 'gold_tag': 'STEWART expresses frustration and sadness', 'last_speaker': 'STEWART'}\n",
      "Last word -> STEWART : \"Understand me. I am here for her, for her I wonder that I don't wake, that I am not asleep to be here talking with you. I love her. But what is the use? She doesn't care for me. I wish her gone. I wish you gone. I want to wake and find it was a dream, that is what I want. I want to believe I am not this man. I want my self back; the one I know.\"\n",
      "prediction :  I did not punish her. I have been punished, by her.\n",
      "Real answer : Understand me. I am here for her, for her I wonder that I don't wake, that I am not asleep to be here talking with you. I love her. But what is the use? She doesn't care for me. I wish her gone. I wish you gone. I want to wake and find it was a dream, that is what I want. I want to believe I am not this man. I want my self back; the one I know.\n",
      "Bert Score : {'precision': [0.8736147880554199], 'recall': [0.8273748755455017], 'f1': [0.8498663306236267], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10752688172043011, 'rouge2': 0.021978021978021976, 'rougeL': 0.10752688172043011, 'rougeLsum': 0.10752688172043011}\n",
      "bleu 1/2 : 0.0006862090874988424 0.00011379490354829094\n",
      "ppl : 39.66963762010848\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK FURY: We should tell them to go back to sleep?\\nAGENT MARIA HILL: If we can't control the Tesseract's energy, there may not be a minimum safe\\nNICK FURY: I need you to make sure that PHASE 2\\nAGENT MARIA HILL: Sir, is that really a priority right now?\\nNICK FURY: Until such time as the world ends, we will act as though it intends to spin on. Clear out the tech below. Every piece of PHASE 2 on a truck and gone.\\n\\n\", 'answer': 'Yes, sir. With me.', 'gold_tag': 'AGENT MARIA HILL is subordinate to NICK FURY and follows his orders', 'last_speaker': 'AGENT MARIA HILL'}\n",
      "Last word -> AGENT MARIA HILL : \"Yes, sir. With me.\"\n",
      "prediction :  Sir, you can't just order all of PHASE 2 to be destroyed.\n",
      "Real answer : Yes, sir. With me.\n",
      "Bert Score : {'precision': [0.8365144729614258], 'recall': [0.8433807492256165], 'f1': [0.8399335741996765], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 52.457540566245235\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nAGENT MARIA HILL: We're at lock, sir.\\n\\n\", 'answer': \"Good. Let's vanish.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'NICK FURY'}\n",
      "Last word -> NICK FURY : \"Good. Let's vanish.\"\n",
      "prediction :  Thank you, Maria.\n",
      "Real answer : Good. Let's vanish.\n",
      "Bert Score : {'precision': [0.8673275709152222], 'recall': [0.8948096036911011], 'f1': [0.8808543086051941], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 115.37877869726151\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nAGENT MARIA HILL: Sir.\\nNICK FURY: Agent Hill?\\nAGENT MARIA HILL: Those cards, they were in Coulson's locker, not in his jacket.\\nNICK FURY: They needed the push. They found it. Get our communications back up, whatever you have to do. I want eyes on everything.\\n\\n\", 'answer': 'Yes, sir.', 'gold_tag': 'AGENT MARIA HILL is a subordinate to NICK FURY', 'last_speaker': 'AGENT MARIA HILL'}\n",
      "Last word -> AGENT MARIA HILL : \"Yes, sir.\"\n",
      "prediction :  On it.\n",
      "Real answer : Yes, sir.\n",
      "Bert Score : {'precision': [0.9116195440292358], 'recall': [0.8392238616943359], 'f1': [0.8739249110221863], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1379.1074314521288\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK FURY: They'll come back.\\nAGENT MARIA HILL: You really sure about that?\\nNICK FURY: I am.\\nAGENT MARIA HILL: Why?\\n\\n\", 'answer': \"Because we'll need them to.\", 'gold_tag': 'NICK FURY indicates a future need for the implied group, suggesting a potential crisis or threat', 'last_speaker': 'NICK FURY'}\n",
      "Last word -> NICK FURY : \"Because we'll need them to.\"\n",
      "prediction :  Because I've seen it before.\n",
      "Real answer : Because we'll need them to.\n",
      "Bert Score : {'precision': [0.8781800270080566], 'recall': [0.872405469417572], 'f1': [0.8752832412719727], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.2 0.07071067811865477\n",
      "ppl : 59.24499189867193\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMANRAY: I'm starvin' like Marvin.\\nCHEEBA: My world famous, famous world Arroz con pollo will be ready very soon.\\nMANRAY: Hurry up, I wanna watch HBO.\\nCHEEBA: Did we get our bill yet?\\nMANRAY: I guess that will come with the rent, gas, and Con Ed bills, too.\\nCHEEBA: Ahh, the luxuries of life.\\nMANRAY: Yo, check it. This is good and all that but one day soon I want to have much Benjamins so I can have a nice crib and pay all my bills. You hear me.\\nCHEEBA: Chill, I'm the brains behind this outfit.\\nMANRAY: And I'm the feet.\\nCHEEBA: Yo, you gotta show some patience. You want me to snap my fingers and presto chango - you're an overnight sensation. Son, there is no such thing.\\n\\n\", 'answer': \"I'm tired of waiting.\", 'gold_tag': 'MANRAY is somewhat impatient', 'last_speaker': 'MANRAY'}\n",
      "Last word -> MANRAY : \"I'm tired of waiting.\"\n",
      "prediction :  You gotta work for it.\n",
      "Real answer : I'm tired of waiting.\n",
      "Bert Score : {'precision': [0.8794536590576172], 'recall': [0.8868041038513184], 'f1': [0.8831135630607605], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 66.8947646999267\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHEEBA: Not this way. Out through the fire escape.\\n\\n', 'answer': 'My tap shoes.', 'gold_tag': 'MANRAY is a tap dancer , MANRAY is concerned about his tap shoes', 'last_speaker': 'MANRAY'}\n",
      "Last word -> MANRAY : \"My tap shoes.\"\n",
      "prediction :   No way. This way.\n",
      "Real answer : My tap shoes.\n",
      "Bert Score : {'precision': [0.8701035380363464], 'recall': [0.883481502532959], 'f1': [0.8767414689064026], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 375.25744284757786\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMANRAY: We ran out without my shoes and the floor. I gotta get my stuff. What about our savings?\\n\\n', 'answer': 'Are you crazy? The joint is crawling with cops now. You wanna go to Rikers? Go to the hoosegow?', 'gold_tag': 'CHEEBA is risk-avoidant , CHEEBA suggests the immediate danger of encountering the police if they return to their previous location', 'last_speaker': 'CHEEBA'}\n",
      "Last word -> CHEEBA : \"Are you crazy? The joint is crawling with cops now. You wanna go to Rikers? Go to the hoosegow?\"\n",
      "prediction :  It's gone, man. The bank said it was stolen.\n",
      "Real answer : Are you crazy? The joint is crawling with cops now. You wanna go to Rikers? Go to the hoosegow?\n",
      "Bert Score : {'precision': [0.882366418838501], 'recall': [0.8348404765129089], 'f1': [0.8579457402229309], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06896551724137931, 'rouge2': 0.0, 'rougeL': 0.06896551724137931, 'rougeLsum': 0.06896551724137931}\n",
      "bleu 1/2 : 0.036576998645322836 0.012268298307578937\n",
      "ppl : 34.42503382205898\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEMILIE: It's not a charade, all this?\\nSCHINDLER: A charade? How could it be a charade? There's no way I could have known this before, but there was always something missing. In every business I tried, I see now it wasn't me that was failing, it was this thing, this missing thing. Even if I'd known what it was, there's nothing I could have done about it, because you can't create this sort of thing. And it makes all the difference in the world between success and failure.\\nEMILIE: Luck.\\n\\n\", 'answer': 'War.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SCHINDLER'}\n",
      "Last word -> SCHINDLER : \"War.\"\n",
      "prediction :  Luck? You think it's luck?\n",
      "Real answer : War.\n",
      "Bert Score : {'precision': [0.8066550493240356], 'recall': [0.9252482056617737], 'f1': [0.8618912100791931], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 45.24787571738364\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSCHINDLER: What?\\n\\n', 'answer': 'I feel like an old-fashioned couple. It feels good.', 'gold_tag': 'EMILIE enjoys the feeling of being in an old-fashioned couple', 'last_speaker': 'EMILIE'}\n",
      "Last word -> EMILIE : \"I feel like an old-fashioned couple. It feels good.\"\n",
      "prediction :  You're right. I'm sorry.\n",
      "Real answer : I feel like an old-fashioned couple. It feels good.\n",
      "Bert Score : {'precision': [0.8642622232437134], 'recall': [0.8433969020843506], 'f1': [0.8537021279335022], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.280543941850759\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEMILIE: Should I stay?\\nSCHINDLER: It's a beautiful city.\\nEMILIE: Should I stay?\\nSCHINDLER: It's up to you. That's not it either.\\n\\n\", 'answer': \"No, it's up to you. Promise me no doorman or maitre 'd will presume I am anyone other than Mrs. Schindler... and I'll stay.\", 'gold_tag': \"EMILIE is the wife of Schindler , EMILIE wants to be recognized as Mrs. Schindler, not by her association with others like doormen or maitre 'd\", 'last_speaker': 'EMILIE'}\n",
      "Last word -> EMILIE : \"No, it's up to you. Promise me no doorman or maitre 'd will presume I am anyone other than Mrs. Schindler... and I'll stay.\"\n",
      "prediction :  That's not it either.\n",
      "Real answer : No, it's up to you. Promise me no doorman or maitre 'd will presume I am anyone other than Mrs. Schindler... and I'll stay.\n",
      "Bert Score : {'precision': [0.8420810699462891], 'recall': [0.7974485158920288], 'f1': [0.8191573023796082], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12903225806451613, 'rouge2': 0.0, 'rougeL': 0.06451612903225806, 'rougeLsum': 0.06451612903225806}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 70.18535287856128\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJENNY: You sure this is your car?\\nTEENAGER: My grandmother's rich.\\nJENNY: Slow down, slow down.\\nTEENAGER: Geez, Mrs. Haydn, we just got going.\\nJENNY: I told you I'm looking for someone.\\nTEENAGER: In the cars, too?!\\nJENNY: I don't know where he is.\\nTEENAGER: This is going to be a real drag. I thought you wanted to go fast. They after you?\\nJENNY: What? No, of course not.\\n\\n\", 'answer': 'Would be kinda neat if they were. I think I could outrun them. Maybe get my picture in the papers.', 'gold_tag': 'The TEENAGER is excited about the possibility of being chased and having his picture taken , The excitement suggests a desire for thrill or attention', 'last_speaker': 'TEENAGER'}\n",
      "Last word -> TEENAGER : \"Would be kinda neat if they were. I think I could outrun them. Maybe get my picture in the papers.\"\n",
      "prediction : So, you're not going to give me a ride.\n",
      "Real answer : Would be kinda neat if they were. I think I could outrun them. Maybe get my picture in the papers.\n",
      "Bert Score : {'precision': [0.8648050427436829], 'recall': [0.8576149344444275], 'f1': [0.8611949682235718], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 17.21781157354578\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTEENAGER: I'm telling you, you're going to find him at the roadblock, or right after, or not at all.\\nJENNY: If he didn't want to go through the roadblock, is there any other way to get to Vegas?\\nTEENAGER: Fly. The five-fifty. We already passed it. But it'll take him way out of\\nJENNY: Pull over. I've got to get back there.\\nTEENAGER: Why wouldn't he want to go through the roadblock?... What did you guys do?... I won't tell anybody.\\n\\n\", 'answer': \"It's easier not to tell if you don't know.\", 'gold_tag': \"JENNY's actions suggest she's a decisive, quick-thinking person\", 'last_speaker': 'JENNY'}\n",
      "Last word -> JENNY : \"It's easier not to tell if you don't know.\"\n",
      "prediction :  It's not that. It's just that he's not going to make it.\n",
      "Real answer : It's easier not to tell if you don't know.\n",
      "Bert Score : {'precision': [0.8676395416259766], 'recall': [0.8682025671005249], 'f1': [0.867920994758606], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.30769230769230765, 'rouge2': 0.08333333333333333, 'rougeL': 0.30769230769230765, 'rougeLsum': 0.30769230769230765}\n",
      "bleu 1/2 : 0.25 0.047673129462279626\n",
      "ppl : 12.630685825838036\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTEENAGER: Wait. Could I have your autograph?\\nJENNY: Sure.\\nTEENAGER: I have nothing to do. I'd like to help you.\\n\\n\", 'answer': \"Don't worry. I'll be all right.\", 'gold_tag': 'JENNY is confident and independent', 'last_speaker': 'JENNY'}\n",
      "Last word -> JENNY : \"Don't worry. I'll be all right.\"\n",
      "prediction :  Oh, you don't have to help me. It's okay.\n",
      "Real answer : Don't worry. I'll be all right.\n",
      "Bert Score : {'precision': [0.8877648711204529], 'recall': [0.9040245413780212], 'f1': [0.8958209156990051], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2105263157894737, 'rouge2': 0.11764705882352941, 'rougeL': 0.2105263157894737, 'rougeLsum': 0.2105263157894737}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.211135808914937\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBARBARA: The markings he's made on my father's arms are from the pollen of the tule plant. The twigs have no significance other than they've been struck by lightning and are consequently appeals to the spirit of lightning. It's all entirely harmless, a religious ceremony, not a medical one.\\nBOCK: You don't seriously believe all that mumbo-jumbo will cure him?\\nBARBARA: On the other hand, it won't kill him, Doctor.\\nBOCK: Okay. Go ahead.\\nBARBARA: Thank you.\\nBOCK: Miss Drummond, are you still taking your father out?\\nBARBARA: Yes. I still have to arrange an ambulance service. Is there a phone around I could use?\\nBOCK: Use my office.\\n\\n\", 'answer': 'Thank you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BARBARA'}\n",
      "Last word -> BARBARA : \"Thank you.\"\n",
      "prediction :  Doctor Bock, what did you think when you first met my father?\n",
      "Real answer : Thank you.\n",
      "Bert Score : {'precision': [0.8119622468948364], 'recall': [0.8812887668609619], 'f1': [0.8452062606811523], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 46.64913881795828\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBARBARA: Hello. I'd like to arrange an ambulance for one-thirty tomorrow afternoon... Thank you... ...Drummond, first name, Barbara. I'll pay cash... No, you're to pick up my father, Drummond, Edward, at the Manhattan Medical Center, Holly Pavilion, Room Eight-O-Six. It's a stretcher case. I presume you provide the stretcher. He's to be taken to American Airlines, Yes... No... Kennedy Airport, Flight Seven-Two-Nine to Yuma, Arizona. I'll accompany the patient... Yes, thank you.\\nBOCK: You believe in witchcraft, Miss Drummond?\\nBARBARA: I believe in everything, Doctor.\\nBOCK: Like a drink?\\n\\n\", 'answer': 'Yes. My father, you should know, was a very successful doctor in Boston, a member of the Harvard Medical Faculty. He was a widower, and I was his only child. He was not an especially religious man, a sober Methodist. One evening, seven years ago, he attended a Pentecostal meeting in', 'gold_tag': \"BARBARA's father, Edward Drummond, was a successful doctor from Boston and a member of the Harvard Medical Faculty , BARBARA's father passed away seven years ago\", 'last_speaker': 'BARBARA'}\n",
      "Last word -> BARBARA : \"Yes. My father, you should know, was a very successful doctor in Boston, a member of the Harvard Medical Faculty. He was a widower, and I was his only child. He was not an especially religious man, a sober Methodist. One evening, seven years ago, he attended a Pentecostal meeting in\"\n",
      "prediction :  No, thank you.\n",
      "Real answer : Yes. My father, you should know, was a very successful doctor in Boston, a member of the Harvard Medical Faculty. He was a widower, and I was his only child. He was not an especially religious man, a sober Methodist. One evening, seven years ago, he attended a Pentecostal meeting in\n",
      "Bert Score : {'precision': [0.8503310680389404], 'recall': [0.8005602955818176], 'f1': [0.8246954679489136], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.037037037037037035, 'rouge2': 0.0, 'rougeL': 0.037037037037037035, 'rougeLsum': 0.037037037037037035}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 131.62534391397838\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOCK: What the hell am I supposed to say to that, Miss Drummond? I'm sitting here boozing and, all of a sudden, you start telling me some demented story about your father's religious conversion.\\nBARBARA: No, no, you miss the point, Doctor. Not my father's conversion -- mine. You see, I had been hitting the acid pretty regularly at that time. I had achieved a few minor sensory deformities, some suicidal despairs, but nothing as wild as fluency in an obscure Apache dialect. I mean, like wow, man! I mean, here was living afflatus right before my eyes! Within a week, my father had closed his Beacon Hill practice and set out to start a mission in the Mexican mountains. And I turned in my S.D.S. card and my crash helmet and followed him. It was a disaster, at least for me. My father had received the revelation, not I. He stood gaunt on a mountain slope and preached the apocalypse to solemnly amused Indians. I masturbated a great deal. We lived in a grass wickiup and ate raw rabbit and crushed pi�on nuts. It was hideous. Within two months, I was back in Boston, a hollow shell and dizzy with dengue, disenchanted with everything. I turned to austerity, nursing school. I became haggard, driven and had shamelessly incestuous dreams about my father. I took up with some of the senior staff at the hospital. One of them, a portly psychiatrist, explained I was generated by an unresolved lust for my father. I apparently cracked up. One day, they found me walking to work naked and screaming obscenities. There was talk of institutionalizing me, so I packed a bag and went back to my father in the Sierra Madre Mountains. I've been there ever since. That's three years. My father is, of course, mad as a hatter. I watch over him and have been curiously content. You see, Doctor, I believe in everything.\\nBOCK: Now what was that all about, Miss Drummond?\\nBARBARA: I thought I was obvious as hell. I'm trying to tell you I have a thing for middle-aged men.\\nBOCK: I admire your candor.\\nBARBARA: You've been admiring a lot more than that.\\nBOCK: You're wasting your time. I've been impotent for years.\\nBARBARA: Rubbish.\\n\\n\", 'answer': 'What the hell\\'s wrong with being impotent? My God, you kids are more hung up on sex than the Victorians! I\\'ve got a son, twenty-three. I threw him out of the house last year. Pietistic little humbug. He preached universal love and despised everyone. He had a blanket contempt for the middle class, even its decencies. He detested my mother because she had petit bourgeois pride in her son the doctor. I cannot tell you how brutishly he ignored that rather good old lady. When she died, he didn\\'t even come to the funeral. He thought the chapel service an hypocrisy. His generation didn\\'t live with lies, he told me. \"Everybody lives with lies,\" I said. I grabbed him by his poncho, dragged him the', 'gold_tag': \"BOCK has a son who he threw out of his house last year , BOCK does not appreciate his son's disregard for their family's middle-class values\", 'last_speaker': 'BOCK'}\n",
      "Last word -> BOCK : \"What the hell's wrong with being impotent? My God, you kids are more hung up on sex than the Victorians! I've got a son, twenty-three. I threw him out of the house last year. Pietistic little humbug. He preached universal love and despised everyone. He had a blanket contempt for the middle class, even its decencies. He detested my mother because she had petit bourgeois pride in her son the doctor. I cannot tell you how brutishly he ignored that rather good old lady. When she died, he didn't even come to the funeral. He thought the chapel service an hypocrisy. His generation didn't live with lies, he told me. \"Everybody lives with lies,\" I said. I grabbed him by his poncho, dragged him the\"\n",
      "prediction :  What do you want me to do, Miss Drummond?\n",
      "Real answer : What the hell's wrong with being impotent? My God, you kids are more hung up on sex than the Victorians! I've got a son, twenty-three. I threw him out of the house last year. Pietistic little humbug. He preached universal love and despised everyone. He had a blanket contempt for the middle class, even its decencies. He detested my mother because she had petit bourgeois pride in her son the doctor. I cannot tell you how brutishly he ignored that rather good old lady. When she died, he didn't even come to the funeral. He thought the chapel service an hypocrisy. His generation didn't live with lies, he told me. \"Everybody lives with lies,\" I said. I grabbed him by his poncho, dragged him the\n",
      "Bert Score : {'precision': [0.8419880270957947], 'recall': [0.796809196472168], 'f1': [0.8187758326530457], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05755395683453238, 'rouge2': 0.0, 'rougeL': 0.04316546762589929, 'rougeLsum': 0.04316546762589929}\n",
      "bleu 1/2 : 8.419870713131053e-07 1.630500952458807e-07\n",
      "ppl : 30.967059173500434\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBARBARA: Right on.\\nBOCK: When I say impotent, I don't mean merely limp. Disagreeable as it may be for a woman, a man may sometimes lust for other things, something less transient than an erection, some sense of permanent worth. That's what medicine was for me, my reason for being. When I was thirty-four, Miss Drummond, I presented a paper that pioneered the whole goddam field of immunology. A breakthrough! I'm in all the textbooks. I happen to be an eminent man, Miss Drummond. And you want to know something, Miss Drummond? I don't give a goddam. When I say I'm impotent, I mean I've lost even my desire for work, which is a hell of a lot more primal a passion than sex. I've lost my raison d'etre, my purpose, the only thing I ever truly loved. It's all rubbish anyway. Transplants, antibodies, we manufacture genes, we can produce birth ectogenetically, we can practically clone people like carrots, and half the kids in this ghetto haven't even been inoculated for polio! We have assembled the most enormous medical establishment ever conceived, and people are sicker than ever! We cure nothing! We heal nothing! The whole goddam wretched the hell I'm talking about, do you?\\nBARBARA: Of course, I do.\\nBOCK: I'm tired, I'm terribly tired, Miss Drummond. And I hurt, and I've got nothing going for me anymore. Can you understand that?\\nBARBARA: Yes, of course.\\nBOCK: Then can you understand that the\\nBARBARA: Sounds to me like a familiar case of morbid menopause.\\nBOCK: Oh Christ.\\nBARBARA: Well, it's hard for me to take your despair very seriously, Doctor. You obviously enjoy it so much.\\nBOCK: Oh, bugger off. That's all I need now, clinical insights. Some cockamamie twenty-five-year-old... ...acidhead's going to reassure me about menopause now. Look, I'd like to be alone, so why don't you beat it? Close the door and turn off the lights on your way out.\\nBARBARA: Mr. Blacktree disapproves of my miniskirt, but it was the only thing I had to come to the city with. Back at the tribe, I wear ankle-length buckskin.\\nBOCK: Swell. Just close the door and turn off the lights. What're you shooting, Doc? Leave me alone...\\nBARBARA: Potassium. You take enough of this stuff, it'll kill you, Doc. It occurred to me that I might have read you wrong, that you really were suicidal. So I came back.\\n\\n\", 'answer': \"Who the hell asked you! Who the hell asked you! Leave me alone! Why the hell don't you leave me alone! Why didn't you let me do it? Who the hell asked you!\", 'gold_tag': 'BOCK is experiencing a deep existential crisis , BOCK is in a poor state of health, both physically and mentally , BOCK expresses his current state of impotence, not only in the sexual sense but also regarding his passion for his work , BOCK seems to be deeply unhappy and possibly suicidal in his present state', 'last_speaker': 'BOCK'}\n",
      "Last word -> BOCK : \"Who the hell asked you! Who the hell asked you! Leave me alone! Why the hell don't you leave me alone! Why didn't you let me do it? Who the hell asked you!\"\n",
      "prediction :  Get out.\n",
      "Real answer : Who the hell asked you! Who the hell asked you! Leave me alone! Why the hell don't you leave me alone! Why didn't you let me do it? Who the hell asked you!\n",
      "Bert Score : {'precision': [0.877129316329956], 'recall': [0.7803612947463989], 'f1': [0.8259205222129822], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1332.6882763352337\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOCK: You wouldn't be awake.\\nBARBARA: What time is it?\\nBOCK: I swiped this for you out of the nurses' locker room. I'll make good on your dress. I'm afraid it's torn beyond repair. Buy yourself a new one or, if you like, give me your size and I'll send it on to you. But I want to talk to you about that.\\nBARBARA: Talk to me about what?\\nBOCK: About your father. You really shouldn't move him in his condition. I just had a look at his chart. There's no reason to presume brain damage. You know as well as I you can't predict anything in these instances. He could pull out of that coma at any time. I think you should let him stay here. I'll personally look after him.\\nBARBARA: Is this your way of saying you'd like me to stay in town a few more days?\\nBOCK: Well, that would be nice, too. What do you say, Miss Drummond?\\nBARBARA: I expect you can call me Barbara, considering you ravished me three times last night.\\nBOCK: Three times?\\nBARBARA: Oh, look at him, pretending he didn't count. You were as puffed up as a toad about it. Punched a couple of holes in your crusade for universal impotence, didn't it? I think we're on a first name basis by now. I'll call you Herb.\\nBOCK: Let's give your father a week, Barbara, what do you say?\\n\\n\", 'answer': \"No, I don't want my father in this hospital. I had a dream about this hospital. I dreamt this enormous starched white tile building suddenly erupted like\", 'gold_tag': \"BARBARA's father is in a coma , BARBARA is in charge of her father's care , BARBARA's temporal information: BARBARA's father is currently in the hospital and in a coma, this information is likely to change in the future\", 'last_speaker': 'BARBARA'}\n",
      "Last word -> BARBARA : \"No, I don't want my father in this hospital. I had a dream about this hospital. I dreamt this enormous starched white tile building suddenly erupted like\"\n",
      "prediction :  Herb.\n",
      "Real answer : No, I don't want my father in this hospital. I had a dream about this hospital. I dreamt this enormous starched white tile building suddenly erupted like\n",
      "Bert Score : {'precision': [0.9344737529754639], 'recall': [0.8135105967521667], 'f1': [0.8698067665100098], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1722.1162718393539\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOCK: Look, you're not going. I love you, and I'm not going to let you go. Come on, let's start putting your father's things back. He's staying here. I'll find an apartment somewhere. I'm staying in a filthy little hotel room. We can't use that.\\nBARBARA: I can't make it here, Herb. I'll crack up. I cracked up once already. One week here, and I'd be running naked through the streets screaming again. I can retain my sanity only\\nBOCK: For God's sake, Barbara, you can't seriously see me living in a grass shack hunting jackrabbits for dinner? Be sensible for God's sake.\\nBARBARA: I am being sensible. What is it you're so afraid of leaving here? Your plastic home? Your conditioned air? Your synthetic clothes? Your instant\\nBOCK: You make it sound almost plausible.\\nBARBARA: I don't know why you even hesitate. What's holding you here? Is it your wife?\\nBOCK: No, that's all over. I suppose if I'm married to anything, it's this hospital. It's been my whole life. I just can't walk out on it as if it never mattered. I'm middle-class. Among us middle-class, love doesn't triumph over all. Responsibility does.\\nBARBARA: Herb, don't ask me to stay here with you, because I love you, and I will. And we'll both be destroyed. I've got the bill here to pay yet.\\n\\n\", 'answer': \"I'll come with you.\", 'gold_tag': 'BOCK is considering accompanying BARBARA', 'last_speaker': 'BOCK'}\n",
      "Last word -> BOCK : \"I'll come with you.\"\n",
      "prediction :  The bill?\n",
      "Real answer : I'll come with you.\n",
      "Bert Score : {'precision': [0.8462072014808655], 'recall': [0.848990797996521], 'f1': [0.8475966453552246], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 4267.338351367515\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTAYA: Did you always want to be a soldier?\\nCHRIS: I wanted to be a cowboy-- but I did that and I felt like I was meant for more.\\nTAYA: So you started rescuing girls from bars?\\nCHRIS: I rescued that bar from you. Do you like country music?\\nTAYA: Only when I'm depressed.\\nCHRIS: You want kids?\\nTAYA: Someday. My mom says I have a nose for picking the wrong men.\\nCHRIS: That's a shitty thing to tell a girl.\\nTAYA: I've proven her right.\\nCHRIS: But those wrong picks put you here. They made you who you are. And I like who you are.\\nTAYA: What happens when there's a real person on the other end of that gun?\\n\\n\", 'answer': \"I don't know... I just pray I can do my job if that day comes.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'CHRIS'}\n",
      "Last word -> CHRIS : \"I don't know... I just pray I can do my job if that day comes.\"\n",
      "prediction :  When there is, you're in trouble.\n",
      "Real answer : I don't know... I just pray I can do my job if that day comes.\n",
      "Bert Score : {'precision': [0.8582265973091125], 'recall': [0.8386387825012207], 'f1': [0.8483196496963501], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 63.41443910991218\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRIS: You're trembling...\\nTAYA: I know. I don't...\\nCHRIS: We don't have to do this...\\n\\n\", 'answer': 'I want to. I do...', 'gold_tag': 'Everyday Language', 'last_speaker': 'TAYA'}\n",
      "Last word -> TAYA : \"I want to. I do...\"\n",
      "prediction :  We do...\n",
      "Real answer : I want to. I do...\n",
      "Bert Score : {'precision': [0.9099347591400146], 'recall': [0.8901681303977966], 'f1': [0.8999428749084473], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0.11156508007421491 0.04989342059223037\n",
      "ppl : 2647.7687616567096\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTAYA: I thought you were dead. I thought--\\n\\n', 'answer': \"Shh. I'm know. I'm so sorry.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'CHRIS'}\n",
      "Last word -> CHRIS : \"Shh. I'm know. I'm so sorry.\"\n",
      "prediction :  I know. You thought I was dead. But I'm not.\n",
      "Real answer : Shh. I'm know. I'm so sorry.\n",
      "Bert Score : {'precision': [0.8735021948814392], 'recall': [0.8617498278617859], 'f1': [0.8675862550735474], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4210526315789474, 'rouge2': 0.11764705882352941, 'rougeL': 0.4210526315789474, 'rougeLsum': 0.4210526315789474}\n",
      "bleu 1/2 : 0.2 0.04714045207910317\n",
      "ppl : 14.928019013061382\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRIS: You're the most beautiful thing I've ever seen.\\nTAYA: I have an alien growing inside me-- And there's a strange man in my bedroom.\\nCHRIS: Our bedroom.\\nTAYA: Why isn't it on your finger?\\nCHRIS: If it catches the light...\\nTAYA: Your hands feel different.\\nCHRIS: They're mine. I swear...\\nTAYA: Why am I so fucking nervous?\\nCHRIS: I'm nervous too.\\nTAYA: No you're not. Don't lie.\\nCHRIS: I am... What if that little alien reaches out and grabs me?\\n\\n\", 'answer': 'Why are you so good with me.', 'gold_tag': 'Everyday Language', 'last_speaker': 'TAYA'}\n",
      "Last word -> TAYA : \"Why are you so good with me.\"\n",
      "prediction :  You're not going anywhere.\n",
      "Real answer : Why are you so good with me.\n",
      "Bert Score : {'precision': [0.8590247631072998], 'recall': [0.8642057776451111], 'f1': [0.8616074919700623], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 52.15233916306354\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRIS: You sabotaged me back there.\\nTAYA: What am I supposed to do. You're not talking. You act like it's all okay--\\nCHRIS: It is okay. I'm fine.\\nTAYA: You're not fine. Your blood pressure--\\nCHRIS: Babe, I'm driving down the freeway, it's sunny and 72 degrees. I'm fine. But there are people dying over there and I look around and it's like it's not even happening. It's barely on the news, no one talks about it. No one cares. And if I stay too long I'll forget about it too.\\nTAYA: Chris--\\nCHRIS: We're at war and I'm headed to the mall. I don't belong here. I can't help anybody-\\nTAYA: --it's happening--\\nCHRIS: Oh shit--\\nTAYA: What're you doing!\\nCHRIS: I'm going back.\\n\\n\", 'answer': \"--oh my god, you're crazy! You're fucking crazy you know that?\", 'gold_tag': \"TAYA appears frustrated and scared by CHRIS's decision to go back to war\", 'last_speaker': 'TAYA'}\n",
      "Last word -> TAYA : \"--oh my god, you're crazy! You're fucking crazy you know that?\"\n",
      "prediction :   What?\n",
      "Real answer : --oh my god, you're crazy! You're fucking crazy you know that?\n",
      "Bert Score : {'precision': [0.8578996658325195], 'recall': [0.7707545161247253], 'f1': [0.8119955658912659], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2819.76384282969\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTAYA: Marc wrote that letter two weeks ago. Did he say any of that to you? Chris? I want to know what you thought of his letter...\\n\\n', 'answer': \"An AQI informant called in a tip. Biggles had just been shot. We were operating off emotion and-- we walked into an ambush. But that's not what killed him. That letter did. That letter killed Marc. He let go and he paid the price for it. (03.18.14) 92.\", 'gold_tag': \"CHRIS works in a high-risk, high-stress environment , CHRIS deals with informants and dangerous situations like ambushes , CHRIS operates on emotion , CHRIS has an opinion that emotional vulnerability can cost lives, as in Marc's case , CHRIS's temporal information\", 'last_speaker': 'CHRIS'}\n",
      "Last word -> CHRIS : \"An AQI informant called in a tip. Biggles had just been shot. We were operating off emotion and-- we walked into an ambush. But that's not what killed him. That letter did. That letter killed Marc. He let go and he paid the price for it. (03.18.14) 92.\"\n",
      "prediction :  I haven't talked to him since he left. I haven't seen him in three years.\n",
      "Real answer : An AQI informant called in a tip. Biggles had just been shot. We were operating off emotion and-- we walked into an ambush. But that's not what killed him. That letter did. That letter killed Marc. He let go and he paid the price for it. (03.18.14) 92.\n",
      "Bert Score : {'precision': [0.862851619720459], 'recall': [0.832056999206543], 'f1': [0.8471745252609253], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08823529411764706, 'rouge2': 0.0, 'rougeL': 0.058823529411764705, 'rougeLsum': 0.058823529411764705}\n",
      "bleu 1/2 : 0.014773754448311182 0.003419459704337659\n",
      "ppl : 9.868733138827716\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRIS: If something ever happened to me-- you'd meet someone else. You'd be alright.\\nTAYA: Do you want to die? Is that what it is?\\nCHRIS: No.\\nTAYA: Then tell me why do you do it. I want to understand.\\nCHRIS: I do it for you. To protect you.\\nTAYA: No you don't. I'm here. Your family is here. Your children have no father--\\nCHRIS: Without this, there's nothing.\\nTAYA: Bullshit. It's not about us anymore. You don't know when to quit. It's over- You did your part! We sacrificed enough. Let somebody else go--\\nCHRIS: I could never live with myself.\\nTAYA: You find a way! You have to. I need you to be human again. I need you here. If you leave again, we might not be here when you get back.\\n\\n\", 'answer': 'I know.', 'gold_tag': 'CHRIS is in a state of conflict about a potentially dangerous, upcoming deployment or mission', 'last_speaker': 'CHRIS'}\n",
      "Last word -> CHRIS : \"I know.\"\n",
      "prediction :  I can't.\n",
      "Real answer : I know.\n",
      "Bert Score : {'precision': [0.8995177745819092], 'recall': [0.9014896154403687], 'f1': [0.900502622127533], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4, 'rouge2': 0.0, 'rougeL': 0.4, 'rougeLsum': 0.4}\n",
      "bleu 1/2 : 0.5 0.223606797749979\n",
      "ppl : 127.82165926513017\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEVAN: Are you okay?\\n\\n', 'answer': \"There it is. Let's go.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'TOMMY'}\n",
      "Last word -> TOMMY : \"There it is. Let's go.\"\n",
      "prediction :  Yeah, I'm fine.\n",
      "Real answer : There it is. Let's go.\n",
      "Bert Score : {'precision': [0.8751794099807739], 'recall': [0.8889228105545044], 'f1': [0.8819975256919861], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 38.73067596202411\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEVAN: Crockett!!\\nTOMMY: Look what you made me do!\\nEVAN: What's wrong with you?! Kayleigh! Wake up!\\n\\n\", 'answer': \"Why don't you fucking kiss her, Prince Charming!\", 'gold_tag': 'TOMMY is aggressive', 'last_speaker': 'TOMMY'}\n",
      "Last word -> TOMMY : \"Why don't you fucking kiss her, Prince Charming!\"\n",
      "prediction :  What?\n",
      "Real answer : Why don't you fucking kiss her, Prince Charming!\n",
      "Bert Score : {'precision': [0.8439135551452637], 'recall': [0.7809869050979614], 'f1': [0.811231791973114], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOMMY: Listen to me good, Evan...\\n\\n', 'answer': \"I'll do whatever you want. You don't want me to ever see Kayleigh again, fine. Just let Crockett go. Besides, you kill him now and they'll stick you in juvy for sure. And I know you'd never leave your sister alone with your father. Oh fuck, Lenny, no!\", 'gold_tag': \"EVAN is willing to compromise and cares about people, expressing concern for Crockett and Lenny , EVAN has knowledge or understanding of his rights and the legal implications of Tommy's actions , EVAN knows about Tommy's family situation , EVAN and TOMMY share a troubling familiarity with TOMMY's home life\", 'last_speaker': 'EVAN'}\n",
      "Last word -> EVAN : \"I'll do whatever you want. You don't want me to ever see Kayleigh again, fine. Just let Crockett go. Besides, you kill him now and they'll stick you in juvy for sure. And I know you'd never leave your sister alone with your father. Oh fuck, Lenny, no!\"\n",
      "prediction :  Tommy, I'm not gonna be in the business.\n",
      "Real answer : I'll do whatever you want. You don't want me to ever see Kayleigh again, fine. Just let Crockett go. Besides, you kill him now and they'll stick you in juvy for sure. And I know you'd never leave your sister alone with your father. Oh fuck, Lenny, no!\n",
      "Bert Score : {'precision': [0.8668745756149292], 'recall': [0.8243718147277832], 'f1': [0.8450891375541687], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0655737704918033, 'rouge2': 0.0, 'rougeL': 0.0655737704918033, 'rougeLsum': 0.0655737704918033}\n",
      "bleu 1/2 : 0.0008422433748856836 0.00028473022872061614\n",
      "ppl : 30.409356406877286\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOMMY: You forgot to put the toaster on the edge.\\nEVAN: But you, Kayleigh and Lenny like toast. And that's really all that matters now.\\n\\n\", 'answer': \"I'll get you changed. Visiting hours are almost up.\", 'gold_tag': 'TOMMY indicates that visiting hours are almost up', 'last_speaker': 'TOMMY'}\n",
      "Last word -> TOMMY : \"I'll get you changed. Visiting hours are almost up.\"\n",
      "prediction :  How do you know they like toast?\n",
      "Real answer : I'll get you changed. Visiting hours are almost up.\n",
      "Bert Score : {'precision': [0.8332847356796265], 'recall': [0.836698591709137], 'f1': [0.8349881172180176], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.10735389901075512 0.03666833725656689\n",
      "ppl : 171.53638778702947\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSALIERI: Herr Mozart, what brings you here?\\nMOZART: Your Excellency, you requested some specimens of my work. Here they are. I don't have to tell you how much I need your help. I truly appreciate your looking at these. I have pressures on me - financial pressures. As you know, I'm a married man now.\\nSALIERI: So you are. How is your pretty wife?\\nMOZART: She is well. She is - well, actually, I'm about to become a father! She only told me last night. You are the first to know.\\nSALIERI: I'm flattered. And congratulations to you, of course.\\nMOZART: So you see, this post is very important to me right now.\\nSALIERI: Why didn't you come to me yesterday, Mozart? This is a most painful situation. Yesterday I could have helped you. Today, I can't.\\nMOZART: Why? Here is the music. It's here. I am submitting it humbly. Isn't that what you wanted?\\nSALIERI: I have just come from the palace. The post has been filled.\\nMOZART: Filled? That's impossible! They haven't even seen my work. I need this post. Please, can't you help me? Please!\\nSALIERI: My dear Mozart, there is no one in the world I would rather help, but now it is too late.\\nMOZART: Whom did they choose?\\nSALIERI: Herr Sommer.\\nMOZART: Sommer? Herr Sommer? But the man's a fool! He's a total mediocrity.\\nSALIERI: No, no, no: he has yet to achieve\\nMOZART: But I can't lose this post, I simply can't! Excellency, please. Let's go to the palace, and you can explain to the Emperor that Herr Sommer is an awful choice. He could actually do musical harm to the Princess!\\nSALIERI: An implausible idea. Between you and me, no one in the world could do musical harm to the Princess Elizabeth.\\nMOZART: Look, I must have pupils. Without pupils I can't manage.\\nSALIERI: You don't mean to tell me you are living in poverty?\\nMOZART: No, but I'm broke. I'm always broke. I don't know why.\\nSALIERI: It has been said, my friend, that you are inclined to live somewhat above your means.\\nMOZART: How can anyone say that? We have no cook, no maid. We have no footman. Nothing at all!\\nSALIERI: How is that possible? You give concerts, don't you? I hear they are quite successful.\\nMOZART: They're stupendously successful. You can't get a seat. The only problem is none will hire me. They all want to hear me play, but they won't let me teach their daughters. As if I was some kind of fiend. I'm not a fiend!\\nSALIERI: Of course not.\\nMOZART: Do you have a daughter?\\nSALIERI: I'm afraid not.\\nMOZART: Well, could you lend me some money till you have one? Then I'll teach her for free. That's a promise. Oh, I'm sorry. I'm being silly. Papa's right - I should put a padlock on my mouth. Seriously, is there any chance you could manage a loan? Only for six months, eight at most. After that I'll be the richest man in Vienna. I'll pay you back double. Anything. Name your terms. I'm not joking. I'm working on something that's going to explode like a bomb all over Europe!\\nSALIERI: Ah, how exciting! Tell me more.\\nMOZART: I'd better not. It's a bit of a secret.\\nSALIERI: Come, come, Mozart; I'm interested. Truly.\\nMOZART: Actually, it's a big secret. Oh, this is delicious! What is it?\\nSALIERI: Cream cheese mixed with granulated al Mascarpone.\\nMOZART: Ah. Italian?\\nSALIERI: Forgive me. We all have patriotic feelings of some kind.\\nMOZART: Two thousand, two hundred florins is all I need A hundred? Fifty?\\nSALIERI: What exactly are you working on?\\nMOZART: I can't say. Really\\n\\n\", 'answer': \"I don't think you should become known in Vienna as a debtor, Mozart. However, I know a very distinguished gentleman I could recommend to you. And he has a daughter. Will that do?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SALIERI'}\n",
      "Last word -> SALIERI : \"I don't think you should become known in Vienna as a debtor, Mozart. However, I know a very distinguished gentleman I could recommend to you. And he has a daughter. Will that do?\"\n",
      "prediction :  Then I can't help you.\n",
      "Real answer : I don't think you should become known in Vienna as a debtor, Mozart. However, I know a very distinguished gentleman I could recommend to you. And he has a daughter. Will that do?\n",
      "Bert Score : {'precision': [0.8865259885787964], 'recall': [0.835508406162262], 'f1': [0.8602613806724548], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15, 'rouge2': 0.0, 'rougeL': 0.15, 'rougeLsum': 0.15}\n",
      "bleu 1/2 : 0.001479145486593173 0.0003697863716482933\n",
      "ppl : 41.3908323636129\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOZART: Nine performances! Nine! That's all it's had - and withdrawn.\\nSALIERI: I know; it's outrageous. Still, if the public doesn't like one's work one has to accept the fact gracefully.\\nMOZART: But what is it they don't like?\\nSALIERI: Well, I can speak for the Emperor. You made too many demands on the royal ear. The poor man can't concentrate for more than an hour and you gave him four.\\nMOZART: What did you think of it yourself? Did you like it at all?\\nSALIERI: I think it's marvelous. Truly.\\nMOZART: It's the best opera yet written. I know it! Why didn't they come?\\nSALIERI: I think you overestimate our dear Viennese, my friend. Do you know you didn't even give them a good bang at the end of songs so they knew when to clap?\\nMOZART: I know, I know. Perhaps you should give me some lessons in that.\\nSALIERI: I wouldn't presume. All the same, if it wouldn't be imposing, I would like you to see my new piece. It would be a tremendous honour for me.\\nMOZART: Oh no, the honour would be all mine.\\nSALIERI: Grazie, mio caro, Wolfgang!\\n\\n\", 'answer': 'Grazie, a lei, Signor Antonio!', 'gold_tag': 'Everyday Language', 'last_speaker': 'MOZART'}\n",
      "Last word -> MOZART : \"Grazie, a lei, Signor Antonio!\"\n",
      "prediction :  The opera is not yet written, I'm afraid.\n",
      "Real answer : Grazie, a lei, Signor Antonio!\n",
      "Bert Score : {'precision': [0.8418365120887756], 'recall': [0.7906743288040161], 'f1': [0.8154537081718445], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 52.370989587243095\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOZART: What happened? Is it over?\\nSALIERI: I'm taking you home. You're not well.\\n\\n\", 'answer': 'No, no. I have to get back. I have -', 'gold_tag': 'MOZART has some health issues , MOZART has an immediate need or obligation to fulfill', 'last_speaker': 'MOZART'}\n",
      "Last word -> MOZART : \"No, no. I have to get back. I have -\"\n",
      "prediction :  I'm not well?\n",
      "Real answer : No, no. I have to get back. I have -\n",
      "Bert Score : {'precision': [0.8200862407684326], 'recall': [0.820656418800354], 'f1': [0.8203712105751038], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 195.61516258385637\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSALIERI: Thank you. Go.\\nMOZART: Papa! Papa!\\nSALIERI: Come now. Where is your wife?\\nMOZART: Not here! She's not well, either. She went to the Spa.\\nSALIERI: You mean she's not coming back?\\nMOZART: You're so good to me. Truly. Thank you.\\nSALIERI: No, please.\\nMOZART: I mean to come to my opera. You are the only colleague who did.\\nSALIERI: I would never miss anything that you had written. You must know that.\\nMOZART: This is only a vaudeville.\\nSALIERI: Oh no. It is a sublime piece. The grandest operone. I tell you, you are the greatest composer known to me.\\nMOZART: Do you mean that?\\nSALIERI: I do.\\nMOZART: I have bad fancies. I don't sleep well anymore. Then I drink too much, and think stupid things.\\nSALIERI: Are you ill?\\nMOZART: The doctor thinks I am. But -\\nSALIERI: What?\\nMOZART: I'm too young to be so sick.\\nSALIERI: Shall I answer it?\\nMOZART: No! No, it's him!\\nSALIERI: Who?\\nMOZART: The man. He's here.\\nSALIERI: What man?\\nMOZART: Tell him to go away. Tell him I'm still working on it. Don't let him in! Wait! Ask him if he'd give me some money now. Tell him if he would, that would help me finish it.\\nSALIERI: Finish what?\\n\\n\", 'answer': 'He knows. He knows!', 'gold_tag': 'Everyday Language', 'last_speaker': 'MOZART'}\n",
      "Last word -> MOZART : \"He knows. He knows!\"\n",
      "prediction :  My opera.\n",
      "Real answer : He knows. He knows!\n",
      "Bert Score : {'precision': [0.8965974450111389], 'recall': [0.866438627243042], 'f1': [0.881260097026825], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5316.3067763321715\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOZART: What happened?\\nSALIERI: He said to give you this. And if you finish the work by tomorrow night, he will pay you another hundred ducats.\\nMOZART: Another? But that's too soon! Tomorrow night? It's impossible! Did he say a hundred?\\nSALIERI: Yes. Can I - could I help you, in any way?\\nMOZART: Would you? Actually, you could.\\nSALIERI: My dear friend, it would be my greatest pleasure.\\nMOZART: But you'd have to swear not to tell a soul. I'm not allowed.\\nSALIERI: Of course.\\nMOZART: You know, it's all here in my head. It's just ready to be set down. But when I'm dizzy like this my eyes won't focus. I can't write.\\nSALIERI: Then, let us try together. I'd regard it as such an honour. Tell me, what is this work?\\n\\n\", 'answer': 'A Mass. A Mass for the Dead.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MOZART'}\n",
      "Last word -> MOZART : \"A Mass. A Mass for the Dead.\"\n",
      "prediction :  It is my Requiem Mass.\n",
      "Real answer : A Mass. A Mass for the Dead.\n",
      "Bert Score : {'precision': [0.8927963972091675], 'recall': [0.9178167581558228], 'f1': [0.9051337242126465], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.13406400920712788 0.04739878501170794\n",
      "ppl : 130.48356649148653\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOZART: Do you want to rest a bit?\\nSALIERI: Oh no. I'm not tired at all.\\nMOZART: We'll stop for just a moment. Then we'll do the Lacrimosa.\\nSALIERI: I can keep going, I assure you. Shall we try?\\nMOZART: Would you stay with me while I sleep a little?\\nSALIERI: I'm not leaving you.\\nMOZART: I am so ashamed.\\nSALIERI: What for?\\n\\n\", 'answer': 'I was foolish. I thought you did not care for my work - or me. Forgive me. Forgive me!', 'gold_tag': \"MOZART believes he has been foolish for assuming Salieri didn't care for his work or him\", 'last_speaker': 'MOZART'}\n",
      "Last word -> MOZART : \"I was foolish. I thought you did not care for my work - or me. Forgive me. Forgive me!\"\n",
      "prediction :  I am so ashamed.\n",
      "Real answer : I was foolish. I thought you did not care for my work - or me. Forgive me. Forgive me!\n",
      "Bert Score : {'precision': [0.8870391845703125], 'recall': [0.8558159470558167], 'f1': [0.8711479306221008], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0909090909090909, 'rouge2': 0.0, 'rougeL': 0.0909090909090909, 'rougeLsum': 0.0909090909090909}\n",
      "bleu 1/2 : 0.005879436464002277 0.0021468666511683054\n",
      "ppl : 129.49363447668603\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: I've decided it's impossible to properly say hello in this place\\nTOM: A jogger, huh?\\nANNIE: I don't jog, Mr. Booker. I run.\\nTOM: Lucky for you. The grizzlies around here only go for joggers.\\nANNIE: If I can survive rush hour, I figure I can handle grizzlies...\\nTOM: You sleeping all right in that house?\\nANNIE: I don't sleep all right anywhere. But the house is fine. Who's R.B.?\\nTOM: Sorry about that. I thought everything got cleared out. R.B. is my wife... ex-wife... Rachel. We used to live in that house together.\\nANNIE: I thought you lived in Chicago?\\nTOM: I thought you were an editor, not a reporter?\\nANNIE: I have a way with animals.\\nTOM: It's all right. He's young. Just hold out your hand a little lower so he can get the smell of you.\\nANNIE: Oh yes. I forgot. He's beautiful.\\nTOM: Why don't you ride anymore? Grace told me you used to ride when she was younger.\\nANNIE: She did? I don't know, really. No time mostly. I thought it was supposed to be spring. Are you shy, Mr. Booker?\\nTOM: Just polite. Well, maybe you'd like to try riding again, some time before you go home. Enjoy the day.\\nANNIE: You too. Shit.\\nTOM: Need a lift?\\n\\n\", 'answer': 'I can handle it!', 'gold_tag': 'Everyday Language', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"I can handle it!\"\n",
      "prediction :  No. I just have to get home before dark.\n",
      "Real answer : I can handle it!\n",
      "Bert Score : {'precision': [0.860897958278656], 'recall': [0.8529301285743713], 'f1': [0.8568955659866333], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0.11111111111111109 0.03726779962499649\n",
      "ppl : 82.7898165379205\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: Oh-oh. The answer's no.\\nTOM: You haven't heard the question yet. Truth is, you'd be doing me a favor. I got all these eager young colts need riding and poor old Rimrock here is feeling kind of left out...\\nANNIE: Poor thing.\\nTOM: He'd be grateful, he'd take real good care with you.\\nANNIE: Is this how you're going to make me pay my phone bill?\\n\\n\", 'answer': \"No, ma'am, I'm afraid that's extra.\", 'gold_tag': 'TOM may be the man in charge of a ranch or similar establishment', 'last_speaker': 'TOM'}\n",
      "Last word -> TOM : \"No, ma'am, I'm afraid that's extra.\"\n",
      "prediction :  I think you'd find it a very pleasant experience.\n",
      "Real answer : No, ma'am, I'm afraid that's extra.\n",
      "Bert Score : {'precision': [0.853553295135498], 'recall': [0.8194705843925476], 'f1': [0.8361647725105286], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473685, 'rouge2': 0.0, 'rougeL': 0.10526315789473685, 'rougeLsum': 0.10526315789473685}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 31.101479255446414\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOM: Relax our center... It's just sitting in a bucket.\\nANNIE: Yeah, it's been a while, but I... I remember the basic ideas...\\nTOM: OK. I'll stop talking then.\\nANNIE: Actually, I never rode Western. I'm sorry. Go ahead.\\nTOM: Well, he don't know that. Just sit the horse. Good... You have a nice seat.\\nANNIE: Thanks.\\nTOM: Feel good?\\nANNIE: Yeah.\\nTOM: You look all right. You want to pick it up a little?\\nANNIE: OK.\\n\\n\", 'answer': \"Watch your reins, he'll go with you, give him some room, let him do the work. Relax, don't grab him with your thighs, just so long as he can feel your body. You want to let it go some more?\", 'gold_tag': 'TOM guides ANNIE through horse riding', 'last_speaker': 'TOM'}\n",
      "Last word -> TOM : \"Watch your reins, he'll go with you, give him some room, let him do the work. Relax, don't grab him with your thighs, just so long as he can feel your body. You want to let it go some more?\"\n",
      "prediction :  You're doing well.\n",
      "Real answer : Watch your reins, he'll go with you, give him some room, let him do the work. Relax, don't grab him with your thighs, just so long as he can feel your body. You want to let it go some more?\n",
      "Bert Score : {'precision': [0.8633896708488464], 'recall': [0.8144040703773499], 'f1': [0.8381817936897278], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.04347826086956521, 'rouge2': 0.0, 'rougeL': 0.04347826086956521, 'rougeLsum': 0.04347826086956521}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 71.40311824494417\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: It's a whole other world you have going on here. It just goes along, doing what it has to. And you're a part of it, you just wake up and, and there you are... And everything that seems like life or death some place else -- doesn't affect any of this one bit.\\nTOM: Lift your leg.\\nANNIE: How long did you live here with your wife?\\nTOM: Five years. My son was born here.\\nANNIE: Son?\\nTOM: Yeah. I haven't seen him in a while. He used to come to the ranch over summers, but then he started having friends and was going off to college, so... Good boy.\\nANNIE: How did you meet her?\\nTOM: College. In Illinois. She was playing the cello. I hadn't heard cello music growing up. She had the reddest hair, the bluest eyes. When she played, it was... She was the most beautiful thing I'd ever seen.\\nANNIE: Why didn't it work out?\\nTOM: She was never really happy here. She did the best she could. Grace told me you have a country house in Connecticut. Sounds like a beautiful place.\\nANNIE: It is. It's lovely.\\nTOM: Ever think of moving there full time?\\nANNIE: We did at one point. When we thought we'd have more children. And we after tried. We tried everything, but... wasn't meant to be.\\nTOM: I hear that! See, I knew she was never going to be a ranchest, but I wanted to try -- I thought maybe she'd give music lessons to the kids in town or at the school, maybe even recitals. My son would grow up here. Maybe have one or two more. I'd teach 'em what I could. They'd play with my brother's kids. All grow up together. And even if they all decided to go out into the world, they'd always know where home was -- cause we'd keep it for 'em...\\nANNIE: That's very important to you, isn't it? Home.\\nTOM: Yeah, I think it is. And I don't mean everybody's got to be married, have kids -- It's more like, knowing where you're from, where you belong, what feeds you, where you can go no matter what happens... Knowing what you're supposed to be doing while you're here.\\nANNIE: How did you find out all that?\\n\\n\", 'answer': 'I got lost.', 'gold_tag': 'Everyday Language', 'last_speaker': 'TOM'}\n",
      "Last word -> TOM : \"I got lost.\"\n",
      "prediction :  I just did.\n",
      "Real answer : I got lost.\n",
      "Bert Score : {'precision': [0.9018929600715637], 'recall': [0.9126236438751221], 'f1': [0.9072265625], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.0, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0.3333333333333333 0.12909944487358058\n",
      "ppl : 546.7962215776957\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOM: Everything under control?\\nANNIE: Not really. I'd forgotten how long it's been since I've done this. And I couldn't get any Parmesan cheese.\\nTOM: Just make yourself comfortable.\\nANNIE: I am comfortable.\\nTOM: Ha, ha... all right, well, uh I guess you can bring out the pasta.\\nANNIE: You missed a button.\\nTOM: Huh?\\n\\n\", 'answer': \"Thank you. Oh, good, Grace, would you bring in the bread... I'll get the salad and then we're all set.\", 'gold_tag': 'ANNIE is capable of organizing a meal', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"Thank you. Oh, good, Grace, would you bring in the bread... I'll get the salad and then we're all set.\"\n",
      "prediction :  You.\n",
      "Real answer : Thank you. Oh, good, Grace, would you bring in the bread... I'll get the salad and then we're all set.\n",
      "Bert Score : {'precision': [0.9143614768981934], 'recall': [0.8041442036628723], 'f1': [0.8557184338569641], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913045, 'rouge2': 0.0, 'rougeL': 0.08695652173913045, 'rougeLsum': 0.08695652173913045}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3485.528394424211\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOM: I won't apologize for this. And I won't hide it. Not for anybody.\\n\\n\", 'answer': \"I won't ask you to.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"I won't ask you to.\"\n",
      "prediction :  What do you mean?\n",
      "Real answer : I won't ask you to.\n",
      "Bert Score : {'precision': [0.8133565187454224], 'recall': [0.8309184312820435], 'f1': [0.8220437169075012], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0.19470019576785122 0.07109445944848267\n",
      "ppl : 79.14500084705968\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: Oh, God, what are we going to do? I'm supposed to --\\n\\n\", 'answer': \"Ssshhh... Stand still, Annie. Takes what we've got, just for now. Can you do that?\", 'gold_tag': 'TOM is calm and comforting , TOM is trying to reassure ANNIE in the middle of a crisis', 'last_speaker': 'TOM'}\n",
      "Last word -> TOM : \"Ssshhh... Stand still, Annie. Takes what we've got, just for now. Can you do that?\"\n",
      "prediction :  I know. I know. I'll take care of it.\n",
      "Real answer : Ssshhh... Stand still, Annie. Takes what we've got, just for now. Can you do that?\n",
      "Bert Score : {'precision': [0.8685486912727356], 'recall': [0.8324398398399353], 'f1': [0.8501110076904297], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 19.600305795440896\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: Show me again.\\nTOM: Annie!\\n\\n', 'answer': 'One more time.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"One more time.\"\n",
      "prediction :  What?\n",
      "Real answer : One more time.\n",
      "Bert Score : {'precision': [0.873242974281311], 'recall': [0.8655351996421814], 'f1': [0.8693720698356628], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOM: I figured, whenever you decided to go, you'd be all set.\\nANNIE: How thoughtful of you. And what if I decide not to go? Leave me alone!\\nTOM: Annie, please...\\nANNIE: NO!... NO!... YOU DON'T DECIDE THIS!... NO!...\\nTOM: I don't know any other way, Annie.\\nANNIE: Why?\\nTOM: You think this is easy for me!? It's just happened this way sometimes. I can't explain it. But I look at you and see Grace and I see Robert, and no matter what you decide about him, I just know this is right. Your life isn't here and you know it.\\nANNIE: Then what have we been doing? I mean what was the point?\\nTOM: The point was to love each other.\\nANNIE: Why?\\n\\n\", 'answer': \"Because we had to... And I'll never stop loving you, Annie. Here. Where my life is. Annie...\", 'gold_tag': 'TOM is in a romantic relationship with ANNIE , TOM cares for ANNIE deeply and is willing to respect her decisions even when they cause him distress', 'last_speaker': 'TOM'}\n",
      "Last word -> TOM : \"Because we had to... And I'll never stop loving you, Annie. Here. Where my life is. Annie...\"\n",
      "prediction :  Because we can.\n",
      "Real answer : Because we had to... And I'll never stop loving you, Annie. Here. Where my life is. Annie...\n",
      "Bert Score : {'precision': [0.9184321165084839], 'recall': [0.8395628333091736], 'f1': [0.877228319644928], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1904761904761905, 'rouge2': 0.10526315789473684, 'rougeL': 0.1904761904761905, 'rougeLsum': 0.1904761904761905}\n",
      "bleu 1/2 : 0.0062690417009968035 0.005429149370447241\n",
      "ppl : 349.1643260816206\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOM: Annie?\\nANNIE: Can we go for one more ride?\\n\\n', 'answer': \"Sure. I'll saddle them up.\", 'gold_tag': 'TOM is capable of saddling horses , TOM is experienced with horse riding', 'last_speaker': 'TOM'}\n",
      "Last word -> TOM : \"Sure. I'll saddle them up.\"\n",
      "prediction :  Sure.\n",
      "Real answer : Sure. I'll saddle them up.\n",
      "Bert Score : {'precision': [0.9690805673599243], 'recall': [0.8888925909996033], 'f1': [0.927256166934967], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2857142857142857, 'rouge2': 0.0, 'rougeL': 0.2857142857142857, 'rougeLsum': 0.2857142857142857}\n",
      "bleu 1/2 : 0.01831563888873418 0.00579191356895553\n",
      "ppl : 940.7736565945374\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOM: What?\\nANNIE: I mean, why did you get\\nTOM: I got married because Betsy said we had to break up or get\\nANNIE: But when you met her, did you believe she was the only person for you? That in some mystical, I don't even know him. But say something, but\\nTOM: Yes, I did.\\n\\n\", 'answer': 'Thank you, Tom. I feel so much', 'gold_tag': 'ANNIE shows sensitivity', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"Thank you, Tom. I feel so much\"\n",
      "prediction :  And now you're saying you don't believe that.\n",
      "Real answer : Thank you, Tom. I feel so much\n",
      "Bert Score : {'precision': [0.8589345216751099], 'recall': [0.853996992111206], 'f1': [0.8564586043357849], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 25.40160848225856\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBENNY: Get your glove, c'mon.\\nSCOTTY: What's the big deal?\\n\\n\", 'answer': 'Nightgame!', 'gold_tag': 'Everyday Language', 'last_speaker': 'BENNY'}\n",
      "Last word -> BENNY : \"Nightgame!\"\n",
      "prediction :  Come on.\n",
      "Real answer : Nightgame!\n",
      "Bert Score : {'precision': [0.9065366387367249], 'recall': [0.8456013798713684], 'f1': [0.8750094771385193], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1684.9433606999041\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSCOTTY: Benny - wait. It's okay, it was my fault. I'll just take whatever I get. You don't have to do this.\\n\\n\", 'answer': \"Yeah I do, Smalls. I have to. ...Follow your heart, kid, and you'll never go wrong.\", 'gold_tag': \"Benny shows responsibility and leadership , Benny understands the importance of following one's heart , Benny inculcates a sense of wisdom and maturity\", 'last_speaker': 'BENNY'}\n",
      "Last word -> BENNY : \"Yeah I do, Smalls. I have to. ...Follow your heart, kid, and you'll never go wrong.\"\n",
      "prediction :  You're right, I don't have to do it. I just have to do it.\n",
      "Real answer : Yeah I do, Smalls. I have to. ...Follow your heart, kid, and you'll never go wrong.\n",
      "Bert Score : {'precision': [0.8610564470291138], 'recall': [0.8531042337417603], 'f1': [0.8570619225502014], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3636363636363636, 'rouge2': 0.06451612903225808, 'rougeL': 0.30303030303030304, 'rougeLsum': 0.30303030303030304}\n",
      "bleu 1/2 : 0.18575954994646748 0.03519515356891461\n",
      "ppl : 9.05857432248238\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBENNY: OOOOH SSSSHIT!\\n\\n', 'answer': \"What're we waitin' for?! Let's go after 'em!\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SCOTTY'}\n",
      "Last word -> SCOTTY : \"What're we waitin' for?! Let's go after 'em!\"\n",
      "prediction :  I'M SORRY!\n",
      "Real answer : What're we waitin' for?! Let's go after 'em!\n",
      "Bert Score : {'precision': [0.8012507557868958], 'recall': [0.8071691393852234], 'f1': [0.8041990995407104], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 48.56916816771838\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSANTEN: What the hell's going on?\\nBOWMAN: Single event upsets. All over the board. Latch up. Free flow... We're gonna lose chips. Shut it down!\\nSANTEN: Shut it down?\\n\\n\", 'answer': \"Now! Everything! SEP, some kind of massive solar flare. Santen's shutting off every system he can get his hands... Proton flux. Multiple event upsets...\", 'gold_tag': 'BOWMAN indicates an immediate crisis , SANTEN is also involved in this immediate crisis', 'last_speaker': 'BOWMAN'}\n",
      "Last word -> BOWMAN : \"Now! Everything! SEP, some kind of massive solar flare. Santen's shutting off every system he can get his hands... Proton flux. Multiple event upsets...\"\n",
      "prediction :  No, no, no. We can't shut it down.\n",
      "Real answer : Now! Everything! SEP, some kind of massive solar flare. Santen's shutting off every system he can get his hands... Proton flux. Multiple event upsets...\n",
      "Bert Score : {'precision': [0.8558422327041626], 'recall': [0.8210756778717041], 'f1': [0.8380985260009766], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.058823529411764705, 'rouge2': 0.0, 'rougeL': 0.058823529411764705, 'rougeLsum': 0.058823529411764705}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 28.81461601979304\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOWMAN: Radiation alert. Safe area. Go. You, too.\\nSANTEN: You need me here on the flight deck.\\n\\n', 'answer': 'I want one of us in charge back there.', 'gold_tag': 'BOWMAN has a position of authority , SANTEN is a subordinate to BOWMAN', 'last_speaker': 'BOWMAN'}\n",
      "Last word -> BOWMAN : \"I want one of us in charge back there.\"\n",
      "prediction :  I can't take that chance. You and the others can make it. I'm staying here.\n",
      "Real answer : I want one of us in charge back there.\n",
      "Bert Score : {'precision': [0.8661147356033325], 'recall': [0.8631488084793091], 'f1': [0.8646292090415955], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307691, 'rouge2': 0.0, 'rougeL': 0.07692307692307691, 'rougeLsum': 0.07692307692307691}\n",
      "bleu 1/2 : 0.06666666666666667 0.02182178902359924\n",
      "ppl : 19.382303819646488\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSANTEN: Copy. We're okay, but the ship's hit bad.\\n\\n\", 'answer': \"... We're dead in the water... I can't run damage assessment. She's together now, but she might come apart at any moment. Change of plans. We're launching now. Suit up.\", 'gold_tag': \"BOWMAN is in charge and demonstrates leadership and decision-making skills , BOWMAN has knowledge in assessing damage and the state of the ship  , BOWMAN's occupation is related to spaceship operations , BOWMAN indicates a change of plans and an immediate launch, implying a situation that requires swift action and departure\", 'last_speaker': 'BOWMAN'}\n",
      "Last word -> BOWMAN : \"... We're dead in the water... I can't run damage assessment. She's together now, but she might come apart at any moment. Change of plans. We're launching now. Suit up.\"\n",
      "prediction :  How bad?\n",
      "Real answer : ... We're dead in the water... I can't run damage assessment. She's together now, but she might come apart at any moment. Change of plans. We're launching now. Suit up.\n",
      "Bert Score : {'precision': [0.8183378577232361], 'recall': [0.8043162226676941], 'f1': [0.8112664818763733], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2923.794536231302\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOWMAN: You're talking to a class of second-graders from Iowa at 1430.\\nSANTEN: It's your turn to do the kiddies.\\nBOWMAN: Don't even try. You're up, and you know it. Besides, I outrank you. I could order you to do it.\\nSANTEN: ... Just 'cause they promote faster in the Navy...\\nBOWMAN: You gotta promote faster when you have the best people... 1430. With a smile on your face.\\nSANTEN: Pulling rank on me for the shower, too?\\n\\n\", 'answer': 'Not rank, gender. Ladies first.', 'gold_tag': 'BOWMAN is assertive and uses her authority when needed', 'last_speaker': 'BOWMAN'}\n",
      "Last word -> BOWMAN : \"Not rank, gender. Ladies first.\"\n",
      "prediction :  You gotta promote faster when you have the best people... 1430. With a smile on your face.\n",
      "Real answer : Not rank, gender. Ladies first.\n",
      "Bert Score : {'precision': [0.8421290516853333], 'recall': [0.8565719127655029], 'f1': [0.8492891192436218], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 88.37948407070179\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMcCROSKEY: Grab hold of yourself! You've got to talk them down. You're the only chance they've got!\\n\\n\", 'answer': 'All right, Striker, now you listen to me and you listen close. Flying is no different than riding a bicycle...it just happens to be a lot harder to put baseball cards in the spokes. Now, if you just follow my instructions...', 'gold_tag': 'KRAMER has knowledge and experience in flying , KRAMER possibly has a background as a pilot', 'last_speaker': 'KRAMER'}\n",
      "Last word -> KRAMER : \"All right, Striker, now you listen to me and you listen close. Flying is no different than riding a bicycle...it just happens to be a lot harder to put baseball cards in the spokes. Now, if you just follow my instructions...\"\n",
      "prediction :  I can't do it, Chief. I'm just a beat cop. I don't know how to talk these people down.\n",
      "Real answer : All right, Striker, now you listen to me and you listen close. Flying is no different than riding a bicycle...it just happens to be a lot harder to put baseball cards in the spokes. Now, if you just follow my instructions...\n",
      "Bert Score : {'precision': [0.8616636991500854], 'recall': [0.8242561221122742], 'f1': [0.8425449728965759], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.049602133734270686 0.009304226613118026\n",
      "ppl : 10.656308328499183\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKRAMER: I don't understand it. He should have been in range ten minutes ago.\\n\\n\", 'answer': 'Gunderson, check the radar range. Anything yet?', 'gold_tag': 'McCROSKEY is in charge , McCROSKEY is giving orders to check the radar range , McCROSKEY holds a position of authority in the same field', 'last_speaker': 'McCROSKEY'}\n",
      "Last word -> McCROSKEY : \"Gunderson, check the radar range. Anything yet?\"\n",
      "prediction :  That's right. We've been trying to reach him for hours.\n",
      "Real answer : Gunderson, check the radar range. Anything yet?\n",
      "Bert Score : {'precision': [0.8670004606246948], 'recall': [0.8510872721672058], 'f1': [0.8589701652526855], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.062052009553303\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMcCROSKEY: Two more minutes! They could be miles off course.\\n\\n', 'answer': \"That's impossible. They're on instruments!\", 'gold_tag': 'KRAMER has knowledge of aircraft navigation systems', 'last_speaker': 'KRAMER'}\n",
      "Last word -> KRAMER : \"That's impossible. They're on instruments!\"\n",
      "prediction :  What's the problem?\n",
      "Real answer : That's impossible. They're on instruments!\n",
      "Bert Score : {'precision': [0.8785830736160278], 'recall': [0.8602160215377808], 'f1': [0.86930251121521], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 62.66045822959744\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMcCROSKEY: Rex, I've decided that the best thing to do is to foam the runway -- let him do a wheels-up landing. It'd be a lot simpler.\\nKRAMER: No, the risk of fire is too great. If she starts burning, you write off all those people who can't get out of there on their own power.\\nMcCROSKEY: Well that's better than writing them all off? Are you going to play God with a hundred and 38 lives?\\nKRAMER: No. A belly landing isn't all that simple. It takes a good pilot to keep from smearin' himself all over the runway.\\nMcCROSKEY: If Striker has the guts to try this, he deserves the best shot we can give him. We've gotta foam that runway.\\nKRAMER: His only shot's with the wheels down. I've seen foam tear a man's guts out.\\nMcCROSKEY: And if Striker goes to pieces?\\n\\n\", 'answer': \"That's a risk we'll just have to take.\", 'gold_tag': 'KRAMER is a risk-averse person who prioritizes safety above all', 'last_speaker': 'KRAMER'}\n",
      "Last word -> KRAMER : \"That's a risk we'll just have to take.\"\n",
      "prediction :  He's got to make it.\n",
      "Real answer : That's a risk we'll just have to take.\n",
      "Bert Score : {'precision': [0.8805660009384155], 'recall': [0.866569995880127], 'f1': [0.8735119104385376], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0.10976232721880529 0.03880684294761699\n",
      "ppl : 88.6070939615461\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMcCROSKEY: Ya know, this would be a tough landing for anyone to make. Maybe, if we hold them off for a bit we'll get a break in the weather.\\n\\n\", 'answer': \"All right, but let's wait until they reach the control area.\", 'gold_tag': 'KRAMER has a decision-making role in the conversation', 'last_speaker': 'KRAMER'}\n",
      "Last word -> KRAMER : \"All right, but let's wait until they reach the control area.\"\n",
      "prediction :  You think?\n",
      "Real answer : All right, but let's wait until they reach the control area.\n",
      "Bert Score : {'precision': [0.7845942974090576], 'recall': [0.8208458423614502], 'f1': [0.8023108243942261], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1007.0519941523104\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKRAMER: Steve, I want every light you can get poured on that field.\\n\\n', 'answer': \"It's being done right now.\", 'gold_tag': \"McCROSKEY is carrying out KRAMER's order to illuminate the field\", 'last_speaker': 'McCROSKEY'}\n",
      "Last word -> McCROSKEY : \"It's being done right now.\"\n",
      "prediction :  Alright, Kramer, but you know what?\n",
      "Real answer : It's being done right now.\n",
      "Bert Score : {'precision': [0.8210340738296509], 'recall': [0.847124457359314], 'f1': [0.8338751792907715], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 45.743994371785234\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMcCROSKEY: It sure is quiet out there.\\nKRAMER: Yeah -- too quiet.\\n\\n', 'answer': 'Looks like I picked the wrong week to quit sniffing glue.', 'gold_tag': 'McCROSKEY recently quit sniffing glue', 'last_speaker': 'McCROSKEY'}\n",
      "Last word -> McCROSKEY : \"Looks like I picked the wrong week to quit sniffing glue.\"\n",
      "prediction :  I'm telling you, Kramer, it's too quiet.\n",
      "Real answer : Looks like I picked the wrong week to quit sniffing glue.\n",
      "Bert Score : {'precision': [0.8531047105789185], 'recall': [0.8642942905426025], 'f1': [0.8586630821228027], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09999999999999999, 'rouge2': 0.0, 'rougeL': 0.09999999999999999, 'rougeLsum': 0.09999999999999999}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.215103176496093\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKRAMER: Bring it down! Easy!\\n\\n', 'answer': \"Look at all those buttons! Oh that's beautiful! Just beautiful!\", 'gold_tag': 'McCROSKEY shows interest and admiration for complex machinery or technology , McCROSKEY is fascinated with the buttons', 'last_speaker': 'McCROSKEY'}\n",
      "Last word -> McCROSKEY : \"Look at all those buttons! Oh that's beautiful! Just beautiful!\"\n",
      "prediction :  I'm sorry.\n",
      "Real answer : Look at all those buttons! Oh that's beautiful! Just beautiful!\n",
      "Bert Score : {'precision': [0.8661198019981384], 'recall': [0.8213446140289307], 'f1': [0.8431380987167358], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 70.196163546962\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKRAMER: Remember your brakes and switches! Get ready to flare it out! You're coming in too fast! Watch your speed!\\nMcCROSKEY: He's coming right at us!\\n\\n\", 'answer': \"You're coming in too hot! Put down full flaps! Watch your nose!\", 'gold_tag': 'KRAMER is knowledgeable about flying or landing a plane', 'last_speaker': 'KRAMER'}\n",
      "Last word -> KRAMER : \"You're coming in too hot! Put down full flaps! Watch your nose!\"\n",
      "prediction :  He's going to hit us!\n",
      "Real answer : You're coming in too hot! Put down full flaps! Watch your nose!\n",
      "Bert Score : {'precision': [0.882591187953949], 'recall': [0.8471323251724243], 'f1': [0.8644983768463135], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 73.68357356818517\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICKY: ...you big fuckin' hick, you. Come here. Come here. Get him up. Come here.\\n\\n\", 'answer': 'Get up.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MARINO'}\n",
      "Last word -> MARINO : \"Get up.\"\n",
      "prediction :  I'm gonna take a look.\n",
      "Real answer : Get up.\n",
      "Bert Score : {'precision': [0.8730896711349487], 'recall': [0.9051066040992737], 'f1': [0.888809859752655], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 40.51896220834336\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICKY: Come here, come here.\\nMARINO: Get up.\\n\\n', 'answer': 'You go over there right now and you apologize. You better hope he lets you back in.', 'gold_tag': 'NICKY is in a position of power , NICKY is concerned about a present situation where someone needs to be apologized to immediately', 'last_speaker': 'NICKY'}\n",
      "Last word -> NICKY : \"You go over there right now and you apologize. You better hope he lets you back in.\"\n",
      "prediction :  No.\n",
      "Real answer : You go over there right now and you apologize. You better hope he lets you back in.\n",
      "Bert Score : {'precision': [0.9148980379104614], 'recall': [0.8234127759933472], 'f1': [0.866748034954071], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1275.3241709894667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICKY: Be careful. Hey, come on. Get inside. Can you fuckin' believe that? Look at this motherfucker. I fucked up, Frankie. I fucked up good this time. Should have never started with this fuckin' broad.\\nMARINO: Take it easy. What could you do? I mean, she threw herself at you, right?\\n\\n\", 'answer': \"I'm in a bad fuckin' spot here. You know that? Bad fuckin' spot.\", 'gold_tag': \"NICKY is currently in a 'bad spot' , NICKY is currently in a problematic situation, caused by a recent event involving a woman\", 'last_speaker': 'NICKY'}\n",
      "Last word -> NICKY : \"I'm in a bad fuckin' spot here. You know that? Bad fuckin' spot.\"\n",
      "prediction :  I was in control.\n",
      "Real answer : I'm in a bad fuckin' spot here. You know that? Bad fuckin' spot.\n",
      "Bert Score : {'precision': [0.9025989770889282], 'recall': [0.8346259593963623], 'f1': [0.8672826886177063], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.22222222222222224, 'rougeLsum': 0.22222222222222224}\n",
      "bleu 1/2 : 0.026349806140466083 0.009621588806014277\n",
      "ppl : 255.7434187014836\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICKY: Dominick! Oh, Dominick. Oh, Dom. Frankie. Frankie, leave the kid alone. He's still breathin'. He's still breathin'. Leave him alone. Frankie.\\nMARINO: All right. Strip him.\\n\\n\", 'answer': \"No balls, you got no fuckin' balls. Oh, Dominick. Oh, Dom. Dominick. Dominick. Dominick.\", 'gold_tag': 'NICKY is aggressive', 'last_speaker': 'NICKY'}\n",
      "Last word -> NICKY : \"No balls, you got no fuckin' balls. Oh, Dominick. Oh, Dom. Dominick. Dominick. Dominick.\"\n",
      "prediction :  I'm tellin' ya, you're gonna wanna leave him alone. He's still breathin'.\n",
      "Real answer : No balls, you got no fuckin' balls. Oh, Dominick. Oh, Dom. Dominick. Dominick. Dominick.\n",
      "Bert Score : {'precision': [0.8294185996055603], 'recall': [0.8561010360717773], 'f1': [0.8425486087799072], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0689655172413793, 'rouge2': 0.0, 'rougeL': 0.0689655172413793, 'rougeLsum': 0.0689655172413793}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.397041082386272\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAULSEN: Well, look, there isn't a ton of information here, but from what there is, I'd say that these two people here -- what are their names? Shanna and Ashley?\\nERIN: Right, I guess those are the kids --\\nPAULSEN: They've both got some immune system problem. Can't say what from, whether it's viral or genetic or what, but something's wrong. And these guys -- Donna and Peter --\\nERIN: Their parents, I'm pretty sure.\\n\\n\", 'answer': \"Well, from what this stuff says, I'd say they both have some form of cancer.\", 'gold_tag': 'PAULSEN is likely working in a field where medical knowledge is required', 'last_speaker': 'PAULSEN'}\n",
      "Last word -> PAULSEN : \"Well, from what this stuff says, I'd say they both have some form of cancer.\"\n",
      "prediction :  -- they're both dead.\n",
      "Real answer : Well, from what this stuff says, I'd say they both have some form of cancer.\n",
      "Bert Score : {'precision': [0.9128229022026062], 'recall': [0.8437799215316772], 'f1': [0.8769446015357971], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0.015981965301676893 0.005835788605995528\n",
      "ppl : 160.79942113077902\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: ... and when I realized our area's just as bad as Hinkley, I thought maybe my neighbors are all sick too. So I went and asked.\\nPAULSEN: You did?\\nERIN: Uh-huh. Spent the last few days knocking on doors. And you know what? They're not. I mean, they got problems, but none of this cancer stuff. And their pets are fine. So I don't know -- I just can't shake the feeling that it wasn't no multivitamin they put in the water.\\n\\n\", 'answer': \"Well, if you're talking about contamination, you're getting out of my area of expertise. Let me give you the name of a toxicologist friend of mine over at USC.\", 'gold_tag': 'Paulsen is outside his comfort zone regarding contamination and toxicology matters , Paulsen has connections, as evidenced by his suggestion to refer Erin to a toxicologist friend at USC', 'last_speaker': 'PAULSEN'}\n",
      "Last word -> PAULSEN : \"Well, if you're talking about contamination, you're getting out of my area of expertise. Let me give you the name of a toxicologist friend of mine over at USC.\"\n",
      "prediction :  I see.\n",
      "Real answer : Well, if you're talking about contamination, you're getting out of my area of expertise. Let me give you the name of a toxicologist friend of mine over at USC.\n",
      "Bert Score : {'precision': [0.8608380556106567], 'recall': [0.8259588479995728], 'f1': [0.8430378437042236], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 676.559384365141\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAULSEN: I gotta say, Erin -- first time I saw you, I did not peg you as the kind to go off and conduct her own epidemiological study.\\n\\n', 'answer': \"Don't go telling anyone. It'll ruin my reputation.\", 'gold_tag': 'ERIN values her reputation', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Don't go telling anyone. It'll ruin my reputation.\"\n",
      "prediction :  I didn't go off and do it, Paulsen. I was just trying to help out.\n",
      "Real answer : Don't go telling anyone. It'll ruin my reputation.\n",
      "Bert Score : {'precision': [0.8663969039916992], 'recall': [0.8898927569389343], 'f1': [0.8779876232147217], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23076923076923075, 'rouge2': 0.08333333333333334, 'rougeL': 0.23076923076923075, 'rougeLsum': 0.23076923076923075}\n",
      "bleu 1/2 : 0.06666666666666667 0.02182178902359924\n",
      "ppl : 36.221894048285144\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIRECTOR: What can I do for you, Mr. Welles?\\nWELLES: Call me Tom.\\nDIRECTOR: Alright, Tom.\\nWELLES: What I'd like, very simply, is access to your archive. And, now I understand this isn't something you normally do for private citizens...\\nDIRECTOR: There are reasons for the way we do things here.\\nWELLES: Absolutely. Of course I'll abide by whatever decision you make, but I'd appreciate if you'll hear me out... Few days ago, I was contacted by a couple living in Philadelphia, a doctor and his wife. What happened was they picked up a young girl hitchhiking off 81, which heads into Philadelphia, started up a conversation with this girl, she looked homeless, seemed about eighteen maybe. They convinced her to let them buy her a meal in the city. Nice kid, mature, didn't have much to say, but they got a sense she's a runaway, so all through dinner the doctor's working on her, trying to convince her that at the very least she should pick up a telephone. Not surprisingly, she ate her food, excused herself... That's the last they saw her. The reason they came to me for help, the reason I'm coming to you, is we had a friend of mine in the department They want to see if I can I.D. this girl, somehow pass along a message to let the parents know the kid's alive, doing alright.\\nDIRECTOR: Why not go to the N.C.I.C. or N.C.M.E.C.?\\nWELLES: I figured you share information.\\nDIRECTOR: We do.\\nWELLES: For whatever reasons I thought you might be more receptive.\\nDIRECTOR: Why don't they come to me?\\nWELLES: This doctor and wife, they're nice people, but they don't want to get too involved. They're not trying to have the parents come looking for the girl either. You and I both know sometimes, not often, but sometimes there's real reasons why a kid'll run. Molestation, whatever. Besides that, the girl's probably eighteen, so she's legal.\\nDIRECTOR: I'm not so sure about this.\\nWELLES: They're putting themselves in place of this kid's parents and thinking they'd want to hear their girl's okay, even if that's all they hear.\\nDIRECTOR: I can give you my card, if your clients want to call me...\\nWELLES: They were pretty clear they didn't want this coming back on them.\\nDIRECTOR: Well, that's all I can do. Sorry.\\n\\n\", 'answer': \"Who knows... maybe she's already given her parents a call, right?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'WELLES'}\n",
      "Last word -> WELLES : \"Who knows... maybe she's already given her parents a call, right?\"\n",
      "prediction :  That's okay. I understand.\n",
      "Real answer : Who knows... maybe she's already given her parents a call, right?\n",
      "Bert Score : {'precision': [0.8606091141700745], 'recall': [0.824721097946167], 'f1': [0.8422830700874329], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 36.9688164458796\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWELLES: Fuck.\\n\\n', 'answer': \"Excuse me... Tom, hold on... Listen, maybe I can help after all. Why don't you come on back in... we'll see what we can do.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'DIRECTOR'}\n",
      "Last word -> DIRECTOR : \"Excuse me... Tom, hold on... Listen, maybe I can help after all. Why don't you come on back in... we'll see what we can do.\"\n",
      "prediction :  What?\n",
      "Real answer : Excuse me... Tom, hold on... Listen, maybe I can help after all. Why don't you come on back in... we'll see what we can do.\n",
      "Bert Score : {'precision': [0.8259222507476807], 'recall': [0.7725418210029602], 'f1': [0.7983407974243164], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07142857142857142, 'rouge2': 0.0, 'rougeL': 0.07142857142857142, 'rougeLsum': 0.07142857142857142}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIRECTOR: This is it. It's not much. (points at computers) We've got less than five percent on computer and we lose that funding in December. I'll have someone show it to you anyway. Other than that, I'm afraid it's the wet thumb method. Files are mostly by state and year of disappearance. We try to keep the children and adults separate. No eating or smoking in here, but\\nWELLES: Any good?\\nDIRECTOR: It's horrible, but it'll be your best friend after a few days. I hope you realize what kind of long shot you're chasing after.\\nWELLES: You're gonna be seeing a lot of me. You're sure you don't mind?\\n\\n\", 'answer': \"It's good what you're doing.\", 'gold_tag': 'WELLES indicates a strong commitment to his cause', 'last_speaker': 'DIRECTOR'}\n",
      "Last word -> DIRECTOR : \"It's good what you're doing.\"\n",
      "prediction :  No.\n",
      "Real answer : It's good what you're doing.\n",
      "Bert Score : {'precision': [0.9257372617721558], 'recall': [0.8365143537521362], 'f1': [0.8788670897483826], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1275.3241709894667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTARCK: The antennae array\\'s completely fried, we\\'ve got no radio, no laser, no highgain... No one\\'s going to be coming to help us.\\nMILLER: How much oh-two do we have?\\nSTARCK: Oxygen is not the problem.\\nMILLER: Carbon dioxide?\\nSTARCK: It\\'s building up with every breath we take. And the CO2 filters on the Event Horizon are shot.\\nMILLER: We can take the filters from the Clark...\\nSTARCK: I thought of that, with the filters from the Clark, we\\'ve got enough breathable air for twenty hours. After that, we\\'d better be on our way home.\\nMILLER: What about the life readings you picked up?\\nSTARCK: The Event Horizon sensors show the same thing: \"Bio-readings of indeterminate origin.\" Right before that wave hit the Clark, there was some kind of surge, right off the scale, but now it\\'s back to its previous levels. I don\\'t know, but whatever it is, it\\'s not the crew.\\n\\n', 'answer': \"So where is the rest of the crew? We've been over every inch of this ship and all we've found is blood. Dr. Weir? Any suggestions? What happened here?\", 'gold_tag': 'MILLER has the immediate concern of finding the rest of the crew and survival plans', 'last_speaker': 'MILLER'}\n",
      "Last word -> MILLER : \"So where is the rest of the crew? We've been over every inch of this ship and all we've found is blood. Dr. Weir? Any suggestions? What happened here?\"\n",
      "prediction :  It could be something in the atmosphere.\n",
      "Real answer : So where is the rest of the crew? We've been over every inch of this ship and all we've found is blood. Dr. Weir? Any suggestions? What happened here?\n",
      "Bert Score : {'precision': [0.8713457584381104], 'recall': [0.8342136144638062], 'f1': [0.8523754477500916], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.052631578947368425, 'rouge2': 0.0, 'rougeL': 0.052631578947368425, 'rougeLsum': 0.052631578947368425}\n",
      "bleu 1/2 : 0.00616561560877894 0.002105958652832994\n",
      "ppl : 73.85794408651299\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTARCK: Miller...\\nMILLER: What is it, Starck?\\nSTARCK: ...I ran the bio-scan with the DNA/RNA filter. The results were bio-readings of indeterminate origin...\\nMILLER: \"...bio-readings of indeterminate origin,\" don\\'t you have anything useful to tell me?\\nSTARCK: I\\'ve got a theory.\\nMILLER: Go ahead.\\nSTARCK: There was a another surge in the bio- readings right before you... you saw what you saw. We picked up a similar readings right before the Clarke was damaged. What if there were a connection between the two? The gravity waves, the hallucination, all part of an defensive reaction, like an immune system...\\n\\n', 'answer': \"I don't need to hear this.\", 'gold_tag': \"MILLER displays skepticism and dismissiveness towards STARCK's theory\", 'last_speaker': 'MILLER'}\n",
      "Last word -> MILLER : \"I don't need to hear this.\"\n",
      "prediction :  ...An immune system?\n",
      "Real answer : I don't need to hear this.\n",
      "Bert Score : {'precision': [0.8409367203712463], 'recall': [0.84763103723526], 'f1': [0.844270646572113], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 752.8877521357401\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTARCK: You've got to listen...\\nMILLER: To what? What are you saying? This ship is alive?\\nSTARCK: I didn't say that, I said the bio- readings correspond to what happened to you, the ship is reacting to us...\\nMILLER: We're hanging on by our fingernails and you're giving me bullshit stories...\\nSTARCK: It's not bullshit, it's the only conclusion the data supports...\\nMILLER: Starck, do you know how crazy that sounds? It's impossible.\\nSTARCK: I know that.\\nMILLER: If you knew it was impossible, then why'd you waste my time?\\nSTARCK: I thought you wanted an answer. And that's the only one I have.\\nMILLER: What I want is to survive the next ten hours.\\nSTARCK: Nine hours and twenty-two minutes.\\n\\n\", 'answer': \"I'm going outside to work on the Clark. And Starck... don't tell anyone what you just told me. We've got enough to worry about.\", 'gold_tag': \"MILLER tasks himself with fixing 'the Clark'\", 'last_speaker': 'MILLER'}\n",
      "Last word -> MILLER : \"I'm going outside to work on the Clark. And Starck... don't tell anyone what you just told me. We've got enough to worry about.\"\n",
      "prediction :  And what's the next miracle?\n",
      "Real answer : I'm going outside to work on the Clark. And Starck... don't tell anyone what you just told me. We've got enough to worry about.\n",
      "Bert Score : {'precision': [0.8477588891983032], 'recall': [0.8131618499755859], 'f1': [0.8301000595092773], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1818181818181818, 'rouge2': 0.0, 'rougeL': 0.12121212121212122, 'rougeLsum': 0.12121212121212122}\n",
      "bleu 1/2 : 0.008948308742466242 0.0022370771856165604\n",
      "ppl : 58.44675612268913\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMILLER: Are you cold? You need something to warm you up?\\nJACKIE: You could torch the club so I don’t have to do this shit.\\nMILLER: Be prepared - it’s not as big a house as they thought. I think the weather kept people home.\\n\\n', 'answer': 'You sure it’s not the marquee? Reads like Night of the Living Dead.', 'gold_tag': 'JACKIE is a performer', 'last_speaker': 'JACKIE'}\n",
      "Last word -> JACKIE : \"You sure it’s not the marquee? Reads like Night of the Living Dead.\"\n",
      "prediction :  I don’t think so. I don’t think it’s that.\n",
      "Real answer : You sure it’s not the marquee? Reads like Night of the Living Dead.\n",
      "Bert Score : {'precision': [0.8586219549179077], 'recall': [0.841827392578125], 'f1': [0.850141704082489], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.08333333333333334, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0.07124226538110606 0.023895382239484966\n",
      "ppl : 12.430611571512946\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACKIE: I’d try it on you but you have no sense of humor.\\nMILLER: No, I don’t.\\nJACKIE: I have never seen you laugh.\\nMILLER: No you haven’t.\\nJACKIE: How can that be? You represent comics.\\nMILLER: You just answered your own question. Can you imagine how fucking painful my life would be if I had to act like an audience with all my comics? “You laughed more at his joke, than ya did at mine” “You think he’s funny, he’s not funny”. So I don’t react to anyone and everyone feels equal.\\nJACKIE: And you call that personal management? Your father had affection for his clients.\\nMILLER: Which his clients didn’t have. He got you that TV show and you fired him.\\nJACKIE: It was a William Morris package deal. Your father understood.\\nMILLER: Just don’t talk to me about affection.\\nJACKIE: I don’t need your affection. You know what I need? I need to work. I want a New York club.\\n\\n', 'answer': 'Yeah, that’ll get you out of the hole you’re in - $30 a show at the', 'gold_tag': 'Everyday Language', 'last_speaker': 'MILLER'}\n",
      "Last word -> MILLER : \"Yeah, that’ll get you out of the hole you’re in - $30 a show at the\"\n",
      "prediction : You’re in New York.\n",
      "Real answer : Yeah, that’ll get you out of the hole you’re in - $30 a show at the\n",
      "Bert Score : {'precision': [0.8796783685684204], 'recall': [0.8457708954811096], 'f1': [0.8623914122581482], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2727272727272727, 'rouge2': 0.2, 'rougeL': 0.2727272727272727, 'rougeLsum': 0.2727272727272727}\n",
      "bleu 1/2 : 0.012446767091965986 0.0045449167361884995\n",
      "ppl : 36.61600078754712\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACKIE: I’m hot now. I’m viral. Your father knew how to take advantage of opportunities like this... “Millah the Killah” I used to call him.\\n\\n', 'answer': 'He loved when you called him that. It killed him when you stopped.', 'gold_tag': 'MILLER\\'s father loved being called \"Millah the Killah\" by JACKIE , Shared memories: JACKIE and MILLER share a memory of MILLER\\'s father, who used to be affectionately called ‘Millah the Killah’ by JACKIE', 'last_speaker': 'MILLER'}\n",
      "Last word -> MILLER : \"He loved when you called him that. It killed him when you stopped.\"\n",
      "prediction :  Dad was a good man. He was a good man.\n",
      "Real answer : He loved when you called him that. It killed him when you stopped.\n",
      "Bert Score : {'precision': [0.8775132894515991], 'recall': [0.85822594165802], 'f1': [0.8677625060081482], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913043, 'rouge2': 0.0, 'rougeL': 0.08695652173913043, 'rougeLsum': 0.08695652173913043}\n",
      "bleu 1/2 : 0.07408182206817181 0.024693940689390605\n",
      "ppl : 17.73436028615676\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACKIE: What am I a Rent-A-Comic?\\nMILLER: She’s a fan who runs a cable network.\\nJACKIE: There was a neon sign on her forehead that said “NO. You didn’t see it?\\nMILLER: There are new executives out there. You have to cultivate them. They say no this time, you come back with another idea.\\nJACKIE: I come back and tap dance some more for these fucking jerks without an ounce of talent between them. They’re gonna tell me what’s funny and what’s not?\\nMILLER: Being funny isn’t enough anymore. This sacrilegious remark stops Jackie cold.\\n\\n', 'answer': 'Now you’re fired.', 'gold_tag': 'JACKIE fired Miller', 'last_speaker': 'JACKIE'}\n",
      "Last word -> JACKIE : \"Now you’re fired.\"\n",
      "prediction :  You’re right. I can’t compete with that.\n",
      "Real answer : Now you’re fired.\n",
      "Bert Score : {'precision': [0.8786019682884216], 'recall': [0.895821213722229], 'f1': [0.8871280550956726], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.30769230769230765, 'rouge2': 0.18181818181818182, 'rougeL': 0.30769230769230765, 'rougeLsum': 0.30769230769230765}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.781572234687847\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMILLER: Over three million views in eight hours and it keeps climbing. You’re on Kimmel. You’re on Conan. Carol from RAW TV called me. She needs a host for a reality show pilot. They shoot on Monday in NY?\\nJACKIE: Monday? Why so fast?\\nMILLER: They had D’Angelo signed but he had to drop out last minute.\\nJACKIE: Why? He got a better deal?\\nMILLER: He’s got pancreatic cancer.\\n\\n', 'answer': 'Finally, I catch a fuckin’ break in this business.', 'gold_tag': 'JACKIE commented about finally catching a break , The language JACKIE uses suggests a direct and perhaps cynical personality', 'last_speaker': 'JACKIE'}\n",
      "Last word -> JACKIE : \"Finally, I catch a fuckin’ break in this business.\"\n",
      "prediction :  Oh my god.\n",
      "Real answer : Finally, I catch a fuckin’ break in this business.\n",
      "Bert Score : {'precision': [0.8475263118743896], 'recall': [0.8333114981651306], 'f1': [0.8403587341308594], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 265.24986382201877\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBB: What is this? What is this crowd here? We're charging admission?\\n\\n\", 'answer': 'Back away... give me some elbow', 'gold_tag': 'TILLEY values personal space , TILLEY is focused on a task, as indicated by the request for some elbow room', 'last_speaker': 'TILLEY'}\n",
      "Last word -> TILLEY : \"Back away... give me some elbow\"\n",
      "prediction :  Yeah. It's a fundraiser.\n",
      "Real answer : Back away... give me some elbow\n",
      "Bert Score : {'precision': [0.8927927017211914], 'recall': [0.8158254027366638], 'f1': [0.8525754809379578], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 47.628665271407776\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTILLEY: Yeah. You in there? Yeah. They got my license as well. Sorry to hear it. This is where my car used to be. Stolen? I.R.S. Fucking bandits! Bandits! Thieving sons of bitches!\\nBB: You need a ride uptown?\\nTILLEY: I could use one.\\n\\n', 'answer': 'Come on.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BB'}\n",
      "Last word -> BB : \"Come on.\"\n",
      "prediction :  You could use one.\n",
      "Real answer : Come on.\n",
      "Bert Score : {'precision': [0.8490637540817261], 'recall': [0.8979195356369019], 'f1': [0.8728084564208984], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 318.0050674284004\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTILLEY: Some bullshit commission, huh? Tell me, where's it written it the Constitution that says you can't hustle for money? Where's it written? It ain't like I went into an alley and hit a guy over the head with a brick and stole his money... not like I broke into somebody's house and stole his stuff. All I'm doing is selling... where's the crime in that?\\nBB: I don't know what the world's coming to.\\n\\n\", 'answer': \"You're telling me. I don't know what the world's coming to.\", 'gold_tag': \"TILLEY is defensive about his job or actions , TILLEY's job or actions involve the sales industry or hustling for money , TILLEY is skeptical about the current state of the world\", 'last_speaker': 'TILLEY'}\n",
      "Last word -> TILLEY : \"You're telling me. I don't know what the world's coming to.\"\n",
      "prediction :  You don't know what the world's coming to? You're a cop. You should know what the world's coming to.\n",
      "Real answer : You're telling me. I don't know what the world's coming to.\n",
      "Bert Score : {'precision': [0.8970224261283875], 'recall': [0.9055231809616089], 'f1': [0.9012527465820312], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.5945945945945946, 'rouge2': 0.5142857142857142, 'rougeL': 0.5405405405405405, 'rougeLsum': 0.5405405405405405}\n",
      "bleu 1/2 : 0.42105263157894735 0.37463432463267754\n",
      "ppl : 8.734168658341192\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBB: You know what our big crime is? We're nickel and dime guys. We're small time hustlers. They got us because we're hustling nickels and dimes.\\nTILLEY: Nickels and dimes. You got a good point there, BB. You're right on the money with that kind of thinking.\\nBB: Gotta find a new business to get into.\\nTILLEY: New? Very hard to find something new to get into.\\nBB: Maybe... maybe not.\\n\\n\", 'answer': 'Better put on my thinking cap... not easy to think of something new.', 'gold_tag': 'Everyday Language', 'last_speaker': 'TILLEY'}\n",
      "Last word -> TILLEY : \"Better put on my thinking cap... not easy to think of something new.\"\n",
      "prediction :  What do you mean?\n",
      "Real answer : Better put on my thinking cap... not easy to think of something new.\n",
      "Bert Score : {'precision': [0.8128216862678528], 'recall': [0.81369948387146], 'f1': [0.8132603764533997], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 79.14500084705968\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSOL: Stop thinking, Max, just feel. Use your intuition. It's the only way to get into the flow. What did you think of Hamlet?\\nMAX: I didn't get to it.\\nSOL: It's been a month. You haven't taken a single break.\\nMAX: I'm so close, Sol. I'm so close but I just can't grab it.\\nSOL: Have you met the new fish my niece bought me? I named her Icarus. After you. My renegade pupil. You fly The more I see you, the more I see myself thirty years ago. My greatest pupil. Published at 16, Ph.D. at 20.\\nMAX: We'll see.\\nSOL: But life isn't just mathematics. I spent forty years looking for patterns in\\nMAX: You found things...\\n\\n\", 'answer': 'I found things, but not a pattern.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SOL'}\n",
      "Last word -> SOL : \"I found things, but not a pattern.\"\n",
      "prediction : ...in the ocean, in the universe, in the mind. I saw the beauty of it.\n",
      "Real answer : I found things, but not a pattern.\n",
      "Bert Score : {'precision': [0.8480708599090576], 'recall': [0.8789428472518921], 'f1': [0.8632308840751648], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09090909090909091, 'rouge2': 0.0, 'rougeL': 0.09090909090909091, 'rougeLsum': 0.09090909090909091}\n",
      "bleu 1/2 : 0.06666666666666667 0.02182178902359924\n",
      "ppl : 22.505516824237013\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMAX: Euclid crashed. I lost all my data, my hardware.\\nSOL: Your mainframe?\\nMAX: Burnt...\\nSOL: What happened?\\nMAX: I don't know, first I got these horrible picks. Then Euclid spits out some numbers. Never saw anything like it and then it fries. The whole machine just crashed.\\nSOL: You have a printout?\\nMAX: Of?\\nSOL: The picks, the number?\\nMAX: I threw it out.\\nSOL: What was the number it spit out?\\nMAX: I don't know, just a long string of digits.\\nSOL: How many?\\nMAX: I don't know.\\nSOL: What was it, a sixteen!? How many?\\nMAX: I don't know. Probably around two hundred. Why?\\nSOL: I dealt with some bugs back in my Pi days. I was wondering if it was similar to one I ran into. Have you met Archimedes. The one with the black spot. You see?\\nMAX: Yeah.\\nSOL: Remember Archimedes of Syracuse? The King asks Archimedes to determine if a present he's received was actually solid gold. Unsolved problem at the time. It tortures the great Greek mathematician for weeks. Insomnia haunts him and he for nights on end. Finally, his equally exhausted wife, with this genius, convinces him to take a bath, to relax. discovery. Now, what's the moral of the story.\\nMAX: That a breakthrough will come...\\n\\n\", 'answer': \"Wrong. The point of the story is the wife. Listen to your wife, she will give you perspective. Meaning, you need a break, Max, you have to take a bath, otherwise you'll get nowhere. There will be no order, only chaos. Go home and take a bath.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SOL'}\n",
      "Last word -> SOL : \"Wrong. The point of the story is the wife. Listen to your wife, she will give you perspective. Meaning, you need a break, Max, you have to take a bath, otherwise you'll get nowhere. There will be no order, only chaos. Go home and take a bath.\"\n",
      "prediction : ...when you're least expecting it.\n",
      "Real answer : Wrong. The point of the story is the wife. Listen to your wife, she will give you perspective. Meaning, you need a break, Max, you have to take a bath, otherwise you'll get nowhere. There will be no order, only chaos. Go home and take a bath.\n",
      "Bert Score : {'precision': [0.8298168778419495], 'recall': [0.8431537747383118], 'f1': [0.836432158946991], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.037037037037037035, 'rouge2': 0.0, 'rougeL': 0.037037037037037035, 'rougeLsum': 0.037037037037037035}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 17.90135645598035\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSOL: Max?\\nMAX: What's going on, Sol!?\\n\\n\", 'answer': \"Relax, it's early.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SOL'}\n",
      "Last word -> SOL : \"Relax, it's early.\"\n",
      "prediction :  I'm sorry. I'm not going to be able to make it.\n",
      "Real answer : Relax, it's early.\n",
      "Bert Score : {'precision': [0.8504045009613037], 'recall': [0.8629142642021179], 'f1': [0.8566136956214905], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 9.954095984830454\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSOL: Now, what\\'s up?\\nMAX: What\\'s the two hundred and sixteen number, Sol?\\nSOL: Excuse me?\\nMAX: You asked me if I had seen a two hundred and sixteen digit number, right?\\nSOL: Oh, you mean the bug. I found it working on Pi.\\nMAX: What do you mean by \"found it\"?\\nSOL: What\\'s this all about, Max?\\nMAX: Well, there\\'s these religious Jews who have...\\nSOL: Religious Jews?\\nMAX: Well, you know, Hassidim. I met one in the coffee shop. The guy\\'s a number theorist. The Torah is their data set. The thing is, they\\'re searching for a two\\nSOL: Really? What\\'s it mean to them?\\nMAX: They say they don\\'t know, but that\\'s crazy. I mean what are the odds...\\nSOL: It\\'s just a coincidence.\\nMAX: But hold on, there\\'s something else. You remember those strange picks I got.\\nSOL: Yesterday\\'s stock picks?\\nMAX: Right. Well, it turns out that they were correct. I hit two picks on the nose. Smack on the nose.\\nSOL: Hmmm.\\nMAX: Something\\'s going on, and it has to do with that No. it\\'s a pattern. A pattern is in that number\\n\\n', 'answer': 'Come with me.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SOL'}\n",
      "Last word -> SOL : \"Come with me.\"\n",
      "prediction :  You mean the bug?\n",
      "Real answer : Come with me.\n",
      "Bert Score : {'precision': [0.8221728801727295], 'recall': [0.8437108993530273], 'f1': [0.8328026533126831], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 475.2186277988785\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSOL: Listen to me. The Ancient Japanese considered the Go simple and ordered, in fact, the possibilities of game play are endless. They say that no two Go games have ever been alike. Just like snowflakes. So, the Go board actually represents an extremely complex and chaotic universe. That is the truth of our world, Max. pattern.\\nMAX: But as a Go game progresses, the possibilities become smaller and smaller. The board does take on order. Soon, all moves are predictable. So, maybe, even though we're not sophisticated enough to be aware of it, there is an underlying order...a pattern, beneath every Go game. Maybe that pattern is like the pattern in the market, in the Torah. The two sixteen number.\\nSOL: That is insanity, Max.\\nMAX: Or maybe it's genius. I have to get that number.\\n\\n\", 'answer': \"Hold on, you have to slow down. You're losing it, you have to take a breath. Listen to yourself. You're connecting a computer bug I had, a computer bug you might have had, and some religious hogwash. If you want to find the number two sixteen in the world, you'll be able to pull it out of anywhere. Two\", 'gold_tag': \"Sol shows concern for Max's mental state, advising him to slow down , Max feels an immediate need to find the number 216\", 'last_speaker': 'SOL'}\n",
      "Last word -> SOL : \"Hold on, you have to slow down. You're losing it, you have to take a breath. Listen to yourself. You're connecting a computer bug I had, a computer bug you might have had, and some religious hogwash. If you want to find the number two sixteen in the world, you'll be able to pull it out of anywhere. Two\"\n",
      "prediction :  You're insane.\n",
      "Real answer : Hold on, you have to slow down. You're losing it, you have to take a breath. Listen to yourself. You're connecting a computer bug I had, a computer bug you might have had, and some religious hogwash. If you want to find the number two sixteen in the world, you'll be able to pull it out of anywhere. Two\n",
      "Bert Score : {'precision': [0.8921324014663696], 'recall': [0.8241793513298035], 'f1': [0.8568106889724731], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06153846153846154, 'rouge2': 0.031746031746031744, 'rougeL': 0.06153846153846154, 'rougeLsum': 0.06153846153846154}\n",
      "bleu 1/2 : 2.0968978291897723e-13 9.377612175880148e-14\n",
      "ppl : 69.00424694794395\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSOL: You're early. I was just studying our... What did you do to yourself?\\nMAX: You lied to me.\\nSOL: I thought you were going to take a break.\\nMAX: You found the two sixteen number in Pi, didn't you? You saw it. I saw it, Sol. I don't know what happened, but I know things. The market is going to crash. It's going to crash. It hasn't yet, but I know it will. I saw it, Sol. What is it, Sol? What's the number?\\nSOL: You have it?\\nMAX: It's in my head!\\nSOL: Okay, sit down. I gave up before I pinpointed it. But my guess is that certain problems cause computers to get stuck in a particular loop. The loop leads to meltdown, but their own structure. The computer has a sense of its own silicon nature and it In some ways...I guess...\\nMAX: Studying the pattern made Euclid conscious of itself. Before it died it spit out the number That consciousness is the number.\\nSOL: No, Max, it's only a nasty bug. A door in front of a cliff. You're driving yourself over the edge. You need to stop.\\nMAX: Stop? How can I stop? I'm this close.\\nSOL: The bug doesn't only destroy computers.\\nMAX: What are you saying?\\nSOL: Look what it did to your computer. Look what it's doing to you. It's killing you. Leave it\\nMAX: You were afraid of it. That's why you quit.\\nSOL: Max, I got burnt.\\nMAX: C'mon, Sol.\\nSOL: It caused my stroke.\\nMAX: That's bullshit. It's math, numbers, ideas. Mathematicians are suppose to be out on the edge. You taught me that!\\nSOL: Max, there's more than math! There's a whole world...\\nMAX: That's where discoveries happen. We have to go out there alone, all alone, no one can accompany us. We have to search the edge. We have to risk it all. But you ran from it. You're a coward.\\nSOL: Max, it's death!\\nMAX: You can't tell me what it is. You don't know You've retreated to your goldfish, to your books, to your Go, but you're not satisfied.\\nSOL: Get out! Max, get out!\\nMAX: I want to understand it. I want to know!\\n\\n\", 'answer': 'Out!', 'gold_tag': 'Everyday Language', 'last_speaker': 'SOL'}\n",
      "Last word -> SOL : \"Out!\"\n",
      "prediction :  Get out!\n",
      "Real answer : Out!\n",
      "Bert Score : {'precision': [0.8995579481124878], 'recall': [0.9519857168197632], 'f1': [0.9250295758247375], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.6666666666666666, 'rouge2': 0.0, 'rougeL': 0.6666666666666666, 'rougeLsum': 0.6666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 858.579724593727\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARTIE: Polly, why're y'doin' this?\\nPOLLY: I don't know.\\nARTIE: Angels? Be reasonable, Polly, it's rubbish. You've said it y'self. You'd be better off spendin' more time with the livin'.\\nPOLLY: Meaning?\\nARTIE: You know perfectly well what I mean. Your daughter needs you. Instead you sit around holdin' on t'...\\nPOLLY: You can't even say his name.\\nARTIE: Let me come with y'then. It'll be dark soon.\\n\\n\", 'answer': 'Thank you, I can manage.', 'gold_tag': 'Everyday Language', 'last_speaker': 'POLLY'}\n",
      "Last word -> POLLY : \"Thank you, I can manage.\"\n",
      "prediction :  Polly, you're not goin' anywhere.\n",
      "Real answer : Thank you, I can manage.\n",
      "Bert Score : {'precision': [0.847655713558197], 'recall': [0.8768279552459717], 'f1': [0.8619950413703918], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1818181818181818, 'rouge2': 0.0, 'rougeL': 0.1818181818181818, 'rougeLsum': 0.1818181818181818}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 48.64552737978683\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPOLLY: Artie, did you knock...? What have you got there?\\n\\n', 'answer': \"Nothin'...\", 'gold_tag': 'ARTIE is secretive', 'last_speaker': 'ARTIE'}\n",
      "Last word -> ARTIE : \"Nothin'...\"\n",
      "prediction :  Uh, yeah. I brought you a gift.\n",
      "Real answer : Nothin'...\n",
      "Bert Score : {'precision': [0.8509145379066467], 'recall': [0.8068942427635193], 'f1': [0.8283199667930603], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 51.25101340693239\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPOLLY: Where are you going?\\n\\n', 'answer': \"T'find that reporter.\", 'gold_tag': 'ARTIE is planning to find a reporter, which is an immediate action', 'last_speaker': 'ARTIE'}\n",
      "Last word -> ARTIE : \"T'find that reporter.\"\n",
      "prediction :  I'm going to get the car.\n",
      "Real answer : T'find that reporter.\n",
      "Bert Score : {'precision': [0.8993673324584961], 'recall': [0.8850390911102295], 'f1': [0.8921456933021545], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 49.91782820955138\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPATRICK: Everything seems to be ok.\\nMICHELLE: Well, thank you. I appreciate it.\\nPATRICK: Please. I didn’t do shit- pardon my French. I almost had him. He just took off so fast... In school, I could do a mile in six-fifty.\\nMICHELLE: The other way to think of it is his speed was a testament to how scared he was of you.\\nPATRICK: Thank you for salvaging my pride.\\nMICHELLE: Anytime.\\nPATRICK: Well, if you see anything, hear anything, just give a holler.\\nMICHELLE: I’m a grandmother.\\n\\n', 'answer': 'Oh?...Congratulations.', 'gold_tag': 'Everyday Language', 'last_speaker': 'PATRICK'}\n",
      "Last word -> PATRICK : \"Oh?...Congratulations.\"\n",
      "prediction :  So, what’s the plan?\n",
      "Real answer : Oh?...Congratulations.\n",
      "Bert Score : {'precision': [0.8558971285820007], 'recall': [0.8629926443099976], 'f1': [0.8594302535057068], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 32.99260782890798\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPATRICK: I didn’t want to disturb you but I just got home and saw all your\\nMICHELLE: That wouldn’t be good.\\nPATRICK: I know it probably sounds like I’m being chicken little or something but it'll amaze you what the winds can do up here.\\nMICHELLE: No, I’ve seen it. You should’ve been here in ‘99. It was like the\\nPATRICK: I believe it. You’re probably going to need a hand.\\nMICHELLE: Yes, probably. Thank you.\\nPATRICK: Your mother’s funeral was today?\\nMICHELLE: There was no service. We just...\\nPATRICK: I’m very sorry, Michelle.\\nMICHELLE: I never counted but I think there’s\\n\\n\", 'answer': 'The wind’s from the west. We’ll do that side.', 'gold_tag': 'PATRICK recently observed wind effects upon arriving home', 'last_speaker': 'PATRICK'}\n",
      "Last word -> PATRICK : \"The wind’s from the west. We’ll do that side.\"\n",
      "prediction :  How many?\n",
      "Real answer : The wind’s from the west. We’ll do that side.\n",
      "Bert Score : {'precision': [0.8456892967224121], 'recall': [0.8344435691833496], 'f1': [0.8400288224220276], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1185.4508853775085\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPATRICK: Any symptoms? Dizziness...?\\nMICHELLE: Oh, no, I’m fine. I think... Except my leg.\\n\\n', 'answer': 'You can take off the seat belt now.', 'gold_tag': \"PATRICK is in a position to help MICHELLE , PATRICK shows concern for MICHELLE's well-being , PATRICK directs MICHELLE's actions to alleviate her discomfort\", 'last_speaker': 'PATRICK'}\n",
      "Last word -> PATRICK : \"You can take off the seat belt now.\"\n",
      "prediction :  What's wrong with your leg?\n",
      "Real answer : You can take off the seat belt now.\n",
      "Bert Score : {'precision': [0.8337962031364441], 'recall': [0.8493132591247559], 'f1': [0.8414831161499023], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 56.900390506028344\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPATRICK: You should probably go to the E.R.\\nMICHELLE: I don’t want any entanglements right now. I just want to go home. I’ll see my own doctor.\\n\\n', 'answer': 'It’s your call.', 'gold_tag': \"PATRICK is concerned about MICHELLE's health , PATRICK respects MICHELLE's decisions\", 'last_speaker': 'PATRICK'}\n",
      "Last word -> PATRICK : \"It’s your call.\"\n",
      "prediction :  I understand, but you’re covered in blood. I can’t let you leave like this.\n",
      "Real answer : It’s your call.\n",
      "Bert Score : {'precision': [0.8601197004318237], 'recall': [0.870158851146698], 'f1': [0.8651101589202881], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.730342147786375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPATRICK: Looks to me like maybe a hairline fracture. You need real treatment.\\nMICHELLE: Why did you do it?\\n\\n', 'answer': 'It was necessary.', 'gold_tag': 'Everyday Language', 'last_speaker': 'PATRICK'}\n",
      "Last word -> PATRICK : \"It was necessary.\"\n",
      "prediction :  You know I didn't do it.\n",
      "Real answer : It was necessary.\n",
      "Bert Score : {'precision': [0.8537611961364746], 'recall': [0.8882733583450317], 'f1': [0.8706753849983215], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 27.942509680930684\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMISS STUBBS: Jenny. Again.\\n\\n', 'answer': \"Isn't it because Mr Rochester's blind?\", 'gold_tag': 'JENNY references Mr. Rochester, a character from Jane Eyre , JENNY is knowledgeable about literature , JENNY is well-read or studying literature', 'last_speaker': 'JENNY'}\n",
      "Last word -> JENNY : \"Isn't it because Mr Rochester's blind?\"\n",
      "prediction :  I’m sorry, Miss Stubbs.\n",
      "Real answer : Isn't it because Mr Rochester's blind?\n",
      "Bert Score : {'precision': [0.8551725149154663], 'recall': [0.8246169686317444], 'f1': [0.8396167755126953], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 61.92601232724625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMISS STUBBS: Jenny, could I have a word?\\nJENNY: Of course.(To Hattie and Tina) I'll catch you up.\\nMISS STUBBS: You can do anything you want, Jenny. You know that. You're clever and you're pretty... But sometimes those things fight. I'm worried that at the moment clever\\nJENNY: What do you mean?\\nMISS STUBBS: I couldn't bear it if clever Jenny lost. It's because of people like you that I plough through illiterate essays by Sandra Lovell about her pony. And there aren't many of you, I can tell you. One every few years. Is your boyfriend interested in clever Jenny?\\nJENNY: I think so.\\nMISS STUBBS: Interested enough to let her do what she wants?\\nJENNY: He couldn't stop me.\\nMISS STUBBS: He might not have to stop you. That's what I'm trying to tell you.\\nJENNY: I'm not sure what you're trying to tell me.\\nMISS STUBBS: I'm telling you to go to Oxford. No matter what. Or you'll break my heart.\\nJENNY: Where did you go? Sorry? Where did you go? Which university?\\nMISS STUBBS: Girton. Cambridge.\\nJENNY: Oh.\\nMISS STUBBS: What does that mean? `Oh'?\\nJENNY: You're clever. And you're pretty. So presumably, Clever Miss Stubbs won. And here you are, reading all those pony essays. I don't know. These last few months, I've been to Paris, and to jazz clubs, and I've eaten in wonderful restaurants, and seen wonderful films, heard beautiful music...\\nMISS STUBBS: I'm sure you have. But I was filled up with beautiful things, books and music and conversation, in exactly the same way at Cambridge. And I didn't have to pay the same sort of price. Are you taking precautions, Jenny?\\nJENNY: It's nothing to do with that.\\nMISS STUBBS: Isn't it?\\nJENNY: Maybe our lives are always going to end up with pony essays. Or housework. And yes, maybe we'll go up to Oxford. But if we're all going to die the moment we graduate, maybe it's what we do before that counts.\\nMISS STUBBS: I'm sorry you think I'm dead.\\nJENNY: I don't think you're dead. But...\\n\\n\", 'answer': \"You'd better get to your next class.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MISS STUBBS'}\n",
      "Last word -> MISS STUBBS : \"You'd better get to your next class.\"\n",
      "prediction :  I know what you mean. I'm sorry.\n",
      "Real answer : You'd better get to your next class.\n",
      "Bert Score : {'precision': [0.8616136312484741], 'recall': [0.8316101431846619], 'f1': [0.8463460803031921], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 29.058224470771375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJENNY: This is lovely. But it is. Really. I'd love to live somewhere like this.\\nMISS STUBBS: Oh, it's not hard. Go to Oxford and become a teacher and this is what you end up with.\\nJENNY: But all these books and pictures.... Yes, but...That's all you need, isn't it? Just a place to...I'm sorry I said those silly things. I didn't understand.\\nMISS STUBBS: Let's forget all about it.\\nJENNY: A Burne-Jones. What?\\nMISS STUBBS: You make it sound as though it's an original. Do you like him?\\nJENNY: Yes. I do. Still.\\nMISS STUBBS: Still? Gosh, you sound very old and wise.\\nJENNY: I feel old. But really not very wise. Miss Stubbs, I'm....I need your help.\\n\\n\", 'answer': \"I was so hoping that's what you were going to say.\", 'gold_tag': 'MISS STUBBS is willing to offer help', 'last_speaker': 'MISS STUBBS'}\n",
      "Last word -> MISS STUBBS : \"I was so hoping that's what you were going to say.\"\n",
      "prediction :  Of course.\n",
      "Real answer : I was so hoping that's what you were going to say.\n",
      "Bert Score : {'precision': [0.8743749856948853], 'recall': [0.8157104253768921], 'f1': [0.8440245985984802], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 372.21681075022684\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTYLER: Hey. It's Tyler.\\nALLY: Hi.\\nTYLER: You're going to stand me up. I can feel it in my bones. I'll be devastated.\\nALLY: No... I...I was just...\\nTYLER: You were just sitting around in your pajamas watching T.V.\\n\\n\", 'answer': \"No. I'm not watching T.V. I'm just...getting dressed. And I'm going to meet you at the place at..what time again? Right...yes. Eight...okay. Shit.\", 'gold_tag': 'ALLY is getting dressed for the meet-up , ALLY is preparing to meet TYLER at a predetermined location at eight', 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"No. I'm not watching T.V. I'm just...getting dressed. And I'm going to meet you at the place at..what time again? Right...yes. Eight...okay. Shit.\"\n",
      "prediction :  I was just...\n",
      "Real answer : No. I'm not watching T.V. I'm just...getting dressed. And I'm going to meet you at the place at..what time again? Right...yes. Eight...okay. Shit.\n",
      "Bert Score : {'precision': [0.8220691680908203], 'recall': [0.7981680035591125], 'f1': [0.809942364692688], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1176470588235294, 'rouge2': 0.0, 'rougeL': 0.1176470588235294, 'rougeLsum': 0.1176470588235294}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 593.5303625909296\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALLY: Really? I had a nice time.\\n\\n', 'answer': \"You had a nice time or you're having a nice time? Because if you're having one, why rush to end it?\", 'gold_tag': \"TYLER is inquiring about the current status of ALLY's enjoyment\", 'last_speaker': 'TYLER'}\n",
      "Last word -> TYLER : \"You had a nice time or you're having a nice time? Because if you're having one, why rush to end it?\"\n",
      "prediction :  Yeah, I know.\n",
      "Real answer : You had a nice time or you're having a nice time? Because if you're having one, why rush to end it?\n",
      "Bert Score : {'precision': [0.8407124280929565], 'recall': [0.8159188628196716], 'f1': [0.8281301856040955], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 62.90789405885124\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTYLER: Did I tell you I'm Caucasian?\\nALLY: Apparently. Can't we just stroll while I feed you ice cream with fireworks in the\\nTYLER: No. If I stop, he wins.\\nALLY: Who, the attendant?\\n\\n\", 'answer': 'No, the frigging Giant Panda.', 'gold_tag': \"TYLER's humor is more sarcastic and dry\", 'last_speaker': 'TYLER'}\n",
      "Last word -> TYLER : \"No, the frigging Giant Panda.\"\n",
      "prediction :  I'm sure he's just happy you're here.\n",
      "Real answer : No, the frigging Giant Panda.\n",
      "Bert Score : {'precision': [0.8380959033966064], 'recall': [0.8433741927146912], 'f1': [0.8407267332077026], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.76801983697969\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALLY: I don't know what you're smiling about.\\nTYLER: I won.\\nALLY: Paying off the attendant is not winning... It's cheating.\\nTYLER: I just paid a premium to cut out the middle man. That's innovation. That's free market enterprising. That's what made America great.\\nALLY: Aha. By the way, what happened to your eye?\\nTYLER: Oh, it's nothing, just a bar fight.\\nALLY: How butch.\\nTYLER: I know. I'm practically a pirate.\\nALLY: Okay, Captain Morgan...\\nTYLER: You've got some serious timing. I'll walk you to the train.\\n\\n\", 'answer': \"I'll take a cab.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"I'll take a cab.\"\n",
      "prediction :  How far is it?\n",
      "Real answer : I'll take a cab.\n",
      "Bert Score : {'precision': [0.8485276103019714], 'recall': [0.8689184188842773], 'f1': [0.858601987361908], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 153.1153178648553\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTYLER: I know. But we have coasters.\\nALLY: I don't do coasters till the third date. Is that you?\\nTYLER: That's Michael. My brother.\\nALLY: He looks like you... or you look like him. Does he play around here?\\nTYLER: Not any more.\\nALLY: Do you play?\\nTYLER: It depends who you ask.\\nALLY: If I asked anybody?\\nTYLER: They'd say no. I try but it turns out you need talent.\\nALLY: So what talents do you actually have?\\nTYLER: Falconry. I come from a long line of falconers.\\nALLY: There's a lot of money in that.\\nTYLER: Well there is one thing...\\nALLY: What's that?\\n\\n\", 'answer': 'Our appetizer. It used to say \"In Case Of Asteroid\" but I took a shower and', 'gold_tag': 'Everyday Language', 'last_speaker': 'TYLER'}\n",
      "Last word -> TYLER : \"Our appetizer. It used to say \"In Case Of Asteroid\" but I took a shower and\"\n",
      "prediction :  I know a lot of people who are very good at it.\n",
      "Real answer : Our appetizer. It used to say \"In Case Of Asteroid\" but I took a shower and\n",
      "Bert Score : {'precision': [0.8720211982727051], 'recall': [0.8434908390045166], 'f1': [0.8575187921524048], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.14285714285714288, 'rougeLsum': 0.14285714285714288}\n",
      "bleu 1/2 : 0.11942188509563156 0.027890943437018378\n",
      "ppl : 21.870663853089397\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALLY: So what kind of grade did you end up with from Vogelstein?\\nTYLER: I don't actually get grades. Beat. I'm not technically enrolled. I worked out an auditing thing.\\nALLY: Oh. And The Strand is not a significant career choice.\\nTYLER: I like the books. You don't have to help me, you know.\\nALLY: At the rate you're going, dish washing is going to be your life's vocation. I can say I knew you when. This is the playful, you get me all wet part? Right?\\nTYLER: You make it sound so cheap.\\nALLY: hundred times.\\nTYLER: I'm sorry. I didn't...\\n\\n\", 'answer': \"You know what never happens in this scene, Tyler-who-doesn't-really-go- to-school? Tyler-who-doesn't-really care-about-his-job? This. No, that usually never happens.\", 'gold_tag': \"ALLY is concerned about Tyler's future , TYLER is easy-going and does not engage in the usual life path\", 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"You know what never happens in this scene, Tyler-who-doesn't-really-go- to-school? Tyler-who-doesn't-really care-about-his-job? This. No, that usually never happens.\"\n",
      "prediction :  It's okay. I'm sorry I didn't get my shit together.\n",
      "Real answer : You know what never happens in this scene, Tyler-who-doesn't-really-go- to-school? Tyler-who-doesn't-really care-about-his-job? This. No, that usually never happens.\n",
      "Bert Score : {'precision': [0.8388490676879883], 'recall': [0.807087779045105], 'f1': [0.8226619958877563], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.045454545454545456, 'rouge2': 0.0, 'rougeL': 0.045454545454545456, 'rougeLsum': 0.045454545454545456}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.160321299192896\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTYLER: Apologize.\\nALLY: Never. Your middle name is Keats? Your parents are pretentious as hell.\\nTYLER: Apologize.\\nALLY: I'd rather eat monkeys.\\nTYLER: I surrender! Oh my God, you're relentless.\\n\\n\", 'answer': 'Victory at all costs.', 'gold_tag': 'ALLY is competitive and displays a relentless pursuit of victory', 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"Victory at all costs.\"\n",
      "prediction :  And you're the only one who can do it.\n",
      "Real answer : Victory at all costs.\n",
      "Bert Score : {'precision': [0.8351789116859436], 'recall': [0.8219707012176514], 'f1': [0.8285222053527832], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18.8597105768129\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALLY: You like?\\nTYLER: Let's just skip dinner and I'll tell you how great you look in like eighteen different languages.\\nALLY: You just want to skip dinner. I got you a tie.\\nTYLER: I was going to make a joke about how I'm not prepared for the commitment of exchanging accessories and how neck wear especially is a slippery slope, but I should probably shut up and say thank you.\\n\\n\", 'answer': \"You're learning.\", 'gold_tag': 'ALLY has a thoughtful nature', 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"You're learning.\"\n",
      "prediction :  I got you a tie.\n",
      "Real answer : You're learning.\n",
      "Bert Score : {'precision': [0.8873170614242554], 'recall': [0.908082127571106], 'f1': [0.8975794911384583], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 330.9455275742666\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALLY: Where are you going?\\nTYLER: I have something I've got to do.\\nALLY: Now?\\n\\n\", 'answer': 'Are you capable of taking care of yourself for an hour? Do you need me here every minute, or what?', 'gold_tag': 'Tyler is responsible enough to look after Ally , Tyler has to do something for the next hour', 'last_speaker': 'TYLER'}\n",
      "Last word -> TYLER : \"Are you capable of taking care of yourself for an hour? Do you need me here every minute, or what?\"\n",
      "prediction :  Yeah.\n",
      "Real answer : Are you capable of taking care of yourself for an hour? Do you need me here every minute, or what?\n",
      "Bert Score : {'precision': [0.9112157225608826], 'recall': [0.8100336790084839], 'f1': [0.8576508164405823], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALLY: He banged an Inuit! She's really nice. And smart. I don't get it. What's going on?\\nTYLER: Your dad was here.\\nALLY: What?\\nTYLER: When I got home.\\nALLY: I hate him!\\nTYLER: There's more. He knows me. Before I met you. He arrested me and Aidan. He gave me that gash over my eye.\\nALLY: I don't understand.\\nTYLER: I mouthed off to him. He ... responded. Then Aidan saw you guys together at school. Aidan suggested...I...introduced myself to you. Ally...\\nALLY: I'm going to be sick.\\nTYLER: Hey. Don't do that. What are you doing?\\nALLY: Do you realize what you've done?\\nTYLER: Yeah.\\nALLY: Did you think I would never find out? I mean, think about it. I had to find out eventually. You set it up that way.\\nTYLER: But it doesn't mean anything. I didn't mean to hurt you,\\n\\n\", 'answer': \"No. That's exactly what you meant to do.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"No. That's exactly what you meant to do.\"\n",
      "prediction :  Oh, you really didn't?\n",
      "Real answer : No. That's exactly what you meant to do.\n",
      "Bert Score : {'precision': [0.8293370008468628], 'recall': [0.8552286028862], 'f1': [0.8420838713645935], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.09196986029286058 0.033582644728665616\n",
      "ppl : 86.11886825177893\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALLY: Using the little sister is dirty pool.\\nTYLER: Is it working? Beat.\\n\\n', 'answer': 'Maybe.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"Maybe.\"\n",
      "prediction :  I'm not sure.\n",
      "Real answer : Maybe.\n",
      "Bert Score : {'precision': [0.8558655977249146], 'recall': [0.9474986791610718], 'f1': [0.899354100227356], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 48.78926453800242\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTYLER: Hey...Hey.\\nALLY: Hmmm.\\nTYLER: I'll be back in an hour. I have to stop by my dad's office.\\nALLY: Do you want french toast or pancakes for breakfast?\\nTYLER: Whichever tastes better a la mode.\\nALLY: Say hi to your dad for me.\\nTYLER: If I said I love you... what would you say?\\nALLY: I love you.\\n\\n\", 'answer': 'I love you too.', 'gold_tag': 'TYLER is in a romantic relationship with ALLY', 'last_speaker': 'TYLER'}\n",
      "Last word -> TYLER : \"I love you too.\"\n",
      "prediction :  So, what do you want to do today?\n",
      "Real answer : I love you too.\n",
      "Bert Score : {'precision': [0.8337529897689819], 'recall': [0.8633618950843811], 'f1': [0.8482991456985474], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.12500000000000003 0.04225771273642583\n",
      "ppl : 17.64915175750907\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Erin -- hi. Sorry you had to wait. Here, sit down, sit down.\\nERIN: Thanks a lot. I tell you, I never thought just standing would take it out of me, but ever since that shithead hit me, it feels like my whole body's put together wrong.\\n\\n\", 'answer': \"Jesus, you poor thing. Well, listen, you came to the right place. Whoever did this to you made one hell of a mistake, and you and me, we're gonna make him pay for it. Why don't you tell me what happened?\", 'gold_tag': 'ED likely has a professional occupation where he can help people seek justice or compensation , ERIN is currently suffering from the negative effects of a recent car crash', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Jesus, you poor thing. Well, listen, you came to the right place. Whoever did this to you made one hell of a mistake, and you and me, we're gonna make him pay for it. Why don't you tell me what happened?\"\n",
      "prediction :  Sorry, Erin.\n",
      "Real answer : Jesus, you poor thing. Well, listen, you came to the right place. Whoever did this to you made one hell of a mistake, and you and me, we're gonna make him pay for it. Why don't you tell me what happened?\n",
      "Bert Score : {'precision': [0.9010659456253052], 'recall': [0.8155674934387207], 'f1': [0.8561875224113464], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1325.1083591054771\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: ... Matthew's six, Katie's four, and Beth's just nine months. ... just wanna be a good mom, a nice person, a decent citizen. Just wanna take good care of my kids. You know?\\n\\n\", 'answer': 'Yeah. I know.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Yeah. I know.\"\n",
      "prediction :  Yeah, I know.\n",
      "Real answer : Yeah. I know.\n",
      "Bert Score : {'precision': [0.94529128074646], 'recall': [0.9714431762695312], 'f1': [0.9581888318061829], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
      "bleu 1/2 : 0.6666666666666666 0.5773502691896257\n",
      "ppl : 62.90789405885124\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: Open and shut? Open and fucking shut?\\nED: If you hadn't used profanity --\\nERIN: Oh, please, it was long over by then. God damn, he made me look like some cheap --\\nED: I told you the questions might get a little personal --\\nERIN: Bullshit. You told me I'd get half a million dollars. You told me I'd be set.\\nED: Okay -- let's try and settle down here.\\nERIN: Settle down? I got 74 bucks to my name, Mr. Masry! I can't afford to settle down!\\nED: I'm sorry, Erin.\\n\\n\", 'answer': \"Yeah? Well, fuck you. Sorry doesn't feed my kids.\", 'gold_tag': \"ERIN's fiery personality and frustration\", 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Yeah? Well, fuck you. Sorry doesn't feed my kids.\"\n",
      "prediction :  Sorry? That's it? You're sorry? You're sorry I lost my job, my apartment, and my self-respect? You're sorry?\n",
      "Real answer : Yeah? Well, fuck you. Sorry doesn't feed my kids.\n",
      "Bert Score : {'precision': [0.8480944633483887], 'recall': [0.8718359470367432], 'f1': [0.8598013520240784], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0.05555555555555554 0.018077538151554672\n",
      "ppl : 6.911536795347701\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Erin! How's it going?\\nERIN: You never called me back. I left messages.\\nED: You did? Wow, sorry about that. Listen, Mario's a little not so bright. He seems to think that you said --\\nERIN: There's two things I can't stand, Mr. Masry. Being ignored, and being lied to. You did both.\\nED: I never lied. I may have miscalculated -- that happens sometimes, but --\\nERIN: You said things would be fine, and they're not.\\nED: I'm sorry about that. Really. But --\\nERIN: I don't need pity. I need a paycheck. And I've looked, but when you've spent the last six years raising babies, it's real hard to convince someone to give you a job that pays worth a damn. So I figure, since you're the one who said I was gonna be okay, you should be the one to hire me.\\nED: I'd love to help, Erin, but I'm sorry, I have a full staff right now, so --\\nERIN: Bullshit. If you had a full staff, you'd have time to return your damn phone calls.\\nED: Okay, look. If you really want to apply for a job here, you can do it the way everyone else does. Send in a r�sum�, make an --\\nERIN: I'm not everyone else, Mr. Masry. I'm someone you made promises to that you didn't deliver on. I trusted you. With my kids' well-being. Now, I'm smart, and I'm hard- working, and I'll do anything. But if you think I'm leaving here without a job, you got another thing coming.\\n\\n\", 'answer': 'No benefits.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"No benefits.\"\n",
      "prediction :  You're right, Erin. I'm sorry. I'll call the office right now, and get them to set up an interview for you.\n",
      "Real answer : No benefits.\n",
      "Bert Score : {'precision': [0.824917197227478], 'recall': [0.8813521265983582], 'f1': [0.8522014617919922], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.574492181066057\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: Mr. Masry?\\nED: Yeah?\\nERIN: I was wondering -- could you tell me who I'd talk to about maybe getting an advance on my paycheck? Just -- for the weekend.\\nED: Jane's the office manager. She handles payroll and petty cash. But she leaves early on Fridays.\\nERIN: Oh. Okay. That's okay.\\nED: Oh, for Christ's sake ... All I have is hundreds.\\nERIN: I don't wanna take your money, Mr. Masry.\\n\\n\", 'answer': \"Bullshit, you don't.\", 'gold_tag': 'ED is willing to help out', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Bullshit, you don't.\"\n",
      "prediction :  Well, you will.\n",
      "Real answer : Bullshit, you don't.\n",
      "Bert Score : {'precision': [0.9243061542510986], 'recall': [0.8809868097305298], 'f1': [0.9021267890930176], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0.3333333333333333 0.12909944487358058\n",
      "ppl : 161.84358504354535\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: How long's she been crying like that? ... Well, she's got that tooth coming in -- Give her a cold washcloth to suck on -- I gotta go -- there's a clean one in that bag -- I'll check back in a bit. Sorry. My kid --\\nED: Where's Anna?\\nERIN: Out to lunch with the girls.\\nED: Oh. Huh. Well, look, I got this file I need valued.\\nERIN: Oh. Okay.\\nED: You do know how to do that, don't you?\\nERIN: Yeah. I got it. No problem.\\nED: Good. You're a girl.\\nERIN: Excuse me?\\nED: How come you're not at lunch with the girls? You're a girl.\\n\\n\", 'answer': \"I guess I'm not the right kind.\", 'gold_tag': \"ERIN distinguishes herself from 'the girls' that ED refers to\", 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"I guess I'm not the right kind.\"\n",
      "prediction :  Uh, I gotta go.\n",
      "Real answer : I guess I'm not the right kind.\n",
      "Bert Score : {'precision': [0.8574361205101013], 'recall': [0.8623412847518921], 'f1': [0.8598817586898804], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.11809163818525367 0.043120969391201254\n",
      "ppl : 61.80980824334132\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: What are you doing here?\\nED: I got an interesting call this afternoon. It was from a Dr. Frankel.\\nERIN: Oh, yeah?\\nED: He wanted you to know the legal limit for hexavalent chromium, is .05 parts per million. And that at the rate you mentioned, .58, it could be responsible for the cancers in that family you asked about. The Irvings.\\nERIN: Well, that was nice of him. Isn't it funny how some people go out of their way to help people and others just give 'em the ax?\\nED: Look, I'm sorry. You were gone. I just assumed you were off having fun.\\nERIN: Now, why in the hell would you assume that?\\nED: I don't know. Maybe cause you look like someone who has a lot of fun.\\nERIN: Boy, are you ever a shitty judge of people.\\nED: So what's the story on this thing? This cancer stuff?\\nERIN: You wanna know, you gotta hire me back. I got a lot of bills to pay.\\n\\n\", 'answer': 'Fine.', 'gold_tag': 'Ed has a job where he has control over hiring people', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Fine.\"\n",
      "prediction :  I'm sorry, okay? I didn't mean to get you into this. I'll make it up to you.\n",
      "Real answer : Fine.\n",
      "Bert Score : {'precision': [0.8202154636383057], 'recall': [0.9212837219238281], 'f1': [0.8678168654441833], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 7.750311750802276\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: But, PG&E told her about the chromium?\\nERIN: They told her something, but it can't have been too specific, cause I talked to her, and she sure didn't think her water was bad.\\nED: So what made you think it was?\\nERIN: It doesn't take a genius to look at those medical records and think something's wrong.\\nED: What medical records?\\nERIN: The ones in the box of files. The box of files? The one from your office? Boy, you musta really fine-tooth-combed it then, huh? And you fired me. Jesus.\\nED: That document you found, the one that says it was the bad chromium -- you didn't happen to make a copy did you?\\nERIN: Course I did.\\nED: Lemme see it, will you?\\nERIN: I want a raise. And benefits. Including dental.\\nED: Look, Erin, this is not the way I do business, this extortion nonsense. Okay. A 5% raise, and --\\nERIN: There's a lot of other places I could work.\\nED: A ten percent raise and benefits. But that's it. I'm drawing the line. This is the only thing you found?\\nERIN: So far. But that place is a pig sty. I wouldn't be surprised if there's more.\\n\\n\", 'answer': 'Find out.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Find out.\"\n",
      "prediction :  I'll tell you what, Erin. I'll look into it.\n",
      "Real answer : Find out.\n",
      "Bert Score : {'precision': [0.8261493444442749], 'recall': [0.8745704293251038], 'f1': [0.8496705293655396], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.48147509221641\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: It's Sinatra's world, we just live in it. Hello? ... Hi, babys. Baby's fine. Yes, I did. I did, too, you just didn't feel it. You think I could leave without kissing my babys? Okay, here you go. Bye-bye ... bye-bye ... no, you. Okay, together. Bye-bye.\\n\\n\", 'answer': 'Um -- you mind pulling over? Just -- for a second?', 'gold_tag': 'ERIN feels uncomfortable , ERIN needs some private space , ERIN requested to pull over', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Um -- you mind pulling over? Just -- for a second?\"\n",
      "prediction :  You know, you're right. It is Sinatra's world.\n",
      "Real answer : Um -- you mind pulling over? Just -- for a second?\n",
      "Bert Score : {'precision': [0.8493586778640747], 'recall': [0.8061772584915161], 'f1': [0.8272047638893127], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473685, 'rouge2': 0.0, 'rougeL': 0.10526315789473685, 'rougeLsum': 0.10526315789473685}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 32.6670754102917\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Hunh-uh. Absolutely not.\\nERIN: That's crazy -- why not?\\n\\n\", 'answer': \"Because I said no. Look -- the only reason PG&E's even talking to us is cause this is a quiet little real estate dispute. We add plaintiffs, and suddenly we're in the middle of a toxic tort -- with a statute problem -- against a massive utility. No, thank you.\", 'gold_tag': 'ED is possibly a lawyer or professional involved in real estate disputes', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Because I said no. Look -- the only reason PG&E's even talking to us is cause this is a quiet little real estate dispute. We add plaintiffs, and suddenly we're in the middle of a toxic tort -- with a statute problem -- against a massive utility. No, thank you.\"\n",
      "prediction :  I can't get my head around it.\n",
      "Real answer : Because I said no. Look -- the only reason PG&E's even talking to us is cause this is a quiet little real estate dispute. We add plaintiffs, and suddenly we're in the middle of a toxic tort -- with a statute problem -- against a massive utility. No, thank you.\n",
      "Bert Score : {'precision': [0.8374959230422974], 'recall': [0.8264623284339905], 'f1': [0.8319424986839294], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.03448275862068966, 'rouge2': 0.0, 'rougeL': 0.03448275862068966, 'rougeLsum': 0.03448275862068966}\n",
      "bleu 1/2 : 0.0003069679258442461 0.00010484950742849092\n",
      "ppl : 23.427384832938664\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: Okay, so here's what I'll do. I'll go on up to Ted and Rita Daniels -- two of the nicest people you'd ever hope to meet, who spend every single day watching their little girl fight like a dog against this cancer -- I'll tell them we can't help them cause you don't feel like working that hard.\\nED: It's not about working hard --\\nERIN: Bullshit.\\nED: -- It's about being realistic. Something like this, Erin -- it could take forever. They're a huge corporation. They'd completely bury us in paperwork. I'm just one guy with a shitty little P.I. firm.\\n\\n\", 'answer': '-- who happens to know they poisoned people and lied about it.', 'gold_tag': 'ERIN is a champion for the people', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"-- who happens to know they poisoned people and lied about it.\"\n",
      "prediction :  I understand.\n",
      "Real answer : -- who happens to know they poisoned people and lied about it.\n",
      "Bert Score : {'precision': [0.881354570388794], 'recall': [0.8346444368362427], 'f1': [0.857363760471344], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 524.1272433307118\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: And this shit is bad news, Mr. Masry. Not only does it attack every organ of the body, it fucks with your DNA, too. That means these people's genes, and the genes of their kids, and the genes of their grandkids --\\n\\n\", 'answer': 'I know how DNA works, Erin --', 'gold_tag': 'ED is knowledgeable about DNA', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"I know how DNA works, Erin --\"\n",
      "prediction :  So what do you want me to do, Erin?\n",
      "Real answer : I know how DNA works, Erin --\n",
      "Bert Score : {'precision': [0.8595331311225891], 'recall': [0.854899525642395], 'f1': [0.8572100400924683], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 34.22828010542347\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: We can get these people. With a little effort, I really think we can nail their asses to the wall.\\nED: Oh, you do? With all your legal expertise, you believe that?\\n\\n', 'answer': \"Okay, fine. I don't know shit about shit. But I know the difference -- -- BETWEEN RIGHT AND WRONG!\", 'gold_tag': 'ERIN admits her lack of legal expertise', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Okay, fine. I don't know shit about shit. But I know the difference -- -- BETWEEN RIGHT AND WRONG!\"\n",
      "prediction :  Of course. I've read all the evidence. I know what they're trying to cover up.\n",
      "Real answer : Okay, fine. I don't know shit about shit. But I know the difference -- -- BETWEEN RIGHT AND WRONG!\n",
      "Bert Score : {'precision': [0.8749855756759644], 'recall': [0.8364436030387878], 'f1': [0.8552806377410889], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22857142857142856, 'rouge2': 0.06060606060606061, 'rougeL': 0.17142857142857143, 'rougeLsum': 0.17142857142857143}\n",
      "bleu 1/2 : 0.15318566767292974 0.09154594627133818\n",
      "ppl : 13.853730999430038\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Damn it. How many families we talking about here?\\nERIN: Four more. Eleven people. So far.\\nED: You think there's more?\\nERIN: Well -- I found one document at the water board that had a toxic test well reading from 1967. A hell of a lot of people have lived on that land since then.\\nED: This is a whole different ball game, Erin. A much bigger deal.\\nERIN: Kinda like David and what's-his-name?\\nED: Kinda like David and what's-his-name's whole fucking family. Okay, here's the deal -- if, and only if, you find me the evidence to back all this up -- I'll do it. I'll take it on.\\nERIN: You're doing the right thing, Mr. Masry.\\nED: Yeah, yeah. Remind me of that when I'm filing for bankruptcy.\\nERIN: Course, gathering evidence -- now, that's a big job. A hell of a lot bigger than just filing. I'm gonna be working a lot harder now, taking on a lot more responsibility ...\\nED: What now?\\n\\n\", 'answer': \"Another raise wouldn't hurt. And with all the time I'm gonna be spending on the road, I'll probably be needing my own cel phone, won't I?\", 'gold_tag': 'ERIN is not afraid to negotiate for a raise and additional resources for her work , ERIN anticipates needing more resources like a cell phone due to increased time spent on the road', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Another raise wouldn't hurt. And with all the time I'm gonna be spending on the road, I'll probably be needing my own cel phone, won't I?\"\n",
      "prediction :  ... And I'm gonna need a lot more help.\n",
      "Real answer : Another raise wouldn't hurt. And with all the time I'm gonna be spending on the road, I'll probably be needing my own cel phone, won't I?\n",
      "Bert Score : {'precision': [0.887078046798706], 'recall': [0.8549307584762573], 'f1': [0.8707077503204346], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20512820512820512, 'rouge2': 0.1081081081081081, 'rougeL': 0.20512820512820512, 'rougeLsum': 0.20512820512820512}\n",
      "bleu 1/2 : 0.05041325323016525 0.030871686671905183\n",
      "ppl : 40.515291394741375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Is that what I think it is?\\n\\n', 'answer': 'She lived on the plume. You never know.', 'gold_tag': 'ERIN has experience dealing with a case related to the plume area , ED and ERIN have worked on or discussed a case involving a person who lived on the plume', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"She lived on the plume. You never know.\"\n",
      "prediction :  It is.\n",
      "Real answer : She lived on the plume. You never know.\n",
      "Bert Score : {'precision': [0.9190986156463623], 'recall': [0.8619086742401123], 'f1': [0.8895854353904724], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 728.6563772339246\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: They used the hex chrom here, in these cooling tanks, as an anti-corrosive. Then they dumped it here, in these six ponds.\\nED: I don't remember seeing any ponds up there.\\nERIN: They covered 'em over. And not too carefully either, cause you dig one inch under the surface, and the dirt is green as\\nED: And that's what caused the contamination?\\nERIN: It didn't help, but no. The real problem's on the bottom. See, according to this, they were supposed to line the ponds so this shit couldn't seep into the ground. But guess what --\\nED: They skipped that step.\\nERIN: I guess it was a little too inconvenient. So for fourteen years, this stuff flowed into the groundwater, free as you please.\\nED: Jesus. I don't even wanna ask what you did to make this Melendez guy talk.\\nERIN: For your information, Frank cares what was in those ponds 'cause he used to spend half his day wading around them. That was his job.\\nED: No shit.\\n\\n\", 'answer': 'No -- SHIT! SHIT! Hot! Hot! Hot! You ... asshole ...', 'gold_tag': 'Everyday Language', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"No -- SHIT! SHIT! Hot! Hot! Hot! You ... asshole ...\"\n",
      "prediction :  The state said they'd fix it. But they're not doing anything.\n",
      "Real answer : No -- SHIT! SHIT! Hot! Hot! Hot! You ... asshole ...\n",
      "Bert Score : {'precision': [0.8355962038040161], 'recall': [0.7523522973060608], 'f1': [0.7917922735214233], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 26.350537322743236\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Erin -- lemme tell you something. If I'da put three researchers on this, I wouldn't expect them to dig up all the information you got here. This is some damn good work.\\nERIN: Yeah? Then gimme another raise.\\nED: Hey, I got a staff to pay, plus rent, plus I haven't billed a minute of my time since I started on this case, so you can quit hitting me up like I'm rich or something.\\nERIN: Don't give me that. You're gonna get plenty rich off of this, Mr. 40 percent. We got those PG&E fuckers by the balls here.\\nED: We've got the PG&E fuckers in Hinkley by the balls. But nobody's getting rich unless we can pin this on the corporate PG&E fuckers in San Francisco.\\nERIN: What do you mean?\\nED: PG&E corporate is claiming they had no way of knowing what was going on in Hinkley.\\nERIN: Oh, they knew. They had to know.\\nED: Show me the document that proves that. Then they didn't know. And if they didn't know, we can't hit 'em for punitive damages. And punitive damages is where the money is.\\nERIN: Jesus Christ, Ed -- you know, the more I work on this thing, the more I realize what a crock of shit this legal system is. Here we got a company that poisoned a whole aquifer -- that built a pool for a town, then filled it with toxic water -- and we're the ones who've gotta bust our ass proving things? That's just not right.\\nED: I like this case.\\nERIN: Really? It makes me sick.\\nED: Me too. That's why I like it. It's been a long time since I had a case I cared about.\\nERIN: You didn't care about my case?\\nED: I would now. Hey. I like working with you.\\nERIN: Well, good, Ed. I like working with you too.\\n\\n\", 'answer': \"When'd you start calling me Ed?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"When'd you start calling me Ed?\"\n",
      "prediction :  So what do you think?\n",
      "Real answer : When'd you start calling me Ed?\n",
      "Bert Score : {'precision': [0.8548002243041992], 'recall': [0.8380517363548279], 'f1': [0.8463431000709534], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.1637461506155964 0.05789300674674099\n",
      "ppl : 57.37141838444661\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: Jesus. They look like the Secret Service.\\n\\n', 'answer': \"They're trying to intimidate us. Tell them to wait in the conference room.\", 'gold_tag': 'ED is in a position of authority , ED directs ERIN on what to do', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"They're trying to intimidate us. Tell them to wait in the conference room.\"\n",
      "prediction :  I know, right?\n",
      "Real answer : They're trying to intimidate us. Tell them to wait in the conference room.\n",
      "Bert Score : {'precision': [0.8186748623847961], 'recall': [0.8641740679740906], 'f1': [0.8408093452453613], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 116.74439390378859\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Hey. A new plaintiff called, wants to meet you. I told him we'd be out there Thursday.\\nERIN: D'you get his name? Course not. Jesus, Ed --\\nED: He said he'd be at the gas station at six.\\n\\n\", 'answer': 'Boy, this job takes me to some of the best damn places, huh?', 'gold_tag': 'Everyday Language', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Boy, this job takes me to some of the best damn places, huh?\"\n",
      "prediction :  I'm sorry. I'm not going to meet him.\n",
      "Real answer : Boy, this job takes me to some of the best damn places, huh?\n",
      "Bert Score : {'precision': [0.8786296248435974], 'recall': [0.848666787147522], 'f1': [0.8633883595466614], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913043, 'rouge2': 0.0, 'rougeL': 0.08695652173913043, 'rougeLsum': 0.08695652173913043}\n",
      "bleu 1/2 : 0.0669076785648738 0.02261892368524442\n",
      "ppl : 23.667037148588264\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: Someone's following me.\\nED: What? Who?\\nERIN: Some guy in a truck -- he waited till I was alone, then he followed me, like, two miles. Jesus, I'm shaking. Get me a beer.\\nED: Beer, please. What kind of truck? He's gone. Did you get a license plate? Or a make?\\nERIN: No, Ed -- what with me running for my life, I didn't have time to check those things --\\nED: I was just asking. Are you all right?\\nERIN: Yeah. Yeah, I'm ... fine.\\n\\n\", 'answer': \"Jesus, you look like shit. When was the last time you had a decent night's sleep?\", 'gold_tag': 'ED is accommodating and considerate', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Jesus, you look like shit. When was the last time you had a decent night's sleep?\"\n",
      "prediction :  I'll get you a beer.\n",
      "Real answer : Jesus, you look like shit. When was the last time you had a decent night's sleep?\n",
      "Bert Score : {'precision': [0.8797526359558105], 'recall': [0.8463887572288513], 'f1': [0.8627482652664185], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1739130434782609, 'rouge2': 0.0, 'rougeL': 0.1739130434782609, 'rougeLsum': 0.1739130434782609}\n",
      "bleu 1/2 : 0.044321263344933554 0.011080315836233388\n",
      "ppl : 39.55242814497217\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Lock the door every which way you can. And if there's anything -- funny sound, whatever -- pound on the wall. I'll come right over.\\nERIN: I think you should know -- there's very few people in the world who don't piss me off 90 percent of the time. You're one of 'em.\\n\\n\", 'answer': \"I'm triple locking my door, so don't even think of trying to take advantage.\", 'gold_tag': 'ED is cautious and protective', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"I'm triple locking my door, so don't even think of trying to take advantage.\"\n",
      "prediction :  I'm glad I made you happy.\n",
      "Real answer : I'm triple locking my door, so don't even think of trying to take advantage.\n",
      "Bert Score : {'precision': [0.8722087144851685], 'recall': [0.8501836657524109], 'f1': [0.8610554337501526], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17391304347826086, 'rouge2': 0.09523809523809522, 'rougeL': 0.17391304347826086, 'rougeLsum': 0.17391304347826086}\n",
      "bleu 1/2 : 0.043932856352621126 0.01521878786487298\n",
      "ppl : 34.74749989843928\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: I want my fucking money --\\nED: I'm sorry, I'm gonna have to put you on hold for just one second here -- Do you mind?\\nERIN: Yeah, I mind. You bet your ass I mind.\\nED: Oh, Jesus. You wanna tell me what the problem is here, or --\\nERIN: It's my paycheck. Which I earned. Which I deserve. Which I shouldn't have to beg for. That fat-ass bitch won't give it to me.\\nED: Erin, you're a big girl. If you got a problem with Jane, work it out for yourself. I don't have time to deal with --\\nERIN: Fuck you. Make time. Cause I bust my ass for you. I watch everything else in my life go straight in the toilet, for you. And what do you do for me? Huh? You see the way I'm treated around here -- but have you ever stood up for me once? Have you ever mentioned to everyone what good work I'm doing? Have you ever bothered saying, hey, the best tits; she gets paid the most cause she's the best God damn employee I've ever had?\\nED: Is that what you want?\\nERIN: I want my paycheck. By the end of the day.\\nED: I'll see what I can do.\\n\\n\", 'answer': \"You might want to think real hard about the amount, too. My kids are sitting in the God damn parking lot right now, cause I still don't make enough to afford good child care. Makes me think about looking around for a job where I'm appreciated, for shit's sake.\", 'gold_tag': \"ERIN perceives herself as undervalued and underpaid , ERIN is a mother who struggles to provide for her children due to her financial situation , ERIN's job takes a significant toll on her personal life , ERIN experiences financial concerns and needs to make arrangements for child care\", 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"You might want to think real hard about the amount, too. My kids are sitting in the God damn parking lot right now, cause I still don't make enough to afford good child care. Makes me think about looking around for a job where I'm appreciated, for shit's sake.\"\n",
      "prediction :  I don't wanna be here. I don't wanna do this. But I do.\n",
      "Real answer : You might want to think real hard about the amount, too. My kids are sitting in the God damn parking lot right now, cause I still don't make enough to afford good child care. Makes me think about looking around for a job where I'm appreciated, for shit's sake.\n",
      "Bert Score : {'precision': [0.8579725027084351], 'recall': [0.8114829063415527], 'f1': [0.8340803980827332], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11940298507462686, 'rouge2': 0.030769230769230767, 'rougeL': 0.11940298507462686, 'rougeLsum': 0.11940298507462686}\n",
      "bleu 1/2 : 0.009647726896626413 0.0022453862376869533\n",
      "ppl : 8.12318654939857\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: Believe it or not, I would've been satisfied with just the check.\\nED: Well, you go threatening to leave, I can't take any chances. You're the only person around who understands what I'm doing. Things come up, I gotta know I got someone to turn to.\\nERIN: What kind of things come up?\\nED: Things like the head counsel for PG&E calling me with an offer. 20 million, plus attorney's fees. Take it or leave it.\\nERIN: Whoa. No shit.\\nED: It's about 50 thousand per plaintiff.\\nERIN: So what are you thinking?\\nED: I'm thinking ... I wish someone else had to make this decision. 50 thousand bucks is more than any other California toxic plaintiff has gotten. Ever. But ...\\nERIN: ... but it won't cover Annabelle Daniels's medical bills.\\nED: And it's less than pocket change for PG&E.\\nERIN: Do you think we'd do better by going to trial?\\nED: Maybe. but maybe not. We still don't have anything linking this to PG&E corporate. Plus, there's the statute problem. Plus, we're way short on manpower, so we'd need to bring on more lawyers ...\\nERIN: Plus, 40 percent of 20 million's a whole lot of money.\\nED: It's eight million dollars, Erin. Eight million dollars.\\nERIN: That's a fucking fortune, Ed. And you know I'm the last person on Earth to walk away from a big payday. But you and me didn't get into this to get rich. We did it cause we both have this voice in our heads saying, do the right thing; get these plaintiffs what they deserve -- the right to live and die in some kind of comfort and peace. If 50,000 isn't gonna buy that, then we gotta say no. Trust me. If you don't do the right thing for these people, getting that 6 million dollars is gonna feel like shit.\\n\\n\", 'answer': 'I knew I put up with your bullshit for a reason.', 'gold_tag': 'ED demonstrates a level of fear in being left to handle the case alone', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"I knew I put up with your bullshit for a reason.\"\n",
      "prediction :  I think I know how you feel, Erin.\n",
      "Real answer : I knew I put up with your bullshit for a reason.\n",
      "Bert Score : {'precision': [0.87221360206604], 'recall': [0.8689849972724915], 'f1': [0.8705963492393494], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2105263157894737, 'rouge2': 0.0, 'rougeL': 0.2105263157894737, 'rougeLsum': 0.2105263157894737}\n",
      "bleu 1/2 : 0.17182231969774306 0.04107339044498862\n",
      "ppl : 43.162938567526375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: Holy shit. Who do they represent, God?\\nED: Don't joke. They might. So do me a favor and behave yourself for once. Ed Masry to see Kurt Potter.\\n\\n\", 'answer': \"Scuse me, sir, you got a real nice ass, you know that? Oh, I'm sorry. Was that not what you meant by behaving myself?\", 'gold_tag': 'ERIN is a forthright and uninhibited individual , ERIN uses humor and flirtatious comments in formal settings', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Scuse me, sir, you got a real nice ass, you know that? Oh, I'm sorry. Was that not what you meant by behaving myself?\"\n",
      "prediction :  Kurt Potter? Who the hell is that?\n",
      "Real answer : Scuse me, sir, you got a real nice ass, you know that? Oh, I'm sorry. Was that not what you meant by behaving myself?\n",
      "Bert Score : {'precision': [0.8507848978042603], 'recall': [0.8041995763778687], 'f1': [0.8268366456031799], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0625, 'rouge2': 0.0, 'rougeL': 0.0625, 'rougeLsum': 0.0625}\n",
      "bleu 1/2 : 0.012594669908908207 0.004301898749003176\n",
      "ppl : 87.77035628670788\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: She insulted me!\\nED: Bullshit. It was a misunderstanding. But instead of handling it politely, instead of treating her with respect --\\nERIN: Why the fuck should I respect her?\\nED: Because that's how people treat each other!\\nERIN: Not in my world.\\nED: Gee, I wonder why.\\n\\n\", 'answer': \"Hey! You're my ride!\", 'gold_tag': 'ERIN is dependent on ED for transportation', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Hey! You're my ride!\"\n",
      "prediction :  You know what? I'm going to take care of this.\n",
      "Real answer : Hey! You're my ride!\n",
      "Bert Score : {'precision': [0.8522388935089111], 'recall': [0.8688161969184875], 'f1': [0.8604477047920227], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12500000000000003, 'rouge2': 0.0, 'rougeL': 0.12500000000000003, 'rougeLsum': 0.12500000000000003}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13.529396488278977\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: If you tell me to relax, I\\'m gonna kick your fucking head off --\\nED: Erin, it\\'s just a meeting.\\nERIN: People don\\'t fly down in their own god damn plane for \"just a meeting\" --\\nED: Look, you said you weren\\'t feeling great. I thought you should rest.\\nERIN: Bullshit. You\\'d drag me off my deathbed if it suited you.\\nED: Okay, look. It\\'s an important meeting. Kurt thought, if it was just lawyers --\\nERIN: Kurt thought? What about you? Do you think anymore?\\nED: Look, this is serious now. They\\'re talking serious money --\\nERIN: And, what, I\\'m not serious?\\nED: You\\'re emotional. You\\'re erratic. You say any God damn thing that comes into your head. And I\\'m not saying that\\'s bad. That can be great; that can be a lot of fun --\\nERIN: \"Fun?\" Jesus, \"fun?\" I kill myself for a year and a half, hand you the best case of your life on a God damn silver platter, remind you of why you became a lawyer in the first place, and you think of me as \"fun?\"\\nED: Okay, now you\\'re making this personal, and it isn\\'t --\\nERIN: Not personal? That\\'s my work in there, Ed. My sweat, my labor, my time. If that\\'s not personal, I don\\'t know what is. How dare you take that away from me.\\nED: No one\\'s taking anything --\\nERIN: Bullshit. You stuck me in Siberia dictating to some God damn steno clerk so you could finish this thing without me. After all I\\'ve done for you, that\\'s the thanks I get.\\nED: Don\\'t give me that. You\\'ve gotten plenty. You\\'ve been well-paid; you\\'ve gotten lots of perks ...\\n\\n', 'answer': 'Perks? Jesus -- perks? If this piece of shit is supposed to take the place of your respect, you can take it and shove it up your ass.', 'gold_tag': 'ERIN feels underappreciated and disrespected', 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Perks? Jesus -- perks? If this piece of shit is supposed to take the place of your respect, you can take it and shove it up your ass.\"\n",
      "prediction :  Perks? What kind of perks? What kind of perks are there when you're a fucking hostage in your own fucking office?\n",
      "Real answer : Perks? Jesus -- perks? If this piece of shit is supposed to take the place of your respect, you can take it and shove it up your ass.\n",
      "Bert Score : {'precision': [0.8807480335235596], 'recall': [0.8600128889083862], 'f1': [0.8702569603919983], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.24489795918367346, 'rouge2': 0.0, 'rougeL': 0.20408163265306123, 'rougeLsum': 0.20408163265306123}\n",
      "bleu 1/2 : 0.17060269299375935 0.0247226789808706\n",
      "ppl : 16.72399813147189\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: Between 50 and 400 million, definitely?\\nED: Uh-huh.\\nERIN: And if you had to guess ...\\nED: With nothing linking it to the corporate offices yet, I'd say we'll end up on the lower end of that. Still a lot of money.\\nERIN: So why would PG&E offer it?\\nED: Because. They know the evidence; they know they're gonna lose a jury trial. Maybe they wouldn't lose 400 million bucks, but once you factor in all they'd spend on this case in the next ten years, it makes a lot of --\\nERIN: Wait, what do you mean, ten years?\\nED: Five years, maybe, for a trial. Double that for the appeal.\\nERIN: I'm sorry, are you saying that if this thing goes to trial, it'll be ten years before these plaintiffs see their money?\\nED: Hey, that's not so bad. Compare it to the Love Canal -- that was twenty years ago, and those people still haven't seen a dime. So in legal terms, ten years is --\\nERIN: Fuck legal terms. We're talking about human beings here. Sick people. A whole bunch of them are gonna be dead in ten years. They need their money now! We gotta get 'em to agree to the arbitration, Ed. We gotta get every damn one of those plaintiffs to --\\nED: I know. We're having a meeting, it's all set up --\\nERIN: When? Where?\\nED: Tuesday at seven, at the Hinkley firehouse.\\nERIN: Okay, good. I think I should be the one to tell 'em, cause they trust me more than --\\nED: You're not gonna be there.\\nERIN: The fuck I'm not. I don't care what the doctor says --\\nED: This isn't doctor's orders. It's mine. I'm saying you can't come.\\nERIN: Why not?\\nED: Because Kurt doesn't want to work with you. He thinks you're a loose cannon.\\nERIN: Fuck Kurt.\\nED: Erin --\\nERIN: No, I'm serious. You know what Kurt Potter is? He's the kind of guy who never would have taken this case in the first place. He's the kind of guy who would have sold these plaintiffs down the river when PG&E offered 20 million. He doesn't work like us, Ed. There's no little voice in his head telling him to do the right thing.\\n\\n\", 'answer': \"Don't come, Erin. I mean it. If you do, I'm gonna have to fire you. Just ... concentrate on getting well.\", 'gold_tag': 'Erin is currently unwell, as indicated by Ed telling her to concentrate on getting better', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Don't come, Erin. I mean it. If you do, I'm gonna have to fire you. Just ... concentrate on getting well.\"\n",
      "prediction :  There is something in his head.\n",
      "Real answer : Don't come, Erin. I mean it. If you do, I'm gonna have to fire you. Just ... concentrate on getting well.\n",
      "Bert Score : {'precision': [0.856850266456604], 'recall': [0.8465766310691833], 'f1': [0.8516824841499329], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 142.22663118728983\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIN: Morning!\\nED: Erin? What are you --\\nERIN: You know what, Mr. Potter? I completely forgot your birthday this year. And seeing as how you've been so good to me, I think that is a terrible oversight. So what I been doing over the last few days is I've been putting together a present for you. 635. They all signed. Every single one.\\nED: Ho - ly - shit.\\n\\n\", 'answer': \"Oh, now don't get all jealous, Ed. I got a little something for you, too. Internal PG&E documents, all about the contamination. The one I like best says, and I'm paraphrasing here, but it says yes, the water's poisonous, but it'd be better for all involved if this matter wasn't discussed with the neighbors. It's to the\", 'gold_tag': \"Erin is involved in the same project as Ed , The project focuses on PG&E's internal documents about water contamination\", 'last_speaker': 'ERIN'}\n",
      "Last word -> ERIN : \"Oh, now don't get all jealous, Ed. I got a little something for you, too. Internal PG&E documents, all about the contamination. The one I like best says, and I'm paraphrasing here, but it says yes, the water's poisonous, but it'd be better for all involved if this matter wasn't discussed with the neighbors. It's to the\"\n",
      "prediction :  I'm sorry. I'm just so sorry. I was in such a rush to get here that I forgot to get you a card. But I wrote your name on it.\n",
      "Real answer : Oh, now don't get all jealous, Ed. I got a little something for you, too. Internal PG&E documents, all about the contamination. The one I like best says, and I'm paraphrasing here, but it says yes, the water's poisonous, but it'd be better for all involved if this matter wasn't discussed with the neighbors. It's to the\n",
      "Bert Score : {'precision': [0.8486058712005615], 'recall': [0.8224748969078064], 'f1': [0.8353360891342163], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22916666666666666, 'rouge2': 0.02127659574468085, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.08131393194811984 0.010677042345905845\n",
      "ppl : 7.8088395427007296\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Hey! I don't know what to say.\\nERIN: Say you were wrong.\\nED: I was wrong.\\nERIN: Say you shortchanged me and you shortchanged yourself.\\nED: I did. Both.\\nERIN: Say you'd be the luckiest son of a bitch on Earth if I didn't up and quit over all this.\\nED: The luckiest son of a bitch in the universe, Erin. The luckiest son of a bitch in history. But I know you're not gonna quit on me.\\nERIN: How do you know that?\\n\\n\", 'answer': 'Cause you got a little voice in your head saying, do the right thing. Give him another chance.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Cause you got a little voice in your head saying, do the right thing. Give him another chance.\"\n",
      "prediction :  I know you're not gonna quit on me because I know you. I know you like I know my own skin, Erin. I know you're not gonna quit on me because I know you're the best person I've ever met.\n",
      "Real answer : Cause you got a little voice in your head saying, do the right thing. Give him another chance.\n",
      "Bert Score : {'precision': [0.8285565972328186], 'recall': [0.8534813523292542], 'f1': [0.8408343195915222], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06451612903225805, 'rouge2': 0.0, 'rougeL': 0.06451612903225805, 'rougeLsum': 0.06451612903225805}\n",
      "bleu 1/2 : 0.05000000000000001 0.011322770341445961\n",
      "ppl : 6.816793013829198\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKENNY: Yes, sir.\\nGREEN: Can I help you?\\nKENNY: Yes, sir. I need a room\\n\\n', 'answer': 'I think we can do that. Come in.', 'gold_tag': 'GREEN is likely an employee or owner of a business , GREEN is possibly associated with a hotel as they are able to provide a room', 'last_speaker': 'GREEN'}\n",
      "Last word -> GREEN : \"I think we can do that. Come in.\"\n",
      "prediction :  We don't have any rooms available.\n",
      "Real answer : I think we can do that. Come in.\n",
      "Bert Score : {'precision': [0.8514835238456726], 'recall': [0.8592122793197632], 'f1': [0.8553304672241211], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 42.56519422728325\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKENNY: Kenneth Fraser. Glad to meet you... My wire's been in the hospital so things might be a little dusty, but You're in music, I guess, aren't you? 'Cause my niece sings most of the day. That won't bother you, will it?\\nGREEN: I didn't think it would. She's calling herself L.A. Joan this- week. Last week it was Dakota. Guess if you have to change your name a state's as good as anything.\\nKENNY: She sure sings nice.\\nGREEN: My wife and I think so, but we're family. Your family's always good or bad depending on how you look at your family. What do you do, pick or sing?\\nKENNY: Oh... a little of both. Just thought I'd look around at Nashville for a while.\\nGREEN: When you run out or money, 'cause you will here, you can go sing at Bishop's Pub. They let you pass the hat. All these kids do that. Most every place doesn't want to bother with you.\\nKENNY: I'm not really a musician.\\nGREEN: Well, don't be shy. I got the address here. Anytime you need it. Room's twenty-five dollar! a week and you can have breakfast with me if you like.\\nKENNY: Suits me. Listen, do you know anything about cars?\\n\\n\", 'answer': \"A little. What do you need? Get ready. We're going to the hospital. we're going.\", 'gold_tag': \"GREEN has some knowledge about cars , KENNY's spouse is in the hospital\", 'last_speaker': 'GREEN'}\n",
      "Last word -> GREEN : \"A little. What do you need? Get ready. We're going to the hospital. we're going.\"\n",
      "prediction :  Nope.\n",
      "Real answer : A little. What do you need? Get ready. We're going to the hospital. we're going.\n",
      "Bert Score : {'precision': [0.9249782562255859], 'recall': [0.8362513780593872], 'f1': [0.8783798813819885], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 520.8555041813767\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGREEN: Sure... you're a fine boy, Ken, you\\nKENNY: Okay... you get to sleep. I'll see you in the morning. Good night.\\n\\n\", 'answer': 'Good night,', 'gold_tag': \"GREEN has a good opinion about KENNY's character\", 'last_speaker': 'GREEN'}\n",
      "Last word -> GREEN : \"Good night,\"\n",
      "prediction :  Good night, Kenny.\n",
      "Real answer : Good night,\n",
      "Bert Score : {'precision': [0.9251201152801514], 'recall': [0.9358536005020142], 'f1': [0.9304559230804443], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.8, 'rouge2': 0.6666666666666666, 'rougeL': 0.8, 'rougeLsum': 0.8}\n",
      "bleu 1/2 : 0.6666666666666666 0.5773502691896257\n",
      "ppl : 233.3149459654341\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARMAND FL�CHARD: Mademoiselle...\\nARABELLA DE CHAVILLE: Tiens, voil� le petit Chopin. A qui ?\\nARMAND FL�CHARD: A toi, mademoiselle.\\n\\n', 'answer': 'Et bien, allons-y, mon vieux.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ARABELLA DE CHAVILLE'}\n",
      "Last word -> ARABELLA DE CHAVILLE : \"Et bien, allons-y, mon vieux.\"\n",
      "prediction :  Ah, the little Chopin... For me, sir.\n",
      "Real answer : Et bien, allons-y, mon vieux.\n",
      "Bert Score : {'precision': [0.8562753796577454], 'recall': [0.7778241038322449], 'f1': [0.8151665925979614], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 176.76225563315768\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARMAND FL�CHARD: Oh, mon billet.\\nARABELLA DE CHAVILLE: Et bien, Tarzan ?\\n\\n', 'answer': 'Travaillons... mademoiselle, travaillons.', 'gold_tag': 'ARMAND FLÉCHARD is involved in some kind of work or job', 'last_speaker': 'ARMAND FL�CHARD'}\n",
      "Last word -> ARMAND FL�CHARD : \"Travaillons... mademoiselle, travaillons.\"\n",
      "prediction :  What is that ?\n",
      "Real answer : Travaillons... mademoiselle, travaillons.\n",
      "Bert Score : {'precision': [0.7966557741165161], 'recall': [0.7492580413818359], 'f1': [0.772230327129364], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 513.8821217893917\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARMAND FL�CHARD: Nous allons attaquer aujourd'hui l'allegretto amoroso. Mais � quoi pensez-vous donc ?\\nARABELLA DE CHAVILLE: Oh, � autre chose. Oh, c'est pas pr�t de m'arriver. D'ailleurs, je n'aimerais jamais qu'un homme d'action, un homme comme moi. Et � Montpaillard... ... il n'y a que des nouilles !\\nARMAND FL�CHARD: Merci beaucoup, mademoiselle. Je suis donc... une nouille.\\nARABELLA DE CHAVILLE: Mais vous �tes de Dijon.\\nARMAND FL�CHARD: Oui, enfin, c'est vite dit, �a.\\n\\n\", 'answer': \"Mais qu'est-ce qu'il y a ?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ARABELLA DE CHAVILLE'}\n",
      "Last word -> ARABELLA DE CHAVILLE : \"Mais qu'est-ce qu'il y a ?\"\n",
      "prediction :  Vous avez donc des amis ?\n",
      "Real answer : Mais qu'est-ce qu'il y a ?\n",
      "Bert Score : {'precision': [0.8110730648040771], 'recall': [0.7897261381149292], 'f1': [0.8002572655677795], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0.16666666666666669 0.05773502691896258\n",
      "ppl : 81.69472117784429\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARMAND FL�CHARD: Au galop, mademoiselle, au galop !\\nARABELLA DE CHAVILLE: Monsieur Fl�chard, comme vous me traitez durement.\\nARMAND FL�CHARD: Oh, et tant pis.\\nARABELLA DE CHAVILLE: Tant mieux. J'aime quand vous �tes m�chant avec moi.\\nARMAND FL�CHARD: Oh !\\nARABELLA DE CHAVILLE: Vous �tes un homme, vous.\\nARMAND FL�CHARD: Non, je suis une nouille ! Allez vous-en... l� !\\nARABELLA DE CHAVILLE: Oh !... Je vais le dire � maman.\\n\\n\", 'answer': \"C'est �a, � votre maman, voil�. Bon...\", 'gold_tag': \"ARMAND FLÉCHARD seems unfazed by ARABELLA DE CHAVILLE's threats\", 'last_speaker': 'ARMAND FL�CHARD'}\n",
      "Last word -> ARMAND FL�CHARD : \"C'est �a, � votre maman, voil�. Bon...\"\n",
      "prediction :  Maman ?\n",
      "Real answer : C'est �a, � votre maman, voil�. Bon...\n",
      "Bert Score : {'precision': [0.8535743951797485], 'recall': [0.8036214709281921], 'f1': [0.8278450965881348], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 4481.554868998832\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARMAND FL�CHARD: Pourquoi ?\\nARABELLA DE CHAVILLE: C'est mon secret. Vous �tes ivre, monsieur Fl�chard.\\n\\n\", 'answer': 'Mais... mais... Arabella... Mademoiselle ! Mais enfin, je... mais...', 'gold_tag': 'Everyday Language', 'last_speaker': 'ARMAND FL�CHARD'}\n",
      "Last word -> ARMAND FL�CHARD : \"Mais... mais... Arabella... Mademoiselle ! Mais enfin, je... mais...\"\n",
      "prediction :  Ivres ?\n",
      "Real answer : Mais... mais... Arabella... Mademoiselle ! Mais enfin, je... mais...\n",
      "Bert Score : {'precision': [0.7978659868240356], 'recall': [0.7521342039108276], 'f1': [0.774325430393219], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3680.1493631950775\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARABELLA DE CHAVILLE: C'est faux.\\nARMAND FL�CHARD: C'est moi qui ai ross� Parju !\\nARABELLA DE CHAVILLE: Vous ? Allons donc !\\nARMAND FL�CHARD: Tenez, la preuve !\\nARABELLA DE CHAVILLE: Je ne vous crois pas.\\nARMAND FL�CHARD: N'emp�che... L'homme qui vous aime dans l'ombre.\\nARABELLA DE CHAVILLE: Vous avez lu mes lettres.\\nARMAND FL�CHARD: C'est moi qui les ai �crites.\\nARABELLA DE CHAVILLE: Mais c'est vous ?\\nARMAND FL�CHARD: Oui.\\nARABELLA DE CHAVILLE: Mais pourquoi ?\\nARMAND FL�CHARD: Mais parce que je vous aime !\\nARABELLA DE CHAVILLE: Comment ?\\nARMAND FL�CHARD: Je vous aime !\\nARABELLA DE CHAVILLE: Quoi ?\\n\\n\", 'answer': 'Je vous aime !', 'gold_tag': 'ARMAND FLÉCHARD harbors feelings for ARABELLA DE CHAVILLE', 'last_speaker': 'ARMAND FL�CHARD'}\n",
      "Last word -> ARMAND FL�CHARD : \"Je vous aime !\"\n",
      "prediction :  C'est vrai. Je vous aime. Je suis tomb� amoureux de vous, Arabella.\n",
      "Real answer : Je vous aime !\n",
      "Bert Score : {'precision': [0.8179416656494141], 'recall': [0.8925900459289551], 'f1': [0.8536369800567627], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.375, 'rouge2': 0.2857142857142857, 'rougeL': 0.375, 'rougeLsum': 0.375}\n",
      "bleu 1/2 : 0.16666666666666669 0.12309149097933275\n",
      "ppl : 50.627564141801265\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARMAND FL�CHARD: Oh oui, Arabella.\\nARABELLA DE CHAVILLE: Vous allez �tre mis en prison ?\\nARMAND FL�CHARD: Oui... Comment donc ? En prison ? Mais j'y vais.\\nARABELLA DE CHAVILLE: Vous feriez �a pour moi ?\\nARMAND FL�CHARD: Oui, Arabella.\\nARABELLA DE CHAVILLE: Tout de suite ?\\n\\n\", 'answer': \"J'y vais. J'y vais !\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ARMAND FL�CHARD'}\n",
      "Last word -> ARMAND FL�CHARD : \"J'y vais. J'y vais !\"\n",
      "prediction :  Non, Arabella.\n",
      "Real answer : J'y vais. J'y vais !\n",
      "Bert Score : {'precision': [0.8730103969573975], 'recall': [0.7634767293930054], 'f1': [0.8145778775215149], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1508.4898734002093\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATHAN: Meditations on a Banana Slug was a delightful read.\\nLILA: Thank you so much. I love slugs. All slugs, not just banana slugs.\\nNATHAN: As do I.\\nLILA: They're so even keel. They forge ahead with slow determination. They don't get distracted or side-tracked. They don't care what they look like. They don't care that people look at\\nNATHAN: They don't seem to be especially ego driven, this is true.\\nLILA: You've got to respect that.\\nNATHAN: I have to say that I'm not there yet.\\nLILA: Where?\\nNATHAN: Slugdom. Sluggishness. Whatever you'd call it. I'm not there yet. I still have many human characteristics.\\nLILA: That's not necessarily a bad thing.\\nNATHAN: Yes. I suppose not. But still. One would like to move along. To move beyond.\\nLILA: I'm not sure we can escape our natures. Believe me I've tried. I'm not even so sure anymore that we should want to.\\nNATHAN: I love that you said that. It makes me feel a bit lighter. I've been rather heavy lately. Thinking about my childhood. Realizing how much a product I am of my upbringing. I've been seeing someone. A therapist.\\nLILA: You are a therapist, right?\\nNATHAN: No no. I'm a psychologist, but I do research. I'm a behaviorist. I work with animals. Mice at the moment.\\nLILA: I hope you don't perform any of those dreadful torture experiments, Nathan.\\nNATHAN: Heavens no. My work now is... Right now I'm teaching mice... well, table manners, to be candid.\\nLILA: How's it going?\\nNATHAN: Quite well, really. It's a lot of work. A lot of reinforcement, mostly positive. Right now I've gotten two of my subjects to use napkins. Tiny napkins of course.\\nLILA: Paper or cloth?\\nNATHAN: I hope you don't think me daft. It's important work. It's part of a larger sociological experiment. I'm federally funded.\\nLILA: What's the larger experiment?\\nNATHAN: It's my thesis that if table manners can be taught to mice, they can be taught to humans.\\nLILA: Going out on a limb, aren't you, Nathan?\\nNATHAN: The truth is most people don't have table manners today. And when the foundations of civilized society crumble and disappear, civilized society in its entirely follows closely at its heels.\\nLILA: I'm not sure.\\nNATHAN: Courtesy, decorum, manners, are all sadly lacking from our daily intercourse. Rudeness, vulgarity, meanness are the norm.\\nLILA: We are animals after all.\\n\\n\", 'answer': 'Ergo if I can teach table manners to mice, I can teach them to humans. If I can teach table manners to humans, I can save the world.', 'gold_tag': \"NATHAN is a behaviorist psychologist who works with animals, particularly mice , The goal of NATHAN's research project is to teach humans the same manners\", 'last_speaker': 'NATHAN'}\n",
      "Last word -> NATHAN : \"Ergo if I can teach table manners to mice, I can teach them to humans. If I can teach table manners to humans, I can save the world.\"\n",
      "prediction :  Yes. I'm afraid you're right.\n",
      "Real answer : Ergo if I can teach table manners to mice, I can teach them to humans. If I can teach table manners to humans, I can save the world.\n",
      "Bert Score : {'precision': [0.8296369314193726], 'recall': [0.8169529438018799], 'f1': [0.8232460618019104], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05714285714285715, 'rouge2': 0.0, 'rougeL': 0.05714285714285715, 'rougeLsum': 0.05714285714285715}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 21.918098221858852\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLILA: It looks wonderful.\\nNATHAN: You look wonderful. I'm on top of the world tonight, Lila. Work is going splendidly and my personal life is ...\\nLILA: Um-mmm. Oh Nathan, this salad is delish...\\nNATHAN: My God! The fork! The fork!\\nLILA: I'm sorry?\\nNATHAN: Tell her, Harold... It's just that... It's nothing. It's just that the outside fork is the\\nLILA: Oh, I'm sorry. I'm sorry, Nathan. I never really learned those things.\\nNATHAN: No biggie.\\nLILA: Boy, this is good!\\nNATHAN: I'm sorry that I became so upset.\\nLILA: No, I'm sorry. I'm really backward in certain areas.\\nNATHAN: It's only that I really enjoy your company and...\\nLILA: You do?\\nNATHAN: Yes, and...\\nLILA: You really enjoy my company?\\nNATHAN: Yes. Please don't talk with food in your mouth, Lila. Please. You're so pretty and it only mars your... I'm sorry. I'm being critical. It's just that I have some peculiarities, and...\\nLILA: I like you, too, Nathan.\\nNATHAN: You do?\\nLILA: Yeah But I have some peculiarities also.\\nNATHAN: I don't care. I don't care! Like what, for example?\\n\\n\", 'answer': 'Like nothing.', 'gold_tag': 'Everyday Language', 'last_speaker': 'LILA'}\n",
      "Last word -> LILA : \"Like nothing.\"\n",
      "prediction :  I'm not sure.\n",
      "Real answer : Like nothing.\n",
      "Bert Score : {'precision': [0.8691887259483337], 'recall': [0.9093011021614075], 'f1': [0.8887925744056702], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 48.78926453800242\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATHAN: Darling, did you bring the insect repellent lotion?\\nLILA: Yes, darling.\\nNATHAN: Oh, and the sun block?\\nLILA: Of course.\\nNATHAN: What SPF, sweetie? Perfectomundo! We are ready! Say, wouldn\\'t it be wonderful to have an insect repellent lotion that also worked as a sun block? Think of all the time one would save.\\nLILA: Yes, darling.\\nNATHAN: I think I\\'ll get Johannsen in chemistry on that. Oh! Did you bring the first aid kit?\\nLILA: Yes.\\nNATHAN: Flares?\\nLILA: Absolutely.\\nNATHAN: We could call it \"Quit Bugging Me, Sunny.\" Get it? Sunny. S-u-n-n-y.\\nLILA: That\\'s very funny.\\n\\n', 'answer': 'I love you so much.', 'gold_tag': 'NATHAN is in a loving relationship with Lila', 'last_speaker': 'NATHAN'}\n",
      "Last word -> NATHAN : \"I love you so much.\"\n",
      "prediction :  I'm glad you think so. I'm a very funny man.\n",
      "Real answer : I love you so much.\n",
      "Bert Score : {'precision': [0.8682597875595093], 'recall': [0.8811357021331787], 'f1': [0.8746503591537476], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.35294117647058826, 'rouge2': 0.0, 'rougeL': 0.35294117647058826, 'rougeLsum': 0.35294117647058826}\n",
      "bleu 1/2 : 0.10000000000000002 0.03333333333333335\n",
      "ppl : 13.693365031973592\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLILA: Did you see that?\\nNATHAN: What?\\nLILA: I don't know. Something.\\nNATHAN: A deer?\\nLILA: No. Too... upright. Might've been a person.\\nNATHAN: It might behoove us to turn back at this point.\\nLILA: Come on.\\n\\n\", 'answer': \"If it's a person, why should we go see it? It's not like it's nature or anything. It's just a person. Sometimes people who live in the woods don't want to be seen. They live in the woods because they're anti-social, Lila. We have to respect that. This is the way to get ticks, Lila. This is it. Bingo! Lyme Disease! You've hit the nail on the head here. Oh for God's sa...\", 'gold_tag': 'NATHAN expresses a desire for privacy , NATHAN shows knowledge about the habits of people who live in remote areas', 'last_speaker': 'NATHAN'}\n",
      "Last word -> NATHAN : \"If it's a person, why should we go see it? It's not like it's nature or anything. It's just a person. Sometimes people who live in the woods don't want to be seen. They live in the woods because they're anti-social, Lila. We have to respect that. This is the way to get ticks, Lila. This is it. Bingo! Lyme Disease! You've hit the nail on the head here. Oh for God's sa...\"\n",
      "prediction :  Are you crazy? We're in the middle of nowhere. We'll never find our way back.\n",
      "Real answer : If it's a person, why should we go see it? It's not like it's nature or anything. It's just a person. Sometimes people who live in the woods don't want to be seen. They live in the woods because they're anti-social, Lila. We have to respect that. This is the way to get ticks, Lila. This is it. Bingo! Lyme Disease! You've hit the nail on the head here. Oh for God's sa...\n",
      "Bert Score : {'precision': [0.8710456490516663], 'recall': [0.8260433673858643], 'f1': [0.8479478359222412], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1414141414141414, 'rouge2': 0.020618556701030927, 'rougeL': 0.10101010101010101, 'rougeLsum': 0.10101010101010101}\n",
      "bleu 1/2 : 0.004185602666398331 0.002501376027092803\n",
      "ppl : 8.050933211057396\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLILA: Who are you? You don't understand my language, do you? I take it back, you do understand my language. Oh God.\\nNATHAN: Oh my God! Is he dead? Please put something on. You'll catch cold. It's cold. What do you suppose he is, a survivalist?\\nLILA: I think he's feral.\\nNATHAN: Feral? Don't touch him! He might be diseased! He might... My God, rabies!\\nLILA: He looks perfectly fine.\\nNATHAN: I think we should go. Please. Before us, or whatever feral things do.\\nLILA: I don't understand you. This is fascinating and you just want to run away. I mean, here we have a human being totally uncontaminated by civilization, totally free, and all you want to do is run back to your...\\nNATHAN: Actually, I just had an amusing thought.\\nLILA: What?\\nNATHAN: Feral, huh? Totally uncontaminated?\\nLILA: Look at him. He doesn't understand\\nNATHAN: It's perfect!\\nLILA: Nathan, what the hell are you talking about?\\nNATHAN: Forget mice! Actually forget guinea pigs, cats, monkeys, and chimps also. I'm on to stage five: The human subject.\\nLILA: Oh no. You can't take him from his home, Nathan.\\nNATHAN: Don't you see? He's my Tabula Rasa, my Eliza Dolittle. He's my ticket to the top of the Behaviorist food chain. He's going to make me famous.\\nLILA: I won't allow you. It's wrong. He's happy here.\\nNATHAN: Is he, Lila? Is he happy living filthy and naked alone in this tick infested wilderness? Never to know the love of a good woman, never to revel in the pitter-patter of little feet, never to read Moby Dick, or marvel at a Monet, or just sit back after a day of hard but rewarding work, smoke a pipe, and wonder about the nature of reality.\\nLILA: You'd be taking away his freedom, Nathan.\\n\\n\", 'answer': \"Freedom's just another word for nothing left to lose, Lila, to quote Janet Jackson. Belonging to something, a person or a society, is a basic human craving. We are communal creatures. This poor soul has no one, nothing...\", 'gold_tag': 'Everyday Language', 'last_speaker': 'NATHAN'}\n",
      "Last word -> NATHAN : \"Freedom's just another word for nothing left to lose, Lila, to quote Janet Jackson. Belonging to something, a person or a society, is a basic human craving. We are communal creatures. This poor soul has no one, nothing...\"\n",
      "prediction :  Freedom? He's free to do what? To eat what? To drink what? To piss in the woods? He's free to live? He's free to die? I'm giving him a chance to live.\n",
      "Real answer : Freedom's just another word for nothing left to lose, Lila, to quote Janet Jackson. Belonging to something, a person or a society, is a basic human craving. We are communal creatures. This poor soul has no one, nothing...\n",
      "Bert Score : {'precision': [0.8212530612945557], 'recall': [0.823425829410553], 'f1': [0.8223380446434021], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16, 'rouge2': 0.0, 'rougeL': 0.16, 'rougeLsum': 0.16}\n",
      "bleu 1/2 : 0.10362863977255007 0.016647305298637286\n",
      "ppl : 8.49452181197459\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATHAN: ...what is it that makes us human, if not the knowledge that we are indeed human? Think of this poor soul's education as the greatest gift we could bestow upon...\\nLILA: All right.\\n\\n\", 'answer': \"Great. Grab his feet. We'll throw him in the trunk.\", 'gold_tag': 'NATHAN is authoritative, giving instructions to LILA', 'last_speaker': 'NATHAN'}\n",
      "Last word -> NATHAN : \"Great. Grab his feet. We'll throw him in the trunk.\"\n",
      "prediction : ... him.\n",
      "Real answer : Great. Grab his feet. We'll throw him in the trunk.\n",
      "Bert Score : {'precision': [0.9234440326690674], 'recall': [0.8849086761474609], 'f1': [0.9037657976150513], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666669, 'rouge2': 0.0, 'rougeL': 0.16666666666666669, 'rougeLsum': 0.16666666666666669}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 406.9011145969563\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLILA: Are you seeing somebody else, Nathan? I just have to know.\\nNATHAN: Of course not.\\nLILA: It would just be helpful to know.\\nNATHAN: No.\\nLILA: Because, you know, you seem so distant. And you work late every night. And we hardly ever have sex, and when we do, it's... I don't know. It feels different.\\nNATHAN: I'm just preoccupied.\\nLILA: Do you like my new look?\\nNATHAN: Yeah. It's nice. It's really good.\\nLILA: I'm trying, you know. I'm trying to be what you want. I want to be what you want, Nathan. All I want is to be what you want.\\nNATHAN: Shh. It's okay. It's okay, Lila. You're what I want. You know that. You're exactly what I want.\\nLILA: Really?\\nNATHAN: Sure. Of course.\\nLILA: Because I'm really trying, you know. Rosie says maybe only another two years of the elctrolysis.\\nNATHAN: That's great.\\nLILA: I've signed up for a ballet class. And look at my nails! A real girl!\\nNATHAN: That's great. It's a great color for you.\\n\\n\", 'answer': \"Oh, Nathan, let's have a baby!\", 'gold_tag': 'LILA is thinking about having a baby', 'last_speaker': 'LILA'}\n",
      "Last word -> LILA : \"Oh, Nathan, let's have a baby!\"\n",
      "prediction :  I feel like I'm losing my mind, Nathan.\n",
      "Real answer : Oh, Nathan, let's have a baby!\n",
      "Bert Score : {'precision': [0.862025260925293], 'recall': [0.8773128986358643], 'f1': [0.8696019053459167], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 27.74043886316719\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLILA: Oh! I didn't see you there, sneaky boy! You're like a boy sneaking in...\\nNATHAN: ...the back door of a movie theater. Yes, indeed.\\nLILA: You remember that from my book? I'm touched! What's wrong?\\nNATHAN: Nothing. Hard day. Gonna have a drink.\\nLILA: I'll make it. I'm so happy, Nathan! Everything's going to be so great! Scotch on the rocks, right? Just kidding. I know what you drink, mister. I know what you drink. Voila!\\nNATHAN: Thanks.\\nLILA: How's work?\\nNATHAN: Cruddy, okay? Are you satisfied?\\nLILA: No. I don't want your work to be cruddy.\\nNATHAN: My assistant quit today. Okay? He was highly valuable to the project.\\nLILA: Oh, baby. I'm sorry. Can't you hire somebody else?\\nNATHAN: I guess.\\nLILA: Hey! I could come work for you! I know I haven't been all that supportive of this project, but I've come around.\\nNATHAN: Have you?\\nLILA: Oh yes, baby! I think that this is a wonderful project you're doing, taking this poor unfortunate, uncivilized creature and turning him into a human being! What a wonderful wonderful compassionate man you are!\\nNATHAN: Really?\\nLILA: Yes! And I want to help. You won't have to pay me, and I was thinking of giving up that crazy nature writing anyway.\\nNATHAN: How come?\\nLILA: Who needs it? I have you and I have being a woman and I have thinking about womanly things! I love being a woman because...\\nNATHAN: Such as what womanly things?\\n\\n\", 'answer': \"Such as my man and how to please him! Such as making wonderful dinners for my man! Such as looking pretty for my man! And I'm writing an article on quilting for the Ladies Home Journal!\", 'gold_tag': 'LILA is enthusiastic about traditional gender roles , LILA is writing an article on quilting for the Ladies Home Journal', 'last_speaker': 'LILA'}\n",
      "Last word -> LILA : \"Such as my man and how to please him! Such as making wonderful dinners for my man! Such as looking pretty for my man! And I'm writing an article on quilting for the Ladies Home Journal!\"\n",
      "prediction :  ...such as you.\n",
      "Real answer : Such as my man and how to please him! Such as making wonderful dinners for my man! Such as looking pretty for my man! And I'm writing an article on quilting for the Ladies Home Journal!\n",
      "Bert Score : {'precision': [0.8664897680282593], 'recall': [0.801051676273346], 'f1': [0.8324866890907288], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1, 'rouge2': 0.05263157894736842, 'rougeL': 0.1, 'rougeLsum': 0.1}\n",
      "bleu 1/2 : 5.567233596748553e-06 2.156180300465357e-06\n",
      "ppl : 578.021757808084\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATHAN: Bravo to you, Puff!\\n\\n', 'answer': 'That was wonderful!', 'gold_tag': 'Everyday Language', 'last_speaker': 'LILA'}\n",
      "Last word -> LILA : \"That was wonderful!\"\n",
      "prediction :  Nathan, do you think you could ever find a way to get a little more sleep?\n",
      "Real answer : That was wonderful!\n",
      "Bert Score : {'precision': [0.8168421983718872], 'recall': [0.8548244833946228], 'f1': [0.8354018926620483], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 26.412580411829886\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATHAN: I'm going to go down and check on Puff. See how he's holding up.\\nLILA: Should I come with?\\nNATHAN: Nah. You just relax. How's the book?\\nLILA: Ummm. It's good.\\n\\n\", 'answer': \"I won't be long.\", 'gold_tag': \"NATHAN's temporal information\", 'last_speaker': 'NATHAN'}\n",
      "Last word -> NATHAN : \"I won't be long.\"\n",
      "prediction :  I'll be right back.\n",
      "Real answer : I won't be long.\n",
      "Bert Score : {'precision': [0.8453918099403381], 'recall': [0.8558027744293213], 'f1': [0.8505654335021973], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4000000000000001, 'rouge2': 0.0, 'rougeL': 0.4000000000000001, 'rougeLsum': 0.4000000000000001}\n",
      "bleu 1/2 : 0.25 0.09128709291752769\n",
      "ppl : 52.10948404977269\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATHAN: Hey.\\nLILA: You were gone a long time.\\nNATHAN: Yeah. Puff and I got into a big, philosophical discussion. He\\'s really quite well read, considering he\\'s only been literate for a month now. He\\'s going to make us famous, Lila.\\nLILA: So he\\'s doing okay?\\nNATHAN: Seemed fine. Quiet evening enjoying\\nLILA: That\\'s funny because, you know, I just went and picked him up at some flophouse on the lower eastside. He called here when he ran out of his \"mad\" money after spending an entire evening drinking, watching strippers, and fucking a whore! Oh, and what did you do tonight, honey?\\nNATHAN: Shit.\\nLILA: And what did you do tonight, honey?\\nNATHAN: I\\'ve fallen in love with somebody else, Lila.\\nLILA: And what did you do tonight, honey?\\nNATHAN: I fucked her! Okay? I fucked her. I\\'m sorry. But that\\'s what the hell I did.\\nLILA: Do you know what I gave up to be with you?\\nNATHAN: Yes.\\nLILA: I gave up my soul, my beliefs. I gave up my body hair!\\nNATHAN: Yeah, well, I\\'m sorry. The human heart is a strange thing.\\nLILA: How the hell would you know anything about the human heart?\\nNATHAN: Lila...\\n\\n', 'answer': \"How's that for ladylike, Nathan.\", 'gold_tag': 'LILA is expressive', 'last_speaker': 'LILA'}\n",
      "Last word -> LILA : \"How's that for ladylike, Nathan.\"\n",
      "prediction :  I'm sorry. I didn't mean to say that out loud. I'm sorry.\n",
      "Real answer : How's that for ladylike, Nathan.\n",
      "Bert Score : {'precision': [0.8378114104270935], 'recall': [0.8159197568893433], 'f1': [0.8267207145690918], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809522, 'rouge2': 0.0, 'rougeL': 0.09523809523809522, 'rougeLsum': 0.09523809523809522}\n",
      "bleu 1/2 : 0.08333333333333333 0.027524094128159027\n",
      "ppl : 7.231514655649958\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTYLER: Next! Oh, no. What do you want?\\nUTAH: Shrimp and fries.\\nTYLER: I mean, what do you want? What are you doing hanging around here.\\nUTAH: I need you to teach me.\\nTYLER: Gimme a break. One shrimp and fries to go! Anything to drink?\\nUTAH: I'm serious.\\nTYLER: I can see that. But forget it. Stick to tennis, or whatever you're good at. Miniature golf. Here, your number's 37.\\nUTAH: Well, I'm just gonna go back out there till I catch on to it or break my neck.\\nTYLER: What is it? You all of a sudden got this bug you had to go surfing? This is a line, right?\\nUTAH: No, no. See, all my life I've done things for other people. In high school I played football because my old man expected me to. Then my parents always figured I'd go to law school, so I did. Football scholarship. Graduated Phi Beta Kappa--\\nTYLER: This gonna take long?\\nUTAH: Wait, so I'm a big hero to my folks, right? But two years ago they got killed in a car wreck and I just suddenly realized all my goals had been their goals. And I hadn't been living my own life. So I wanted something for myself. Something that maybe didn't make any sense. You know what I mean? I came out here from Ohio a month ago. Never saw the ocean before. I didn't think it would effect me so much. Like I'm drawn to it, or something. I want to do what you do. It's the truth.\\nTYLER: Tomorrow, 6 AM. Here. If you're a minute late I'm gone. And Stud... I didn't take you to raise. I can show you a few things but after that you're on your own. That'll be four fifty.\\n\\n\", 'answer': 'Keep the change, Teach.', 'gold_tag': 'Everyday Language', 'last_speaker': 'UTAH'}\n",
      "Last word -> UTAH : \"Keep the change, Teach.\"\n",
      "prediction :  Got it. Thanks.\n",
      "Real answer : Keep the change, Teach.\n",
      "Bert Score : {'precision': [0.9086616039276123], 'recall': [0.8550140857696533], 'f1': [0.8810219168663025], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 305.8125684978934\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nUTAH: Nice place.\\n\\n', 'answer': \"He rents it for the summer. Bodhi always gets some slick place and throws it open to every surf burnout around. Most a these guys can't keep a job. When the swell comes, they're gone, they have to ride.\", 'gold_tag': 'TYLER is aware that Bodhi rents a slick place every summer , TYLER is familiar with the habits of surfer burnouts , TYLER indicates that the event of Bodhi renting the house happens every summer', 'last_speaker': 'TYLER'}\n",
      "Last word -> TYLER : \"He rents it for the summer. Bodhi always gets some slick place and throws it open to every surf burnout around. Most a these guys can't keep a job. When the swell comes, they're gone, they have to ride.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : He rents it for the summer. Bodhi always gets some slick place and throws it open to every surf burnout around. Most a these guys can't keep a job. When the swell comes, they're gone, they have to ride.\n",
      "Bert Score : {'precision': [0.921406626701355], 'recall': [0.8225999474525452], 'f1': [0.8692043423652649], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTYLER: You had enough?\\nUTAH: Yeah. I just want to sit out here for a minute.\\nTYLER: Look at you.\\nUTAH: What?\\nTYLER: Well, usually you have this sort of intense scowl of concentration, like you're doing this for a school project or something... I don't know, like something's driving you. See, it's gone. If I didn't know better I'd say you looked almost\\nUTAH: I... I don't know. I can't describe what I'm feeling.\\nTYLER: You don't have to. Those are cold.\\n\\n\", 'answer': 'Warm them up.', 'gold_tag': 'Everyday Language', 'last_speaker': 'UTAH'}\n",
      "Last word -> UTAH : \"Warm them up.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : Warm them up.\n",
      "Bert Score : {'precision': [0.9430572986602783], 'recall': [0.8979228138923645], 'f1': [0.9199367761611938], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nUTAH: Ouch.\\nTYLER: Betadyne doesn't hurt.\\nUTAH: You're kneeling on my hand.\\nTYLER: So what'd the other guy look like?\\nUTAH: Never saw him, was your basic hit and run.\\nTYLER: But you look like you been in a train wreck, how'd he just drive away? Johnny, what is it with you? You have that look again, it's like you're about to tell me something and then you don't... or you can't. What's going on? What? What do you want to tell me?\\n\\n\", 'answer': \"I'm glad you pulled me out of the water that day...\", 'gold_tag': 'UTAH recalls an incident where TYLER pulled him out of the water', 'last_speaker': 'UTAH'}\n",
      "Last word -> UTAH : \"I'm glad you pulled me out of the water that day...\"\n",
      "prediction :  I'm not sure.\n",
      "Real answer : I'm glad you pulled me out of the water that day...\n",
      "Bert Score : {'precision': [0.8793231248855591], 'recall': [0.8500775694847107], 'f1': [0.8644530773162842], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.14285714285714288, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0.023161150407600514 0.008970274980764192\n",
      "ppl : 48.78926453800242\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPOLLY: Elsie!\\nELSIE: Yes, Mum?\\nPOLLY: Elsie, where have you been?\\n\\n', 'answer': 'In the garden...', 'gold_tag': 'ELSIE was recently in the garden', 'last_speaker': 'ELSIE'}\n",
      "Last word -> ELSIE : \"In the garden...\"\n",
      "prediction :  I've been to see Mr. Blenkinsop, Mum.\n",
      "Real answer : In the garden...\n",
      "Bert Score : {'precision': [0.8261232376098633], 'recall': [0.8400758504867554], 'f1': [0.8330411314964294], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 28.26240478921546\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELSIE: I'm sorry, Joseph. It's all my fault. I didn't mean for any of this to happen...\\nPOLLY: What are you doing in here? This is Joseph's room! My Joseph's room!\\nELSIE: Mummy, you're hurting me!\\n\\n\", 'answer': \"I'm sorry...\", 'gold_tag': 'POLLY immediately shows remorse', 'last_speaker': 'POLLY'}\n",
      "Last word -> POLLY : \"I'm sorry...\"\n",
      "prediction :  It's Elsie, you idiot!\n",
      "Real answer : I'm sorry...\n",
      "Bert Score : {'precision': [0.8300166726112366], 'recall': [0.8405076861381531], 'f1': [0.8352292776107788], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 64.28971700867596\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELSIE: Are they gone?\\n\\n', 'answer': \"On the contrary. They've asked to hear about the fairies.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'POLLY'}\n",
      "Last word -> POLLY : \"On the contrary. They've asked to hear about the fairies.\"\n",
      "prediction :  I think so.\n",
      "Real answer : On the contrary. They've asked to hear about the fairies.\n",
      "Bert Score : {'precision': [0.8588180541992188], 'recall': [0.8436484336853027], 'f1': [0.8511657118797302], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 293.76335955553515\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELSIE: I'm so sorry, Mum. We had to do it this way so you could see them. But they are real...they are.\\n\\n\", 'answer': 'I believe you.', 'gold_tag': \"POLLY's trust in her daughter is strong\", 'last_speaker': 'POLLY'}\n",
      "Last word -> POLLY : \"I believe you.\"\n",
      "prediction :  Oh, my baby.\n",
      "Real answer : I believe you.\n",
      "Bert Score : {'precision': [0.864708423614502], 'recall': [0.888374924659729], 'f1': [0.8763818740844727], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 194.6260484351809\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHELEN: Look. We can leave our coats over there. I want to get rid of this.\\nJENNY: I'm so sorry.\\nHELEN: That's OK. It's nice, isn't it?\\nJENNY: It's beautiful. Where did it come from?\\nHELEN: Oh, South Ken somewhere. This is...Well, it's good for this sort of concert, isn't it?\\nJENNY: Thank you.\\nHELEN: We should go shopping together one day, if you want.\\nJENNY: That would be nice. But South Ken... C'est beaucoup trop cher pour moi.\\nHELEN: Sorry?\\nJENNY: I just said....It was too expensive for me.\\nHELEN: No you didn't. You said something completely different.\\nJENNY: I just...Well, I said it in French.\\nHELEN: In French? Why?\\nJENNY: I don't know.\\nHELEN: Anyway. It's too expensive for me, too. We don't have to worry about that. If you want something\\n\\n\", 'answer': 'Why on earth would he want to take me shopping?', 'gold_tag': 'JENNY is unsure about why a person would want to take her shopping', 'last_speaker': 'JENNY'}\n",
      "Last word -> JENNY : \"Why on earth would he want to take me shopping?\"\n",
      "prediction :  I think it's lovely.\n",
      "Real answer : Why on earth would he want to take me shopping?\n",
      "Bert Score : {'precision': [0.8683058023452759], 'recall': [0.8216925859451294], 'f1': [0.8443562984466553], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 39.42754574486181\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHELEN: There. You'll do. You can keep it. I can only wear so many every day.\\nJENNY: Really? Thank you.\\nHELEN: What about tonight? Will you be needing a nightie? Or not?\\nJENNY: A nightie? Will we be sharing bedrooms?\\nHELEN: You're not sleeping with him?\\nJENNY: No. I'm...No.\\nHELEN: Good for you.\\nJENNY: Really? Do you think so?\\nHELEN: You're only sixteen. And you don't want to get into the family way, do you?\\nJENNY: Oh, I'd make sure that didn't happen. I'm going to do it when I'm seventeen. On my seventeenth birthday, hopefully.\\nHELEN: With David?\\nJENNY: Well...Golly. I suppose it will be with David, won't it?\\n\\n\", 'answer': \"When's your birthday? Oh, he'll be around in April. If that's what you want. Anyway. I'll find you a nightie.\", 'gold_tag': \"JENNY's seventeenth birthday is in April, which is when she plans to have sex for the first time\", 'last_speaker': 'HELEN'}\n",
      "Last word -> HELEN : \"When's your birthday? Oh, he'll be around in April. If that's what you want. Anyway. I'll find you a nightie.\"\n",
      "prediction :  I can't wait to see you with him.\n",
      "Real answer : When's your birthday? Oh, he'll be around in April. If that's what you want. Anyway. I'll find you a nightie.\n",
      "Bert Score : {'precision': [0.8775768280029297], 'recall': [0.8477782011032104], 'f1': [0.8624201416969299], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12121212121212122, 'rouge2': 0.0, 'rougeL': 0.12121212121212122, 'rougeLsum': 0.12121212121212122}\n",
      "bleu 1/2 : 0.027891270018553734 0.00942897021038504\n",
      "ppl : 29.213973534298905\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHELEN: Oh, it's always like this. There are millions of places I've never seen because I've been stuck in here.\\nJENNY: You never get out?\\n\\n\", 'answer': \"There's never anywhere to go in the places they stop.\", 'gold_tag': 'HELEN is dissatisfied with the places she gets to visit', 'last_speaker': 'HELEN'}\n",
      "Last word -> HELEN : \"There's never anywhere to go in the places they stop.\"\n",
      "prediction :  I don't know what it's like out there. I've never been.\n",
      "Real answer : There's never anywhere to go in the places they stop.\n",
      "Bert Score : {'precision': [0.856103241443634], 'recall': [0.8632103800773621], 'f1': [0.8596421480178833], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23999999999999996, 'rouge2': 0.0, 'rougeL': 0.16, 'rougeLsum': 0.16}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 8.915030361711874\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHELEN: They won\\'t be long. Either way.\\nJENNY: \"Either way\"?\\n\\n', 'answer': \"Sometimes they find something, sometimes they don't. And when they do find something, we usually have to leave quite quickly. They can be a bit naughty, sometimes. Anyway. It's nice to have company. I'm usually outside on my own.\", 'gold_tag': 'HELEN often finds herself outside alone , HELEN appreciates company , HELEN has a tolerant attitude towards naughtiness', 'last_speaker': 'HELEN'}\n",
      "Last word -> HELEN : \"Sometimes they find something, sometimes they don't. And when they do find something, we usually have to leave quite quickly. They can be a bit naughty, sometimes. Anyway. It's nice to have company. I'm usually outside on my own.\"\n",
      "prediction :  Just get in the car.\n",
      "Real answer : Sometimes they find something, sometimes they don't. And when they do find something, we usually have to leave quite quickly. They can be a bit naughty, sometimes. Anyway. It's nice to have company. I'm usually outside on my own.\n",
      "Bert Score : {'precision': [0.8638012409210205], 'recall': [0.8284201622009277], 'f1': [0.845740795135498], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 116.5810112298399\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWILLIE: Ready.\\n\\n', 'answer': 'Jesus.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"Jesus.\"\n",
      "prediction :  Come on, Willie, you're not gonna let me win, are ya?\n",
      "Real answer : Jesus.\n",
      "Bert Score : {'precision': [0.7927883863449097], 'recall': [0.917560338973999], 'f1': [0.8506232500076294], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.841400358631192\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMARCUS: How's it goin'?\\nWILLIE: I'm finished when I'm finished.\\nMARCUS: I'm goin' downstairs... I need a melon-bailer and a loofah.\\nWILLIE: Got it.\\n\\n\", 'answer': \"Fuck the loofah, let's go.\", 'gold_tag': 'MARCUS speaks in a directive manner', 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"Fuck the loofah, let's go.\"\n",
      "prediction :  Can you get me one?\n",
      "Real answer : Fuck the loofah, let's go.\n",
      "Bert Score : {'precision': [0.831497311592102], 'recall': [0.8376638293266296], 'f1': [0.8345692157745361], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 125.48739252566166\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWILLIE: I gotta get a drink on. See ya tomorrow.\\nMARCUS: Just don't come in to work stinkin' of booze again.\\nWILLIE: Don't worry about me. Get going, you'll be late for your Wizard of Oz Candy Bar Guild thing.\\nMARCUS: Lollipop Guild, asshole. Jesus, two year olds flip me shit better'n you.\\nWILLIE: You tryin' to say something to me?\\n\\n\", 'answer': \"Yeah. I'm gonna stick my whole fist up your ass.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"Yeah. I'm gonna stick my whole fist up your ass.\"\n",
      "prediction :  Just that I don't need you here.\n",
      "Real answer : Yeah. I'm gonna stick my whole fist up your ass.\n",
      "Bert Score : {'precision': [0.8706151247024536], 'recall': [0.8647300004959106], 'f1': [0.8676626086235046], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473685, 'rouge2': 0.0, 'rougeL': 0.10526315789473685, 'rougeLsum': 0.10526315789473685}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 56.036264932109944\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMARCUS: That\\'s just the kinda shit that\\'s gonna get us pinched!\\nWILLIE: She said she was eighteen.\\nMARCUS: You promised no arcades! You said you\\'d only hustle Big & Tall!\\nWILLIE: Ah, it\\'s like shooting fish in a barrel -- there\\'s no sport,\\nMARCUS: How many times, you fuck? \"The bigger the store, the bigger the take.\" Well, we can\\'t work the big stores with your big fucking train wrecks!\\nWILLIE: You got some nerve you little shit ya! You my mom now?! You shat me out your womb, is that it? You gotta take care of me!? Well I can take care of myself and I don\\'t need no lectures! I know how to keep a low profile!\\nMARCUS: What the fuck is this?!\\nWILLIE: Mind your own fucking business.\\n\\n', 'answer': 'You cocksucker! ...EVER HEAR OF THE OPEN-BOTTLE LAW?! -- You dumb Dipshit Motherfucker!', 'gold_tag': \"MARCUS's language is indicative of a tough, possibly criminal, lifestyle\", 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"You cocksucker! ...EVER HEAR OF THE OPEN-BOTTLE LAW?! -- You dumb Dipshit Motherfucker!\"\n",
      "prediction :  I'm your business.\n",
      "Real answer : You cocksucker! ...EVER HEAR OF THE OPEN-BOTTLE LAW?! -- You dumb Dipshit Motherfucker!\n",
      "Bert Score : {'precision': [0.858085036277771], 'recall': [0.7884048223495483], 'f1': [0.8217704892158508], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 223.80106210778644\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWILLIE: No, I think it's a cop though. You think someone's onto us?\\nMARCUS: Is there anything in the room? Anything professional?\\nWILLIE: No. Clothes.\\n\\n\", 'answer': 'Just ditch. You got anywhere to sack out for a while?', 'gold_tag': 'WILLIE lives a transient lifestyle, indicated by his need to find a temporary place to stay , WILLIE is in a transient situation, needing to find a temporary place to hide', 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"Just ditch. You got anywhere to sack out for a while?\"\n",
      "prediction :  You think he's a cop?\n",
      "Real answer : Just ditch. You got anywhere to sack out for a while?\n",
      "Bert Score : {'precision': [0.8585392832756042], 'recall': [0.8512182235717773], 'f1': [0.8548630475997925], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23529411764705885, 'rouge2': 0.0, 'rougeL': 0.23529411764705885, 'rougeLsum': 0.23529411764705885}\n",
      "bleu 1/2 : 0.12047768476488081 0.030119421191220207\n",
      "ppl : 58.90527206514393\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWILLIE: GOD dammit!\\nMARCUS: You tear your ball again?\\nWILLIE: No, it's okay.\\n\\n\", 'answer': \"Let's do the other thing. There.\", 'gold_tag': 'Shared memories - MARCUS and WILLIE seem to have a shared history of WILLIE frequently experiencing a specific injury or medical condition', 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"Let's do the other thing. There.\"\n",
      "prediction :  You're going to be sorry in the morning.\n",
      "Real answer : Let's do the other thing. There.\n",
      "Bert Score : {'precision': [0.8556627035140991], 'recall': [0.8833327293395996], 'f1': [0.8692775964736938], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.12500000000000003 0.04225771273642583\n",
      "ppl : 27.60419222156992\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWILLIE: I think I've turned a corner.\\nMARCUS: Yeah? You fucking Petites now?\\nWILLIE: No no. No; I beat the crap out of some kids today -- but, you know, for a purpose. It really made me feel pretty good about myself -- like I did something constructive for a change. Accomplished somethin'.\\n\\n\", 'answer': '...You need many years of therapy. Many, many, many, many, many... many fucking years of therapy.', 'gold_tag': 'MARCUS suggests WILLIE needs therapy , MARCUS might have some knowledge about mental health issues', 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"...You need many years of therapy. Many, many, many, many, many... many fucking years of therapy.\"\n",
      "prediction :  What'd you do it for?\n",
      "Real answer : ...You need many years of therapy. Many, many, many, many, many... many fucking years of therapy.\n",
      "Bert Score : {'precision': [0.8240491151809692], 'recall': [0.7863020896911621], 'f1': [0.8047332167625427], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09090909090909091, 'rouge2': 0.0, 'rougeL': 0.09090909090909091, 'rougeLsum': 0.09090909090909091}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 55.235440533743876\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWILLIE: 'Tendo it is. ...Everything I touch turns to shit\\n\\n\", 'answer': \"What are you, drinking Sterno now? 'Cause you're sounding like my Aunt Tilly right before she smeared her own shit on the bedroom walls and we had to lock her up and she spent the rest of her life with a shaved head and eating lunch through a tube up her nose... ...You better be in shape by this evening, fat man. After tonight, I don't give a shit. But this is the time to reach deep down and suck it up. ...Lovely boy.\", 'gold_tag': 'MARCUS has a somewhat antagonistic personality, often deriding and belittling WILLIE , MARCUS has experienced some familial distress, as evidenced by his story about his Aunt Tilly , MARCUS expects WILLIE to be in shape by that evening', 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"What are you, drinking Sterno now? 'Cause you're sounding like my Aunt Tilly right before she smeared her own shit on the bedroom walls and we had to lock her up and she spent the rest of her life with a shaved head and eating lunch through a tube up her nose... ...You better be in shape by this evening, fat man. After tonight, I don't give a shit. But this is the time to reach deep down and suck it up. ...Lovely boy.\"\n",
      "prediction :  You don't have to do this, Willie.\n",
      "Real answer : What are you, drinking Sterno now? 'Cause you're sounding like my Aunt Tilly right before she smeared her own shit on the bedroom walls and we had to lock her up and she spent the rest of her life with a shaved head and eating lunch through a tube up her nose... ...You better be in shape by this evening, fat man. After tonight, I don't give a shit. But this is the time to reach deep down and suck it up. ...Lovely boy.\n",
      "Bert Score : {'precision': [0.8633360266685486], 'recall': [0.7998547554016113], 'f1': [0.830383837223053], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10638297872340426, 'rouge2': 0.021739130434782608, 'rougeL': 0.0851063829787234, 'rougeLsum': 0.0851063829787234}\n",
      "bleu 1/2 : 4.77191451149876e-06 1.152526849778951e-06\n",
      "ppl : 21.943624853676567\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWILLIE: Barbie it is... ...That it?\\nMARCUS: Let's go. ...Oh Christ.\\n\\n\", 'answer': \"Let's do it.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'WILLIE'}\n",
      "Last word -> WILLIE : \"Let's do it.\"\n",
      "prediction :  You know, Marcus, I don't know if you ever thought of it, but you know, if you were to die, you know, it would be a real bummer, don't you think?\n",
      "Real answer : Let's do it.\n",
      "Bert Score : {'precision': [0.791500449180603], 'recall': [0.867516040802002], 'f1': [0.8277667164802551], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.054054054054054064, 'rouge2': 0.0, 'rougeL': 0.054054054054054064, 'rougeLsum': 0.054054054054054064}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 6.066085556122104\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK FURY: How bad is it?\\n\\n', 'answer': \"That's the problem, sir. We don't know.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'AGENT PHIL COULSON'}\n",
      "Last word -> AGENT PHIL COULSON : \"That's the problem, sir. We don't know.\"\n",
      "prediction :  It's not as bad as we thought. We've got some good news.\n",
      "Real answer : That's the problem, sir. We don't know.\n",
      "Bert Score : {'precision': [0.8572296500205994], 'recall': [0.8752378225326538], 'f1': [0.8661401271820068], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17391304347826086, 'rouge2': 0.0, 'rougeL': 0.17391304347826086, 'rougeLsum': 0.17391304347826086}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.294622223358036\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK FURY: Sound the general call. I want every living soul not working rescue looking for that brief case. Roger that. Coulson, get back to base. This is a LEVEL SEVEN. As of right now, we are at war.\\n\\n', 'answer': 'What do we do?', 'gold_tag': 'AGENT PHIL COULSON is a member of the team that responds to the LEVEL SEVEN alert , AGENT PHIL COULSON has a high-ranking role within the organization , AGENT PHIL COULSON is ordered to return to the base immediately', 'last_speaker': 'AGENT PHIL COULSON'}\n",
      "Last word -> AGENT PHIL COULSON : \"What do we do?\"\n",
      "prediction :  I'm on it, sir.\n",
      "Real answer : What do we do?\n",
      "Bert Score : {'precision': [0.8614112138748169], 'recall': [0.8370955586433411], 'f1': [0.8490793108940125], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 50.939956296898025\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nAGENT PHIL COULSON: Sorry, boss. They got rabbited.\\nNICK FURY: Just stay awake. EYES ON ME!\\nAGENT PHIL COULSON: No. I'm clocked out here.\\nNICK FURY: Not an option.\\n\\n\", 'answer': \"It's okay, boss. This was never going to work... if they didn't have something... to...\", 'gold_tag': \"AGENT PHIL COULSON indicates he is 'clocked out,' suggesting a deteriorating health condition or severe fatigue\", 'last_speaker': 'AGENT PHIL COULSON'}\n",
      "Last word -> AGENT PHIL COULSON : \"It's okay, boss. This was never going to work... if they didn't have something... to...\"\n",
      "prediction :  No. I'm off the clock.\n",
      "Real answer : It's okay, boss. This was never going to work... if they didn't have something... to...\n",
      "Bert Score : {'precision': [0.8973290920257568], 'recall': [0.8237691521644592], 'f1': [0.8589771389961243], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 82.80351628079966\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDREW: This is ridiculous.\\n\\n', 'answer': 'Back to work.', 'gold_tag': 'Everyday Language', 'last_speaker': 'D.S.'}\n",
      "Last word -> D.S. : \"Back to work.\"\n",
      "prediction :  What is?\n",
      "Real answer : Back to work.\n",
      "Bert Score : {'precision': [0.8506816029548645], 'recall': [0.8704527616500854], 'f1': [0.8604536056518555], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 842.4769011449364\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDREW: Cops! Somebody called the cops?!?\\n\\n', 'answer': \"Drew! Come with me to San De's chamber... Just Drew.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'D.S.'}\n",
      "Last word -> D.S. : \"Drew! Come with me to San De's chamber... Just Drew.\"\n",
      "prediction :  Well, you gotta be a little careful when you're doing something illegal, Drew.\n",
      "Real answer : Drew! Come with me to San De's chamber... Just Drew.\n",
      "Bert Score : {'precision': [0.8469382524490356], 'recall': [0.8269205093383789], 'f1': [0.8368096351623535], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0.07692307692307693 0.025318484177091663\n",
      "ppl : 17.6171587797033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nD.S.: Try to hit me here with your feet.\\n\\n', 'answer': 'With pleasure.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DREW'}\n",
      "Last word -> DREW : \"With pleasure.\"\n",
      "prediction :  Okay.\n",
      "Real answer : With pleasure.\n",
      "Bert Score : {'precision': [0.9371885657310486], 'recall': [0.8881062269210815], 'f1': [0.9119875431060791], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2086.293093463323\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDREW: We've got to rebuild this?\\n\\n\", 'answer': 'No. Tear it down.', 'gold_tag': 'Everyday Language', 'last_speaker': 'D.S.'}\n",
      "Last word -> D.S. : \"No. Tear it down.\"\n",
      "prediction :  Yes, I'm afraid so.\n",
      "Real answer : No. Tear it down.\n",
      "Bert Score : {'precision': [0.8283398747444153], 'recall': [0.8812036514282227], 'f1': [0.8539544343948364], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 25.787751361808162\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDREW: I can't do it.\\n\\n\", 'answer': \"There is no can't, only won't.\", 'gold_tag': 'D.S. acts as a mentor or coach , D.S. believes in potential and motivation rather than accepting failure', 'last_speaker': 'D.S.'}\n",
      "Last word -> D.S. : \"There is no can't, only won't.\"\n",
      "prediction :  What's the matter?\n",
      "Real answer : There is no can't, only won't.\n",
      "Bert Score : {'precision': [0.859716534614563], 'recall': [0.8278614282608032], 'f1': [0.8434882760047913], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 61.28673303229714\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTACY: There... There's his car. I know he's at work tonight. He hasn't come into Swenson's since he called my house. My mother told him I was still at high school, after I told him I was nineteen. I guess I should tell him I'm fifteen.\\nLINDA: Don't you dare, you'll never hear from him again.\\nSTACY: Does Doug care that you're seventeen?\\nLINDA: Doug sees beyond that stuff to what the person inside is like. That's why I'm marrying him.\\nSTACY: If he ever calls again I'll say I'm eighteen.\\n\\n\", 'answer': 'Boy I am so glad to be through with all these games.', 'gold_tag': 'LINDA is a mature and straightforward person , LINDA dislikes playing games in relationships', 'last_speaker': 'LINDA'}\n",
      "Last word -> LINDA : \"Boy I am so glad to be through with all these games.\"\n",
      "prediction :  Stacy, don't you dare.\n",
      "Real answer : Boy I am so glad to be through with all these games.\n",
      "Bert Score : {'precision': [0.8297718167304993], 'recall': [0.8416919708251953], 'f1': [0.8356894254684448], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 152.89250432444229\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINDA: You've got to get used to working Christmas. People are always screaming and yelling... then they get home and they're all Christmasy.\\nSTACY: I think Christmas brings out the worst in people.\\nLINDA: I guess Ron hasn't called yet.\\nSTACY: Not since November.\\nLINDA: Stacy, it doesn't look good for the relationship.\\nSTACY: Don't you think it meant anything to him. Even if I am fifteen?\\nLINDA: Stacy. What does it matter? He's a stereo salesman. You want to marry him? You want to have kids with him? You want this guy to come home, fifty years old, and he's still got that little Pacific Stereo badge on? Come on.\\nSTACY: I should quit this job. I'm going to get so fat working here... nobody will ever take me out.\\nLINDA: Stacy. How many times do I have to tell you? You are really going to be beautiful... someday.\\nSTACY: Thanks a lot.\\n\\n\", 'answer': \"Hey -- Ron Johnson? It's his loss.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'LINDA'}\n",
      "Last word -> LINDA : \"Hey -- Ron Johnson? It's his loss.\"\n",
      "prediction :  Well, hey, you're not even in high school yet. You're still a kid.\n",
      "Real answer : Hey -- Ron Johnson? It's his loss.\n",
      "Bert Score : {'precision': [0.8484771251678467], 'recall': [0.8547418713569641], 'f1': [0.8515979647636414], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09090909090909091, 'rouge2': 0.0, 'rougeL': 0.09090909090909091, 'rougeLsum': 0.09090909090909091}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.83146762210109\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTACY: What do you think of that guy who works at the theatre? You know, Mark Ratner.\\nLINDA: Oh, come on. What is he? Fifteen?\\nSTACY: Sixteen.\\n\\n', 'answer': 'Just watch out if he pulls up in a van, and then puts on a Led Zeppelin tape.', 'gold_tag': 'LINDA is aware of popular rock band Led Zeppelin , LINDA has a skeptical opinion about Mark, the guy who works at the theatre', 'last_speaker': 'LINDA'}\n",
      "Last word -> LINDA : \"Just watch out if he pulls up in a van, and then puts on a Led Zeppelin tape.\"\n",
      "prediction :  Oh, you're so right. He's just a kid.\n",
      "Real answer : Just watch out if he pulls up in a van, and then puts on a Led Zeppelin tape.\n",
      "Bert Score : {'precision': [0.8641996383666992], 'recall': [0.833358883857727], 'f1': [0.8484991192817688], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.21428571428571427, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.03581309960752377 0.01210703740332595\n",
      "ppl : 21.725054439338766\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTACY: I really thought he would show up. I waited... and waited... and waited...\\nLINDA: That little prick.\\nSTACY: Then I called his house, and his mother told me he was in the garage helping his father.\\nLINDA: That little prick.\\nSTACY: I paid for it and everything.\\nLINDA: There goes your stereo for another year. Mike Damone is a no-brain little prick. I'm not letting him get away with this.\\nSTACY: Don't do anything, Linda. I'd rather just forget about it. I don't even like the guy.\\n\\n\", 'answer': \"Stacy, he's not a guy. He's a little prick!\", 'gold_tag': 'LINDA shows animosity towards those who hurt her friends', 'last_speaker': 'LINDA'}\n",
      "Last word -> LINDA : \"Stacy, he's not a guy. He's a little prick!\"\n",
      "prediction :  I don't want to forget about it. I want to make him pay.\n",
      "Real answer : Stacy, he's not a guy. He's a little prick!\n",
      "Bert Score : {'precision': [0.8757736086845398], 'recall': [0.8697160482406616], 'f1': [0.8727343082427979], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 21.106177963056446\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: What was that?\\nYURI: Oh nothing.\\nJOHN: Tell me.\\nYURI: No. It is too judgmental.\\nJOHN: Tell me what he said.\\nYURI: He says why did you send to Russia for a wife. You are not ashamed of it? It's no surprise to want to love.\\nJOHN: No. It's not that.\\nYURI: Do you believe in love?\\nJOHN: I suppose it's... I mean define your terms.\\n\\n\", 'answer': \"It's very strange. How many people are truly themselves with their love? It is the greatest human disaster and it is never in the newspapers. There are no Marches Against Heartache, no Ministries Against Loneliness, no Concerts Against Disappointment. We look away. And still we know in secret that nothing is more important to us. The one thing we all share but don't say. Look John I will show you something. Here look, something beautiful from Russia. Here is Life, there, take it. Here is bread. Khylep. This is work. We all need this, here eat. Good. But we cannot survive with just work, so here is meat and blood. Myasa. This is family and country, flesh, strength, eat. But again this is not life. Here is joy and pain. Chyesnok. Without these life has no flavour, is too serious. Eat. But this vodka. Is love. Only this magic changes you inside. The moon and the stars and the sun. This is a love song, a soldier's song to his beloved -- Alexei, he's Afghanstya, a veteran of Afghanistan. He saw terrible things.\", 'gold_tag': 'YURI is thoughtful and philosophical , YURI is willing to share her culture and beliefs with JOHN', 'last_speaker': 'YURI'}\n",
      "Last word -> YURI : \"It's very strange. How many people are truly themselves with their love? It is the greatest human disaster and it is never in the newspapers. There are no Marches Against Heartache, no Ministries Against Loneliness, no Concerts Against Disappointment. We look away. And still we know in secret that nothing is more important to us. The one thing we all share but don't say. Look John I will show you something. Here look, something beautiful from Russia. Here is Life, there, take it. Here is bread. Khylep. This is work. We all need this, here eat. Good. But we cannot survive with just work, so here is meat and blood. Myasa. This is family and country, flesh, strength, eat. But again this is not life. Here is joy and pain. Chyesnok. Without these life has no flavour, is too serious. Eat. But this vodka. Is love. Only this magic changes you inside. The moon and the stars and the sun. This is a love song, a soldier's song to his beloved -- Alexei, he's Afghanstya, a veteran of Afghanistan. He saw terrible things.\"\n",
      "prediction :  I mean the real thing.\n",
      "Real answer : It's very strange. How many people are truly themselves with their love? It is the greatest human disaster and it is never in the newspapers. There are no Marches Against Heartache, no Ministries Against Loneliness, no Concerts Against Disappointment. We look away. And still we know in secret that nothing is more important to us. The one thing we all share but don't say. Look John I will show you something. Here look, something beautiful from Russia. Here is Life, there, take it. Here is bread. Khylep. This is work. We all need this, here eat. Good. But we cannot survive with just work, so here is meat and blood. Myasa. This is family and country, flesh, strength, eat. But again this is not life. Here is joy and pain. Chyesnok. Without these life has no flavour, is too serious. Eat. But this vodka. Is love. Only this magic changes you inside. The moon and the stars and the sun. This is a love song, a soldier's song to his beloved -- Alexei, he's Afghanstya, a veteran of Afghanistan. He saw terrible things.\n",
      "Bert Score : {'precision': [0.877068281173706], 'recall': [0.7965193390846252], 'f1': [0.8348554372787476], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.031413612565445025, 'rouge2': 0.0, 'rougeL': 0.020942408376963356, 'rougeLsum': 0.020942408376963356}\n",
      "bleu 1/2 : 1.3841285779600526e-16 3.460321444900132e-17\n",
      "ppl : 181.6279862608844\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nYURI: John. We can see you hiding. How is bank?\\nJOHN: Fine. I thought you were leaving today.\\n\\n', 'answer': \"To be indoors on such a day. It's crime.\", 'gold_tag': 'YURI enjoys outdoor activities', 'last_speaker': 'YURI'}\n",
      "Last word -> YURI : \"To be indoors on such a day. It's crime.\"\n",
      "prediction :  I'm going to stay for a while longer.\n",
      "Real answer : To be indoors on such a day. It's crime.\n",
      "Bert Score : {'precision': [0.8592177629470825], 'recall': [0.8816108107566833], 'f1': [0.8702702522277832], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2105263157894737, 'rouge2': 0.0, 'rougeL': 0.2105263157894737, 'rougeLsum': 0.2105263157894737}\n",
      "bleu 1/2 : 0.11031211282307446 0.03729230060020541\n",
      "ppl : 31.688454586948748\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: Hey.\\n\\n', 'answer': \"He's just having fun. He's maybe too strong you know...\", 'gold_tag': 'Everyday Language', 'last_speaker': 'YURI'}\n",
      "Last word -> YURI : \"He's just having fun. He's maybe too strong you know...\"\n",
      "prediction :  What do you want?\n",
      "Real answer : He's just having fun. He's maybe too strong you know...\n",
      "Bert Score : {'precision': [0.8394176363945007], 'recall': [0.8245879411697388], 'f1': [0.8319367170333862], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.055782540037107455 0.020368903662172547\n",
      "ppl : 82.82606459634773\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nYURI: I understand. I'm so sorry\\nJOHN: You can stay tonight.\\nYURI: I have brought you trouble. Maybe I should have come alone.\\n\\n\", 'answer': 'Good night.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"Good night.\"\n",
      "prediction :  No, it's not your fault. I was in the wrong place at the wrong time.\n",
      "Real answer : Good night.\n",
      "Bert Score : {'precision': [0.8425830006599426], 'recall': [0.8895625472068787], 'f1': [0.8654356598854065], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 10.024329489623053\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: What are you doing?\\nYURI: John, I'm sorry. It's my fault.\\nJOHN: What's he doing? What the fuck are you doing? Leave her alone.\\nYURI: He says sit down. Or he'll cut her. Sit down please.\\nJOHN: Tell him to stop and let her go, and we'll talk. Put the fucking kettle down.\\nYURI: John.\\nJOHN: Put the fucking kettle down. Tell, Yuri, tell him put it down or I'm going to make him.\\nYURI: He says you scare him so much he must go to the toilet in his trousers. John, he is a soldier. A trained killer. We must do what he says.\\nJOHN: What? What does he want? What did he say? Tell me!\\nYURI: He says you are very sad ridiculous man. I don't agree of course. And that you must pay someone to have sex like a prostitute. Nadia is a prostitute. I'm sorry.\\nJOHN: What does he want. The Russian shithead. What do you want ?\\nYURI: He wants money.\\nJOHN: Tell him to put the kettle down and I'll give him money.\\nYURI: He wants a lot of money.\\nJOHN: I'll give him money. Tell him to put the...\\nYURI: He wants the money from your bank.\\nJOHN: I'll fuckin' give it to him! We'll go down there.\\nYURI: You don't understand. He wants all the money that is in your bank.\\nJOHN: I've got eight hundred pounds. Oh Jesus. Oh Jesus.\\nYURI: He is sure you can do this. Of course you can not.\\nJOHN: Oh Jesus. Of course I can't. Just leave her alone.\\nYURI: I'm so sorry.\\n\\n\", 'answer': 'Leave her alone.', 'gold_tag': 'JOHN shows a strong determination to protect', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"Leave her alone.\"\n",
      "prediction :  Just leave her alone.\n",
      "Real answer : Leave her alone.\n",
      "Bert Score : {'precision': [0.9642213582992554], 'recall': [0.9753944277763367], 'f1': [0.9697757363319397], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.8571428571428571, 'rouge2': 0.8, 'rougeL': 0.8571428571428571, 'rougeLsum': 0.8571428571428571}\n",
      "bleu 1/2 : 0.5 0.408248290463863\n",
      "ppl : 305.9254561726352\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBITSEY: His prints were all over the kitchen, including one on the bag.\\nZACK: Half-a-thumb print.\\nBITSEY: Okay, half-a-thumb print.\\nZACK: Could have touched it before it was a murder weapon.\\nBITSEY: Do you fondle your friends' garbage bags?\\nZACK: Yeah, I get very touchy around household plastics. 'Hello, everybody -- ooooh, Tupperware.' Chill. I'm just saying the bag could have been out on the counter or something.\\nBITSEY: Hey, Zack?\\nZACK: Yeah.\\nBITSEY: He did it.\\nZACK: But the murder's way too fucking clumsy. And this guy's a major intellectual. Top of his Yale class, a Rhodes gig, tenured at 27, two books. He's an academic stud.\\nBITSEY: And, empirically speaking, a psychotic.\\nZACK: Look at his wife, she's a regular Grace Kelly. Old money svelte. Father was Ambassador to Spain --\\nBITSEY: Shit! The light's on again.\\nZACK: Ignore it. It's a rental.\\nBITSEY: Thanks, Zack. Do you smell anything?\\nZACK: No. Besides the guy's a flaming liberal.\\nBITSEY: A person's politics has nothing to do with their propensity to commit crime. Aren't we supposed to smell it if it's overheating?\\nZACK: Wrong, seventy-three percent of all serial killers vote republican.\\nBITSEY: Throw the cigarette out so we can smell. No! You'll stink up the car. Throw it out!\\nZACK: I'm not gonna fucking pollute.\\nBITSEY: Zack! We better pull off. Shit, this is so irritating.\\nZACK: How far to Huntsville?\\nBITSEY: Look.\\n\\n\", 'answer': \"'NEWS Magazine reporters Bitsy Bloom and Zack Stemmons entered the rest area with car trouble...\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ZACK'}\n",
      "Last word -> ZACK : \"'NEWS Magazine reporters Bitsy Bloom and Zack Stemmons entered the rest area with car trouble...\"\n",
      "prediction :  It's a little too late for you to start getting all cute on me.\n",
      "Real answer : 'NEWS Magazine reporters Bitsy Bloom and Zack Stemmons entered the rest area with car trouble...\n",
      "Bert Score : {'precision': [0.8284748792648315], 'recall': [0.810183048248291], 'f1': [0.819226861000061], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 21.428908956601795\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBITSEY: Try phone records, a net search.\\nZACK: Fucking better than watching you work. You think he's telling the truth?\\nBITSEY: Don't ask me that. I don't know. There is no truth, only perspectives.\\nZACK: Can't say that. If you say 'there is no truth,' you're claiming it's true that there is no truth -- it's a logical contradiction.\\nBITSEY: Working on our philosophy merit badge, Zack?\\nZACK: I, on the other hand, think Gale's telling the truth.\\nBITSEY: This you know telepathically?\\n\\n\", 'answer': \"It's just my perspective.\", 'gold_tag': 'ZACK trusts his intuition in determining the truth', 'last_speaker': 'ZACK'}\n",
      "Last word -> ZACK : \"It's just my perspective.\"\n",
      "prediction :  No. I don't know anything. I'm just a guy who's been around, seen a lot of shit.\n",
      "Real answer : It's just my perspective.\n",
      "Bert Score : {'precision': [0.8549237251281738], 'recall': [0.8886162042617798], 'f1': [0.8714444041252136], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16000000000000003, 'rouge2': 0.0, 'rougeL': 0.08000000000000002, 'rougeLsum': 0.08000000000000002}\n",
      "bleu 1/2 : 0.0588235294117647 0.019174124721184262\n",
      "ppl : 9.017408615246525\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: Thirty-three o what?\\nBITSEY: Seven. 'Check out the crime scene in Austin.' You made it sound so close. Shit, two and half hours and that damn lig --\\n\\n\", 'answer': 'Bitsey.', 'gold_tag': \"Zack knows about Bitsey's assignment , Zack has a calming influence , Zack tries to pacify Bitsey when she gets exasperated\", 'last_speaker': 'ZACK'}\n",
      "Last word -> ZACK : \"Bitsey.\"\n",
      "prediction :  Oh, you're talking about the case.\n",
      "Real answer : Bitsey.\n",
      "Bert Score : {'precision': [0.841060221195221], 'recall': [0.8519207835197449], 'f1': [0.8464556336402893], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 33.79684260109832\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBITSEY: It was in the case file.\\nZACK: Fuck, in her stomach? That's colder than Wisconsin.\\nBITSEY: Zack, open your vanity.\\nZACK: What?\\nBITSEY: The vanity mirror, pull it down. See that truck behind us?\\nZACK: Yeah.\\nBITSEY: Isn't that the cowboy from the rest area?\\nZACK: Same truck.\\nBITSEY: Weird coincidence, huh?\\n\\n\", 'answer': \"Coincidences are always weird, that's why they're coincidences.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ZACK'}\n",
      "Last word -> ZACK : \"Coincidences are always weird, that's why they're coincidences.\"\n",
      "prediction :  What is?\n",
      "Real answer : Coincidences are always weird, that's why they're coincidences.\n",
      "Bert Score : {'precision': [0.8344669938087463], 'recall': [0.7959579229354858], 'f1': [0.8147576451301575], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 842.4769011449364\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: Fuck. Hey.\\nBITSEY: For God's sake, Zack.\\nZACK: You're not a happy camper.\\nBITSEY: It's not a happy place.\\nZACK: Talked to the Austin prosecutor. Belyeu's a yokel. Prosecutor says he fucked up the penalty phase, says Gale probably would have gotten life on mitigating factors. Gale stuck with him, though, all through appeals, despite major pro bono offers.\\nBITSEY: What else?\\nZACK: Notta on Berlin, we pick up the money in Houston tonight, overheat light came on twice, and you're about to get a surprise.\\nBITSEY: I don't want a surprise.\\n\\n\", 'answer': 'Too late.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ZACK'}\n",
      "Last word -> ZACK : \"Too late.\"\n",
      "prediction :  What kind of surprise?\n",
      "Real answer : Too late.\n",
      "Bert Score : {'precision': [0.8179430961608887], 'recall': [0.8867796659469604], 'f1': [0.8509715795516968], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 381.3976040050285\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: This is mostly an Oklahoma caravan. I got stuck behind them on the way in. Execution's not for another 36 hours. It's gonna be a zoo. There's the P.R. guy.\\nBITSEY: What a life, waiting around for someone to die.\\nZACK: Fuck, look.\\n\\n\", 'answer': 'This is a little too coincidental.', 'gold_tag': \"BITSEY's outlook on life is somewhat cynical and detached\", 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"This is a little too coincidental.\"\n",
      "prediction :  Hey, what's wrong?\n",
      "Real answer : This is a little too coincidental.\n",
      "Bert Score : {'precision': [0.8445946574211121], 'recall': [0.8310245275497437], 'f1': [0.8377547264099121], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 30.37965253612474\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: 'Cause I couldn't see the license plate.\\nBITSEY: Forget it. What time is it?\\nZACK: 6:05. Why don't you have a watch?\\n\\n\", 'answer': \"It's a long story.\", 'gold_tag': 'BITSEY does not carry a watch , BITSEY has a significant story behind her not wearing one', 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"It's a long story.\"\n",
      "prediction :  I do have a watch. But I don't like to wear it.\n",
      "Real answer : It's a long story.\n",
      "Bert Score : {'precision': [0.8724328279495239], 'recall': [0.874512791633606], 'f1': [0.8734715580940247], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2222222222222222, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0.08333333333333333 0.027524094128159027\n",
      "ppl : 16.715742446937476\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: What!?\\nBITSEY: It's open.\\nZACK: So? Maybe the maid forgot.\\n\\n\", 'answer': 'Look!', 'gold_tag': 'Everyday Language', 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"Look!\"\n",
      "prediction :  No. It's open.\n",
      "Real answer : Look!\n",
      "Bert Score : {'precision': [0.9142307639122009], 'recall': [0.8835775852203369], 'f1': [0.8986427783966064], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 151.95557076829277\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: I'll check the bathroom. Clear in here! Don't touch it! Fuck, Bitsey, there could have been prints.\\n\\n\", 'answer': 'Look.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"Look.\"\n",
      "prediction :  What do you think?\n",
      "Real answer : Look.\n",
      "Bert Score : {'precision': [0.7952632904052734], 'recall': [0.9270861744880676], 'f1': [0.8561301231384277], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 53.25875838002556\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: Let's say Gale's right. Some sick- fuck-Agatha Christie-wannabe set him up, arranged like the perfect murder. Why send a magazine journalist proof a few hours before he's won? Doesn't make sense.\\nBITSEY: No, it's perfect. He knows News Magazine won't give the scoop to the dailies or nightly news, not after having paid for it. Probably guessed we wouldn't call the cops. And, most importantly, knows I'll tell Gale tomorrow.\\nZACK: Why does he give a shit?\\nBITSEY: Zack, what if Harraway's murder was just a means to getting Gale. I mean sending him through hell, a sick cat and mouse game. You kill the one person he has left. Make sure he sits six years on death row for the murder -- a place he's made a public career of loathing. And then just let him die, die knowing everyone will remember him with disgust. You destroy his loved ones, his life's work, his memory -- and you make him watch.\\nZACK: That's a lot of hate. You're talking beyond sadism. Then why release it?\\nBITSEY: If the mouse dies the game's over. Maybe the cat's enjoying himself. Or...\\nZACK: Or?\\nBITSEY: Imagine walking to the chamber knowing this exists.\\nZACK: The 'cat' is a fucking psychopath.\\n\\n\", 'answer': 'Yeah, but smart.', 'gold_tag': 'Bitsey is analytical', 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"Yeah, but smart.\"\n",
      "prediction :  That's why I want to find out who did it.\n",
      "Real answer : Yeah, but smart.\n",
      "Bert Score : {'precision': [0.844345211982727], 'recall': [0.8749946355819702], 'f1': [0.859396755695343], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.94597667398105\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBITSEY: Did you see the cowboy go in?\\nZACK: He went in Belyeu's building?\\nBITSEY: Into his office. Just saw him.\\nZACK: Fuck!\\nBITSEY: Follow him. Find out who he is, where he lives -- what he --\\nZACK: How are you gonna get to Ellis?\\n\\n\", 'answer': 'A taxi.', 'gold_tag': 'BITSEY suggests taking a taxi, implying she might be in a rush due to the urgency of the situation', 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"A taxi.\"\n",
      "prediction :  I don't know. I'm not gonna get to him. I'm gonna get to the guy that's got the information.\n",
      "Real answer : A taxi.\n",
      "Bert Score : {'precision': [0.8287791013717651], 'recall': [0.8886860013008118], 'f1': [0.8576877117156982], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 10.738708984436935\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBITSEY: Zack! Wake up! Get up! Did you throw the towel on the floor?\\nZACK: What?\\nBITSEY: The towel on my bathroom floor. Did you put it there?\\nZACK: Yeah, I guess. It's a hotel room. What --\\nBITSEY: Do you do that at home?\\nZACK: No. Fuck, Bitsey. I'm sorry, it's not like it's --\\nBITSEY: Get up.\\nZACK: What the fuck's wrong with you?\\nBITSEY: Grab the T.V. I want to check something.\\nZACK: What?\\nBITSEY: We're taking a tour.\\nZACK: Where?\\n\\n\", 'answer': 'Austin. Get the T.V.', 'gold_tag': 'BITSEY could be staying at a hotel at the moment', 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"Austin. Get the T.V.\"\n",
      "prediction :  The T.V.!\n",
      "Real answer : Austin. Get the T.V.\n",
      "Bert Score : {'precision': [0.9323676228523254], 'recall': [0.936356246471405], 'f1': [0.9343576431274414], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.7499999999999999, 'rouge2': 0.6666666666666666, 'rougeL': 0.7499999999999999, 'rougeLsum': 0.7499999999999999}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 407.7100341028221\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: Hairy.\\n\\n', 'answer': 'Come on.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"Come on.\"\n",
      "prediction :  Hairy?\n",
      "Real answer : Come on.\n",
      "Bert Score : {'precision': [0.8396275043487549], 'recall': [0.895676851272583], 'f1': [0.8667469620704651], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 861.2248477292591\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBITSEY: ...Because of the Berlin thing, Constance knew the police would go whose life was shit anyway. But...\\nZACK: She was in love with him.\\n\\n', 'answer': \"I don't know. Something. They were close. She wouldn't want him dead.\", 'gold_tag': 'BITSEY engages in thoughtful dialogue about the situation involving Constance and the man she was close with', 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"I don't know. Something. They were close. She wouldn't want him dead.\"\n",
      "prediction :  Yes.\n",
      "Real answer : I don't know. Something. They were close. She wouldn't want him dead.\n",
      "Bert Score : {'precision': [0.9200605154037476], 'recall': [0.8348712921142578], 'f1': [0.8753982186317444], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2104.611116571625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBITSEY: Remember this thing about Dusty being a bull-horner, going to far?\\nZACK: Why he was fired from DeathWatch, and the A.C.L.U.\\nBITSEY: Right. Maybe the plan was for Dusty to release the tape after Gale's conviction, after a year or so. You know, force him to dry out, let him play the heroic victim, give him back his dignity. So, Dusty Wright's sitting on this tape, waiting, the only one who knows about it. And maybe good ole Dusty starts to think that an erroneous execution is a hell of a lot more politically useful than a last-minute save.\\nZACK: Which would only prove the system works.\\nBITSEY: Yeah. Almost martyrs don't count. What's one murder to stop thousands?\\nZACK: So he'll wait, release the whole tape after the execution.\\n\\n\", 'answer': 'Right. Somewhere he must have the original. What time is it?', 'gold_tag': 'BITSEY is possibly involved in investigative or strategy-based work', 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"Right. Somewhere he must have the original. What time is it?\"\n",
      "prediction :  Right. He'll wait.\n",
      "Real answer : Right. Somewhere he must have the original. What time is it?\n",
      "Bert Score : {'precision': [0.915986955165863], 'recall': [0.8609840869903564], 'f1': [0.88763427734375], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.26666666666666666, 'rouge2': 0.0, 'rougeL': 0.26666666666666666, 'rougeLsum': 0.26666666666666666}\n",
      "bleu 1/2 : 0.023161150407600514 0.008970274980764192\n",
      "ppl : 266.92786023734715\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBITSEY: Don't move from the booth. Call the second you see the truck. Remember, let it ring just once. Then get into the woods --\\nZACK: I know. Go.\\nBITSEY: Into the woods, Zack.\\n\\n\", 'answer': 'Go!', 'gold_tag': \"BITSEY and ZACK seem to have prior experience with this drill, as indicated by BITSEY's instructions and ZACK's quick understanding.\", 'last_speaker': 'ZACK'}\n",
      "Last word -> ZACK : \"Go!\"\n",
      "prediction :  I know.\n",
      "Real answer : Go!\n",
      "Bert Score : {'precision': [0.8915202021598816], 'recall': [0.8563527464866638], 'f1': [0.873582661151886], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 663.9337011017111\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBITSEY: Everyone! Wake up New York, the warden, the Governor, the goddamn Supreme Court death clerk! How far is it?\\nZACK: Took me 30 this afternoon. You've got 26, maybe more.\\n\\n\", 'answer': \"I'll make it.\", 'gold_tag': \"BITSEY's temporal information\", 'last_speaker': 'BITSEY'}\n",
      "Last word -> BITSEY : \"I'll make it.\"\n",
      "prediction :  26 miles, you're right. You're right. I'm going to take the rest of the night off. I'm not going to do anything else.\n",
      "Real answer : I'll make it.\n",
      "Bert Score : {'precision': [0.8438687920570374], 'recall': [0.8825681209564209], 'f1': [0.8627848029136658], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06451612903225806, 'rouge2': 0.0, 'rougeL': 0.06451612903225806, 'rougeLsum': 0.06451612903225806}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 8.191538492510047\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBEN: You crying?\\nELENA: I'm just sad Ben -- I mean it was... you were, but, you know. I just don't know...\\nBEN: Whatever that means Elena -- And you complain about me not communicating... I thought it was --\\nELENA: No, I didn't mean to sound negative. It was -- But Ben. What is going to happen with us? Have you --\\nBEN: You have to bring this up now? What? Did I do something here? Is that it? Is it something I did?\\nELENA: I wasn't accusing you, Ben. It's just that we've got to be honest. Not just with ourselves, but with\\nBEN: Hell, I know. I -- I guess if you want to accuse me, you've got -- Oh hell! I've got to pick up Paul. I almost forgot.\\nELENA: You were saying?\\nBEN: Yikes -- I was hoping to wear this thing to the Halford's Friday.\\nELENA: That shirt?\\nBEN: What?\\n\\n\", 'answer': \"Leave it -- I'll wash it for you.\", 'gold_tag': 'Elena is willing to help Ben by washing his shirt for him', 'last_speaker': 'ELENA'}\n",
      "Last word -> ELENA : \"Leave it -- I'll wash it for you.\"\n",
      "prediction :  It's the most beautiful shirt I've ever seen.\n",
      "Real answer : Leave it -- I'll wash it for you.\n",
      "Bert Score : {'precision': [0.8438982367515564], 'recall': [0.8436596989631653], 'f1': [0.8437789678573608], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.22222222222222224, 'rougeLsum': 0.22222222222222224}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.197780081151755\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELENA: The turkey in?\\n\\n', 'answer': 'Stuffed and baking.', 'gold_tag': 'BEN is involved in cooking , Cooking indicates his domestic side', 'last_speaker': 'BEN'}\n",
      "Last word -> BEN : \"Stuffed and baking.\"\n",
      "prediction :  Yeah, he's in.\n",
      "Real answer : Stuffed and baking.\n",
      "Bert Score : {'precision': [0.8713411092758179], 'recall': [0.853787899017334], 'f1': [0.8624751567840576], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 65.99028171459744\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELENA: Oh lord. You think I'm so dense. And now you want to be seen with your dense wife at the cocktail party. You want to wear that with those pants at all. You want to wear that, and you want me to shake hands with your friends and accord me the respect of talking honestly about this... You don't\\nBEN: Sure I do. Do I know what loneliness feels like? Sure I do. I know a lot about it, if that's what you mean.\\n\\n\", 'answer': \"Benjamin. That's supposed to explain it?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ELENA'}\n",
      "Last word -> ELENA : \"Benjamin. That's supposed to explain it?\"\n",
      "prediction :  You know about loneliness?\n",
      "Real answer : Benjamin. That's supposed to explain it?\n",
      "Bert Score : {'precision': [0.8588466048240662], 'recall': [0.8570960760116577], 'f1': [0.8579704165458679], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 169.07106314101202\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROXANNE: Do you miss your home, Captain? Have you someone there?\\nWILLARD: No. Not really. I was discharged from the army four years ago. I went home, wasted some time, bought a Mustang Mach 1, drove it a week. Then I re-upped for another tour. No, everything I love is here.\\nROXANNE: Then you are like us. What will you do after the war?\\nWILLARD: I just follow my footsteps, one at a time, trying to answer the little questions and staying away from the big ones.\\nROXANNE: What's a big question?\\nWILLARD: Kurtz. I know you've heard of him.\\nROXANNE: Yes.\\nWILLARD: What did you hear?\\nROXANNE: That strange things.. terrible things have occured around this American, Kurtz.\\nWILLARD: What things?\\nROXANNE: Gaston would never tell me. It was asubject not to be spoken of, Captain.\\nWILLARD: Yes.\\nROXANNE: Did you know -- deeper in the jungle, upriver -- there are savages?\\nWILLARD: I know.\\n\\n\", 'answer': \"But Captain, I mean -- cannibals. What a pity, you don't drink. Since my husband died, there are so many things I must do alone.\", 'gold_tag': \"ROXANNE is a widow who has to do many things alone since her husband's death , WILLARD is sober and doesn't drink\", 'last_speaker': 'ROXANNE'}\n",
      "Last word -> ROXANNE : \"But Captain, I mean -- cannibals. What a pity, you don't drink. Since my husband died, there are so many things I must do alone.\"\n",
      "prediction : And you are going to find him?\n",
      "Real answer : But Captain, I mean -- cannibals. What a pity, you don't drink. Since my husband died, there are so many things I must do alone.\n",
      "Bert Score : {'precision': [0.8450202941894531], 'recall': [0.8368686437606812], 'f1': [0.8409246802330017], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.021836081997362308 0.005273914848074366\n",
      "ppl : 53.604457807347586\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROXANNE: Are you warm, Captain?\\nWILLARD: The river is beautiful.\\n\\n', 'answer': 'I spend hours watching that river from my bedroom window. It fascinates me.', 'gold_tag': 'ROXANNE spends hours watching the river from her bedroom window , ROXANNE has a contemplative or introspective nature', 'last_speaker': 'ROXANNE'}\n",
      "Last word -> ROXANNE : \"I spend hours watching that river from my bedroom window. It fascinates me.\"\n",
      "prediction :  I can't believe it.\n",
      "Real answer : I spend hours watching that river from my bedroom window. It fascinates me.\n",
      "Bert Score : {'precision': [0.8787806034088135], 'recall': [0.8655236959457397], 'f1': [0.8721017837524414], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2222222222222222, 'rouge2': 0.0, 'rougeL': 0.2222222222222222, 'rougeLsum': 0.2222222222222222}\n",
      "bleu 1/2 : 0.026349806140466083 0.009621588806014277\n",
      "ppl : 40.57476084568562\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROXANNE: I will fix you breakfast.\\nWILLARD: I'm afraid I won't have time -- I gotta --\\nROXANNE: Whe you reach the boat you will find that half your fifty calibre stores -- a case of grenades, a mortar and two M-16's and a case of clips are being transfered to us by your order.\\nWILLARD: So that's it.\\nROXANNE: You may think what you wish, Captain, but I like you very much.\\nWILLARD: What if I say no.\\n\\n\", 'answer': 'Then Philippe will have to kill all of you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROXANNE'}\n",
      "Last word -> ROXANNE : \"Then Philippe will have to kill all of you.\"\n",
      "prediction :  I can't make you.\n",
      "Real answer : Then Philippe will have to kill all of you.\n",
      "Bert Score : {'precision': [0.8967342376708984], 'recall': [0.8661916255950928], 'f1': [0.8811984062194824], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.07162619921504752 0.02615419001229357\n",
      "ppl : 92.50702820183514\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMcCALEB: What do you got going tomorrow?\\nBUDDY: Same as always. egg.\\nMcCALEB: I need a driver for a few days. Ten bucks an hour plus meals.\\nBUDDY: What is it, an investigation?\\nMcCALEB: I’m looking for a driver, Buddy, not a partner.\\nBUDDY: Okay. I’m in. Whose car.\\nMcCALEB: We take yours, I pay for gas. We take mine, I sit in the back.\\nBUDDY: Right, cuz of your chest, right? Let’s take mine. too much of a chauffeur with you\\nMcCALEB: See you in the morning.\\n\\n', 'answer': 'You look tired, McCaleb. You should get some sleep.', 'gold_tag': 'McCALEB appears to be tired in the present', 'last_speaker': 'BUDDY'}\n",
      "Last word -> BUDDY : \"You look tired, McCaleb. You should get some sleep.\"\n",
      "prediction :  I’m in.\n",
      "Real answer : You look tired, McCaleb. You should get some sleep.\n",
      "Bert Score : {'precision': [0.8697017431259155], 'recall': [0.856166422367096], 'f1': [0.8628809452056885], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 229.3154686887029\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMcCALEB: Hey, Buddy! You’re working tomorrow. Six AM.\\n\\n', 'answer': 'Cool. Aww shit, Terry!', 'gold_tag': 'BUDDY works the early shift', 'last_speaker': 'BUDDY'}\n",
      "Last word -> BUDDY : \"Cool. Aww shit, Terry!\"\n",
      "prediction :  Yeah. I’ll be there.\n",
      "Real answer : Cool. Aww shit, Terry!\n",
      "Bert Score : {'precision': [0.883637547492981], 'recall': [0.8600532412528992], 'f1': [0.8716859221458435], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 67.2365918460467\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBUDDY: Who wants to go to the desert anyhow?\\nMcCALEB: You go where the clues lead.\\n\\n', 'answer': 'Don’t any clues lead to the beach for crying out loud?!', 'gold_tag': 'BUDDY prefers going to the beach', 'last_speaker': 'BUDDY'}\n",
      "Last word -> BUDDY : \"Don’t any clues lead to the beach for crying out loud?!\"\n",
      "prediction :  What clues?\n",
      "Real answer : Don’t any clues lead to the beach for crying out loud?!\n",
      "Bert Score : {'precision': [0.8875170946121216], 'recall': [0.8171396255493164], 'f1': [0.8508755564689636], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 855.6024000553664\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMcCALEB: Shit... What do you figure I owe you, Buddy?\\nBUDDY: Um, about two hundred or so.\\nMcCALEB: Sounds right.\\nBUDDY: You look like shit, Terry. You should take a nap or something.\\nMcCALEB: You take a check?\\nBUDDY: Sure.\\nMcCALEB: I’ll bring it over. Should I make it out to Buddy?\\nBUDDY: Jasper. Jasper Noone.\\nMcCALEB: I knew the Noone part.\\n\\n', 'answer': 'I look more like a Buddy than a Jasper, huh? Take a nap!', 'gold_tag': \"BUDDY is informal and casual, showing concern for McCALEB's health\", 'last_speaker': 'BUDDY'}\n",
      "Last word -> BUDDY : \"I look more like a Buddy than a Jasper, huh? Take a nap!\"\n",
      "prediction : I wish I could’ve seen you, Terry.\n",
      "Real answer : I look more like a Buddy than a Jasper, huh? Take a nap!\n",
      "Bert Score : {'precision': [0.8517800569534302], 'recall': [0.8435527086257935], 'f1': [0.8476464152336121], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809525, 'rouge2': 0.0, 'rougeL': 0.09523809523809525, 'rougeLsum': 0.09523809523809525}\n",
      "bleu 1/2 : 0.06062469223956427 0.020707274552675604\n",
      "ppl : 33.59322556833214\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLUKE: You ask me that counselor's making a mountain out of a molehill...\\nJACKIE: I'm worried.\\nLUKE: Me too.\\nJACKIE: Luke, I need to switch next Friday for Thursday, so why don't you take the weekend... ...that way you'll be there, and I'll pick up Monday, Tuesday, and Wednesday.\\nLUKE: Fine. But I wanted to take the kids to work with me on Wednesday so I'll take Wednesday, and you can pick up that Thursday, Friday after soccer, and Saturday before riding.\\nJACKIE: Easy enough.\\n\\n\", 'answer': 'Good...Well...Take care.', 'gold_tag': 'LUKE agrees to take the children on the upcoming weekend and on Wednesday', 'last_speaker': 'LUKE'}\n",
      "Last word -> LUKE : \"Good...Well...Take care.\"\n",
      "prediction :   I'm not going to have time to work on it.\n",
      "Real answer : Good...Well...Take care.\n",
      "Bert Score : {'precision': [0.8497449159622192], 'recall': [0.8345674872398376], 'f1': [0.8420878648757935], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.503800313722447\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACKIE: You know, you can come inside the house.\\nLUKE: Did you see the lawyer? Oh. Well...\\nJACKIE: Called him. We set an ap...\\nLUKE: Don't do this.\\nJACKIE: You're saying, don't make the kids a football, don't put them through a war. But I'm doing this for their well-being.\\nLUKE: Partly. But partly, you're mad. You know the kids aren't really in danger. This is about Rachel, and you're right, I'm disappointed in her learning curve, and...\\nJACKIE: Slugs. Have faster learning curves. Trees, even.\\nLUKE: I'm afraid she's going to walk.\\nJACKIE: And I'm supposed to care.\\nLUKE: About me, yeh. Like I care about you.\\nJACKIE: Like you cared about me three years ago?\\nLUKE: Hey. You kicked me out.\\nJACKIE: Maybe you should talk to your daughter, about why. She seems to have missed that part. Forget I said that.\\nLUKE: This thing with Rache. I need this. I don't want to lose her. And I will see to it that the kids don't suffer. Help me, huh? I'd do it for you.\\n\\n\", 'answer': \"One last chance, don't make me regret it... ...or you will, too.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'JACKIE'}\n",
      "Last word -> JACKIE : \"One last chance, don't make me regret it... ...or you will, too.\"\n",
      "prediction :  I'm not asking you to do anything.\n",
      "Real answer : One last chance, don't make me regret it... ...or you will, too.\n",
      "Bert Score : {'precision': [0.8802992105484009], 'recall': [0.8328773379325867], 'f1': [0.8559319376945496], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809525, 'rouge2': 0.0, 'rougeL': 0.09523809523809525, 'rougeLsum': 0.09523809523809525}\n",
      "bleu 1/2 : 0.06993452279385044 0.023887187063648833\n",
      "ppl : 22.88103472911671\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACKIE: I thought a phone call was inappropriate. I could have taken you to that restaurant, but it would have been a waste of money. I know. I wouldn't know what to say. If it were you.\\nLUKE: We're going to win this.\\nJACKIE: Walk in the park. And thanks for the 'we'.\\nLUKE: You're not alone in this. You're not alone. Jesus, you're not alone, okay? What happens next?\\nJACKIE: I live or I die.\\nLUKE: Tell the kids together? Want Rache someplace else?\\n\\n\", 'answer': 'My compliments. On your learning curve.', 'gold_tag': 'LUKE receives compliments from Jackie regarding his learning curve', 'last_speaker': 'JACKIE'}\n",
      "Last word -> JACKIE : \"My compliments. On your learning curve.\"\n",
      "prediction :  No.\n",
      "Real answer : My compliments. On your learning curve.\n",
      "Bert Score : {'precision': [0.9310479760169983], 'recall': [0.8785929679870605], 'f1': [0.9040602445602417], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1275.3241709894667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHERRICK: You're early, Mr. Rus. Again, pick it up at bar twenty-four. Where were you, Mr. Rus?\\nRUS: Sorry.\\nHERRICK: And Miss Lubbers, could you find a key closer to the one the rest of us are using? Thank you. People, let's try to start together. Again, from bar twenty- four. Mr. Rus, if you would, please. Let's walk and talk. Mr. Rus, I thought you said you could read music.\\n\\n\", 'answer': \"I can, when it has words. This stuff's got no words. Herrick looks like he just crapped a pineapple.\", 'gold_tag': 'RUS struggles with reading music without words', 'last_speaker': 'RUS'}\n",
      "Last word -> RUS : \"I can, when it has words. This stuff's got no words. Herrick looks like he just crapped a pineapple.\"\n",
      "prediction :  I can.\n",
      "Real answer : I can, when it has words. This stuff's got no words. Herrick looks like he just crapped a pineapple.\n",
      "Bert Score : {'precision': [0.9570918083190918], 'recall': [0.8360835313796997], 'f1': [0.8925046920776367], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.1, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0.00010173418450532208 4.5496910437881206e-05\n",
      "ppl : 1003.4219990433002\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHERRICK: E - G - B - D - F... It's easy to remember. Every Good Boy Does Fine. F - A - C - E... Face, that's easy enough. Those are the notes.\\nRUS: It's like a code.\\n\\n\", 'answer': \"Exactly! And you have to know that code because it's telling you where to come in. Exactly!\", 'gold_tag': 'HERRICK has knowledge of reading musical notes', 'last_speaker': 'HERRICK'}\n",
      "Last word -> HERRICK : \"Exactly! And you have to know that code because it's telling you where to come in. Exactly!\"\n",
      "prediction :  That's right.\n",
      "Real answer : Exactly! And you have to know that code because it's telling you where to come in. Exactly!\n",
      "Bert Score : {'precision': [0.8783114552497864], 'recall': [0.8314876556396484], 'f1': [0.8542584180831909], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1904761904761905, 'rouge2': 0.0, 'rougeL': 0.1904761904761905, 'rougeLsum': 0.1904761904761905}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 65.67370267700424\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHERRICK: Just sing the notes on the page.\\nRUS: I sing like shit... sorry, Mr. Herrick. I sing like... you know.\\nHERRICK: I'm not auditioning you for the Metropolitan opera. Just sing the notes.\\nRUS: Okay.\\n\\n\", 'answer': \"That's a sharp. Go on.\", 'gold_tag': 'HERRICK is knowledgeable about singing and musical notation', 'last_speaker': 'HERRICK'}\n",
      "Last word -> HERRICK : \"That's a sharp. Go on.\"\n",
      "prediction :  That's good.\n",
      "Real answer : That's a sharp. Go on.\n",
      "Bert Score : {'precision': [0.911622166633606], 'recall': [0.8959922790527344], 'f1': [0.9037396907806396], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4444444444444444, 'rouge2': 0.28571428571428575, 'rougeL': 0.4444444444444444, 'rougeLsum': 0.4444444444444444}\n",
      "bleu 1/2 : 0.11156508007421491 0.04989342059223037\n",
      "ppl : 88.55636485172964\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRUS: Da-da-da-da-da-de-de-dum.. Herrick isn't really listening. Da-dum-da-dum-da-da-da... Da-da-dum-dum-de. BOOM! BOOM! Da-da-da-daah! Converted to PDF by www.screentalk.org 43. BOOM! Rus laughs and beats out a celebratory riff on the big drum.\\nHERRICK: All right, all right! I don't see any notation calling for improvisation, Mr. Rus.\\nRUS: I did it! Wow! Hey, Mr. Herrick I can play this shit! Sorry, play this drum.\\nHERRICK: Yes, Mr. Rus, you can. Maybe you don't know it, but you've also learned a new language. A whole new language.\\nRUS: Wow, I did. I have.\\nHERRICK: Maybe all you wanted to do was bang on something, but you, sir, have learned a language.\\nRUS: Yeah! Wait'll my dad hears this shit... sorry, stuff.\\n\\n\", 'answer': \"There's nothing to be sorry about, Mr. Rus. Herrick catches some of Rust enthusiasm.\", 'gold_tag': 'HERRICK is open-minded and appreciative of enthusiasm', 'last_speaker': 'HERRICK'}\n",
      "Last word -> HERRICK : \"There's nothing to be sorry about, Mr. Rus. Herrick catches some of Rust enthusiasm.\"\n",
      "prediction :  You're not even listening, Mr. Herrick.\n",
      "Real answer : There's nothing to be sorry about, Mr. Rus. Herrick catches some of Rust enthusiasm.\n",
      "Bert Score : {'precision': [0.8945947885513306], 'recall': [0.8597749471664429], 'f1': [0.8768393397331238], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0.043932856352621126 0.01521878786487298\n",
      "ppl : 65.5908936875022\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEEBAND: What are you doing up so late?\\nKURT: I... I’ve been out.\\n\\n', 'answer': 'Alcohol? Hardly conducive to good work. You should get to bed.', 'gold_tag': \"SEEBAND is concerned about KURT's potential consumption of alcohol and its impact on his work , KURT has been out late at night\", 'last_speaker': 'SEEBAND'}\n",
      "Last word -> SEEBAND : \"Alcohol? Hardly conducive to good work. You should get to bed.\"\n",
      "prediction :  Out? Where?\n",
      "Real answer : Alcohol? Hardly conducive to good work. You should get to bed.\n",
      "Bert Score : {'precision': [0.8630267977714539], 'recall': [0.8461325764656067], 'f1': [0.8544961810112], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1063.2461133268894\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKURT: Professor Seeband, about yesterday; of course I would never...\\n\\n', 'answer': 'You have a new subject. Me. For the directors’ gallery. (indicates a sketched portrait of Lenin) That style, more or less. We start tomorrow at four in the afternoon. In my office at the hospital.', 'gold_tag': 'SEEBAND is a professor and likely a director , SEEBAND works in an office at a hospital , SEEBAND has arranged a meeting with KURT for the next day at four in his office', 'last_speaker': 'SEEBAND'}\n",
      "Last word -> SEEBAND : \"You have a new subject. Me. For the directors’ gallery. (indicates a sketched portrait of Lenin) That style, more or less. We start tomorrow at four in the afternoon. In my office at the hospital.\"\n",
      "prediction :  I know. I was mistaken. I'm sorry.\n",
      "Real answer : You have a new subject. Me. For the directors’ gallery. (indicates a sketched portrait of Lenin) That style, more or less. We start tomorrow at four in the afternoon. In my office at the hospital.\n",
      "Bert Score : {'precision': [0.8633710741996765], 'recall': [0.8230333924293518], 'f1': [0.8427197933197021], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 28.733726311089136\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKURT: An... abortion?\\nSEEBAND: If I do not remove the fetus she will not survive the pregnancy.\\nKURT: Here?\\nSEEBAND: We have a reputation to maintain.\\nKURT: Is it really the only way? Really?\\n\\n', 'answer': 'Are you doubting my professional ability? Would I put myself through something like this... and my daughter!... if it were not absolutely necessary?', 'gold_tag': 'SEEBAND prioritizes professional reputation , SEEBAND is potentially a parent to a female patient', 'last_speaker': 'SEEBAND'}\n",
      "Last word -> SEEBAND : \"Are you doubting my professional ability? Would I put myself through something like this... and my daughter!... if it were not absolutely necessary?\"\n",
      "prediction :  It is.\n",
      "Real answer : Are you doubting my professional ability? Would I put myself through something like this... and my daughter!... if it were not absolutely necessary?\n",
      "Bert Score : {'precision': [0.8966634273529053], 'recall': [0.8007549047470093], 'f1': [0.8459995985031128], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 728.6563772339246\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOP #1: For God's sake, Tom, there's a monster in there! Call for assistance and tell them to bring guns.\\n\\n\", 'answer': 'Keep moving! Will you people', 'gold_tag': 'Everyday Language', 'last_speaker': 'COP #2'}\n",
      "Last word -> COP #2 : \"Keep moving! Will you people\"\n",
      "prediction :  This is not a monster, Tom. It's just a man.\n",
      "Real answer : Keep moving! Will you people\n",
      "Bert Score : {'precision': [0.8348572850227356], 'recall': [0.8161893486976624], 'f1': [0.8254177570343018], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.74853318485652\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOP #1: There he is!\\n\\n', 'answer': \"It's that Spider-Man!\", 'gold_tag': 'Everyday Language', 'last_speaker': 'COP #2'}\n",
      "Last word -> COP #2 : \"It's that Spider-Man!\"\n",
      "prediction :  Where?\n",
      "Real answer : It's that Spider-Man!\n",
      "Bert Score : {'precision': [0.8819902539253235], 'recall': [0.826770544052124], 'f1': [0.8534882068634033], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2637.1266702665757\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOP #2: He won't get away this time!\\nCOP #1: Hold your fire! He's got a girl.\\n\\n\", 'answer': \"Looks like he's got a hostage.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'COP #2'}\n",
      "Last word -> COP #2 : \"Looks like he's got a hostage.\"\n",
      "prediction :  Don't worry about it! He's got to get her out of there!\n",
      "Real answer : Looks like he's got a hostage.\n",
      "Bert Score : {'precision': [0.878364086151123], 'recall': [0.9020872116088867], 'f1': [0.8900676369667053], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2857142857142857, 'rouge2': 0.21052631578947367, 'rougeL': 0.2857142857142857, 'rougeLsum': 0.2857142857142857}\n",
      "bleu 1/2 : 0.08333333333333333 0.027524094128159027\n",
      "ppl : 30.834697682059012\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWARDEN: I am wet.\\nKAREN: If you're looking for my husband, he isn't here.\\nWARDEN: And if I'm not looking for him?\\nKAREN: He still isn't here. If that does you any good.\\nWARDEN: Well, I'm looking for him. Do you know where he is?\\nKAREN: I haven't the slightest idea. Perhaps he's in town. I guess it was `in town' the way you put it, wasn't it? Or perhaps he's at the Club. Having a drink.\\nWARDEN: I got some papers it's important for him to sign. Today.\\nKAREN: I'll try phoning him at the Club for you.\\nWARDEN: I never like to disturb a man drinking.\\nKAREN: What is it you want, Sergeant?\\n\\n\", 'answer': \"I could use a drink myself right now. Bad. Anyway, I got a faint suspicion the Captain's `in town.' Ain't you going to ask me in? 28.\", 'gold_tag': 'WARDEN appreciates a good drink , WARDEN has an authoritative persona and a slight dry sense of humor , KAREN is a good host', 'last_speaker': 'WARDEN'}\n",
      "Last word -> WARDEN : \"I could use a drink myself right now. Bad. Anyway, I got a faint suspicion the Captain's `in town.' Ain't you going to ask me in? 28.\"\n",
      "prediction :  I want to talk to your husband.\n",
      "Real answer : I could use a drink myself right now. Bad. Anyway, I got a faint suspicion the Captain's `in town.' Ain't you going to ask me in? 28.\n",
      "Bert Score : {'precision': [0.8843405246734619], 'recall': [0.8249825239181519], 'f1': [0.8536309003829956], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0.016409319790747813 0.003963227253940484\n",
      "ppl : 53.1760959244223\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAREN: You're taking an awful chance, you know. My maid is liable to be home any time.\\nWARDEN: No she won't. Thursday's her day off.\\nKAREN: You think of everything, don't you, Sergeant?\\nWARDEN: I try. In my position you have to.\\nKAREN: Are these really important?\\nWARDEN: Yes. But not important they get signed today. Tomorrow's okay. I got carbons of those back at the office. So it won't be much work to fix them up.\\nKAREN: That's what I like about you, Sergeant. You have confidence. It's also what I dislike about you.\\nWARDEN: It's not confidence. It's honesty.\\nKAREN: Honesty? How did you acquire such an old-fashioned virtue?\\nWARDEN: I figgered out one day it was the shortest distance between two points.\\nKAREN: Well, he's clever as well as virile.\\nWARDEN: No -- it's just that I hate to see a beautiful woman goin all to waste.\\nKAREN: Waste, did you say? Now that's a subject I might tell you something about. There's we. And then there's waste. Positive and negative. The negative is sometimes more interesting... more evil. For example -- what about the house without a child? Tell me your thoughts, Sergeant.\\nWARDEN: You're going to cry.\\nKAREN: Not if I can help it.\\nWARDEN: Please don't cry... I can't stand to see somebody cry.\\nKAREN: What are you doing?\\nWARDEN: I'm leaving. Isn't that what you want?\\nKAREN: I don't know, Sergeant. To be honest, I don't know.\\nWARDEN: I know a beach near Diamond Head. Nobody ever goes there. The cars on the highway pass above and they never know it's there. You feel like you used to feel when you were a kid, hiding by yourself in a cave, watching the others hunting you.\\nKAREN: Maybe... why not?\\nWARDEN: How about Payday?\\nKAREN: You don't have to spend money on me, Sergeant.\\nWARDEN: I just like to have some on me when I take out a woman. Can you get away?\\nKAREN: Maybe.\\n\\n\", 'answer': \"I'll be in Kuhio Park. Say, nine o'clock. Payday.\", 'gold_tag': \"WARDEN has a meeting with KAREN at Kuhio Park on Payday at nine o'clock\", 'last_speaker': 'WARDEN'}\n",
      "Last word -> WARDEN : \"I'll be in Kuhio Park. Say, nine o'clock. Payday.\"\n",
      "prediction :  I'll call you tomorrow.\n",
      "Real answer : I'll be in Kuhio Park. Say, nine o'clock. Payday.\n",
      "Bert Score : {'precision': [0.8927095532417297], 'recall': [0.8449562788009644], 'f1': [0.8681766986846924], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25000000000000006, 'rouge2': 0.14285714285714288, 'rougeL': 0.25000000000000006, 'rougeLsum': 0.25000000000000006}\n",
      "bleu 1/2 : 0.07162619921504752 0.02615419001229357\n",
      "ppl : 38.80948608092959\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAREN: Why, hello. I didn't think you were coming.\\nWARDEN: Why not? I'm not late.\\nKAREN: No, I guess you're not. But then I came a little early. I must have been overanxious. You weren't overanxious though, were you? You got here right on the dot.\\nWARDEN: Maybe I'd of been early too only I stopped to get a drink.\\nKAREN: You certainly chose a savory spot for our meeting.\\nWARDEN: Would you rather it'd been the cocktail lounge of the Royal?\\nKAREN: No, but I've had five chances to be picked up in the last few minutes.\\nWARDEN: That's par for the course around here.\\nKAREN: Well, I don't care for it. I never went in much for back-alley loving.\\nWARDEN: Didn't you?\\nKAREN: You probably think I'm a tramp, don't you?\\nWARDEN: What makes you think I'd think that?\\nKAREN: Don't try to be gallant, Sergeant. If you think this is a mistake, come right out and say so.\\nWARDEN: Listen, what started all this, anyway? Why'm I shakin inside like a school kid out with teacher! Where'd I come up with a yen for of all things the Compny Commander's wife! And her actin like Lady Astor's horse all because I only got here on time!\\nKAREN: On the other hand, I've got a bathing suit under my dress.\\n\\n\", 'answer': 'Funny. I got one in a U-Drive-It parked around the corner.', 'gold_tag': 'Everyday Language', 'last_speaker': 'WARDEN'}\n",
      "Last word -> WARDEN : \"Funny. I got one in a U-Drive-It parked around the corner.\"\n",
      "prediction :  You're not serious?\n",
      "Real answer : Funny. I got one in a U-Drive-It parked around the corner.\n",
      "Bert Score : {'precision': [0.8075515627861023], 'recall': [0.8252644538879395], 'f1': [0.8163118958473206], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 98.07579187624721\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAREN: I hope the ocean's ice cold. I hope\\nWARDEN: Just so long's you melt afterwards.\\n\\n\", 'answer': 'I love the way you laugh.', 'gold_tag': 'KAREN values humor , WARDEN displays a witty nature', 'last_speaker': 'KAREN'}\n",
      "Last word -> KAREN : \"I love the way you laugh.\"\n",
      "prediction :  So do I. I'm so nervous.\n",
      "Real answer : I love the way you laugh.\n",
      "Bert Score : {'precision': [0.8682612180709839], 'recall': [0.8955444097518921], 'f1': [0.8816918134689331], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 45.93159414469536\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAREN: Nobody ever kissed me that way... not really...\\nWARDEN: Nobody?\\nKAREN: No. Nobody.\\nWARDEN: Not even one? Out of all the many men you've been kissed by?\\nKAREN: Well, that will take some figuring. How many men do you think there've been?\\nWARDEN: I wouldn't know. Can't you even make me a rough estimate?\\nKAREN: Not without an adding machine. Do you have your adding machine with you?\\nWARDEN: No, I forgot to bring it.\\nKAREN: Then I guess you won't find out, will you?\\nWARDEN: Maybe I already know.\\nKAREN: What's the matter? What are you hinting at?\\nWARDEN: Why? Is there something to hint at?\\nKAREN: I don't know. Maybe a lot. Or maybe you just think there's a lot.\\nWARDEN: Maybe I do. Maybe there's been a long line of beach parties --\\nKAREN: You must be crazy -- !\\nWARDEN: Am I? Listen, baby, maybe not here. But what about when you and Holmes were at Fort Bliss?\\nKAREN: I had to go and forget you were a man -- with the same rotten filthy mind the rest of them have. For a minute I had to convince myself you were different --\\nWARDEN: Only it's true, ain't it?\\nKAREN: Yes, it's true! A part of it, some small part of whatever sewage you've been listening to. Some day perhaps you'll get all the story.\\nWARDEN: All what story?\\n\\n\", 'answer': \"You're getting to sound so much like a typical male. So you just sweat it out like a typical male.\", 'gold_tag': 'KAREN reveals defensiveness when her past is questioned', 'last_speaker': 'KAREN'}\n",
      "Last word -> KAREN : \"You're getting to sound so much like a typical male. So you just sweat it out like a typical male.\"\n",
      "prediction :  All the story.\n",
      "Real answer : You're getting to sound so much like a typical male. So you just sweat it out like a typical male.\n",
      "Bert Score : {'precision': [0.8586889505386353], 'recall': [0.8409351110458374], 'f1': [0.8497192859649658], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1327.6673360259208\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAREN: All right. I've never told it to anyone before. But I think now is the time. I'll tell you the whole bloody messy thing. You can take it back to the barracks with you. I'd been married to Captain Dana E. Holmes two years. Only he was a First Lieutenant then. Back at Fort Bliss. We lived right on a little lake where we could fish and swim and be alone, our 'dream cottage'... I'm sure you must be able to picture it. It was off on a back road, four miles from the highway. Two miles from a neighbor and a telephone.... I hadn't been married long when I knew my husband was stepping out on me. But -- you get used to that. Your mother tells you that it's life, that i t happens to a lot of women. Of course, she doesn't tell you until after it happens. Then, by that time, you're pregnant. And at least you've something else to hope for. I think I was almost happy that night the pains began. Even though they were weeks too early, a whole month too on that dapper silk gabardine uniform he used to wear. He was going to an officer's 'seminar.' He was kidding me about false labor. I didn't think it was humorous. I told him to get home early, to bring the doctor with him. He smiled tenderly and told me about the psychic reactions of women to pregnancy. But never fear, he'd be back early. And maybe he would have... if the 'seminar' hadn't been with the hat-check girl in one of the night clubs.\\nWARDEN: Listen.\\nKAREN: He was only a little drunk when he came in... at five a.m. He looked alarmed when he saw me. I guess it was because of my screams. I was lying there on the floor, you see -- No, don't say anything. I'm not finished yet. Of course, the baby was dead. It was a boy. But they worked over me at the hospital and fixed me up fine. They even took my appendix out, too. They threw that in free. It was all fine.\\nWARDEN: Listen. Listen. Please.\\nKAREN: And, of course, one more thing no more children. Do you know what that means? You're not a woman. You're not anything. You're a gutted shell... Sure, I went out with some of the men after that. A few months of it. I'd been made dirty and I wanted to be clean. You can see that, can't you?... Anyway, I got my revenge on Dana. I kept on living with him.\\nWARDEN: The hateful, miserable --\\nKAREN: You hunt so hungrily for love... love, if you can find it, you think, might give things meaning again.\\nWARDEN: Listens Listen to me --\\n\\n\", 'answer': \"All right. I'm listening. I know. Until I met you I didn't think it was possible, either.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'KAREN'}\n",
      "Last word -> KAREN : \"All right. I'm listening. I know. Until I met you I didn't think it was possible, either.\"\n",
      "prediction :  I'm not finished. I'm not finished. I'll be finished when I'm ready. I'll tell you the rest of it then.\n",
      "Real answer : All right. I'm listening. I know. Until I met you I didn't think it was possible, either.\n",
      "Bert Score : {'precision': [0.8699279427528381], 'recall': [0.8728140592575073], 'f1': [0.8713685870170593], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3181818181818182, 'rouge2': 0.04761904761904762, 'rougeL': 0.2727272727272727, 'rougeLsum': 0.2727272727272727}\n",
      "bleu 1/2 : 0.15 0.02809757434745082\n",
      "ppl : 9.257217775355704\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAREN: You just love to shock people, don't you?! Where on earth did you learn to dance like that?\\n\\n\", 'answer': 'Believe it or not -- Chicago, Illinois.', 'gold_tag': 'WARDEN learned to dance in Chicago, Illinois', 'last_speaker': 'WARDEN'}\n",
      "Last word -> WARDEN : \"Believe it or not -- Chicago, Illinois.\"\n",
      "prediction :  I've been in some pretty... exotic places.\n",
      "Real answer : Believe it or not -- Chicago, Illinois.\n",
      "Bert Score : {'precision': [0.8318180441856384], 'recall': [0.8268178701400757], 'f1': [0.8293104767799377], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 49.002156128949906\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOCTOR EINSTEIN: Hey, Johnny, down here, what do you think I find ?\\nJONATHAN: What ?\\nDOCTOR EINSTEIN: The Panama Canal. And it just fits Mister Spenalzo. See the hole he's digging. Four feet wide, six feet long. He just fits ! You'd think he knew we were bringing Mister Spenalzo along. That's hospitality.\\nJONATHAN: Rather a good joke on my aunts. They're living in a house with a body buried in the cellar.\\nDOCTOR EINSTEIN: Hey, how do we get him in here ?\\nJONATHAN: Yes, we can't just walk Mister Spenalzo in through the door. We'll bring the car up between the cemetery and the house, and after they've gone to bed, we'll bring Mister Spenalzo in through the window.\\n\\n\", 'answer': 'Hey, Johnny...', 'gold_tag': 'Everyday Language', 'last_speaker': 'DOCTOR EINSTEIN'}\n",
      "Last word -> DOCTOR EINSTEIN : \"Hey, Johnny...\"\n",
      "prediction :  That's a good idea.\n",
      "Real answer : Hey, Johnny...\n",
      "Bert Score : {'precision': [0.887219250202179], 'recall': [0.8416131734848022], 'f1': [0.863814651966095], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 38.71453809597839\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOCTOR EINSTEIN: Hey, Johnny, Johnny, come quick !\\nJONATHAN: What's the matter ?\\nDOCTOR EINSTEIN: You know that hole in the cellar ?\\nJONATHAN: Yes.\\n\\n\", 'answer': 'Well, we got an ace in the hole.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DOCTOR EINSTEIN'}\n",
      "Last word -> DOCTOR EINSTEIN : \"Well, we got an ace in the hole.\"\n",
      "prediction :  I think it's a time hole.\n",
      "Real answer : Well, we got an ace in the hole.\n",
      "Bert Score : {'precision': [0.8758569359779358], 'recall': [0.8735760450363159], 'f1': [0.8747149705886841], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0.11942188509563156 0.04136895450425726\n",
      "ppl : 87.57278564374326\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOCTOR EINSTEIN: This is all fixed up nice now. Nice and smooth like a lake. Oh, Johnny, bed feels good already. You know, we didn't get any sleep for forty-eight hours.\\nJONATHAN: You're forgetting, Doctor.\\n\\n\", 'answer': 'What ?', 'gold_tag': 'Everyday Language', 'last_speaker': 'DOCTOR EINSTEIN'}\n",
      "Last word -> DOCTOR EINSTEIN : \"What ?\"\n",
      "prediction :  Oh, no. I'm not forgetting. I'm just remembering.\n",
      "Real answer : What ?\n",
      "Bert Score : {'precision': [0.8323511481285095], 'recall': [0.79817795753479], 'f1': [0.8149064183235168], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.009563851728632\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJONATHAN: My brother, Mortimer. I just heard him upstairs.\\nDOCTOR EINSTEIN: No, no, no ! I am tired. You forget, I got to operate on your face tomorrow.\\nJONATHAN: (voice over. We just see his shadow on the wall behind You are going to operate tomorrow, Doctor. But tonight we are taking care of Mortimer.\\nDOCTOR EINSTEIN: No, but Johnny, not tonight ! I'm sleepy. We'll do it tomorrow. Or the next day.\\nJONATHAN: Look at me, Doctor. You can see that it's got to be done, can't you?\\nDOCTOR EINSTEIN: Yeah, I know that look.\\nJONATHAN: It's a little late to dissolve our partnership.\\nDOCTOR EINSTEIN: Okay, okay, Johnny, okay. We'll do it. But the quick way, huh ? The quick twist like in London.\\nJONATHAN: No, Doctor. I think this calls for something special. I think, perhaps, the Melbourne method.\\n\\n\", 'answer': 'Not the Melbourne method, please ! Two hours ! And then when it was all over, what ? The fellow in London was just as dead as the fellow in Melbourne.', 'gold_tag': 'DOCTOR EINSTEIN and JONATHAN have a shared history of performing operations together, as suggested by their references to the \"quick twist like in London\" and the \"Melbourne method. \".', 'last_speaker': 'DOCTOR EINSTEIN'}\n",
      "Last word -> DOCTOR EINSTEIN : \"Not the Melbourne method, please ! Two hours ! And then when it was all over, what ? The fellow in London was just as dead as the fellow in Melbourne.\"\n",
      "prediction :  (Sighs) You're going to make me sick, Johnny.\n",
      "Real answer : Not the Melbourne method, please ! Two hours ! And then when it was all over, what ? The fellow in London was just as dead as the fellow in Melbourne.\n",
      "Bert Score : {'precision': [0.8450883626937866], 'recall': [0.8327908515930176], 'f1': [0.8388945460319519], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 41.090312592142915\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nD.J.: His name is Ferris Mueller.\\n\\n', 'answer': 'Bueller. Ferris Bueller.', 'gold_tag': 'Everyday Language', 'last_speaker': 'FERRIS'}\n",
      "Last word -> FERRIS : \"Bueller. Ferris Bueller.\"\n",
      "prediction :  Oh, my gosh! That's like the coolest name ever!\n",
      "Real answer : Bueller. Ferris Bueller.\n",
      "Bert Score : {'precision': [0.7834916710853577], 'recall': [0.8190088272094727], 'f1': [0.8008567094802856], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.941455035507023\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nD.J.: Sorry about that.\\n\\n', 'answer': \"It's cool.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'FERRIS'}\n",
      "Last word -> FERRIS : \"It's cool.\"\n",
      "prediction :  You're sorry?\n",
      "Real answer : It's cool.\n",
      "Bert Score : {'precision': [0.8201906681060791], 'recall': [0.8740489482879639], 'f1': [0.8462637662887573], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 106.73153854977384\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nD.J.: He has an incredible story.\\n\\n', 'answer': \"I'm going to tell a massive lie here. It's going to by very thick and very steamy. I think radio's a facinating medium, it challenges the imagination. Unlike television which provides the images, radio... You know this. Anyway, it's always been a dream of mine to be on the radio. I have what I consider to be an excellent broadcast voice. I practise it in the bathroom all the time. I used to play records and do introductions to them. But I've never had the chance to sit behind a microphone and try it out for real. This is a 50,000 watt outlet. I'm going out to several million people so let me just say, I'm in a very pleasant groove right now. Well, Steve, you and your listeners are probably not going to believe this but...\", 'gold_tag': 'FERRIS is likely a young, aspiring radio broadcaster , FERRIS practices his broadcast voice and dreams of being on the radio , FERRIS tends to lie or exaggerate , FERRIS refers to his present state of being \"in a very pleasant groove\"', 'last_speaker': 'FERRIS'}\n",
      "Last word -> FERRIS : \"I'm going to tell a massive lie here. It's going to by very thick and very steamy. I think radio's a facinating medium, it challenges the imagination. Unlike television which provides the images, radio... You know this. Anyway, it's always been a dream of mine to be on the radio. I have what I consider to be an excellent broadcast voice. I practise it in the bathroom all the time. I used to play records and do introductions to them. But I've never had the chance to sit behind a microphone and try it out for real. This is a 50,000 watt outlet. I'm going out to several million people so let me just say, I'm in a very pleasant groove right now. Well, Steve, you and your listeners are probably not going to believe this but...\"\n",
      "prediction :  What do you mean?\n",
      "Real answer : I'm going to tell a massive lie here. It's going to by very thick and very steamy. I think radio's a facinating medium, it challenges the imagination. Unlike television which provides the images, radio... You know this. Anyway, it's always been a dream of mine to be on the radio. I have what I consider to be an excellent broadcast voice. I practise it in the bathroom all the time. I used to play records and do introductions to them. But I've never had the chance to sit behind a microphone and try it out for real. This is a 50,000 watt outlet. I'm going out to several million people so let me just say, I'm in a very pleasant groove right now. Well, Steve, you and your listeners are probably not going to believe this but...\n",
      "Bert Score : {'precision': [0.7883177995681763], 'recall': [0.7667608261108398], 'f1': [0.7773898839950562], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.040268456375838924, 'rouge2': 0.0, 'rougeL': 0.040268456375838924, 'rougeLsum': 0.040268456375838924}\n",
      "bleu 1/2 : 1.8141720890235224e-15 4.684172191961615e-16\n",
      "ppl : 79.14500084705968\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFERRIS: I was going to say I knew Springsteen's home phone number and I was going to give out the number of the New Jersey State Police but I thought I might get busted. After I got flunked in driver's ed for sideswiping a mail box, which was not in any way, shape or from my fault. I was putting out a cigarette, like I was told. It was weird. I'm so used to getting in a car and lighting up, because I'm not allowed to smoke at home, that I got in the driver's ed. car and spaced completely, pulled out of the lot, lit up a 'boro and Mrs. Heller looked at me like I'd just pulled a bunny out of my nose or something and I realized what the hell I was doing and I went to put it out and hit the mail box. Anyway, I was so pissed off at her reaction to the whole thing that I considered running an ad in a sleaze magazine for a school teacher that does phone sex and I was gonna use Mrs. Heller's home number but is cost too much. I took it again and passed. But I had to work at Burger King to get the cash to pay for the driver's ed. car. The car got fixed in auto shop for nothing and can't prove it? I'm in high school, remember?\\nD.J.: How did you get picked for this.\\n\\n\", 'answer': \"It's kind of a long story but I've been doing alot of programming for NASA.\", 'gold_tag': 'FERRIS does programming for NASA', 'last_speaker': 'FERRIS'}\n",
      "Last word -> FERRIS : \"It's kind of a long story but I've been doing alot of programming for NASA.\"\n",
      "prediction :  I didn't get picked for anything. I'm here because I'm here. I'm here because I'm a high school student.\n",
      "Real answer : It's kind of a long story but I've been doing alot of programming for NASA.\n",
      "Bert Score : {'precision': [0.8703456521034241], 'recall': [0.8593533039093018], 'f1': [0.8648145794868469], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14634146341463414, 'rouge2': 0.0, 'rougeL': 0.09756097560975609, 'rougeLsum': 0.09756097560975609}\n",
      "bleu 1/2 : 0.10526315789473682 0.024182541670333724\n",
      "ppl : 10.916435721408599\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK: How did you get all of this stuff into the country?\\nRAYMOND: This is America. There is nothing you can not buy.\\nNICK: So why all the secrecy? Why aren't you guys working with the US military?\\nRAYMOND: I am not permitted to speak of such things.\\nNICK: You said you wanted my trust, then I need yours.\\nRAYMOND: I am a patriot. I love my country. Can you understand that?\\nNICK: Sure.\\nRAYMOND: It is my job to protect my country. Sometimes I must even protect it from itself. From mistakes we have made. Mistakes that we do not want the world to know about.\\nNICK: Your talking about the nuclear testing in the Pacific.\\n\\n\", 'answer': 'Yes. This testing done by my country left a terrible mess. We are here to clean it up.', 'gold_tag': 'RAYMOND feels a responsibility toward his country', 'last_speaker': 'RAYMOND'}\n",
      "Last word -> RAYMOND : \"Yes. This testing done by my country left a terrible mess. We are here to clean it up.\"\n",
      "prediction :  You know about that?\n",
      "Real answer : Yes. This testing done by my country left a terrible mess. We are here to clean it up.\n",
      "Bert Score : {'precision': [0.8033816814422607], 'recall': [0.8528469800949097], 'f1': [0.8273756504058838], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 290.5313375076204\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK: What's with the chewing gum?\\nRAYMOND: Makes us look more American.\\n\\n\", 'answer': 'Just let me do all the talking.', 'gold_tag': 'NICK is a leader or decision maker in their current scenario', 'last_speaker': 'NICK'}\n",
      "Last word -> NICK : \"Just let me do all the talking.\"\n",
      "prediction :  You're right.\n",
      "Real answer : Just let me do all the talking.\n",
      "Bert Score : {'precision': [0.869637131690979], 'recall': [0.8372546434402466], 'f1': [0.8531387448310852], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 58.40577433756828\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK: Three eggs. I thought there would be more.\\nRAYMOND: You were right.\\n\\n', 'answer': \"That can't be. That's got to be over twenty eggs.\", 'gold_tag': 'NICK scrutinizes the number of eggs', 'last_speaker': 'NICK'}\n",
      "Last word -> NICK : \"That can't be. That's got to be over twenty eggs.\"\n",
      "prediction :  They don't have any.\n",
      "Real answer : That can't be. That's got to be over twenty eggs.\n",
      "Bert Score : {'precision': [0.8595776557922363], 'recall': [0.8445760607719421], 'f1': [0.8520108461380005], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 62.05261265622551\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK: Hey, it's me!\\n\\n\", 'answer': 'What happened?', 'gold_tag': 'Everyday Language', 'last_speaker': 'RAYMOND'}\n",
      "Last word -> RAYMOND : \"What happened?\"\n",
      "prediction :  Nick, what's going on?\n",
      "Real answer : What happened?\n",
      "Bert Score : {'precision': [0.889055609703064], 'recall': [0.9165405035018921], 'f1': [0.9025888442993164], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 54.68066335030334\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBUD: Lynn Wheeler. We haven't been properly introduced. I'm Detective Bud Carter.\\nLYNN: I know who you are.\\nBUD: You have a ride home?\\nLYNN: We took the bus.\\n\\n\", 'answer': \"Take a cab. 'You need anything...anything at all. Be sure to call me.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"Take a cab. 'You need anything...anything at all. Be sure to call me.\"\n",
      "prediction :  What did you do with your car?\n",
      "Real answer : Take a cab. 'You need anything...anything at all. Be sure to call me.\n",
      "Bert Score : {'precision': [0.8526058793067932], 'recall': [0.8388592004776001], 'f1': [0.8456766605377197], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809523, 'rouge2': 0.0, 'rougeL': 0.09523809523809523, 'rougeLsum': 0.09523809523809523}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 53.875726369134206\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLYNN: It's Officer White, isn't it? Can I get you a drink?\\nBUD: Yeah, plain scotch.\\nLYNN: I was friendly with Sue Lefferts, but we weren't really friends. You know what I mean?\\nBUD: Are you sorry she's dead?\\nLYNN: Of course I am. What kind of question is that?\\nBUD: Have you ever heard of Dick Stensland?\\nLYNN: No I haven't. Do you know why Pierce is humoring you?\\nBUD: You use words like that, you might make me mad.\\nLYNN: Yes. But do you know?\\nBUD: Yeah I know. Patchett's running whores and judging by his address, probably something bigger on the side. He doesn't want any attention.\\nLYNN: That's right. Our motives are selfish, so we're cooperating.\\nBUD: Why was Susan Lefferts at the Nite Owl?\\nLYNN: I don't know. I never heard of the Nite Owl till today.\\nBUD: Did Lefferts have a boyfriend?\\nLYNN: Like I said we were friendly, not friends.\\nBUD: How'd she meet Patchett?\\nLYNN: Pierce meets people. Sue came on the bus with dreams of Hollywood. This is how they turned out. Thanks to Pierce, we still get to act a little.\\nBUD: Tell me about Patchett.\\nLYNN: He's waiting for you to mention mention.\\nBUD: You want some advice, Miss Bracken?\\nLYNN: It's Lynn.\\nBUD: Miss Bracken, don't ever try to fucking bribe me or threaten me or I'll have you and Patchett in shit up to your ears.\\nLYNN: I remember you from Christmas Eve. You have a thing for helping women, don't you, Officer White?\\nBUD: Maybe I'm just fucking curious.\\nLYNN: You say 'fuck' a lot.\\nBUD: You fuck for money.\\nLYNN: There's blood on your shirt. Is that an integral part of your job?\\nBUD: Yeah.\\nLYNN: Do you enjoy it?\\nBUD: When they deserve it.\\nLYNN: Did they deserve it today?\\nBUD: I'm not sure.\\nLYNN: But you did it anyway.\\nBUD: Yeah, just like the half dozen guys you screwed today.\\nLYNN: Actually, it was two. You're different, Officer White. You're the first man in five years who didn't tell me I look like Veronica Lake inside of a minute.\\nBUD: You look better than Veronica Lake. Now, Pierce Patchett.\\nLYNN: He takes a cut of our earnings and invests it for us. He makes us quit the life at thirty. He doesn't let us use narcotics and he doesn't abuse us. Can your policeman's mentality grasp those contradictions?\\nBUD: He had you cut to look like Veronica Lake?\\nLYNN: No. I'm really a brunette, but the rest is me. And that's all the news that's fit to print. It was nice meeting you, Officer.\\nBUD: Look. I want to see you again.\\nLYNN: Are you asking me for a date or an appointment?\\nBUD: I don't know.\\nLYNN: If it's a date I think you'd better tell me your first name because I --\\n\\n\", 'answer': 'Forget I asked. It was a mistake.', 'gold_tag': 'BUD has a direct and confrontational speaking style', 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"Forget I asked. It was a mistake.\"\n",
      "prediction :  Bud.\n",
      "Real answer : Forget I asked. It was a mistake.\n",
      "Bert Score : {'precision': [0.9228485822677612], 'recall': [0.8635494709014893], 'f1': [0.892214834690094], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15333.327466928442\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLYNN: Did you forget some -- I wondered when you might ring the bell again, Officer White.\\nBUD: It's Bud.\\n\\n\", 'answer': \"You should see yourself. You look like you're ten years old. If you'd called first, I wouldn't look this ridiculous.\", 'gold_tag': 'LYNN might be somewhat self-conscious about her appearance , BUD potentially looks young for his age', 'last_speaker': 'LYNN'}\n",
      "Last word -> LYNN : \"You should see yourself. You look like you're ten years old. If you'd called first, I wouldn't look this ridiculous.\"\n",
      "prediction :  Oh, I'm sorry.\n",
      "Real answer : You should see yourself. You look like you're ten years old. If you'd called first, I wouldn't look this ridiculous.\n",
      "Bert Score : {'precision': [0.835712194442749], 'recall': [0.8173097372055054], 'f1': [0.8264085650444031], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07407407407407408, 'rouge2': 0.0, 'rougeL': 0.07407407407407408, 'rougeLsum': 0.07407407407407408}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 36.9601620592924\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBUD: Who was that guy who was here earlier?\\nLYNN: It doesn't matter. All they get is Veronica Lake. You got the real Lynn Margaret Bracken... Where'd this come from?\\nBUD: When I was ten, my old man threw a bottle at my mother. I guess I got in the way.\\nLYNN: So you saved her.\\nBUD: Yeah. But not for long.\\nLYNN: Do you like being a cop, Bud?\\nBUD: I used to. What I do now is strong-arm. Sitting duck stuff... No, I don't like it. If I could work Homicide like a real detective... There's something wrong with the Nite Owl. That prick Exley shot the wrong guys. But they made him a hero and whoever killed my partner is still out there. In here I know it. But I can't prove it. I'm not a detective. I'm not smart enough. I'm just the guy they bring in to scare the other guy shitless.\\nLYNN: You found Patchett. You found me. You're smart enough. Be a detective if that's what you want.\\n\\n\", 'answer': 'That simple, huh?', 'gold_tag': \"BUD's current feelings and circumstances suggest he is poised to make career-related decisions in the imminent future\", 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"That simple, huh?\"\n",
      "prediction :  I don't want. I don't want to be a detective. I want to be with you.\n",
      "Real answer : That simple, huh?\n",
      "Bert Score : {'precision': [0.8477789163589478], 'recall': [0.8409388065338135], 'f1': [0.8443450331687927], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 9.839246165104843\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBUD: Did you talk to Exley?\\nLYNN: Come in out of the rain. In the morning we'll have both our stories for breakfast.\\nBUD: I want to know about Exley.\\nLYNN: He's the opposite of you. He's more like me. Cold, calculating.\\nBUD: How'd you get to know so much about him?\\nLYNN: Come in out of the rain, Bud.\\nBUD: You gonna tell me what happened with you and Exley?\\nLYNN: We talked.\\nBUD: So tell me about it.\\nLYNN: In the morning.\\nBUD: No. Now. You fucked him.\\n\\n\", 'answer': 'I thought I was helping you. I thought --', 'gold_tag': 'LYNN is secretive or protective', 'last_speaker': 'LYNN'}\n",
      "Last word -> LYNN : \"I thought I was helping you. I thought --\"\n",
      "prediction :  I didn't fuck him.\n",
      "Real answer : I thought I was helping you. I thought --\n",
      "Bert Score : {'precision': [0.8837854862213135], 'recall': [0.8514714241027832], 'f1': [0.8673275709152222], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615385, 'rouge2': 0.0, 'rougeL': 0.15384615384615385, 'rougeLsum': 0.15384615384615385}\n",
      "bleu 1/2 : 0.07162619921504752 0.02615419001229357\n",
      "ppl : 65.6785254659878\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHARRY: Empty. Go.\\nGIB: Harry Tasker wallet. Harry Tasker passport. Plane ticket stub, hotel receipt, Tasker. Two postcards of Lake Geneva. House keys. Souvenir snowing Swiss village.\\nHARRY: What's this for?\\nGIB: For Dana, schmuck. Bring your kid something. You know. The dad thing.\\nHARRY: Got it. Nice touch. Okay, pick me up at eight. The de-brief is at ten hundred.\\nGIB: Hey, hey, hey... what are we forgetting?\\nHARRY: What a team. See you at eight.\\n\\n\", 'answer': 'Yep. Sleep fast.', 'gold_tag': 'Everyday Language', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"Yep. Sleep fast.\"\n",
      "prediction :  So, I know we're talking about the job, but I'm still trying to figure out how to get out of the house.\n",
      "Real answer : Yep. Sleep fast.\n",
      "Bert Score : {'precision': [0.82302325963974], 'recall': [0.9081028699874878], 'f1': [0.8634724020957947], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.626380271904663\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: Kids. Ten seconds of joy. Thirty years of misery.\\nHARRY: She knows not to steal. I've taught her better than that.\\n\\n\", 'answer': \"Yeah, but you're not her parents, anymore, you and Helen. Her parents are Axl Rose and Madonna. The five minutes you spend a day with her can't compete with that kind of constant bombardment. You're outgunned, amigo.\", 'gold_tag': 'Gib is aware of popular culture figures like Axl Rose and Madonna , Shared memories', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"Yeah, but you're not her parents, anymore, you and Helen. Her parents are Axl Rose and Madonna. The five minutes you spend a day with her can't compete with that kind of constant bombardment. You're outgunned, amigo.\"\n",
      "prediction :  You've taught her to be a thief?\n",
      "Real answer : Yeah, but you're not her parents, anymore, you and Helen. Her parents are Axl Rose and Madonna. The five minutes you spend a day with her can't compete with that kind of constant bombardment. You're outgunned, amigo.\n",
      "Bert Score : {'precision': [0.8638665080070496], 'recall': [0.8283882141113281], 'f1': [0.845755398273468], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12499999999999999, 'rouge2': 0.0, 'rougeL': 0.12499999999999999, 'rougeLsum': 0.12499999999999999}\n",
      "bleu 1/2 : 0.003932510495157257 0.00094979151906113\n",
      "ppl : 63.77143645216265\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: Twenty here, fifty there... I figured my wife's boyfriend was taking it.\\nHARRY: I thought you moved out.\\n\\n\", 'answer': \"Well . . . I moved back in. My lawyer said it would give me a better claim on the house in the property settlement. Don't change the subject... you owe me two hundred bucks.\", 'gold_tag': \"GIB's lawyer's advice has led him to move back in with his spouse , GIB plans to get a beneficial claim from the property settlement\", 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"Well . . . I moved back in. My lawyer said it would give me a better claim on the house in the property settlement. Don't change the subject... you owe me two hundred bucks.\"\n",
      "prediction :  I did, but I came back.\n",
      "Real answer : Well . . . I moved back in. My lawyer said it would give me a better claim on the house in the property settlement. Don't change the subject... you owe me two hundred bucks.\n",
      "Bert Score : {'precision': [0.8980321884155273], 'recall': [0.831615149974823], 'f1': [0.8635484576225281], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10256410256410256, 'rouge2': 0.0, 'rougeL': 0.10256410256410256, 'rougeLsum': 0.10256410256410256}\n",
      "bleu 1/2 : 0.0013266573081177418 0.0004595675723784975\n",
      "ppl : 90.2485714335815\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: It's all set up... ghost phones and fax, all the usual stuff. You have a suite at the Marquis Hotel under Renquist. Okay, reality check. Go.\\n\\n\", 'answer': \"Hi, I'm Harry Renquist. I own a--\", 'gold_tag': 'HARRY is a business owner under the alias of Harry Renquist , HARRY will be taking on the persona of a business owner in the near future', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"Hi, I'm Harry Renquist. I own a--\"\n",
      "prediction :  Harry.\n",
      "Real answer : Hi, I'm Harry Renquist. I own a--\n",
      "Bert Score : {'precision': [0.9356223344802856], 'recall': [0.8164652585983276], 'f1': [0.8719919323921204], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2222222222222222, 'rouge2': 0.0, 'rougeL': 0.2222222222222222, 'rougeLsum': 0.2222222222222222}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11007.819891353316\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: There's another guy, still in the car.\\n\\n\", 'answer': 'Stay on him.', 'gold_tag': 'HARRY is commanding , HARRY suggests a position of authority', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"Stay on him.\"\n",
      "prediction :  I'm not going to hurt him.\n",
      "Real answer : Stay on him.\n",
      "Bert Score : {'precision': [0.8766424655914307], 'recall': [0.9107024669647217], 'f1': [0.893347978591919], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0.16666666666666669 0.05773502691896258\n",
      "ppl : 41.014086729853794\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: Copy that.\\n\\n', 'answer': 'And make it fast. My horse is getting tired.', 'gold_tag': \"HARRY seems to be in a hurry , HARRY's statement about the horse getting tired implies he may currently be on horseback\", 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"And make it fast. My horse is getting tired.\"\n",
      "prediction :  I'm glad you're here.\n",
      "Real answer : And make it fast. My horse is getting tired.\n",
      "Bert Score : {'precision': [0.8653107285499573], 'recall': [0.8626477122306824], 'f1': [0.8639771342277527], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.806183890430395\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: Hey, did that guy Harry chased last night call in to give himself up yet? Cause apparently that's the only way we're going to catch the son of a bitch --\\n\\n\", 'answer': 'Okay. Here she comes.', 'gold_tag': 'HARRY is observant , HARRY values the tactical aspect of his work', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"Okay. Here she comes.\"\n",
      "prediction :  No, he hasn't called in. I'm still out there looking for him.\n",
      "Real answer : Okay. Here she comes.\n",
      "Bert Score : {'precision': [0.8535689115524292], 'recall': [0.9030395150184631], 'f1': [0.877607524394989], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 30.816640176834355\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHARRY: Look at the way the little punk is driving. He's all over the place. Look-- he hasn't signalled once.\\n\\n\", 'answer': \"Goddammit! That's outrageous.\", 'gold_tag': \"GIB is outraged , The cause of GIB's outrage is reckless driving\", 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"Goddammit! That's outrageous.\"\n",
      "prediction :  What's he doing?\n",
      "Real answer : Goddammit! That's outrageous.\n",
      "Bert Score : {'precision': [0.8402373790740967], 'recall': [0.8216450810432434], 'f1': [0.8308373093605042], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 81.12721718240346\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHARRY: So, you wanna play huh? You little--\\n\\n', 'answer': \"That's it. Get 'im Harry We'll teach that little puke not to signal.\", 'gold_tag': 'HARRY shows a willingness to fight', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"That's it. Get 'im Harry We'll teach that little puke not to signal.\"\n",
      "prediction :  Yeah, I want to play.\n",
      "Real answer : That's it. Get 'im Harry We'll teach that little puke not to signal.\n",
      "Bert Score : {'precision': [0.8773183226585388], 'recall': [0.8414989113807678], 'f1': [0.8590353727340698], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1, 'rouge2': 0.0, 'rougeL': 0.1, 'rougeLsum': 0.1}\n",
      "bleu 1/2 : 0.04037930359893108 0.014276239697197267\n",
      "ppl : 72.00484428130241\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: Ha! The little prick ditched you! That is so goddamn funny.\\nHARRY: Son of a bitch!\\n\\n', 'answer': 'Can we go to the office now, Mr. Superspy?', 'gold_tag': 'Everyday Language', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"Can we go to the office now, Mr. Superspy?\"\n",
      "prediction :  You gotta hand it to him. He's got some serious balls.\n",
      "Real answer : Can we go to the office now, Mr. Superspy?\n",
      "Bert Score : {'precision': [0.8327791690826416], 'recall': [0.8343542814254761], 'f1': [0.8335659503936768], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809525, 'rouge2': 0.0, 'rougeL': 0.09523809523809525, 'rougeLsum': 0.09523809523809525}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 11.705989697768437\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: What's going on?\\nHARRY: Look, uh... I've got to talk to Helen about this thing with Dana. I'm just going to run in and see if she can get away for lunch.\\nGIB: You want me to just hang-- ?\\nHARRY: Just hang a minute.\\n\\n\", 'answer': \"I'll just hang then, shall I?\", 'gold_tag': 'GIB acts patiently and cooperatively', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"I'll just hang then, shall I?\"\n",
      "prediction :  I'm sorry.\n",
      "Real answer : I'll just hang then, shall I?\n",
      "Bert Score : {'precision': [0.8825623989105225], 'recall': [0.8170942068099976], 'f1': [0.8485674262046814], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 70.196163546962\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: You look like you got gut-kicked. What's the matter? You sick?\\nHARRY: He-- Helen. Helen-- it's Helen. It's Helen, Gib.\\nGIB: Something to do with Helen, is what I'm getting.\\nHARRY: She's having an affair.\\nGIB: Congratulations. Welcome to the club.\\nHARRY: It can't be. Not Helen.\\nGIB: Nobody believes it can happen to them.\\nHARRY: It can't be.\\nGIB: Same thing happened to me with wife two. I had no idea until I came home and the house was empty. I mean empty. She even took the ice-cube trays from the fridge. What kind of person would think of that?\\nHARRY: I still don't believe it.\\nGIB: Relax. Helen still loves you. She just wants this guy to bang her. It's nothing serious. You'll get used to it after a --\\nHARRY: STOP. CHEERING. ME. UP.\\n\\n\", 'answer': \"What'dya expect Harry? She's a flesh and blood woman. And you're never there. It was only a matter of time. I say we concentrate on work. That's how I always got through it whenever my life turned to dogshit. Let's catch some terrorists and then you can beat the crap out of them. You'll feel better. Women. Can't live with 'em. Can't kill 'em.\", 'gold_tag': 'GIB copes with marital issues by focusing on his job , GIB is cynical about relationships', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"What'dya expect Harry? She's a flesh and blood woman. And you're never there. It was only a matter of time. I say we concentrate on work. That's how I always got through it whenever my life turned to dogshit. Let's catch some terrorists and then you can beat the crap out of them. You'll feel better. Women. Can't live with 'em. Can't kill 'em.\"\n",
      "prediction :  What?\n",
      "Real answer : What'dya expect Harry? She's a flesh and blood woman. And you're never there. It was only a matter of time. I say we concentrate on work. That's how I always got through it whenever my life turned to dogshit. Let's catch some terrorists and then you can beat the crap out of them. You'll feel better. Women. Can't live with 'em. Can't kill 'em.\n",
      "Bert Score : {'precision': [0.8471719026565552], 'recall': [0.7893191576004028], 'f1': [0.8172229528427124], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0273972602739726, 'rouge2': 0.0, 'rougeL': 0.0273972602739726, 'rougeLsum': 0.0273972602739726}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: Okay, she's turning on Seventeenth. Make a left, you should see her.\\n\\n\", 'answer': 'There she is.', 'gold_tag': \"HARRY displays his alertness , HARRY acts quickly upon GIB's instructions\", 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"There she is.\"\n",
      "prediction :  You know what, Gib?\n",
      "Real answer : There she is.\n",
      "Bert Score : {'precision': [0.7894108295440674], 'recall': [0.8856713771820068], 'f1': [0.8347752094268799], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 257.20203589922545\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: Guy's a spook!\\nHARRY: Yeah, but for who? *\\n\\n\", 'answer': 'He could be working her to get to you.', 'gold_tag': 'GIB is knowledgeable about intelligence operations , HARRY is likely a person of interest , Others may want to infiltrate HARRY , HARRY has something valuable or secret', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"He could be working her to get to you.\"\n",
      "prediction :  Who?\n",
      "Real answer : He could be working her to get to you.\n",
      "Bert Score : {'precision': [0.8501011729240417], 'recall': [0.8313958644866943], 'f1': [0.8406444191932678], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3856.0021279346893\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHARRY: Shit! It's almost eight. * She's still at my house. *\\n\\n\", 'answer': 'The purse is still at the house.', 'gold_tag': 'Everyday Language', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"The purse is still at the house.\"\n",
      "prediction :  Oh. * I'm sorry. *\n",
      "Real answer : The purse is still at the house.\n",
      "Bert Score : {'precision': [0.857913613319397], 'recall': [0.8705851435661316], 'f1': [0.8642029762268066], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 97.28690295035811\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: You've reached a new low with this one. I can't believe you're crazy enough to use the room at the Marquis.\\nHARRY: Why not? You think I can afford a suite like that on my salary? Is Jean-Claude done yet? *\\n\\n\", 'answer': 'Not quite.', 'gold_tag': 'GIB suggests caution and prudence in operations', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"Not quite.\"\n",
      "prediction :  Yes, he is. *\n",
      "Real answer : Not quite.\n",
      "Bert Score : {'precision': [0.8599082231521606], 'recall': [0.8978472948074341], 'f1': [0.8784683346748352], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 145.15024448749455\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: I thought this look like your work.\\nHARRY: Let's go. I'll brief you in the air.\\n\\n\", 'answer': \"You're welcome.\", 'gold_tag': 'GIB suggests his job involves analysis or field observation', 'last_speaker': 'GIB'}\n",
      "Last word -> GIB : \"You're welcome.\"\n",
      "prediction :  The guy's a jumper.\n",
      "Real answer : You're welcome.\n",
      "Bert Score : {'precision': [0.8749276399612427], 'recall': [0.855372428894043], 'f1': [0.865039587020874], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 58.93539033681528\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: --you tell the son of bitch this is Bright Boy Alert. Repeat,\\nHARRY: ... the Coast Guard has to clear them back to a twenty mile radius. Anybody that can't make the minimum safe distance we need an airlift on, immediately--\\nGIB: I can get 3 Marine Corps Harriers here in about 12 minutes. They're on maneuvers out of Boca Chica.\\n\\n\", 'answer': \"Get 'em. I'll brief them on the way in.\", 'gold_tag': 'HARRY is able to request military support and brief them', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"Get 'em. I'll brief them on the way in.\"\n",
      "prediction :  They're on maneuvers?\n",
      "Real answer : Get 'em. I'll brief them on the way in.\n",
      "Bert Score : {'precision': [0.8251368999481201], 'recall': [0.8430799245834351], 'f1': [0.8340119123458862], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714288, 'rouge2': 0.0, 'rougeL': 0.14285714285714288, 'rougeLsum': 0.14285714285714288}\n",
      "bleu 1/2 : 0.045111761078870896 0.017471709937655493\n",
      "ppl : 120.25158228562384\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGIB: ... well get the Highway Patrol to go through the streets and tell everybody on their damn loudspeakers. Just the basics... get away from windows, don't look at it... yeah--\\n\\n\", 'answer': 'Here they come. Roger, Mike Three Five, you are cleared to engage. Be advised, your targets have Stingers and light machine guns.', 'gold_tag': 'HARRY is in a position of command , HARRY potentially operates within a military or law enforcement setting , HARRY uses technical language and clear directives', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"Here they come. Roger, Mike Three Five, you are cleared to engage. Be advised, your targets have Stingers and light machine guns.\"\n",
      "prediction : ... I'm glad you're okay, Gib.\n",
      "Real answer : Here they come. Roger, Mike Three Five, you are cleared to engage. Be advised, your targets have Stingers and light machine guns.\n",
      "Bert Score : {'precision': [0.8338306546211243], 'recall': [0.830112099647522], 'f1': [0.8319672346115112], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06896551724137931, 'rouge2': 0.0, 'rougeL': 0.06896551724137931, 'rougeLsum': 0.06896551724137931}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 27.89377297065059\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: What the hell are you?\\n\\n', 'answer': 'Interested? Follow the crow.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SKULL COWBOY'}\n",
      "Last word -> SKULL COWBOY : \"Interested? Follow the crow.\"\n",
      "prediction :  I'm Skull Cowboy.\n",
      "Real answer : Interested? Follow the crow.\n",
      "Bert Score : {'precision': [0.8664741516113281], 'recall': [0.8431634902954102], 'f1': [0.854659914970398], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 222.09935110576\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSKULL COWBOY: Get it?\\nERIC: Leave me alone -- !\\n\\n', 'answer': 'Do something about it.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SKULL COWBOY'}\n",
      "Last word -> SKULL COWBOY : \"Do something about it.\"\n",
      "prediction :  Come on, Eric, it's just a joke.\n",
      "Real answer : Do something about it.\n",
      "Bert Score : {'precision': [0.8522771000862122], 'recall': [0.8795778751373291], 'f1': [0.8657123446464539], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 26.116586735404177\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSKULL COWBOY: Glad to see you're finally with the program.\\nERIC: Bugger off to the graveyard, skull- face, I'm busy.\\nSKULL COWBOY: You work for the dead. Forget that, and you can forget it all.\\n\\n\", 'answer': 'Forget this. She always red red was her color.', 'gold_tag': 'ERIC has a connection with someone who loved the color red', 'last_speaker': 'ERIC'}\n",
      "Last word -> ERIC : \"Forget this. She always red red was her color.\"\n",
      "prediction :  This is the only life I have. I'll be dead before I forget it.\n",
      "Real answer : Forget this. She always red red was her color.\n",
      "Bert Score : {'precision': [0.8341702222824097], 'recall': [0.853416919708252], 'f1': [0.8436838388442993], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666669, 'rouge2': 0.0, 'rougeL': 0.08333333333333334, 'rougeLsum': 0.08333333333333334}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 29.757478333163544\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSKULL COWBOY: Do this thing and you will be vulnerable. The blood will not return. No powers. No reunion. Nothing.\\nERIC: Fine with me.\\nSKULL COWBOY: You'll be alone.\\n\\n\", 'answer': \"I'm already alone.\", 'gold_tag': 'ERIC is in a state of isolation', 'last_speaker': 'ERIC'}\n",
      "Last word -> ERIC : \"I'm already alone.\"\n",
      "prediction :  I don't need the blood. I need you.\n",
      "Real answer : I'm already alone.\n",
      "Bert Score : {'precision': [0.8927690386772156], 'recall': [0.8982324600219727], 'f1': [0.895492434501648], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 36.88645286922691\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: Don't waste my time.\\n\\n\", 'answer': \"Very well, it's your ass.\", 'gold_tag': 'SKULL COWBOY speaks in a direct, no-nonsense manner', 'last_speaker': 'SKULL COWBOY'}\n",
      "Last word -> SKULL COWBOY : \"Very well, it's your ass.\"\n",
      "prediction :  What's the matter, Eric? You're getting a little too comfortable.\n",
      "Real answer : Very well, it's your ass.\n",
      "Bert Score : {'precision': [0.8481424450874329], 'recall': [0.8611322045326233], 'f1': [0.854587972164154], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18.821820666006456\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSWAY: Come back when you've learned how to drink, Billy --\\nMEMPHIS: See you're still stealing the sailors from the sea --\\n\\n\", 'answer': 'What are you doing here?', 'gold_tag': 'SWAY is familiar with MEMPHIS and is surprised at his presence', 'last_speaker': 'SWAY'}\n",
      "Last word -> SWAY : \"What are you doing here?\"\n",
      "prediction :  The sea's got nothing on you.\n",
      "Real answer : What are you doing here?\n",
      "Bert Score : {'precision': [0.8114891052246094], 'recall': [0.820438027381897], 'f1': [0.8159390091896057], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 48.83162436853899\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMEMPHIS: Gosh, no. Lipstick? What next? Mascara, blush,\\nSWAY: Deodorant.\\nMEMPHIS: Wow. Bozo, the very sexy clown --\\nSWAY: So, you seeing anybody?\\nMEMPHIS: No. I had a girl. She was great. The problem is: great girls come along once every ten years. So I gotta wait another three years before I can even bother to look...\\nSWAY: She was so great, why'd you leave her?\\n\\n\", 'answer': 'Her parole officer strongly recommended it ...', 'gold_tag': 'MEMPHIS insinuates that he did not have a choice in ending that relationship as it was recommended by her parole officer', 'last_speaker': 'MEMPHIS'}\n",
      "Last word -> MEMPHIS : \"Her parole officer strongly recommended it ...\"\n",
      "prediction :  Because I gotta have a girl who's great, not one who's good. And I don't know where she is, but I know she's out there.\n",
      "Real answer : Her parole officer strongly recommended it ...\n",
      "Bert Score : {'precision': [0.8162031173706055], 'recall': [0.8280899524688721], 'f1': [0.8221035599708557], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.092334581703756\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSWAY: What are you doing... ?\\nMEMPHIS: Seeing if you wanted to go for a ride?\\nSWAY: I can't. I got a back load of repairs and one of the mechanics called in sick and I haven't slept and-- (stops short; sees the new Eleanor Where to -- ?\\nMEMPHIS: I dunno. I know a place.\\nSWAY: This time it's for real?\\n\\n\", 'answer': 'Oh, yeah. For real, point-five.', 'gold_tag': \"MEMPHIS invites SWAY for a 'real' car ride\", 'last_speaker': 'MEMPHIS'}\n",
      "Last word -> MEMPHIS : \"Oh, yeah. For real, point-five.\"\n",
      "prediction :  You don't wanna know.\n",
      "Real answer : Oh, yeah. For real, point-five.\n",
      "Bert Score : {'precision': [0.8466107845306396], 'recall': [0.8375365138053894], 'f1': [0.8420491814613342], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 29.606835290643346\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGWEN: Unbelievable.\\nJOSH: What?\\nGWEN: I'm reading a stupid article in a stupid magazine.\\nJOSH: If it's stupid, why read it? Yeah. She's a bore.\\nGWEN: She's breaking up with her husband of twenty years. Said a friend,\\nJOSH: Some poor tree gave its life so we could know that.\\n\\n\", 'answer': \"It's comforting, reading about these broken marriages.\", 'gold_tag': 'GWEN finds comfort in reading about broken marriages', 'last_speaker': 'GWEN'}\n",
      "Last word -> GWEN : \"It's comforting, reading about these broken marriages.\"\n",
      "prediction :  Why do you always have to be so cynical?\n",
      "Real answer : It's comforting, reading about these broken marriages.\n",
      "Bert Score : {'precision': [0.8279603123664856], 'recall': [0.8611838817596436], 'f1': [0.8442453742027283], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18.982521573729585\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOSH: Why?\\nGWEN: It's not enough for our marriage to succeed. Everyone else's must fail.\\nJOSH: Is this going to be one of those nights?\\nGWEN: What?\\nJOSH: One of those nights we talk.\\nGWEN: No. There's no need to talk, because there's no problem.\\nJOSH: I've been under a lot of stress.\\nGWEN: You don't have to apologize. There's nothing wrong with the slump we're going through. In fact, it's a good thing.\\nJOSH: How's that?\\nGWEN: Too much passion can ruin a marriage. Look at Eric and Sylvia. At the beginning, you couldn't pry them apart. They were joined at the genitals. And, then...total burn-out. A marriage cannot sustain that kind of intensity. It's good for people to grow bored with each other. That way, they can meet and fall in love again. In case you hadn't noticed...I'm trying to seduce you.\\nJOSH: I can feel that.\\nGWEN: You're welcome to reciprocate.\\nJOSH: I can't.\\nGWEN: It's alright.\\nJOSH: To seduce...to be seduced, there needs to be an element of surprise. I know all your moves. You know mine. How can there be any surprise?\\nGWEN: Rub my feet. I think we should have an affair.\\nJOSH: What?\\nGWEN: With each other.\\nJOSH: That makes no sense.\\nGWEN: You pick me up at a bar...\\nJOSH: And, what? Pretend I don't know you?\\nGWEN: Or we could meet at a hotel. I'll register under my maiden name.\\nJOSH: college boy.\\nGWEN: When I met you, you were a college boy.\\nJOSH: badly for her.\\nGWEN: Alright. Bad example. You can stop.\\nJOSH: Actors pretend. That's what they do. I'm not an actor. And I love you the way you are.\\nGWEN: I love you, too.\\nJOSH: Pretending to be strangers is not going to solve the problem. Beat.\\n\\n\", 'answer': 'Who said there was a problem?', 'gold_tag': 'Everyday Language', 'last_speaker': 'GWEN'}\n",
      "Last word -> GWEN : \"Who said there was a problem?\"\n",
      "prediction :  I know.\n",
      "Real answer : Who said there was a problem?\n",
      "Bert Score : {'precision': [0.8705434799194336], 'recall': [0.8567919135093689], 'f1': [0.863612949848175], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 663.9337011017111\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGWEN: You missed the on-ramp.\\nJOSH: I know.\\nGWEN: Why?\\n\\n', 'answer': 'Somewhere we need to go first.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JOSH'}\n",
      "Last word -> JOSH : \"Somewhere we need to go first.\"\n",
      "prediction :  I don’t know.\n",
      "Real answer : Somewhere we need to go first.\n",
      "Bert Score : {'precision': [0.8411023020744324], 'recall': [0.8628407716751099], 'f1': [0.8518328666687012], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 81.41445378019965\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGWEN: We don't have to do this tonight.\\nJOSH: Yes, we do.\\nGWEN: We can't go in here. Everything's different.\\n\\n\", 'answer': \"That's okay. We're different, too.\", 'gold_tag': 'JOSH is experiencing a change tonight', 'last_speaker': 'JOSH'}\n",
      "Last word -> JOSH : \"That's okay. We're different, too.\"\n",
      "prediction :  I know.\n",
      "Real answer : That's okay. We're different, too.\n",
      "Bert Score : {'precision': [0.8929482698440552], 'recall': [0.8803812265396118], 'f1': [0.8866202235221863], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 663.9337011017111\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGWEN: Sarah\\'s a very interesting girl. Did you know she\\'s training for the marathon?\\nJOSH: I don\\'t want to talk about Sarah.\\nGWEN: What do you want to talk about, then?\\nJOSH: I want to talk about me... ...and what a fool I\\'ve been. I thought if we came here tonight we could...start again.\\nGWEN: But I thought you were over this place. And, look...There\\'s nothing left. Not one remnant of our first date...anywhere. You\\'re supposed to wait--\\nJOSH: I can\\'t wait. I have to know. \"You are on the verge of success\"...in bed.\\nGWEN: \"You will have a change of plans\"...in bed. Hmm. That\\'s what I\\'ve heard.\\nJOSH: The last cookie. Go ahead.\\nGWEN: No. You open it.\\n\\n', 'answer': \"It's blank. No, it's perfect. Blank...no problems, no history, nothing...in bed.\", 'gold_tag': 'JOSH is the more serious and introspective of the two', 'last_speaker': 'JOSH'}\n",
      "Last word -> JOSH : \"It's blank. No, it's perfect. Blank...no problems, no history, nothing...in bed.\"\n",
      "prediction :  (takes the cookie and eats it)\n",
      "Real answer : It's blank. No, it's perfect. Blank...no problems, no history, nothing...in bed.\n",
      "Bert Score : {'precision': [0.8315922021865845], 'recall': [0.8374795317649841], 'f1': [0.8345255255699158], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809522, 'rouge2': 0.0, 'rougeL': 0.09523809523809522, 'rougeLsum': 0.09523809523809522}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 45.658014309567065\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOSH: By the way, I didn't get your name.\\nGWEN: What? Oh, my name. My name is Gail. Gail Bonds.\\nJOSH: Well, Gail, I'm not usually this forward on a first date, may I take you to my car and ravish you?\\nGWEN: Hmm. On one condition.\\nJOSH: What's that?\\nGWEN: That you tell me your name.\\n\\n\", 'answer': \"Oh, I thought everyone knew my name. I'm Bill Gates. Billionaire.\", 'gold_tag': 'JOSH introduces himself jokingly as Bill Gates , JOSH claims to be a billionaire', 'last_speaker': 'JOSH'}\n",
      "Last word -> JOSH : \"Oh, I thought everyone knew my name. I'm Bill Gates. Billionaire.\"\n",
      "prediction :  Josh.\n",
      "Real answer : Oh, I thought everyone knew my name. I'm Bill Gates. Billionaire.\n",
      "Bert Score : {'precision': [0.9251351356506348], 'recall': [0.8433322906494141], 'f1': [0.882341742515564], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 6905.092471407262\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGWEN: Is it true what they say, Bill, about billionaires? That all the wealth is just a way to compensate...for size?\\nJOSH: People are jealous.\\nGWEN: I can imagine. It must be so lonely at the top. What are you doing?\\nJOSH: What do you think I'm doing?\\nGWEN: We're not in a bed.\\n\\n\", 'answer': \"You shouldn't read fortune cookies too literally. ...Can anyone see us?...Is anyone looking?...Why should it bother you? You're alone...with your wife...That's the way it's supposed to be...You know every inch of her...every smell...every sigh...every freckle...the shape of her ass...the mole under her nipple...the whole history of her body...And, you know that if you really concentrate, you can succeed...in imagining...she's someone you don't know...\", 'gold_tag': 'JOSH is defensive about his wealth , JOSH is unfaithful, insinuating illicit activities', 'last_speaker': 'JOSH'}\n",
      "Last word -> JOSH : \"You shouldn't read fortune cookies too literally. ...Can anyone see us?...Is anyone looking?...Why should it bother you? You're alone...with your wife...That's the way it's supposed to be...You know every inch of her...every smell...every sigh...every freckle...the shape of her ass...the mole under her nipple...the whole history of her body...And, you know that if you really concentrate, you can succeed...in imagining...she's someone you don't know...\"\n",
      "prediction :  That's right.\n",
      "Real answer : You shouldn't read fortune cookies too literally. ...Can anyone see us?...Is anyone looking?...Why should it bother you? You're alone...with your wife...That's the way it's supposed to be...You know every inch of her...every smell...every sigh...every freckle...the shape of her ass...the mole under her nipple...the whole history of her body...And, you know that if you really concentrate, you can succeed...in imagining...she's someone you don't know...\n",
      "Bert Score : {'precision': [0.8546899557113647], 'recall': [0.7730298042297363], 'f1': [0.8118115067481995], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.046511627906976744, 'rouge2': 0.023809523809523808, 'rougeL': 0.046511627906976744, 'rougeLsum': 0.046511627906976744}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 65.67370267700424\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOSH: You're right. We could use some more color in the living room.\\nGWEN: Yes?\\nJOSH: I said you're right.\\nGWEN: About what?\\nJOSH: About more color in the living room.\\n\\n\", 'answer': \"Oh. I'm glad you think so.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'GWEN'}\n",
      "Last word -> GWEN : \"Oh. I'm glad you think so.\"\n",
      "prediction :  And what do you think about this?\n",
      "Real answer : Oh. I'm glad you think so.\n",
      "Bert Score : {'precision': [0.8289318084716797], 'recall': [0.8574813604354858], 'f1': [0.8429648876190186], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2857142857142857, 'rouge2': 0.16666666666666666, 'rougeL': 0.2857142857142857, 'rougeLsum': 0.2857142857142857}\n",
      "bleu 1/2 : 0.2857142857142857 0.2182178902359924\n",
      "ppl : 51.33173580900531\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJUDITH: Good morning Tom Quiney. A barrel of Huffcap ale and three flagons of Malmesey wine to be delivered to New Place if you would. On our account.\\nQUINEY: Your usual order and my usual reply. Marry me Judith. I would help bring back your smile.\\nJUDITH: Yes and every other maid in the county’s. You chase them all.\\nQUINEY: But I only ever propose to one.\\nJUDITH: I’d think you’d tire of it.\\n\\n', 'answer': 'I remember a girl. The prettiest and happiest in town. And I remember her laugh and I remember kiss chase. I’d like to see the woman that girl should have become. Because it surely isn’t you. All Is True - Shooting Script', 'gold_tag': \"QUINEY remembers JUDITH as the prettiest and happiest girl in town, her laughter, and playing 'kiss chase' together , QUINEY has a romantic vision of JUDITH\", 'last_speaker': 'QUINEY'}\n",
      "Last word -> QUINEY : \"I remember a girl. The prettiest and happiest in town. And I remember her laugh and I remember kiss chase. I’d like to see the woman that girl should have become. Because it surely isn’t you. All Is True - Shooting Script\"\n",
      "prediction :  I'm not tired. I'm not tired.\n",
      "Real answer : I remember a girl. The prettiest and happiest in town. And I remember her laugh and I remember kiss chase. I’d like to see the woman that girl should have become. Because it surely isn’t you. All Is True - Shooting Script\n",
      "Bert Score : {'precision': [0.8693220019340515], 'recall': [0.8172607421875], 'f1': [0.8424878120422363], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07843137254901962, 'rouge2': 0.0, 'rougeL': 0.07843137254901962, 'rougeLsum': 0.07843137254901962}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.9761760311898\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nQUINEY: A glass Miss Shakespeare? To toast this sunny morning?\\nJUDITH: I need no excuse for a glass of wine Mr. Quiney. Beat.\\nQUINEY: There is another pleasure, equally heady.\\nJUDITH: And plenty of country girls for you to get it with.\\nQUINEY: Your looks won’t last forever Jude.\\n\\n', 'answer': 'And I shall be glad when they’re gone because I shall be no more bothered by the likes of you.', 'gold_tag': 'JUDITH is bothered by QUINEY or similar types', 'last_speaker': 'JUDITH'}\n",
      "Last word -> JUDITH : \"And I shall be glad when they’re gone because I shall be no more bothered by the likes of you.\"\n",
      "prediction :  Neither will you.\n",
      "Real answer : And I shall be glad when they’re gone because I shall be no more bothered by the likes of you.\n",
      "Bert Score : {'precision': [0.8744434118270874], 'recall': [0.8352270126342773], 'f1': [0.8543854355812073], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08333333333333333, 'rouge2': 0.0, 'rougeL': 0.08333333333333333, 'rougeLsum': 0.08333333333333333}\n",
      "bleu 1/2 : 0.001153125778821586 0.0004466036937458461\n",
      "ppl : 428.6259148377796\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nQUINEY: You know that I am not a good man. There have been women. Many women.\\n\\n', 'answer': 'I have seen too little of life. You’ve seen too much. Between us perhaps we may begin again.', 'gold_tag': 'JUDITH has led a sheltered life , QUINEY acknowledges his moral shortcomings', 'last_speaker': 'JUDITH'}\n",
      "Last word -> JUDITH : \"I have seen too little of life. You’ve seen too much. Between us perhaps we may begin again.\"\n",
      "prediction :  I know that you are a good man.\n",
      "Real answer : I have seen too little of life. You’ve seen too much. Between us perhaps we may begin again.\n",
      "Bert Score : {'precision': [0.8750155568122864], 'recall': [0.8551677465438843], 'f1': [0.8649777770042419], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14814814814814814, 'rouge2': 0.0, 'rougeL': 0.14814814814814814, 'rougeLsum': 0.14814814814814814}\n",
      "bleu 1/2 : 0.03581309960752377 0.01210703740332595\n",
      "ppl : 38.18732821282954\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJUDITH: I saw Margaret Wheeler in the Church today Tom.\\n\\n', 'answer': 'I know it Judith and I have confessed all to you. I can not undo what is done. All I can say is that her child and she will not want.', 'gold_tag': 'QUINEY has confessed a past mistake involving Margaret Wheeler and her child , QUINEY has revealed a level of responsibility', 'last_speaker': 'QUINEY'}\n",
      "Last word -> QUINEY : \"I know it Judith and I have confessed all to you. I can not undo what is done. All I can say is that her child and she will not want.\"\n",
      "prediction :  Oh, did you?\n",
      "Real answer : I know it Judith and I have confessed all to you. I can not undo what is done. All I can say is that her child and she will not want.\n",
      "Bert Score : {'precision': [0.8214901685714722], 'recall': [0.8109837770462036], 'f1': [0.8162031173706055], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0588235294117647, 'rouge2': 0.0, 'rougeL': 0.0588235294117647, 'rougeLsum': 0.0588235294117647}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 366.1748607741317\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOBB V.O.: It's cookin', Bud. It's cookin' fast.\\n\\n\", 'answer': \"Mike, I've got Edgar Bingham now. Just showed with two of his crew, for a sit down with Kay.\", 'gold_tag': 'BUD is involved in some kind of operation , BUD is currently dealing with Edgar Bingham and his crew', 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"Mike, I've got Edgar Bingham now. Just showed with two of his crew, for a sit down with Kay.\"\n",
      "prediction :  Oh, man.\n",
      "Real answer : Mike, I've got Edgar Bingham now. Just showed with two of his crew, for a sit down with Kay.\n",
      "Bert Score : {'precision': [0.8813157081604004], 'recall': [0.8416181802749634], 'f1': [0.8610096573829651], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 303.4053714103693\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOBB V.O.: Negative at Tibedaux's. Can't walk in. What's our move?\\n\\n\", 'answer': 'We wait.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"We wait.\"\n",
      "prediction :  We're out of moves.\n",
      "Real answer : We wait.\n",
      "Bert Score : {'precision': [0.8528691530227661], 'recall': [0.873146653175354], 'f1': [0.8628888130187988], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 103.02617299979931\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBUD: It's Jesse...\\nCOBB V.O.: He's heading toward the alley, Bud. We take him down?\\nBUD: Let him go.\\nCOBB V.O.: What?!\\nBUD: Let him go.\\nCOBB V.O.: Bud, that's crazy! Jesse goes in first, can't let that happen.\\n\\n\", 'answer': \"That's exactly what we're gonna do! We got no way inside. Let Jesse go in hard and draw fire. He pushes Lucian out to us. Stand the fuck down. I'm on my way.\", 'gold_tag': 'BUD is authoritative, decisive, and strategic , BUD is a law enforcement officer or similar, given his command over the situation and terminology used', 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"That's exactly what we're gonna do! We got no way inside. Let Jesse go in hard and draw fire. He pushes Lucian out to us. Stand the fuck down. I'm on my way.\"\n",
      "prediction :  Let him go!\n",
      "Real answer : That's exactly what we're gonna do! We got no way inside. Let Jesse go in hard and draw fire. He pushes Lucian out to us. Stand the fuck down. I'm on my way.\n",
      "Bert Score : {'precision': [0.8905534744262695], 'recall': [0.8306782245635986], 'f1': [0.8595744371414185], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10256410256410256, 'rouge2': 0.0, 'rougeL': 0.10256410256410256, 'rougeLsum': 0.10256410256410256}\n",
      "bleu 1/2 : 1.5133309920828285e-05 5.861105729636343e-06\n",
      "ppl : 318.9783931151721\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBLANCA: So how’s that thing?\\nMARIA: What thing?\\nBLANCA: Your job? What do you have to do?\\nMARIA: I told you not to talk about it.\\nBLANCA: Maria... Maria, look at me!\\nMARIA: What the hell are you doing?\\nBLANCA: I’m going to be a mule. I talked to Franklin and he arranged it.\\nMARIA: You what?\\nBLANCA: You heard me. Why not?\\nMARIA: Because you can’t... you won’t make it.\\nBLANCA: Well, I’m doing it. I already told them.\\nMARIA: Blanca, what the hell...?\\nBLANCA: It’s five thousand dollars, Maria. Do you know how much that is in pesos? I figured it out. It’s like ten million. I can buy my family a house with that.\\nMARIA: You can’t go.\\nBLANCA: You know what? I don’t need your permission. I can do what I want.\\nMARIA: Do you realize what you’re saying...? Blanca you have to tell them you’re not\\nBLANCA: No... Anyway, I can’t now. I already said yes.\\nMARIA: ...Do you know what you’re going to tell your family?\\n\\n', 'answer': 'Do you?', 'gold_tag': 'Everyday Language', 'last_speaker': 'BLANCA'}\n",
      "Last word -> BLANCA : \"Do you?\"\n",
      "prediction :  I'm going to tell them that I have a new job.\n",
      "Real answer : Do you?\n",
      "Bert Score : {'precision': [0.8454765677452087], 'recall': [0.8390277624130249], 'f1': [0.8422398567199707], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.606122652726413\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBLANCA: ...How are you doing?\\n\\n', 'answer': '...OK.... You?', 'gold_tag': 'Everyday Language', 'last_speaker': 'MARIA'}\n",
      "Last word -> MARIA : \"...OK.... You?\"\n",
      "prediction :  I am doing well, thank you.\n",
      "Real answer : ...OK.... You?\n",
      "Bert Score : {'precision': [0.8616079092025757], 'recall': [0.8246496915817261], 'f1': [0.8427237868309021], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 52.93244892140506\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBLANCA: What are you doing?\\nMARIA: We can’t stay here?\\nBLANCA: What do you mean?\\nMARIA: Don’t you get it? They did something to Lucy? Everything’s totally fucked up. We have to get out of here before they come back.\\nBLANCA: But...\\n\\n', 'answer': 'Hurry up!!', 'gold_tag': 'Everyday Language', 'last_speaker': 'MARIA'}\n",
      "Last word -> MARIA : \"Hurry up!!\"\n",
      "prediction :  It’s not safe here. They could find us.\n",
      "Real answer : Hurry up!!\n",
      "Bert Score : {'precision': [0.8439751863479614], 'recall': [0.782211184501648], 'f1': [0.8119202852249146], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 35.92692234137646\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMELANIE: What made it...\\n\\n', 'answer': \"It deliberately came down at you -- you're bleeding...\", 'gold_tag': 'MELANIE is currently bleeding', 'last_speaker': 'MITCH'}\n",
      "Last word -> MITCH : \"It deliberately came down at you -- you're bleeding...\"\n",
      "prediction :  I don't know. It was...it was just this feeling I had. I knew I had to do something.\n",
      "Real answer : It deliberately came down at you -- you're bleeding...\n",
      "Bert Score : {'precision': [0.8276514410972595], 'recall': [0.8230322003364563], 'f1': [0.8253353834152222], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06896551724137932, 'rouge2': 0.0, 'rougeL': 0.06896551724137932, 'rougeLsum': 0.06896551724137932}\n",
      "bleu 1/2 : 0.05555555555555554 0.018077538151554672\n",
      "ppl : 11.608547676295236\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMITCH: You\\'ll be able to find your way back, won\\'t you?\\nMELANIE: Oh, yes. Will I be seeing you again? San Francisco\\'s a long way from here.\\nMITCH: I\\'m in San Francisco five days a week. With a lot of time on my hands. I\\'d like to see you. Maybe we could go swimming or something. Mother tells me you like to swim.\\nMELANIE: How does Mother know what I like to do?\\nMITCH: I guess she and I read the same gossip columns.\\nMELANIE: Oh. That. Rome.\\nMITCH: Mmmm. I like to swim. We might get along very...\\nMELANIE: In case you\\'re interested, I was pushed into that fountain. Without any clothes on? With all my clothes on! The newspaper that ran the story happens to be a rival of my father\\'s paper. Anything they said...\\nMITCH: You were just a poor, innocent victim of circumstance, huh?\\nMELANIE: I\\'m neither poor nor innocent, but the truth of that particular...\\nMITCH: The truth is you were running around with a pretty wild crowd...\\nMELANIE: Yes, but...\\nMITCH: ...who didn\\'t much care for propriety or convention or...\\nMELANIE: Yes.\\nMITCH: ...the opinions of others, and you went right along with them, isn\\'t that the truth?\\nMELANIE: Yes, that\\'s the truth. But I was pushed into that fountain, and that\\'s the truth, too.\\nMITCH: Sure. Do you really know Annie Hayworth?\\nMELANIE: No. At least, I didn\\'t until I came up here.\\nMITCH: So you didn\\'t go to school together.\\nMELANIE: No.\\nMITCH: And you didn\\'t come up here to see her.\\nMELANIE: No.\\nMITCH: You were lying.\\nMELANIE: Yes, I was lying.\\nMITCH: Did you really write a letter to me? Or was that a lie, too?\\nMELANIE: I wrote the letter.\\nMITCH: What did it say?\\nMELANIE: It said, \"Dear Mr. Brenner, I think you need those lovebirds, after all. They may help your personality.\" That\\'s what it said.\\nMITCH: But you tore it up.\\nMELANIE: Yes.\\nMITCH: Why?\\nMELANIE: Because it seemed stupid and foolish.\\nMITCH: Like jumping into a fountain in Rome!\\nMELANIE: I told you what happened in Rome!\\nMITCH: Do you expect me to believe...?\\nMELANIE: I don\\'t give a damn what you believe!\\nMITCH: I\\'d still like to see you.\\nMELANIE: Why?\\nMITCH: I think it could be fun.\\nMELANIE: That might have been good enough in Rome last summer. But it\\'s not good enough now.\\nMITCH: It is for me.\\nMELANIE: But not for me.\\nMITCH: What do you want ?\\n\\n', 'answer': 'I thought you knew! I want to go through life laughing and beautiful and jumping into fountains naked! Good night!', 'gold_tag': 'MELANIE is known to be part of a wild crowd and disregards propriety and convention', 'last_speaker': 'MELANIE'}\n",
      "Last word -> MELANIE : \"I thought you knew! I want to go through life laughing and beautiful and jumping into fountains naked! Good night!\"\n",
      "prediction :  I want the truth.\n",
      "Real answer : I thought you knew! I want to go through life laughing and beautiful and jumping into fountains naked! Good night!\n",
      "Bert Score : {'precision': [0.912906289100647], 'recall': [0.8220497369766235], 'f1': [0.8650990128517151], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666669, 'rouge2': 0.09090909090909091, 'rougeL': 0.16666666666666669, 'rougeLsum': 0.16666666666666669}\n",
      "bleu 1/2 : 0.00915781944436709 0.007477328265079177\n",
      "ppl : 212.8104004145285\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMITCH: It smelled of the fire.\\nMELANIE: It\\'s hard to believe anything at all happened yesterday, isn\\'t it? It\\'s so beautiful and still now. I think I\\'ve got it all figured out, by the way.\\nMITCH: Really? Tell me about it.\\nMELANIE: It\\'s an uprising.\\nMITCH: Of birds?\\nMELANIE: Certainly, of birds. It all started several months ago with a peasant sparrow up in the hills, a malcontent. He went around telling all the other sparrows that human beings weren\\'t fit to rule this planet, preaching wherever anyone would listen...\\nMITCH: Growing a beard...\\nMELANIE: Yes, of course, he had to have a beard! \\'Birds of the world, unite!\\' he kept saying, over and over...\\nMITCH: So they united.\\nMELANIE: Not at first. Oh yes, a few sparrows out for kicks...\\nMITCH: Well, they\\'ll go along with anything.\\nMELANIE: Sure. But eventually, even the more serious-minded birds began to listen. \"Why should humans rule?\" they asked themselves.\\nMITCH: Hear!\\nMELANIE: Why should we submit ourselves to their domination?\\nMITCH: Hear, hear!\\nMELANIE: And all the while, that sparrow was getting in his little messages. Birds of the world, unite!\\nMITCH: Take wing!\\nMELANIE: You have nothing to lose but your feathers.\\nMITCH: What it was, probably...\\nMELANIE: Mmm?\\nMITCH: They\\'re probably hungry, that\\'s all. This was a bad summer. They eat berries and... and nuts, you know, and the hills are all burned out, so\\nMELANIE: With my little sparrow leading team.\\nMITCH: It\\'s so damn quiet out there.\\nMELANIE: It was like that yesterday.\\nMITCH: What do you mean?\\nMELANIE: After the gulls attacked.\\nMITCH: I hadn\\'t thought of that. And then the swifts came.\\nMELANIE: It makes you feel as if they\\'re...\\n\\n', 'answer': \"No, they're having a meeting, Melanie. Your sparrow is standing on a soap box and...\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MITCH'}\n",
      "Last word -> MITCH : \"No, they're having a meeting, Melanie. Your sparrow is standing on a soap box and...\"\n",
      "prediction : ... as if they're trying to kill us.\n",
      "Real answer : No, they're having a meeting, Melanie. Your sparrow is standing on a soap box and...\n",
      "Bert Score : {'precision': [0.8586227893829346], 'recall': [0.841673731803894], 'f1': [0.8500638008117676], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.09090909090909091, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.05210775245981356 0.0176156354783007\n",
      "ppl : 34.827827498255154\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMELANIE: They were angry, Mitch. They came out of the chimney in fury. I had the feeling they wanted each and every one of us dead.\\nMITCH: Melanie, Melanie...\\nMELANIE: I'm frightened, Mitch.\\nMITCH: No, no...\\nMELANIE: I'm frightened and confused and I... I think I want to go back to San Francisco where there are buildings and... and concrete and...\\nMITCH: Melanie...\\n\\n\", 'answer': '...everything I know. Oh damn it, why did you have to walk into that shop?', 'gold_tag': 'MELANIE refers to a past event where MITCH walked into a shop which presumably led to their current predicament', 'last_speaker': 'MELANIE'}\n",
      "Last word -> MELANIE : \"...everything I know. Oh damn it, why did you have to walk into that shop?\"\n",
      "prediction :  No, listen to me. I can't do this. I can't go on.\n",
      "Real answer : ...everything I know. Oh damn it, why did you have to walk into that shop?\n",
      "Bert Score : {'precision': [0.8685784935951233], 'recall': [0.856718122959137], 'f1': [0.8626075387001038], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1379310344827586, 'rouge2': 0.0, 'rougeL': 0.0689655172413793, 'rougeLsum': 0.0689655172413793}\n",
      "bleu 1/2 : 0.12980013051190084 0.030314779366662815\n",
      "ppl : 13.511902154623037\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMITCH: That was Al on the phone. He wants me to meet him out at the Fawcett place. Says some detectives from Santa Rosa'll be there in a little while. Will you be all right here?\\n\\n\", 'answer': 'Yes. I was just taking her in some tea. Be careful. Please.', 'gold_tag': \"MELANIE is caring, as she was about to take someone tea , MELANIE's immediate plan is taking tea to someone , MELANIE is concerned for MITCH's safety\", 'last_speaker': 'MELANIE'}\n",
      "Last word -> MELANIE : \"Yes. I was just taking her in some tea. Be careful. Please.\"\n",
      "prediction :  Of course.\n",
      "Real answer : Yes. I was just taking her in some tea. Be careful. Please.\n",
      "Bert Score : {'precision': [0.894542932510376], 'recall': [0.8560182452201843], 'f1': [0.8748565912246704], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 372.21681075022684\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMELANIE: When will they stop?\\nMITCH: I thought they'd have stopped by\\nMELANIE: What time is it?\\nMITCH: Almost two a.m.\\nMELANIE: You must be exhausted.\\n\\n\", 'answer': 'How about you? I wonder if Cathy fed them.', 'gold_tag': 'MITCH cares about his family , MITCH remembered to check if Cathy fed the birds', 'last_speaker': 'MITCH'}\n",
      "Last word -> MITCH : \"How about you? I wonder if Cathy fed them.\"\n",
      "prediction :  I'm not. I'm just so angry.\n",
      "Real answer : How about you? I wonder if Cathy fed them.\n",
      "Bert Score : {'precision': [0.8595468997955322], 'recall': [0.838689923286438], 'f1': [0.8489903211593628], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 33.03389894769616\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMITCH: You should have left when you wanted to. You'd have been safe in San Francisco.\\nMELANIE: I don't want to be safe. I want to be with you.\\nMITCH: The power.\\nMELANIE: Mitch...\\nMITCH: Wait here. Don't move. We'd better light some of those lamps.\\nMELANIE: No... wait. Hold me.\\n\\n\", 'answer': \"I think they're easing off.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MITCH'}\n",
      "Last word -> MITCH : \"I think they're easing off.\"\n",
      "prediction :  I'll be right back.\n",
      "Real answer : I think they're easing off.\n",
      "Bert Score : {'precision': [0.8145566582679749], 'recall': [0.8658270835876465], 'f1': [0.8394097685813904], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1818181818181818, 'rouge2': 0.0, 'rougeL': 0.1818181818181818, 'rougeLsum': 0.1818181818181818}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 52.10948404977269\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMITCH: Here we go.\\n\\n', 'answer': 'Mitch!', 'gold_tag': 'Everyday Language', 'last_speaker': 'MELANIE'}\n",
      "Last word -> MELANIE : \"Mitch!\"\n",
      "prediction :  What do you think?\n",
      "Real answer : Mitch!\n",
      "Bert Score : {'precision': [0.8111445903778076], 'recall': [0.8668140769004822], 'f1': [0.8380557894706726], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 53.25875838002556\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEMMETT: She married an old man, she's made a living on telling women they're too fat, she hawks her crap on the Home Shopping Network...\\nELLE: But maybe it's not what you think.\\nEMMETT: Bu t maybe it is-- . How do you figure?\\nELLE: Because people aren't always what they seem to be and you refuse to see that. Have a little faith. You might be surprised.\\nEMMETT: I can't believe you called me a butt- head. No one's called me a butt-head since ninth grade.\\n\\n\", 'answer': 'Maybe not to your face...', 'gold_tag': 'ELLE calling EMMETT a butt-head in the past', 'last_speaker': 'ELLE'}\n",
      "Last word -> ELLE : \"Maybe not to your face...\"\n",
      "prediction :  Emmet, you're not thinking about this right.\n",
      "Real answer : Maybe not to your face...\n",
      "Bert Score : {'precision': [0.8207738399505615], 'recall': [0.8145846724510193], 'f1': [0.8176674842834473], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615385, 'rouge2': 0.0, 'rougeL': 0.15384615384615385, 'rougeLsum': 0.15384615384615385}\n",
      "bleu 1/2 : 0.14285714285714285 0.048795003647426664\n",
      "ppl : 52.77298250934339\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELLE: I'll cover her -- parts.\\nEMMETT: Well, that's what we're trying to prove didn't happen. Do you have any reason to believe it did?\\nELLE: She's not!\\n\\n\", 'answer': \"Did your daughter ever say anything to you about Brooke and Heyworth's relationship? an infomercial? She said they humped like Much as it is for me, hearing you tell about it. Why do you say that? Ys. . . . e I didn't stick around long enough to watch him stick his swizzle stick in her that ' s where he was about to put it .\", 'gold_tag': 'EMMETT is trying to deduce facts and understand the situation', 'last_speaker': 'EMMETT'}\n",
      "Last word -> EMMETT : \"Did your daughter ever say anything to you about Brooke and Heyworth's relationship? an infomercial? She said they humped like Much as it is for me, hearing you tell about it. Why do you say that? Ys. . . . e I didn't stick around long enough to watch him stick his swizzle stick in her that ' s where he was about to put it .\"\n",
      "prediction :  That's not a reason.\n",
      "Real answer : Did your daughter ever say anything to you about Brooke and Heyworth's relationship? an infomercial? She said they humped like Much as it is for me, hearing you tell about it. Why do you say that? Ys. . . . e I didn't stick around long enough to watch him stick his swizzle stick in her that ' s where he was about to put it .\n",
      "Bert Score : {'precision': [0.841680645942688], 'recall': [0.7875468134880066], 'f1': [0.8137143850326538], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.057971014492753624, 'rouge2': 0.029850746268656716, 'rougeL': 0.057971014492753624, 'rougeLsum': 0.057971014492753624}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 68.6065050339829\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELLE: I never trust a woman who's not blonde. Except for my friend Serena, but that's only because she's a blonde at heart. That's the whole reason I ' m starting the Blonde Legal Defense Fund. Blondes are discriminated against worldwide! Brooke's a blonde, and people are saying she's sleeping with the cheesy pool boy and shooting her husband. If she was a mousy brunette, it would be,\\nEMMETT: You're serious?\\nELLE: You should see the way I ' m treated in class! I'm a complete source of mockery. This is why the Blonde Legal Defense Fund is needed.\\nEMMETT: -- I can't.\\nELLE: discrimination! If she were a true blonde, she would've left the cheating bastard. Blondes don't let their husbands get fellated by brunettes and live to tell about it. caught him.\\nEMMETT: That's not really a topic that keeps me up at night -- but maybe it should.\\nELLE: Speaking of that �-- I bought you some seaweed cream while we were at the spa. The bags under your eyes. You're an better care of yourself.\\nEMMETT: I don't -- Do that stuff.\\nELLE: Well, you should --. I f you look good, you � feel good and if you feel good, you project joy into the world. Fine. Sorry I brought it up.\\nEMMETT: You really think I ' m attractive?\\n\\n\", 'answer': 'For a butt-head? Yes.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ELLE'}\n",
      "Last word -> ELLE : \"For a butt-head? Yes.\"\n",
      "prediction :  I think you're attractive. I don't know if you're the right man for me, but I think you're attractive.\n",
      "Real answer : For a butt-head? Yes.\n",
      "Bert Score : {'precision': [0.8335998058319092], 'recall': [0.842043399810791], 'f1': [0.8378002643585205], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07142857142857142, 'rouge2': 0.0, 'rougeL': 0.07142857142857142, 'rougeLsum': 0.07142857142857142}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5.750504587377784\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEMMETT: Whoa -- Why? internship was a mistake. What're you talking about? You earned it-\\nELLE: I didn't earn anything. I got this\\nEMMETT: So now you're --? Going back to LA. Maybe I can fulfill my destiny as a useless bimbo and join the Swedish Bikini Team. No more navy blue suits. No more panty-hose. No more trying to be something I ' m not. What if you're trying to be something you are? The hell with Donovan. Stay.\\n\\n\", 'answer': \"Thanks for not treating me the way everyone else here does. Call me if you're ever in California.\", 'gold_tag': 'Elle is considering returning to Los Angeles , Elle reveals her struggle with conforming to a certain persona , Elle is contemplating leaving her current location and returning to LA', 'last_speaker': 'ELLE'}\n",
      "Last word -> ELLE : \"Thanks for not treating me the way everyone else here does. Call me if you're ever in California.\"\n",
      "prediction :  I'm sorry. I can't.\n",
      "Real answer : Thanks for not treating me the way everyone else here does. Call me if you're ever in California.\n",
      "Bert Score : {'precision': [0.8800997138023376], 'recall': [0.832048773765564], 'f1': [0.855400025844574], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.83958938113242\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTREVOR: Hey there, boy. You're a good dog. Yes, you are.\\nELLEN: Sorry for reacting the way I did back there.\\nTREVOR: Don't apologize. That's how most\\nELLEN: Didn't scare me. It just surprised me. ... Thanks for dinner. I had a good time.\\nTREVOR: You're welcome.\\nELLEN: Here... you need a little life in that place of yours.\\nTREVOR: ... Good night.\\n\\n\", 'answer': '... Night.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ELLEN'}\n",
      "Last word -> ELLEN : \"... Night.\"\n",
      "prediction :  You're welcome.\n",
      "Real answer : ... Night.\n",
      "Bert Score : {'precision': [0.8283596038818359], 'recall': [0.8810411691665649], 'f1': [0.8538886308670044], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 74.10636759224718\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELLEN: ... I have to fly up there for a computer conference.\\nTREVOR: When's that?\\nELLEN: Day after tomorrow.\\n\\n\", 'answer': 'Never been to San Francisco.', 'gold_tag': 'TREVOR has never been to San Francisco', 'last_speaker': 'TREVOR'}\n",
      "Last word -> TREVOR : \"Never been to San Francisco.\"\n",
      "prediction :  That's good. You should go.\n",
      "Real answer : Never been to San Francisco.\n",
      "Bert Score : {'precision': [0.8564879894256592], 'recall': [0.8594743013381958], 'f1': [0.8579785227775574], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 54.83238815019819\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTREVOR: If you want, I'll take care of Jack.\\nELLEN: I can't ask you to do that.\\n\\n\", 'answer': 'Sure you can.', 'gold_tag': 'Trevor is helpful and supportive', 'last_speaker': 'TREVOR'}\n",
      "Last word -> TREVOR : \"Sure you can.\"\n",
      "prediction :  Why not?\n",
      "Real answer : Sure you can.\n",
      "Bert Score : {'precision': [0.851506769657135], 'recall': [0.877126932144165], 'f1': [0.8641270399093628], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 712.3091117331476\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELLEN: ... These conferences mainly focus on software now.\\nTREVOR: Software sells.\\nELLEN: So, how's Jack?\\nTREVOR: ... Jack's good.\\nELLEN: And what about Trevor? Was Trevor a good boy, too?\\nTREVOR: What's that supposed to mean?\\nELLEN: Nothing...\\nTREVOR: Is that supposed to mean something?\\n\\n\", 'answer': 'Trevor...', 'gold_tag': 'Everyday Language', 'last_speaker': 'ELLEN'}\n",
      "Last word -> ELLEN : \"Trevor...\"\n",
      "prediction :  Did Jack ask you to find him a new job?\n",
      "Real answer : Trevor...\n",
      "Bert Score : {'precision': [0.8251160979270935], 'recall': [0.8401437997817993], 'f1': [0.8325621485710144], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 63.612567333872484\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTREVOR: Jack?\\n\\n', 'answer': 'Here, boy... here, Jack. Come to Mommy, sweetheart. ... Oh, my God. Jack?!', 'gold_tag': \"ELLEN calls to Jack like a mother to a child  , ELLEN shows concern when he doesn't respond\", 'last_speaker': 'ELLEN'}\n",
      "Last word -> ELLEN : \"Here, boy... here, Jack. Come to Mommy, sweetheart. ... Oh, my God. Jack?!\"\n",
      "prediction :  Yes?\n",
      "Real answer : Here, boy... here, Jack. Come to Mommy, sweetheart. ... Oh, my God. Jack?!\n",
      "Bert Score : {'precision': [0.8439938426017761], 'recall': [0.7955505847930908], 'f1': [0.8190564513206482], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 9554.816423904052\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTREVOR: It's aspirin...\\nELLEN: ... I can't talk to you right now, Trevor. Please. I'm so upset I can't even drive. I just need some time alone.\\n\\n\", 'answer': \"I know about what's not fair. I left part of my lung in a damn hospital because some gangbanger didn't like the grade I gave him. Sometimes you do all the right things. You work hard in school... get a good job... pay your taxes. Things still go bad. I'm so sorry, Ellen.\", 'gold_tag': \"TREVOR is a hard-working individual , TREVOR has experienced a serious health issue due to violence , TREVOR possibly indicates he's a teacher , TREVOR's past includes a hospital stay where part of his lung was removed\", 'last_speaker': 'TREVOR'}\n",
      "Last word -> TREVOR : \"I know about what's not fair. I left part of my lung in a damn hospital because some gangbanger didn't like the grade I gave him. Sometimes you do all the right things. You work hard in school... get a good job... pay your taxes. Things still go bad. I'm so sorry, Ellen.\"\n",
      "prediction :  Ellen, I know this is hard for you, but I have to tell you something.\n",
      "Real answer : I know about what's not fair. I left part of my lung in a damn hospital because some gangbanger didn't like the grade I gave him. Sometimes you do all the right things. You work hard in school... get a good job... pay your taxes. Things still go bad. I'm so sorry, Ellen.\n",
      "Bert Score : {'precision': [0.8635032176971436], 'recall': [0.8267157077789307], 'f1': [0.8447090983390808], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.19718309859154928, 'rouge2': 0.028985507246376805, 'rougeL': 0.11267605633802816, 'rougeLsum': 0.11267605633802816}\n",
      "bleu 1/2 : 0.026464644092359407 0.012250749717016621\n",
      "ppl : 9.99052528839446\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELLEN: ... I'd like to apologize for the other night.\\nTREVOR: Shouldn't listen to me. I was half asleep.\\nELLEN: We really need to talk.\\nTREVOR: ... Not tonight. Have to finish some work...\\nELLEN: Tomorrow then? It's important to me.\\nTREVOR: ... Okay.\\n\\n\", 'answer': \"... How 'bout seven o'clock?\", 'gold_tag': \"ELLEN wants to have a talk with TREVOR by seven o'clock tomorrow\", 'last_speaker': 'ELLEN'}\n",
      "Last word -> ELLEN : \"... How 'bout seven o'clock?\"\n",
      "prediction :  Thank you.\n",
      "Real answer : ... How 'bout seven o'clock?\n",
      "Bert Score : {'precision': [0.8607449531555176], 'recall': [0.7977200150489807], 'f1': [0.8280349373817444], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 255.93043327652487\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHEPARD: You want to go back inside?\\nWHITACRE: I think they might have it bugged. We're safer out here.\\nSHEPARD: Bugged? What?\\nWHITACRE: This used to be Dwayne Andreas' house, you know that?\\nSHEPARD: I'm aware of that.\\nWHITACRE: There are things I know, but if I decide to tell you what's going on, could I be prosecuted for it?\\n\\n\", 'answer': \"I can't provide you with immunity, but any information you tell me about your involvement in criminal activity would be discussed with\", 'gold_tag': 'SHEPARD is in a position of authority, possibly law enforcement or legal , SHEPARD cannot provide WHITACRE with immunity', 'last_speaker': 'SHEPARD'}\n",
      "Last word -> SHEPARD : \"I can't provide you with immunity, but any information you tell me about your involvement in criminal activity would be discussed with\"\n",
      "prediction :  I can't make any promises, but I can try to protect you.\n",
      "Real answer : I can't provide you with immunity, but any information you tell me about your involvement in criminal activity would be discussed with\n",
      "Bert Score : {'precision': [0.9090991616249084], 'recall': [0.873798131942749], 'f1': [0.891099214553833], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.33333333333333337, 'rouge2': 0.11764705882352942, 'rougeL': 0.27777777777777773, 'rougeLsum': 0.27777777777777773}\n",
      "bleu 1/2 : 0.14486606950235942 0.07565383741945779\n",
      "ppl : 16.157408474461352\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWHITACRE: What if we just move your chair over here.\\n\\n', 'answer': 'Thatta boy, Mark.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SHEPARD'}\n",
      "Last word -> SHEPARD : \"Thatta boy, Mark.\"\n",
      "prediction :  No. I'm staying right here.\n",
      "Real answer : Thatta boy, Mark.\n",
      "Bert Score : {'precision': [0.8658037185668945], 'recall': [0.8459989428520203], 'f1': [0.8557867407798767], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 38.44766449106146\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWHITACRE: Look at that, look at Bob and Terry. Man, I'd love to be a fly on the wall for that one. I was good wasn't I? I seemed scared.\\n\\n\", 'answer': \"Remember what we told you, Mark: tell them that you're cooperating first thing and whatever you do, do not take one of their lawyers.\", 'gold_tag': 'SHEPARD is in a position of authority or mentorship , SHEPARD provides guidance and advice to WHITACRE , WHITACRE is possibly involved in some kind of legal situation , WHITACRE has an upcoming meeting or encounter with Bob and Terry , SHEPARD and WHITACRE have shared memories of discussing or preparing for similar situations', 'last_speaker': 'SHEPARD'}\n",
      "Last word -> SHEPARD : \"Remember what we told you, Mark: tell them that you're cooperating first thing and whatever you do, do not take one of their lawyers.\"\n",
      "prediction :  You were fine. You're a good actor.\n",
      "Real answer : Remember what we told you, Mark: tell them that you're cooperating first thing and whatever you do, do not take one of their lawyers.\n",
      "Bert Score : {'precision': [0.8881497383117676], 'recall': [0.8315913677215576], 'f1': [0.8589405417442322], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.06451612903225806, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 48.0554456086497\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHEPARD: Mark, you can't be here.\\nWHITACRE: They threw me out, Brian.\\nSHEPARD: You're jeopardizing everything.\\nWHITACRE: Tossed me out of ADM. I'm out.\\nSHEPARD: Not here, Mark-- on the phone we can set something up.\\nWHITACRE: You gotta help me.\\n\\n\", 'answer': 'If you need to talk, call me.', 'gold_tag': 'SHEPARD acts in a professional capacity', 'last_speaker': 'SHEPARD'}\n",
      "Last word -> SHEPARD : \"If you need to talk, call me.\"\n",
      "prediction :  How do you mean?\n",
      "Real answer : If you need to talk, call me.\n",
      "Bert Score : {'precision': [0.8140556812286377], 'recall': [0.8328563570976257], 'f1': [0.8233487010002136], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0.11809163818525367 0.043120969391201254\n",
      "ppl : 157.0078606194256\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIRK: Aren't you dead? I assume you are loitering here to learn what efficiency rating I plan to give your cadets.\\nSPOCK: I am understandably curious.\\nKIRK: They destroyed the simulator room and you with it.\\nSPOCK: The Kobayshi Maru scenario frequently wreaks havoc with students and equipment. As I recall you took the test three times yourself. Your final solution was, shall we say, unique?\\nKIRK: It had the virtue of never having been tried.\\nSPOCK: Yours was not a solution which would have occurred to a Vulcan mentality.\\nKIRK: So you said at the time. Speaking of which, your prot g 's first rare -- a trifle emotional --\\nSPOCK: She's half Romulan, Jim. The admixture makes her more volatile than -- me, for example.\\nKIRK: Than you. Yes, I see that. By\\nSPOCK: I know of your fondness for antiques.\\nKIRK: 'It was the best of times, it was the worst of times...' Message, Spock?\\nSPOCK: None of which I am consciously aware -- except, of course, happy birthday -- surely the best of times.\\nKIRK: Hrummm... and where are you off to, now?\\nSPOCK: The Enterprise. I must check in before your inspection. And you?\\nKIRK: Home.\\nSPOCK: Something oppresses you.\\n\\n\", 'answer': 'Something.', 'gold_tag': 'Everyday Language', 'last_speaker': 'KIRK'}\n",
      "Last word -> KIRK : \"Something.\"\n",
      "prediction :  Yes. I'm worried about the cadets. I'm afraid they're not as good as they think they are.\n",
      "Real answer : Something.\n",
      "Bert Score : {'precision': [0.8463666439056396], 'recall': [0.9655814170837402], 'f1': [0.9020522236824036], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.075425422111792\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIRK: We've got a problem. Something may be wrong at Regula I. We've been ordered to investigate.\\nSPOCK: Regula I is a scientific research laboratory, if memory serves...\\nKIRK: I told Starfleet all we had was a boatload of children but we're the only ship in the quadrant. Spock: those cadets of yours -- how good are they? How will they respond under real pressure?\\nSPOCK: Like all living beings, Admiral each according to his gifts. The ship is yours.\\nKIRK: That won't be necessary: just take me to Regula I.\\nSPOCK: Excuse my presumption, but I do not agree. As a teacher on a training mission, I am content to command a Starship. If we are to go on actual duty, it is clear that the senior officer aboard must assume command.\\nKIRK: But it may be nothing; garbled communications. Why don't you...\\nSPOCK: You proceed from a false assumption. I am a Vulcan. I have no ego to bruise.\\nKIRK: You are going to remind me that logic alone dictates your actions.\\nSPOCK: I was going to remind you of nothing, least of all that which you know well. Your mistake, if I may be so bold, was promotion. Commanding a Starship is your first best destiny. Anything else is a waste of material.\\nKIRK: I would not presume to debate you.\\nSPOCK: That is wise. In any case, were I to invoke logic, logic clearly dictates that the needs of the many outweigh the needs of the few.\\nKIRK: Or the one.\\nSPOCK: You are my superior officer. You are also my friend. I have been and always shall be yours.\\nKIRK: Will you accompany me to the bridge?\\n\\n\", 'answer': \"I'd best talk with Mr. Scott, first so that he may, in his own words, explain the situation to his cadets.\", 'gold_tag': \"SPOCK's temporal information\", 'last_speaker': 'SPOCK'}\n",
      "Last word -> SPOCK : \"I'd best talk with Mr. Scott, first so that he may, in his own words, explain the situation to his cadets.\"\n",
      "prediction :  It is unnecessary. The ship is yours.\n",
      "Real answer : I'd best talk with Mr. Scott, first so that he may, in his own words, explain the situation to his cadets.\n",
      "Bert Score : {'precision': [0.8765699863433838], 'recall': [0.8393086791038513], 'f1': [0.8575347661972046], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06896551724137931, 'rouge2': 0.0, 'rougeL': 0.06896551724137931, 'rougeLsum': 0.06896551724137931}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 167.0810880673653\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSPOCK: They knew just where to hit us.\\nKIRK: WHO? Who knew just where to hit us? And why?\\nSPOCK: One thing is certain; we cannot escape on auxiliary power.\\nKIRK: Visual! phasers --\\nSPOCK: Too late --\\n\\n', 'answer': 'Hang on!', 'gold_tag': 'KIRK is a determined character', 'last_speaker': 'KIRK'}\n",
      "Last word -> KIRK : \"Hang on!\"\n",
      "prediction :  Damage report!\n",
      "Real answer : Hang on!\n",
      "Bert Score : {'precision': [0.9078655242919922], 'recall': [0.9075818061828613], 'f1': [0.907723605632782], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1475.5911451298548\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIRK: What IS working around here?\\nSPOCK: Not much, Admiral. We have partial main power...\\nKIRK: That's it?\\n\\n\", 'answer': 'Best we could do in two hours.', 'gold_tag': 'Spock can work under time pressure , Spock was given two hours to perform a task', 'last_speaker': 'SPOCK'}\n",
      "Last word -> SPOCK : \"Best we could do in two hours.\"\n",
      "prediction :  Yes, sir. We're doing the best we can.\n",
      "Real answer : Best we could do in two hours.\n",
      "Bert Score : {'precision': [0.8477045297622681], 'recall': [0.8556779623031616], 'f1': [0.8516725301742554], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.14285714285714288, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0.12500000000000003 0.04225771273642583\n",
      "ppl : 23.212412931744964\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIRK: Then I'm coming with you.\\nSPOCK: I would cite regulation, but I know you will simply ignore it.\\n\\n\", 'answer': \"See, we're getting to know each other.\", 'gold_tag': 'Shared understanding that Kirk often ignores regulations', 'last_speaker': 'KIRK'}\n",
      "Last word -> KIRK : \"See, we're getting to know each other.\"\n",
      "prediction :  Regulations were made to be broken, Spock.\n",
      "Real answer : See, we're getting to know each other.\n",
      "Bert Score : {'precision': [0.8255869150161743], 'recall': [0.8473478555679321], 'f1': [0.8363258838653564], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0.14285714285714285 0.048795003647426664\n",
      "ppl : 75.88212840607541\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSPOCK: What you refer to as the \"Red Matter located Captain Pike.\\nKIRK: Is he alive?\\nSPOCK: Unknown.\\n\\n', 'answer': \"Let's move.\", 'gold_tag': 'KIRK takes on a leadership role , KIRK is in a command position', 'last_speaker': 'KIRK'}\n",
      "Last word -> KIRK : \"Let's move.\"\n",
      "prediction :  Can you get him out of there?\n",
      "Real answer : Let's move.\n",
      "Bert Score : {'precision': [0.8533668518066406], 'recall': [0.8595641851425171], 'f1': [0.8564543128013611], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 75.35241534843234\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROHEIM: . that look on her face, you know the and it's not even me, my body. Some guy, this good-looking guy... he looks like the Marlboro Man, only shirtless. And so... the Marlboro Man's running his banging her... and her knees... by her ears, you know? And that look on her face. That look.\\nHORUS: Roheim.\\nROHEIM: Bitch.\\nHORUS: Come on.\\n\\n\", 'answer': 'Walk with me.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROHEIM'}\n",
      "Last word -> ROHEIM : \"Walk with me.\"\n",
      "prediction :  She's a good fucker. I'll tell you that.\n",
      "Real answer : Walk with me.\n",
      "Bert Score : {'precision': [0.8439198136329651], 'recall': [0.8628825545310974], 'f1': [0.8532958626747131], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.30584225507331\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROHEIM: They're going to can me.\\nHORUS: No one's canning anyone. No one saw us... watch your step... leave.\\n\\n\", 'answer': 'Should be an extra key over the door.', 'gold_tag': 'ROHEIM expresses awareness of the environment by mentioning the location of the key', 'last_speaker': 'ROHEIM'}\n",
      "Last word -> ROHEIM : \"Should be an extra key over the door.\"\n",
      "prediction :  They're going to can me.\n",
      "Real answer : Should be an extra key over the door.\n",
      "Bert Score : {'precision': [0.8714843392372131], 'recall': [0.8493501543998718], 'f1': [0.8602748513221741], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 64.69262560955616\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHORUS: You're going to be okay?\\nROHEIM: I don't know. You might have solo act tomorrow night.\\nHORUS: Get some sleep.\\nROHEIM: You're a good man, Horus.\\nHORUS: I have to get home, now. I'll call.\\n\\n\", 'answer': 'You know what Olga said before she walked out on me? Her last words to me. She turned at the front door. Looked around the room and she says, \"keep it clean.\" That\\'s it, can you believe it? Then out But like a.shmuck,.I keep the place spotless... in case she walks through that door one day. I don\\'t think she\\'s coming back.', 'gold_tag': 'ROHEIM keeps his place clean in case she comes back, highlighting his lingering hopes', 'last_speaker': 'ROHEIM'}\n",
      "Last word -> ROHEIM : \"You know what Olga said before she walked out on me? Her last words to me. She turned at the front door. Looked around the room and she says, \"keep it clean.\" That's it, can you believe it? Then out But like a.shmuck,.I keep the place spotless... in case she walks through that door one day. I don't think she's coming back.\"\n",
      "prediction :  You're going to be okay?\n",
      "Real answer : You know what Olga said before she walked out on me? Her last words to me. She turned at the front door. Looked around the room and she says, \"keep it clean.\" That's it, can you believe it? Then out But like a.shmuck,.I keep the place spotless... in case she walks through that door one day. I don't think she's coming back.\n",
      "Bert Score : {'precision': [0.8238449096679688], 'recall': [0.8022700548171997], 'f1': [0.8129143118858337], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05479452054794521, 'rouge2': 0.0, 'rougeL': 0.05479452054794521, 'rougeLsum': 0.05479452054794521}\n",
      "bleu 1/2 : 2.239096968518188e-06 7.916403250867262e-07\n",
      "ppl : 40.15862506273733\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHORUS: Jesus, Aaron. I don't want you to be here.\\n\\n\", 'answer': 'I need a drink.', 'gold_tag': 'ROHEIM is in need of an alcoholic beverage , This need possibly implies stress or a need to relax', 'last_speaker': 'ROHEIM'}\n",
      "Last word -> ROHEIM : \"I need a drink.\"\n",
      "prediction :  I know you don't want me to be here, but I am.\n",
      "Real answer : I need a drink.\n",
      "Bert Score : {'precision': [0.8676568269729614], 'recall': [0.8926690816879272], 'f1': [0.8799852132797241], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.08333333333333333 0.027524094128159027\n",
      "ppl : 12.066372932525084\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGELA: Wait, hold the door! Going down?\\n\\n', 'answer': 'Not if I can help it.', 'gold_tag': 'JOHN demonstrates a preference for avoiding the downward direction', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"Not if I can help it.\"\n",
      "prediction :  Don't be ridiculous, Angela. I'm not going to be late for work.\n",
      "Real answer : Not if I can help it.\n",
      "Bert Score : {'precision': [0.8425298929214478], 'recall': [0.808121919631958], 'f1': [0.8249673247337341], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.1, 'rougeLsum': 0.1}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.452574101993001\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGELA: I saw you at --\\nJOHN: -- I remember.\\nANGELA: And --\\nJOHN: Yeah.\\nANGELA: I'd like to ask you a few\\nJOHN: I'm not really in the talking mood right now.\\nANGELA: Could you just listen then?\\nJOHN: Always a catch...\\nANGELA: My sister was murdered last week.\\nJOHN: Sorry to hear...\\nANGELA: Dodson? You don't remember her? You sure?\\nJOHN: She look anything like you? I would've remembered.\\nANGELA: Then last Tuesday she just decided to step off the roof.\\nJOHN: I thought you said she was murdered? You'd be surprised at what people\\nANGELA: Look, I know I'm not making much sense -- hell I'm not really sure what I'm doing here... I just feel -- the circles you travel in -- the occult, demonology, exorcisms... I believe someone got to her, Mr. Constantine, brainwashed her into stepping off that roof. Some kind of legion or cult. Well I thought with your background and experience, you could at least point me in the right direction.\\nJOHN: Yeah, okay. Sure.\\nANGELA: My sister always talked about a world better than this. Heaven as some call it. She wasn't afraid of dying because she knew it was waiting for her. What everyone fails to grasp is that if she had really taken her own life --\\nJOHN: -- she would have committed a mortal sin and her soul would have gone straight to Hell where it would never feel love or compassion or anything but pain again as the master himself rips her apart over and over for the rest of eternity. That about right?\\nANGELA: You're not the only one afraid of Hell.\\n\\n\", 'answer': 'Oh shit...', 'gold_tag': 'Everyday Language', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"Oh shit...\"\n",
      "prediction :  I'm not afraid of Hell, Angela. I'm just afraid of what I'd do to you if you went there.\n",
      "Real answer : Oh shit...\n",
      "Bert Score : {'precision': [0.8177180290222168], 'recall': [0.8181359171867371], 'f1': [0.8179268836975098], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 10.245885019681264\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: The cat too?\\nANGELA: Yeah, why...?\\n\\n', 'answer': 'Why, do you have any?', 'gold_tag': 'Everyday Language', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"Why, do you have any?\"\n",
      "prediction :  I don't know.\n",
      "Real answer : Why, do you have any?\n",
      "Bert Score : {'precision': [0.8264612555503845], 'recall': [0.8099895715713501], 'f1': [0.8181425333023071], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 52.19149636039691\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: So I took things into my own hands and I found a way out.\\nANGELA: You attempted suicide.\\n\\n', 'answer': 'I never attempt anything.', 'gold_tag': 'JOHN has familiarity with life-threatening situations', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"I never attempt anything.\"\n",
      "prediction :  I didn't attempt anything. I just wanted to stop the pain.\n",
      "Real answer : I never attempt anything.\n",
      "Bert Score : {'precision': [0.8970880508422852], 'recall': [0.9379124641418457], 'f1': [0.9170461297035217], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.375, 'rouge2': 0.14285714285714288, 'rougeL': 0.375, 'rougeLsum': 0.375}\n",
      "bleu 1/2 : 0.2727272727272727 0.1651445647689541\n",
      "ppl : 32.568148788508324\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: cocky, peddles their influence or hijacks a soul -- I deport their scaly ass right back to Hell. I don't get them all but maybe enough to insure my retirement. Well, what would you do if you were sentenced to a prison where half the inmates were put there by you?\\nANGELA: Why you? I mean many go to Hell, why were you able to escape?\\nJOHN: I don't know.\\nANGELA: God has a plan for all of us.\\nJOHN: Not for me.\\n\\n\", 'answer': 'Detective Dodson here.', 'gold_tag': 'ANGELA is a detective who introduced Detective Dodson', 'last_speaker': 'ANGELA'}\n",
      "Last word -> ANGELA : \"Detective Dodson here.\"\n",
      "prediction :  Maybe you are the plan.\n",
      "Real answer : Detective Dodson here.\n",
      "Bert Score : {'precision': [0.8573188781738281], 'recall': [0.7985438704490662], 'f1': [0.8268882036209106], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 214.94308003509317\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGELA: She'd tell everyone about things she said she saw. Crazy things. Things that hadn't happened yet. She'd scare my mother to death, talking on and on about Revelations and the end of the world. Then one day she just stopped... never said another word.\\n\\n\", 'answer': \"So you put her in here. Angela doesn't need to be reminded. It hurts even more now.\", 'gold_tag': \"JOHN is empathetic and understanding about ANGELA's situation , JOHN shows concern for ANGELA's emotional state\", 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"So you put her in here. Angela doesn't need to be reminded. It hurts even more now.\"\n",
      "prediction :  Why would she stop?\n",
      "Real answer : So you put her in here. Angela doesn't need to be reminded. It hurts even more now.\n",
      "Bert Score : {'precision': [0.8590394854545593], 'recall': [0.8410357236862183], 'f1': [0.8499423265457153], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 629.7437413264959\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGELA: There is no 14h act in Corinthians. John's face goes pale --\\n\\n\", 'answer': 'I need a church.', 'gold_tag': 'John demonstrates a sense of urgency , John is oriented towards religious places', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"I need a church.\"\n",
      "prediction :  Are you sure?\n",
      "Real answer : I need a church.\n",
      "Bert Score : {'precision': [0.8271352052688599], 'recall': [0.873862087726593], 'f1': [0.8498567938804626], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 105.98414918782687\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: 13:29. 13:30 -- Here... Corinthians 14:01... 'The sins of the father would only be exceeded by the ego of the son.' why I couldn't place it... not a normal possession... But he can't cross over -- impossible for the son to cross over...\\nANGELA: Whose son? God's?\\n\\n\", 'answer': 'No. The other one. Lucifer had a son too.', 'gold_tag': 'JOHN is knowledgeable, particularly in religious text and supernatural phenomenon', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"No. The other one. Lucifer had a son too.\"\n",
      "prediction :  No.\n",
      "Real answer : No. The other one. Lucifer had a son too.\n",
      "Bert Score : {'precision': [0.9579082727432251], 'recall': [0.8643589019775391], 'f1': [0.9087322950363159], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.19999999999999998, 'rouge2': 0.0, 'rougeL': 0.19999999999999998, 'rougeLsum': 0.19999999999999998}\n",
      "bleu 1/2 : 0.00033546262790251185 0.0001060825974037491\n",
      "ppl : 1275.3241709894667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: been in the presence of the Creator either. That goes double for us -- God's most prized creations. Mammon would be the last demon we'd ever want crossing over.\\nANGELA: that's what you said.\\nJOHN: Some psychic with the chops to reach all the way to Hell and the grit to withstand whatever shit she'd pull out. But even a bridge wouldn't help Mammon. Because to cross over, the myth says he'd still need the one thing he could never get. Divine assistance. The help of God. Impossible? Sure it's impossible. That's what makes it so dangerous. These things exist to break the rules, to find the loopholes. If the past is any indication, then the future isn't on our side.\\n\\n\", 'answer': \"She knew. That's why she killed sense... John, she sacrificed herself to beat him. John nods. Your point? Why is she in Hell?\", 'gold_tag': 'ANGELA is inquisitive and rational', 'last_speaker': 'ANGELA'}\n",
      "Last word -> ANGELA : \"She knew. That's why she killed sense... John, she sacrificed herself to beat him. John nods. Your point? Why is she in Hell?\"\n",
      "prediction :  But you're wrong.\n",
      "Real answer : She knew. That's why she killed sense... John, she sacrificed herself to beat him. John nods. Your point? Why is she in Hell?\n",
      "Bert Score : {'precision': [0.8571141362190247], 'recall': [0.8285294771194458], 'f1': [0.8425794243812561], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 68.85742214864031\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: Hey, Beeman? Beeman?!\\nANGELA: Maybe he's not here.\\nJOHN: He's always here.\\nANGELA: What?\\nJOHN: Oh Jesus, no --\\nANGELA: Oh God --\\nJOHN: Who are you?! Answer me!! Goddamit -- reveal yourself! I summon you! ... this is my fault... I sent them in... I sent them right to their deaths... a damn one-man plague.\\nANGELA: John, you need a doctor.\\n\\n\", 'answer': \"I've seen a goddamn doctor!! Get away from me!! Stay the hell away -- Please --\", 'gold_tag': 'John refuses medical help, indicating a negative past experience with health care, or a stubborn personality', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"I've seen a goddamn doctor!! Get away from me!! Stay the hell away -- Please --\"\n",
      "prediction :  I need nothing. I need no one.\n",
      "Real answer : I've seen a goddamn doctor!! Get away from me!! Stay the hell away -- Please --\n",
      "Bert Score : {'precision': [0.8802838325500488], 'recall': [0.8255715370178223], 'f1': [0.852050244808197], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09090909090909091, 'rouge2': 0.0, 'rougeL': 0.09090909090909091, 'rougeLsum': 0.09090909090909091}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 68.5923412775547\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGELA: But you knew that already, didn't you? You see something in me... I need to understand -- Why not?\\nJOHN: Because you open up to that world, you're inviting whatever's out there back in. That's what happened to Isabel. No, she embraced her gift while you denied yours and that denial is exactly why you're still alive. Stick with me, that'll change. And I don't need another ghost following me around.\\nANGELA: Dammit, John -- they killed my sister! I can't let them get away with that. Even if it means going down the same path she did. Now if you won't help me get there, I'll find my own way. But I won't run. Never. The two stand there -- locked in this moment.\\n\\n\", 'answer': \"You do this, there's no turning back. You see them -- they see you. Understand?\", 'gold_tag': 'JOHN views himself as a protector to ANGELA', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"You do this, there's no turning back. You see them -- they see you. Understand?\"\n",
      "prediction :  No, Angela, you're not going to find anything there. It's just a trick.\n",
      "Real answer : You do this, there's no turning back. You see them -- they see you. Understand?\n",
      "Bert Score : {'precision': [0.8686279058456421], 'recall': [0.8614898324012756], 'f1': [0.8650440573692322], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.26666666666666666, 'rouge2': 0.0, 'rougeL': 0.20000000000000004, 'rougeLsum': 0.20000000000000004}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 17.80486154389624\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGELA: Why water?\\nJOHN: It's the universal conduit. Lubricates the transition from one plane to another. Now ask me if there's water in Hell. Normally only a portion of the body has to be suspended but you wanted the crash course...\\nANGELA: What will I see? His eyes say it all. Enough. Lie down? For how long?\\n\\n\", 'answer': 'Last chance... Take a deep one.', 'gold_tag': \"JOHN is patient and careful , JOHN gives Angela a 'last chance' before proceeding\", 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"Last chance... Take a deep one.\"\n",
      "prediction :  It's not that kind of Hell.\n",
      "Real answer : Last chance... Take a deep one.\n",
      "Bert Score : {'precision': [0.8504498600959778], 'recall': [0.853040337562561], 'f1': [0.8517431020736694], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 67.38121359925582\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGELA: All those people... so sad... ... I've always known... where the bad guys are... where to aim, when to duck... it's not luck... I've always known...\\n\\n\", 'answer': 'Angela?', 'gold_tag': 'Everyday Language', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"Angela?\"\n",
      "prediction :  I know you've always known...\n",
      "Real answer : Angela?\n",
      "Bert Score : {'precision': [0.7905606031417847], 'recall': [0.8575517535209656], 'f1': [0.822694718837738], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 137.43112504455098\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: That half-breed tipped my scales when he started killing my friends. I'm just adding a little counterweight.\\nANGELA: What about me? I can't stay here forever.\\n\\n\", 'answer': \"You're staying in the car.\", 'gold_tag': 'JOHN is authoritative by dictating where ANGELA should stay', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"You're staying in the car.\"\n",
      "prediction :  I know, Angela. You're coming with me.\n",
      "Real answer : You're staying in the car.\n",
      "Bert Score : {'precision': [0.8721050024032593], 'recall': [0.8865926265716553], 'f1': [0.8792891502380371], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.16666666666666666, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0.14285714285714285 0.048795003647426664\n",
      "ppl : 38.259915000674376\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGELA: Something's coming...\\nJOHN: What happened to staying in the car?\\nANGELA: You were in danger.\\n\\n\", 'answer': \"Well now there's a premonition.\", 'gold_tag': \"JOHN is surprised at ANGELA's intervention\", 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"Well now there's a premonition.\"\n",
      "prediction :  Danger?\n",
      "Real answer : Well now there's a premonition.\n",
      "Bert Score : {'precision': [0.8599143624305725], 'recall': [0.8398861289024353], 'f1': [0.8497822284698486], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1158.966045399559\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOHN: soldier's spear. It matches that child's drawing John removed from the fridge -- now lying on his seat. Then you know what this spear would mean to a demon trying to cross over. She doesn't. Mammon needed divine assistance -- how's the blood of God's only son? Not quite. Twins. Here we go --\\nANGELA: What is that?\\nJOHN: Hang on --\\nANGELA: I lost it. He's down --\\n\\n\", 'answer': \"He's not down. Gimme your phone.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'JOHN'}\n",
      "Last word -> JOHN : \"He's not down. Gimme your phone.\"\n",
      "prediction :  -- Wait. It's a child's drawing.\n",
      "Real answer : He's not down. Gimme your phone.\n",
      "Bert Score : {'precision': [0.860027551651001], 'recall': [0.8680882453918457], 'f1': [0.8640391230583191], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 55.196210389015874\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKING KARL: Hi! I'm Karl, and Welcome to my\\nEMMET: For Kreativity...\\nKING KARL: Exaktly!\\nEMMET: Why did you build all this stuff?\\n\\n\", 'answer': 'Well...Why not?', 'gold_tag': 'KING KARL exhibits a whimsical and free-spirited nature with his response of \"Why not?\" to Emmet\\'s question', 'last_speaker': 'KING KARL'}\n",
      "Last word -> KING KARL : \"Well...Why not?\"\n",
      "prediction :  What?\n",
      "Real answer : Well...Why not?\n",
      "Bert Score : {'precision': [0.9233975410461426], 'recall': [0.855856716632843], 'f1': [0.8883451819419861], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKING KARL: If you can conceive it, we will achieve it. Build anything whenever you feel it.\\nEMMET: You know we really don't have time--\\n\\n\", 'answer': 'Invent a game, like Roller Cricket. Or buy Bullfighting Tennis tickets...', 'gold_tag': 'KING KARL encourages building and inventing games', 'last_speaker': 'KING KARL'}\n",
      "Last word -> KING KARL : \"Invent a game, like Roller Cricket. Or buy Bullfighting Tennis tickets...\"\n",
      "prediction :  We will get everything we want.\n",
      "Real answer : Invent a game, like Roller Cricket. Or buy Bullfighting Tennis tickets...\n",
      "Bert Score : {'precision': [0.8657526969909668], 'recall': [0.8295553922653198], 'f1': [0.8472676277160645], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 89.26394477524835\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKING KARL: Make any idea thought or spoken. Rules were meant to be broken!\\n\\n', 'answer': 'No, rules were meant to be followed.', 'gold_tag': 'EMMET believes in following the rules', 'last_speaker': 'EMMET'}\n",
      "Last word -> EMMET : \"No, rules were meant to be followed.\"\n",
      "prediction :  I'm not sure I agree.\n",
      "Real answer : No, rules were meant to be followed.\n",
      "Bert Score : {'precision': [0.8604696989059448], 'recall': [0.8522819876670837], 'f1': [0.8563563227653503], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 30.255860560800436\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBIZZLEBEK: I've read your stories. They're fantastic.\\nKAFKA: I don't know what you could have read.\\nBIZZLEBEK: Just what you've published.\\nKAFKA: -- In magazines nobody reads.\\nBIZZLEBEK: I read the one about the penal colony.\\nKAFKA: Did you?\\n\\n\", 'answer': \"The needles inscribing the judgement into the flesh of the man. Very good. If I could sculpt as well as that, I'd be quite proud of myself.\", 'gold_tag': 'BIZZLEBEK aspires to be a sculptor', 'last_speaker': 'BIZZLEBEK'}\n",
      "Last word -> BIZZLEBEK : \"The needles inscribing the judgement into the flesh of the man. Very good. If I could sculpt as well as that, I'd be quite proud of myself.\"\n",
      "prediction :  Yes.\n",
      "Real answer : The needles inscribing the judgement into the flesh of the man. Very good. If I could sculpt as well as that, I'd be quite proud of myself.\n",
      "Bert Score : {'precision': [0.9308216571807861], 'recall': [0.830348014831543], 'f1': [0.8777188062667847], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2104.611116571625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBIZZLEBEK: Where are your friends?\\n\\n', 'answer': 'Good question. Who are my friends ... would also be of interest.', 'gold_tag': 'KAFKA questions the nature of his friends , KAFKA questions the identity of his friends', 'last_speaker': 'KAFKA'}\n",
      "Last word -> KAFKA : \"Good question. Who are my friends ... would also be of interest.\"\n",
      "prediction :  They are not my friends. They are my enemies.\n",
      "Real answer : Good question. Who are my friends ... would also be of interest.\n",
      "Bert Score : {'precision': [0.8815178871154785], 'recall': [0.8604779839515686], 'f1': [0.8708708882331848], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3, 'rouge2': 0.22222222222222224, 'rougeL': 0.3, 'rougeLsum': 0.3}\n",
      "bleu 1/2 : 0.15922918012750872 0.11942188509563156\n",
      "ppl : 24.820280979158227\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAFKA: Gabriela was right -- it's easier for me to understand suicide. I'm a practicing suicide.\\nBIZZLEBEK: -- In what sense?\\nKAFKA: Bachelorhood is just the slow form. The bachelor doesn't sew seeds. Only the moment matters. The space he occupies grows smaller and smaller -- until the only space right for him is his coffin.\\nBIZZLEBEK: These strange stories you write -- they come naturally, do they?\\nKAFKA: Naturally? -- that's not the word I would have chosen.\\nBIZZLEBEK: Where do you get your ideas? Only joking -- I'm just joking. Let's go to a brothel then, Kafka, come on.\\nKAFKA: I haven't got the energy. I mean, I have to conserve my energy.\\nBIZZLEBEK: Why do you work in that hideous insurance office? -- dealing with people who fall off ladders. Now take me -- I make my living as a stone mason. It's not my art -- but it's the tools of my art. You could be -- a journalist.\\nKAFKA: That would be even worse -- it would be a compromise.\\nBIZZLEBEK: Success or nothing?\\n\\n\", 'answer': \"No -- not even success. My writing is not for making a living -- it's for living. Not for other people, it's for me. ... I'm the exile. Gabriela was right about that too.\", 'gold_tag': 'KAFKA\\'s writing is not for making a living, but for living , KAFKA refers to himself as an \"exile\"', 'last_speaker': 'KAFKA'}\n",
      "Last word -> KAFKA : \"No -- not even success. My writing is not for making a living -- it's for living. Not for other people, it's for me. ... I'm the exile. Gabriela was right about that too.\"\n",
      "prediction :  I'm a journalist. I'm a writer.\n",
      "Real answer : No -- not even success. My writing is not for making a living -- it's for living. Not for other people, it's for me. ... I'm the exile. Gabriela was right about that too.\n",
      "Bert Score : {'precision': [0.9185625910758972], 'recall': [0.8397574424743652], 'f1': [0.8773940205574036], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.05, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.0031345208504984018 0.000767797667183584\n",
      "ppl : 20.160077943958992\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAFKA: You work in the cemetery.\\nBIZZLEBEK: A man must eat -- And drink.\\n\\n', 'answer': 'The Castle cemetery.', 'gold_tag': \"KAFKA's persona - KAFKA knows about the specific site, KAFKA's persona - KAFKA is detail-oriented\", 'last_speaker': 'KAFKA'}\n",
      "Last word -> KAFKA : \"The Castle cemetery.\"\n",
      "prediction :  What do you do in the cemetery?\n",
      "Real answer : The Castle cemetery.\n",
      "Bert Score : {'precision': [0.8589928150177002], 'recall': [0.881224513053894], 'f1': [0.8699666261672974], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4, 'rouge2': 0.0, 'rougeL': 0.4, 'rougeLsum': 0.4}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 50.08151326092294\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBIZZLEBEK: Are you sure you wouldn't prefer going through official channels?\\nKAFKA: Official channels -- a lot of good they've done me. My only hope is to approach the officials personally.\\nBIZZLEBEK: -- I'm flattered, of course, to be considered a friend -- even without knowing all the details. (Kafka doesn't take -- To see such determination is reward enough for me.\\nKAFKA: The Kafka men are famous for it, you know. Delivering meat barefoot in the depths of winter, picking up sacks of flour with their teeth -- -- Oh, yes, determination runs in the family.\\nBIZZLEBEK: There is one thing I'd like you to tell me.\\nKAFKA: I'm trying to find things out myself -- that's the whole point.\\nBIZZLEBEK: What made you think I'd be able to get you into the Castle?\\nKAFKA: The cemetery is nearer the Castle than anywhere else -- wasn't it part of the Castle originally? -- I always assumed there'd be a gate or something. Isn't there?\\n\\n\", 'answer': 'In a manner of speaking.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BIZZLEBEK'}\n",
      "Last word -> BIZZLEBEK : \"In a manner of speaking.\"\n",
      "prediction :  No.\n",
      "Real answer : In a manner of speaking.\n",
      "Bert Score : {'precision': [0.9285663366317749], 'recall': [0.817108690738678], 'f1': [0.8692793250083923], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1275.3241709894667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBIZZLEBEK: I was restoring some stones here in the upper section one day -- and I found this.\\nKAFKA: An empty tomb?\\nBIZZLEBEK: A cenotaph -- a monument to someone whose remains ended up elsewhere. But look -- The Castle gates were blockaded in the time of the great plague -- it's an escape route. Don't get stuck.\\nKAFKA: Not a chance. I'm the thinnest person I know. -- You appreciate my writing.\\nBIZZLEBEK: Yes.\\nKAFKA: Will you do me a favor then?\\nBIZZLEBEK: Another one?\\nKAFKA: If I don't see you later -- go to my house and find my notebooks -- and destroy them. All my manuscripts -- just burn them. Please.\\nBIZZLEBEK: What an extraordinary request!\\nKAFKA: It's my last and final one.\\nBIZZLEBEK: Then its authority is in doubt.\\nKAFKA: A true friend would do it.\\n\\n\", 'answer': 'Not necessarily. A wife would.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BIZZLEBEK'}\n",
      "Last word -> BIZZLEBEK : \"Not necessarily. A wife would.\"\n",
      "prediction :  You want me to destroy your manuscripts?\n",
      "Real answer : Not necessarily. A wife would.\n",
      "Bert Score : {'precision': [0.8281873464584351], 'recall': [0.8692504167556763], 'f1': [0.8482221961021423], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 79.54855333164525\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDAVID: No way... I think. we \"ve met. You need a better line than that or I\\'ll have to assume you\\'re a pervert who likes to stare at Your skirt was so short I couldn\\'t help it.\\nWOMAN: Dress.\\nDAVID: Skirt, dress, same thing.\\nWOMAN: If you\\'re a pervert, yeah. All\\nDAVID: So do shorts, dear.\\nWOMAN: Yeah, but there\\'s that pesky piece of fabric right here that interferes with your fantasy life. Wake me when you have a good come back to that.\\nDAVID: I have one but, unlike you, I wouldn\\'t say it in public.\\nWOMAN: Pussy.\\nDAVID: Hello...? Hello? The line cut.\\nWOMAN: you pretty much have it maxed out?\\nDAVID: You\\'re relentless.\\nWOMAN: I never sleep through the night. I catch up on the bus. You going to run again?\\nDAVID: I just started a new job, today.\\nWOMAN: I saw your concession speech. I heard Bill Clinton called it the best political speech he\\'s seen in\\nDAVID: Something got into me. What\\'s the deal with you and argyles?\\nWOMAN: What\\'s the deal with you and boring shades of blue?\\nDAVID: At least my clothes match.\\nWOMAN: That\\'s easy if you. restrict yourself to one color.\\nDAVID: The belt and shoes are black.\\nWOMAN: Variety is the spice of .life .\\n\\n', 'answer': \"There you` go with the platitudes again. I guess it wasn't the ch mpagne . Hello? Hello?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'DAVID'}\n",
      "Last word -> DAVID : \"There you` go with the platitudes again. I guess it wasn't the ch mpagne . Hello? Hello?\"\n",
      "prediction :  What do you do for a living?\n",
      "Real answer : There you` go with the platitudes again. I guess it wasn't the ch mpagne . Hello? Hello?\n",
      "Bert Score : {'precision': [0.816146731376648], 'recall': [0.8062427043914795], 'f1': [0.8111644387245178], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08333333333333333, 'rouge2': 0.0, 'rougeL': 0.08333333333333333, 'rougeLsum': 0.08333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 21.20261649705394\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWOMAN: Your phone sucks. Don't guys like you get special phones that actually work in the middle of the biggest city in the country?\\n\\n\", 'answer': 'Depends what the telecom lobby thinks of your voting record.', 'gold_tag': 'DAVID is likely a political figure or lawmaker , DAVID made a comment about a voting record impacting the quality of telecommunications he receives', 'last_speaker': 'DAVID'}\n",
      "Last word -> DAVID : \"Depends what the telecom lobby thinks of your voting record.\"\n",
      "prediction :  It's not that big of a deal. I like my phone.\n",
      "Real answer : Depends what the telecom lobby thinks of your voting record.\n",
      "Bert Score : {'precision': [0.8503017425537109], 'recall': [0.8465880155563354], 'f1': [0.8484408259391785], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0909090909090909, 'rouge2': 0.0, 'rougeL': 0.0909090909090909, 'rougeLsum': 0.0909090909090909}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 25.287735111007674\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDAVID: I'll pay for the damage.\\nWOMAN: Hope your new job pays better than your old one.\\nDAVID: Give me your number and I'll send you a check.\\nWOMAN: God, that is smooth. Spill coffee on me then ask for my number. Just let me spill some on you and we'll be even.\\nDAVID: It's my first day at the office!\\nWOMAN: Tell your boss some crazy chick dumped coffee on you on the MI. It's New York; he'll understand.\\nDAVID: No!\\nWOMAN: Come on. Just a little.\\nDAVID: You're crazy. Actually crazy. He's not here! Who was that? What is this, third grade?\\n\\n\", 'answer': \"You forgot what that was like, didn't you? How fun it was... Oh my God! How do you stand it? There. We're even. Sturdy little fucker, isn't it? By the way, I'm Elise.\", 'gold_tag': 'WOMAN is bold and spontaneous , WOMAN is not afraid to stand her ground and engage in playful banter', 'last_speaker': 'WOMAN'}\n",
      "Last word -> WOMAN : \"You forgot what that was like, didn't you? How fun it was... Oh my God! How do you stand it? There. We're even. Sturdy little fucker, isn't it? By the way, I'm Elise.\"\n",
      "prediction :  David, you are cute.\n",
      "Real answer : You forgot what that was like, didn't you? How fun it was... Oh my God! How do you stand it? There. We're even. Sturdy little fucker, isn't it? By the way, I'm Elise.\n",
      "Bert Score : {'precision': [0.8681905269622803], 'recall': [0.8034841418266296], 'f1': [0.8345849514007568], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.04878048780487805, 'rouge2': 0.0, 'rougeL': 0.04878048780487805, 'rougeLsum': 0.04878048780487805}\n",
      "bleu 1/2 : 0.00017754359721063726 6.482975542191821e-05\n",
      "ppl : 225.87095410846754\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: And what if I don't want to give up on her?\\nROB: You don't call.\\nMIKE: But you said I shouldn't call if I wanted to give up on her.\\nROB: Right.\\nMIKE: So I don't call either way.\\nROB: Right.\\nMIKE: So what's the difference?\\nROB: The only difference between giving up and not giving up is if you take her back when she wants to come back. See, you can't do anything to make her want to come back. You can only do things to make her not want to come back.\\nMIKE: So the only difference is if I forget about her or pretend to forget about her.\\nROB: Right.\\nMIKE: Well that sucks.\\nROB: It sucks.\\nMIKE: So it's almost a retroactive decision. So I could, like, let's say, forget about her and when she comes back make like I just pretended to forget about her.\\nROB: Right...or more likely the opposite.\\nMIKE: Right... Wait, what do you mean?\\nROB: I mean first you'll pretend not to care, not call - whatever, and then, eventually, you really won't care.\\nMIKE: Unless she comes back first.\\nROB: Ah, see, that's the thing. Somehow they don't come back until you really don't care anymore.\\nMIKE: There's the rub.\\nROB: There's the rub.\\nMIKE: Thanks, man. Sorry we always talk about the same thing all the time...\\nROB: Hey man, don't sweat it.\\nMIKE: ...It's just that you've been there. Rob, I just want you to know, you're the only one I can talk to about her.\\n\\n\", 'answer': 'Thanks. Thanks, man.', 'gold_tag': \"ROB listens to Mike's worries\", 'last_speaker': 'ROB'}\n",
      "Last word -> ROB : \"Thanks. Thanks, man.\"\n",
      "prediction :  Well, I'm here.\n",
      "Real answer : Thanks. Thanks, man.\n",
      "Bert Score : {'precision': [0.8950128555297852], 'recall': [0.916690468788147], 'f1': [0.9057219624519348], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 40.15017161405982\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROB: I don't think I'm gonna take it.\\nMIKE: I's a gig.\\nROB: I mean, I need the money.\\nMIKE: You're an actor. Find the Zen in the role.\\nROB: It's definitely a step back for me.\\nMIKE: Look, there's not much of a call for Shakespeare in this town.\\nROB: There's just something about being\\nMIKE: What do you want? You're tall.\\nROB: Do you realize how hard it's going to be to tell my parents? I still haven't told them I didn't get the pilot.\\nMIKE: You tested over a month ago. I'm sure they figured it out by now.\\n\\n\", 'answer': 'It\\'s like \"Hi, Mom. I\\'m not going to be starring in that sit-com and, oh by the way, I\\'m Goofy. Send more money.\"', 'gold_tag': 'ROB is afraid of disappointing his parents', 'last_speaker': 'ROB'}\n",
      "Last word -> ROB : \"It's like \"Hi, Mom. I'm not going to be starring in that sit-com and, oh by the way, I'm Goofy. Send more money.\"\"\n",
      "prediction : Yeah. I just don't want to have to deal with it.\n",
      "Real answer : It's like \"Hi, Mom. I'm not going to be starring in that sit-com and, oh by the way, I'm Goofy. Send more money.\"\n",
      "Bert Score : {'precision': [0.8835010528564453], 'recall': [0.8338510394096375], 'f1': [0.8579583168029785], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.10256410256410256, 'rougeLsum': 0.10256410256410256}\n",
      "bleu 1/2 : 0.03053736193083294 0.010128097161185581\n",
      "ppl : 9.108968795148202\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE: Haven't you noticed I didn't mention Michelle once today?\\nROB: I didn't want to say anything.\\nMIKE: Why?\\nROB: I don't know. It's like not talking to\\nMIKE: What? Like, you didn't want to jinx it?\\nROB: Kinda.\\nMIKE: I don't talk about her that much.\\nROB: Oh no?\\nMIKE: I didn't mention her once today.\\nROB: Well, until now. Tend the pin.\\nMIKE: The only reason I mentioned her at all is to say that I'm not going to talk about her anymore. I thought you'd appreciate that.\\nROB: I do. Good for you, man.\\nMIKE: I've decided to get out there. Go ahead. Play it out. I'm not making any more excuses for myself.\\nROB: Good to hear, Mikey.\\nMIKE: You want to hit the town tonight?\\nROB: I shouldn't, Mike, it's a weeknight.\\nMIKE: What do you have? A Pluto call back?\\nROB: Sure. Kick me when I'm down.\\nMIKE: Count 'em up.\\nROB: I'll give you an eight.\\nMIKE: What'd you get?\\nROB: An eight.\\nMIKE: Looks like we're in a dead heat after one hole. This is turning into quite a rivalry.\\n\\n\", 'answer': 'You better replace the pin, Chi-Chi. The natives look restless.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROB'}\n",
      "Last word -> ROB : \"You better replace the pin, Chi-Chi. The natives look restless.\"\n",
      "prediction :  I'm not going to play along.\n",
      "Real answer : You better replace the pin, Chi-Chi. The natives look restless.\n",
      "Bert Score : {'precision': [0.8677160739898682], 'recall': [0.8433682918548584], 'f1': [0.855368971824646], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 33.03690767669065\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROB: So, if the party starts at eight, why are\\nMIKE: To get a drink before we meet the guys for a bite at eleven.\\nROB: Oh. Where is this place?\\nMIKE: It's one of these. For some reason, cool bars in L.A. have to be very hard to find and have no signs out front.\\nROB: That doesn't sound too good for business.\\nMIKE: It's kinda like a speakeasy kind of thing. It's kinda cool. It's like you're in on some kind of secret. You tell a chick you've been some place, it's like bragging that you know how to find it. The only way you could know where a place is is if someone who knows brought you there. You have to have someone come before. There is a direct line connecting you back to the original, unequivocally cool, club patrons. It's kinda like Judaism...\\nROB: Sounds more like Aids...\\n\\n\", 'answer': \"... That's probably a more appropriate analogy.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MIKE'}\n",
      "Last word -> MIKE : \"... That's probably a more appropriate analogy.\"\n",
      "prediction :  Well, I'll call you. I'll be there around ten. You know, I'm not gonna drive. I don't wanna be the one that shows up drunk. I don't wanna be the one that shows up late. I don't wanna be the one that shows up at all.\n",
      "Real answer : ... That's probably a more appropriate analogy.\n",
      "Bert Score : {'precision': [0.8195003271102905], 'recall': [0.8414645195007324], 'f1': [0.8303371667861938], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.03389830508474577, 'rouge2': 0.0, 'rougeL': 0.03389830508474577, 'rougeLsum': 0.03389830508474577}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5.256582852341893\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMELVIN: That's some face they left hanging on you. You look like...\\nSIMON: Could you take it just a little easy, Mr. Udall? Thank you. Verdell... sweetheart? By the way, thanks for saving me.\\nMELVIN: I called. I never touched you. I didn't leave my name or nothing.\\n\\n\", 'answer': 'Verdell? Hi, sweetheart.', 'gold_tag': 'SIMON shows affection for Verdell', 'last_speaker': 'SIMON'}\n",
      "Last word -> SIMON : \"Verdell? Hi, sweetheart.\"\n",
      "prediction :  I think you're mistaken.\n",
      "Real answer : Verdell? Hi, sweetheart.\n",
      "Bert Score : {'precision': [0.8545053005218506], 'recall': [0.8419966101646423], 'f1': [0.8482048511505127], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 44.009728647505916\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSIMON: Hello?... yes... sure... finally, huh? Why, \"finally\"? Because I called you so many times. Maybe Oh, boy... I was hoping it was something like that. You didn\\'t get one of them, huh? \\'Cause I mean it wasn\\'t only your office -- it was your home, hotel and the cigar club you like in San Francisco. No -- Sarcastic... Of course. I believe you. No, don\\'t fire anyone... Please. Maybe I\\'m wrong about the 20 times. Take a breath... So, you miss me a little? Hey, strike the question -- How\\'s the case going? Really. Fantastic. I didn\\'t hear. I haven\\'t been watching. Great. Just great. I\\'m so happy. Whoopie! Me? Well, I\\'m mending. No, I look fine. Well, some of the damage might still be noticeable if you look closely... Carl, I need some help and you\\'re the logical one to turn to. No! Not \\'cause I blame you for you can ever think that. No, I\\'m I guess because you hired the guy who did this you think... No, I am a sarcastic person. Well, if you must know, the reason I said you were the logical person is because you always told me how you thought I was this great person who made you feel good about humanity and everything. You do remembering saying that? Well, whew. Okay, so Carl. I hate asking but this money thing is ridiculously serious... \"Will you please loan me money? I will pay you back. I will give you whatever percentage of my income I don\\'t absolutely need until I do. It will take a while. But I don\\'t know what I\\'ll do if you say\"... that. I understand... yes... No, I do. But you know, you know -- you didn\\'t even ask how much, Carl? Well, Frank has no right to discuss how much I\\'m in hock... no, you\\'re right -- not the point. So... what have you been up to??? Uh-huh... Oh, the group show... how was it? Well, I\\'m not surprised that there\\'s that much talent around... great... Look -- gotta go... no, you shouldn\\'t feel that way at all... take care, you, too... you, too... Good-bye. Pal o\\' mine.\\nMELVIN: Maybe I\\'ll bring him some food by.\\nSIMON: Thank you for walking him. If you\\'ll excuse me I\\'m not feeling so well.\\nMELVIN: It smells like shit in here?\\nSIMON: Go away.\\nMELVIN: That cleaning woman doesn\\'t...\\nSIMON: Please, just leave.\\nMELVIN: Where are all your queer party friends?\\nSIMON: Get out. Nothing worse than having to feel this way in front of you?\\nMELVIN: Nellie, you\\'re a disgrace to depression.\\nSIMON: Rot in hell, Melvin.\\nMELVIN: No need to stop being a lady... quit worrying -- you\\'ll be back on your knees in no time.\\nSIMON: Is this fun for you? Well, you lucky devil... It just gets better and better. I am losing my apartment and Frank wants me to promise to paint hotter subjects and to beg my parents, who haven\\'t called, for help... and I won\\'t. And I don\\'t want to paint anymore. So the life I was trying for is over. The life I had is gone and I am feeling so damn sorry for myself that it is difficult to breathe. Right times for you -- terrified... Terrified... Lucky you, you\\'re here for rock bottom... me wallowing in self-pity in front of you, you absolute horror of a human being...\\nMELVIN: Well, I\\'ll do one thing for you that might cheer you up.\\nSIMON: Get out.\\nMELVIN: Don\\'t piss on a gift, tough guy. You want to know why the dog prefers me... it\\'s not affection. It\\'s a trick. I carry bacon in my pocket.\\nSIMON: Oh, my gosh.\\nMELVIN: Now we\\'ll both call him.\\nSIMON: Come on, sweetheart...\\nMELVIN: Yo, yo, yo...\\nSIMON: Would you leave now, please?\\n\\n', 'answer': \"Stupid dog. I don't get it.\", 'gold_tag': \"Melvin is insensitive and tactless, using derogatory terms and exhibiting a lack of empathy for Simon's situation , Melvin takes care of Simon's dog\", 'last_speaker': 'MELVIN'}\n",
      "Last word -> MELVIN : \"Stupid dog. I don't get it.\"\n",
      "prediction :  I'll stay as long as you like.\n",
      "Real answer : Stupid dog. I don't get it.\n",
      "Bert Score : {'precision': [0.8312678337097168], 'recall': [0.8676997423171997], 'f1': [0.8490931987762451], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 29.30600948345781\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMELVIN: I took a chance you were up. I brought you Chinese soup.\\nSIMON: Thanks.\\nMELVIN: I have never been so tired in my life. Okay, if I sit here?\\nSIMON: Got any easier questions?\\nMELVIN: I haven't been sleeping. I haven't been clear or felt like myself. I'm in trouble. Some son of a bitch is burning my bridges behind my back... But the tiredness -- boy... Not just sleepy.\\nSIMON: But sick -- nauseous -- where everything looks distorted and\\n\\n\", 'answer': \"Yeah... I'm glad we did this. Good talking to you.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MELVIN'}\n",
      "Last word -> MELVIN : \"Yeah... I'm glad we did this. Good talking to you.\"\n",
      "prediction : ... No.\n",
      "Real answer : Yeah... I'm glad we did this. Good talking to you.\n",
      "Bert Score : {'precision': [0.8912795186042786], 'recall': [0.8405056595802307], 'f1': [0.8651482462882996], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 308.3416200843396\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMELVIN: Can I ask you a personal question? Do you ever get an erection for a woman?\\nSIMON: Melvin...\\nMELVIN: Wouldn't your lie be a lot easier if you were not...\\nSIMON: You consider your life easy.\\n\\n\", 'answer': 'I give you that one... Nice packing.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MELVIN'}\n",
      "Last word -> MELVIN : \"I give you that one... Nice packing.\"\n",
      "prediction :  Oh, I see.\n",
      "Real answer : I give you that one... Nice packing.\n",
      "Bert Score : {'precision': [0.8438674807548523], 'recall': [0.8284569978713989], 'f1': [0.8360912799835205], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0.08786571270524224 0.03403024420100487\n",
      "ppl : 68.32818314572262\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSIMON: Thank you, Melvin. You overwhelm me.\\nMELVIN: They did a nice job... Cozy, huh?\\nSIMON: I love you.\\n\\n', 'answer': \"I'll tell you, buddy, I'd be the luckiest guy alive if that did it for me.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MELVIN'}\n",
      "Last word -> MELVIN : \"I'll tell you, buddy, I'd be the luckiest guy alive if that did it for me.\"\n",
      "prediction :  Me too.\n",
      "Real answer : I'll tell you, buddy, I'd be the luckiest guy alive if that did it for me.\n",
      "Bert Score : {'precision': [0.8737039566040039], 'recall': [0.8237746953964233], 'f1': [0.8480049967765808], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09999999999999999, 'rouge2': 0.0, 'rougeL': 0.09999999999999999, 'rougeLsum': 0.09999999999999999}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 575.3779900326209\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSIMON: It's Carol.\\nMELVIN: Here. Take the dog.\\n\\n\", 'answer': 'Good luck.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SIMON'}\n",
      "Last word -> SIMON : \"Good luck.\"\n",
      "prediction :  I can't take the dog. I've got to go back to the office.\n",
      "Real answer : Good luck.\n",
      "Bert Score : {'precision': [0.8461954593658447], 'recall': [0.8935871720314026], 'f1': [0.8692458868026733], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.934601271287248\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMELVIN: You going to come talk to me or not?\\nSIMON: I\\'m coming. What did she say?\\nMELVIN: I\\'m a great guy -- \"extraordinary\"... ... and she doesn\\'t want contact with me. I\\'m dying here.\\nSIMON: Because... ... you love her?\\nMELVIN: No... and you\\'re supposed to be sensitive and sharp.\\nSIMON: Okay... you tell me why --\\nMELVIN: I don\\'t know... Let me sleep on it and figure it out. Because I\\'m stuck! Can\\'t go back to what I had... She\\'s evicted me from my life.\\nSIMON: Did you like it that much?\\nMELVIN: It was better than this... Look, you, I\\'m very intelligent. If you\\'re going to give me advice or conversation or consolation or hope, you got to be better than you\\'re doing. If you can\\'t be at least momentarily interesting than shut the hell up. I\\'m drowning and you\\'re describing water.\\nSIMON: Picking on me won\\'t help.\\nMELVIN: Well, if that\\'s true then I\\'m really in trouble.\\nSIMON: But you know where you\\'re lucky?\\nMELVIN: Absolutely not.\\nSIMON: You know who you want. I\\'ll take your seat any day. So do something... don\\'t sleep on it... go over there. I don\\'t think anybody should ever sleep on anything -- it\\'s not always good\\nMELVIN: Hey... I\\'m charged here. But she might kill me for showing up this late.\\nSIMON: Then get in your jammies and I\\'ll read you a story... I think you\\'ve got a chance. The only real enemy you have is her ability to think logically -- the best thing you have going for you is your willingness to humiliate yourself if it gives you one chance in whatever -- so go catch her off- guard.\\nMELVIN: Okay. Thanks a lot. Here I go.\\nSIMON: What\\'s wrong?\\n\\n', 'answer': 'I forgot to lock the door.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MELVIN'}\n",
      "Last word -> MELVIN : \"I forgot to lock the door.\"\n",
      "prediction :  I'm not going to make it.\n",
      "Real answer : I forgot to lock the door.\n",
      "Bert Score : {'precision': [0.8934556245803833], 'recall': [0.896085798740387], 'f1': [0.8947687745094299], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.30769230769230765, 'rouge2': 0.0, 'rougeL': 0.30769230769230765, 'rougeLsum': 0.30769230769230765}\n",
      "bleu 1/2 : 0.16666666666666669 0.05773502691896258\n",
      "ppl : 33.49451272394237\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLARDNER: You always say that. You always say that. I'm telling you, you never met the man.\\nMCCULLERS: Seventeen months ago I was posting a walk in Lisbon, and he was there. He never saw me. But I saw him, though.\\nLARDNER: Lisbon?\\nMCCULLERS: In Portugal, yes.\\nLARDNER: Here's the news: He hasn't been in Portugal since '90. I know that from the file. Why don't you read the file, man?\\nMCCULLERS: In fact, I think I talked with him, in Bonn.\\n\\n\", 'answer': \"You always say that. You always have to know everybody. Why don't I just take the weekend off and let you kill him. Since you two are so close.\", 'gold_tag': \"LARDNER and MCCULLERS frequently argue about MCCULLERS's supposed acquaintance with the individuals in question\", 'last_speaker': 'LARDNER'}\n",
      "Last word -> LARDNER : \"You always say that. You always have to know everybody. Why don't I just take the weekend off and let you kill him. Since you two are so close.\"\n",
      "prediction :  Bonn?\n",
      "Real answer : You always say that. You always have to know everybody. Why don't I just take the weekend off and let you kill him. Since you two are so close.\n",
      "Bert Score : {'precision': [0.7933995127677917], 'recall': [0.8146657943725586], 'f1': [0.8038920164108276], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 36753.636588294634\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLARDNER: Well?\\nMCCULLERS: I don't think so.\\nLARDNER: Well, remember when Frysal's men paid off the Deejay in Cairo to announce a bogus press conference in the --\\nMCCULLERS: --Nooo--\\nLARDNER: --Yes. And the Munich Olympics in '72. A local radio station started broadcasting news of the massacre two minutes before it happened.\\nMCCULLERS: That's strictly B�ader-Meinhof stuff.\\nLARDNER: It was the PLO.\\n\\n\", 'answer': 'Whatever.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MCCULLERS'}\n",
      "Last word -> MCCULLERS : \"Whatever.\"\n",
      "prediction :  What the PLO did was to go in there and take over. They took over the whole thing.\n",
      "Real answer : Whatever.\n",
      "Bert Score : {'precision': [0.849435567855835], 'recall': [0.9172167181968689], 'f1': [0.8820258378982544], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 31.42744844680131\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMCCULLERS: I wish he'd do his job already so we could do our job.\\nLARDNER: We can't do our job unless he does his job.\\nMCCULLERS: Why don't we just do his job then, so we can do our job, and get the fuck out of here.\\nLARDNER: Do his job? I'm not a cold-blooded killer.\\nMCCULLERS: Wait a minute--\\nLARDNER: -Look. You want to kill a Good Guy, but not be a Bad Guy, you wait until a Bad Guy kills the Good Guy, and then you come in and kill the Bad Guy, and then you're the Good Guy.\\nMCCULLERS: So if we do his job, we're the bad guys. If we do our job, we're the good guys.\\n\\n\", 'answer': 'Yup.', 'gold_tag': 'LARDNER takes out bad guys as a good guy', 'last_speaker': 'LARDNER'}\n",
      "Last word -> LARDNER : \"Yup.\"\n",
      "prediction :  I'm not sure how this works.\n",
      "Real answer : Yup.\n",
      "Bert Score : {'precision': [0.8492984771728516], 'recall': [0.8861862421035767], 'f1': [0.8673503398895264], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.932415592710605\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMCCULLERS: Looks like someone keeps trying to do our job for us.\\nLARDNER: If he does our job, he's our job.\\n\\n\", 'answer': 'I get it.', 'gold_tag': 'MCCULLERS shares LARDNER\\'s professional space , The use of terms like \"our job\" signals that they share some professional responsibility', 'last_speaker': 'MCCULLERS'}\n",
      "Last word -> MCCULLERS : \"I get it.\"\n",
      "prediction :  I've got a lot of friends in the Army, and they all think it's a great idea.\n",
      "Real answer : I get it.\n",
      "Bert Score : {'precision': [0.8527504205703735], 'recall': [0.9049508571624756], 'f1': [0.8780755400657654], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.244109471189343\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLARDNER: Did you see Blank in there?\\nMCCULLERS: No...\\n\\n', 'answer': 'Good. For a second there I thought we were in trouble.', 'gold_tag': \"LARDNER's perceived threat from Blank's presence will become irrelevant once they ascertain Blank's absence , MCCULLERS's initial ignorance about Blank's presence becomes irrelevant after LARDNER's clarification\", 'last_speaker': 'LARDNER'}\n",
      "Last word -> LARDNER : \"Good. For a second there I thought we were in trouble.\"\n",
      "prediction :  Did you see anyone else?\n",
      "Real answer : Good. For a second there I thought we were in trouble.\n",
      "Bert Score : {'precision': [0.836543083190918], 'recall': [0.8527084589004517], 'f1': [0.8445484042167664], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 162.15790695663506\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDAN: Dan Soulsby.\\nMARTIN: Martin. Nice to meet you.\\nDAN: Where you heading to?\\nMARTIN: Away from here. Pisswater.\\n\\n', 'answer': \"At least it's cold pisswater. Here's to getting away. That was bad. It's gonna take all day to get another bus here.\", 'gold_tag': 'DAN shows a sense of humor even in less ideal situations , DAN implies that the wait for the next bus will be all day', 'last_speaker': 'DAN'}\n",
      "Last word -> DAN : \"At least it's cold pisswater. Here's to getting away. That was bad. It's gonna take all day to get another bus here.\"\n",
      "prediction :  I see.\n",
      "Real answer : At least it's cold pisswater. Here's to getting away. That was bad. It's gonna take all day to get another bus here.\n",
      "Bert Score : {'precision': [0.8523346185684204], 'recall': [0.8220789432525635], 'f1': [0.836933434009552], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 676.559384365141\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMARTIN: You have a license?\\nDAN: Had one. They took it away.\\nMARTIN: I got one. Let's go.\\n\\n\", 'answer': \"See that? They're all fake.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'DAN'}\n",
      "Last word -> DAN : \"See that? They're all fake.\"\n",
      "prediction :  No.\n",
      "Real answer : See that? They're all fake.\n",
      "Bert Score : {'precision': [0.9198631048202515], 'recall': [0.8261698484420776], 'f1': [0.8705026507377625], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1275.3241709894667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMARTIN: You take a hockey puck in the face?\\nDAN: A fist. My stepdad socked me. I flew across the room and dented the sheetrock in the kitchen. My mom saw everything and still took his side.\\nMARTIN: You got cracked good.\\nDAN: I hate that guy. Two hundred pounds of worthless grease.\\nMARTIN: Why'd he hit you?\\nDAN: I wrecked his sixty-five Mustang and his boat in the same week. His babies. I totaled them.\\nMARTIN: I would have popped you too.\\nDAN: It was worth it. But I didn't deserve the tour in hell. Don't ever go to military school if you can help it. It sucks. I jumped the wall two days ago.\\nMARTIN: You going back?\\nDAN: I'm done with that racket. I'm going to Seattle and playing music.\\nMARTIN: I know some chords.\\n\\n\", 'answer': \"Think you can learn drums? I'm the next Billy Squire. Krokus will be opening for me one day. Shit.\", 'gold_tag': 'DAN aims to be a drummer', 'last_speaker': 'DAN'}\n",
      "Last word -> DAN : \"Think you can learn drums? I'm the next Billy Squire. Krokus will be opening for me one day. Shit.\"\n",
      "prediction :  What do you want to do?\n",
      "Real answer : Think you can learn drums? I'm the next Billy Squire. Krokus will be opening for me one day. Shit.\n",
      "Bert Score : {'precision': [0.837558925151825], 'recall': [0.838553249835968], 'f1': [0.8380557894706726], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307691, 'rouge2': 0.0, 'rougeL': 0.07692307692307691, 'rougeLsum': 0.07692307692307691}\n",
      "bleu 1/2 : 0.01909314066544796 0.006614057941723061\n",
      "ppl : 25.275119424072976\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFERGUS: You all right?\\nJUDE: Fucking animal.\\nFERGUS: You don't know that.\\nJUDE: Fucking do. I had him all over me.\\nFERGUS: Tough work, that.\\nJUDE: Someone's got to do it. Nah, it was a breeze. Just thought of you. And you know what, Fergus? One of you made me want it...\\n\\n\", 'answer': 'Which one?', 'gold_tag': 'Everyday Language', 'last_speaker': 'FERGUS'}\n",
      "Last word -> FERGUS : \"Which one?\"\n",
      "prediction :  Who?\n",
      "Real answer : Which one?\n",
      "Bert Score : {'precision': [0.9574110507965088], 'recall': [0.9181058406829834], 'f1': [0.9373465776443481], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3856.0021279346893\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJUDE: Hello, stranger. You vanished. What was it, Fergus? Did you blow the gaff on us or did you just fuck up?\\nFERGUS: Leave me alone, Jude.\\nJUDE: No. That's the last thing I'll do. You never asked what happened.\\nFERGUS: I heard.\\nJUDE: Eddie and Tinker died.\\nFERGUS: I know.\\nJUDE: Maguire and me got out by the skin of our teeth. No thanks to you.... What you think of the hair?\\nFERGUS: Suits you.\\nJUDE: Aye, I was sick of being blond. Needed a tougher look, if you know what I mean. Fuck me, Fergus. Am I to take it that's a no? We had a court-martial in your absence. They wanted to put a bullet in your head. I pleaded for clemency. Said we should find out what happened first. So what did happen?\\nFERGUS: He ran. I couldn't shoot him in the back. I tried to catch him. He made it to the road and got hit by a Saracen.\\nJUDE: So you did fuck up.\\nFERGUS: Yes.\\nJUDE: But you know what the thing is, Fergus?\\nFERGUS: No, what is the thing?\\nJUDE: You vanished quite effectively. Became Mister Nobody. And you've no idea how useful that could be.\\nFERGUS: What do you mean?\\nJUDE: We've got some plans here. And we'll need a Mister Nobody to execute them.\\nFERGUS: No way, Jude. I'm out.\\nJUDE: You're never out, Fergus. Maybe you don't care whether you die or not. But consider the girl, Fergus. The wee black chick.\\nFERGUS: Leave her out of this.\\nJUDE: Jesus, Fergus, you're a walking cliche. You know we won't leave her out of this. But I'm glad to see you care. And I must admit I'm curious.\\nFERGUS: What the fuck do you know, Jude?\\nJUDE: You fucking tell me, boy --\\nFERGUS: She's nobody. She likes me.\\n\\n\", 'answer': \"So I suppose a fuck is out of the question. Keep your head down, Fergus. No You'll be hearing from us. Keep the faith.\", 'gold_tag': 'JUDE is manipulative as she attempts to leverage FERGUS\\' care for \"the wee black chick\" to coerce him into cooperation', 'last_speaker': 'JUDE'}\n",
      "Last word -> JUDE : \"So I suppose a fuck is out of the question. Keep your head down, Fergus. No You'll be hearing from us. Keep the faith.\"\n",
      "prediction :  -- because you're a fucking fool. You fucked up. And now you're going to pay.\n",
      "Real answer : So I suppose a fuck is out of the question. Keep your head down, Fergus. No You'll be hearing from us. Keep the faith.\n",
      "Bert Score : {'precision': [0.8774546384811401], 'recall': [0.8566489219665527], 'f1': [0.8669270277023315], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09756097560975609, 'rouge2': 0.0, 'rougeL': 0.09756097560975609, 'rougeLsum': 0.09756097560975609}\n",
      "bleu 1/2 : 0.036587442406268426 0.011976051736540165\n",
      "ppl : 9.829670339335228\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJUDE: You a handyman, Fergie?\\nFERGUS: I take pride in my work.\\n\\n', 'answer': 'I sincerely hope so. Tools of the trade. And forget about the girl.', 'gold_tag': \"JUDE is a discerning individual who values professionalism , JUDE could have some connection to FERGUS's work\", 'last_speaker': 'JUDE'}\n",
      "Last word -> JUDE : \"I sincerely hope so. Tools of the trade. And forget about the girl.\"\n",
      "prediction :  I'm sure you do.\n",
      "Real answer : I sincerely hope so. Tools of the trade. And forget about the girl.\n",
      "Bert Score : {'precision': [0.8693312406539917], 'recall': [0.8557561039924622], 'f1': [0.8624902367591858], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 55.61190690172467\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHELEN: Oh -- hello--\\nKLAATU: May I see you for a minute?\\nHELEN: I -- I was Just going to lunch.\\nKLAATU: May I walk out with you?\\n\\n', 'answer': 'Mrs. Benson speaking. Oh, hello...', 'gold_tag': 'HELEN uses formal language, indicating a professional or educated background', 'last_speaker': 'HELEN'}\n",
      "Last word -> HELEN : \"Mrs. Benson speaking. Oh, hello...\"\n",
      "prediction :  I can't.\n",
      "Real answer : Mrs. Benson speaking. Oh, hello...\n",
      "Bert Score : {'precision': [0.8603305220603943], 'recall': [0.85739666223526], 'f1': [0.8588610291481018], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 127.82165926513017\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKLAATU: I saw Bobby this morning before he went to school--\\nHELEN: Yes--?\\nKLAATU: I want to know what he told you last night.\\nHELEN: I -- I didn't really pay much attention--\\n\\n\", 'answer': 'Did you believe what he told you? I have a reason for asking this -- a very important reason.', 'gold_tag': \"KLAATU shows concern for Bobby's actions and the implications of his conversations\", 'last_speaker': 'KLAATU'}\n",
      "Last word -> KLAATU : \"Did you believe what he told you? I have a reason for asking this -- a very important reason.\"\n",
      "prediction :  What?!\n",
      "Real answer : Did you believe what he told you? I have a reason for asking this -- a very important reason.\n",
      "Bert Score : {'precision': [0.8309667110443115], 'recall': [0.8075421452522278], 'f1': [0.819087028503418], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473684, 'rouge2': 0.0, 'rougeL': 0.10526315789473684, 'rougeLsum': 0.10526315789473684}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 956.2491657536009\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHELEN: What is it you want?\\nKLAATU: Before I ask you to be honest with me, perhaps I should be completely honest with you--\\nHELEN: What happened?\\nKLAATU: What time is it?\\nHELEN: Just twelve.\\nKLAATU: We'll be stuck here for a little while -- about thirty minutes.\\nHELEN: We could try pushing the other buttons. I have a flashlight in my purse.\\nKLAATU: It won't work.\\nHELEN: Why not?\\nKLAATU: You see -- the electricity's been neutralized -- all over the world.\\n\\n\", 'answer': \"Bobby was telling the truth -- wasn't he?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'HELEN'}\n",
      "Last word -> HELEN : \"Bobby was telling the truth -- wasn't he?\"\n",
      "prediction :  What?\n",
      "Real answer : Bobby was telling the truth -- wasn't he?\n",
      "Bert Score : {'precision': [0.8595308065414429], 'recall': [0.805227518081665], 'f1': [0.8314934968948364], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKLAATU: --I've already told you more than I told Professor Barnhardt, because my life, in a sense, is in your hands. I thought if you knew the facts you'd appreciate the importance of my not being -- apprehended, -- before the meeting tonight.\\nHELEN: Yes, of course. Of course I do. You hold great hope for this meeting.\\nKLAATU: I can see no other hope for your planet. If the meeting should fail, then I'm afraid there is no hope. It must be twelve-thirty.\\n\\n\", 'answer': 'Yes -- Just exactly.', 'gold_tag': 'Everyday Language', 'last_speaker': 'HELEN'}\n",
      "Last word -> HELEN : \"Yes -- Just exactly.\"\n",
      "prediction :  --You're right. I can't believe it.\n",
      "Real answer : Yes -- Just exactly.\n",
      "Bert Score : {'precision': [0.8400483131408691], 'recall': [0.8330329060554504], 'f1': [0.8365259766578674], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.159902379950026\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHELEN: Where are you going now?\\nKLAATU: Back to the boardinghouse. I'll be safe there for the afternoon -- and I can keep an eye on Bobby. He's the only other person who knows anything about--\\nHELEN: No, wait a minute -- there's someone else.\\nKLAATU: Who?\\n\\n\", 'answer': \"Tom... He was there last night when Bobby told me what he saw. Of course, he doesn't know anything definite. He'd talk to me first, anyway, before-- We can't take that chance. I'll get in touch with him right away and make sure.\", 'gold_tag': 'HELEN has a close relationship with a person named Tom', 'last_speaker': 'HELEN'}\n",
      "Last word -> HELEN : \"Tom... He was there last night when Bobby told me what he saw. Of course, he doesn't know anything definite. He'd talk to me first, anyway, before-- We can't take that chance. I'll get in touch with him right away and make sure.\"\n",
      "prediction :  You. You're the other person who knows about this.\n",
      "Real answer : Tom... He was there last night when Bobby told me what he saw. Of course, he doesn't know anything definite. He'd talk to me first, anyway, before-- We can't take that chance. I'll get in touch with him right away and make sure.\n",
      "Bert Score : {'precision': [0.8804603219032288], 'recall': [0.8386617302894592], 'f1': [0.8590528964996338], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 48.70801109331437\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKLAATU: I'm sure Barnhardt can arrange to hide me until the meeting.\\nHELEN: Where is the meeting going to be?\\n\\n\", 'answer': 'At the ship.', 'gold_tag': 'KLAATU is soon going to attend a meeting', 'last_speaker': 'KLAATU'}\n",
      "Last word -> KLAATU : \"At the ship.\"\n",
      "prediction :  It's not a meeting, it's a party.\n",
      "Real answer : At the ship.\n",
      "Bert Score : {'precision': [0.8472100496292114], 'recall': [0.9001630544662476], 'f1': [0.872884213924408], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18.380431485783568\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKLAATU: Hello.\\nHELEN: I -- I thought you were--\\nKLAATU: I was.\\nHELEN: You mean he has the power of life and death?\\nKLAATU: No -- that is a power reserved to This technique, in certain cases, can re-stimulate life for a limited period. It's a refinement of scientific principles known to your own people.\\nHELEN: But how -- how long--?\\n\\n\", 'answer': 'How long will I live? That no one can say.', 'gold_tag': 'KLAATU has had his life re-stimulated for an indeterminate time period', 'last_speaker': 'KLAATU'}\n",
      "Last word -> KLAATU : \"How long will I live? That no one can say.\"\n",
      "prediction :  I'm afraid I can't give you any more information.\n",
      "Real answer : How long will I live? That no one can say.\n",
      "Bert Score : {'precision': [0.8556086421012878], 'recall': [0.8490411043167114], 'f1': [0.8523122668266296], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1904761904761905, 'rouge2': 0.0, 'rougeL': 0.1904761904761905, 'rougeLsum': 0.1904761904761905}\n",
      "bleu 1/2 : 0.09942659075715217 0.03334869235560668\n",
      "ppl : 11.580050559863878\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLERK: Twelve gauge. You need shells? Moss\\nMOSS: Uh-huh. Double ought.\\nCLERK: They'll give you a wallop.\\nMOSS: You have camping supplies?\\nCLERK: Tent poles.\\nMOSS: Uh-huh.\\nCLERK: You already have the tent?\\nMOSS: Somethin' like that.\\nCLERK: Well you give me the model number of the tent I can order you the poles.\\nMOSS: Never mind. I want a tent.\\nCLERK: What kind of tent?\\nMOSS: The kind with the most poles.\\nCLERK: Well I guess that'd be our ten-foot backyard Per-Gola. You can stand up in it. Well, some people could stand up in it. Six foot clearance at the ridge. You might just could.\\n\\n\", 'answer': \"Let me have that one. Where's the nearest hardware store?\", 'gold_tag': 'MOSS has a need for camping supplies', 'last_speaker': 'MOSS'}\n",
      "Last word -> MOSS : \"Let me have that one. Where's the nearest hardware store?\"\n",
      "prediction :  Uh-huh.\n",
      "Real answer : Let me have that one. Where's the nearest hardware store?\n",
      "Bert Score : {'precision': [0.8041415214538574], 'recall': [0.8365483283996582], 'f1': [0.8200249075889587], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 98.24153081040103\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOSS: One room, one night.\\nCLERK: That's twenty-six dollars.\\nMOSS: You on all night?\\nCLERK: Yessir, be here til ten tomorrow morning.\\nMOSS: For you. I ain't asking you to do anything illegal.\\nCLERK: I'm waitin' to hear your description of that.\\n\\n\", 'answer': \"There's somebody lookin' for me. Not police. Just call me if anyone else checks in tonight.\", 'gold_tag': 'MOSS is not being sought after by the police , MOSS is being sought after by an unidentified person', 'last_speaker': 'MOSS'}\n",
      "Last word -> MOSS : \"There's somebody lookin' for me. Not police. Just call me if anyone else checks in tonight.\"\n",
      "prediction :  Okay, here's the way it is. You're gonna find a guy in a room. He's got a girl with him. You're gonna get him out of there.\n",
      "Real answer : There's somebody lookin' for me. Not police. Just call me if anyone else checks in tonight.\n",
      "Bert Score : {'precision': [0.8486489653587341], 'recall': [0.8517759442329407], 'f1': [0.8502095937728882], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.08333333333333333, 'rougeLsum': 0.08333333333333333}\n",
      "bleu 1/2 : 0.037037037037037035 0.01193524790065722\n",
      "ppl : 7.033863759737558\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLERK: How those Larries holdin' up?\\nMOSS: Good. I need everything else.\\nCLERK: Okay.\\nMOSS: You get a lot of people come in here with no clothes on?\\n\\n\", 'answer': \"No sir, it's unusual.\", 'gold_tag': 'CLERK works in a place where they sell or lend clothes', 'last_speaker': 'CLERK'}\n",
      "Last word -> CLERK : \"No sir, it's unusual.\"\n",
      "prediction :  Just a lot of people.\n",
      "Real answer : No sir, it's unusual.\n",
      "Bert Score : {'precision': [0.8506584167480469], 'recall': [0.8407694697380066], 'f1': [0.8456850051879883], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 173.52306990837408\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMICHAEL: There's a lot I can't tell you, Tom. I know that's upset you in the past; and you've felt that it was because of some lack of trust or confidence. But it is because I do trust you that I've kept so much secret from you. It's precisely that at this moment, you are the only one that I can completely trust. In time, you'll understand everything.\\nHAGEN: But your people... Neri... Rocco; you don't think...\\nMICHAEL: No, I have confidence in their loyalty... but this is life and death, and Tom, you are my brother.\\nHAGEN: Mikey, I hoped...\\nMICHAEL: No Tom, just listen. All my people are businessmen; their loyalty is based on that. One thing I learned from my father is to try to think as the people around you think...and on that basis, anything is possible. Fredo has a good heart, but he is weak...and stupid, and stupid people are the most dangerous of all. I've kept you out of things, Tom, because I've always known that your instincts were legitimate, and I wanted you to know very little of things that would make you an accomplice, for your own protection. I never blamed you for the setbacks the family took under Sonny; I know you were in a position of limited power, and you did your best to advise and caution him. What I am saying is that now, for how long I do not know, you will be the Don. If what I think has happened is true; I will leave tonight, and absolutely no one will know how to contact me. And even you are not to try to reach me unless it is absolutely necessary. I give you complete power: over Neri... Fredo, everyone. I am trusting you with the lives of my wife and children, and the future of this family, solely resting on your judgment and talent. ...But Tom, you must know that I do this only because I believe you are the only one who is capable of taking over for me. I've prepared this; have had it for over a month. It won't explain everything; but indicates where I will be, so in a sense, it is my life. Also, there are three tasks that must be executed immediately. Pop would have given those to Luca -- You knew Pop as well as anyone, act as though you were him. It discusses Kay as well; that will be the most difficult. The men who tried to kill me tonight, will never leave the estate.\\nHAGEN: Will we...be able to get who ordered it out of them?\\nMICHAEL: I don't think so. Unless I'm very wrong...they're already dead. Killed by someone inside...very frightened that they botched it. That's why I am going to disappear in a few minutes, and leave everything to you.\\nHAGEN: But if you're wrong...\\n\\n\", 'answer': \"If I'm wrong... ...I don't think I'm wrong. Yes.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MICHAEL'}\n",
      "Last word -> MICHAEL : \"If I'm wrong... ...I don't think I'm wrong. Yes.\"\n",
      "prediction :  I'm not wrong, Tom. You know I'm not wrong.\n",
      "Real answer : If I'm wrong... ...I don't think I'm wrong. Yes.\n",
      "Bert Score : {'precision': [0.9000680446624756], 'recall': [0.8782579898834229], 'f1': [0.8890292644500732], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.5217391304347826, 'rouge2': 0.1904761904761905, 'rougeL': 0.5217391304347826, 'rougeLsum': 0.5217391304347826}\n",
      "bleu 1/2 : 0.3333333333333333 0.06454972243679029\n",
      "ppl : 17.195707785073846\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMICHAEL: Do you think they have somebody to back up Cicci?\\n\\n', 'answer': \"No. But if they do have somebody, you'll do three years for perjury if you give them so much as a wrong middle name. Michael, take the Fifth all the way, that way you can't get into trouble.\", 'gold_tag': 'HAGEN is a cautious and knowledgeable character , HAGEN is able to provide advice on legal matters , MICHAEL is involved in legal trouble , MICHAEL is facing an imminent legal situation', 'last_speaker': 'HAGEN'}\n",
      "Last word -> HAGEN : \"No. But if they do have somebody, you'll do three years for perjury if you give them so much as a wrong middle name. Michael, take the Fifth all the way, that way you can't get into trouble.\"\n",
      "prediction :  Maybe. But I think they're trying to get us to fight the wrong guy.\n",
      "Real answer : No. But if they do have somebody, you'll do three years for perjury if you give them so much as a wrong middle name. Michael, take the Fifth all the way, that way you can't get into trouble.\n",
      "Bert Score : {'precision': [0.9076437950134277], 'recall': [0.8458168506622314], 'f1': [0.875640332698822], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.10909090909090907, 'rougeLsum': 0.10909090909090907}\n",
      "bleu 1/2 : 0.05145494632798638 0.008442857817139271\n",
      "ppl : 18.54661202596832\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMICHAEL: Al, get me a wet towel. Does Kay know I'm back? Did the boy get something from me for Christmas?\\nHAGEN: I took care of it.\\nMICHAEL: What was it, so I'll know.\\nHAGEN: A little care he can ride in with an electric motor.\\nMICHAEL: Fellas, can you wait outside a minute? Where's my brother?\\nHAGEN: Roth got out on a private boat. He's in a hospital in Miami. Had a stroke but he's recovered okay. Bussetta's dead.\\nMICHAEL: I asked about Fredo?\\nHAGEN: The new government arrested him, held him for a couple of days with a lot of the other casino people, including Roth's brother, Sam. The American Embassy arranged flights for citizens; I'm not sure, but I\\nMICHAEL: I want you to reach Fredo. I know he's scared, but have one of our people reach him. Assure him that there will be no reprisals. Tell him that I know Roth misled him.\\nHAGEN: My information is that Fredo thought it was a kidnapping. Roth assured him nothing would happen to you.\\nMICHAEL: They can come in now.\\nHAGEN: Wait... there's something else.\\nMICHAEL: Alright. Go on, tell me.\\nHAGEN: Kay had a miscarriage; she lost the baby.\\nMICHAEL: Was it a boy or a girl?\\nHAGEN: Mike, at three and a half...\\nMICHAEL: What is it, can't you give me straight answers anymore!\\nHAGEN: It was a boy.\\nMICHAEL: And Kay...she's all right?\\nHAGEN: She took the Senate Investigation worse.\\nMICHAEL: Does she blame it on me? The baby?\\n\\n\", 'answer': \"I don't know.\", 'gold_tag': 'HAGEN is an informed individual', 'last_speaker': 'HAGEN'}\n",
      "Last word -> HAGEN : \"I don't know.\"\n",
      "prediction :  It's not that simple, Michael.\n",
      "Real answer : I don't know.\n",
      "Bert Score : {'precision': [0.8331464529037476], 'recall': [0.8503047227859497], 'f1': [0.8416381478309631], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 43.41551227683465\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMICHAEL: Christ, Tom; I needed more time with him. I really needed him.\\nHAGEN: Did he give you his politicians?\\nMICHAEL: Not all...I needed another four months and I would have had them all. I guess you've figured it all out?\\nHAGEN: How will they come at you?\\nMICHAEL: I know now. I'll make them call me Don.\\nHAGEN: Have you agreed on a meeting?\\n\\n\", 'answer': \"A week from tonight. In Brooklyn on Tessio's ground, where I'll be safe. But after the Baptism. I've decided to stand as godfather to Connie's baby.\", 'gold_tag': \"MICHAEL has an important meeting lined up a week from the conversation , MICHAEL has a significant role in Connie's baby's baptism as the godfather\", 'last_speaker': 'MICHAEL'}\n",
      "Last word -> MICHAEL : \"A week from tonight. In Brooklyn on Tessio's ground, where I'll be safe. But after the Baptism. I've decided to stand as godfather to Connie's baby.\"\n",
      "prediction :  I'll call him tonight.\n",
      "Real answer : A week from tonight. In Brooklyn on Tessio's ground, where I'll be safe. But after the Baptism. I've decided to stand as godfather to Connie's baby.\n",
      "Bert Score : {'precision': [0.8825302124023438], 'recall': [0.8387562036514282], 'f1': [0.8600866198539734], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17142857142857143, 'rouge2': 0.0606060606060606, 'rougeL': 0.1142857142857143, 'rougeLsum': 0.1142857142857143}\n",
      "bleu 1/2 : 0.0020433857192320333 0.0005275999240309154\n",
      "ppl : 64.85855267378216\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: They have everything we ordered?\\nPJ: Glocks, Uzis, Tec-9s...\\nSEAN: What the hell is that?\\nPJ: Oh, my hair? Shondra just did it. What? You hate it?\\nSEAN: No. I just think it's a choice my character would have made.\\nPJ: Don't go there, Sean. You're just jealous you didn't think of it first.\\n\\n\", 'answer': 'Whatever.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SEAN'}\n",
      "Last word -> SEAN : \"Whatever.\"\n",
      "prediction :  It's just that I don't like seeing you all dressed up like a prostitute.\n",
      "Real answer : Whatever.\n",
      "Bert Score : {'precision': [0.8296096324920654], 'recall': [0.9239319562911987], 'f1': [0.8742340207099915], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.313716666603085\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: Okay, got the gangsta wear. What's so funny?\\nPJ: That wig, man! I didn't know this was Halloween. Bring me back some candy!\\n\\n\", 'answer': 'Whatever.', 'gold_tag': 'SEAN possibly indicates a more serious personality', 'last_speaker': 'SEAN'}\n",
      "Last word -> SEAN : \"Whatever.\"\n",
      "prediction :  It's a joke, man.\n",
      "Real answer : Whatever.\n",
      "Bert Score : {'precision': [0.8508114218711853], 'recall': [0.9327428340911865], 'f1': [0.8898952603340149], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 29.203089026675446\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPJ: Nope, you're not convincing me. Remember your core character. You're an oppressed black man from\\nSEAN: Yeah, I know, I'm having trouble finding this one. Lemme try it again. Gimme your ride, punk, or I will dust yo ass!\\n\\n\", 'answer': \"Add a 'beeyotch' and I think you're there.\", 'gold_tag': 'PJ plays the role of a coach or guide for acting', 'last_speaker': 'PJ'}\n",
      "Last word -> PJ : \"Add a 'beeyotch' and I think you're there.\"\n",
      "prediction :  I'm not afraid of you, man. I'm not gonna give you my car.\n",
      "Real answer : Add a 'beeyotch' and I think you're there.\n",
      "Bert Score : {'precision': [0.8585021495819092], 'recall': [0.814020037651062], 'f1': [0.8356695771217346], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666669, 'rouge2': 0.0, 'rougeL': 0.16666666666666669, 'rougeLsum': 0.16666666666666669}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.327547344800285\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: What's next?\\nPJ: How about... number three?\\n\\n\", 'answer': \"Yeah, perfect. Let's take it to another level, my man.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SEAN'}\n",
      "Last word -> SEAN : \"Yeah, perfect. Let's take it to another level, my man.\"\n",
      "prediction :  Are you sure?\n",
      "Real answer : Yeah, perfect. Let's take it to another level, my man.\n",
      "Bert Score : {'precision': [0.8299344778060913], 'recall': [0.8398414850234985], 'f1': [0.8348585367202759], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 105.98414918782687\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: How much did you have to give this guy, anyway? What are you talking about? When you set this thing up yesterday, what did you pay?\\nPJ: I thought you set it up.\\nSEAN: You mean the owner doesn't know this is all fake?\\nPJ: Oh damn.\\nSEAN: Get in there! He could get shot!\\n\\n\", 'answer': \"I'm not going in there! You go in there!\", 'gold_tag': 'PJ refuses to approach the owner of the establishment', 'last_speaker': 'PJ'}\n",
      "Last word -> PJ : \"I'm not going in there! You go in there!\"\n",
      "prediction :  I think he's just messing with us.\n",
      "Real answer : I'm not going in there! You go in there!\n",
      "Bert Score : {'precision': [0.864261269569397], 'recall': [0.8445894718170166], 'f1': [0.8543121218681335], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11111111111111112, 'rouge2': 0.0, 'rougeL': 0.11111111111111112, 'rougeLsum': 0.11111111111111112}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 25.178471950719246\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nINSPECTOR: Kafka -- is that your real name?\\nKAFKA: Yes. Yes, of course -- why wouldn't it be?\\nINSPECTOR: When was the last time you saw Mr. Raban?\\nKAFKA: Wednesday. We left the office together.\\nINSPECTOR: Did you go anywhere afterwards -- to have a drink perhaps?\\nKAFKA: No, we said goodbye outside the building. He went off, as usual, toward his house.\\nINSPECTOR: Your office is the Workmen's --\\nKAFKA: -- Accident and Compensation Association.\\nINSPECTOR: Where you've been employed for seven years.\\nKAFKA: Eight -- and seven months.\\nINSPECTOR: Engaged in the manufacture and distribution of ... pills and so forth.\\nKAFKA: Well -- other departments are, yes.\\nINSPECTOR: Would you describe your relationship with the dead man as close?\\nKAFKA: Yes. Since he came to the office, almost three years ago, we've been quite good friends. How was Eduard ...\\nINSPECTOR: He was found in the River. Could he swim?\\nKAFKA: I don't know.\\nINSPECTOR: Was he depressed?\\nKAFKA: No. He didn't seem to be. Do you think he drowned himself?\\nINSPECTOR: Grown men don't normally fall into the river, do they?\\nKAFKA: No, I suppose not.\\nINSPECTOR: He might have had a drink or two, despite what you think.\\nKAFKA: Can I ask -- how you found me?\\nINSPECTOR: His landlady knew of no other friends to refer us to.\\nKAFKA: I don't think he really had any. He had no family either.\\nINSPECTOR: We know that.\\nKAFKA: He wasn't a lonely man, though.\\nINSPECTOR: What makes you think so?\\n\\n\", 'answer': '... Just a perception.', 'gold_tag': 'Everyday Language', 'last_speaker': 'KAFKA'}\n",
      "Last word -> KAFKA : \"... Just a perception.\"\n",
      "prediction :  He was a good friend to me.\n",
      "Real answer : ... Just a perception.\n",
      "Bert Score : {'precision': [0.8832211494445801], 'recall': [0.8757586479187012], 'f1': [0.8794741034507751], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0.14285714285714285 0.048795003647426664\n",
      "ppl : 41.27841710384235\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nINSPECTOR: I don't usually involve myself with you people in the Old Quarter -- but the River runs its own course. It won't be the last time it deposits its unwanted debris on my doorstep.\\nKAFKA: Probably not.\\nINSPECTOR: Anyway, I'd like you to reflect that in me you have -- I won't say a friend, because we're complete fencers, of course -- from distinctly incompatible social classes -- but to some extent, shall we say, an interested third party.\\nKAFKA: I'll bear that in mind.\\n\\n\", 'answer': '-- Should you happen upon anything that might be relevant.', 'gold_tag': 'Everyday Language', 'last_speaker': 'INSPECTOR'}\n",
      "Last word -> INSPECTOR : \"-- Should you happen upon anything that might be relevant.\"\n",
      "prediction :  Good. I'm sure you will. I must say, I'm more than a little surprised to find you sitting here like this, in the middle of the night.\n",
      "Real answer : -- Should you happen upon anything that might be relevant.\n",
      "Bert Score : {'precision': [0.8342536091804504], 'recall': [0.8385117053985596], 'f1': [0.8363772630691528], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05263157894736842, 'rouge2': 0.0, 'rougeL': 0.05263157894736842, 'rougeLsum': 0.05263157894736842}\n",
      "bleu 1/2 : 0.037037037037037035 0.01193524790065722\n",
      "ppl : 8.761902110442264\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nINSPECTOR: You said she was extremely upset. People who are extremely upset -- Kafka -- are given to disappearing in a hurry. They go and calm down for a day or so and then they come back.\\nKAFKA: But that's just my point -- she was more than upset, she was livid. She slammed every door on her way downstairs -- except that one. I was just behind her and I didn't even hear that one shut -- not at all.\\nINSPECTOR: That's not what I call conclusive evidence of an abduction.\\n\\n\", 'answer': \"If someone was waiting here in the hallway to spirit her away, wouldn't they have shut the door as quietly\", 'gold_tag': 'KAFKA shows concern over the disappearance of a woman , KAFKA is assertive in expressing his perspective', 'last_speaker': 'KAFKA'}\n",
      "Last word -> KAFKA : \"If someone was waiting here in the hallway to spirit her away, wouldn't they have shut the door as quietly\"\n",
      "prediction :  I'm not sure I'd say she was abducted either. I'm not sure I'd say she was anywhere. I'm not sure I'd say she existed.\n",
      "Real answer : If someone was waiting here in the hallway to spirit her away, wouldn't they have shut the door as quietly\n",
      "Bert Score : {'precision': [0.8298490643501282], 'recall': [0.8340920805931091], 'f1': [0.8319652080535889], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0392156862745098, 'rouge2': 0.0, 'rougeL': 0.0392156862745098, 'rougeLsum': 0.0392156862745098}\n",
      "bleu 1/2 : 0.041666666666666664 0.013459547551454133\n",
      "ppl : 6.263473583023543\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nINSPECTOR: Why would someone want to kidnap this woman -- the name is Rossmann?\\nKAFKA: You told me to contact you if anything relevant came up -- Gabriela is relevant. When I spoke to you before I didn't know she'd been seeing Eduard.\\nINSPECTOR: That's been noted. But where does it lead us? Unless you have something more to add.\\nKAFKA: She's missing. I went to her house and she hadn't returned there.\\n\\n\", 'answer': \"She lost her job today. Just between you and me, I'd probably go away and brood a bit myself.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'INSPECTOR'}\n",
      "Last word -> INSPECTOR : \"She lost her job today. Just between you and me, I'd probably go away and brood a bit myself.\"\n",
      "prediction : What's the address?\n",
      "Real answer : She lost her job today. Just between you and me, I'd probably go away and brood a bit myself.\n",
      "Bert Score : {'precision': [0.8276530504226685], 'recall': [0.8185102939605713], 'f1': [0.8230562806129456], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 53.74912115579179\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAFKA: Maybe it's true then what she said.\\nINSPECTOR: What did she say?\\nKAFKA: That the police may have allegiance to something other than truth. -- She didn't think Eduard committed suicide. Any more than I do. She was convinced of it.\\n\\n\", 'answer': \"I'm going to say something, and I hope it's quite clear because I won't be repeating it. We don't have to hunt for criminals. We're drawn towards them. The guilty show us the way.\", 'gold_tag': 'INSPECTOR is likely a law enforcement officer , INSPECTOR has a somewhat cynical view of his job , INSPECTOR indicates that the guilty are drawn to them, rather than the police needing to seek out crime', 'last_speaker': 'INSPECTOR'}\n",
      "Last word -> INSPECTOR : \"I'm going to say something, and I hope it's quite clear because I won't be repeating it. We don't have to hunt for criminals. We're drawn towards them. The guilty show us the way.\"\n",
      "prediction :  And what did you tell her?\n",
      "Real answer : I'm going to say something, and I hope it's quite clear because I won't be repeating it. We don't have to hunt for criminals. We're drawn towards them. The guilty show us the way.\n",
      "Bert Score : {'precision': [0.8432216644287109], 'recall': [0.8253511190414429], 'f1': [0.8341907262802124], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.044444444444444446, 'rouge2': 0.0, 'rougeL': 0.044444444444444446, 'rougeLsum': 0.044444444444444446}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 70.50374148461412\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGALE: You broke the lock.\\nDEWEY: You broke my heart.\\nGALE: What are we looking for?\\nDEWEY: A bloody knife. A ghost mask. Something like that?\\nGALE: Can we turn the light on?\\nDEWEY: That's not the way it's done. And it's sexier in the dark.\\nGALE: Dewey, you and I would never make it.\\nDEWEY: Maybe not. But think about the sex. As frustrated as I am...\\nGALE: ... and as lonely as I am...\\nDEWEY: We'd break some furniture.\\nGALE: Tell you what. We get through this one. And we'll take out a hotel room. Over here with the light.\\nDEWEY: They're roomates.\\nGALE: And Joel's pre-med.\\nDEWEY: The sorority girl was gutted with autopsy precision.\\nGALE: Shit! It's both of them. The first murders were to throw us - using the same names as Woodsboro. But they've moved on - they're getting closer to Sidney. They're not looking for a Himbry or a Tatum to kill. They're looking for the new Tatum.\\n\\n\", 'answer': 'Hallie?', 'gold_tag': 'Everyday Language', 'last_speaker': 'DEWEY'}\n",
      "Last word -> DEWEY : \"Hallie?\"\n",
      "prediction :  They're going to kill Sidney.\n",
      "Real answer : Hallie?\n",
      "Bert Score : {'precision': [0.8622807264328003], 'recall': [0.8120486736297607], 'f1': [0.83641117811203], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 92.4960011620006\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGALE: Ssshh! What was that?\\nDEWEY: Let's find out.\\nGALE: This is all too familiar.\\n\\n\", 'answer': 'Over here.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DEWEY'}\n",
      "Last word -> DEWEY : \"Over here.\"\n",
      "prediction :  You can't let this go.\n",
      "Real answer : Over here.\n",
      "Bert Score : {'precision': [0.8492527008056641], 'recall': [0.8945187926292419], 'f1': [0.8712981939315796], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 51.20621299636415\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDEWEY: Gale! Gale!\\n\\n', 'answer': 'NOOOOOOO!', 'gold_tag': 'Everyday Language', 'last_speaker': 'GALE'}\n",
      "Last word -> GALE : \"NOOOOOOO!\"\n",
      "prediction :  I'm here, Dewey!\n",
      "Real answer : NOOOOOOO!\n",
      "Bert Score : {'precision': [0.8555875420570374], 'recall': [0.8199943900108337], 'f1': [0.83741295337677], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 103.05024789894372\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDEWEY: They found another note?\\nGALE: Uh-huh. Another News clipping. Another one about Sid's mom. Dewey, whether we like it or not it looks like we're going to have to go back into our past.\\nDEWEY: You mean OUR past as in Me and Sid. This has nothing to do with you Gale.\\nGALE: This has everything to do with me Dewey. I was the one who brought the nation's attention to this shit anyway. I'll be damned if I'm gonna sit around and pass on the buck again.\\nDEWEY: Do you really mean it this time Gale?\\nGALE: Yes. Look, let's get something straight Dewey, I got into this shit cause the police came looking for ME. Not cause I'm out to make the SUNRISE STUDIOS SLASHINGS.\\nDEWEY: Why would the police come to you?\\nGALE: Again, I am the author of the definitive book on the Woodsboro murders.! What about you?\\nDEWEY: What about me?\\nGALE: You said you'd never leave Woodsboro, 'The only place that's real!' But now you're here. Not with me. Dewey, I took care of you. I waited until you were well. I couldn't stay there, I mean, it's like dog years, one year in Woodsboro is like seven everywhere else.\\nDEWEY: So it's off to London for a week? New York for a month? L.A Forever?\\nGALE: It was fucking '60 Minutes II'! I couldn't say no! I could've been the next Diane Sawyer!\\nDEWEY: What's wrong with just being Gale Weathers? I liked her!\\nGALE: It didn't work Dewey. We tried, we're different.\\nDEWEY: You used to say that was our strength.\\nGALE: Dewey, you're not just here because of that second rate K-Mart, straight-to-video version of me, are you?\\nDEWEY: Brace yourself, Gale, all of this is actually not About you.\\nGALE: All of what Dewey? You do know something, don't you?\\nDEWEY: Off the record.\\nGALE: Always.\\nDEWEY: Two months ago, the Woodsboro police got a call from a woman who said she was with 'Stab 3'. She wanted to see the file on Sid, for research.\\nGALE: And?\\nDEWEY: The boys said no. She wouldn't give her name. A month later, the station gets broken into, the file room ransacked.\\nGALE: Someone stole Sid's file?\\nDEWEY: I already removed it. I think someone on the film was trying to find Sid, and that's the only reason I came here. To make do a little private investigating of my own and make sure no one here was planning anything.\\nGALE: I'm sorry, this is too good!\\nDEWEY: What part of 'Off the record' don't you understand?\\nGALE: Right. Sorry. Do you think he did it?\\nDEWEY: I've got my suspicions but still, nothing you say can ever make me take my eyes off one person.\\nGALE: And who is that?\\nDEWEY: Jennifer needs me.\\nGALE: Jennifer?! Wait, where are you going off to?\\n\\n\", 'answer': \"I'm on duty.\", 'gold_tag': 'DEWEY is committed to his job and is portrayed as someone who is sensitive and cares about others', 'last_speaker': 'DEWEY'}\n",
      "Last word -> DEWEY : \"I'm on duty.\"\n",
      "prediction :  I'm going to find Sid.\n",
      "Real answer : I'm on duty.\n",
      "Bert Score : {'precision': [0.9085661172866821], 'recall': [0.9171050786972046], 'f1': [0.9128156304359436], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4, 'rouge2': 0.25, 'rougeL': 0.4, 'rougeLsum': 0.4}\n",
      "bleu 1/2 : 0.2 0.07071067811865477\n",
      "ppl : 141.23270718838566\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDEWEY: Sheriff just radioed me. I'm gonna check out a possible lead. Thought you might like to join me.\\nGALE: What kind of lead?\\nDEWEY: A car was spotted in the bushes a little ways up the road.\\nGALE: I'd love to. If you're sure it's alright?\\nDEWEY: Ma'am, I am the Deputy of this town.\\nGALE: Can I bring Kenny?\\nDEWEY: NO! I mean...I should probably take just you.\\n\\n\", 'answer': \"I'll be back.\", 'gold_tag': 'GALE will return after joining DEWEY in checking out his lead', 'last_speaker': 'GALE'}\n",
      "Last word -> GALE : \"I'll be back.\"\n",
      "prediction :  I understand.\n",
      "Real answer : I'll be back.\n",
      "Bert Score : {'precision': [0.9008997082710266], 'recall': [0.8635164499282837], 'f1': [0.8818120360374451], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.0, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 524.1272433307118\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGALE: So is Dewey your real name?\\nDEWEY: Dwight. Dewey was something I got stuck with a long time ago.\\nGALE: I like it. It's... sexy.\\nDEWEY: Nah... it's just this town's way of not taking me serious.\\nGALE: What about Gale Weathers? I sound like a meteorologist... People treat me like the Antichrist of television journalism.\\nDEWEY: I don't think you're so bad.\\n\\n\", 'answer': 'Are all the local boys as sweet as you?', 'gold_tag': 'Everyday Language', 'last_speaker': 'GALE'}\n",
      "Last word -> GALE : \"Are all the local boys as sweet as you?\"\n",
      "prediction :  I don't think you're so bad either.\n",
      "Real answer : Are all the local boys as sweet as you?\n",
      "Bert Score : {'precision': [0.845984160900116], 'recall': [0.8392839431762695], 'f1': [0.8426206707954407], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 26.661975477855986\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDEWEY: You okay?\\nGALE: What's that?\\nDEWEY: Looks like a car. Shit. It's Neil Prescott's car.\\nGALE: Sidney's father?\\n\\n\", 'answer': \"We gotta get back. Jesus. He's here. What the fuck is he doing here?\", 'gold_tag': 'DEWEY potentially works in a field that demands quick response times and analytical skills , GALE might be less experienced in high-stake, tense situations compared to Dewey', 'last_speaker': 'DEWEY'}\n",
      "Last word -> DEWEY : \"We gotta get back. Jesus. He's here. What the fuck is he doing here?\"\n",
      "prediction :  Yep.\n",
      "Real answer : We gotta get back. Jesus. He's here. What the fuck is he doing here?\n",
      "Bert Score : {'precision': [0.9181057810783386], 'recall': [0.8467280268669128], 'f1': [0.8809734582901001], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 908.8374124511863\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDEWEY: I'll call for backup.\\n\\n\", 'answer': \"I'll get my camera. Kenny! Camera! Quick! Kenny? Dewey? Dewey? Where are you?\", 'gold_tag': 'GALE shows assertive behavior , GALE is involved in the reporting or media industry , GALE intends to get a camera and gives a directive to Kenny', 'last_speaker': 'GALE'}\n",
      "Last word -> GALE : \"I'll get my camera. Kenny! Camera! Quick! Kenny? Dewey? Dewey? Where are you?\"\n",
      "prediction :  It's too late.\n",
      "Real answer : I'll get my camera. Kenny! Camera! Quick! Kenny? Dewey? Dewey? Where are you?\n",
      "Bert Score : {'precision': [0.8530224561691284], 'recall': [0.7962720394134521], 'f1': [0.8236708641052246], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 56.06652033320609\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHADOW: You could've crispered half your company with that little stunt, but more importantly you wrecked the physical evidence I use to prove it's arson. You've made my day longer, Probie. Go home and think about that.\\nBRIAN: Uh, I'm Brian McCaffrey. Your new assistant.\\nSHADOW: Your Dennis' kid. I work alone. Are you still here?\\nBRIAN: Get used to me, Inspector. I'm not going anywhere.\\nSHADOW: Then go find a corner. I don't want you in my way.\\nBRIAN: I think we should get something straight here. I was assigned to this office by the city.\\nSHADOW: Look, I knew your father, he had a helluva reputation on this job. But that don't mean you get any slack. Swayzak sends you down here, okay, I gotta eat you, that's the rules and I got nothing to say about that. But Swayzak or no, you live with me. Step out of line, and I don't care who knows you, I'll swing the hammer. You think you're the first?\\nBRIAN: Where are you going?\\n\\n\", 'answer': 'Pest control.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SHADOW'}\n",
      "Last word -> SHADOW : \"Pest control.\"\n",
      "prediction :  I'm going to get a drink.\n",
      "Real answer : Pest control.\n",
      "Bert Score : {'precision': [0.8927425146102905], 'recall': [0.8695866465568542], 'f1': [0.8810124397277832], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 34.56706249095988\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRIAN: \"Trychtichlorate is a binary structured --\"\\nSHADOW: -- Go to the bottom. Under heat properties.\\nBRIAN: \"During heat episodes of 2000 Kelvin or higher, Trych breaks down and dissipates. Will consume magnesium\".\\nSHADOW: Ever burned magnesium? It\\'s so hot Son of a bitch tears \\'em apart just to eat the oxygen. Wouldn\\'t take much at all to melt ten gauge wire. Problem\\'s burnt magnesium leaves a powder trace -- unless you could find something that would eat its residue.\\nBRIAN: Trychticholorate. Then Swayzak can announce Seagrave was a murder.\\nSHADOW: Look, it isn\\'t proof, okay? Someone may have put the chemical in the outlet, but we found it as a vapor\\nBRIAN: And the putty around the door?\\nSHADOW: Even if it was used to seal the air off, that doesn\\'t explain why someone would go to the trouble of a backdraft. A gun\\'s a helluva lot easier\\nBRIAN: But the right guess on this is arson.\\nSHADOW: I don\\'t guess.\\nBRIAN: Some people say you don\\'t do much of anything when it comes to this case.\\n\\n', 'answer': \"I don't work for them, either.\", 'gold_tag': \"SHADOW doesn't appreciate some other people's critique of his work\", 'last_speaker': 'SHADOW'}\n",
      "Last word -> SHADOW : \"I don't work for them, either.\"\n",
      "prediction :  I'm not in this case.\n",
      "Real answer : I don't work for them, either.\n",
      "Bert Score : {'precision': [0.8779743909835815], 'recall': [0.8820739388465881], 'f1': [0.8800193667411804], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 90.00099350632615\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHADOW: Take the top off. Go ahead. Take it off.\\nBRIAN: Jesus!\\nSHADOW: That's it! Oh, that son of a bitch, he's different, goddamn it! You see what this tells us, huh? Our killer doesn't love fire!\\nBRIAN: What?\\nSHADOW: I got it after we talked to Ronald. Torches. Want to fry the whole goddamn world. But the fires that killed those guys never really burned up much. -- The burns were all lit in outlets surrounded by double firebreaks in the walls. And he made his burns backdrafts.\\nBRIAN: But he killed these guys.\\nSHADOW: But he could have killed everybody there. The firebreaks kept it from spreading in the wall. The backdraft blew out the flame. That's it. That's the reason.\\nBRIAN: What reason?\\nSHADOW: Why backdrafts. Whoever fried Seagrave and Cosgrove went to a helluva lot of trouble to make sure they died by fire, but also made sure the fire blew itself out.\\nBRIAN: That's why the sealant on the doors... So what have we got, a torch with a conscience?\\nSHADOW: No, we have a stone killer trying to make a point.\\nBRIAN: Are you going public with this?\\n\\n\", 'answer': \"No. Do that and I guarantee you'll scare him off. I don't want him running away.\", 'gold_tag': 'SHADOW is responsible for guiding and teaching Brian', 'last_speaker': 'SHADOW'}\n",
      "Last word -> SHADOW : \"No. Do that and I guarantee you'll scare him off. I don't want him running away.\"\n",
      "prediction :  I'm going to tell the whole story. I'm going to tell them what we found.\n",
      "Real answer : No. Do that and I guarantee you'll scare him off. I don't want him running away.\n",
      "Bert Score : {'precision': [0.8793367743492126], 'recall': [0.8751701712608337], 'f1': [0.8772485256195068], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11428571428571428, 'rouge2': 0.0, 'rougeL': 0.11428571428571428, 'rougeLsum': 0.11428571428571428}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.955470779500466\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRIAN: Hey boss, Dekom Trust is owned by Pan Illinois... which is majority controlled by Lakeside Dynamics... which is a division of Windy City Ventures... who's partners are... Alan Seagrave, Donald Cosgrove, and Jeffrey Holcomb.\\n\\n\", 'answer': 'Son of a bitch. They knew each other.', 'gold_tag': 'SHADOW is quick at coming to conclusions', 'last_speaker': 'SHADOW'}\n",
      "Last word -> SHADOW : \"Son of a bitch. They knew each other.\"\n",
      "prediction :  I see...\n",
      "Real answer : Son of a bitch. They knew each other.\n",
      "Bert Score : {'precision': [0.8131133317947388], 'recall': [0.8161277770996094], 'f1': [0.8146177530288696], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1395.7884785758715\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRIAN: So Seagrave and Holcomb were accountants...\\nSHADOW: And Cosgrove. Coppers figured he laundered money for the mob before getting into real estate. They weren't very high on Seagrave, either.\\nBRIAN: Nice bunch of guys.\\n\\n\", 'answer': \"Who all ended up wearing candles for faces... Swayzak's up to his ass in this We need to get a look at his files.\", 'gold_tag': \"SHADOW implies a need to immediately investigate Swayzak's files\", 'last_speaker': 'SHADOW'}\n",
      "Last word -> SHADOW : \"Who all ended up wearing candles for faces... Swayzak's up to his ass in this We need to get a look at his files.\"\n",
      "prediction :  They were. And they were all friends.\n",
      "Real answer : Who all ended up wearing candles for faces... Swayzak's up to his ass in this We need to get a look at his files.\n",
      "Bert Score : {'precision': [0.8927237391471863], 'recall': [0.8186064958572388], 'f1': [0.8540601134300232], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0625, 'rouge2': 0.0, 'rougeL': 0.0625, 'rougeLsum': 0.0625}\n",
      "bleu 1/2 : 0.012594669908908207 0.004301898749003176\n",
      "ppl : 84.59819587067068\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHADOW: Well Brian, I guess you can say it's arson now...\\nBRIAN: How ya feeling? Did you pull me out?\\nSHADOW: Yeah.\\nBRIAN: Did I say thanks?\\nSHADOW: No.\\nBRIAN: Just wondering.\\nSHADOW: I hate hospitals. You're so... so goddamn useless...\\nBRIAN: So what do you want me to do?\\n\\n\", 'answer': \"I've been lying here hours... just thinking... We're close... We're not looking in the right place, Brian. This one knows us and we're not looking in the right place...\", 'gold_tag': 'Shadow has been lying and thinking for hours, indicating dedication to solving their case , Shadow shows signs of perseverance and resolve', 'last_speaker': 'SHADOW'}\n",
      "Last word -> SHADOW : \"I've been lying here hours... just thinking... We're close... We're not looking in the right place, Brian. This one knows us and we're not looking in the right place...\"\n",
      "prediction :  I want you to get rid of this.\n",
      "Real answer : I've been lying here hours... just thinking... We're close... We're not looking in the right place, Brian. This one knows us and we're not looking in the right place...\n",
      "Bert Score : {'precision': [0.88897305727005], 'recall': [0.84478759765625], 'f1': [0.8663173317909241], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0975609756097561, 'rouge2': 0.0, 'rougeL': 0.0975609756097561, 'rougeLsum': 0.0975609756097561}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 49.21248006201707\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHADOW: Your brother was a good man.\\nBRIAN: Yeah.\\nSHADOW: Another couple of good men get burned up for their city? Is that how it's going to read? You're the only one that knows.\\nBRIAN: Like it never happened...\\n\\n\", 'answer': 'Want to help me with something?', 'gold_tag': \"SHADOW is in a position to seek BRIAN's help\", 'last_speaker': 'SHADOW'}\n",
      "Last word -> SHADOW : \"Want to help me with something?\"\n",
      "prediction : I don't think so.\n",
      "Real answer : Want to help me with something?\n",
      "Bert Score : {'precision': [0.8217368125915527], 'recall': [0.8051447868347168], 'f1': [0.8133561611175537], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 9.520780760890878\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWEBSTER: All I want is the money, Benedict. Just give me what's mine and you can go back to stealing cars and screwing your best friend's wife. Pack it in, Vince, you're only wasting time -- I don't give a damn about you, just the money -- He's reloaded during this -- moving forward as we... Vince, if you don't cut this horseshit I may have to hurt you.\\n\\n\", 'answer': 'Leave my brother alone!', 'gold_tag': 'JULIUS is protective , JULIUS is protective of his brother', 'last_speaker': 'JULIUS'}\n",
      "Last word -> JULIUS : \"Leave my brother alone!\"\n",
      "prediction :  You're not going to hurt me, you're not going to hurt me, you're not going to hurt me.\n",
      "Real answer : Leave my brother alone!\n",
      "Bert Score : {'precision': [0.8176860809326172], 'recall': [0.8692395091056824], 'f1': [0.8426750302314758], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5.0391321379942635\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWEBSTER: Just exactly who are you?\\nJULIUS: Vincent's twin brother -- we're in this together.\\nWEBSTER: Keep your hands that way.\\n\\n\", 'answer': \"Don't be nervous -- I hate violence and I never carry guns.\", 'gold_tag': 'JULIUS dislikes violence , JULIUS never carries guns', 'last_speaker': 'JULIUS'}\n",
      "Last word -> JULIUS : \"Don't be nervous -- I hate violence and I never carry guns.\"\n",
      "prediction :  I'm not a killer.\n",
      "Real answer : Don't be nervous -- I hate violence and I never carry guns.\n",
      "Bert Score : {'precision': [0.8975461721420288], 'recall': [0.8700239658355713], 'f1': [0.8835708498954773], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 50.982785529565874\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWEBSTER: 'Shakespeare's Collected Works'?... 'The Mind of Confucius'?... 'Advanced Quantum Mechanics'?... What is this shit?\\nJULIUS: I needed something to read on the airplane.\\n\\n\", 'answer': 'Yeah, well your flying days are over...', 'gold_tag': 'WEBSTER implies that JULIUS will not be flying anymore in the foreseeable future', 'last_speaker': 'WEBSTER'}\n",
      "Last word -> WEBSTER : \"Yeah, well your flying days are over...\"\n",
      "prediction :  You're reading 'Advanced Quantum Mechanics' on an airplane?\n",
      "Real answer : Yeah, well your flying days are over...\n",
      "Bert Score : {'precision': [0.8477725982666016], 'recall': [0.8413602113723755], 'f1': [0.8445541858673096], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 36.51530003696693\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKICHIJIRO: After I saw you and Padre Garupe for the first time...I thought...I started to believe...that God might take me back. Because in...in my dreams, the fire was no longer so bright.\\nRODRIGUES: Jesus said, \"Every one therefore that shall confess me before men, I will also confess him before my Father who is in heaven. But he that shall deny me before men, I will also deny him before my Father who is in heaven.\" Do you want me to hear your confession now?\\n\\n', 'answer': 'Bless me, Father, for I have sinned.', 'gold_tag': 'Everyday Language', 'last_speaker': 'KICHIJIRO'}\n",
      "Last word -> KICHIJIRO : \"Bless me, Father, for I have sinned.\"\n",
      "prediction :  I want you to know that I am not afraid. I am not afraid of death. I am not afraid of the fire. I am not afraid of God. I am not afraid of anything.\n",
      "Real answer : Bless me, Father, for I have sinned.\n",
      "Bert Score : {'precision': [0.8232893943786621], 'recall': [0.8551745414733887], 'f1': [0.8389291167259216], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.04761904761904761, 'rouge2': 0.0, 'rougeL': 0.04761904761904761, 'rougeLsum': 0.04761904761904761}\n",
      "bleu 1/2 : 0.028571428571428577 0.009166984970282115\n",
      "ppl : 4.33312522840724\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKICHIJIRO: Why did you come here, Padre? This place is dangerous. Where are you going?\\nRODRIGUES: Nowhere.\\nKICHIJIRO: We must be careful. There’s a price of three hundred pieces of silver for you.\\nRODRIGUES: Three hundred...Judas got only thirty.\\n\\n', 'answer': 'There are Kirishitans in other places. Not far. We can hide there. I will take care of you. Rodrigues says nothing.', 'gold_tag': \"KICHIJIRO is aware of local happenings , KICHIJIRO's association with Padre RODRIGUES\", 'last_speaker': 'KICHIJIRO'}\n",
      "Last word -> KICHIJIRO : \"There are Kirishitans in other places. Not far. We can hide there. I will take care of you. Rodrigues says nothing.\"\n",
      "prediction :  That’s the price for betrayal.\n",
      "Real answer : There are Kirishitans in other places. Not far. We can hide there. I will take care of you. Rodrigues says nothing.\n",
      "Bert Score : {'precision': [0.8522318005561829], 'recall': [0.8507604598999023], 'f1': [0.8514955639839172], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 47.848686211045845\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKICHIJIRO: We won't reach the village today if we can not walk faster. Are you all right, Padre? You seem tired.\\nRODRIGUES: Just...no, I'm all right. Just so thirsty. The fish was so salty.\\nKICHIJIRO: I will find you some water. Keep walking.\\nRODRIGUES: No, that's all right, I...I thirst.\\nKICHIJIRO: Our Lord said that.\\nRODRIGUES: Yes. I mean...I ate so much of that fish. You made me.\\nKICHIJIRO: For strength.\\nRODRIGUES: Lord, hear me. My foot is on the path, but I don't know where it leads. Please, Lord, lead me. Give me Your hand...\\n\\n\", 'answer': 'I am sorry, Padre. I thought something was wrong. But never mind. There is a stream just nearby. You can drink as much as you like.', 'gold_tag': 'KICHIJIRO is attentive and caring', 'last_speaker': 'KICHIJIRO'}\n",
      "Last word -> KICHIJIRO : \"I am sorry, Padre. I thought something was wrong. But never mind. There is a stream just nearby. You can drink as much as you like.\"\n",
      "prediction :  Rodrigues.\n",
      "Real answer : I am sorry, Padre. I thought something was wrong. But never mind. There is a stream just nearby. You can drink as much as you like.\n",
      "Bert Score : {'precision': [0.8392278552055359], 'recall': [0.8326784372329712], 'f1': [0.8359403610229492], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 593.7330375964316\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLARICE: Good afternoon... I wonder if you could help me. I'm looking for Mrs. Lippman's family?\\n\\n\", 'answer': \"They don't live here anymore.\", 'gold_tag': \"Mr. Gumb has knowledge about Mrs. Lippman's family's current residence status , This suggests a familiarity with them or their former residence\", 'last_speaker': 'MR. GUMB'}\n",
      "Last word -> MR. GUMB : \"They don't live here anymore.\"\n",
      "prediction :  Oh, good afternoon... Mrs. Lippman...?\n",
      "Real answer : They don't live here anymore.\n",
      "Bert Score : {'precision': [0.8042540550231934], 'recall': [0.8497492074966431], 'f1': [0.8263759016990662], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 127.19013563243097\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLARICE: Excuse me, but I really do need to talk to you. This was Mrs. Lippman's house. Did you know her?\\n\\n\", 'answer': \"Just briefly. What's the problem, Officer?\", 'gold_tag': 'MR. GUMB had some interaction with Mrs. Lippman , CLARICE is a law enforcement officer, identified as \"Officer\" by MR. GUMB', 'last_speaker': 'MR. GUMB'}\n",
      "Last word -> MR. GUMB : \"Just briefly. What's the problem, Officer?\"\n",
      "prediction :  Yes, I did.\n",
      "Real answer : Just briefly. What's the problem, Officer?\n",
      "Bert Score : {'precision': [0.8686162829399109], 'recall': [0.853958249092102], 'f1': [0.8612249493598938], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 91.42863472794014\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLARICE: I'm investigating the death of Fredrica Bimmel. Who are you, please? Mr. Gordon, did you know Fredrica when she worked for Mrs. Lippman?\\n\\n\", 'answer': \"No. Wait... Was she a great, fat person? I may have seen her, I'm not sure...\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MR. GUMB'}\n",
      "Last word -> MR. GUMB : \"No. Wait... Was she a great, fat person? I may have seen her, I'm not sure...\"\n",
      "prediction :  I'm a private investigator. I'm afraid I can't tell you anything about Fredrica Bimmel.\n",
      "Real answer : No. Wait... Was she a great, fat person? I may have seen her, I'm not sure...\n",
      "Bert Score : {'precision': [0.8477897047996521], 'recall': [0.837706446647644], 'f1': [0.8427179455757141], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23529411764705882, 'rouge2': 0.0625, 'rougeL': 0.17647058823529413, 'rougeLsum': 0.17647058823529413}\n",
      "bleu 1/2 : 0.18575954994646748 0.03519515356891461\n",
      "ppl : 15.334664058864277\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMR. GUMB: Mrs. Lippman had a son, maybe he could help you. I have his card somewhere. Do you mind stepping inside, while I looks for it?\\n\\n', 'answer': 'Thanks.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CLARICE'}\n",
      "Last word -> CLARICE : \"Thanks.\"\n",
      "prediction :  No, I don't mind.\n",
      "Real answer : Thanks.\n",
      "Bert Score : {'precision': [0.8312907218933105], 'recall': [0.938064455986023], 'f1': [0.8814558982849121], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 34.87167317760386\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOLLY (v.o.): We had our bad moments, like any couple. Kit accused me of only being along for the ride,while at times I wished he'd fall in the river and drown, so I could watch.\\nKIT: Take a break. Red... Life of Riley, huh?\\n\\n\", 'answer': 'Mostly. though. we got along fine and stayed in love.', 'gold_tag': 'HOLLY v.o. stays in love , Shared memories between HOLLY v.o. and KIT', 'last_speaker': 'HOLLY (v.o.)'}\n",
      "Last word -> HOLLY (v.o.) : \"Mostly. though. we got along fine and stayed in love.\"\n",
      "prediction :  I've been watching him for a while now. He's so... so...\n",
      "Real answer : Mostly. though. we got along fine and stayed in love.\n",
      "Bert Score : {'precision': [0.8443698883056641], 'recall': [0.8716272115707397], 'f1': [0.8577820062637329], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.092775747342865\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOLLY (v.o.): For days afterward I lived in dread. At times I wished I could fall asleep and be taken off to some magical land, but this never happened.\\n\\n', 'answer': 'Holly!', 'gold_tag': 'Everyday Language', 'last_speaker': 'KIT'}\n",
      "Last word -> KIT : \"Holly!\"\n",
      "prediction :  I'm so sorry, Holly. I wish I could've done something to stop it.\n",
      "Real answer : Holly!\n",
      "Bert Score : {'precision': [0.8101844191551208], 'recall': [0.8310704827308655], 'f1': [0.820494532585144], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 8.972646997360991\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOLLY (v.o.): We needed supplies, so we went to a rich man's house. Kit figured it'd be safer and quicker than shopping in the downtown... A maid came to the door.\\nKIT: Hi, I come to check the meter. My tools are in here. Oh, this Is Holly. She's from Texas.\\nHOLLY (v.o.): Later we found out she was deaf and we hadn't even known it.\\n\\n\", 'answer': 'Excuse me.', 'gold_tag': 'Everyday Language', 'last_speaker': 'KIT'}\n",
      "Last word -> KIT : \"Excuse me.\"\n",
      "prediction :  What do you think?\n",
      "Real answer : Excuse me.\n",
      "Bert Score : {'precision': [0.8067143559455872], 'recall': [0.8231065273284912], 'f1': [0.8148280382156372], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 53.25875838002556\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: You want to try that handgun against this rifle, go ahead.\\n\\n', 'answer': 'Some day you might have to face me without a gun.', 'gold_tag': 'CORBETT believes he could potentially best ERIC in a face-to-face confrontation , The confrontation would be without firearms', 'last_speaker': 'CORBETT'}\n",
      "Last word -> CORBETT : \"Some day you might have to face me without a gun.\"\n",
      "prediction :  I'm not sure. I don't know if I can handle it.\n",
      "Real answer : Some day you might have to face me without a gun.\n",
      "Bert Score : {'precision': [0.8549622893333435], 'recall': [0.8725085258483887], 'f1': [0.8636462688446045], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 9.545193335164205\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: How the hell were they smart enough to find us?\\nCORBETT: Smart? Sure. That's why I'm sitting in this plane and they're down there blowing me kisses. Been driving long?\\nERIC: I needed a pilot's license to take the job here, so I got one in six weeks.\\nCORBETT: That makes the flight more interesting. See the blood? Pack of wolves took down a moose. Greedy, gut-ripping sons of bitches. I'd kill the last wolf on earth, right in front of the President of the U.S. Stinking, cowardly predator, the wolf.\\nERIC: Sounds like professional jealousy.\\n\\n\", 'answer': \"Hunting and trapping was a damn fine life. Me and Mitchell, Bob and LeMalle, we were teams. I'd always go with Mitchell. Good man, Mitchell. I'd let Bob worry about goddamn LeMalle. We'd hire a plane in October. On the way to a dirt airstrip somewhere, we'd drop supplies. We'd land, tell the pilot to come back for us a few days before Christmas.\", 'gold_tag': 'CORBETT has a background in hunting and trapping , CORBETT worked in teams with individuals named Mitchell, Bob, and LeMalle', 'last_speaker': 'CORBETT'}\n",
      "Last word -> CORBETT : \"Hunting and trapping was a damn fine life. Me and Mitchell, Bob and LeMalle, we were teams. I'd always go with Mitchell. Good man, Mitchell. I'd let Bob worry about goddamn LeMalle. We'd hire a plane in October. On the way to a dirt airstrip somewhere, we'd drop supplies. We'd land, tell the pilot to come back for us a few days before Christmas.\"\n",
      "prediction :  I'd kill a wolf in front of the President, you say? I'd kill a wolf in front of the Pope. I'd kill a wolf in front of the devil. I'd kill a wolf in front of a pack of wolves. You know what I'd kill?\n",
      "Real answer : Hunting and trapping was a damn fine life. Me and Mitchell, Bob and LeMalle, we were teams. I'd always go with Mitchell. Good man, Mitchell. I'd let Bob worry about goddamn LeMalle. We'd hire a plane in October. On the way to a dirt airstrip somewhere, we'd drop supplies. We'd land, tell the pilot to come back for us a few days before Christmas.\n",
      "Bert Score : {'precision': [0.8171989321708679], 'recall': [0.8155480027198792], 'f1': [0.8163726925849915], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23529411764705885, 'rouge2': 0.034188034188034185, 'rougeL': 0.16806722689075632, 'rougeLsum': 0.16806722689075632}\n",
      "bleu 1/2 : 0.13111766738155714 0.01397719030631232\n",
      "ppl : 5.400881497464041\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: Stay put!\\nCORBETT: You got the belly to look me in the eye and pull the trigger?\\nERIC: Be no different than shooting a rabid dog. Next time you want to kill yourself, don't include me.\\nCORBETT: I took the odds on getting down in one piece, and I made it. Now we're in my territory.\\nERIC: With light clothing and no supplies, this is nobody's territory.\\nCORBETT: You sound like the tourists. Know-it-alls who read about survival in a magazine. Fuck you. You won't make it off this mountain.\\nERIC: Let's go.\\nCORBETT: I'm not gonna carry you out of here.\\nERIC: That's right. You're not.\\nCORBETT: Look, take these cuffs off. We need to work together.\\n\\n\", 'answer': \"Forget it. Last time I checked the flight plan, we were forty miles northeast of Devil's Cauldron. Southwest is that way. No sense waiting for a goddamn taxi.\", 'gold_tag': 'ERIC referenced a \"flight plan\" , ERIC mentions their current location and direction', 'last_speaker': 'ERIC'}\n",
      "Last word -> ERIC : \"Forget it. Last time I checked the flight plan, we were forty miles northeast of Devil's Cauldron. Southwest is that way. No sense waiting for a goddamn taxi.\"\n",
      "prediction :  You're right. We don't have time for this.\n",
      "Real answer : Forget it. Last time I checked the flight plan, we were forty miles northeast of Devil's Cauldron. Southwest is that way. No sense waiting for a goddamn taxi.\n",
      "Bert Score : {'precision': [0.8746037483215332], 'recall': [0.8430792093276978], 'f1': [0.8585522174835205], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615385, 'rouge2': 0.0, 'rougeL': 0.10256410256410257, 'rougeLsum': 0.10256410256410257}\n",
      "bleu 1/2 : 0.0205212496559747 0.00490551693762291\n",
      "ppl : 12.203668959710392\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: It'll be interesting, trying to build a fire without any wood.\\nCORBETT: Welcome to the environment, Mr. Ecology. Out here, one mistake is all you get. Why in hell you care enough about me to die taking me in?\\n\\n\", 'answer': \"I don't plan on dying.\", 'gold_tag': 'ERIC is determined and confident', 'last_speaker': 'ERIC'}\n",
      "Last word -> ERIC : \"I don't plan on dying.\"\n",
      "prediction :  It was a spur of the moment thing. I didn't think it through.\n",
      "Real answer : I don't plan on dying.\n",
      "Bert Score : {'precision': [0.8732624650001526], 'recall': [0.8867766857147217], 'f1': [0.8799676895141602], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0.07692307692307693 0.025318484177091663\n",
      "ppl : 9.890342169146942\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: We'll stop here, dig out a snow shelter.\\n\\n\", 'answer': \"Snow shelter. Okay. You dig. I'll have a little sit-down. Even in the drifts, this snow's too powdery to make a shelter. When you're done jerking around, reach down the back of my coat.\", 'gold_tag': 'CORBETT is tired and possibly older or less physically fit than ERIC , CORBETT requested to sit while ERIC digs , CORBETT is knowledgeable about snow shelters , CORBETT pointed out that the snow is too powdery to build one', 'last_speaker': 'CORBETT'}\n",
      "Last word -> CORBETT : \"Snow shelter. Okay. You dig. I'll have a little sit-down. Even in the drifts, this snow's too powdery to make a shelter. When you're done jerking around, reach down the back of my coat.\"\n",
      "prediction :  The storm is too powerful. We can't find shelter.\n",
      "Real answer : Snow shelter. Okay. You dig. I'll have a little sit-down. Even in the drifts, this snow's too powdery to make a shelter. When you're done jerking around, reach down the back of my coat.\n",
      "Bert Score : {'precision': [0.888339638710022], 'recall': [0.8391817808151245], 'f1': [0.8630613088607788], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.01381700533824807 0.0032769905483676838\n",
      "ppl : 40.79554419472107\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORBETT: Still quite a hike to Devil's Cauldron. Days. A long stretch to go without sleep, my friend. You can hide behind that pistol for now, but take your eyes off me long enough to sneeze --\\n\\n\", 'answer': '-- Turn around.', 'gold_tag': 'ERIC commands CORBETT to turn around', 'last_speaker': 'ERIC'}\n",
      "Last word -> ERIC : \"-- Turn around.\"\n",
      "prediction :  It's not a pistol, Corbett. It's a rifle. And I'm not hiding behind it. I'm not hiding from you either. I'm just waiting for you to make the next move.\n",
      "Real answer : -- Turn around.\n",
      "Bert Score : {'precision': [0.8279722332954407], 'recall': [0.8575496077537537], 'f1': [0.8425014019012451], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 7.211760770899805\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: We're not sitting here 'til November. There's a cargo plane coming to Devil's Cauldron in four days, and I'm putting you on it.\\nCORBETT: We get wet, we freeze to death in a couple hours.\\nERIC: I've been on ice like this when I was a kid, skating. Spread your weight, keep moving. Go on.\\nCORBETT: Be my guest.\\nERIC: I'm right behind you.\\nCORBETT: Wait 'til I'm across! Most dangerous thing in the world: A regular Joe, in over his head. You trying to prove how tough you are for me, or for yourself?\\nERIC: It wasn't my idea to crash the plane.\\nCORBETT: Let's camp. There's grayling under this ice. I'll snare some for dinner.\\nERIC: We've got another two hours of daylight.\\n\\n\", 'answer': 'Pushing it is flat wrong. All you prove is your ignorance about breaking trail.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CORBETT'}\n",
      "Last word -> CORBETT : \"Pushing it is flat wrong. All you prove is your ignorance about breaking trail.\"\n",
      "prediction :  A couple more days and I'll have a whole mess of 'em. You can go back to the world, and I'll stay here.\n",
      "Real answer : Pushing it is flat wrong. All you prove is your ignorance about breaking trail.\n",
      "Bert Score : {'precision': [0.8351490497589111], 'recall': [0.8434635996818542], 'f1': [0.8392857313156128], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05128205128205128, 'rouge2': 0.0, 'rougeL': 0.05128205128205128, 'rougeLsum': 0.05128205128205128}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.201778388820044\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORBETT: Have to backtrack, find another way down.\\nERIC: Forget it. It would take days.\\n\\n', 'answer': 'Going to be a bit of a challenge with handcuffs on.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CORBETT'}\n",
      "Last word -> CORBETT : \"Going to be a bit of a challenge with handcuffs on.\"\n",
      "prediction :  How far to the next one?\n",
      "Real answer : Going to be a bit of a challenge with handcuffs on.\n",
      "Bert Score : {'precision': [0.8521409034729004], 'recall': [0.8469036221504211], 'f1': [0.8495142459869385], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352942, 'rouge2': 0.0, 'rougeL': 0.11764705882352942, 'rougeLsum': 0.11764705882352942}\n",
      "bleu 1/2 : 0.07243303475117972 0.025091539267089076\n",
      "ppl : 141.93178918212067\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: Too bad we're heading west.\\nCORBETT: There's a snowmobile. Inside a day we could be on the Yukon. I got money there. Remember that five thousand? Make it ten. Be smart. Take it and walk away.\\nERIC: You don't get it, do you? Stop!\\nCORBETT: Nothing personal. Just wanted to see what you'd do. Have to get these wet things off.\\nERIC: You're not going to slow us down! Keep moving!\\n\\n\", 'answer': \"Inside of three hours you'd be dragging my dead carcass.\", 'gold_tag': 'CORBETT predicts that in less than three hours, he could slow them down to the point of death due to his wet clothes', 'last_speaker': 'CORBETT'}\n",
      "Last word -> CORBETT : \"Inside of three hours you'd be dragging my dead carcass.\"\n",
      "prediction :  You don't know the way.\n",
      "Real answer : Inside of three hours you'd be dragging my dead carcass.\n",
      "Bert Score : {'precision': [0.8605458736419678], 'recall': [0.8387426137924194], 'f1': [0.8495043516159058], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352942, 'rouge2': 0.0, 'rougeL': 0.11764705882352942, 'rougeLsum': 0.11764705882352942}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 31.055901969752007\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: Stay awake! You want to go\\nCORBETT: If that means freeze my balls off, no thanks. I'll be okay. Told you I'm fine!\\nERIC: How many do you see?\\nCORBETT: What?! Fuck off. Save yourself.\\nERIC: You don't feel cold?\\nCORBETT: It's a spring day...\\nERIC: Wake up, goddammit! You've got classic hypothermia -- crankiness, fatigue, can't feel your coldness. Worst thing you can do is fade out. One more thing -- this doesn't mean we're going steady. Stay still.\\nCORBETT: Where's my ELT?\\nERIC: Emergency transmitter? All your gear is back at Wilder's.\\nCORBETT: You got one?\\nERIC: It was blown up with the plane.\\nCORBETT: Too bad. We'd be out of here in a few hours.\\nERIC: How? Nobody this far north monitors that frequency until avalanche season. Besides, I'm surprised a tough guy like you uses fancy electronics.\\nCORBETT: I'm surprised a flat-ender like you knows cold-weather remedies.\\nERIC: Read a lot of adventure stories when I was a kid...\\nCORBETT: I'm hungry. Go kill me some dinner.\\nERIC: An appetite. Maybe you won't die after all.\\n\\n\", 'answer': 'Hate to disappoint you.', 'gold_tag': 'CORBETT has a tough, resilient personality and a resistant attitude towards authority', 'last_speaker': 'CORBETT'}\n",
      "Last word -> CORBETT : \"Hate to disappoint you.\"\n",
      "prediction :  I'm serious.\n",
      "Real answer : Hate to disappoint you.\n",
      "Bert Score : {'precision': [0.8706234097480774], 'recall': [0.8632617592811584], 'f1': [0.8669269680976868], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 133.41270904411942\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORBETT: Talk to that good-looking girl of yours?\\nERIC: You broke the radio, remember?\\nCORBETT: I'm sure she's fine. Seemed like a clever kid. You were real resourceful out there. Got me thinking of this perimeter man, froze all his fingers one winter. So he hacked the tips off and sharpened the exposed bones. Gets along better than ever. Yeah, maybe I underestimated you.\\nERIC: I liked you better frozen. You didn't talk so much.\\nCORBETT: You're damn lucky, glimpsing this country before it's ruined, gone for good. You saw wonders you'd only dreamed of. That alone makes you different than the sorry bastards back where you came from, because you have dreamt them. Remember that demon in the gut? Sometimes it's nothing more than wondering if the so-called civilized life has bred the balls and brains out of you. That's what you want out of this, isn't it?\\n\\n\", 'answer': 'All I want want is you in jail --', 'gold_tag': 'ERIC is focused on getting Corbett into jail', 'last_speaker': 'ERIC'}\n",
      "Last word -> ERIC : \"All I want want is you in jail --\"\n",
      "prediction :  You know what I want?\n",
      "Real answer : All I want want is you in jail --\n",
      "Bert Score : {'precision': [0.8299697041511536], 'recall': [0.8372067213058472], 'f1': [0.833572506904602], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4615384615384615, 'rouge2': 0.18181818181818182, 'rougeL': 0.3076923076923077, 'rougeLsum': 0.3076923076923077}\n",
      "bleu 1/2 : 0.08986579282344431 0.03177235575108143\n",
      "ppl : 52.68563472708887\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORBETT: Could've told you no one would help... Maybe you can talk sense into your boyfriend.\\nERIC: Shut up!\\nCORBETT: Either way, you better clear out. I don't want anyone innocent getting harmed.\\n\\n\", 'answer': \"We're moving. Let's go.\", 'gold_tag': \"ERIC had an immediate response to CORBETT's comment\", 'last_speaker': 'ERIC'}\n",
      "Last word -> ERIC : \"We're moving. Let's go.\"\n",
      "prediction :  You're not going to hurt her!\n",
      "Real answer : We're moving. Let's go.\n",
      "Bert Score : {'precision': [0.849565863609314], 'recall': [0.8988299369812012], 'f1': [0.8735038638114929], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 37.44795058394195\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORBETT: They know I'm here. I don't say something, they'll plow this town under. You willing to accept that responsibility?\\nERIC: Say you're okay. Tell them I'll kill you if they rush us.\\n\\n\", 'answer': 'Bob?', 'gold_tag': 'Everyday Language', 'last_speaker': 'CORBETT'}\n",
      "Last word -> CORBETT : \"Bob?\"\n",
      "prediction :  I'm not going to be your messenger. I'm not going to be your hostage. I'm not going to be anything. I'm going to get out of here.\n",
      "Real answer : Bob?\n",
      "Bert Score : {'precision': [0.804736316204071], 'recall': [0.834042489528656], 'f1': [0.8191273808479309], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5.102640948766276\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nERIC: How come you didn't let him shoot me?\\nCORBETT: Like I said, I'd still be up on that mountain, frozen solid, it wasn't for you.\\nERIC: We'll get you to a hospital, soon as we get to Fairbanks.\\nCORBETT: So they can patch me up and put me in a cage? Forget it. Meyerling's right -- I'm a dinosaur. Greedy bastards like him, it's their turn with this land. Put me in the woods, let me live or die on my own. Look down there, tell me what any of this matters. Struggles of men get swallowed by the bigness. Soon there won't be a trace of our troubles... or us.\\n\\n\", 'answer': \"You're wrong. Everything we do leaves its mark. You said it yourself -- there are hundred- year-old footprints in the tundra.\", 'gold_tag': 'ERIC has a more optimistic outlook compared to CORBETT, believing that everything leaves its mark', 'last_speaker': 'ERIC'}\n",
      "Last word -> ERIC : \"You're wrong. Everything we do leaves its mark. You said it yourself -- there are hundred- year-old footprints in the tundra.\"\n",
      "prediction :  I understand.\n",
      "Real answer : You're wrong. Everything we do leaves its mark. You said it yourself -- there are hundred- year-old footprints in the tundra.\n",
      "Bert Score : {'precision': [0.8863813877105713], 'recall': [0.8394219875335693], 'f1': [0.8622627854347229], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 524.1272433307118\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMITCHELL: Accident Investigation. Detective Mitchell.\\nLISA: Hi, my name-is Lisa Cohen. I was a witness in a bus accident case a few weeks ago...\\nMITCHELL: Yeah, hi, Lisa, what can I do for you?\\nLISA: Well, this is probably gonna sound a little weird, but are you allowed to tell me how to get in touch with that woman's family? I'm obviously probably too late to go to the funeral, but I really wanted to send some flowers or something.\\nMITCHELL: Yeah, I can --\\nLISA: Or is that like classified information?\\nMITCHELL: No no. Family's been notified...Lemme see what I got.\\nLISA: She mentioned she had a daughter...\\nMITCHELL: Lemme just... OK: I don't have anything for a daughter. The only contact I have is a cousin, Abigail Berwitz. I got a number in Arizona...\\nLISA: So did you have the trial, or whatever? Or did you make the -- did they have a ruling yet?\\nMITCHELL: Yes. It was, uh, No Criminality found. OK?\\nLISA: No Criminality.\\nMITCHELL: Right.\\nLISA: Wow. That's a -- great system you got. OK. Wow.\\nMITCHELL: OK?\\n\\n\", 'answer': 'Yeah.', 'gold_tag': 'Everyday Language', 'last_speaker': 'LISA'}\n",
      "Last word -> LISA : \"Yeah.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : Yeah.\n",
      "Bert Score : {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 1.0, 'rouge2': 0.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
      "bleu 1/2 : 1.0 0.316227766016838\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMITCHELL: So now you're sayin' he ran the light.\\nLISA: Yes. He wasn't even looking at the road. And I was definitely trying to get his attention...\\nMITCHELL: No, I get the picture. So you're flirtin' with this guy, he's wavin' at you, he runs the light, hits the decedent, she dies on the scene...the both of youse lie to me on both of your statements, and then somewheres in there you turn around, decide the guy belongs in jail. That right? That about right?\\nLISA: I don't have any control over if he goes to jail or not. I certainly have my hopes. I just want to set the record straight, so that if he gets away with this I won't have been a part of it.\\nMITCHELL: And what do you think I should do with you? Just gimme•a clue. 'cause I'm just a little bit lost over here...:\\nLISA: Do whatever you want. I know what I did.\\nMITCHELL: OK. Well. Before we do anything, Lisa, anybody will tell you that just because he ran a red light is not a criminal offence.\\nLISA: Even if he kills someone?\\nMITCHELL: Even if you cause an accidental death, that's right. For this to be a criminal offense, the law says you need two aggravating circumstances. Like he ran a red light and he was speeding. Or he ran a red light and he was --\\nLISA: So he's not liable to be prosecuted for manslaughter? Or second degree murder?\\nMITCHELL: No. He could be charged with reckless driving, and fillip' out a false police report. Which, that's no joke --\\nLISA: That's unbelievable! What does he have to do? Kill her on purpose?\\nMITCHELL: Yes. Because that's the definition of murder. Killin' somebody on purpose. You're not sayin' he ran her over on purpose, are you?\\nLISA: No.\\nMITCHELL: All, right, look. Lemme take another statement, and, uh...We'11 look into it,\\nLISA: You're kidding.\\nMITCHELL: No. I'll go over it with my sergeant, probably pull this guy in again. Reinterview him. Put a little pressure on him. See what he says.\\n\\n\", 'answer': 'Thank you...! Thank you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'LISA'}\n",
      "Last word -> LISA : \"Thank you...! Thank you.\"\n",
      "prediction :  Fine. But you're not going to do anything about it?\n",
      "Real answer : Thank you...! Thank you.\n",
      "Bert Score : {'precision': [0.8364334106445312], 'recall': [0.8419227600097656], 'f1': [0.8391690850257874], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.493012774721834\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMITCHELL: Detective Mitchell.\\nLISA: Oh, hi, it's Lisa Cohen calling.\\nMITCHELL: Hi Lisa, what can I do for you?\\nLISA: Well, I was just wondering what ever happened, if anything, with the case. You said you might re-interview the bus driver...\\nMITCHELL: Yes, we did:.We brought him back in --\\nLISA: You did? What happened?\\nMITCHELL: Well, he basically stuck to his original representation, and that was pretty much it. I brought it up with my sergeant, but he agrees with me we still don't have enough to charge this guy, so there's really not a lot more we can do at this point.\\nLISA: But how did you ask the questions?\\nMITCHELL: Excuse me?\\nLISA: He's obviously not gonna change his statement if you just ask him like really politely: Why would he? We already know he's a liar.\\nMITCHELL: Hey, you know, Lisa, in the old days we'd just throw him in the back with a rubber hose and we'd get whatever answer we want out of him. But fortunately we don't do that kind of thing anymore --\\nLISA: Yeah, not to white people.\\nMITCHELL: Excuse me?\\nLISA: You don't do it to white people. Anyway, I'm not saying you --\\nMITCHELL: We don't do it to who?\\nLISA: Oh my God...\\nMITCHELL: First of all, I don't know why you're bringin' the guy's race into it. There's forty thousand cops in this city --\\nLISA: Yes, thank you, yes.\\nMITCHELL: -- and I hate to disillusion you, but most of 'em are pretty good guys, just tryin' to do their job. Bottom line is the DA's not gonna take this case. (Pause) Now you could talk to my sergeant if you want to, but --\\n\\n\", 'answer': 'Yes, I would.', 'gold_tag': 'Everyday Language', 'last_speaker': 'LISA'}\n",
      "Last word -> LISA : \"Yes, I would.\"\n",
      "prediction :  No, I think I'll just stick to my story.\n",
      "Real answer : Yes, I would.\n",
      "Bert Score : {'precision': [0.8582735061645508], 'recall': [0.9172273278236389], 'f1': [0.8867716789245605], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0.11111111111111109 0.03726779962499649\n",
      "ppl : 24.229636493010887\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRISTY: A convent? They put me in a convent? What's the problem? Wasn't there any more room in Hell?\\nMOTHER SUPERIOR: What is your full name? Your Christian name?\\nCHRISTY: Mother Theresa. Gandhi. Don't you understand? This is all a mistake. I'm the good guy. I'm the witness. And I'm being punished!\\nMOTHER SUPERIOR: Your name?\\nCHRISTY: Christy. Christy Van Cartier.\\nMOTHER SUPERIOR: Enough joking.\\nCHRISTY: That's my real name! Currently I'm a singer. Sort of.\\nMOTHER SUPERIOR: Very well.\\nCHRISTY: Oh my God. This isn't happening, tell me this isn't happening. It's a nightmare, I'm back at St. Anne's!\\nMOTHER SUPERIOR: St. Anne's?\\nCHRISTY: Parochial school. Akron. St. Android's.\\nMOTHER SUPERIOR: You were unhappy?\\nCHRISTY: I was expelled! When I was fifteen?\\nMOTHER SUPERIOR: The reason?\\nCHRISTY: Beats me! What do you think? Smoking! Heavy petting, without a chaperone. Heavy petting, with the chaperone. And wearing a black bra, under my uniform. The demon bra. You see? You see? I have to get out of here I have to make a phone call. Don't you get it? I'm in a convent! You're a nun!\\nMOTHER SUPERIOR: Sit down.\\nCHRISTY: What?\\nMOTHER SUPERIOR: Sit. Miss Van Cartier.\\nCHRISTY: What?\\nMOTHER SUPERIOR: Your cigarette -- out. It has come to pass.\\nCHRISTY: What?\\nMOTHER SUPERIOR: I joined this convent some thirty years ago. At that time, the world knew some measure of peace. And hope. Our order was a beacon of hospitality, to families, to children, to a neighborhood filled with promise. And, as the years have passed, I have watched that promise destroyed. Drugs. Gangs. so I have made this convent an oasis, a retreat from horror.\\nCHRISTY: Are you talking about me?\\nMOTHER SUPERIOR: And all those like you.\\nCHRISTY: You mean black people?\\nMOTHER SUPERIOR: Absolutely not. I mean the wicked. The heedless. And their Las Vegas concubines.\\nCHRISTY: What's a concubine?\\nMOTHER SUPERIOR: Check your driver's license.\\nCHRISTY: Fine. Got it. Look, the way I see it, I'm stuck here, right? I mean, I'm here or I'm target practice. So here's the deal -- I don't bug you, you don't bug me. I'll catch up on some sleep, watch some tube, lay back and lay low. So just get me a key and show me to my room, and do not disturb. Capisce?\\nMOTHER SUPERIOR: Of course. But it's almost lunch.\\nCHRISTY: Cool. Is there a menu? Or buffet?\\nMOTHER SUPERIOR: Before we do, you might like to freshen up. And you'll certainly want to change\\n\\n\", 'answer': 'had on since the night Deal.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CHRISTY'}\n",
      "Last word -> CHRISTY : \"had on since the night Deal.\"\n",
      "prediction :  Oh, yeah! I'll get the hell out of these clothes!\n",
      "Real answer : had on since the night Deal.\n",
      "Bert Score : {'precision': [0.8298960328102112], 'recall': [0.8588535189628601], 'f1': [0.8441265225410461], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352942, 'rouge2': 0.0, 'rougeL': 0.11764705882352942, 'rougeLsum': 0.11764705882352942}\n",
      "bleu 1/2 : 0.10000000000000002 0.03333333333333335\n",
      "ppl : 41.105853086729546\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRISTY: No! No! I can't do this!\\nMOTHER SUPERIOR: Normally dressed, you are a sore thumb, and you endanger us all. While you are here, you will conduct yourself as a nun. Only I shall know who, and what, you truly are. You will not disrupt the convent. You will not influence the Sisters with your colorful street talk. You will draw no attention to yourself in any way.\\nCHRISTY: But look at rites Look at this! I'm a nun! I'm invisible! I'm a penguin!\\nMOTHER SUPERIOR: As of now, and until you leave, you are\\n\\n\", 'answer': 'Mary Clarence? Like a guy? Like a dumb guy?', 'gold_tag': 'Everyday Language', 'last_speaker': 'CHRISTY'}\n",
      "Last word -> CHRISTY : \"Mary Clarence? Like a guy? Like a dumb guy?\"\n",
      "prediction :  What are you doing?\n",
      "Real answer : Mary Clarence? Like a guy? Like a dumb guy?\n",
      "Bert Score : {'precision': [0.8144288063049316], 'recall': [0.8184860944747925], 'f1': [0.8164524435997009], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 72.29521208294543\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOTHER SUPERIOR: Clarence Loyola. There are three vows that every nun must accept. The vow of poverty...\\nCHRISTY: No problem.\\nMOTHER SUPERIOR: The vow of obedience.\\nCHRISTY: Like to who?\\nMOTHER SUPERIOR: And the vow of chastity.\\n\\n', 'answer': \"I'm outta here.\", 'gold_tag': 'CHRISTY indicates a lack of religious conviction or perhaps a more rebellious nature', 'last_speaker': 'CHRISTY'}\n",
      "Last word -> CHRISTY : \"I'm outta here.\"\n",
      "prediction :  What is chastity?\n",
      "Real answer : I'm outta here.\n",
      "Bert Score : {'precision': [0.8470966815948486], 'recall': [0.8451628684997559], 'f1': [0.8461286425590515], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 109.82784024236405\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRISTY: Is this all the food I get?\\nMOTHER SUPERIOR: Yes. Until breakfast.\\nCHRISTY: That's tomorrow! Don't you have any snacks? Machines?\\nMOTHER SUPERIOR: This shall be your cell, Mary Clarence.\\nCHRISTY: My what?\\n\\n\", 'answer': 'Your cell. Your room.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MOTHER SUPERIOR'}\n",
      "Last word -> MOTHER SUPERIOR : \"Your cell. Your room.\"\n",
      "prediction :  Mary Clarence.\n",
      "Real answer : Your cell. Your room.\n",
      "Bert Score : {'precision': [0.8947840929031372], 'recall': [0.886017382144928], 'f1': [0.8903791308403015], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1621.9766099246942\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOTHER SUPERIOR: A balloon and a banana! Tell me, Mary Clarence, what were you thinking?\\nCHRISTY: Those girls were asking questions. They\\'ve got it rough. I wish somebody had talked to me about that stuff when was their age. I wish somebody would talk to me about it now.\\nMOTHER SUPERIOR: This is a convent, not a clinic. We offer moral guidance, not hardware.\\nCHRISTY: Have you been out in those streets? Do you know what those kids are up against? You should help them!\\nMOTHER SUPERIOR: We are nuns. We seek solutions through\\nCHRISTY: Sometimes it\\'s not enough!\\nMOTHER SUPERIOR: You are correct. Sometimes prayer alone cannot help a situation. Such as your own, for example. How do you feel about physical labor?\\nCHRISTY: It never solves anything.\\nMOTHER SUPERIOR: Do your recall the words of Saint Peter, in Ecciesiastes 1:27? He spoke unto a wastrel youth. He said, \"Take up thy task, and know ye the path of contentment.\"\\nCHRISTY: In English?\\n\\n', 'answer': 'How to put it... ah, Of course, Mary Clarence. \"No pain, no gain.\"', 'gold_tag': 'MOTHER SUPERIOR uses religious texts to guide others', 'last_speaker': 'MOTHER SUPERIOR'}\n",
      "Last word -> MOTHER SUPERIOR : \"How to put it... ah, Of course, Mary Clarence. \"No pain, no gain.\"\"\n",
      "prediction : \"In the sweat of thy face shalt thou eat bread, till thou return to the ground, for out of it wast thou taken; for dust thou art, and into dust shalt thou return.\"\n",
      "Real answer : How to put it... ah, Of course, Mary Clarence. \"No pain, no gain.\"\n",
      "Bert Score : {'precision': [0.77170330286026], 'recall': [0.8119957447052002], 'f1': [0.7913370132446289], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13043478260869568, 'rouge2': 0.0, 'rougeL': 0.08695652173913043, 'rougeLsum': 0.08695652173913043}\n",
      "bleu 1/2 : 0.030303030303030304 0.00973123680201904\n",
      "ppl : 2.4259562097881013\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRISTY: I'm sorry, I'm not a weaver!\\nMOTHER SUPERIOR: Months of work, and the loom, absolutely ruined!\\n\\n\", 'answer': \"Look, this isn't my kind of thing! I wasn't cut out to make little tapestries, or knit little sweaters! I don't do that! I'm a star!\", 'gold_tag': 'CHRISTY does not enjoy craft activities such as knitting or making tapestries', 'last_speaker': 'CHRISTY'}\n",
      "Last word -> CHRISTY : \"Look, this isn't my kind of thing! I wasn't cut out to make little tapestries, or knit little sweaters! I don't do that! I'm a star!\"\n",
      "prediction :  I don't know what to say!\n",
      "Real answer : Look, this isn't my kind of thing! I wasn't cut out to make little tapestries, or knit little sweaters! I don't do that! I'm a star!\n",
      "Bert Score : {'precision': [0.8409167528152466], 'recall': [0.815977931022644], 'f1': [0.8282596468925476], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.21621621621621623, 'rouge2': 0.1142857142857143, 'rougeL': 0.16216216216216217, 'rougeLsum': 0.16216216216216217}\n",
      "bleu 1/2 : 0.017836996673626204 0.01128110722110117\n",
      "ppl : 24.194308284866995\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFOLEY: Call everyone in - every car patrol, beat cop, off-duty, too! Pull 'em in, close every street! Now! I'm gonna do what Gordon never could.\\nBLAKE: What's that?\\nFOLEY: I'm gonna take down the Batman.\\n\\n\", 'answer': 'Sir, what about the armed robbers?', 'gold_tag': 'BLAKE is a police officer , BLAKE shows concern for ongoing crimes', 'last_speaker': 'BLAKE'}\n",
      "Last word -> BLAKE : \"Sir, what about the armed robbers?\"\n",
      "prediction :  You can't.\n",
      "Real answer : Sir, what about the armed robbers?\n",
      "Bert Score : {'precision': [0.88153076171875], 'recall': [0.8409599661827087], 'f1': [0.8607674837112427], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 100.9806306171031\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFOLEY: Negative! Stay on the Batman!\\nBLAKE: But he's getting away!\\n\\n\", 'answer': 'Who do you want to catch? Some robber, or the son-of-a-bitch who killed Harvey Dent?', 'gold_tag': \"FOLEY believes Batman is responsible for Harvey Dent's death\", 'last_speaker': 'FOLEY'}\n",
      "Last word -> FOLEY : \"Who do you want to catch? Some robber, or the son-of-a-bitch who killed Harvey Dent?\"\n",
      "prediction :  He's not going to get away.\n",
      "Real answer : Who do you want to catch? Some robber, or the son-of-a-bitch who killed Harvey Dent?\n",
      "Bert Score : {'precision': [0.8502047061920166], 'recall': [0.8385108709335327], 'f1': [0.8443173170089722], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0.037188360024738305 0.012882425802602028\n",
      "ppl : 46.00832573468382\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFOLEY: Foley.\\nBLAKE: It's a trap! Pull everyone out! with explosives - There's a ring around the tunnels - they're gonna blow it and trap the cops underground!\\n\\n\", 'answer': \"Pull out! Pull 'em out!\", 'gold_tag': \"FOLEY is in a position of authority and is quick to act upon receiving critical information , FOLEY has the ability to deploy or withdraw personnel in dangerous situations , FOLEY's temporal information - FOLEY's response to BLAKE's warning indicates that they are in a time-critical situation\", 'last_speaker': 'FOLEY'}\n",
      "Last word -> FOLEY : \"Pull out! Pull 'em out!\"\n",
      "prediction :  I can't get everyone out. We're running out of time.\n",
      "Real answer : Pull out! Pull 'em out!\n",
      "Bert Score : {'precision': [0.8458060026168823], 'recall': [0.8357390761375427], 'f1': [0.8407424092292786], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23529411764705882, 'rouge2': 0.0, 'rougeL': 0.23529411764705882, 'rougeLsum': 0.23529411764705882}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 17.20519728468002\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBLAKE: Foley?\\nFOLEY: Jesus, Blake! Every cop in the city's down in those tunnels!\\n\\n\", 'answer': 'Not every cop...', 'gold_tag': 'Blake is a police officer , Blake and Foley share the experience of being police officers dealing with a crisis in the city', 'last_speaker': 'BLAKE'}\n",
      "Last word -> BLAKE : \"Not every cop...\"\n",
      "prediction :  Get the hostages out. I'll hold them off.\n",
      "Real answer : Not every cop...\n",
      "Bert Score : {'precision': [0.8529037237167358], 'recall': [0.8333367705345154], 'f1': [0.8430067896842957], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 44.54788058831748\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFRANK: Morning, Jim.\\nJIM: Morning.\\n\\n', 'answer': 'Listen, have you got a minute?', 'gold_tag': 'Everyday Language', 'last_speaker': 'FRANK'}\n",
      "Last word -> FRANK : \"Listen, have you got a minute?\"\n",
      "prediction :  How was your trip?\n",
      "Real answer : Listen, have you got a minute?\n",
      "Bert Score : {'precision': [0.8414792418479919], 'recall': [0.8325635194778442], 'f1': [0.8369976878166199], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 117.72574845366975\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFRANK: We lost water pressure three weeks ago. For a while, I thought we'd be okay with the water in the other flats. The cistern and tanks. But it vanishes so quick you wouldn't believe. You drink it, it\\nJIM: They're all empty...\\nFRANK: It hasn't rained in over a week. You can set up a plastic sheet to catch dew and condensation. Trap it somehow. I saw it on TV once and I've been experimenting, but I can't get it to work, and... you don't happen to... You'd never think it. Needing rain so badly... Not in fucking England... Jim, we don't have enough water for\\nJIM: Right.\\n\\n\", 'answer': \"No. It's not what you think.\", 'gold_tag': \"FRANK's comments reveal a sense of frustration and desperation\", 'last_speaker': 'FRANK'}\n",
      "Last word -> FRANK : \"No. It's not what you think.\"\n",
      "prediction :  How long you been here?\n",
      "Real answer : No. It's not what you think.\n",
      "Bert Score : {'precision': [0.8165678977966309], 'recall': [0.849593997001648], 'f1': [0.832753598690033], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.1637461506155964 0.05789300674674099\n",
      "ppl : 125.169164412352\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFRANK: HOLD ON! Fuck.\\nJIM: The world's worst place to get a flat.\\n\\n\", 'answer': \"Agreed. I think we'd better do this quick.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'FRANK'}\n",
      "Last word -> FRANK : \"Agreed. I think we'd better do this quick.\"\n",
      "prediction :  I know. I'm going to get a pump from that gas station.\n",
      "Real answer : Agreed. I think we'd better do this quick.\n",
      "Bert Score : {'precision': [0.8765177130699158], 'recall': [0.8789888620376587], 'f1': [0.8777515292167664], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09090909090909093, 'rouge2': 0.0, 'rougeL': 0.09090909090909093, 'rougeLsum': 0.09090909090909093}\n",
      "bleu 1/2 : 0.08333333333333333 0.027524094128159027\n",
      "ppl : 47.70938076570459\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJIM: Jesus Christ. We're never going to be able to get out of London.\\n\\n\", 'answer': \"Don't you worry about that. I've sat twenty years in this seat. I've got my routes.\", 'gold_tag': \"FRANK has been in the same job for twenty years , FRANK mentions routes , FRANK's job is likely as a bus or taxi driver\", 'last_speaker': 'FRANK'}\n",
      "Last word -> FRANK : \"Don't you worry about that. I've sat twenty years in this seat. I've got my routes.\"\n",
      "prediction :  I know. It's a nightmare.\n",
      "Real answer : Don't you worry about that. I've sat twenty years in this seat. I've got my routes.\n",
      "Bert Score : {'precision': [0.8993661403656006], 'recall': [0.8524078726768494], 'f1': [0.8752576112747192], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.74834618349147\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFRANK: Hey.\\nJIM: What...\\nFRANK: Shh. You're having a bad dream, that's all.\\n\\n\", 'answer': 'Okay, Dad.', 'gold_tag': 'JIM is possibly Frank\\'s son, as implied by his response \"Okay, Dad\" , FRANK is possibly older , Jim refers to FRANK as \\'Dad\\'', 'last_speaker': 'JIM'}\n",
      "Last word -> JIM : \"Okay, Dad.\"\n",
      "prediction :  I know.\n",
      "Real answer : Okay, Dad.\n",
      "Bert Score : {'precision': [0.9002910256385803], 'recall': [0.8872217535972595], 'f1': [0.8937086462974548], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 663.9337011017111\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJIM: Here you go, Frank. This is how you catch dew. I'm covered in the fucking stuff.\\n\\n\", 'answer': \"Okay. Let's get rolling. If we make good time, we'll be there before midday.\", 'gold_tag': 'FRANK wants to reach their destination before midday', 'last_speaker': 'FRANK'}\n",
      "Last word -> FRANK : \"Okay. Let's get rolling. If we make good time, we'll be there before midday.\"\n",
      "prediction :  That's right.\n",
      "Real answer : Okay. Let's get rolling. If we make good time, we'll be there before midday.\n",
      "Bert Score : {'precision': [0.8708052635192871], 'recall': [0.8420182466506958], 'f1': [0.8561698794364929], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473684, 'rouge2': 0.0, 'rougeL': 0.10526315789473684, 'rougeLsum': 0.10526315789473684}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 65.67370267700424\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTODD: It... grabbed me. It was just like Miss Harmon said. I couldn't believe it. But there it was, the camps, the uniforms, the ...the way they saluted each other. But what am I telling you for? You know more about this stuff than anybody.\\nDUSSANDER: Yes, what are you telling me for?\\nTODD: Then last year I wrote my big term paper on Dachau. I got an A+. It was the only A+ she gave. I mean I always do real well. A's on everything. That's why I'm accelerated.\\nDUSSANDER: Accelerated?\\nTODD: You know, accelerated. I skipped two grades, second and ninth. I didn't need them. That's why I'm already a junior.\\nDUSSANDER: I see...\\n\\n\", 'answer': \"Some kids resent me for it. That's not important. Anyway, my paper really floored my history teacher. I guess because I got through all those books without throwing up. But I learned something. I learned that when you talk about the camps now, you have to remember to sound really disgusted. I mean, you can't just say what happened like the magazines did and leave it at that. If I tried that the teacher would have freaked and called my parents in.\", 'gold_tag': 'TODD wrote an A+ term paper on Dachau , TODD understands the sensitivities of discussing concentration camps and adjusts his tone accordingly', 'last_speaker': 'TODD'}\n",
      "Last word -> TODD : \"Some kids resent me for it. That's not important. Anyway, my paper really floored my history teacher. I guess because I got through all those books without throwing up. But I learned something. I learned that when you talk about the camps now, you have to remember to sound really disgusted. I mean, you can't just say what happened like the magazines did and leave it at that. If I tried that the teacher would have freaked and called my parents in.\"\n",
      "prediction :  Then, last year, I wrote that paper and Miss Harmon said it was so good, so detailed, she was going to publish it in the school paper. But she never did.\n",
      "Real answer : Some kids resent me for it. That's not important. Anyway, my paper really floored my history teacher. I guess because I got through all those books without throwing up. But I learned something. I learned that when you talk about the camps now, you have to remember to sound really disgusted. I mean, you can't just say what happened like the magazines did and leave it at that. If I tried that the teacher would have freaked and called my parents in.\n",
      "Bert Score : {'precision': [0.8615023493766785], 'recall': [0.8386717438697815], 'f1': [0.8499337434768677], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.19130434782608696, 'rouge2': 0.0, 'rougeL': 0.08695652173913043, 'rougeLsum': 0.08695652173913043}\n",
      "bleu 1/2 : 0.04980166045049829 0.005660034116962419\n",
      "ppl : 16.053475976510057\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTODD: I\\'ve never seen anyone drink bourbon with McDonald\\'s before. ...So, How did the stuff get to Patin?\\nDUSSANDER: In railroad cars marked \"Medical Supplies.\" It came in long crates that looked like coffins.\\nTODD: That\\'s fitting. Was it always Zyklon-B?\\nDUSSANDER: No, from time to time we would be sent something else. Experimental gases. The High Command was always interested in improving efficiency. Once they sent us a gas code-named \"Pegasus.\" A nerve gas. Thank God they never sent it again. It...\\nTODD: It what?\\nDUSSANDER: It didn\\'t work very well. It was quite boring.\\nTODD: Bullshit. You\\'re lying. What did it do?\\nDUSSANDER: It killed them. What do you think it did, made them walk on water? It killed them.\\nTODD: Tell me. Tell me.\\nDUSSANDER: I won\\'t. I refuse. Where are my cigarettes?\\nTODD: What did it do?\\nDUSSANDER: It made them dance.\\nTODD: Dance?\\nDUSSANDER: Like Zyklon-B, it came in through the shower heads. After a few seconds the prisoners began to leap about. Some were screaming. Most of them were laughing. They began to vomit and to... to defecate helplessly.\\nTODD: You mean they... they... shit themselves? ...Woah.\\nDUSSANDER: They began to twitch all over and make high, strange sounds in their throats. At last they collapsed and just lay there on the concrete, twitching and yodeling, with blood streaming from their noses. But I lied to you, boy. It didn\\'t kill them. Either because it wasn\\'t strong enough or because we couldn\\'t bring ourselves to wait that long. I suppose it was that. I sent five men in with rifles to end their agonies. These were five men I trusted. It would have looked bad on my record to have wasted so many cartridges at a time when the Fuehrer had declared every cartridge a national resource. I was always given high marks for efficiency.\\nTODD: Yeah, I bet.\\nDUSSANDER: How do you eat this crap everyday?\\nTODD: Why didn\\'t you just do the job yourself? You carried a gun, didn\\'t you?\\nDUSSANDER: I was the commandant of the camp.\\nTODD: So you never killed anybody?\\nDUSSANDER: The entire world was at war, boy. People died.\\nTODD: That\\'s not a real answer. I\\'m asking about you.\\nDUSSANDER: Boy, I was a soldier in a position of power. You don\\'t get to be there by selling ...girl scout\\'s cookies.\\nTODD: I know what the SS was, Dussander. Who are you talking to? It was a bunch of dumb, rich kids who bought their way into the service so they wouldn\\'t have to go fight on the front.\\nDUSSANDER: That\\'s enough for today, boy. I beg you. I\\'m tired.\\n\\n', 'answer': 'Yeah, fine. That was good story though. You always tell them good, once I get you started.', 'gold_tag': 'TODD is interested in war history, particularly the operations of the SS', 'last_speaker': 'TODD'}\n",
      "Last word -> TODD : \"Yeah, fine. That was good story though. You always tell them good, once I get you started.\"\n",
      "prediction :  You're tired?\n",
      "Real answer : Yeah, fine. That was good story though. You always tell them good, once I get you started.\n",
      "Bert Score : {'precision': [0.8287915587425232], 'recall': [0.8211095333099365], 'f1': [0.8249326348304749], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1, 'rouge2': 0.0, 'rougeL': 0.1, 'rougeLsum': 0.1}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 187.7996834485129\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDUSSANDER: What for?\\nTODD: Just to be safe.\\nDUSSANDER: To hell with this. You open it.\\nTODD: Oh, relax, old man. Sit down and open it.\\nDUSSANDER: You wrapped it yourself, I see. Pete's Quality Costume Clothiers - Serving You Since 1976.\\nTODD: Go ahead, try it on.\\nDUSSANDER: Are you out of your mind, boy? What makes you think I would put something like that on?\\nTODD: I thought you'd like it --\\nDUSSANDER: Like it? My God, you're a bigger fool than I thought. Maybe I'll put it on and do a little shopping downtown. Is that what you thought? You stupid, boy. You... You know, you are correct. I am the stupid one. For months I have suffered your indignities. I have exposed my past to you while watching you stuff your face with those wretched hamburgers. I have stocked my refrigerator with Coca Cola and ding dongs. All for you, I have done these things and I'm tired of it. But because I value my life and my freedom, what's left of it anyway, I do them. But I'll die before I put this thing on, you fucking piss-ant.\\nTODD: That's enough. You don't get to talk to me like that.\\nDUSSANDER: I should smash you.\\nTODD: Do it. Please. Indignities? What you've suffered with me is nothing compared to what the Israelis would do to you. Remember what happened to Eichmann? You forget that, I think. And, you know, that's my fault. I have let you forget. You have gotten comfortable with this situation. Well, don't you for one minute ever forget who holds the cards here. Don't you ever forget that envelope under my mattress. I tried to do this the nice way, I tried to do something to please you, but you don't want it. So fine, we'll do it the hard way. You will put this on because I want to see you in it. Now strip.\\n\\n\", 'answer': 'I hope you go to hell --', 'gold_tag': 'DUSSANDER values his freedom and life', 'last_speaker': 'DUSSANDER'}\n",
      "Last word -> DUSSANDER : \"I hope you go to hell --\"\n",
      "prediction :  Fine, you want to do it the hard way? I'll show you how hard it is.\n",
      "Real answer : I hope you go to hell --\n",
      "Bert Score : {'precision': [0.8365993499755859], 'recall': [0.8371803760528564], 'f1': [0.8368897438049316], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2608695652173913, 'rouge2': 0.0, 'rougeL': 0.1739130434782609, 'rougeLsum': 0.1739130434782609}\n",
      "bleu 1/2 : 0.12500000000000003 0.028867513459481287\n",
      "ppl : 12.838243424568434\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTODD: You what?\\nDUSSANDER: I told him you were getting back on track by your own accord. I gave him my word. If you get even one flunk card--\\nTODD: Are you out of your fucking mind? I'm going to get three or four flunk cards. I failed an economics test today, so there's another\\nDUSSANDER: Boy, it was the best I could do without arousing suspicion.\\nTODD: I could have done better myself --\\nDUSSANDER: Well you didn't, did you? This is the way it is and now you are upset because the only way you can make things right is to work.\\nTODD: You're insane. I'm upset because it can't be done.\\nDUSSANDER: It can. And it will. You will work.\\nTODD: I don't take orders from you. Maybe you've forgotten --\\nDUSSANDER: Listen, boy. Before today it was possible, just barely possible, that you could have denounced me and come out clean yourself. The way your nerves have been lately I don't think so, but never mind that. It was - at least technically possible. But now things have changed. Today I impersonated your grandfather, one Victor Bowden. And it was you who arranged the meeting. What would people make of that? If things come out now... perhaps you were right, your age and a good attorney might keep you out of jail, but you would be humiliated, boy, publicly. You would be infamous. Your parents too. Do you know what such a scandal would do to them? To you? Think about that.\\nTODD: You fucker.\\nDUSSANDER: It's a done deal, boy. If you don't like it, you can discuss it at family counselling.\\nTODD: God! I wish... I wish --\\nDUSSANDER: Never mind your wishes. Your wishes make me sick. All I want to hear is that you understand the situation.\\nTODD: Look, you gotta believe me. There is no way in hell that I can pull myself out of a half year slide in a couple of weeks. I wish I could, but we're just going to have to think of something else.\\nDUSSANDER: Boy, the time for discussion is over. This is the way it is. You are going to work. And I am going to be right here with you.\\n\\n\", 'answer': 'What are you talking about?', 'gold_tag': 'Everyday Language', 'last_speaker': 'TODD'}\n",
      "Last word -> TODD : \"What are you talking about?\"\n",
      "prediction :  I can't believe you're doing this to me.\n",
      "Real answer : What are you talking about?\n",
      "Bert Score : {'precision': [0.8205289840698242], 'recall': [0.82357257604599], 'f1': [0.8220478892326355], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 10.868557992769366\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDUSSANDER: Come over right away, boy. I'm having a heart attack, a bad one, I think. I understand that you cannot talk, but you can listen. I cannot call 911... at least not yet. There is quite a mess here. I need help... and that means you need help.\\nTODD: Well if you put it that way --\\nDUSSANDER: Tell your parents I've had a letter, an important letter, and I need you to read it to me.\\nTODD: Yeah, sure. I'll be right there.\\n\\n\", 'answer': 'Now we see what you are made of, boy.', 'gold_tag': \"DUSSANDER's temporal information: DUSSANDER is currently having a heart attack, and there is a mess that he needs cleaned up in his home\", 'last_speaker': 'DUSSANDER'}\n",
      "Last word -> DUSSANDER : \"Now we see what you are made of, boy.\"\n",
      "prediction :  Thank you, boy. I'm so glad.\n",
      "Real answer : Now we see what you are made of, boy.\n",
      "Bert Score : {'precision': [0.8938395380973816], 'recall': [0.8571380376815796], 'f1': [0.8751041889190674], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0.10108844328543891 0.03501806396568503\n",
      "ppl : 36.953289346688535\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDUSSANDER: Hurry up, for God's sake.\\nTODD: Don't you die on me, you old bastard. Not now.\\nDUSSANDER: I think we're okay.\\nTODD: Me too.\\nDUSSANDER: Call an ambulance. What are you talking about? For God's sake, boy...\\nTODD: I want the key and I want to know where the bank is.\\n\\n\", 'answer': 'Hillcrest Savings on Domingo Avenue. The key is behind the clock on the mantle piece.', 'gold_tag': 'DUSSANDER has a key to Hillcrest Savings on Domingo Avenue , DUSSANDER keeps the key hidden behind a clock on the mantle piece', 'last_speaker': 'DUSSANDER'}\n",
      "Last word -> DUSSANDER : \"Hillcrest Savings on Domingo Avenue. The key is behind the clock on the mantle piece.\"\n",
      "prediction :  The bank? You're crazy.\n",
      "Real answer : Hillcrest Savings on Domingo Avenue. The key is behind the clock on the mantle piece.\n",
      "Bert Score : {'precision': [0.8459785580635071], 'recall': [0.8129003047943115], 'f1': [0.8291096687316895], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1, 'rouge2': 0.0, 'rougeL': 0.1, 'rougeLsum': 0.1}\n",
      "bleu 1/2 : 0.015981965301676893 0.005835788605995528\n",
      "ppl : 127.00825819824635\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nINDY: We cannot afford to take mythology at face value. Next week: \"Egyptology.\" Starting with the excavation of Naukratis by Blinders Petrie in 1885. I will be in my office if anybody\\'s got any problems for the next hour and a half. Marcus! I did it!\\nBRODY: You\\'ve got itl\\nINDY: You know how long I\\'ve been looking for that?!\\nBRODY: All your life.\\nINDY: All my life!\\nBRODY: Well done, Indy. Very well done, indeed This will find a place of honor in our Spanish collection.\\nINDY: We can discuss my honorarium over dinner and champagne tonight. Your treat.\\n\\n', 'answer': 'Yes. My treat.', 'gold_tag': 'BRODY is on friendly, celebratory terms with INDY, willing to treat him to dinner and champagne', 'last_speaker': 'BRODY'}\n",
      "Last word -> BRODY : \"Yes. My treat.\"\n",
      "prediction :  You've got a deal.\n",
      "Real answer : Yes. My treat.\n",
      "Bert Score : {'precision': [0.8565621376037598], 'recall': [0.9093359112739563], 'f1': [0.882160484790802], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 51.677086224299856\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nINDY: Dad? He's an academic A bookworm. He's not a field mans Dad? Dad?\\nBRODY: What has the old fool got himself into now?\\nINDY: I don't know. But whatever it is, he's in over his head! Dad?\\nBRODY: It's today's mail. And it's been opened.\\nINDY: Mail! That's it, Marcus! Venice, Italy!\\nBRODY: What is it?\\nINDY: clue he ever followed. Every discovery he made. A complete record of his search for the Holy Grail. This is his whole life. Why would he have sent this to me?\\nBRODY: I don't know. But someone must want it pretty badly.\\nINDY: Do you believe, Marcus? Do you believe the Grail actually exists?\\nBRODY: The search for the Cup of Christ is the search for the divine in all of us. But if you want facts, Indy, I have none to give you. At my age, I'm prepared to take a few things on faith.\\nINDY: Call Donovan, Marcus. Tell him I'll take that ticket to Venice now.\\n\\n\", 'answer': \"I'll tell him we'll take two.\", 'gold_tag': 'BRODY is a collaborator and is willing to accompany INDY on his journey', 'last_speaker': 'BRODY'}\n",
      "Last word -> BRODY : \"I'll tell him we'll take two.\"\n",
      "prediction :  What about the Grail?\n",
      "Real answer : I'll tell him we'll take two.\n",
      "Bert Score : {'precision': [0.8644186854362488], 'recall': [0.8551945686340332], 'f1': [0.8597818613052368], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 197.3604585231934\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nINDY: How\\'s the head?\\nBRODY: It\\'s better, now I\\'ve seen this. It\\'s the name of a city. \"Alexandretta?\" Hmmm...\\nINDY: The Knights of the First Crusade laid siege to the city of Alexandretta for over a year. The entire city was destroyed. The present city of Iskenderun is built on its ruins. Marcus� you remember what the Grail Tablet said. \"Across the desert and through the mountain to the But where exactly?\\nBRODY: Your father would know. Your father did know. Look. He made a map. He must have pieced it together from clues scattered through the whole history of the Grail Quest. Now, he knew there was a city with an oasis due east. Here. He knew the course turned south through the desert to a river, and the river led into the mountains. Here. Straight to the canyon. He knew everything except where to begin, the name of the city.\\nINDY: Alexandretta. Now we know.\\nBRODY: Yes. Now we know.\\nINDY: Marcus, get hold of Sallah. Tell him to meet you in Iskenderun.\\nBRODY: What about you?\\n\\n', 'answer': \"I'm going after Dad.\", 'gold_tag': 'INDY has an immediate plan to pursue his father', 'last_speaker': 'INDY'}\n",
      "Last word -> INDY : \"I'm going after Dad.\"\n",
      "prediction :  I'll go to Alexandretta.\n",
      "Real answer : I'm going after Dad.\n",
      "Bert Score : {'precision': [0.8787780404090881], 'recall': [0.9252586364746094], 'f1': [0.9014196395874023], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20000000000000004, 'rouge2': 0.0, 'rougeL': 0.20000000000000004, 'rougeLsum': 0.20000000000000004}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 123.01225601014305\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRODY: I've got to talk to you.\\nINDY: This isn't really a good time.\\nBRODY: Indy, it's important.\\n\\n\", 'answer': 'All right. Come on in.', 'gold_tag': 'Everyday Language', 'last_speaker': 'INDY'}\n",
      "Last word -> INDY : \"All right. Come on in.\"\n",
      "prediction :  What is it?\n",
      "Real answer : All right. Come on in.\n",
      "Bert Score : {'precision': [0.8289550542831421], 'recall': [0.8660519123077393], 'f1': [0.8470975160598755], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 140.93475091067572\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRODY: They want you to go for it. And they'll pay.\\nINDY: Good work, Marcus. I had a feeling this would happen. And, of course, the Museum gets the Ark when we're done.\\nBRODY: Of course.\\nINDY: Okay, here's the way it's gonna be. First, I'll high-tail it to Shanghai and get the piece from General Hok. Then I think I know where I can find Ravenwood. If only I can get -\\nBRODY: General Hok's a tough customer. They don't call him the Wild Boar for Japanese.\\n\\n\", 'answer': \"I'll worry about that when the time comes. My only hope is to find the Well of the Souls before the Nazis do.\", 'gold_tag': 'INDY is knowledgeable, mentioning the Ark, General Hok, and the Well of Souls', 'last_speaker': 'INDY'}\n",
      "Last word -> INDY : \"I'll worry about that when the time comes. My only hope is to find the Well of the Souls before the Nazis do.\"\n",
      "prediction :  I'm not afraid of him.\n",
      "Real answer : I'll worry about that when the time comes. My only hope is to find the Well of the Souls before the Nazis do.\n",
      "Bert Score : {'precision': [0.891730010509491], 'recall': [0.8600141406059265], 'f1': [0.8755849599838257], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0.005464744489458514 0.0019320789429739668\n",
      "ppl : 48.52977811682073\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELENA: You have a great future as a driver. If they don't arrest you first!!\\nSALVATORE: That's nothing to do with it, it's the car that's still being run in...\\nELENA: SO now how do we get home?\\n\\n\", 'answer': 'Hello, Dr Mendola...Hem...', 'gold_tag': 'SALVATORE is familiar with Dr. Mendola', 'last_speaker': 'SALVATORE'}\n",
      "Last word -> SALVATORE : \"Hello, Dr Mendola...Hem...\"\n",
      "prediction :  I can't drive with this thing on my head.\n",
      "Real answer : Hello, Dr Mendola...Hem...\n",
      "Bert Score : {'precision': [0.8298110961914062], 'recall': [0.8236029148101807], 'f1': [0.8266953825950623], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 25.298167546324294\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSALVATORE: Elena!...But when...\\n\\n', 'answer': \"I got back today. You can't imagine the excuses I had to make up to be here...\", 'gold_tag': 'ELENA has returned today after being away', 'last_speaker': 'ELENA'}\n",
      "Last word -> ELENA : \"I got back today. You can't imagine the excuses I had to make up to be here...\"\n",
      "prediction :  I know. I'm sorry.\n",
      "Real answer : I got back today. You can't imagine the excuses I had to make up to be here...\n",
      "Bert Score : {'precision': [0.8773871660232544], 'recall': [0.8279715776443481], 'f1': [0.8519634008407593], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1739130434782609, 'rouge2': 0.0, 'rougeL': 0.1739130434782609, 'rougeLsum': 0.1739130434782609}\n",
      "bleu 1/2 : 0.009693551957930502 0.003539584713137937\n",
      "ppl : 40.98218205534661\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELENA: So what'd they say?\\nSALVATORE: The army says that, as a war orphan, I don't have to serve in the military, but nothing can be done. It's a bureaucratic error. I have to leave. Day after tomorrow morning. They're sending me to Rome. But they'll discharge me ten days later. Let's go...\\nELENA: No, Salvatore. You'd better go. It's my father.\\nSALVATORE: Good, this way we can finally talk. I'll convince him this time.\\nELENA: He won't be convinced, Salvatore. He has other plans for me.\\nSALVATORE: Who?\\n\\n\", 'answer': \"The son of one of his colleagues. Don't act that way. We'll talk about it later. Wait for me Thursday at the Cinema Paradiso. I'll be coming with the five o'clock bus.\", 'gold_tag': \"ELENA is the daughter of a man , ELENA is expected to meet SALVATORE at the Cinema Paradiso on Thursday , ELENA will arrive with the five o'clock bus\", 'last_speaker': 'ELENA'}\n",
      "Last word -> ELENA : \"The son of one of his colleagues. Don't act that way. We'll talk about it later. Wait for me Thursday at the Cinema Paradiso. I'll be coming with the five o'clock bus.\"\n",
      "prediction :  You'll find out.\n",
      "Real answer : The son of one of his colleagues. Don't act that way. We'll talk about it later. Wait for me Thursday at the Cinema Paradiso. I'll be coming with the five o'clock bus.\n",
      "Bert Score : {'precision': [0.8700824975967407], 'recall': [0.8185603022575378], 'f1': [0.8435354232788086], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.049999999999999996, 'rouge2': 0.0, 'rougeL': 0.049999999999999996, 'rougeLsum': 0.049999999999999996}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 127.65482586599991\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELENA: It's the first time I've had to chance to tell the story. I never mentioned it to anybody.\\nSALVATORE: Alfredo, damn him! He cast his spell on you too!\\n\\n\", 'answer': \"I told him I'd take his advice. But before I went away I left you that note... I was on my way down the stairs... over the...)\", 'gold_tag': 'ELENA is reminiscing about a past event where she left a note for SALVATORE before going away , Shared memories: ELENA and SALVATORE recall a time when ELENA left a note for SALVATORE before going away.', 'last_speaker': 'ELENA'}\n",
      "Last word -> ELENA : \"I told him I'd take his advice. But before I went away I left you that note... I was on my way down the stairs... over the...)\"\n",
      "prediction :  I was 15 when I was kidnapped by Alfredo. He was my abductor.\n",
      "Real answer : I told him I'd take his advice. But before I went away I left you that note... I was on my way down the stairs... over the...)\n",
      "Bert Score : {'precision': [0.8777579069137573], 'recall': [0.8300719261169434], 'f1': [0.8532491326332092], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1951219512195122, 'rouge2': 0.05128205128205128, 'rougeL': 0.1951219512195122, 'rougeLsum': 0.1951219512195122}\n",
      "bleu 1/2 : 0.10481293666382802 0.05454638163932201\n",
      "ppl : 16.865609591750864\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELENA: But you disappeared all the same.\\nSALVATORE: Oh, how I looked for you, Elena! You'll never know. I wrote, telephoned, nothing. Nobody ever answered. But I dreamt of you for years! That's why I went away...and never came back here. filled eyes.) Even as the years passed, in all the women I met, I was only looking for you. I had success it's true, but there was always something missing... I'd never have imagined that all this had to end because of the man who was like a father to me. A crazy lunatic!\\nELENA: He wasn't crazy. In the beginning I was upset. I think I really hated him. But then, with time, I understood what he said...and your\\nSALVATORE: But I never saw that note! I must have covered it with my hand, without realizing it, that's the only explanation...\\n\\n\", 'answer': \"What difference does it make to find an explanation? That's the way it went. But Alfredo didn't betray you, he was the only one who really understood you. Salvatore, if you had chosen to be with me, you'd have never made your films. And that would have been a pity! Because they're wonderful, I've seen them all. But you shouldn't have gone and changed your name. You should have kept your own.\", 'gold_tag': \"ELENA has watched all of Salvatore's films , ELENA appreciates Salvatore's work , SALVATORE changed his name after leaving his hometown\", 'last_speaker': 'ELENA'}\n",
      "Last word -> ELENA : \"What difference does it make to find an explanation? That's the way it went. But Alfredo didn't betray you, he was the only one who really understood you. Salvatore, if you had chosen to be with me, you'd have never made your films. And that would have been a pity! Because they're wonderful, I've seen them all. But you shouldn't have gone and changed your name. You should have kept your own.\"\n",
      "prediction :  I thought you didn't want me, and I'm sorry.\n",
      "Real answer : What difference does it make to find an explanation? That's the way it went. But Alfredo didn't betray you, he was the only one who really understood you. Salvatore, if you had chosen to be with me, you'd have never made your films. And that would have been a pity! Because they're wonderful, I've seen them all. But you shouldn't have gone and changed your name. You should have kept your own.\n",
      "Bert Score : {'precision': [0.8661723136901855], 'recall': [0.8288849592208862], 'f1': [0.8471184968948364], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13483146067415733, 'rouge2': 0.02298850574712644, 'rougeL': 0.11235955056179772, 'rougeLsum': 0.11235955056179772}\n",
      "bleu 1/2 : 0.00040528087357978495 6.796766874786734e-05\n",
      "ppl : 20.065046678146377\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nELENA: When are you leaving?\\nSALVATORE: This afternoon. Elena, in the future maybe we could...\\nELENA: No, Salvatore...there is no future. There's only the past. Even meeting last night was nothing but a dream, a beautiful dream. We never did it when we were kids, remember?\\n\\n\", 'answer': \"I'll never agree with you. Never, Elena.\", 'gold_tag': \"SALVATORE disagrees with Elena's negative viewpoint\", 'last_speaker': 'SALVATORE'}\n",
      "Last word -> SALVATORE : \"I'll never agree with you. Never, Elena.\"\n",
      "prediction :  I remember. But Elena, I've been thinking...\n",
      "Real answer : I'll never agree with you. Never, Elena.\n",
      "Bert Score : {'precision': [0.8551153540611267], 'recall': [0.8721823692321777], 'f1': [0.8635644912719727], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 91.7442943990364\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHAWK: That\\'s your definition of \"Hard?\"\\nALEX: Show off. Hey, boss tune. \"Come Fly with Me.\"\\nHAWK: Three minutes, 51 seconds.\\nALEX: Still do the puzzles, still know the running times of songs, and I\\'ll bet you\\'re still the best damn cat burg--\\nHAWK: Not anymore. Now I\\'m the laziest damn cat burg--I\\'m going to take it so straight that I won\\'t tape a Mets game without the expressed\\nALEX: Now that you\\'re born again,what do you wanna do? Statue of Liberty? Entertain some ladies? Miss Saigon tix? Seduce some chicks?\\nHAWK: Come on, Alex, let\\'s just get to Alex\\'s. Your bar\\'s the only place that\\'s going to cheer me. God, I\\'d kill for a damn cappuccino. What the hell\\'s a Nintendo?\\nALEX: Oh man, you still got a thing for those unmasculine European coffees? Who\\'s your buddy?\\nHAWK: The man knows, the man knows!\\nALEX: So Mr. Coffee, what went down outside the prison?\\nHAWK: Oh, not much. Mario Brothers want me to do a job.\\nALEX: Those dago-guinea-I can say this shit I\\'m Italian-wop motherfu--\\n\\n', 'answer': \"Ah, had the perfect amount of foam. Just get me to the bar... It's the one good thing in my life that'll never change....\", 'gold_tag': \"HAWK values going to Alex's bar\", 'last_speaker': 'HAWK'}\n",
      "Last word -> HAWK : \"Ah, had the perfect amount of foam. Just get me to the bar... It's the one good thing in my life that'll never change....\"\n",
      "prediction :  You're not even Italian.\n",
      "Real answer : Ah, had the perfect amount of foam. Just get me to the bar... It's the one good thing in my life that'll never change....\n",
      "Bert Score : {'precision': [0.8534060716629028], 'recall': [0.8238465189933777], 'f1': [0.8383658528327942], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 131.74395824859693\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALEX: Hmmmm.....\\nHAWK: Yo Pandora, quit hummm-ing... look at this. It\\'s Captain Bob\\'s steering wheel! Remember when the Captain.....\\nALEX: Hmmm, nasty little safe on the 7th.\\nHAWK: The safe\\'s a Simpson 71. Last only had a 40.\\nALEX: Just means it\\'ll take you an extra 31 seconds to seduce. You re still the best, I know it.\\nHAWK: But you got three guards who... Shit, what am I doing? Where\\'s the want ads? Gonna sell some spatulas.\\nALEX: Hey, I\\'m sorry, man. I\\'m putting out a fire with kerosene.\\nHAWK: This isn\\'t funny. I\\'m not into this. I...\\nALEX: There goes five seconds...My record\\'s eighteen.\\nHAWK: You\\'re not...LISTENING! I\\'m sorr--Goddamn Mario Brothers. Goddamn Gates. Goddamn Rutherford Auction House. By the way, how many seconds?\\nALEX: Rutherford Auction... that name...\\nHAWK: Alex!\\nALEX: Don\\'t wet your diapers. I\\'ll have to change them. \"Witchcraft.\" What\\'s the running time?\\nHAWK: 3:48. I can\\'t get you involved, man. This is my sewage and... God, you love all this, don\\'t you, you bastard. Haven\\'t you ever heard of stamp collecting, or curling?\\nALEX: I\\'m in. Have you seen the public service announcements for Diabetes. We can ride horses, play LaCrosse, and knock off auction houses. I got a plan. You won\\'t have to hail Cesar or Gates.\\n\\n', 'answer': \"I'm a bum.\", 'gold_tag': 'HAWK appears frustrated during this conversation', 'last_speaker': 'HAWK'}\n",
      "Last word -> HAWK : \"I'm a bum.\"\n",
      "prediction :  I can't believe this.\n",
      "Real answer : I'm a bum.\n",
      "Bert Score : {'precision': [0.8720954656600952], 'recall': [0.9143131971359253], 'f1': [0.892705500125885], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.22222222222222224, 'rougeLsum': 0.22222222222222224}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 48.56467541620541\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHAWK: Whoa, you better cut a bigger hole than that.\\n\\n', 'answer': \"Hey, you promised......Don't worry, I'm wearing my girdle.\", 'gold_tag': 'ALEX wears a girdle', 'last_speaker': 'ALEX'}\n",
      "Last word -> ALEX : \"Hey, you promised......Don't worry, I'm wearing my girdle.\"\n",
      "prediction :  You’re right.\n",
      "Real answer : Hey, you promised......Don't worry, I'm wearing my girdle.\n",
      "Bert Score : {'precision': [0.8641738295555115], 'recall': [0.820809543132782], 'f1': [0.8419337272644043], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714288, 'rouge2': 0.0, 'rougeL': 0.14285714285714288, 'rougeLsum': 0.14285714285714288}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 114.94260607547194\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHAWK: Cameras?\\n\\n', 'answer': \"No need. Guards' station's right there.\", 'gold_tag': \"ALEX has knowledge about security measures , ALEX is aware of the guards' station's location\", 'last_speaker': 'ALEX'}\n",
      "Last word -> ALEX : \"No need. Guards' station's right there.\"\n",
      "prediction :  I’ve got the best in the business.\n",
      "Real answer : No need. Guards' station's right there.\n",
      "Bert Score : {'precision': [0.868586540222168], 'recall': [0.8719257116317749], 'f1': [0.8702529072761536], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 51.25943312299258\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALEX: They record everything their\\nHAWK: Yes, master-thief, I can see that. You said something about a plan...\\n\\n', 'answer': 'Am I boring you, smartass? Watch. A little rewind and re-wire action and the Guards are going to be watching a rerun and miss out on our exciting episode.', 'gold_tag': \"ALEX is implied to be a master-thief skilled in electronic manipulation , ALEX's language suggests he is confident , ALEX's language suggests he is potentially argumentative or confrontational , ALEX is planning an imminent diversion involving the manipulation of recording systems to distract the guards\", 'last_speaker': 'ALEX'}\n",
      "Last word -> ALEX : \"Am I boring you, smartass? Watch. A little rewind and re-wire action and the Guards are going to be watching a rerun and miss out on our exciting episode.\"\n",
      "prediction :  I'm not sure yet. I'm just trying to get my head around this.\n",
      "Real answer : Am I boring you, smartass? Watch. A little rewind and re-wire action and the Guards are going to be watching a rerun and miss out on our exciting episode.\n",
      "Bert Score : {'precision': [0.8542989492416382], 'recall': [0.8308748006820679], 'f1': [0.8424240350723267], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08888888888888888, 'rouge2': 0.0, 'rougeL': 0.08888888888888888, 'rougeLsum': 0.08888888888888888}\n",
      "bleu 1/2 : 0.022466755668570322 0.007394714572768667\n",
      "ppl : 8.63525731219145\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALEX: You got about five minutes and\\nHAWK: 5:32. \"Swinging on a Star.\"\\nALEX: You know they invented something while you were inside. Called a watch.\\nHAWK: \"A mule is an animal with long funny ears.\"\\n\\n', 'answer': '\"He kicks up at anything he hears.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ALEX'}\n",
      "Last word -> ALEX : \"\"He kicks up at anything he hears.\"\n",
      "prediction :  So what was that?\n",
      "Real answer : \"He kicks up at anything he hears.\n",
      "Bert Score : {'precision': [0.8179162740707397], 'recall': [0.8277130126953125], 'f1': [0.8227854371070862], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 227.99151525297037\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALEX: \"He can\\'t write his name or read a book. To fool people is his only thought.\"\\n\\n', 'answer': '\"And though he\\'s slippery, he still gets caught.\"', 'gold_tag': 'Everyday Language', 'last_speaker': 'HAWK'}\n",
      "Last word -> HAWK : \"\"And though he's slippery, he still gets caught.\"\"\n",
      "prediction :  \"He's got a good heart, Alex.\"\n",
      "Real answer : \"And though he's slippery, he still gets caught.\"\n",
      "Bert Score : {'precision': [0.8935360908508301], 'recall': [0.8951342105865479], 'f1': [0.8943344354629517], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.14285714285714288, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 37.216586362204026\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALEX: The song\\'s over! Come on!\\nHAWK: What am I doing here? There are so many things I wanna do that aren\\'t this. Paint a lighthouse. Kiss a woman in Italy. Paint a woman in a lighthou--I don\\'t want to steal a horse. Life is...\\nALEX: \"You could be swinging on a star.\" You couldn\\'t have waited to see a psychiatrist. No, you had...\\nHAWK: Let\\'s go down the freight elevator.\\n\\n', 'answer': 'Keep those ideas coming.', 'gold_tag': 'ALEX encourages HAWK to focus', 'last_speaker': 'ALEX'}\n",
      "Last word -> ALEX : \"Keep those ideas coming.\"\n",
      "prediction :  What?\n",
      "Real answer : Keep those ideas coming.\n",
      "Bert Score : {'precision': [0.840562105178833], 'recall': [0.832065224647522], 'f1': [0.8362920880317688], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALEX: I'm not as unpleasantly plump as that Guard am I. I got a bad feeling....\\nHAWK: I can't even swim.\\n\\n\", 'answer': \"Hell, the fall'll probably kill ya...\", 'gold_tag': 'ALEX may have an adventurous or risk-taking side', 'last_speaker': 'ALEX'}\n",
      "Last word -> ALEX : \"Hell, the fall'll probably kill ya...\"\n",
      "prediction :  You can't swim?\n",
      "Real answer : Hell, the fall'll probably kill ya...\n",
      "Bert Score : {'precision': [0.8498497605323792], 'recall': [0.833856463432312], 'f1': [0.8417771458625793], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 54.96429686010178\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALEX: Did I miss anything?\\nHAWK: Oh, not much. Gates just had his tonsils taken out. The hard way.\\nALEX: Geez, Gates was killed. Who do we send the thank you note to?\\nHAWK: The Butler did it. Guy was a cross between Alistair Cook and a Cuisinart. Dude took Mr. Ed and humptied dumptied it over Gates\\'s head. He said it was made by, get this, Leonardo..\\nALEX: Ah yes, a rare Renaissance piece. Da Vinci\\'s \"Sforza,\" an equestrian model of a never executed statue. I consider it to be the prize of tonight\\'s auction of objets d\\'equestrian. Horse things.\\nHAWK: Okay, you got me, Mr. PBS.\\nALEX: Morning edition. Seems two thieves \"attempted\" to steal it last night, but thanks to three \"courageous\" guards, it will be ready for tonight.\\nHAWK: \"Attempted.\" At-tempt-ted! I\\'m not happy about having to steal that horse, but I do have my pride. Face it, when it comes to burglary, and sex, I.... Boing. Uh, this I don t understand...\\nALEX: Why try?\\nHAWK: Because I\\'m tired of not understanding things. Cops, Mafia, and butlers forcing me to bust my ass to steal something, which it turns out I really didn\\'t steal--it\\'s fucked up.\\nALEX: You re not thinking of going to...\\n\\n', 'answer': \"Alex, my man, it's time to play a little offense. Where's your tux?\", 'gold_tag': 'HAWK implies that he plans to take some offensive action soon', 'last_speaker': 'HAWK'}\n",
      "Last word -> HAWK : \"Alex, my man, it's time to play a little offense. Where's your tux?\"\n",
      "prediction :  No. No. I think I'm gonna steal the horse.\n",
      "Real answer : Alex, my man, it's time to play a little offense. Where's your tux?\n",
      "Bert Score : {'precision': [0.8944428563117981], 'recall': [0.8596888780593872], 'f1': [0.8767215609550476], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 39.02988448180903\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAM: Rich. Text from Rachel.\\nRICHARD: What does it say?\\n\\n', 'answer': 'It’s kind of personal.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"It’s kind of personal.\"\n",
      "prediction :  She's on her way.\n",
      "Real answer : It’s kind of personal.\n",
      "Bert Score : {'precision': [0.8750289678573608], 'recall': [0.8783607482910156], 'f1': [0.8766916990280151], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20000000000000004, 'rouge2': 0.0, 'rougeL': 0.20000000000000004, 'rougeLsum': 0.20000000000000004}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 57.274165326728244\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRICHARD: Oh, hey.\\nSAM: Hey. Or did you mean, “hay?” (gesturing to the bales) With an A?\\nRICHARD: No. Just, “hey” as in hello. Sam, this is my niece, Sadie. Sadie, Sam. They exchange hellos. Sadie is going to help out around here for a while. I thought you could show her the ropes.\\n\\n', 'answer': 'Yeah. Okay. Cool.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"Yeah. Okay. Cool.\"\n",
      "prediction :  I’m not sure that’s a good idea.\n",
      "Real answer : Yeah. Okay. Cool.\n",
      "Bert Score : {'precision': [0.8363041877746582], 'recall': [0.8880716562271118], 'f1': [0.861410915851593], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.271996104753391\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAM: Sadie’s not coming in?\\nRICHARD: Nah. She’s not feeling too good.\\nSAM: That’s too bad. I need to tell you something, Rich. I was thinking I should talk to Sadie about it first, but then I thought I should just tell you as soon as possible.\\nRICHARD: Okay.\\nSAM: I think Sadie’s in trouble. Yesterday in the bathroom. She was in the stall. And I was at the sink. And we were talking, you know, through the door. But then I realized I could see her through an opening.\\nRICHARD: What?\\nSAM: It’s crazy. I never would have suspected it. She shoots it in her gut. To hide the marks, I guess. What the fuck, Rich? It’s not\\nRICHARD: I’m sorry. I’m sorry. It’s not what you think. She’s fine.\\n\\n', 'answer': 'What do you mean? Fine? She’s got a fucking monkey on her back, man.', 'gold_tag': 'SAM is willing to confront difficult situations', 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"What do you mean? Fine? She’s got a fucking monkey on her back, man.\"\n",
      "prediction :  So she’s not in trouble?\n",
      "Real answer : What do you mean? Fine? She’s got a fucking monkey on her back, man.\n",
      "Bert Score : {'precision': [0.8943422436714172], 'recall': [0.8537521362304688], 'f1': [0.8735759854316711], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.19047619047619044, 'rouge2': 0.10526315789473682, 'rougeL': 0.19047619047619044, 'rougeLsum': 0.19047619047619044}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 145.59534240004325\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEVE: So...Mister Andretti, your first time on the freeway?\\nADAM: It's Webber. Adam Webber.\\nEVE: Mind if I change the station? Better traffic reports on AM.\\nADAM: Wait! Wait!\\nEVE: What is it?!\\nADAM: It's Perry!\\nEVE: Perry?\\nADAM: Perry Como! You had him! Go back! Go back!\\nEVE: Okay, okay! Take it easy! How's that?\\nADAM: Oh, I could die...\\nEVE: Over this?\\nADAM: Yeah! Listen to this part. This is where it really takes off!\\n\\n\", 'answer': 'You are one scary son-of-a-gun.', 'gold_tag': 'Eve is more practical and less passionate about music', 'last_speaker': 'EVE'}\n",
      "Last word -> EVE : \"You are one scary son-of-a-gun.\"\n",
      "prediction :  \n",
      "Real answer : You are one scary son-of-a-gun.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert Score : {'precision': [0.0], 'recall': [0.0], 'f1': [0.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5830.757790976462\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADAM: Hey, what are you doing?!\\n\\n', 'answer': 'I know a short-cut.', 'gold_tag': 'Everyday Language', 'last_speaker': 'EVE'}\n",
      "Last word -> EVE : \"I know a short-cut.\"\n",
      "prediction :  I'm making a necklace.\n",
      "Real answer : I know a short-cut.\n",
      "Bert Score : {'precision': [0.8951449394226074], 'recall': [0.8898839950561523], 'f1': [0.8925066590309143], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4000000000000001, 'rouge2': 0.0, 'rougeL': 0.4000000000000001, 'rougeLsum': 0.4000000000000001}\n",
      "bleu 1/2 : 0.25 0.09128709291752769\n",
      "ppl : 71.17821387203175\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADAM: Gee-zooie!! You better slow down!!!\\n\\n', 'answer': \"I can't help it. Perry Como always does this to me! I just get so cranked!\", 'gold_tag': 'EVE enjoys the music of Perry Como , EVE is an excitable person', 'last_speaker': 'EVE'}\n",
      "Last word -> EVE : \"I can't help it. Perry Como always does this to me! I just get so cranked!\"\n",
      "prediction :  I'm not going to crash.\n",
      "Real answer : I can't help it. Perry Como always does this to me! I just get so cranked!\n",
      "Bert Score : {'precision': [0.8815614581108093], 'recall': [0.8438763618469238], 'f1': [0.8623073101043701], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1739130434782609, 'rouge2': 0.0, 'rougeL': 0.1739130434782609, 'rougeLsum': 0.1739130434782609}\n",
      "bleu 1/2 : 0.022160631672466777 0.007834966465489321\n",
      "ppl : 67.52289440667491\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEVE: Card, please. End of service.\\nADAM: That was...wonderful! I've never felt anything like that in my life.\\nEVE: Yeah, same here. Don't forget your suitcase.\\n\\n\", 'answer': 'Right. You know--', 'gold_tag': 'Everyday Language', 'last_speaker': 'ADAM'}\n",
      "Last word -> ADAM : \"Right. You know--\"\n",
      "prediction :  I won't. Thank you, Eve.\n",
      "Real answer : Right. You know--\n",
      "Bert Score : {'precision': [0.8400062918663025], 'recall': [0.8238376975059509], 'f1': [0.831843376159668], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2222222222222222, 'rouge2': 0.0, 'rougeL': 0.2222222222222222, 'rougeLsum': 0.2222222222222222}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 54.207101197021295\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADAM: I am so glad to see you!! I thought I'd never see you again!\\nEVE: Okay, down boy. (holds up the baseball card) I can't take this for driving you home. I wish I could, but I can't. So here, take it back. I could have just left it for you at the desk, but it's very valuable. Now take it.\\nADAM: I can't, it's yours.\\nEVE: Take it. damn it!\\nADAM: Okay.\\nEVE: Why are you doing that?\\nADAM: I haven't brushed yet.\\nEVE: Oh. Okay. Well, so long. Enjoy your visit.\\nADAM: Wait, Eve, please! Wait.\\n\\n\", 'answer': \"Please don't follow me. Don't do it!\", 'gold_tag': 'EVE is assertive, pragmatic, and independent', 'last_speaker': 'EVE'}\n",
      "Last word -> EVE : \"Please don't follow me. Don't do it!\"\n",
      "prediction :  I'm not coming back. I'm not coming back.\n",
      "Real answer : Please don't follow me. Don't do it!\n",
      "Bert Score : {'precision': [0.8798452019691467], 'recall': [0.8690892457962036], 'f1': [0.8744341135025024], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.07206006251585\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEVE: Why not buy them milk or something-- instead of Dr. Pepper?\\nADAM: They like Dr. Pepper.\\nEVE: Who are these people?\\nADAM: My Mom and Dad.\\nEVE: Very funny, smart ass.\\nADAM: Hey! Pipe tobacco! I'm going to need all of this! This is swell!\\n\\n\", 'answer': 'Swell? Run, Eve. Run.', 'gold_tag': 'EVE is cautious or wary', 'last_speaker': 'EVE'}\n",
      "Last word -> EVE : \"Swell? Run, Eve. Run.\"\n",
      "prediction :  So, they're your Mom and Dad?\n",
      "Real answer : Swell? Run, Eve. Run.\n",
      "Bert Score : {'precision': [0.8062702417373657], 'recall': [0.8324991464614868], 'f1': [0.8191747665405273], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 37.112552671331066\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADAM: Wait! Wait!\\n\\n', 'answer': 'What?', 'gold_tag': 'Everyday Language', 'last_speaker': 'EVE'}\n",
      "Last word -> EVE : \"What?\"\n",
      "prediction :  What?\n",
      "Real answer : What?\n",
      "Bert Score : {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 1.0, 'rouge2': 0.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
      "bleu 1/2 : 1.0 0.316227766016838\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEVE: Well, another day, another dollar. Stop staring at me!!\\nADAM: Sorry.\\nEVE: Pick you up at eight tomorrow morning.\\nADAM: Hey, you know. I was thinking...\\nEVE: Night!\\n\\n', 'answer': 'Night!', 'gold_tag': 'Everyday Language', 'last_speaker': 'ADAM'}\n",
      "Last word -> ADAM : \"Night!\"\n",
      "prediction :  Yeah, about the night.\n",
      "Real answer : Night!\n",
      "Bert Score : {'precision': [0.8730365037918091], 'recall': [0.8702251315116882], 'f1': [0.8716285824775696], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4, 'rouge2': 0.0, 'rougeL': 0.4, 'rougeLsum': 0.4}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 370.7718627995137\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADAM: We'll have to rent a refrigerated truck for the beef and poultry.\\nEVE: It's your life. And, by the way, it's a dandy.\\nADAM: I guess we'll need another locker.\\nEVE: No problem. We'll just sell another baseball card.\\nADAM: You know, Eve -- don't get mad, okay? - - but, I'd just be lost without you.\\nEVE: Thank you.\\nADAM: And, um ...I guess... I guess you and I, uh...\\nEVE: Adam? Don't even think about it. Okay? I'm sorry. I know that sounds mean, but believe me, it would be meaner if I didn't say it. Okay?\\nADAM: Okay.\\n\\n\", 'answer': \"Now, let's take the truck back and get something to eat.\", 'gold_tag': 'EVE is a decision-maker in their shared tasks', 'last_speaker': 'EVE'}\n",
      "Last word -> EVE : \"Now, let's take the truck back and get something to eat.\"\n",
      "prediction :  That's right. So, what do you say we go back to work?\n",
      "Real answer : Now, let's take the truck back and get something to eat.\n",
      "Bert Score : {'precision': [0.8594100475311279], 'recall': [0.8796597123146057], 'f1': [0.8694170713424683], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.24000000000000002, 'rouge2': 0.0, 'rougeL': 0.24000000000000002, 'rougeLsum': 0.24000000000000002}\n",
      "bleu 1/2 : 0.16666666666666669 0.03892494720807617\n",
      "ppl : 16.18100130807043\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADAM: There's something else I would like you to help me with.\\nEVE: Name it.\\nADAM: Well, this is going to sound a little crazy.\\nEVE: Oh, I'm sure it will!\\nADAM: Then forget it.\\nEVE: No, no! I'm sorry! What is it?\\nADAM: This is for me.\\nEVE: Think of me as your genie. Just ask.\\nADAM: Well... Okay. I would like you to help me find a...wife.\\nEVE: A wife?\\nADAM: Yes.\\nEVE: What for?\\nADAM: Because I want to get married.\\nEVE: Why?!\\nADAM: I don't want to be alone.\\nEVE: You can be single and not alone. Marriage bites!\\nADAM: Bites what?\\nEVE: The big one!\\nADAM: It does?\\nEVE: Sure.\\nADAM: I didn't know that.\\nEVE: Everybody knows that. Ask my divorced sisters. Or ask my divorced mom and dad.\\nADAM: They're all divorced?\\nEVE: Everybody's divorced.\\nADAM: It didn't used to be that way.\\nEVE: I wouldn't know. What kind of wife are you looking for?\\nADAM: One who's not a mutant.\\nEVE: No dogs, huh? Okay.\\nADAM: And if possible, I'd like to marry someone from Pasadena.\\nEVE: When do you need her by? Well, I could probably get you laid in two weeks, but to locate a non-mutant wife from Pasadena...that could take some time.\\n\\n\", 'answer': \"That's what I was afraid of.\", 'gold_tag': \"ADAM wants to get married because he doesn't want to be alone and prefers someone from Pasadena who is not a 'mutant'\", 'last_speaker': 'ADAM'}\n",
      "Last word -> ADAM : \"That's what I was afraid of.\"\n",
      "prediction :  Two weeks?\n",
      "Real answer : That's what I was afraid of.\n",
      "Bert Score : {'precision': [0.8470419645309448], 'recall': [0.8467427492141724], 'f1': [0.8468922972679138], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2638.40457946078\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADAM: What do you mean, you can get me laid?\\nEVE: Could we talk about that a little later?\\nADAM: Of course.\\n\\n', 'answer': 'Thank you.', 'gold_tag': 'EVE may be more worldly or experienced', 'last_speaker': 'EVE'}\n",
      "Last word -> EVE : \"Thank you.\"\n",
      "prediction :  I'm just saying, you're not exactly a catch.\n",
      "Real answer : Thank you.\n",
      "Bert Score : {'precision': [0.8316619396209717], 'recall': [0.8989019989967346], 'f1': [0.8639757037162781], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666669, 'rouge2': 0.0, 'rougeL': 0.16666666666666669, 'rougeLsum': 0.16666666666666669}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.88168391471678\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEVE: Get out! Now, get out!!\\nADAM: Yes, ma'am!\\nEVE: Stop that ma'am crap!\\nADAM: Sorry!\\nEVE: You almost got us killed!\\nADAM: I told you I've never driven before!\\nEVE: Never drive again!\\nADAM: You said it would be easy!\\nEVE: I was wrong!!\\nADAM: Is this your house?\\nEVE: Yes!\\nADAM: I like it.\\n\\n\", 'answer': 'Swell!', 'gold_tag': 'Everyday Language', 'last_speaker': 'EVE'}\n",
      "Last word -> EVE : \"Swell!\"\n",
      "prediction :  Do you?\n",
      "Real answer : Swell!\n",
      "Bert Score : {'precision': [0.8597015738487244], 'recall': [0.8138417601585388], 'f1': [0.8361433148384094], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 742.0707716676985\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEVE: He's going to kill himself. Go skate out on the bike path! It's that way!\\n\\n\", 'answer': 'Okay!', 'gold_tag': 'Everyday Language', 'last_speaker': 'ADAM'}\n",
      "Last word -> ADAM : \"Okay!\"\n",
      "prediction :  What?\n",
      "Real answer : Okay!\n",
      "Bert Score : {'precision': [0.9257243871688843], 'recall': [0.9257243871688843], 'f1': [0.9257243871688843], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADAM: Hey, Eve!\\nEVE: Have you ever heard the saying, \"He hasn\\'t got enough sense to come in out of the rain?\"\\nADAM: Yep. You know, my father -- who is a scientist -- says that everything is a miracle. Everything. Until recently I wasn \\'t sure what he meant by that.\\nEVE: Yeah? No kidding. Listen, you still want to go girl hunting tonight?\\nADAM: I certainly do!\\nEVE: Okay. But you know, this business of finding you a wife -- it\\'s kind of ridiculous, don\\'t you think?\\nADAM: No it\\'s not!\\nEVE: Yes it is. A girlfriend maybe. But a wife? I mean...\\nADAM: Then just help me find a girlfriend! That\\'s all I ask. I\\'ll give you every single card I\\'ve got left!\\nEVE: Hey, screw you! Okay? You think I\\'m just somebody you can buy off! Listen, let me tell you something--\\nADAM: Would you do it just because you\\'re my friend? My very best friend.\\nEVE: Well...yeah. Okay.\\n\\n', 'answer': 'Thank Q, Eve!', 'gold_tag': 'Everyday Language', 'last_speaker': 'ADAM'}\n",
      "Last word -> ADAM : \"Thank Q, Eve!\"\n",
      "prediction :  I knew you would!\n",
      "Real answer : Thank Q, Eve!\n",
      "Bert Score : {'precision': [0.8325853943824768], 'recall': [0.8376531600952148], 'f1': [0.8351116180419922], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 269.7232339304676\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADAM: Hi! Eve?!\\nEVE: Scare me, why don't you?!!? You stupid son of a bitch!!!\\nADAM: I'm really sorry!\\nEVE: What in the hell are you doing here!! You're supposed to be over on San Vicente Boulevard having unsafe sex with that slut Sophie!!\\nADAM: I know...and I'm really sorry.\\nEVE: Well, you should be! Thanks to you, my heart is in my neck!\\nADAM: What?\\nEVE: Goodnight!\\nADAM: Eve, if you'll let me, I can --\\nEVE: Look! I'm limping! How attractive is that?! What if this is for life?!\\nADAM: I know first aid!\\n\\n\", 'answer': 'Well, you had better!!', 'gold_tag': 'Everyday Language', 'last_speaker': 'EVE'}\n",
      "Last word -> EVE : \"Well, you had better!!\"\n",
      "prediction :  Go away!\n",
      "Real answer : Well, you had better!!\n",
      "Bert Score : {'precision': [0.8583724498748779], 'recall': [0.8293412327766418], 'f1': [0.8436071872711182], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 853.2523872285642\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEVE: Wait a minute. There.\\nADAM: Thanks. Steady. Steady. It\\'s going to be all right in no time. I went to Sophie\\'s and she was very hospitable.\\nEVE: Is that what you call it?\\nADAM: But it just wasn\\'t where I wanted to be so I left as politely as I could and found a taxi. But I asked the driver to drop me here instead of at the hotel. There\\'s a song Mister Como sings called \"On the Street Where You Live.\" You know it?\\nEVE: Sing it to me.\\nADAM: \"All at once am I--several stories high-- knowing I\\'m--on the street-- where you live.\" It\\'s about a young man who is overjoyed just to be standing in front of the house of the person he loves.\\nEVE: Adam...dumb question, but humor me. Have you ever had sex before?\\nADAM: No.\\nEVE: How is that possible?\\nADAM: In 1962, when the bomb was dropped on Los Angeles, my parents were in our fallout shelter. That\\'s where I was born. We only survived because it was a huge shelter as fallout shelters go. My father worked on it secretly for years. When he had to, he used contractors, but always from out-of- state and always for just a portion of the job. He told them it was a secret government experiment done through CalTech. My Dad\\'s not a liar, but he felt in this case he had no choice. Of course, it had to be a secret, because we had just enough supplies to last three people thirty-five years. That\\'s also why I have no brothers or sisters. The air vent was the really tricky part, but he was able to cut into a flood control sewer. What I\\'d like to do Eve, is take you down into the fallout shelter with me. We could live there with my Mom and Dad. My dad said if I found a healthy girl I should \"bring her on down\". And you look plenty healthy to me.\\nEVE: Uh-huh. Adam?\\nADAM: Yes, Eve?\\nEVE: I want you to go back to the hotel now. I\\'ll call you a cab.\\nADAM: Of course. I shouldn\\'t be over here at this hour.\\nEVE: That\\'s right. And I\\'ll see you in the morning in the lobby. Do you mind waiting outside for the taxi?\\nADAM: Not at all. And Eve thank you for tonight...and for the kiss. My first. It was at least as good as the sky.\\nEVE: Really? Okay!\\nADAM: And I think better than the ocean. I\\'m serious!\\n\\n', 'answer': 'Neat. Goodnight!', 'gold_tag': 'Everyday Language', 'last_speaker': 'EVE'}\n",
      "Last word -> EVE : \"Neat. Goodnight!\"\n",
      "prediction :  Uh-huh.\n",
      "Real answer : Neat. Goodnight!\n",
      "Bert Score : {'precision': [0.823030948638916], 'recall': [0.84466552734375], 'f1': [0.8337079286575317], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 98.24153081040103\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADAM: Eve, I've got to go back! My parents can't handle this up here. And there was no bomb, was there?\\nEVE: No.\\nADAM: See! I can't tell them that! I can't ever let them know. It makes their life..well, frankly... a joke. I can't let that happen. You understand?\\nEVE: We can make this work, Adam! Believe me! I'm very good at making things work!\\n\\n\", 'answer': \"My mother's like that.\", 'gold_tag': \"ADAM compares EVE's problem-solving skills to those of his mother\", 'last_speaker': 'ADAM'}\n",
      "Last word -> ADAM : \"My mother's like that.\"\n",
      "prediction :  I can't.\n",
      "Real answer : My mother's like that.\n",
      "Bert Score : {'precision': [0.889675498008728], 'recall': [0.8703795075416565], 'f1': [0.8799216747283936], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 127.82165926513017\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOUG: So, is this Peter guy Alice is gonna marry rich?\\nPAMELA: Of course. He's one of the Atlas Steel Vanlaninghams. Pittsburgh. He's a bully.\\nDOUG: So how come Alice's marrying him?\\nPAMELA: Because my parents want her to and Alice is afraid of my parents. It's practically an arranged marriage. They think Alice has peanut shells for brains or something, so they sort of suggested that maybe it was time to tie the old knot and they sort of suggested that Peter was the one to do it with.\\nDOUG: Jeez, no one can be that much of a pushover.\\nPAMELA: Look, Alice is the good daughter, Eleanor is the bad one, and I'm the one who sort of gets off the works. Which one are you?\\n\\n\", 'answer': 'You mean, which kind of brother am I? You got me? The little brother, I guess.', 'gold_tag': 'DOUG is the little brother in his family dynamic , DOUG is likely the youngest', 'last_speaker': 'DOUG'}\n",
      "Last word -> DOUG : \"You mean, which kind of brother am I? You got me? The little brother, I guess.\"\n",
      "prediction :  I'm the good one.\n",
      "Real answer : You mean, which kind of brother am I? You got me? The little brother, I guess.\n",
      "Bert Score : {'precision': [0.8881909847259521], 'recall': [0.8456052541732788], 'f1': [0.8663750886917114], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.19047619047619047, 'rouge2': 0.0, 'rougeL': 0.19047619047619047, 'rougeLsum': 0.19047619047619047}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 78.74627418583904\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAMELA: How's your chin?\\nDOUG: Drop dead.\\nPAMELA: You want a ride?\\nDOUG: Nope.\\nPAMELA: You can drive.\\nDOUG: I don't have my license yet.\\n\\n\", 'answer': \"I don't care.\", 'gold_tag': \"PAMELA is not deterred by DOUG's rudeness\", 'last_speaker': 'PAMELA'}\n",
      "Last word -> PAMELA : \"I don't care.\"\n",
      "prediction :  What's your name?\n",
      "Real answer : I don't care.\n",
      "Bert Score : {'precision': [0.7921907901763916], 'recall': [0.8305236101150513], 'f1': [0.8109044432640076], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 43.93340777610096\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAMELA: How come you never ask me out?\\nDOUG: What for?\\nPAMELA: For like a date, block-head.\\nDOUG: I see you all the time.\\nPAMELA: I don't mean hanging out.\\nDOUG: Come on.\\nPAMELA: You scared of me or something?\\nDOUG: Hell, no. I gotta job, I got school, I don't have time for dates and all that stuff.\\nPAMELA: Then forget it.\\nDOUG: It's not like we're... you know... like I'm your boyfriend or...\\n\\n\", 'answer': 'I said forget it, so forget it.', 'gold_tag': 'Everyday Language', 'last_speaker': 'PAMELA'}\n",
      "Last word -> PAMELA : \"I said forget it, so forget it.\"\n",
      "prediction :  Or what?\n",
      "Real answer : I said forget it, so forget it.\n",
      "Bert Score : {'precision': [0.8424826860427856], 'recall': [0.862075924873352], 'f1': [0.8521666526794434], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3251.522985718638\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOUG: Hi.\\nPAMELA: Jesus... what do you want?\\nDOUG: What are you doing tonight? You want to go out?\\nPAMELA: I don't believe you. You're crazy. I'm baby-sitting. My folks went out to dinner with Peter and Alice and I got tricked\\nDOUG: Oh. Where's Eleanor?\\nPAMELA: I thought you came over to ask me out?\\nDOUG: I did.\\nPAMELA: Good, 'cause Eleanor isn't here.\\nDOUG: Can I come in?\\nPAMELA: No.\\nDOUG: Why not?\\nPAMELA: Because, you know, my parents aren't here.\\nDOUG: Well... maybe some other time...\\n\\n\", 'answer': 'Oh, hell. Okay, but just for a little while.', 'gold_tag': 'Everyday Language', 'last_speaker': 'PAMELA'}\n",
      "Last word -> PAMELA : \"Oh, hell. Okay, but just for a little while.\"\n",
      "prediction :  Maybe some other time.\n",
      "Real answer : Oh, hell. Okay, but just for a little while.\n",
      "Bert Score : {'precision': [0.8548577427864075], 'recall': [0.8450228571891785], 'f1': [0.8499118089675903], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 111.87801589039016\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAMELA: You're not like Jacey.\\nDOUG: Why not?\\nPAMELA: He's so... so trig and polished.\\nDOUG: What's 'trig' mean?\\nPAMELA: You know... handsome, sexy, sophisticated. Pipe-smokers.\\nDOUG: Oh. I don't think Jacey smokes a pipe.\\nPAMELA: Well, you don't have to smoke a pipe to be trig.\\nDOUG: Oh.\\nPAMELA: You think I'm... different than Eleanor?\\nDOUG: Sure.\\nPAMELA: Like... how?\\nDOUG: Like... you're smarter.\\nPAMELA: Yeah, real smart, that's why I'm baby-sitting and she's out having fun. Eleanor's smart.\\nDOUG: So how come she flunked biology?\\nPAMELA: Well, you're no Albert Einstein.\\nDOUG: I got a three-point-two average.\\nPAMELA: Doesn't mean you know my sister.\\nDOUG: Oh yeah? You might be surprised.\\nPAMELA: About what? What? What?\\nDOUG: Why are we talking about Eleanor?\\nPAMELA: I didn't bring her up.\\nDOUG: Look, either you're mad at me 'cause you're mad at me -- or you're mad at me 'cause you like me. 'Cause that's how girls act. I don't know much, but I know that. So like which is it?\\n\\n\", 'answer': 'Both. Doug... Do you love me, Doug? Do you? Jesus... Stop it... stop it!', 'gold_tag': 'Everyday Language', 'last_speaker': 'PAMELA'}\n",
      "Last word -> PAMELA : \"Both. Doug... Do you love me, Doug? Do you? Jesus... Stop it... stop it!\"\n",
      "prediction :  I'm not mad at you.\n",
      "Real answer : Both. Doug... Do you love me, Doug? Do you? Jesus... Stop it... stop it!\n",
      "Bert Score : {'precision': [0.8764331936836243], 'recall': [0.8195220232009888], 'f1': [0.8470227122306824], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1, 'rouge2': 0.0, 'rougeL': 0.1, 'rougeLsum': 0.1}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 40.67697674783417\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAMELA: You think you'll finish sometime today? I'm getting sun stroke.\\nDOUG: Put the top up.\\nPAMELA: Stop acting like Jacey. What makes you think you're so... cool?\\nDOUG: Because -- I know all the answers on 'The $64,000 Question,' because I have X-ray vision and I can sing better than Pat Boone. And because I'm really a negro, but don't tell anyone around here, 'cause you know what would happen to me.\\nPAMELA: God, I can't even talk to you. Name one bad thing I've ever done to you.\\nDOUG: Why?\\nPAMELA: Go on, name one bad thing.\\nDOUG: What's the point?\\nPAMELA: You tell me, because I don't get it! Look, I'm not rich, my father is. And I didn't pick my father. And if I had a choice between having tons of money or having another father, I'd be absolutely delighted to be poor! But unfortunately life is not a cafeteria!\\nDOUG: Life is not a cafeteria?\\nPAMELA: You know what I mean!\\nDOUG: Shit, I'm supposed to feel sorry for you 'cause you're rich?\\nPAMELA: Well, am I supposed to feel sorry for you 'cause you're so poor?\\nDOUG: No.\\nPAMELA: So then just stop it!\\nDOUG: Stop what?!\\nPAMELA: Stop treating me like an Abbott!\\nDOUG: Well, how am I supposed to treat you?\\nPAMELA: Like you used to. Like just plain Pam. And you don't have to say you're sorry, and you don't have to look like somebody just ran over your dog. You just make me want to scream sometimes.\\n\\n\", 'answer': 'You.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DOUG'}\n",
      "Last word -> DOUG : \"You.\"\n",
      "prediction :  Pamela, I'm sorry.\n",
      "Real answer : You.\n",
      "Bert Score : {'precision': [0.8146522045135498], 'recall': [0.9203022718429565], 'f1': [0.8642604947090149], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 90.75594154444454\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAMELA: Who do you look like more, your father or your mother?\\nDOUG: Hell, I don't know.\\nPAMELA: Well, what did your father look like?\\nDOUG: Like a photograph. I never knew him. He died like a month before I was even born. Jacey probably looks more like him than I do. Jacey's named after him. That's how he got to be called 'Jacey,' after his initials, John Charles, J.C.\\nPAMELA: He died in a car wreck, right?\\nDOUG: You never heard about that?\\nPAMELA: About what?\\nDOUG: Well, it was sort of a car wreck. He drowned, or froze to death, or both, I don't know. He was trying to drive out to Mud Island.\\nPAMELA: Mud Island's in the middle of the lake.\\nDOUG: It was winter time, the lake was\\nPAMELA: Jesus, that's pretty stupid. Sorry.\\n\\n\", 'answer': \"It's all right, it is stupid. Real stupid. He did it on a bet. He bet someone twenty bucks that he could do it. He made it all the way out there, too. He went through the ice on his way back.\", 'gold_tag': \"DOUG's father died trying to drive to Mud Island on a bet\", 'last_speaker': 'DOUG'}\n",
      "Last word -> DOUG : \"It's all right, it is stupid. Real stupid. He did it on a bet. He bet someone twenty bucks that he could do it. He made it all the way out there, too. He went through the ice on his way back.\"\n",
      "prediction :  It was the middle of winter, and he was driving out to Mud Island on the lake. He was crazy.\n",
      "Real answer : It's all right, it is stupid. Real stupid. He did it on a bet. He bet someone twenty bucks that he could do it. He made it all the way out there, too. He went through the ice on his way back.\n",
      "Bert Score : {'precision': [0.8647304773330688], 'recall': [0.8472616672515869], 'f1': [0.8559069037437439], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222227, 'rouge2': 0.0, 'rougeL': 0.15873015873015872, 'rougeLsum': 0.15873015873015872}\n",
      "bleu 1/2 : 0.09986132510942386 0.013226955632682382\n",
      "ppl : 26.984234821954065\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOUG: I think my dad was like Jacey is. Some guys are just dare-devils. I bet Jacey once that he couldn't do a back-flip off the garage roof did it.\\nPAMELA: One time Eleanor and I snuck out and walked around the yard naked.\\nDOUG: You did?\\nPAMELA: Yeah. It was sort of a dare, too. She dared me, I dared her, so we both did it.\\nDOUG: Was this day or night?\\nPAMELA: Night.\\nDOUG: Was there a full moon?\\nPAMELA: I don't remember.\\nDOUG: You walked around the yard or did you like run from tree to tree?\\nPAMELA: We just walked around the yard.\\nDOUG: Front yard or back yard?\\nPAMELA: Back yard.\\nDOUG: Oh.\\nPAMELA: Does it matter?\\nDOUG: Yeah. Back yard nudity is hypocritical. It's insincere. People should do and say exactly what they feel or think and not try to hide things.\\nPAMELA: Okay.\\nDOUG: Okay.\\nPAMELA: Hi.\\nDOUG: You look pretty.\\nPAMELA: Really?\\n\\n\", 'answer': 'Yup.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DOUG'}\n",
      "Last word -> DOUG : \"Yup.\"\n",
      "prediction :  Yes.\n",
      "Real answer : Yup.\n",
      "Bert Score : {'precision': [0.9590981006622314], 'recall': [0.8916451930999756], 'f1': [0.9241424202919006], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2104.611116571625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAMELA: How long is your mom gone?\\nDOUG: Two weeks. She goes up every summer to see this friend she went to college with.\\nPAMELA: Eleanor lives in Chicago.\\nDOUG: She does?\\nPAMELA: Yeah. She's going to stewardess school.\\nDOUG: What do they teach you at stewardess school?\\nPAMELA: I don't know. How to wiggle your bottom.\\nDOUG: Maybe you should go there instead of Bryn Mawr? Oww! Damn!\\nPAMELA: Sorry.\\nDOUG: Watch it.\\nPAMELA: It was an accident. Don't be crabby.\\nDOUG: You want to... go upstairs?\\nPAMELA: No.\\nDOUG: I just thought maybe you were tired of just kissing?\\nPAMELA: I'm not tired of kissing. Are you?\\nDOUG: No, but touching is nice.\\nPAMELA: We are touching.\\nDOUG: I just... you know... would like to see what you look like without any clothes on.\\nPAMELA: Doug!\\nDOUG: Aren't you curious?\\nPAMELA: No, I know what I look like\\nDOUG: Can I touch your breasts?\\nPAMELA: Jesus.\\nDOUG: Just on the outside?\\nPAMELA: No. You can kiss me. I like lips.\\nDOUG: You like lips?\\nPAMELA: I like your lips, block-head. I like being here like this. But I'm not taking my clothes off, 'cause if we do that, you know what we'll do. And I'm too... I don't want to be like my sisters. Not if I can help it.\\nDOUG: Shit...\\nPAMELA: Who is it?\\nDOUG: My brother. He just went upstairs with your sister.\\nPAMELA: With Eleanor?\\n\\n\", 'answer': 'Alice.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DOUG'}\n",
      "Last word -> DOUG : \"Alice.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : Alice.\n",
      "Bert Score : {'precision': [0.9830650091171265], 'recall': [0.9830650091171265], 'f1': [0.9830650091171265], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOUG: Hey... hold up!\\nPAMELA: Why didn't you tell me?\\nDOUG: Hell, I didn't know. What does this got to do with us? Why is it okay for you to sneak around with me, but it's not all right for Alice to sneak around with Jacey?\\nPAMELA: Because I'm not Alice! And you're not Jacey! Alice is... is like my mom, they both get hurt so easy, they're like turtles without shells.\\nDOUG: Come on, take it easy.\\nPAMELA: You don't know my father. You don't know how he is about Jacey. He blames him for everything that happened with Eleanor.\\nDOUG: Eleanor fooled around with lots of guys, it's not Jacey's fault your dad kicked her out.\\nPAMELA: Oh, Jesus! He didn't kick her out, he put her in a nut house! He shipped her off to this clinic in Wisconsin.\\nDOUG: But... I thought you said she's in Chicago?\\nPAMELA: She is now. They let her out a month ago.\\nDOUG: Oh, shit.\\n\\n\", 'answer': 'Yeah. Shit.', 'gold_tag': 'Everyday Language', 'last_speaker': 'PAMELA'}\n",
      "Last word -> PAMELA : \"Yeah. Shit.\"\n",
      "prediction :  You gotta help me get her out of here.\n",
      "Real answer : Yeah. Shit.\n",
      "Bert Score : {'precision': [0.8409016132354736], 'recall': [0.9090018272399902], 'f1': [0.8736265897750854], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 26.411138380970826\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOUG: Hi.\\nPAMELA: Hi.\\nDOUG: What's up?\\nPAMELA: I've been thinking -- maybe we shouldn't see each other right now.\\nDOUG: Oh, yeah? Why?\\nPAMELA: Well... if my father... I don't really care what would happen to me if he found out I was seeing you, but I have to take care of Alice and my mother and Eleanor, and... well, it would be hard for me to do that if I were in the doghouse, too. You know?\\nDOUG: Christ, why do you have to take care of them?\\nPAMELA: No one else will.\\n\\n\", 'answer': 'Okay. Sure. See you around.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DOUG'}\n",
      "Last word -> DOUG : \"Okay. Sure. See you around.\"\n",
      "prediction :  I don't understand why you have to take care of them.\n",
      "Real answer : Okay. Sure. See you around.\n",
      "Bert Score : {'precision': [0.8363909721374512], 'recall': [0.8834621906280518], 'f1': [0.8592824339866638], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 23.63750497174802\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOUG: Hey! Hey! Pam! Hi.\\nPAMELA: Hi.\\nDOUG: What are you up to?\\nPAMELA: I come down to use the library sometimes or go shopping.\\nDOUG: How's Bryn Mawr?\\nPAMELA: Very... Bryn. I got to catch the bus back.\\nDOUG: Just have to drop off these set designs -- you want to go get something to eat?\\nPAMELA: I can't. Sorry.\\nDOUG: Why not? It's been a long time. And you seem... not so plain. So, dinner, okay?\\nPAMELA: I can't. I have to go to this party.\\nDOUG: What party?\\nPAMELA: Just a party I got roped into going. Maybe some other time, okay? I mean it, really.\\nDOUG: Just call -- I'm at Reed Hall.\\nPAMELA: Okay. Bye.\\n\\n\", 'answer': 'Bye.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DOUG'}\n",
      "Last word -> DOUG : \"Bye.\"\n",
      "prediction :  What's the party?\n",
      "Real answer : Bye.\n",
      "Bert Score : {'precision': [0.8339555263519287], 'recall': [0.9351458549499512], 'f1': [0.8816567063331604], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 132.94905517534784\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOUG: What were you drinking, Sterno?\\nPAMELA: I'm cold...\\n\\n\", 'answer': \"Hold on, we got to get your pants too. Can you stand up. No, you can't stand up. All right. Nope, nope, let's keep the panties on, okay? Pam? Can you hold on to your underpants? I'll hold on to your underpants.\", 'gold_tag': \"DOUG is caring and attentive , DOUG is willing to help PAMELA , DOUG makes decisions and guides PAMELA , DOUG suggests a leadership or protective role towards PAMELA , PAMELA is currently inebriated , PAMELA's inebriation and cold state are temporary\", 'last_speaker': 'DOUG'}\n",
      "Last word -> DOUG : \"Hold on, we got to get your pants too. Can you stand up. No, you can't stand up. All right. Nope, nope, let's keep the panties on, okay? Pam? Can you hold on to your underpants? I'll hold on to your underpants.\"\n",
      "prediction :  I'm cold, too. I'm going to get a blanket.\n",
      "Real answer : Hold on, we got to get your pants too. Can you stand up. No, you can't stand up. All right. Nope, nope, let's keep the panties on, okay? Pam? Can you hold on to your underpants? I'll hold on to your underpants.\n",
      "Bert Score : {'precision': [0.8904643654823303], 'recall': [0.838850200176239], 'f1': [0.8638870120048523], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.037037037037037035, 'rougeL': 0.10714285714285715, 'rougeLsum': 0.10714285714285715}\n",
      "bleu 1/2 : 0.008520511068835796 0.005217726116595956\n",
      "ppl : 14.648851473285553\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOUG: You're welcome.\\nPAMELA: I'm sorry, Doug.\\nDOUG: Shit. That's it? You're sorry?\\nPAMELA: Oh Jesus... did we?\\nDOUG: Oh-Jesus-did-we what?\\nPAMELA: Did we... do it?\\nDOUG: What do you think?\\nPAMELA: I... don't... remember...\\nDOUG: Goddammit. Well, I know you might find this hard to believe, but I don't sleep with drunks.\\n\\n\", 'answer': 'Doug? Hey!', 'gold_tag': 'Everyday Language', 'last_speaker': 'PAMELA'}\n",
      "Last word -> PAMELA : \"Doug? Hey!\"\n",
      "prediction :  I'm sorry.\n",
      "Real answer : Doug? Hey!\n",
      "Bert Score : {'precision': [0.8539171814918518], 'recall': [0.8283578157424927], 'f1': [0.8409432768821716], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 70.196163546962\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAMELA: Doug! Open the window! Come on, I'm freezing. Doug...!\\nDOUG: If you feel like you're gonna puke use the wastebasket there.\\nPAMELA: I'm sorry. I am so sorry. I was embarrassed. I didn't know where I was when I woke up. I felt like I was dying, so, I just... I was going to call you. I don't know... I was blotto. I mean, I was so happy to see you. Then I just got sad. I got sad. And stupid. It happens, you know?\\nDOUG: You want to hear something stupid?\\nPAMELA: What?\\nDOUG: When I was cleaning you up, wiping the puke off your face, I suddenly realized how much I miss you -- how much I love you. How's that for stupid? What are you crying for?\\nPAMELA: I love you. But it's too late.\\nDOUG: Why?\\nPAMELA: Everything's too screwed up.\\nDOUG: No, no, it's not too late. It's perfect timing. We're on our own now. No Jacey and Eleanor or Jacey and Alice. That's what stinks about being the youngest, we have to sweep up after everybody else. But now it's just us. It's our turn.\\nPAMELA: How can you be in love with me?\\nDOUG: How can you be in love with me?\\nPAMELA: 'Cause I've always have been. You... block-head.\\nDOUG: Hi.\\nPAMELA: Hi.\\nDOUG: You want to see something?\\nPAMELA: What?\\n\\n\", 'answer': 'Come on.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DOUG'}\n",
      "Last word -> DOUG : \"Come on.\"\n",
      "prediction :  What we're gonna do.\n",
      "Real answer : Come on.\n",
      "Bert Score : {'precision': [0.8729509115219116], 'recall': [0.9060786366462708], 'f1': [0.8892062902450562], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 86.36000849202841\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAMELA: How can you...?\\nDOUG: How can I what?\\nPAMELA: Ever... forgive me?\\nDOUG: You always loved me no matter what I did, right?\\nPAMELA: Yeah.\\nDOUG: Maybe that's how I love you -- no matter what. That's the best kind of love, you know?\\nPAMELA: But... oh, Jesus... how do we start all over again?\\nDOUG: There. We're doing it.\\nPAMELA: Doing what?\\nDOUG: Starting over. So, what are you doing tonight? You want to go out?\\nPAMELA: You're crazy.\\nDOUG: Some people never change. Hi.\\n\\n\", 'answer': 'Hi.', 'gold_tag': 'Everyday Language', 'last_speaker': 'PAMELA'}\n",
      "Last word -> PAMELA : \"Hi.\"\n",
      "prediction :  Pamela.\n",
      "Real answer : Hi.\n",
      "Bert Score : {'precision': [0.9962084293365479], 'recall': [0.9962084293365479], 'f1': [0.9962084293365479], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1644.1083499941024\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALISON: I...don't think so.\\nMITCHELL: I woke to the sound of Zoe's breathing. It was laboured. I looked over and noticed she was sweating and all swollen. I grabbed\\nALISON: What happened?\\n\\n\", 'answer': \"I didn't know. I was in a panic. I guessed she'd been bitten by an insect, but there was no doctor. The nearest hospital was forty miles I dialed the hospital. I finally got a doctor on the line. He sounded young, but cool. He was confident, but there was a nervousness. He have been an intern. This was the first time he ever had to deal with anything like this. He wanted to seem like he knew what he was doing, but he was just as scared as I was.\", 'gold_tag': \"MITCHELL's quick reaction possibly indicates his caring and responsible nature , The event MITCHELL recounts about Zoe is not recent as he uses past tense to describe it\", 'last_speaker': 'MITCHELL'}\n",
      "Last word -> MITCHELL : \"I didn't know. I was in a panic. I guessed she'd been bitten by an insect, but there was no doctor. The nearest hospital was forty miles I dialed the hospital. I finally got a doctor on the line. He sounded young, but cool. He was confident, but there was a nervousness. He have been an intern. This was the first time he ever had to deal with anything like this. He wanted to seem like he knew what he was doing, but he was just as scared as I was.\"\n",
      "prediction :  I don't know.\n",
      "Real answer : I didn't know. I was in a panic. I guessed she'd been bitten by an insect, but there was no doctor. The nearest hospital was forty miles I dialed the hospital. I finally got a doctor on the line. He sounded young, but cool. He was confident, but there was a nervousness. He have been an intern. This was the first time he ever had to deal with anything like this. He wanted to seem like he knew what he was doing, but he was just as scared as I was.\n",
      "Bert Score : {'precision': [0.9227253794670105], 'recall': [0.8129879236221313], 'f1': [0.8643876910209656], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.061855670103092786, 'rouge2': 0.021052631578947368, 'rougeL': 0.061855670103092786, 'rougeLsum': 0.061855670103092786}\n",
      "bleu 1/2 : 1.2150773866510097e-13 3.327626468915923e-14\n",
      "ppl : 52.19149636039691\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALISON: What happened?\\n\\n', 'answer': \"Nothing. We made it to the hospital. I didn't have to go as far as I was prepared to. But I was prepared to go all the way.\", 'gold_tag': 'MITCHELL recently had to go to the hospital , MITCHELL was prepared to go to a great length , MITCHELL is determined and committed', 'last_speaker': 'MITCHELL'}\n",
      "Last word -> MITCHELL : \"Nothing. We made it to the hospital. I didn't have to go as far as I was prepared to. But I was prepared to go all the way.\"\n",
      "prediction :  They took her away.\n",
      "Real answer : Nothing. We made it to the hospital. I didn't have to go as far as I was prepared to. But I was prepared to go all the way.\n",
      "Bert Score : {'precision': [0.8937629461288452], 'recall': [0.8469134569168091], 'f1': [0.8697077631950378], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 149.72303517184318\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALISON: Well, it was nice meeting you again,\\nMITCHELL: Mitchell. It was nice to see you again, Ally.\\nALISON: Alison.\\nMITCHELL: Alison.\\nALISON: Say hi to Zoe.\\nMITCHELL: I will.\\nALISON: I hope she gets better.\\n\\n', 'answer': \"I'll tell her that.\", 'gold_tag': 'Mitchell has a close relationship with someone named Zoe', 'last_speaker': 'MITCHELL'}\n",
      "Last word -> MITCHELL : \"I'll tell her that.\"\n",
      "prediction :  She will.\n",
      "Real answer : I'll tell her that.\n",
      "Bert Score : {'precision': [0.9299546480178833], 'recall': [0.8712190985679626], 'f1': [0.8996292352676392], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1865.910899946564\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACK: It’s a cop bar.\\nALLY: Cops?\\n\\n', 'answer': \"Yeah. It's why they serve all night long.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'JACK'}\n",
      "Last word -> JACK : \"Yeah. It's why they serve all night long.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : Yeah. It's why they serve all night long.\n",
      "Bert Score : {'precision': [0.9759025573730469], 'recall': [0.8564736247062683], 'f1': [0.9122960567474365], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.19999999999999998, 'rouge2': 0.0, 'rougeL': 0.19999999999999998, 'rougeLsum': 0.19999999999999998}\n",
      "bleu 1/2 : 0.0009118819655545162 0.0002883623968383479\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACK: One time, my brother came home... I was playing on this upright we used to always have in our den. And I was, like, in my own world. And no one was ever home, and he comes home to take care of my dad, who was sick. And he's sitting there, and he's looking at me. And I swear to God, he looked at me like I was special or something, and it just kind of filled me up, and... I should've never told you that. I don't know.\\nALLY: Why?\\nJACK: 'Cause it's embarrassing. I don't know.\\nALLY: It's so sweet.\\nJACK: 'Cause you're nothing like my brother.\\nALLY: Yeah, I don't look like your brother?\\nJACK: He's a fucking old man. My dad had me when he was sixty-three years old.\\nALLY: Sixty-three years old?\\n\\n\", 'answer': 'And we have different mothers, so...', 'gold_tag': \"JACK has an older half-brother from his father's previous relationship\", 'last_speaker': 'JACK'}\n",
      "Last word -> JACK : \"And we have different mothers, so...\"\n",
      "prediction :  Yeah. I mean, he was a good man. He was a good man, and he was a good dad, but... He was old. And he died. And I'm never gonna be like him. I'm never gonna be like my brother. And I don't know how to deal with it.\n",
      "Real answer : And we have different mothers, so...\n",
      "Bert Score : {'precision': [0.8269470930099487], 'recall': [0.8605970740318298], 'f1': [0.843436598777771], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.034482758620689655, 'rouge2': 0.0, 'rougeL': 0.034482758620689655, 'rougeLsum': 0.034482758620689655}\n",
      "bleu 1/2 : 0.020408163265306117 0.006520506636966265\n",
      "ppl : 6.352201804339251\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALLY: Oh, my God. How did you get in here?\\nJACK: Dad, let me in.\\nALLY: What? I don't feel this way about everybody.\\nJACK: Well, good. Then we're on the same page. You come and sing with me.\\nALLY: Where?\\n\\n\", 'answer': \"Well, first stop's Arizona.\", 'gold_tag': \"JACK's plan to go to Arizona is immediate but not specific in terms of timeline\", 'last_speaker': 'JACK'}\n",
      "Last word -> JACK : \"Well, first stop's Arizona.\"\n",
      "prediction :  The bathroom.\n",
      "Real answer : Well, first stop's Arizona.\n",
      "Bert Score : {'precision': [0.9062246084213257], 'recall': [0.8560194969177246], 'f1': [0.88040691614151], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 361.27790561691626\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALLY: I'm never getting on that thing with you when you've been drinking.\\nJACK: I haven't even thought about drinking or anything else.\\n\\n\", 'answer': \"We'll see how long that lasts. Go wait downstairs.\", 'gold_tag': \"ALLY is cautious , ALLY has concerns about safety , Shared memories: ALLY and JACK have had an experience where JACK was drinking and they went on 'that thing' together, which didn't sit well with ALLY.\", 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"We'll see how long that lasts. Go wait downstairs.\"\n",
      "prediction :  I'm serious.\n",
      "Real answer : We'll see how long that lasts. Go wait downstairs.\n",
      "Bert Score : {'precision': [0.8797864317893982], 'recall': [0.8369131088256836], 'f1': [0.857814371585846], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 133.41270904411942\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACK: What are you writing down in here?\\nALLY: That's my songbook. I usually use a typewriter, but... I had this idea on the bike, and I didn't wanna forget it.\\nJACK: How do you hear it?\\nALLY: ‘I’m alone in my house.’ Aren't you excited to be home and play for all your Arizonian fans?\\nJACK: I don't really come back here.\\nALLY: You avoid your home?\\nJACK: I don't know. The hot air and the... history, I don't know. Bought the ranch I grew up on... Gave it to my brother. We buried Dad there... I just wanted to make sure that nobody paved over his grave or any of that kind of shit.\\nALLY: Is it around here?\\nJACK: It's not far.\\n\\n\", 'answer': \"Why don't we just go there? It's\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"Why don't we just go there? It's\"\n",
      "prediction :  Jack?\n",
      "Real answer : Why don't we just go there? It's\n",
      "Bert Score : {'precision': [0.8751025199890137], 'recall': [0.8043757677078247], 'f1': [0.8382498621940613], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 10476.234058474065\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALLY: I've never sang with a track before.\\nJACK: Listen, you know what I think it is -- I think it's because you need your piano. I think if you're playing it and singing it... and then with the rhythm...\\nALLY: I always play it on the piano.\\nJACK: So I'm just gonna have them fly one in, and we'll try it there... and see where it goes.\\nALLY: You think that's okay? Thank you.\\nJACK: I got you. You're doing great. You okay?\\nALLY: No, I'm so nervous.\\nJACK: You look so beautiful.\\n\\n\", 'answer': 'Thank you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"Thank you.\"\n",
      "prediction :  I'm so nervous.\n",
      "Real answer : Thank you.\n",
      "Bert Score : {'precision': [0.8721914291381836], 'recall': [0.8865472078323364], 'f1': [0.8793107271194458], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 60.975648922868196\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACK: Hey, you? Who are you?\\nALLY: Thought we could use some company...\\nJACK: Hey, Charlie! What are we gonna do with you? Oh, he's beautiful! He's got your eyelashes.\\n\\n\", 'answer': \"‘You can't send me back. I'm too cute.’\", 'gold_tag': 'ALLY\\'s line is \"You can\\'t send me back. I\\'m too cute\" , ALLY has a sense of humor', 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"‘You can't send me back. I'm too cute.’\"\n",
      "prediction :  What are you talking about?\n",
      "Real answer : ‘You can't send me back. I'm too cute.’\n",
      "Bert Score : {'precision': [0.8055496215820312], 'recall': [0.8176485300064087], 'f1': [0.8115540146827698], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 58.2916451132753\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACK: This has never been done before, just so you know.\\n\\n', 'answer': 'It actually has been done before.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ALLY'}\n",
      "Last word -> ALLY : \"It actually has been done before.\"\n",
      "prediction :  What’s that?\n",
      "Real answer : It actually has been done before.\n",
      "Bert Score : {'precision': [0.8246322870254517], 'recall': [0.8567391633987427], 'f1': [0.8403791189193726], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 142.01492253440625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACK: It doesn’t do you any justice, I’ll tell you that.\\nALLY: You always said you liked my nose.\\nJACK: I love your nose.\\nALLY: It's real big up there.\\nJACK: I wish it was bigger up there. The whole thing should just be your fucking nose. Fuck all those people who ever said anything. Just put a billboard of your fucking nose up there.\\nALLY: That’s so ridiculous.\\nJACK: Listen, if I just don’t say this, I’ll never forgive myself.\\nALLY: What?\\n\\n\", 'answer': \"If you don't dig deep in your fucking soul... you won't have legs. I'm just telling you that. You don't tell the truth out there, you're fucked. All you got is you, and what you wanna say to people... and they are listening right now, and they're not gonna be listening forever. Trust me. So, you gotta grab it. And you don't apologize, you don't worry about why they're listening... or how long they're gonna be listening for... you just tell 'em what you wanna say. 'Cause how you say it is the stuff of angels.\", 'gold_tag': 'JACK gives advice to ALLY , JACK emphasizes on truth and authenticity , JACK implies the temporal state of public interest', 'last_speaker': 'JACK'}\n",
      "Last word -> JACK : \"If you don't dig deep in your fucking soul... you won't have legs. I'm just telling you that. You don't tell the truth out there, you're fucked. All you got is you, and what you wanna say to people... and they are listening right now, and they're not gonna be listening forever. Trust me. So, you gotta grab it. And you don't apologize, you don't worry about why they're listening... or how long they're gonna be listening for... you just tell 'em what you wanna say. 'Cause how you say it is the stuff of angels.\"\n",
      "prediction : I love you.\n",
      "Real answer : If you don't dig deep in your fucking soul... you won't have legs. I'm just telling you that. You don't tell the truth out there, you're fucked. All you got is you, and what you wanna say to people... and they are listening right now, and they're not gonna be listening forever. Trust me. So, you gotta grab it. And you don't apologize, you don't worry about why they're listening... or how long they're gonna be listening for... you just tell 'em what you wanna say. 'Cause how you say it is the stuff of angels.\n",
      "Bert Score : {'precision': [0.8826720714569092], 'recall': [0.7881964445114136], 'f1': [0.8327633142471313], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.03669724770642202, 'rouge2': 0.0, 'rougeL': 0.03669724770642202, 'rougeLsum': 0.03669724770642202}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 66.12547473559997\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALLY: Have you been drinking? Are you fucked up right now?\\nJACK: I've had a couple.\\nALLY: It's the morning.\\n\\n\", 'answer': 'Yup. Hey, buddy.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JACK'}\n",
      "Last word -> JACK : \"Yup. Hey, buddy.\"\n",
      "prediction :  I've had a couple of drinks.\n",
      "Real answer : Yup. Hey, buddy.\n",
      "Bert Score : {'precision': [0.881456732749939], 'recall': [0.8910170793533325], 'f1': [0.886211097240448], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 31.704316744800007\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACK: You’ve been nominated for three Grammys and it’s fucking great.\\nALLY: Thank you. How did you find that out?\\nJACK: Bobby told me. He called, he said that they want me to do some Roy Orbison tribute, some super group thing, but...\\nALLY: That’s great.\\nJACK: But the point is you got nominated and it’s great. I’m just trying to figure it out, that’s all.\\nALLY: What are you trying to figure out?\\nJACK: ‘Why you come around with an ass like that?’\\nALLY: What are you... You singing my lyrics...\\nJACK: ‘Why you look so good in those jeans, why you come around with an ass like that...’\\nALLY: Yeah, that’s my song.\\nJACK: Yeah, I know it’s your song, I have to fucking listen to it over and over and fucking...\\nALLY: What about my song? Then -- You’re not making any sense. Yeah, just keep drinking. That’ll give you the answer.\\nJACK: I don’t know, maybe I just fucking failed you, it just kills me, I’m sorry, I just --\\nALLY: You what?! You failed me?\\nJACK: Yeah, you’re embarrassing and it just -- You know, I feel bad for you.\\nALLY: I’m embarrassing?\\nJACK: And I just... You know --\\nALLY: I’m not fucking embarrassing, you’re embarrassing and you know what you’re doing? You’re so embarrassed of your fucking self that you gotta put me down.\\nJACK: I just have to tell you, I have to be honest with you, you know? You’re worried that you’re ugly -- and you’re not, I’m trying to tell you that -- so you need to get all this fucking approval by all these other people and it’s...\\nALLY: I don't need approval.\\nJACK: I just... Why can’t I just be enough for you?\\nALLY: You know what I’d like? Is for my boyfriend to love me.\\nJACK: No...\\nALLY: Actually, for my husband to love me.\\nJACK: Yeah, who’s your fucking boyfriend? You have a boyfriend?\\nALLY: Yeah, I got a boyfriend.\\nJACK: That hurts.\\nALLY: Yeah, I have a boyfriend.\\nJACK: Call me your fucking boyfriend...\\nALLY: You’re my boyfriend! You’re my boyfriend if you don’t treat me like your wife.\\nJACK: I don’t even know what that fucking means.\\nALLY: It means clean your shit up. You’re fucking messy. That’s what it means.\\nJACK: Well, that's not true.\\nALLY: Oh, it isn’t? Well, let’s go. You want to be my drinking buddy? Want to practice?\\nJACK: I don’t think you could handle it.\\nALLY: You don’t? I’ll just do it.\\nJACK: And you know why? ‘Cause you’re too worried what everybody else is thinking. You can’t even concentrate on one fucking thing... That’s right.\\nALLY: You don’t think I can handle it. Here we go. Here we go. Here we go, Jack, want me to be your dad, be your drinking buddy? Here we go...\\nJACK: Yeah, you couldn’t be my dad if you fucking tried. He had more talent in his fucking finger than your whole fucking body, so don’t even fucking go there about that, alright? That’s over the fucking line.\\nALLY: Why don’t you have another drink and we can just get fucking drunk until we fucking disappear, okay? Hey... do you got those pills in your pocket?\\nJACK: You're just fucking ugly, that's all.\\nALLY: I'm what?\\nJACK: You're just fucking ugly.\\nALLY: Get the fuck out! Get out! I said get out!\\n\\n\", 'answer': 'Fine.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JACK'}\n",
      "Last word -> JACK : \"Fine.\"\n",
      "prediction :  I’m sorry, I just -- I’m sorry.\n",
      "Real answer : Fine.\n",
      "Bert Score : {'precision': [0.7820563316345215], 'recall': [0.9233554601669312], 'f1': [0.8468523621559143], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 41.078411332855225\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: Hey, what kind of name is Pokrifki? Hey, what kind of name is Pokrifki?\\nPAULA: Polish. What kind of name is Mayo? Polish. What kind of name is Mayo?\\nZACK: Italian. My mom was Irish. I got Italian. My mom was Irish. I got her ears. But the rest is all wop. her ears. But the rest is all wop.\\nPAULA: Where are you from, Mayo the Wop? Where are you from, Mayo the Wop?\\nZACK: Everywhere and nowhere, Paula the Everywhere and nowhere, Paula the Polack.\\nPAULA: Seriously. Seriously.\\nZACK: My father is a Rear Admiral in the My father is a Rear Admiral in the Seventh Fleet. Seventh Fleet.\\nPAULA: Really? Really?\\nZACK: Yeah. We've lived all over the Yeah. We've lived all over the world. Katmandu, Moscow, Nairobi. world. Katmandu, Moscow, Nairobi.\\nPAULA: Really? I've never been out of Really? I've never been out of Washington except once when I visited Washington except once when I visited this aunt of mine over to Portland. this aunt of mine over to Portland. I mean, over at Portland. Ain't it I mean, over at Portland. Ain't it pathetic the way folks talk around pathetic the way folks talk around here? here? You're putting me on, aren't you? We You're putting me on, aren't you? We don't got no Navy bases in Moscow. don't got no Navy bases in Moscow. You got a girl? You got a girl?\\nZACK: No, and I'm not looking for one No, and I'm not looking for one either. either.\\nPAULA: Yeah, what are you looking for? Yeah, what are you looking for?\\nZACK: I hear most of the girls who come to I hear most of the girls who come to these things are looking for a these things are looking for a husband. husband.\\nPAULA: Not me. Not me.\\nZACK: Yeah? Why're you here? Yeah? Why're you here?\\nPAULA: To meet interesting people, improve To meet interesting people, improve myself. You wouldn't believe the myself. You wouldn't believe the losers we got over in Port Angeles. losers we got over in Port Angeles.\\nZACK: Do you go to school? Do you go to school?\\n\\n\", 'answer': \"No. I work for National Paper. It's No. I work for National Paper. It's a good job. I make eight-twenty- a good job. I make eight-twenty- three an hour. three an hour. When I get enough money saved, I plan When I get enough money saved, I plan to go on to college. to go on to college.\", 'gold_tag': 'PAULA works for National Paper earning eight-twenty-three an hour , PAULA plans to go to college once she saves enough money', 'last_speaker': 'PAULA'}\n",
      "Last word -> PAULA : \"No. I work for National Paper. It's No. I work for National Paper. It's a good job. I make eight-twenty- a good job. I make eight-twenty- three an hour. three an hour. When I get enough money saved, I plan When I get enough money saved, I plan to go on to college. to go on to college.\"\n",
      "prediction :  Yeah, I'm in the drama department. Yeah, I'm in the drama department. I'm a freshman. I'm a freshman.\n",
      "Real answer : No. I work for National Paper. It's No. I work for National Paper. It's a good job. I make eight-twenty- a good job. I make eight-twenty- three an hour. three an hour. When I get enough money saved, I plan When I get enough money saved, I plan to go on to college. to go on to college.\n",
      "Bert Score : {'precision': [0.8816760182380676], 'recall': [0.8232450485229492], 'f1': [0.8514593243598938], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.11904761904761903, 'rougeLsum': 0.11904761904761903}\n",
      "bleu 1/2 : 0.012040891469099537 0.0027704826573930964\n",
      "ppl : 6.364712378255179\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAULA: Want a back rub? Might make you feel Want a back rub? Might make you feel better. better.\\nZACK: I shouldn't have done that. I I shouldn't have done that. I should've walked. should've walked.\\nPAULA: He didn't give you much choice. He didn't give you much choice.\\nZACK: There's always a choice. There's always a choice.\\nPAULA: Where'd you learn to fight like that? Where'd you learn to fight like that?\\nZACK: I don't feel like talking, if you I don't feel like talking, if you don't mind. don't mind.\\nPAULA: Opening up just a little wouldn't Opening up just a little wouldn't kill you, ya know. kill you, ya know.\\nZACK: You want me to fuck you? Is that it? You want me to fuck you? Is that it? Okay, come here. Take your clothes Okay, come here. Take your clothes off. Get into bed. off. Get into bed.\\nPAULA: Where's that coming from? I wouldn't Where's that coming from? I wouldn't fuck now if my life depended on it! fuck now if my life depended on it!\\nZACK: Forget it. Just get out of here. Forget it. Just get out of here.\\nPAULA: I don't know who you think you're I don't know who you think you're talking to! I ain't some whore you talking to! I ain't some whore you brought here! I've been trying to be brought here! I've been trying to be your friend and you treat me like your friend and you treat me like shit! shit!\\nZACK: Be a friend. Leave. Be a friend. Leave.\\n\\n\", 'answer': \"You got no manners and you never tell You got no manners and you never tell the truth! You're nothin' special. the truth! You're nothin' special. And if you ask me, you got no chance And if you ask me, you got no chance at all of being an officer! at all of being an officer!\", 'gold_tag': 'PAULA has a strong sense of self-respect as she refuses to be treated poorly', 'last_speaker': 'PAULA'}\n",
      "Last word -> PAULA : \"You got no manners and you never tell You got no manners and you never tell the truth! You're nothin' special. the truth! You're nothin' special. And if you ask me, you got no chance And if you ask me, you got no chance at all of being an officer! at all of being an officer!\"\n",
      "prediction :  What's wrong with you?\n",
      "Real answer : You got no manners and you never tell You got no manners and you never tell the truth! You're nothin' special. the truth! You're nothin' special. And if you ask me, you got no chance And if you ask me, you got no chance at all of being an officer! at all of being an officer!\n",
      "Bert Score : {'precision': [0.826640784740448], 'recall': [0.7753699421882629], 'f1': [0.8001849055290222], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.031746031746031744, 'rouge2': 0.0, 'rougeL': 0.031746031746031744, 'rougeLsum': 0.031746031746031744}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 38.458170892934305\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: You stayed after all. You stayed after all.\\nPAULA: Wrong. I've driven a hundred and Wrong. I've driven a hundred and twenty miles, told a hundred and twenty miles, told a hundred and twenty lies, and said a hundred and twenty lies, and said a hundred and twenty Hail Mary's since I saw you. twenty Hail Mary's since I saw you. Hungry?\\nZACK: I'm starving. I'm starving. Paula, I never try to fool anybody Paula, I never try to fool anybody about who I am, what I want... so if about who I am, what I want... so if even in the back of your -- even in the back of your --\\nPAULA: I know who you are and what you want. I know who you are and what you want.\\nZACK: What do you want, Paula? What do you What do you want, Paula? What do you really want? really want?\\nPAULA: To have a good time with you until To have a good time with you until you have to go.\\nZACK: That's it? That's it? Mmmm. Last night was fantastic. Mmmm. Last night was fantastic.\\nPAULA: Zack, am I your fantasy? Zack, am I your fantasy? Zack, I dare you not to fall in love Zack, I dare you not to fall in love with me. I ain't gonna get serious with me. I ain't gonna get serious with you, no way. But how can you with you, no way. But how can you resist me? I'm like candy. resist me? I'm like candy.\\nZACK: You're better than candy. You're better than candy.\\n\\n\", 'answer': \"I'm serious. It's gonna be hard to I'm serious. It's gonna be hard to get enough. get enough.\", 'gold_tag': 'PAULA is determined and not planning on getting overly attached or serious', 'last_speaker': 'PAULA'}\n",
      "Last word -> PAULA : \"I'm serious. It's gonna be hard to I'm serious. It's gonna be hard to get enough. get enough.\"\n",
      "prediction :  What do you want to do? What do you want to do?\n",
      "Real answer : I'm serious. It's gonna be hard to I'm serious. It's gonna be hard to get enough. get enough.\n",
      "Bert Score : {'precision': [0.8335099220275879], 'recall': [0.8225704431533813], 'f1': [0.828004002571106], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352942, 'rouge2': 0.0, 'rougeL': 0.11764705882352942, 'rougeLsum': 0.11764705882352942}\n",
      "bleu 1/2 : 0.10108844328543891 0.023609173909393866\n",
      "ppl : 10.184896868888746\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: Getting cocky, aren't you? Huh, you Getting cocky, aren't you? Huh, you little Polack? Getting feisty on me, little Polack? Getting feisty on me, huh? huh?\\nPAULA: Zack, when you're through with a Zack, when you're through with a girl, what do you do? Do you say girl, what do you do? Do you say something or do you just... something or do you just... disappear?\\nZACK: I've never had a girl. I've never had a girl. I forgot to thank you for breakfast. I forgot to thank you for breakfast.\\n\\n\", 'answer': 'Any time, sailor. Any time, sailor.', 'gold_tag': 'PAULA is a caring and considerate individual, as shown in how she cooked breakfast for ZACK and offers to do it again', 'last_speaker': 'PAULA'}\n",
      "Last word -> PAULA : \"Any time, sailor. Any time, sailor.\"\n",
      "prediction :  You're welcome. You're welcome.\n",
      "Real answer : Any time, sailor. Any time, sailor.\n",
      "Bert Score : {'precision': [0.8835153579711914], 'recall': [0.8696427941322327], 'f1': [0.8765242695808411], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.427094387501302\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: I'm sorry. I can't sit with you. I'm sorry. I can't sit with you.\\n\\n\", 'answer': \"I understand. Maybe we'll see each I understand. Maybe we'll see each other after the show... other after the show...\", 'gold_tag': \"PAULA's temporal information: PAULA is planning to attend a show , ZACK's temporal information: ZACK may join PAULA after the show\", 'last_speaker': 'PAULA'}\n",
      "Last word -> PAULA : \"I understand. Maybe we'll see each I understand. Maybe we'll see each other after the show... other after the show...\"\n",
      "prediction :  I'm sorry too.\n",
      "Real answer : I understand. Maybe we'll see each I understand. Maybe we'll see each other after the show... other after the show...\n",
      "Bert Score : {'precision': [0.8615787029266357], 'recall': [0.8255684971809387], 'f1': [0.8431892991065979], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307693, 'rouge2': 0.0, 'rougeL': 0.07692307692307693, 'rougeLsum': 0.07692307692307693}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 84.96863597429754\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: Hi. Hi.\\nPAULA: Are those for me? Are those for me?\\n\\n', 'answer': \"No, they're for your mom. No, they're for your mom.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ZACK'}\n",
      "Last word -> ZACK : \"No, they're for your mom. No, they're for your mom.\"\n",
      "prediction :  Yes.\n",
      "Real answer : No, they're for your mom. No, they're for your mom.\n",
      "Bert Score : {'precision': [0.932608962059021], 'recall': [0.8476489186286926], 'f1': [0.8881015777587891], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2104.611116571625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAULA: I'm so embarrassed. I knew I I'm so embarrassed. I knew I shouldn't have brought you here. shouldn't have brought you here.\\nZACK: No, it's okay. It was a great free No, it's okay. It was a great free meal. Everybody was so uptight I meal. Everybody was so uptight I felt sorry for you. felt sorry for you.\\nPAULA: That's okay. I'm used to it. That's okay. I'm used to it. So, after you graduate you go on to So, after you graduate you go on to basic flight, right? Is that in basic flight, right? Is that in Pensacola? Pensacola?\\nZACK: Yeah, then if I get jets, it's on to Yeah, then if I get jets, it's on to Beeville, Texas. Beeville, Texas.\\nPAULA: Zack, do you ever think about what Zack, do you ever think about what it'd be like to have kids... a it'd be like to have kids... a family. family.\\nZACK: No. Is that what you want? No. Is that what you want?\\nPAULA: Some day. When I'm sure I can do a Some day. When I'm sure I can do a better job of it than my folks. better job of it than my folks.\\nZACK: What would you do differently? What would you do differently?\\nPAULA: For a start, I wouldn't marry a man For a start, I wouldn't marry a man I wasn't in love with. I wasn't in love with.\\nZACK: Why'd your mom marry that guy if she Why'd your mom marry that guy if she didn't love him? didn't love him?\\nPAULA: Because my real father wouldn't marry Because my real father wouldn't marry her. her.\\nZACK: Your real father? Your real father?\\nPAULA: Yeah... him. Yeah... him.\\nZACK: Your real father was an Officer Your real father was an Officer candidate like me? candidate like me?\\nPAULA: Twenty-two years ago. Twenty-two years ago.\\nZACK: No wonder he was looking at me like No wonder he was looking at me like that. that. Uh-oh. Time to get back to the wars. Uh-oh. Time to get back to the wars.\\nPAULA: Call me during the week if you get Call me during the week if you get the chance. the chance.\\nZACK: I'll try, but this week we go into I'll try, but this week we go into survival training, so I can't make survival training, so I can't make any promises. any promises. Well, thanks again for dinner. Thank Well, thanks again for dinner. Thank your mom again for me, will you? your mom again for me, will you?\\nPAULA: Sure. Sure. Zack, I hope you know I didn't have Zack, I hope you know I didn't have to show you that picture. to show you that picture.\\n\\n\", 'answer': 'I know that. I know that.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ZACK'}\n",
      "Last word -> ZACK : \"I know that. I know that.\"\n",
      "prediction :  Yeah, I know. Yeah, I know.\n",
      "Real answer : I know that. I know that.\n",
      "Bert Score : {'precision': [0.8827264308929443], 'recall': [0.8862967491149902], 'f1': [0.8845080137252808], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.6666666666666666, 'rouge2': 0.4000000000000001, 'rougeL': 0.6666666666666666, 'rougeLsum': 0.6666666666666666}\n",
      "bleu 1/2 : 0.3333333333333333 0.08164965809277261\n",
      "ppl : 20.816498286381975\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZACK: Is Paula here? Is Paula here? I'm looking for Sid. I'm looking for Sid.\\nPAULA: So? So?\\nZACK: Paula, he DORed and nobody's seen him. Paula, he DORed and nobody's seen him.\\nPAULA: Why'd he do it? Why'd he do it?\\nZACK: Hey! You know goddamn well what Hey! You know goddamn well what happened so let's not play any games, happened so let's not play any games, okay? okay?\\nPAULA: I'm not playing any games! Go look I'm not playing any games! Go look at Lynette's! at Lynette's!\\n\\n\", 'answer': \"I don't know where that is. I don't know where that is.\", 'gold_tag': \"ZACK is not familiar with Lynette's location\", 'last_speaker': 'ZACK'}\n",
      "Last word -> ZACK : \"I don't know where that is. I don't know where that is.\"\n",
      "prediction :  I can't. I can't.\n",
      "Real answer : I don't know where that is. I don't know where that is.\n",
      "Bert Score : {'precision': [0.9165765643119812], 'recall': [0.8632673025131226], 'f1': [0.8891236186027527], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4, 'rouge2': 0.0, 'rougeL': 0.4, 'rougeLsum': 0.4}\n",
      "bleu 1/2 : 0.06766764161830635 0.017471709937655493\n",
      "ppl : 28.73298644996106\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAULA: I'd like to come with you. I'd like to come with you.\\nZACK: Why? Why?\\n\\n\", 'answer': \"Because he's my friend, too. Because he's my friend, too.\", 'gold_tag': 'PAULA and ZACK share a mutual friendship with the person they are discussing', 'last_speaker': 'PAULA'}\n",
      "Last word -> PAULA : \"Because he's my friend, too. Because he's my friend, too.\"\n",
      "prediction :  Because I want to be there for you.\n",
      "Real answer : Because he's my friend, too. Because he's my friend, too.\n",
      "Bert Score : {'precision': [0.8850452899932861], 'recall': [0.8826557397842407], 'f1': [0.8838488459587097], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1, 'rouge2': 0.0, 'rougeL': 0.1, 'rougeLsum': 0.1}\n",
      "bleu 1/2 : 0.09735009788392564 0.03291033976993492\n",
      "ppl : 35.88453884901747\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAULA: Please stop it. None of that's true. Please stop it. None of that's true. Goddamnit, I love you. I loved you Goddamnit, I love you. I loved you ever since I met you. ever since I met you.\\nZACK: Come on, Paula! You were looking for Come on, Paula! You were looking for a ticket out of here and you didn't a ticket out of here and you didn't care who it was, any more than you care who it was, any more than you cared with the last class of cared with the last class of candidates you and Lynette fucked candidates you and Lynette fucked your way through, looking for a your way through, looking for a husband! Or the class before that! husband! Or the class before that!\\nPAULA: Yeah. You got the whole story just Yeah. You got the whole story just right.\\nZACK: Beware of the Puget Debs -- and we Beware of the Puget Debs -- and we all laughed, especially him. all laughed, especially him.\\nPAULA: I'm not a Puget Deb. I hate that I'm not a Puget Deb. I hate that goddamn term! goddamn term!\\nZACK: I bet you do! I bet you do!\\nPAULA: However you got it figured, I didn't However you got it figured, I didn't kill Sid and Lynette didn't kill him! kill Sid and Lynette didn't kill him! He killed himself! He killed himself!\\nZACK: That's brilliant. That's brilliant.\\n\\n\", 'answer': \"Maybe not, but it is the truth. And Maybe not, but it is the truth. And Zack, you didn't kill him either. Zack, you didn't kill him either. motorcycle.\", 'gold_tag': \"PAULA is defensive and passionate , ZACK is skeptical of PAULA's sincerity\", 'last_speaker': 'PAULA'}\n",
      "Last word -> PAULA : \"Maybe not, but it is the truth. And Maybe not, but it is the truth. And Zack, you didn't kill him either. Zack, you didn't kill him either. motorcycle.\"\n",
      "prediction :  Zack, listen to me. I don't know what I'm doing. I'm not a killer. I don't know what I'm doing. I'm not a killer. I didn't kill Sid. I'm not a killer. I didn't kill Sid. I didn't kill him. He killed himself.\n",
      "Real answer : Maybe not, but it is the truth. And Maybe not, but it is the truth. And Zack, you didn't kill him either. Zack, you didn't kill him either. motorcycle.\n",
      "Bert Score : {'precision': [0.8861439228057861], 'recall': [0.8709888458251953], 'f1': [0.8785010576248169], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2380952380952381, 'rouge2': 0.1219512195121951, 'rougeL': 0.21428571428571427, 'rougeLsum': 0.21428571428571427}\n",
      "bleu 1/2 : 0.11627906976744189 0.07441168295606797\n",
      "ppl : 4.5271009513336\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTANK: Morning. Did you sleep?\\nNEO: No.\\nTANK: You will tonight. I guarantee it. I'm Tank. I'll be your operator.\\nNEO: You don't have...\\nTANK: Any holes? Nope. Me and my brother Dozer, we are 100 percent pure, old fashioned, home-grown human. Born free. Right here in the real world. Genuine child of Zion.\\nNEO: Zion?\\n\\n\", 'answer': \"Zion is the place, man. You'll see it one day. Last human city. All we got left. Goddamn, I got to tell you I'm fairly excited to see what you are capable of. I mean if Morpheus is right and all. We're not supposed to talk.about any of that, but if you are, well then this is an exciting time. We got a lot to do so let's get to it.\", 'gold_tag': 'TANK expects an exciting time ahead, regarding what NEO is capable of', 'last_speaker': 'TANK'}\n",
      "Last word -> TANK : \"Zion is the place, man. You'll see it one day. Last human city. All we got left. Goddamn, I got to tell you I'm fairly excited to see what you are capable of. I mean if Morpheus is right and all. We're not supposed to talk.about any of that, but if you are, well then this is an exciting time. We got a lot to do so let's get to it.\"\n",
      "prediction :  The last free city on Earth.\n",
      "Real answer : Zion is the place, man. You'll see it one day. Last human city. All we got left. Goddamn, I got to tell you I'm fairly excited to see what you are capable of. I mean if Morpheus is right and all. We're not supposed to talk.about any of that, but if you are, well then this is an exciting time. We got a lot to do so let's get to it.\n",
      "Bert Score : {'precision': [0.8780602216720581], 'recall': [0.8082494735717773], 'f1': [0.8417097926139832], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07317073170731707, 'rouge2': 0.0, 'rougeL': 0.07317073170731707, 'rougeLsum': 0.07317073170731707}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 62.7804169156708\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTANK: We're supposed to load all these operations programs first, but this is some major boring shit. Why don't we start something a little fun? How about sore combat training?\\nNEO: Jiujitsu? I'm going to learn jujitsu? No way. Holy shit!\\nTANK: Hey, Mikey, he likes it! Ready for more?\\n\\n\", 'answer': 'Hell yes!', 'gold_tag': 'NEO is excited and enthusiastic about learning', 'last_speaker': 'NEO'}\n",
      "Last word -> NEO : \"Hell yes!\"\n",
      "prediction :  I'm not sure, but I'm not sure I'm ready for a lot of boredom.\n",
      "Real answer : Hell yes!\n",
      "Bert Score : {'precision': [0.8247446417808533], 'recall': [0.8460530042648315], 'f1': [0.8352629542350769], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.894017067538751\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEO: What are they doing to him?\\nTANK: They're cracking his mind.\\nNEO: How?\\n\\n\", 'answer': \"They inject virus-like serums to break down the system. It's like cracking a computer. All it takes is time. Depends on the mind. But eventually, it will crack and his alpha pattern will change from this to this. When it does, Morpheus will tell them anything they want to know.\", 'gold_tag': \"TANK mentions it takes time to crack a system , TANK implies a target deadline when Morpheus' alpha pattern changes\", 'last_speaker': 'TANK'}\n",
      "Last word -> TANK : \"They inject virus-like serums to break down the system. It's like cracking a computer. All it takes is time. Depends on the mind. But eventually, it will crack and his alpha pattern will change from this to this. When it does, Morpheus will tell them anything they want to know.\"\n",
      "prediction :  It's called psychic attack.\n",
      "Real answer : They inject virus-like serums to break down the system. It's like cracking a computer. All it takes is time. Depends on the mind. But eventually, it will crack and his alpha pattern will change from this to this. When it does, Morpheus will tell them anything they want to know.\n",
      "Bert Score : {'precision': [0.8812595009803772], 'recall': [0.8282344341278076], 'f1': [0.8539246320724487], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07017543859649124, 'rouge2': 0.03636363636363636, 'rougeL': 0.07017543859649124, 'rougeLsum': 0.07017543859649124}\n",
      "bleu 1/2 : 2.5325233996576776e-06 9.247467956014542e-07\n",
      "ppl : 83.85799496581149\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALICE: Now don't pick a fight. I'm staying over.\\n\\n\", 'answer': \"Oh, poor Buster. He hasn't been fed in a day and a half. Let me get some food...\", 'gold_tag': \"JULIE is concerned about Buster not being fed , Buster is presumably a pet , JULIE has responsibilities of a pet owner , Julie's information refers to the recent past where Buster hasn’t been fed in a day and a half\", 'last_speaker': 'JULIE'}\n",
      "Last word -> JULIE : \"Oh, poor Buster. He hasn't been fed in a day and a half. Let me get some food...\"\n",
      "prediction :  That's the last thing you want to do.\n",
      "Real answer : Oh, poor Buster. He hasn't been fed in a day and a half. Let me get some food...\n",
      "Bert Score : {'precision': [0.8610523343086243], 'recall': [0.8431919813156128], 'f1': [0.8520285487174988], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18.676746248550135\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALICE: Special occasion?\\nJULIE: I don't know. I guess it was...\\n\\n\", 'answer': \"Don't get all poignant. We're keeping this bottle on ice. When he comes around you're going to need it.\", 'gold_tag': \"ALICE decided to keep the bottle on ice for a future occasion , JULIE has strong emotions tied to the occasion or person they're waiting for , JULIE's special occasion has become an uncertain event\", 'last_speaker': 'ALICE'}\n",
      "Last word -> ALICE : \"Don't get all poignant. We're keeping this bottle on ice. When he comes around you're going to need it.\"\n",
      "prediction :  Yeah, sure.\n",
      "Real answer : Don't get all poignant. We're keeping this bottle on ice. When he comes around you're going to need it.\n",
      "Bert Score : {'precision': [0.8398804664611816], 'recall': [0.835661768913269], 'f1': [0.8377658128738403], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 154.89803285362987\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALICE: Who did this?\\nJULIE: Stu. That was right about the time we met.\\nALICE: When he first came in to the sleep lab?\\nJULIE: Yeah...before your time.\\nALICE: Jesus, honey...he always joked about you curing him, but I never realized what you cured him from.\\nJULIE: He hadn't gotten a good night's sleep in years. The nightmares would wake him up, and he'd start right in painting...\\nALICE: How do you get from here - to there? What?\\nJULIE: I'm serious. It was bicameral disjunction - right brain and left brain out of balance. He was a rightie, so I made him switch the pencil to his left hand. Just to see what'd come out.\\nALICE: Monkeybone?\\nJULIE: Left-handed, he was funny. He'd been doing all this scary, intense work...then he found out he could draw this stuff, and make me laugh, and he liked that.\\nALICE: Wow - two guys in the same brain. - Which one did you fall in love with?\\n\\n\", 'answer': \"I've put a ton of work into that boy, Alice. I am not going to let him get away from me.\", 'gold_tag': 'JULIE has a close, personal relationship with a person named Stu', 'last_speaker': 'JULIE'}\n",
      "Last word -> JULIE : \"I've put a ton of work into that boy, Alice. I am not going to let him get away from me.\"\n",
      "prediction :  The one I fell in love with was the left-handed one.\n",
      "Real answer : I've put a ton of work into that boy, Alice. I am not going to let him get away from me.\n",
      "Bert Score : {'precision': [0.869228720664978], 'recall': [0.858757495880127], 'f1': [0.863961398601532], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05882352941176471, 'rouge2': 0.0, 'rougeL': 0.05882352941176471, 'rougeLsum': 0.05882352941176471}\n",
      "bleu 1/2 : 0.03662639286628481 0.01214760025616164\n",
      "ppl : 26.42976489737525\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALICE: Most we've ever used is half a CC.\\n\\n\", 'answer': \"Five CC's.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'JULIE'}\n",
      "Last word -> JULIE : \"Five CC's.\"\n",
      "prediction :  Yeah, I know. I've got a whole bag of 'em.\n",
      "Real answer : Five CC's.\n",
      "Bert Score : {'precision': [0.8339530229568481], 'recall': [0.8755975365638733], 'f1': [0.8542680144309998], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.69579330863263\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJULIE: The thing is, I'm responsible for the way he's acting. It's the nightmare juice. It's got to be.\\nALICE: Julie, that stuff probably saved his life.\\n\\n\", 'answer': \"I can't explain this, Alice, but I'm not so sure it did. It's as if...he's not Stu any more. The Stu I love is gone!\", 'gold_tag': 'Julie hints at a close relationship with Stu, possibly romantic , Julie expresses her belief that the Stu she loved is gone', 'last_speaker': 'JULIE'}\n",
      "Last word -> JULIE : \"I can't explain this, Alice, but I'm not so sure it did. It's as if...he's not Stu any more. The Stu I love is gone!\"\n",
      "prediction :  Maybe it did, but I can't help feeling that it's the reason he's like this.\n",
      "Real answer : I can't explain this, Alice, but I'm not so sure it did. It's as if...he's not Stu any more. The Stu I love is gone!\n",
      "Bert Score : {'precision': [0.8866732120513916], 'recall': [0.8591511249542236], 'f1': [0.8726952075958252], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.5, 'rouge2': 0.2608695652173913, 'rougeL': 0.2916666666666667, 'rougeLsum': 0.2916666666666667}\n",
      "bleu 1/2 : 0.13691123174202455 0.07085829428423313\n",
      "ppl : 16.21487006059672\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALICE: Listen. Let's bring him in for some tests. I guarantee you're overreacting.\\n\\n\", 'answer': \"Actually, no, I don't think I'm overreacting.\", 'gold_tag': 'Julie is concerned about a situation , Julie shows a tendency to worry or stress', 'last_speaker': 'JULIE'}\n",
      "Last word -> JULIE : \"Actually, no, I don't think I'm overreacting.\"\n",
      "prediction :  He's not breathing, Alice.\n",
      "Real answer : Actually, no, I don't think I'm overreacting.\n",
      "Bert Score : {'precision': [0.8576532602310181], 'recall': [0.8467869758605957], 'f1': [0.8521854877471924], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 63.510912313193224\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLI: If you go to San De, he can send you to a doctor...\\n\\n', 'answer': \"I appreciate your concern, Li, but it's not that serious.\", 'gold_tag': 'DREW does not consider his current health situation to be critical', 'last_speaker': 'DREW'}\n",
      "Last word -> DREW : \"I appreciate your concern, Li, but it's not that serious.\"\n",
      "prediction :  I don't need no doctor, I need you.\n",
      "Real answer : I appreciate your concern, Li, but it's not that serious.\n",
      "Bert Score : {'precision': [0.8654141426086426], 'recall': [0.8646804690361023], 'f1': [0.8650470972061157], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09999999999999999, 'rouge2': 0.0, 'rougeL': 0.09999999999999999, 'rougeLsum': 0.09999999999999999}\n",
      "bleu 1/2 : 0.09735009788392564 0.03291033976993492\n",
      "ppl : 24.986188963180535\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLI: We broke every major rule the temple has, how could we get away with it?\\nDREW: I think we might have. If they knew, they'd have already gotten us! You guys just have to stop looking so guilty. Let's go back to the dorm for a few minutes, go over our\\n\\n\", 'answer': 'Seperate us?', 'gold_tag': 'LI is anxious', 'last_speaker': 'LI'}\n",
      "Last word -> LI : \"Seperate us?\"\n",
      "prediction :  I don't want to go back to the dorm!\n",
      "Real answer : Seperate us?\n",
      "Bert Score : {'precision': [0.8319643139839172], 'recall': [0.8496305346488953], 'f1': [0.840704619884491], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 17.2523696464627\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLI: Are you crazy? You almost got kicked out once over that kind of thing...\\n\\n', 'answer': 'I left that girl at the stream. Are you two still carrying her?', 'gold_tag': 'DREW has previously been involved in an incident , The incident led to DREW almost being expelled , DREW and LI recall an incident where DREW almost got expelled for leaving a girl at the stream', 'last_speaker': 'DREW'}\n",
      "Last word -> DREW : \"I left that girl at the stream. Are you two still carrying her?\"\n",
      "prediction :  Yeah, I know. But I can't help it. I like the thrill of it.\n",
      "Real answer : I left that girl at the stream. Are you two still carrying her?\n",
      "Bert Score : {'precision': [0.8437792658805847], 'recall': [0.8464787006378174], 'f1': [0.845126748085022], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714288, 'rouge2': 0.0, 'rougeL': 0.14285714285714288, 'rougeLsum': 0.14285714285714288}\n",
      "bleu 1/2 : 0.14285714285714285 0.033149677206589796\n",
      "ppl : 8.498684724192355\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLOBRUTO: William No-Middle-Initial Slocum.\\nWILLY: Yes sir.\\nLOBRUTO: Sit. Eighty-four-percent conviction rate. That's remarkable.\\nWILLY: Thank you.\\nLOBRUTO: With a case load thirty percent higher than any other first-year DDA. Of course - you also swapped more cases than the rest of them put together.\\nWILLY: I offered my losing cases in exchange for two or three of anyone else's possible convictions. They couldn't handle their workloads, and I prefer not to lose.\\nLOBRUTO: You're going to need a middle initial.\\nWILLY: Sir?\\nLOBRUTO: You're going to Wooton Sims.\\nWILLY: In two weeks.\\nLOBRUTO: You'll be able to afford a better suit. But those guys all play squash and have middle names. They go in for the mother's maiden name a lot. Beat. Willy doesn't like the implied personal judgement, but the only way it shows is how calm he stays.\\nWILLY: My mother didn't have a maiden name.\\nLOBRUTO: So you're a bastard; sometimes I can be a son-of-a-bitch. Maybe you belong here.\\nWILLY: I didn't work this hard to stay where I belong.\\nLOBRUTO: You're a street-fighter, Willy. You should be in court. We can move you up to better cases. I didn't think so. Well - you got your litigation experience. Your chops. And your juicy private sector job. Anything else the City of Los Angeles can do for you?\\nWILLY: No, I think that's everything - thank you.\\n\\n\", 'answer': \"The offer stands. If you get tired of carrying a spear. It's an opera joke. Give my regards to Bob.\", 'gold_tag': 'LOBRUTO possesses a sense of humor', 'last_speaker': 'LOBRUTO'}\n",
      "Last word -> LOBRUTO : \"The offer stands. If you get tired of carrying a spear. It's an opera joke. Give my regards to Bob.\"\n",
      "prediction : You're not going to like this.\n",
      "Real answer : The offer stands. If you get tired of carrying a spear. It's an opera joke. Give my regards to Bob.\n",
      "Bert Score : {'precision': [0.8344166278839111], 'recall': [0.8490411043167114], 'f1': [0.8416653275489807], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.01616199464406751 0.0055986791750362004\n",
      "ppl : 13.778200160054075\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWILLY: I'm sorry - but nobody else seems to give a damn that sooner or later this guy is gonna finish what he started. Beat.\\nLOBRUTO: Have you been home at all today, Willy?\\nWILLY: No - I've been trying to get some-\\nLOBRUTO: There's a court order out against you.\\nWILLY: What?\\nLOBRUTO: A restraining order. You were at the hospital? Talking to her doctors? Crawford hired a lawyer this time. They saw Judge Gorman this afternoon.\\nWILLY: Against me.\\nLOBRUTO: You need to stay away from him, and his wife, and the hospital. He can have you arrested if you don't. I'm sorry. I can't help you. I told you how it would go.\\nWILLY: Can you do anything for her? Beat.\\n\\n\", 'answer': \"I don't see how.\", 'gold_tag': \"LOBRUTO's knowledge of a court order and its implications suggests a legal or law enforcement background\", 'last_speaker': 'LOBRUTO'}\n",
      "Last word -> LOBRUTO : \"I don't see how.\"\n",
      "prediction :  There's nothing I can do.\n",
      "Real answer : I don't see how.\n",
      "Bert Score : {'precision': [0.8688937425613403], 'recall': [0.8659629821777344], 'f1': [0.8674259185791016], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1818181818181818, 'rouge2': 0.0, 'rougeL': 0.1818181818181818, 'rougeLsum': 0.1818181818181818}\n",
      "bleu 1/2 : 0.2 0.07071067811865477\n",
      "ppl : 24.504250164268175\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLOBRUTO: You're not answering your phone. Beat.\\nWILLY: That's kind of an answer in itself, isn't it?\\nLOBRUTO: Where are you headed?\\nWILLY: Haven't decided yet. Just someplace else.\\nLOBRUTO: I shouldn't have let it get so far out of control. We all lose, Willy.\\nWILLY: Yep.\\nLOBRUTO: We just have to live with that, and keep fighting the good fight.\\nWILLY: That's not what I was doing.\\nLOBRUTO: You belong in a courtroom. Willy packs, thinking about that. Shakes his head.\\nWILLY: I need to - get to know myself better.\\nLOBRUTO: You're a good lawyer. All this may have even made you a better lawyer. Don't waste it.\\nWILLY: I didn't just lose a case! I let a man get away with murder.\\n\\n\", 'answer': 'If it makes you feel any better - technically, you let a man get away with attempted murder.', 'gold_tag': 'LOBRUTO regrets letting a situation get out of control', 'last_speaker': 'LOBRUTO'}\n",
      "Last word -> LOBRUTO : \"If it makes you feel any better - technically, you let a man get away with attempted murder.\"\n",
      "prediction : I know, Willy. I know.\n",
      "Real answer : If it makes you feel any better - technically, you let a man get away with attempted murder.\n",
      "Bert Score : {'precision': [0.842411458492279], 'recall': [0.8026021718978882], 'f1': [0.8220251798629761], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 32.79747979569243\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWILLY: His wife is dead! We can still get him. We can take him back to court.\\nLOBRUTO: Willy...\\nWILLY: Double jeopardy doesn't apply! We bring a new charge - of homicide.\\nLOBRUTO: Willy - what happened to you, on the helicopter - we don't even know if we could prove -\\nWILLY: No: he shot her and she died. The fact that it took time - the fact that he went to trial in between, just for shooting her - doesn't matter. He fired a gun and caused her death, and that's murder. If he can twist the law around - then so can we.\\nLOBRUTO: A second indictment on the same incident?\\nWILLY: A man burns down a house; we charge him with arson. There were people sleeping upstairs - and after weeks in the hospital, they die. We'd charge him with murder. Right?\\nLOBRUTO: All your evidence is still toxic. The confession, the arrest - it's all still inadmissible. I'm sorry, Willy. It was a good idea, but -\\nWILLY: I'll get something new.\\nLOBRUTO: How?\\nWILLY: You don't want to know.\\nLOBRUTO: Willy, you can't -\\nWILLY: I don't work for you. Right?\\nLOBRUTO: Don't do anything crazy.\\n\\n\", 'answer': 'What else have we got left?', 'gold_tag': 'Everyday Language', 'last_speaker': 'WILLY'}\n",
      "Last word -> WILLY : \"What else have we got left?\"\n",
      "prediction :  That's right. I don't work for you. I'm my own man. I'm a free agent. I'm a private investigator. I can do anything I want.\n",
      "Real answer : What else have we got left?\n",
      "Bert Score : {'precision': [0.8503848910331726], 'recall': [0.8383522629737854], 'f1': [0.8443257212638855], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5.890577577178138\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIRIAM: How are you feeling?\\nBARNEY: You're never going to speak to me again I'm going to kill myself. Beat.\\nMIRIAM: Are you done?\\nBARNEY: Please don't leave.\\nMIRIAM: What would you like to talk about - All The President's Men, Herzog or Alphonse Daudet - nice reference, by the way.\\nBARNEY: I'm an idiot.\\nMIRIAM: Don't be so modest. You obviously expected me to come up to your room.\\nBARNEY: Never.\\nMIRIAM: So the champagne and roses are for another woman?\\nBARNEY: Oh God...\\n\\n\", 'answer': \"Why don't you get cleaned up, we'll get some fresh air, and maybe a slice of pizza. I'm absolutely starving. Off Barney's delight --\", 'gold_tag': 'MIRIAM enjoys pizza , MIRIAM is currently hungry', 'last_speaker': 'MIRIAM'}\n",
      "Last word -> MIRIAM : \"Why don't you get cleaned up, we'll get some fresh air, and maybe a slice of pizza. I'm absolutely starving. Off Barney's delight --\"\n",
      "prediction :  I'm not going anywhere.\n",
      "Real answer : Why don't you get cleaned up, we'll get some fresh air, and maybe a slice of pizza. I'm absolutely starving. Off Barney's delight --\n",
      "Bert Score : {'precision': [0.8687475919723511], 'recall': [0.8248365521430969], 'f1': [0.8462228178977966], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.06666666666666668, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.0016844867497713668 0.0006150875937788919\n",
      "ppl : 55.54599616360821\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIRIAM: Oh, Barney, put it in the freezer.\\nBARNEY: What?\\nMIRIAM: Put the onion in the freezer for a few minutes before you chop it. Then it won't make you cry.\\n\\n\", 'answer': 'How did I not know that? Really?', 'gold_tag': 'BARNEY struggles with chopping onions without causing teary eyes', 'last_speaker': 'BARNEY'}\n",
      "Last word -> BARNEY : \"How did I not know that? Really?\"\n",
      "prediction :  Why should it make me cry?\n",
      "Real answer : How did I not know that? Really?\n",
      "Bert Score : {'precision': [0.8664430975914001], 'recall': [0.8664413690567017], 'f1': [0.8664423227310181], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 177.74701421989397\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIRIAM: What\\'s with you? And don\\'t say \"what?\". Let\\'s just skip that whole part, okay?\\nBARNEY: I was giving him a few life lessons.\\nMIRIAM: By telling him I think he\\'s gay? And who even jokes about that anymore?\\nBARNEY: I don\\'t want to fight about Cher.\\nMIRIAM: We\\'re not fighting about Blair. We\\'re fighting about you.\\nBARNEY: Why?\\nMIRIAM: Getting Leo to come in doesn\\'t negate all the other interviews you\\'ve missed to get drunk and watch the game, or all the dinners you\\'ve ruined because you\\'re incorrigible with my friends.\\nBARNEY: It doesn\\'t?\\nMIRIAM: I\\'m going to visit Michael for a week.\\nBARNEY: What? When?\\nMIRIAM: Next weekend.\\nBARNEY: Okay, I\\'ll take the week off.\\nMIRIAM: No. I think a little time apart will do us both good.\\nBARNEY: What? Where is this coming from?\\n\\n', 'answer': \"We've hardly been away from each other since we've been married. It'll be good for us to circulate the air in here a little. It's only a week - okay?\", 'gold_tag': 'MIRIAM believes that time apart from Barney is beneficial , Shared memories', 'last_speaker': 'MIRIAM'}\n",
      "Last word -> MIRIAM : \"We've hardly been away from each other since we've been married. It'll be good for us to circulate the air in here a little. It's only a week - okay?\"\n",
      "prediction :  Because I'm sick of you.\n",
      "Real answer : We've hardly been away from each other since we've been married. It'll be good for us to circulate the air in here a little. It's only a week - okay?\n",
      "Bert Score : {'precision': [0.8716055154800415], 'recall': [0.8312699198722839], 'f1': [0.8509600758552551], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 69.48979748965192\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBARNEY: Thank you.\\n\\n', 'answer': 'Would you excuse me? I have to use the ladies room? WHITE 10-23-09', 'gold_tag': 'Everyday Language', 'last_speaker': 'MIRIAM'}\n",
      "Last word -> MIRIAM : \"Would you excuse me? I have to use the ladies room? WHITE 10-23-09\"\n",
      "prediction :  You're welcome.\n",
      "Real answer : Would you excuse me? I have to use the ladies room? WHITE 10-23-09\n",
      "Bert Score : {'precision': [0.842341423034668], 'recall': [0.7942685484886169], 'f1': [0.8175989389419556], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 74.10636759224718\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRITA: Hello, Gordon-\\n\\n', 'answer': 'Don’t you fuckin’ hello me! You don’t have to work. You got an husband. My missus don’t have to. You do, ‘cause it’s nice. It’s a bit extra. But you don’t have to...I have to fuckin’ work. To pay the electric and the food and the coal. The fuckin’ basics. Only now I can’t. I can’t shift what ain’t there...You fuckin’ idiot.', 'gold_tag': \"GORDON is a working-class man burdened with financial responsibilities , GORDON is angry and frustrated , GORDON's work is closely tied to his ability to provide for himself and his wife, covering basic necessities such as electricity, food, and coal , GORDON is currently unable to work, causing distress as he cannot fulfill his financial obligations\", 'last_speaker': 'GORDON'}\n",
      "Last word -> GORDON : \"Don’t you fuckin’ hello me! You don’t have to work. You got an husband. My missus don’t have to. You do, ‘cause it’s nice. It’s a bit extra. But you don’t have to...I have to fuckin’ work. To pay the electric and the food and the coal. The fuckin’ basics. Only now I can’t. I can’t shift what ain’t there...You fuckin’ idiot.\"\n",
      "prediction :  Oh, hey there.\n",
      "Real answer : Don’t you fuckin’ hello me! You don’t have to work. You got an husband. My missus don’t have to. You do, ‘cause it’s nice. It’s a bit extra. But you don’t have to...I have to fuckin’ work. To pay the electric and the food and the coal. The fuckin’ basics. Only now I can’t. I can’t shift what ain’t there...You fuckin’ idiot.\n",
      "Bert Score : {'precision': [0.8306074142456055], 'recall': [0.7777420282363892], 'f1': [0.8033059239387512], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.02631578947368421, 'rouge2': 0.0, 'rougeL': 0.02631578947368421, 'rougeLsum': 0.02631578947368421}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 87.82959708675405\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGORDON: I feel as if we know each other from someplace...?\\nRITA: Try again, buster...!\\nGORDON: Ma'am, please! While I realize I look like something straight out you no harm. My name is Artemus Gordon. And you look like you're in trouble.\\nRITA: Really? I'm Rita. I was hired here as an entertainer. Not that I'm complaining, but what are you doin' in here?\\nGORDON: Looking for some missing scientists... not that I'm complaining. I'm a special U.S. Marshal on assignment from the President.\\n\\n\", 'answer': \"If you're so special, how come you're lookin' up here when Loveless has 'em all workin' down in the dungeon? Get me out of here and I'll take you down there.\", 'gold_tag': 'Rita is currently trapped and wants to get out of her current location', 'last_speaker': 'RITA'}\n",
      "Last word -> RITA : \"If you're so special, how come you're lookin' up here when Loveless has 'em all workin' down in the dungeon? Get me out of here and I'll take you down there.\"\n",
      "prediction :  Well, I'm glad I met you, Mr. Gordon. I think I'm in a bit of a fix here. I've been kidnapped, and I don't know how to get out of here.\n",
      "Real answer : If you're so special, how come you're lookin' up here when Loveless has 'em all workin' down in the dungeon? Get me out of here and I'll take you down there.\n",
      "Bert Score : {'precision': [0.8545656800270081], 'recall': [0.8227503299713135], 'f1': [0.8383562564849854], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2898550724637681, 'rouge2': 0.08955223880597016, 'rougeL': 0.1739130434782609, 'rougeLsum': 0.1739130434782609}\n",
      "bleu 1/2 : 0.16129032258064513 0.07332355751067662\n",
      "ppl : 5.386090358575353\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGORDON: Too late. The 'dungeon' is cleaned out. It was the first place I checked, right after I sampled the gumbo. Bit heavy on\\nRITA: Thank you... Artemus, was it?\\n\\n\", 'answer': \"One doesn't forget a smile like that. Now where in the world was it...? Have you ever played the Empire Room... the Bijou Cafe perhaps...?\", 'gold_tag': \"GORDON has memory abilities as he recalls events or people based on unique features , GORDON may have knowledge of or connections to entertainment venues like the Empire Room and the Bijou Cafe , RITA has a memorable smile , RITA is potentially a performer, given GORDON's question about her playing in certain venues\", 'last_speaker': 'GORDON'}\n",
      "Last word -> GORDON : \"One doesn't forget a smile like that. Now where in the world was it...? Have you ever played the Empire Room... the Bijou Cafe perhaps...?\"\n",
      "prediction :  Yes, that's right. Artemus Gordon. I'm an FBI agent.\n",
      "Real answer : One doesn't forget a smile like that. Now where in the world was it...? Have you ever played the Empire Room... the Bijou Cafe perhaps...?\n",
      "Bert Score : {'precision': [0.8350147008895874], 'recall': [0.8203428983688354], 'f1': [0.8276137709617615], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05405405405405406, 'rouge2': 0.0, 'rougeL': 0.05405405405405406, 'rougeLsum': 0.05405405405405406}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.496842105679608\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRITA: I won't let Loveless take me again! I'd rather be dead!\\nGORDON: That's not a good one to wish for. To defend herself, Rita grabs one of the sleeping-gas\\n\\n\", 'answer': \"Please, Artemus, don't leave me alone!\", 'gold_tag': 'RITA fears being left alone', 'last_speaker': 'RITA'}\n",
      "Last word -> RITA : \"Please, Artemus, don't leave me alone!\"\n",
      "prediction :  I'll kill him, I swear!\n",
      "Real answer : Please, Artemus, don't leave me alone!\n",
      "Bert Score : {'precision': [0.8657045364379883], 'recall': [0.8508676290512085], 'f1': [0.8582220077514648], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 32.430869053084216\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGEORGE: Mr.Dawson!\\n\\n', 'answer': 'One of ours, George.', 'gold_tag': 'MR. DAWSON recognizes a military aircraft , GEORGE and MR. DAWSON are observing and discussing a military event or situation together', 'last_speaker': 'MR.DAWSON'}\n",
      "Last word -> MR.DAWSON : \"One of ours, George.\"\n",
      "prediction :  Yes?\n",
      "Real answer : One of ours, George.\n",
      "Bert Score : {'precision': [0.8475058078765869], 'recall': [0.8327732682228088], 'f1': [0.8400750160217285], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 9554.816423904052\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGEORGE: Is he a coward?\\n\\n', 'answer': \"He's shell-shocked, George. He's not himself. He may never be himself again.\", 'gold_tag': 'MR. DAWSON is knowledgeable about the effects of war , MR. DAWSON may have been a soldier or closely involved with one', 'last_speaker': 'MR.DAWSON'}\n",
      "Last word -> MR.DAWSON : \"He's shell-shocked, George. He's not himself. He may never be himself again.\"\n",
      "prediction :  I don't think so, George. He's just a man who's lost his way.\n",
      "Real answer : He's shell-shocked, George. He's not himself. He may never be himself again.\n",
      "Bert Score : {'precision': [0.8740828037261963], 'recall': [0.8918023109436035], 'f1': [0.8828536868095398], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2580645161290323, 'rouge2': 0.1379310344827586, 'rougeL': 0.19354838709677422, 'rougeLsum': 0.19354838709677422}\n",
      "bleu 1/2 : 0.15384615384615385 0.11322770341445958\n",
      "ppl : 10.298346288858685\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMR.DAWSON: Spitfires, George. Greatest plane ever built.\\nGEORGE: You didn't even look.\\n\\n\", 'answer': 'Rolls Royce Merlin engines. Sweetest sound you could hear out here.', 'gold_tag': 'MR. DAWSON has an understanding of their technical details', 'last_speaker': 'MR.DAWSON'}\n",
      "Last word -> MR.DAWSON : \"Rolls Royce Merlin engines. Sweetest sound you could hear out here.\"\n",
      "prediction :  I didn't have to. I know that face.\n",
      "Real answer : Rolls Royce Merlin engines. Sweetest sound you could hear out here.\n",
      "Bert Score : {'precision': [0.8438394665718079], 'recall': [0.8273062705993652], 'f1': [0.8354911208152771], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 61.13402472303709\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAMMY: -- so I always just run out at 3:15 to pick him up and then run him real quick over to the sitter\\'s house. Anyway, Larry never minded about it and I was just hoping it would be OK with you too...\\nBRIAN: Well -- Samantha -- I realize that Scottsville is not exactly a major banking center...\\nSAMMY: No it\\'s not...\\nBRIAN: No -- I know it\\'s not... But it\\'s kind of a personal challenge to me to see what we can do to bring local service up to the same kinds of standards we\\'d be trying to meet if we were the biggest branch in the state. And that means I don\\'t want anybody running out at 3:15 or 3:30, or whenever the bus happens to come in that day. Now is there anybody else who can pick your son up after school? Does your husband work in the area? Do you --\\nSAMMY: Oh -- No -- Rudy Sr. isn\\'t \"on the\\nBRIAN: Well, I can give you a couple of days to make some other arrangement, but...\\nSAMMY: Well -- Brian? I understand what you\\'re saying, and I think it\\'s great. I do. Because there\\'s a lot of things around here that could use some attention. Believe me. But I\\'ve honestly been meeting that bus every day for four years now and it really does take just fifteen minutes, and if I take the time out of my lunch hour...\\nBRIAN: I\\'d really prefer it if you would make some other arrangement. OK?\\nSAMMY: I\\'ll do my best...!\\nBRIAN: How old\\'s your son?\\nSAMMY: He\\'s eight.\\n\\n', 'answer': \"That's a terrific age.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'BRIAN'}\n",
      "Last word -> BRIAN : \"That's a terrific age.\"\n",
      "prediction :  Eight. That's great! You know, I think I could help you out with that. I've got a wife and two kids of my own. And I'd like to help you get this job done, Samantha. How about it?\n",
      "Real answer : That's a terrific age.\n",
      "Bert Score : {'precision': [0.8285930156707764], 'recall': [0.8719991445541382], 'f1': [0.8497421145439148], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13043478260869565, 'rouge2': 0.045454545454545456, 'rougeL': 0.13043478260869565, 'rougeLsum': 0.13043478260869565}\n",
      "bleu 1/2 : 0.05263157894736841 0.0119267560832174\n",
      "ppl : 9.821609401239819\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRIAN: Yeah!\\nSAMMY: Um, Brian? Did you want us to turn this time sheet in at the end of the day, or do you want it at the end of the week...?\\nBRIAN: Oh, yeah, end of the day'll be fine.\\nSAMMY: Seems like an awful lot of extra paperwork...\\n\\n\", 'answer': 'I like paperwork.', 'gold_tag': 'BRIAN likes paperwork', 'last_speaker': 'BRIAN'}\n",
      "Last word -> BRIAN : \"I like paperwork.\"\n",
      "prediction :  I know, but it's easier for you guys if you have to deal with it.\n",
      "Real answer : I like paperwork.\n",
      "Bert Score : {'precision': [0.8492274880409241], 'recall': [0.8950583934783936], 'f1': [0.8715408444404602], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473684, 'rouge2': 0.0, 'rougeL': 0.10526315789473684, 'rougeLsum': 0.10526315789473684}\n",
      "bleu 1/2 : 0.06666666666666667 0.02182178902359924\n",
      "ppl : 23.72914262662628\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAMMY: Brian? Did you want to see me?\\nBRIAN: Yeah. I was kind of wondering what happened to you today.\\nSAMMY: Oh -- Didn't Mabel -- I had a false alarm about my son...\\nBRIAN: Yeah, I kind of thought you were gonna work that out.\\nSAMMY: Well, I did work it out -- more or less --\\nBRIAN: Then why're you running outta here in the middle of the day without a word of explanation to me, Sammy?\\nSAMMY: Brian, don't yell at me.\\nBRIAN: I'm -- I'm not yelling. I'm just gettin' a little frustrated here.\\nSAMMY: Well Brian:\\n\\n\", 'answer': 'Sorry, could you close the door please?', 'gold_tag': 'Everyday Language', 'last_speaker': 'BRIAN'}\n",
      "Last word -> BRIAN : \"Sorry, could you close the door please?\"\n",
      "prediction :  Yeah?\n",
      "Real answer : Sorry, could you close the door please?\n",
      "Bert Score : {'precision': [0.8637077808380127], 'recall': [0.8177211880683899], 'f1': [0.8400856256484985], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 4743.506449578175\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRIAN: Yeah. This doesn't apply to you directly, Sammy, but I've noticed that some of the employees have their PC monitors set with all kinds of crazy colors... Purple and polka dots or what have you. And it's not a big deal, but really, this is a bank. You know? It's not really appropriate. So I'm just asking that people stick to a more quote unquote normal range of colors in future... Like I say, it doesn't really apply to you.\\n\\n\", 'answer': \"No, my computer palette's pretty conservative.\", 'gold_tag': \"SAMMY is an employee at the bank, likely under BRIAN's supervision , SAMMY has a conservative computer color palette, suggesting a preference for subtlety or conformity in the workplace\", 'last_speaker': 'SAMMY'}\n",
      "Last word -> SAMMY : \"No, my computer palette's pretty conservative.\"\n",
      "prediction :  Yeah, okay.\n",
      "Real answer : No, my computer palette's pretty conservative.\n",
      "Bert Score : {'precision': [0.874556839466095], 'recall': [0.8626295328140259], 'f1': [0.8685522079467773], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 228.45859708546348\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAMMY: Brian, get off my ass!\\nBRIAN: Excuse me?\\nSAMMY: I didn't change the colors on your stupid computer screen.\\nBRIAN: Well, that's all you gotta say!\\nSAMMY: There is nothing wrong with the work I do here. I have been doing just fine, the whole time before you came here -- And if you think that riding people in this petty, ridiculous way is the way to improve service in this bank or anywhere else I think you're out of your mind!\\nBRIAN: I didn't say there was. Could I please -- Could I please -- May I respond?\\nSAMMY: No, that's really all I have to --\\nBRIAN: May I respond? First of all, I don't appreciate being spoken to with that kind of language. That's not the way I talk to you, and I'd appreciate it if you wouldn't talk that way to me --\\nSAMMY: Well --\\nBRIAN: Second of all, if you say you didn't change the colors on my computer screen, then of course I accept your answer. But you and I are gonna have to find a way to work together --\\nSAMMY: Brian --\\nBRIAN: But that's not gonna happen with the attitude, it's not gonna happen with the lateness, it's not gonna happen by fighting me every step of the way -- OK, well not you, you're not late, but too much of that stuff goes on around here --\\nSAMMY: I am not late and I do not have an attitude -- Well then don't tell me I'm late if I'm not late!\\n\\n\", 'answer': \"I'd really like to finish!\", 'gold_tag': 'Everyday Language', 'last_speaker': 'BRIAN'}\n",
      "Last word -> BRIAN : \"I'd really like to finish!\"\n",
      "prediction :  I'm sorry. I'm sorry I yelled at you.\n",
      "Real answer : I'd really like to finish!\n",
      "Bert Score : {'precision': [0.8672959804534912], 'recall': [0.8482402563095093], 'f1': [0.8576623201370239], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13.140428295738449\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRIAN: You're working late.\\nSAMMY: How did your wife like the bank?\\nBRIAN: Oh, fine. She wasn't feeling so great.\\nSAMMY: That's too bad.\\nBRIAN: No -- I don't mean -- She's not ill. She's just... I don't know...\\nSAMMY: Pregnant?\\nBRIAN: That's it. She's pregnant.\\nSAMMY: It can make you kind of cranky.\\nBRIAN: Yeah... Listen, I'm sorry we've been stepping on each other's toes -- I -- I'm not actually that bad a guy --\\nSAMMY: Yeah, I am too... I know you're not, Brian, but you're driving everybody crazy.\\nBRIAN: Well, I -- I'm just trying to do my best here -- And I'm gettin' it from all sides.\\nSAMMY: I know you are...\\nBRIAN: Anyway... We'll work it out...\\nSAMMY: Well... I could use a beer.\\n\\n\", 'answer': 'I could use a tranquilizer.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BRIAN'}\n",
      "Last word -> BRIAN : \"I could use a tranquilizer.\"\n",
      "prediction :  Yeah... I'll get you one.\n",
      "Real answer : I could use a tranquilizer.\n",
      "Bert Score : {'precision': [0.870596706867218], 'recall': [0.8717260360717773], 'f1': [0.8711610436439514], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1818181818181818, 'rouge2': 0.0, 'rougeL': 0.1818181818181818, 'rougeLsum': 0.1818181818181818}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 71.90918305857511\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAMMY: Last I heard, Rudy's Dad was living over in Auburn. But that was last year.\\nBRIAN: Must be so tough raising a kid on your own... Although I'm beginning to get the idea my wife wouldn't mind a crack at it.\\nSAMMY: Oh... It's just the hormones.\\nBRIAN: Well, no, it isn't. But never mind. Well, here's to improved employee- management relations.\\nSAMMY: Amen. You can't judge all of Scottsville by the people in that bank, believe me.\\nBRIAN: Well -- Let's -- Let's not talk about the bank.\\nSAMMY: OK.\\nBRIAN: Let's just forget about the bank for tonight.\\n\\n\", 'answer': 'Good idea.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SAMMY'}\n",
      "Last word -> SAMMY : \"Good idea.\"\n",
      "prediction :  I'm glad you're looking on the bright side.\n",
      "Real answer : Good idea.\n",
      "Bert Score : {'precision': [0.8582919836044312], 'recall': [0.9065608382225037], 'f1': [0.8817663192749023], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.940399947231196\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRIAN: Sammy?\\nSAMMY: Yeah?\\nBRIAN: I want you to tell me who changed the colors on my computer screen.\\n\\n', 'answer': \"I'll never tell.\", 'gold_tag': 'SAMMY likes to play pranks', 'last_speaker': 'SAMMY'}\n",
      "Last word -> SAMMY : \"I'll never tell.\"\n",
      "prediction :  I don't know.\n",
      "Real answer : I'll never tell.\n",
      "Bert Score : {'precision': [0.8514222502708435], 'recall': [0.8588728904724121], 'f1': [0.8551313281059265], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 52.19149636039691\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAMMY: Morning.\\nBRIAN: Yeah, good morning. Could you get the door?\\nSAMMY: Listen -- I just -- Brian, that's enough.\\n\\n\", 'answer': 'OK. Sorry.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BRIAN'}\n",
      "Last word -> BRIAN : \"OK. Sorry.\"\n",
      "prediction :  It's okay.\n",
      "Real answer : OK. Sorry.\n",
      "Bert Score : {'precision': [0.8734379410743713], 'recall': [0.9273036122322083], 'f1': [0.8995651602745056], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 87.14335918583589\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAMMY: Hello?\\nBRIAN: It's Brian.\\n\\n\", 'answer': 'Brian. Where are you?', 'gold_tag': 'Everyday Language', 'last_speaker': 'SAMMY'}\n",
      "Last word -> SAMMY : \"Brian. Where are you?\"\n",
      "prediction :  Oh, hey. Brian. How are you?\n",
      "Real answer : Brian. Where are you?\n",
      "Bert Score : {'precision': [0.8891820311546326], 'recall': [0.9205143451690674], 'f1': [0.9045768976211548], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.6, 'rouge2': 0.25, 'rougeL': 0.6, 'rougeLsum': 0.6}\n",
      "bleu 1/2 : 0.5 0.316227766016838\n",
      "ppl : 51.83815983941563\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRIAN: I'm buying milk. I just thought I'd say hello. Look, I know it's probably too late, but is there any way you can come out for a little while?\\nSAMMY: Brian, I think you're going crazy.\\nBRIAN: I know I am. Can you meet me?\\n\\n\", 'answer': 'Um, OK.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SAMMY'}\n",
      "Last word -> SAMMY : \"Um, OK.\"\n",
      "prediction :  No.\n",
      "Real answer : Um, OK.\n",
      "Bert Score : {'precision': [0.9456268548965454], 'recall': [0.8501726388931274], 'f1': [0.8953628540039062], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1275.3241709894667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAMMY: Sorry I'm so late.\\nBRIAN: Yeah, I was just about to give up on you.\\nSAMMY: Well -- maybe it would've been better if you had... I mean -- Look, I don't mean to be unsympathetic about your domestic situation, whatever it is, but I'm just beginning to think that if people tried a little harder to stick to their commitments and started taking a little responsibility for their actions, they might end up having a lot less trouble generally. That's all.\\nBRIAN: Hey, that's what I've been trying to tell you guys at the bank.\\nSAMMY: Well, I really don't think I can do this anymore.\\n\\n\", 'answer': 'OK.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BRIAN'}\n",
      "Last word -> BRIAN : \"OK.\"\n",
      "prediction :  What?\n",
      "Real answer : OK.\n",
      "Bert Score : {'precision': [0.8966867923736572], 'recall': [0.9651153087615967], 'f1': [0.9296435713768005], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAMMY: This is incredible.\\nBRIAN: Mmmm.\\n\\n', 'answer': 'That is not what I mean.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SAMMY'}\n",
      "Last word -> SAMMY : \"That is not what I mean.\"\n",
      "prediction :  Do you want to go somewhere else?\n",
      "Real answer : That is not what I mean.\n",
      "Bert Score : {'precision': [0.8357883095741272], 'recall': [0.8523921966552734], 'f1': [0.8440086245536804], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 25.871553012485826\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAMMY: What time is it?\\nBRIAN: What's the matter?\\nSAMMY: Oh my gosh.\\nBRIAN: Hey, you know, Nancy's gonna be gone for the rest of the week...\\nSAMMY: You know... Brian...\\nBRIAN: Yeah?\\nSAMMY: Well, I don't want to... I mean, couldn't we just... I mean, could we give it a rest?\\nBRIAN: Um -- Yeah. Sure. If you want to.\\nSAMMY: I mean... I just think... I don't know: We had a great little fling. You know? Let's not push it. I mean, is that OK? I just --\\nBRIAN: Yeah. Sure. OK. You're right.\\nSAMMY: So are we still friends?\\nBRIAN: Mm hm. Sure.\\n\\n\", 'answer': 'All right. Good...!', 'gold_tag': 'Everyday Language', 'last_speaker': 'SAMMY'}\n",
      "Last word -> SAMMY : \"All right. Good...!\"\n",
      "prediction :  What time is it?\n",
      "Real answer : All right. Good...!\n",
      "Bert Score : {'precision': [0.8093889355659485], 'recall': [0.8425336480140686], 'f1': [0.8256287574768066], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 61.731047094312395\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAMMY: Hello?\\nBRIAN: Yeah, it's Brian.\\nSAMMY: Brian --\\nBRIAN: What the hell happened to you today, lady?\\nSAMMY: Hello?\\nBRIAN: You're fired!\\n\\n\", 'answer': 'GOOD!', 'gold_tag': \"Sammy is fired by Brian , Sammy's reaction suggests she might be dissatisfied with her job\", 'last_speaker': 'SAMMY'}\n",
      "Last word -> SAMMY : \"GOOD!\"\n",
      "prediction :  Brian, I don't know what you're talking about.\n",
      "Real answer : GOOD!\n",
      "Bert Score : {'precision': [0.8017994165420532], 'recall': [0.8592681884765625], 'f1': [0.8295396566390991], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 10.645635275058876\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRIAN: Well... I'm sorry you're havin' all this trouble...\\nSAMMY: Thank you.\\nBRIAN: But you made a pretty good speech to me yesterday about people sticking to their commitments...\\nSAMMY: Yeah...?\\nBRIAN: Well... you made a commitment to this bank, Sammy. To this job.\\nSAMMY: I know I'd --\\nBRIAN: And to working things out with this tough new son of a bitch boss of yours. And whatever might have passed between us after hours doesn't mean you just walk away from that commitment -- yeah, even when you have a legitimate family emergency.\\nSAMMY: I'm really sorry I didn't --\\nBRIAN: Which is why I think in the calm cold light of day, we should both think real hard about whether or not you really want to continue on here at Merchants National Trust.\\nSAMMY: You're not serious.\\nBRIAN: ...you're not happy, I'm not happy, it's not good for you and it sure as heck isn't good for the bank.\\nSAMMY: You know you're the worst manager we've ever had?\\nBRIAN: Come on, Sammy...\\nSAMMY: By far the worst.\\nBRIAN: ...I don't wanna trade insults with you.\\nSAMMY: Well, I don't want to be fired, Brian. I've been working here for seven years.\\nBRIAN: Well --\\nSAMMY: And if I were you I'd be a little nervous about firing an employee I just had an affair with. OK?\\nBRIAN: That's -- Don't threaten me, Sammy: I'm not threatening you. I -- It's just an area I think we should explore.\\nSAMMY: I'm not thr -- You explore it. I'm going back to work. Oh, and I have to pick up Rudy today because there's no one else to do it. But I'll find someone as soon as I have time.\\n\\n\", 'answer': \"Yeah. Fine. Why don't you just take over the whole bank?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'BRIAN'}\n",
      "Last word -> BRIAN : \"Yeah. Fine. Why don't you just take over the whole bank?\"\n",
      "prediction :  I don't think I want to get involved in this.\n",
      "Real answer : Yeah. Fine. Why don't you just take over the whole bank?\n",
      "Bert Score : {'precision': [0.855541467666626], 'recall': [0.8687965273857117], 'f1': [0.8621180057525635], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17391304347826086, 'rouge2': 0.09523809523809525, 'rougeL': 0.17391304347826086, 'rougeLsum': 0.17391304347826086}\n",
      "bleu 1/2 : 0.09048374180359597 0.03016124726786533\n",
      "ppl : 12.40357069284077\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVENKMAN: I love this. We're onto something really big. I can smell it, Ray. We're going to make some headlines with this one.\\nSTANTZ: Hey, hey, hey, stresshound! Are you nuts? If anybody found out about this we'd be in serious trouble. The judge couldn't have been clearer - no ghostbusting.\\n\\n\", 'answer': \"Relax. We're going to keep this whole thing nice and quiet, low key, no profile.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'VENKMAN'}\n",
      "Last word -> VENKMAN : \"Relax. We're going to keep this whole thing nice and quiet, low key, no profile.\"\n",
      "prediction :  I know that, Ray. But this is different. We're not ghostbusting. We're just investigating a little matter of supernatural phenomena.\n",
      "Real answer : Relax. We're going to keep this whole thing nice and quiet, low key, no profile.\n",
      "Bert Score : {'precision': [0.8688759803771973], 'recall': [0.8634374737739563], 'f1': [0.8661481738090515], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15789473684210525, 'rouge2': 0.05555555555555555, 'rougeL': 0.10526315789473685, 'rougeLsum': 0.10526315789473685}\n",
      "bleu 1/2 : 0.10000000000000002 0.022941573387056175\n",
      "ppl : 12.896476640676992\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVENKMAN: Hey! Why don't you pick on someone your own size?\\nSTANTZ: On my signal, boys. Open 'em up -- Now!\\nVENKMAN: Spengs, take the door. Ray, let's try and work them down and into the corner.\\n\\n\", 'answer': \"Watch it! I'm coming under you, Pete. Steady -- watch your streams -- easy now -- Venky, bring him left -- Spengy, pull him down -- trapping -- trapping -- now!\", 'gold_tag': 'STANTZ takes charge and commands the team during their operation', 'last_speaker': 'STANTZ'}\n",
      "Last word -> STANTZ : \"Watch it! I'm coming under you, Pete. Steady -- watch your streams -- easy now -- Venky, bring him left -- Spengy, pull him down -- trapping -- trapping -- now!\"\n",
      "prediction :  You're right, Venkman. You're the man!\n",
      "Real answer : Watch it! I'm coming under you, Pete. Steady -- watch your streams -- easy now -- Venky, bring him left -- Spengy, pull him down -- trapping -- trapping -- now!\n",
      "Bert Score : {'precision': [0.8659437894821167], 'recall': [0.8134697079658508], 'f1': [0.8388869166374207], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06060606060606061, 'rouge2': 0.0, 'rougeL': 0.06060606060606061, 'rougeLsum': 0.06060606060606061}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 25.429494481028495\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVENKMAN: You know he ran that last lap in under six minutes?\\n\\n', 'answer': \"If he wasn't dead he'd be an Olympic prospect.\", 'gold_tag': 'STANTZ has knowledge in sports, especially on athletic capabilities', 'last_speaker': 'STANTZ'}\n",
      "Last word -> STANTZ : \"If he wasn't dead he'd be an Olympic prospect.\"\n",
      "prediction :  That’s a new world record.\n",
      "Real answer : If he wasn't dead he'd be an Olympic prospect.\n",
      "Bert Score : {'precision': [0.8562067747116089], 'recall': [0.8330518007278442], 'f1': [0.8444705605506897], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 95.41225554777375\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTANTZ: It's all yours, Pete. There's not much time left.\\n\\n\", 'answer': 'Okay, one, two, three, four --', 'gold_tag': 'Everyday Language', 'last_speaker': 'VENKMAN'}\n",
      "Last word -> VENKMAN : \"Okay, one, two, three, four --\"\n",
      "prediction :  I'm not sure that I can do it.\n",
      "Real answer : Okay, one, two, three, four --\n",
      "Bert Score : {'precision': [0.8247876167297363], 'recall': [0.7761014699935913], 'f1': [0.7997042536735535], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 20.98835924292872\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTANTZ: My Fault!\\n\\n', 'answer': \"She's new in town.\", 'gold_tag': 'VENKMAN knows the newcomer in town', 'last_speaker': 'VENKMAN'}\n",
      "Last word -> VENKMAN : \"She's new in town.\"\n",
      "prediction :  You're not in charge.\n",
      "Real answer : She's new in town.\n",
      "Bert Score : {'precision': [0.8796737194061279], 'recall': [0.8706685304641724], 'f1': [0.8751479983329773], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20000000000000004, 'rouge2': 0.0, 'rougeL': 0.20000000000000004, 'rougeLsum': 0.20000000000000004}\n",
      "bleu 1/2 : 0.25 0.09128709291752769\n",
      "ppl : 64.02243508267895\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKATHY: Listen...\\nTURNER: Lie down.\\nKATHY: Please.\\nTURNER: Lie down. Against the wall. You listen to me! I am tired. I need to close my eyes. I can't think straight! If you try to move or climb off the bed... I promise I'll hurt you.\\nKATHY: Can't you let me stay in the living room...?...I believe what you told me...\\nTURNER: Doesn't matter.\\nKATHY: I'll let you rest. Don't you have any friends to help you?\\nTURNER: Shut up.\\n\\n\", 'answer': '...Turner?', 'gold_tag': 'Everyday Language', 'last_speaker': 'KATHY'}\n",
      "Last word -> KATHY : \"...Turner?\"\n",
      "prediction :  I can't do anything to you.\n",
      "Real answer : ...Turner?\n",
      "Bert Score : {'precision': [0.8413386344909668], 'recall': [0.8183959722518921], 'f1': [0.8297087550163269], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 36.108879031816535\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTURNER: I thought it was that flare smell... ozone or gunpowder but it was her cigarette...\\nKATHY: Whose?\\nTURNER: ...burnt through her dress... into her skin -- who the hell chain-smokes anymore?!... and... Janice... What time is it?\\n\\n', 'answer': 'Newstime.', 'gold_tag': \"KATHY's immediate response to TURNER's question suggests she is attentive\", 'last_speaker': 'KATHY'}\n",
      "Last word -> KATHY : \"Newstime.\"\n",
      "prediction :  It's about ten past three.\n",
      "Real answer : Newstime.\n",
      "Bert Score : {'precision': [0.810102641582489], 'recall': [0.7953178882598877], 'f1': [0.8026421666145325], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 75.07471588887704\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTURNER: Listen, I\\'ll be going. In the morning.\\nKATHY: Where? Was it all right?\\nTURNER: All right?\\nKATHY: Outside; was it safe? Wherever you went? Revised Draft February 3, 1975 78.\\nTURNER: oh. I\\'m not sure.\\nKATHY: God I wish I knew more... About you... and yesterday. And today.\\nTURNER: I don\\'t remember yesterday. Today... it rained.\\nKATHY: Why\\'d you have to lock me up. He looks at her with a \"You know why.\" You thought I\\'d call the police....Would you have? He feels the answer is no; it almost shames him. I wouldn\\'t have.\\nTURNER: Why?\\nKATHY: Every once in a while I take a picture that isn\\'t like me. But I took it, so it is like me, it must be! I put those pictures away.\\nTURNER: Do you tear them up?\\nKATHY: ...No.\\nTURNER: I\\'d like to see those pictures.\\nKATHY: We don\\'t know each other that well.\\nTURNER: D\\'you know anybody that well?\\nKATHY: I don\\'t want to know you very well. I don\\'t think you\\'re going to live much longer.\\nTURNER: I may surprise you. Anyway: you\\'re not telling the truth.\\nKATHY: What do you mean?\\nTURNER: You\\'d rather be with someone who\\'s not going to live much longer... At least someone who\\'d be... on his way. The man in Vermont wants to stay. And you\\'re afraid.\\nKATHY: I\\'m not afraid of Ben.\\nTURNER: You joke. Instead of... taking it. You take pictures. Empty streets. November. Why haven\\'t you asked me to cut those tapes on your wrists.\\nKATHY: How... much... do you want?\\nTURNER: I just... want... to... stop it, for a few hours, for the rest of the night. And then I\\'ll go. In the morning.\\n\\n', 'answer': \"...That's almost no time at all... Between friends.\", 'gold_tag': \"KATHY's temporal information\", 'last_speaker': 'KATHY'}\n",
      "Last word -> KATHY : \"...That's almost no time at all... Between friends.\"\n",
      "prediction :  How do I know you're not going to leave me?\n",
      "Real answer : ...That's almost no time at all... Between friends.\n",
      "Bert Score : {'precision': [0.8244516849517822], 'recall': [0.8275173306465149], 'f1': [0.8259816765785217], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 21.44283052907892\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKATHY: Y'didn't sleep well.\\nTURNER: You didn't?\\nKATHY: You didn't. You were up early.\\nTURNER: I had some thoughts... I, uh, have a plan that might work. I... need your help.\\nKATHY: Have I ever denied you anything??\\nTURNER: Hey...\\nKATHY: When things quiet down... you're really a sweet man to be with. You had bad dream. You talked.\\nTURNER: What did I say?\\nKATHY: Who's Janice? Was she a volunteer or a draftee like me?\\nTURNER: She was a friend. She's dead.\\nKATHY: Do I have Permission to take a shower?\\nTURNER: You don't have to help, you know.\\nKATHY: Don't worry, you can always count on the old spy-fucker.\\nTURNER: I'm sorry.\\n\\n\", 'answer': \"I didn't mean... I can't help it. I... do that. I... want to help. OK?\", 'gold_tag': 'KATHY is altruistic as she chooses to help TURNER despite her initial reluctance', 'last_speaker': 'KATHY'}\n",
      "Last word -> KATHY : \"I didn't mean... I can't help it. I... do that. I... want to help. OK?\"\n",
      "prediction :  You should be.\n",
      "Real answer : I didn't mean... I can't help it. I... do that. I... want to help. OK?\n",
      "Bert Score : {'precision': [0.8563821911811829], 'recall': [0.8023843765258789], 'f1': [0.8285043835639954], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 368.2986146757505\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKATHY: What is it...\\nTURNER: It's... it goes all the way up to Langley!\\nKATHY: What??\\n\\n\", 'answer': 'Get ready. Hurry!', 'gold_tag': 'TURNER is in a hurry, indicating an urgent situation', 'last_speaker': 'TURNER'}\n",
      "Last word -> TURNER : \"Get ready. Hurry!\"\n",
      "prediction :  I'm afraid so...\n",
      "Real answer : Get ready. Hurry!\n",
      "Bert Score : {'precision': [0.8209636211395264], 'recall': [0.868323564529419], 'f1': [0.8439797163009644], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 129.72966255137297\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTURNER: That's all I reported: the stories were being translated into this odd group of languages. Query: is there an intelligence-network -- previously undetected by CIA -- linking certain Arabic-speaking countries with Spanish and Dutch speaking.\\nKATHY: Who wrote the stories in the first place?\\nTURNER: Different phony names. That's not unusual.\\nKATHY: ...Maybe you ought to run....instead of this.\\nTURNER: They figure me to run.\\n\\n\", 'answer': 'Spies...', 'gold_tag': 'Everyday Language', 'last_speaker': 'KATHY'}\n",
      "Last word -> KATHY : \"Spies...\"\n",
      "prediction :  Who's they?\n",
      "Real answer : Spies...\n",
      "Bert Score : {'precision': [0.8473274111747742], 'recall': [0.8223690986633301], 'f1': [0.8346617221832275], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 245.86853482702898\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKATHY: You're not exactly an ideal boyfriend, you know.\\n\\n\", 'answer': 'Can we get this over with? Kathy. Thank you.', 'gold_tag': 'TURNER shows impatience , TURNER suggests a lack of interest or emotional investment in the conversation with KATHY', 'last_speaker': 'TURNER'}\n",
      "Last word -> TURNER : \"Can we get this over with? Kathy. Thank you.\"\n",
      "prediction :  I'm not exactly an ideal boyfriend, you know.\n",
      "Real answer : Can we get this over with? Kathy. Thank you.\n",
      "Bert Score : {'precision': [0.8373751640319824], 'recall': [0.8167568445205688], 'f1': [0.8269374966621399], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 33.849057117939815\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKATHY: D'you trust him? Revised Draft February 3, 1975 104. Reaching into his pocket for money, Turner feels that key he\\nTURNER: I don't know... He called me Turner -- instead of Condor. He didn't insist on that codename crap. Maybe he's not... 100% pre-sold: Company Man.\\nKATHY: Does he trust you?\\nTURNER: No. He's in the suspicion-business.\\nKATHY: That's what I mean: they're all... real spies! How could anybody, you know, sneak in? And fool them?\\nTURNER: Nobody did.\\nKATHY: Then...?\\n\\n\", 'answer': \"What if there's another CIA? Inside the CIA.\", 'gold_tag': 'TURNER is a critical thinker, considering the possibility of a CIA within the CIA', 'last_speaker': 'TURNER'}\n",
      "Last word -> TURNER : \"What if there's another CIA? Inside the CIA.\"\n",
      "prediction :  He's a Company Man.\n",
      "Real answer : What if there's another CIA? Inside the CIA.\n",
      "Bert Score : {'precision': [0.8835625648498535], 'recall': [0.8737431168556213], 'f1': [0.8786253929138184], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 119.81555536825248\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTURNER: I didn't know you smoked.\\nKATHY: I quit years ago. You're pale.\\nTURNER: ...light in here.\\nKATHY: What are you going to do there?\\nTURNER: See a guy.\\nKATHY: More secrets. What's so hot about keeping secrets? It's just... unfriendly. That's all.\\nTURNER: Like hiding those pictures.\\nKATHY: Yes. Some day, I'd like to show them to you... in case you live through this.\\nTURNER: I'd like to see them. Could you live through that?\\nKATHY: Yes, I could. Now. Thanks. Then SUDDENLY, an almost hopeful thought.\\nTURNER: You could drive me to Washington.\\nKATHY: No. I couldn't. You have a lot of fine qualities but... I don't treat myself great, exactly, but I don't go out of my way to get myself machine-gunned, either.\\nTURNER: What fine qualities?\\nKATHY: You have good eyes. Not kind, but they don't seem to lie or look away much. And they don't miss anything. I could use eyes like that.\\nTURNER: But you're... overdue in Vermont. Is he a tough guy?\\nKATHY: He's pretty tough.\\nTURNER: What will he do to you?\\nKATHY: ...understand, probably.\\nTURNER: Oh... that is tough. Kathy... I need time.\\nKATHY: Hm??\\nTURNER: 8 hours at least until noon tomorrow.\\nKATHY: So?\\nTURNER: You've to give me that much time. I mean... don't call anybody right now, or -- She can't believe it! Her eves FILL. She manages the palest\\nKATHY: Oh boy...!\\nTURNER: Will you take care of yourself.\\nKATHY: Do my best.\\nTURNER: Do your best.\\n\\n\", 'answer': 'Will you take care of yourself?', 'gold_tag': 'Everyday Language', 'last_speaker': 'KATHY'}\n",
      "Last word -> KATHY : \"Will you take care of yourself?\"\n",
      "prediction :  Kathy.\n",
      "Real answer : Will you take care of yourself?\n",
      "Bert Score : {'precision': [0.9244800806045532], 'recall': [0.8241117000579834], 'f1': [0.8714153170585632], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 784.4462284242877\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOM: So he bought this Peugeot sedan at a greatly reduced price while he was there in charge of the White House Advance Team.\\nJENNIFER: How come you're not chasing it down yourself?\\nTOM: Look, I'm junior man -- and it's your beat.\\nJENNIFER: Boy, that's nice...I wish we could all deal with each other like this. I'll check it. Anything I can do for you?\\nTOM: This is my first time at the White House. Is there any chance to look at where he works and the rest of it?\\n\\n\", 'answer': \"I didn't have the guts to ask when I first came up. I'll get you a great tour.\", 'gold_tag': 'JENNIFER is an investigative reporter who has previously covered the White House and has been there before', 'last_speaker': 'JENNIFER'}\n",
      "Last word -> JENNIFER : \"I didn't have the guts to ask when I first came up. I'll get you a great tour.\"\n",
      "prediction :  Sure.\n",
      "Real answer : I didn't have the guts to ask when I first came up. I'll get you a great tour.\n",
      "Bert Score : {'precision': [0.9191806316375732], 'recall': [0.8332825303077698], 'f1': [0.8741264343261719], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 940.7736565945374\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJENNIFER: Damn all you sons-of-bitches. Oh shit, you bastards... Sorry.\\nTOM: No, it's okay...People say different things. They do...the plural threw me.\\nJENNIFER: The last time I was with someone we went through this awful mutual disease questionnaire but I guess it beats getting paranoid the next day. Okay, I'll go first. I haven't...\\nTOM: It would never occur to me to worry at all about you.\\nJENNIFER: You know something? I'm deeply complimented. Isn't it strange to be deeply complimented because the man you're with doesn't think you have a venereal disease?... Give me some of that.\\nTOM: Where's the bathroom?\\n\\n\", 'answer': 'Through the closet.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JENNIFER'}\n",
      "Last word -> JENNIFER : \"Through the closet.\"\n",
      "prediction :  Now I feel like I'm doing something. I'm a nurse, you know.\n",
      "Real answer : Through the closet.\n",
      "Bert Score : {'precision': [0.8466936349868774], 'recall': [0.881126344203949], 'f1': [0.8635668754577637], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.158643679181528\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJENNIFER: I converted a bedroom -- this stuff builds up. Wait till you've been doing this sixteen\\nTOM: I'm not knocking it. It's a great solution. Not only the storage but you can see everything you have.\\nJENNIFER: Do you do bunny rabbits?\\n\\n\", 'answer': \"Isn't this a great date?\", 'gold_tag': 'TOM refers to his conversation with JENNIFER as a date, indicating they are likely engaging in a romantic relationship', 'last_speaker': 'TOM'}\n",
      "Last word -> TOM : \"Isn't this a great date?\"\n",
      "prediction :  I'm sorry?\n",
      "Real answer : Isn't this a great date?\n",
      "Bert Score : {'precision': [0.7987524271011353], 'recall': [0.8351736068725586], 'f1': [0.8165571093559265], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 148.0084184543845\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRUSTY: Okay. Tell me about Benedict.\\n\\n', 'answer': 'The guy is a machine.', 'gold_tag': 'LINUS perceives Benedict as a machine , LINUS views people in terms of their characteristics or behavior', 'last_speaker': 'LINUS'}\n",
      "Last word -> LINUS : \"The guy is a machine.\"\n",
      "prediction :  He's a 43-year-old guy, a little over six feet tall, with a big nose, and he's got a mustache.\n",
      "Real answer : The guy is a machine.\n",
      "Bert Score : {'precision': [0.8431918621063232], 'recall': [0.9094983339309692], 'f1': [0.8750908374786377], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.05263157894736841 0.017099639201419235\n",
      "ppl : 8.039907527405308\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINUS: Give him another ten seconds. As I said: a machine.\\nRUSTY: And that portfolio contains the codes to all the cage doors?\\nLINUS: Two minutes after they've been changed, he's got 'em in hand. I'll tell you: you guys picked a helluva target. He is as smart and ruthless as they come. The last guy caught cheating here, Benedict not only sent him up for ten years, he got the bank to seize the guy's home and bankrupted --\\nRUSTY: -- his brother-in-law's tractor dealership, I heard.\\nLINUS: He doesn't just go after your knees, he goes after your livelihood. And everyone-you- ever-met's livelihood.\\nRUSTY: You scared?\\nLINUS: You suicidal?\\nRUSTY: Only in the morning. Now what?\\n\\n\", 'answer': \"Now comes the girl... if she comes The museum downstairs. She's the curator there. Wait... here she is. You'll like this.\", 'gold_tag': 'LINUS mentions a future event where a woman, the curator, will arrive', 'last_speaker': 'LINUS'}\n",
      "Last word -> LINUS : \"Now comes the girl... if she comes The museum downstairs. She's the curator there. Wait... here she is. You'll like this.\"\n",
      "prediction :  Well, what do you think?\n",
      "Real answer : Now comes the girl... if she comes The museum downstairs. She's the curator there. Wait... here she is. You'll like this.\n",
      "Bert Score : {'precision': [0.8422285318374634], 'recall': [0.8198009729385376], 'f1': [0.8308634757995605], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07142857142857142, 'rouge2': 0.0, 'rougeL': 0.07142857142857142, 'rougeLsum': 0.07142857142857142}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 21.228332195861533\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINUS: I don't know if we can use her yet. I haven't even caught her name.\\nRUSTY: Tess.\\nLINUS: What?\\n\\n\", 'answer': 'certain and very Her name is Tess.', 'gold_tag': 'Everyday Language', 'last_speaker': 'RUSTY'}\n",
      "Last word -> RUSTY : \"certain and very Her name is Tess.\"\n",
      "prediction :  You heard me.\n",
      "Real answer : certain and very Her name is Tess.\n",
      "Bert Score : {'precision': [0.8626043200492859], 'recall': [0.8072331547737122], 'f1': [0.8340007066726685], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 348.4536192637113\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIMBLE: Dug it out of the trash. My guess is that he still pulls down a check every couple weeks.\\nADELLE: Pennsylvania...\\nKIMBLE: He worked there, which means there are more records there -- which means maybe we can place him near Stafford the week of the murder.\\nADELLE: You think that's enough? To convince a district attorney?\\nKIMBLE: It's all I have. Will you help?\\nADELLE: Mulberries. Dad went after deer, we went after berries -- it was the only kind of hunting we could bring ourselves to do. Oh, he used to get so mad when we'd have mulberries for dinner instead of venison... I tried to put things behind me after the trial, Richard -- those accusations, and just... everything. I haven't been back to Stafford since.\\nKIMBLE: You're saying you don't want to get involved?\\nADELLE: Don't make it sound like that.\\nKIMBLE: Well, what is it? You still aren't sure? After all this --\\nADELLE: It's not you, Richard. I know you didn't do it. It's just that I've got my own issues -- which I'll deal with when the time comes, I suppose. Cold in here, isn't it? What? Something she said, the way she said it: For a moment\\nKIMBLE: Nothing. You're a lot like her.\\n\\n\", 'answer': 'Sometimes I wonder just how much.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ADELLE'}\n",
      "Last word -> ADELLE : \"Sometimes I wonder just how much.\"\n",
      "prediction :  You're not supposed to say things like that.\n",
      "Real answer : Sometimes I wonder just how much.\n",
      "Bert Score : {'precision': [0.8395506143569946], 'recall': [0.8381589651107788], 'f1': [0.838854193687439], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.446371189461313\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADELLE: What's wrong?\\n\\n\", 'answer': \"Didn't mean to fall asleep like that... Let's get moving.\", 'gold_tag': 'KIMBLE is in a somnolent state, unintentionally falling asleep , KIMBLE has just woken up from his unintentional sleep', 'last_speaker': 'KIMBLE'}\n",
      "Last word -> KIMBLE : \"Didn't mean to fall asleep like that... Let's get moving.\"\n",
      "prediction :  You know how it is, I'm just a little tired.\n",
      "Real answer : Didn't mean to fall asleep like that... Let's get moving.\n",
      "Bert Score : {'precision': [0.8497055768966675], 'recall': [0.8539980053901672], 'f1': [0.8518463373184204], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 17.317936294472045\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADELLE: So how do I contact you?\\nKIMBLE: You don't. Give me your pager number. I'll check in when I can. But never call back on a private line.\\nADELLE: You really think would --\\nKIMBLE: Assume they are.\\nADELLE: So what do you do now?\\n\\n\", 'answer': 'I go back to Boston and stick with this guy day and night -- and see who makes the first mistake.', 'gold_tag': \"KIMBLE's plan to go back to Boston implies initiative and resourcefulness , KIMBLE is planning to return to Boston where he will observe a man constantly to detect any mistakes\", 'last_speaker': 'KIMBLE'}\n",
      "Last word -> KIMBLE : \"I go back to Boston and stick with this guy day and night -- and see who makes the first mistake.\"\n",
      "prediction :  Now, I'm going to go back to my life.\n",
      "Real answer : I go back to Boston and stick with this guy day and night -- and see who makes the first mistake.\n",
      "Bert Score : {'precision': [0.8748880624771118], 'recall': [0.846199095249176], 'f1': [0.8603044748306274], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.26666666666666666, 'rouge2': 0.14285714285714285, 'rougeL': 0.26666666666666666, 'rougeLsum': 0.26666666666666666}\n",
      "bleu 1/2 : 0.08786571270524224 0.07609393932436488\n",
      "ppl : 22.20283988400295\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADELLE: I'm not sure. I'm at A.P. now, doing some background work on -- INTERCUTTING:\\nKIMBLE: Forget that -- he's coming to Philly. You gotta leave now.\\nADELLE: Is it him?\\nKIMBLE: When you see him, he'll have a right arm -- an artificial arm.\\nADELLE: Then how do I --\\n\\n\", 'answer': \"Forty years old, khaki overcoat, I'm coming as soon as I can, but don't let him out of your sight. Now go.\", 'gold_tag': 'KIMBLE knows specific details about a person of interest, including age and appearance , KIMBLE is planning to join Adelle in tracking the individual as soon as he can , ADELLE needs to leave her current location immediately to track a person of interest in Philadelphia', 'last_speaker': 'KIMBLE'}\n",
      "Last word -> KIMBLE : \"Forty years old, khaki overcoat, I'm coming as soon as I can, but don't let him out of your sight. Now go.\"\n",
      "prediction :  You gotta get out of here, now!\n",
      "Real answer : Forty years old, khaki overcoat, I'm coming as soon as I can, but don't let him out of your sight. Now go.\n",
      "Bert Score : {'precision': [0.8770642876625061], 'recall': [0.8398990631103516], 'f1': [0.8580794334411621], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.19354838709677416, 'rouge2': 0.06896551724137931, 'rougeL': 0.19354838709677416, 'rougeLsum': 0.19354838709677416}\n",
      "bleu 1/2 : 0.03351976174121451 0.025601140909333377\n",
      "ppl : 29.80854744408451\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIMBLE: He's inside?\\nADELLE: Good, you keep doing that.\\nKIMBLE: Where is he?\\nADELLE: Room 130. East wing. Checked in 45 minutes ago and hasn't come out.\\nKIMBLE: But he's alone?\\nADELLE: Came in that way, but...\\n\\n\", 'answer': 'Stay here.', 'gold_tag': 'KIMBLE suggests a possible law enforcement or investigative role', 'last_speaker': 'KIMBLE'}\n",
      "Last word -> KIMBLE : \"Stay here.\"\n",
      "prediction :   But what?\n",
      "Real answer : Stay here.\n",
      "Bert Score : {'precision': [0.8269294500350952], 'recall': [0.8954623937606812], 'f1': [0.8598324656486511], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 829.166382293813\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADELLE: Oh, God, what --\\nKIMBLE: Lock it. Lock the door. Search him. Look for a phone number. Search him. She pulls what she can off the body as Kimble pounds on\\nADELLE: Those people. They'll call the police.\\nKIMBLE: Not gonna let him die. Not now.\\nADELLE: But... he is dead.\\nKIMBLE: Nah. He just thinks he is. He works rhythmically yet maniacally, trying to save the man who murdered his wife, tug-of-warring with God for a few more minutes of life. Soon RISING SIRENS.\\nADELLE: Enough. We have to go. Enough, Richard! He's dead! Just leave him and get out of here bef --\\n\\n\", 'answer': \"Who is it, Sykes? Who were you gonna meet? impossibly for escape. Not gettin' away, not this time. Your lungs are shot -- literally. You can't breathe on your own. Now I'll give you a breath -- but when you exhale, I want somethin' back. I want a name. You're fuckin' with me, Sykes. You're thinking I won't let you die. But I'm not a doctor, not anymore -- and even if I was, I still might get a kick outta seein' you check out twice. So you wanna try this again or not? Okay. Last chance for a good room in hell. Who is it? The mouth opens to reveal its secret -- but instead of\", 'gold_tag': 'KIMBLE is a former doctor , KIMBLE is willing to be ruthless in his pursuit', 'last_speaker': 'KIMBLE'}\n",
      "Last word -> KIMBLE : \"Who is it, Sykes? Who were you gonna meet? impossibly for escape. Not gettin' away, not this time. Your lungs are shot -- literally. You can't breathe on your own. Now I'll give you a breath -- but when you exhale, I want somethin' back. I want a name. You're fuckin' with me, Sykes. You're thinking I won't let you die. But I'm not a doctor, not anymore -- and even if I was, I still might get a kick outta seein' you check out twice. So you wanna try this again or not? Okay. Last chance for a good room in hell. Who is it? The mouth opens to reveal its secret -- but instead of\"\n",
      "prediction :  He's not dead. He's not dead. He's not dead.\n",
      "Real answer : Who is it, Sykes? Who were you gonna meet? impossibly for escape. Not gettin' away, not this time. Your lungs are shot -- literally. You can't breathe on your own. Now I'll give you a breath -- but when you exhale, I want somethin' back. I want a name. You're fuckin' with me, Sykes. You're thinking I won't let you die. But I'm not a doctor, not anymore -- and even if I was, I still might get a kick outta seein' you check out twice. So you wanna try this again or not? Okay. Last chance for a good room in hell. Who is it? The mouth opens to reveal its secret -- but instead of\n",
      "Bert Score : {'precision': [0.8417890071868896], 'recall': [0.7820490598678589], 'f1': [0.8108201622962952], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.04580152671755725, 'rouge2': 0.0, 'rougeL': 0.04580152671755725, 'rougeLsum': 0.04580152671755725}\n",
      "bleu 1/2 : 2.0480707844427363e-06 3.96607202000034e-07\n",
      "ppl : 7.987204350955293\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIMBLE: He was extorting someone. Or trying to. All I needed was name... a number... a fucking zip code, I don't care, just something to... State Disability. Did you check?\\nADELLE: They wouldn't give me anything. It's all confidential.\\nKIMBLE: What about A.P.? You said you were there.\\nADELLE: Just one reference. 1983.\\nKIMBLE: But what was it?\\n\\n\", 'answer': 'We can drive up this fire-break for another mile, mile and a half. Then I know this trail that leads back down and hooks up with the', 'gold_tag': 'Adelle is familiar with navigating difficult terrains', 'last_speaker': 'ADELLE'}\n",
      "Last word -> ADELLE : \"We can drive up this fire-break for another mile, mile and a half. Then I know this trail that leads back down and hooks up with the\"\n",
      "prediction :  It was a person.\n",
      "Real answer : We can drive up this fire-break for another mile, mile and a half. Then I know this trail that leads back down and hooks up with the\n",
      "Bert Score : {'precision': [0.8667397499084473], 'recall': [0.7978083491325378], 'f1': [0.8308467268943787], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0625, 'rouge2': 0.0, 'rougeL': 0.0625, 'rougeLsum': 0.0625}\n",
      "bleu 1/2 : 0.0007956951991274167 0.00029054680630710076\n",
      "ppl : 317.88272020743364\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIMBLE: I'm not leaving. She was afraid he'd say that.\\nADELLE: People saw you, Richard. They'll be coming for you.\\nKIMBLE: I'm not leaving. He came here for a reason.\\nADELLE: Richard. Please. Let's get out while we can.\\nKIMBLE: You go. But if I run now, it never stops. It never ends for me. I'll never be closer than this, and I either find out, now, who he came to see or --\\nADELLE: I just don't want anyone else to die. The havoc in her voice came from somewhere else -- from\\nKIMBLE: What is it? What'd you find out?\\nADELLE: Christ, I didn't want to come back to this place... didn't want to open it all up...\\n\\n\", 'answer': 'Adelle. What do you know?', 'gold_tag': 'Everyday Language', 'last_speaker': 'KIMBLE'}\n",
      "Last word -> KIMBLE : \"Adelle. What do you know?\"\n",
      "prediction :  Open it up?\n",
      "Real answer : Adelle. What do you know?\n",
      "Bert Score : {'precision': [0.852433979511261], 'recall': [0.8433555960655212], 'f1': [0.8478704690933228], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 813.2560381082715\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJULIET: Mummy! Mummy!\\n\\n', 'answer': \"Mummy! (Panicked) She's terribly hurt . . .\", 'gold_tag': 'PAULINE is panicked , Someone is terribly hurt', 'last_speaker': 'PAULINE'}\n",
      "Last word -> PAULINE : \"Mummy! (Panicked) She's terribly hurt . . .\"\n",
      "prediction :  Yes?\n",
      "Real answer : Mummy! (Panicked) She's terribly hurt . . .\n",
      "Bert Score : {'precision': [0.8317601680755615], 'recall': [0.7996317744255066], 'f1': [0.8153796195983887], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 9554.816423904052\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJULIET: (V.0.) Mummy and Daddy sent me to the Bahamas to recuperate. I didn't see them for five years-but we're together now and Mummy's promised they'll never leave me again.\\n\\n\", 'answer': '(V.0.) I spent ages in hospital, too . . . with my leg. I had to have all these operations.', 'gold_tag': 'PAULINE has spent a significant amount of time in a hospital , The hospital stays were due to complications with her leg , The complications required multiple operations', 'last_speaker': 'PAULINE'}\n",
      "Last word -> PAULINE : \"(V.0.) I spent ages in hospital, too . . . with my leg. I had to have all these operations.\"\n",
      "prediction :  (V.0.) That's wonderful, Juliet.\n",
      "Real answer : (V.0.) I spent ages in hospital, too . . . with my leg. I had to have all these operations.\n",
      "Bert Score : {'precision': [0.913366436958313], 'recall': [0.8576877117156982], 'f1': [0.8846518993377686], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0909090909090909, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.004578909722183545 0.0016719814290797606\n",
      "ppl : 117.45794792027591\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAULINE: Osteomyelitus turns your bones to chalk. It took them two years to drain all the muck out.\\n\\n', 'answer': \"Cheer up! All the best people have bad chests and bone diseases! It's all frightfully romantic!\", 'gold_tag': 'JULIET perceives illnesses as something romantic', 'last_speaker': 'JULIET'}\n",
      "Last word -> JULIET : \"Cheer up! All the best people have bad chests and bone diseases! It's all frightfully romantic!\"\n",
      "prediction :  You were there.\n",
      "Real answer : Cheer up! All the best people have bad chests and bone diseases! It's all frightfully romantic!\n",
      "Bert Score : {'precision': [0.8851673007011414], 'recall': [0.8092976808547974], 'f1': [0.8455339670181274], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 382.66347686331426\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJULIET: Hi, Paul! 0www! The evil Prince Runnymeade is escaping! Get him, Paul! The blighter's gone to ground! God! Jonty! Jonty-stop it! Go away! We're not playing anymore . . . go on, bugger off! 0h, God . . . I'm so sorry! Of course it matters! It's Mario! (O.S.) Mother! Jonty broke Paul's record! We must buy her another one!\\nPAULINE: No, thank you.\\n\\n\", 'answer': \"Which one shall we play? Daddy can study while we're playing records!\", 'gold_tag': \"JULIET enjoys playing imaginary games , JULIET respects her father's study time , JULIET enjoys playing records\", 'last_speaker': 'JULIET'}\n",
      "Last word -> JULIET : \"Which one shall we play? Daddy can study while we're playing records!\"\n",
      "prediction :  . . . What? Oh, no. No, no, no. We mustn't. We mustn't.\n",
      "Real answer : Which one shall we play? Daddy can study while we're playing records!\n",
      "Bert Score : {'precision': [0.8279533386230469], 'recall': [0.824087381362915], 'f1': [0.826015830039978], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16, 'rouge2': 0.0, 'rougeL': 0.16, 'rougeLsum': 0.16}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 9.950285288713202\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJULIET: Daddy says the Bible's a load of bunkum!\\nPAULINE: But, we're all going to Heaven!\\nJULIET: I'm not! I'm going to the Fourth World! It's like Heaven, only better because there aren't any Christians. It's an absolute Paradise of music, art and enjoyment. James will be there . . . and Mario! Only they'll be saints.\\nPAULINE: (Giggling) Saint Mario!\\nJULIET: To be known as He!\\nPAULINE: He . . .\\nJULIET: Him.\\nPAULINE: Him . . .\\nJULIET: This.\\nPAULINE: This . . .\\nJULIET: That.\\nPAULINE: That . . . It.\\n\\n\", 'answer': 'Absolutely not! Orson Welles! The most hideous man alive! We give praise to . . . the saints!', 'gold_tag': 'JULIET dislikes Orson Welles', 'last_speaker': 'JULIET'}\n",
      "Last word -> JULIET : \"Absolutely not! Orson Welles! The most hideous man alive! We give praise to . . . the saints!\"\n",
      "prediction :  It.\n",
      "Real answer : Absolutely not! Orson Welles! The most hideous man alive! We give praise to . . . the saints!\n",
      "Bert Score : {'precision': [0.9165542125701904], 'recall': [0.7988561391830444], 'f1': [0.8536674380302429], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 4261.392667540272\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAULINE: I think I'm going crazy.\\nJULIET: No, you're not, Gina-it's everybody else who is bonkers!\\nPAULINE: Let's go overseas . . .\\nJULIET: You mean travel by ourselves? Where shall we go? Not the Bahamas; it's bloody awful! (Excited) Of course! It's so obvious! (O.S.) I know . . . I'll lean back and put my hair on my shoulders-then I'll look just like Veronica Lake!\\nPAULINE: (O.S.) Stay still or they'll be blurry . . .\\nJULIET: (O.S.) Hurry up! I'm freezing!\\nPAULINE: (O.S.) Just a couple more . . .\\nJULIET: (O.S.) I know, I'll lean forward and show more cleavage!\\nPAULINE: (Whispers) I'm sure they'll notice things missing.\\nJULIET: (Whispers) They'll blame the bloody housekeeper. She nicks stuff all the times! This lot's got to be worth 50 quid!\\nPAULINE: I can try my father's safe. I'm sure I can get the keys to his office.\\n\\n\", 'answer': \"That's great! We'll have the fare in no time!\", 'gold_tag': 'Everyday Language', 'last_speaker': 'JULIET'}\n",
      "Last word -> JULIET : \"That's great! We'll have the fare in no time!\"\n",
      "prediction :  (Whispers) Oh, Pauline, don't be so bloody foolish!\n",
      "Real answer : That's great! We'll have the fare in no time!\n",
      "Bert Score : {'precision': [0.8221824765205383], 'recall': [0.8232418298721313], 'f1': [0.8227118253707886], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.204417288247914\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAULINE: (Diary V.O.) I rose at 5:30 this morning and did housework before 8 o'clock, including taking Wendy her breakfast in bed. I feel very pleased with myself on the whole and also the future. (Diary V.O.) We are so brilliantly clever.\\nJULIET: Direct hit! Gave his trousers a good soaking! Everyone will think he's peed himself!\\nPAULINE: I thought he was supposed to be terribly ill.\\n\\n\", 'answer': '(Sarcastic) That was what we were led to believe . . .', 'gold_tag': 'JULIET has a sarcastic attitude', 'last_speaker': 'JULIET'}\n",
      "Last word -> JULIET : \"(Sarcastic) That was what we were led to believe . . .\"\n",
      "prediction :  He's ill all right. He's ill with fright!\n",
      "Real answer : (Sarcastic) That was what we were led to believe . . .\n",
      "Bert Score : {'precision': [0.8266741633415222], 'recall': [0.8136065006256104], 'f1': [0.8200882077217102], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 45.88371967657639\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJULIET: (V.O.) There's something desperately exciting about bodies on stretchers . . . (Regretfully) But it wasn't like that at all! Poor Mother was completely taken in.\\nPAULINE: Do you think Bloody Bill's trying to get into her draws?\\nJULIET: Too right . . . but he doesn't have a show! Nobody gets into Mother's draws except Daddy!\\nPAULINE: (Quietly) Poor Father . . .\\n\\n\", 'answer': \"(Comforting) Don't worry, Gina! Mummy and Daddy love each other.\", 'gold_tag': \"JULIET provides comfort to Pauline about her parents' relationship\", 'last_speaker': 'JULIET'}\n",
      "Last word -> JULIET : \"(Comforting) Don't worry, Gina! Mummy and Daddy love each other.\"\n",
      "prediction : (V.O.) Oh, Pauline, you're such a little fool.\n",
      "Real answer : (Comforting) Don't worry, Gina! Mummy and Daddy love each other.\n",
      "Bert Score : {'precision': [0.8601884841918945], 'recall': [0.8444104194641113], 'f1': [0.8522263765335083], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.5985667638754\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJULIET: The balloon has gone up! Don't try and fob me off! It's going to cost you a hundred pounds, or I'm blabbing to Daddy! (Angry) I don't care what you do! Pauline and I are going to Hollywood. They're desperately keen to sign us up. We're going to be film stars! (Yelling) It's all arranged . . . we don't need your bloody hundred pounds anyway, so stick it up your bottom!\\n\\n\", 'answer': '(Diary V.O.) Deborah was still in bed when I arrived. (Diary V.O.) Dr. Hulme asked us to come into the lounge to have a talk with him. (Diary V.O.) The shock is too great to have penetrated my mind. It is so incredible. Poor Father. Dr. Hulme was absolutely kind and understanding . . . (Diary V.O.) He said we must tell him everything about our going to America. He was both hope-giving and depressing. We talked for a long time and Deborah and I were near tears by the time it was over.', 'gold_tag': \"PAULINE is emotional and sensitive , PAULINE values strong relationships , PAULINE has a desire to go to America , PAULINE's father has just received shocking news\", 'last_speaker': 'PAULINE'}\n",
      "Last word -> PAULINE : \"(Diary V.O.) Deborah was still in bed when I arrived. (Diary V.O.) Dr. Hulme asked us to come into the lounge to have a talk with him. (Diary V.O.) The shock is too great to have penetrated my mind. It is so incredible. Poor Father. Dr. Hulme was absolutely kind and understanding . . . (Diary V.O.) He said we must tell him everything about our going to America. He was both hope-giving and depressing. We talked for a long time and Deborah and I were near tears by the time it was over.\"\n",
      "prediction :  You know I'm not going to Hollywood.\n",
      "Real answer : (Diary V.O.) Deborah was still in bed when I arrived. (Diary V.O.) Dr. Hulme asked us to come into the lounge to have a talk with him. (Diary V.O.) The shock is too great to have penetrated my mind. It is so incredible. Poor Father. Dr. Hulme was absolutely kind and understanding . . . (Diary V.O.) He said we must tell him everything about our going to America. He was both hope-giving and depressing. We talked for a long time and Deborah and I were near tears by the time it was over.\n",
      "Bert Score : {'precision': [0.8642724752426147], 'recall': [0.8048614263534546], 'f1': [0.833509624004364], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.057692307692307696, 'rouge2': 0.0196078431372549, 'rougeL': 0.057692307692307696, 'rougeLsum': 0.057692307692307696}\n",
      "bleu 1/2 : 1.1435942584922277e-06 8.734345423095882e-07\n",
      "ppl : 46.6792224599827\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAULINE: I'm coming with you.\\nJULIET: Yes . . .\\n\\n\", 'answer': \"I know what to do about mother. We don't want to go to too much trouble . . . some sort of accident. People die every day.\", 'gold_tag': 'PAULINE is willing to plan serious actions , PAULINE suggests a bold personality', 'last_speaker': 'PAULINE'}\n",
      "Last word -> PAULINE : \"I know what to do about mother. We don't want to go to too much trouble . . . some sort of accident. People die every day.\"\n",
      "prediction :  You're going to take me with you?\n",
      "Real answer : I know what to do about mother. We don't want to go to too much trouble . . . some sort of accident. People die every day.\n",
      "Bert Score : {'precision': [0.8391345739364624], 'recall': [0.8308777213096619], 'f1': [0.8349857926368713], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06060606060606061, 'rouge2': 0.0, 'rougeL': 0.06060606060606061, 'rougeLsum': 0.06060606060606061}\n",
      "bleu 1/2 : 0.008204659895373907 0.0028024248666446553\n",
      "ppl : 32.596075397023725\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAULINE: (Diary V.O.) Our main idea for the day was to moider mother. (Diary V.O.) This notion is not a new one but this time it is a definite plan which we intend to carry out. We have worked it out carefully and are both thrilled by the idea. Naturally we feel a trifle nervous, but the pleasure of anticipation is great.\\nJULIET: Only the best people fight against all obstacles . . . . . . in pursuit of happiness.\\n\\n', 'answer': '(Diary V.O.) We both spent last night having a simply wonderful time in every possible way.', 'gold_tag': \"JULIET and PAULINE share the memory of carefully devising a plan to murder PAULINE's mother and the pleasure derived from the anticipation of it.\", 'last_speaker': 'PAULINE'}\n",
      "Last word -> PAULINE : \"(Diary V.O.) We both spent last night having a simply wonderful time in every possible way.\"\n",
      "prediction :  (Diary V.O.) I was so happy to hear from you today, Juliet. I have been thinking about you a lot lately.\n",
      "Real answer : (Diary V.O.) We both spent last night having a simply wonderful time in every possible way.\n",
      "Bert Score : {'precision': [0.9014860391616821], 'recall': [0.9002033472061157], 'f1': [0.9008442163467407], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20512820512820512, 'rouge2': 0.1081081081081081, 'rougeL': 0.20512820512820512, 'rougeLsum': 0.20512820512820512}\n",
      "bleu 1/2 : 0.14285714285714285 0.08451542547285168\n",
      "ppl : 19.658979808717394\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAULINE: (Diary V.O.) I rose late and helped Mother vigorously this morning. Deborah rang and we decided to use a rock in a stocking rather than a sandbag. We discussed the moider fully. I feel very keyed up as though I were planning a surprise party. Mother has fallen in with everything beautifully and the happy event is to take place tomorrow afternoon. So next time I write in this diary Mother will be dead. How odd-yet how pleasing.\\nJULIET: Mummy!\\n\\n', 'answer': 'Mummy!', 'gold_tag': 'Everyday Language', 'last_speaker': 'PAULINE'}\n",
      "Last word -> PAULINE : \"Mummy!\"\n",
      "prediction :  Oh, darling, I'm so glad you're home. I've got something to tell you.\n",
      "Real answer : Mummy!\n",
      "Bert Score : {'precision': [0.8151359558105469], 'recall': [0.8321167230606079], 'f1': [0.8235388398170471], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 6.6688701120352345\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKELLY: Did he say anything?\\nKEOUGH: He just kinda gurgled. He was pretty much dead.\\nKELLY: And you didn't see anything?\\nKEOUGH: The lake was dead calm until up he came. The tooth is in there.\\nKELLY: There? That's the morgue.\\nKEOUGH: Yes.\\nKELLY: Is the dead guy in there?\\nKEOUGH: That's where they keep them. You want me to bring the tooth out here?\\n\\n\", 'answer': \"Um. No, no. Let's go.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'KELLY'}\n",
      "Last word -> KELLY : \"Um. No, no. Let's go.\"\n",
      "prediction :  No, you can keep it. I want to talk to the dead guy.\n",
      "Real answer : Um. No, no. Let's go.\n",
      "Bert Score : {'precision': [0.8662065267562866], 'recall': [0.9096726179122925], 'f1': [0.8874076008796692], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473684, 'rouge2': 0.0, 'rougeL': 0.10526315789473684, 'rougeLsum': 0.10526315789473684}\n",
      "bleu 1/2 : 0.07692307692307693 0.025318484177091663\n",
      "ppl : 30.27612301716249\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKELLY: He may be a kook but he's also been all over the world with them. He even swam in the Grimetti with killer Niles all around him, he never got nipped.\\nKEOUGH: And that's why he thinks they're Godly?\\nKELLY: He said he knew it when he looked\\nKEOUGH: You like Jack?\\nKELLY: What? I don't even know the guy.\\nKEOUGH: Hector thinks you like him.\\nKELLY: Well Hector's a giant cracker.\\nKEOUGH: You think Jack's handsome?\\nKELLY: What is this?\\nKEOUGH: I'm just curious. I can never tell what women think is handsome. Is he handsome?\\nKELLY: Well. He's probably rugged handsome I guess. Yeah.\\n\\n\", 'answer': 'Am I?', 'gold_tag': 'KEOUGH indicates a level of insecurity or lack of understanding on this topic', 'last_speaker': 'KEOUGH'}\n",
      "Last word -> KEOUGH : \"Am I?\"\n",
      "prediction :  He's rugged handsome, huh?\n",
      "Real answer : Am I?\n",
      "Bert Score : {'precision': [0.848312497138977], 'recall': [0.8673458099365234], 'f1': [0.857723593711853], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 69.53898770300236\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKELLY: What is she doing now? Mother of God.\\nKEOUGH: What?\\n\\n', 'answer': 'Look ten feet into the water.', 'gold_tag': 'Everyday Language', 'last_speaker': 'KELLY'}\n",
      "Last word -> KELLY : \"Look ten feet into the water.\"\n",
      "prediction :  Where did you get that?\n",
      "Real answer : Look ten feet into the water.\n",
      "Bert Score : {'precision': [0.8315201997756958], 'recall': [0.8299249410629272], 'f1': [0.8307217955589294], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 57.75239044406808\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTONY: Where to?\\nCHARLIE: Kennedy.\\nTONY: I know, I know, stupid. I mean where you goin'?\\nCHARLIE: It's an open ticket. I can go\\nTONY: So?\\nCHARLIE: So I'll send you a postcard from wherever. If I get there.\\nTONY: Nervous?\\nCHARLIE: Yeah.\\nTONY: You flew before?\\nCHARLIE: No. Hey, come on...\\nTONY: Take it easy. I only asked because maybe I could, you know, let you have a little something.\\nCHARLIE: Yeah, well thanks, but I got enough to hold me. My mother can send me some. I don't know.\\nTONY: How about Teresa? I could talk...\\nCHARLIE: Listen, I appreciate it, but I'll handle it myself. I'll write.\\nTONY: And say what?\\n\\n\", 'answer': \"I'll say that I'm travelling.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'CHARLIE'}\n",
      "Last word -> CHARLIE : \"I'll say that I'm travelling.\"\n",
      "prediction :  I don't know, I'll think of something.\n",
      "Real answer : I'll say that I'm travelling.\n",
      "Bert Score : {'precision': [0.8484275937080383], 'recall': [0.8829078674316406], 'f1': [0.8653244376182556], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.375, 'rouge2': 0.14285714285714288, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0.14285714285714285 0.048795003647426664\n",
      "ppl : 17.36631621345106\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTONY: Listen, try a place with some sun. Swimming pools. Palm trees. Girls in little French bathing suits.\\nCHARLIE: Thanks for the ride. Take care of that tiger.\\nTONY: Panther...\\nCHARLIE: Panther! Same thing...\\nTONY: Hey...no more good times like before. Until you come back.\\nCHARLIE: Sure. And you're gonna take the vows next Tuesday, right.\\n\\n\", 'answer': \"Yeah, I'm gonna worry about you, too. See you.\", 'gold_tag': 'TONY appears to be staying put', 'last_speaker': 'TONY'}\n",
      "Last word -> TONY : \"Yeah, I'm gonna worry about you, too. See you.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : Yeah, I'm gonna worry about you, too. See you.\n",
      "Bert Score : {'precision': [0.9285279512405396], 'recall': [0.8402339816093445], 'f1': [0.8821772336959839], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHARLIE: Tony, Teenage Fan Club, they're Scottish you know?\\nTONY: Oh.\\nCHARLIE: I had that dream again.\\nTONY: Oh, is that the one where you suspect that a fat man in a diaper, on a lazy susan has interfered with your plans for the evening?\\nCHARLIE: No, but I have had that one. No, in this one I'm in love...\\nTONY: Yeah.\\nCHARLIE: And I say to myself, 'I've finally found somebody that I'm truly comfortable with.' You know when you're so comfortable that you'll let them put makeup on you to see what you would look like if you were a girl. Anyways you know what I do in the dream next?\\nTONY: You propose?\\nCHARLIE: No. I die.\\nTONY: But Charlie, you're a normal suburban guy at heart, from a normal suburban family. Didn't you tell me you always wanted to get married and have a family.\\nCHARLIE: Yes, but, I'm afraid, okay? There are seven main rites of passage in a man's life. Birth, first day of school, last day of school. Marriage. Kids. Retirement. Death. I'm at marriage. I'm two rites of passage\\nTONY: I'm sorry, I wasn't listening. Christ. It's the cops.\\nCHARLIE: Tony, you are a cop.\\n\\n\", 'answer': \"I know. Isn't it awful? I work with those guys. They're assholes.\", 'gold_tag': 'TONY does not have positive feelings towards his colleagues', 'last_speaker': 'TONY'}\n",
      "Last word -> TONY : \"I know. Isn't it awful? I work with those guys. They're assholes.\"\n",
      "prediction :  What are you doing here?\n",
      "Real answer : I know. Isn't it awful? I work with those guys. They're assholes.\n",
      "Bert Score : {'precision': [0.8223791122436523], 'recall': [0.843280017375946], 'f1': [0.832698404788971], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 46.220167255681424\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHARLIE: Two hours and four minutes. Tony, I need you, and two hours and four minutes later you show up.\\nTONY: Sorry. I know it was irresponsible\\nCHARLIE: I'm gonna tell you, but when I do, just say nothing. Don't judge me. Just be my friend. Okay?\\nTONY: Fine. Okay.\\nCHARLIE: I broke up with Harriet.\\nTONY: You're an asshole.\\nCHARLIE: What's your point?\\nTONY: I'm sorry, I just... why?\\nCHARLIE: Tony, she's a killer. The... everything.\\nTONY: But nothing's proven. The only thing you're actually sure she did so far is she's treated you like a King.\\nCHARLIE: I dunno, Tony, I just...\\n\\n\", 'answer': \"Besides, everyone has something going on with them. I mean, you can't find everything in one person. I mean, she's bright, she's funny, she's independent. So maybe, and it's really just a maybe, she kills her husbands. Marriage is give and take, Man. You take the good with the bad.\", 'gold_tag': 'TONY is somewhat cynical in his perspectives on relationships', 'last_speaker': 'TONY'}\n",
      "Last word -> TONY : \"Besides, everyone has something going on with them. I mean, you can't find everything in one person. I mean, she's bright, she's funny, she's independent. So maybe, and it's really just a maybe, she kills her husbands. Marriage is give and take, Man. You take the good with the bad.\"\n",
      "prediction :  Maybe you should just face the fact that you're an asshole.\n",
      "Real answer : Besides, everyone has something going on with them. I mean, you can't find everything in one person. I mean, she's bright, she's funny, she's independent. So maybe, and it's really just a maybe, she kills her husbands. Marriage is give and take, Man. You take the good with the bad.\n",
      "Bert Score : {'precision': [0.8624010682106018], 'recall': [0.8307173252105713], 'f1': [0.8462628126144409], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1492537313432836, 'rouge2': 0.0, 'rougeL': 0.08955223880597014, 'rougeLsum': 0.08955223880597014}\n",
      "bleu 1/2 : 0.007869682742833147 0.0015069295174861418\n",
      "ppl : 12.555675882091602\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHARLIE: Hello...\\nTONY: Not that it matters anymore, but I thought you should know -- someone just turned themselves in for the murder of Ralph Elliot.\\nCHARLIE: Really? Did she confess to the other murders?\\nTONY: Just the plumber so far, but she'll come along. A little old lady from Pacific Heights. Said he overcharged her on a leaking sink.\\nCHARLIE: Really. Leaky sink, huh?\\n\\n\", 'answer': \"Anyway, crime to stop. Gotta go. I'll catch you later.\", 'gold_tag': \"TONY's departure indicates ongoing investigations , TONY has to leave to continue his crime-related job duties\", 'last_speaker': 'TONY'}\n",
      "Last word -> TONY : \"Anyway, crime to stop. Gotta go. I'll catch you later.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : Anyway, crime to stop. Gotta go. I'll catch you later.\n",
      "Bert Score : {'precision': [0.9239280223846436], 'recall': [0.8271985054016113], 'f1': [0.8728916645050049], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHICKS: The Nightshade Reservation.. Ain't nothin' but red-outs and rejects. They're a fallen tribe.\\nPRIEST: Either way. We have two hours to get in and out.\\nHICKS: What happens in two hours?\\n\\n\", 'answer': 'Sundown.', 'gold_tag': 'PRIEST mentions a two-hour window until sundown, indicating immediate tasks that need to be completed', 'last_speaker': 'PRIEST'}\n",
      "Last word -> PRIEST : \"Sundown.\"\n",
      "prediction :  The Nightshades will know we're here.\n",
      "Real answer : Sundown.\n",
      "Bert Score : {'precision': [0.850834310054779], 'recall': [0.8645714521408081], 'f1': [0.8576478958129883], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 93.3031493861773\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHICKS: Walkin' Pete talked about this place -- said it. used to be really somethin'. Everythin' growin' green as a goddamn dollar bill. 'Course we had to go and screw it up by poisonin' everythin' -- nothin' pretty survives this world ...nothin' decent anyways. Just wish I could'a seen it.\\nPRIEST: How's your arm?\\nHICKS: Sore. Cut's still open. it's completely healed. Not even a scar.\\nPRIEST: You're a halfbreed.\\n\\n\", 'answer': \"My grandmother... she was raped. Nobody knows -- It's recessive in my family. No bloodthirst. No light sensitivity. I'm not proud... but it's a part of me. Ain't nothin' I can do. I woulda told you...just didn't want you treatin' me no different.\", 'gold_tag': \"HICKS comes from a family with a history of violence , HICKS has a secret he's been keeping due to fear of being treated differently – he's a halfbreed, with traits recessive in his family , PRIEST is non-judgemental about HICKS's heritage\", 'last_speaker': 'HICKS'}\n",
      "Last word -> HICKS : \"My grandmother... she was raped. Nobody knows -- It's recessive in my family. No bloodthirst. No light sensitivity. I'm not proud... but it's a part of me. Ain't nothin' I can do. I woulda told you...just didn't want you treatin' me no different.\"\n",
      "prediction :  I'm a halfbreed.\n",
      "Real answer : My grandmother... she was raped. Nobody knows -- It's recessive in my family. No bloodthirst. No light sensitivity. I'm not proud... but it's a part of me. Ain't nothin' I can do. I woulda told you...just didn't want you treatin' me no different.\n",
      "Bert Score : {'precision': [0.8689825534820557], 'recall': [0.8084056377410889], 'f1': [0.8376002311706543], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11538461538461539, 'rouge2': 0.04, 'rougeL': 0.11538461538461539, 'rougeLsum': 0.11538461538461539}\n",
      "bleu 1/2 : 1.079731194875073e-06 2.95696565737542e-07\n",
      "ppl : 70.03571440245302\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHICKS: Yep. Truly a wonder of the world...good thing we listened to the fossil. Don't know how we'd find Lucy without him.\\n\\n\", 'answer': 'Vampires sometimes use abandoned structures as a perch. Watch for booby traps.', 'gold_tag': 'PRIEST is knowledgeable about vampire behavior , PRIEST is knowledgeable about abandoned structures', 'last_speaker': 'PRIEST'}\n",
      "Last word -> PRIEST : \"Vampires sometimes use abandoned structures as a perch. Watch for booby traps.\"\n",
      "prediction :  The fossil?\n",
      "Real answer : Vampires sometimes use abandoned structures as a perch. Watch for booby traps.\n",
      "Bert Score : {'precision': [0.8448725938796997], 'recall': [0.8428065180778503], 'f1': [0.8438383340835571], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1138.5479079890508\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHICKS: This is bullshit. Lucy's been gone five days'-- every stupid minute we waste here\\nPRIEST: Stay here. If anything comes up the steps that isn't me -- Shoot it.\\n\\n\", 'answer': 'Great.', 'gold_tag': 'Everyday Language', 'last_speaker': 'HICKS'}\n",
      "Last word -> HICKS : \"Great.\"\n",
      "prediction :  You're crazy.\n",
      "Real answer : Great.\n",
      "Bert Score : {'precision': [0.876338005065918], 'recall': [0.931158185005188], 'f1': [0.9029167294502258], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 53.727225142379034\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHICKS: We should jump!\\nPRIEST: Not until we stop the trains\\n\\n', 'answer': 'Too late.', 'gold_tag': 'HICKS implies a pressing deadline when he comments \"Too late.\"', 'last_speaker': 'HICKS'}\n",
      "Last word -> HICKS : \"Too late.\"\n",
      "prediction :  What's the matter with you?\n",
      "Real answer : Too late.\n",
      "Bert Score : {'precision': [0.8299853205680847], 'recall': [0.893190860748291], 'f1': [0.8604289293289185], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.344347137962103\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSCOE: I thought maybe she was with your boy there.\\nBELL: No ID in her room?\\n\\n', 'answer': \"Not hardly nothin' in her room. And that establishment was no stickler on registration. Well... ...County'll bury her. Here Lies Female, Unknown. Her Number Was Up. ...Buy you a cup of coffee before you drive home?\", 'gold_tag': 'ROSCOE is a fellow law enforcement officer at a different location , ROSCOE is dealing with an unidentified deceased woman , ROSCOE displays empathy in the face of tragedy , ROSCOE is willing to help BELL , ROSCOE offers to buy BELL coffee', 'last_speaker': 'ROSCOE'}\n",
      "Last word -> ROSCOE : \"Not hardly nothin' in her room. And that establishment was no stickler on registration. Well... ...County'll bury her. Here Lies Female, Unknown. Her Number Was Up. ...Buy you a cup of coffee before you drive home?\"\n",
      "prediction :  No.\n",
      "Real answer : Not hardly nothin' in her room. And that establishment was no stickler on registration. Well... ...County'll bury her. Here Lies Female, Unknown. Her Number Was Up. ...Buy you a cup of coffee before you drive home?\n",
      "Bert Score : {'precision': [0.9172890782356262], 'recall': [0.8073084950447083], 'f1': [0.8587919473648071], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.052631578947368425, 'rouge2': 0.0, 'rougeL': 0.052631578947368425, 'rougeLsum': 0.052631578947368425}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1275.3241709894667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBELL: No money in his room there?\\nROSCOE: Couple hundred on his person. Those hombres would\\'ve taken the stash.\\nBELL: I suppose. Though they was leavin\\' in a hurry.\\nROSCOE: It\\'s all the goddamned money, Ed Tom. The money and the drugs. It\\'s just goddamned beyond everything. What is it mean? What is it leading to?\\nBELL: Yes.\\nROSCOE: If you\\'d a told me twenty years ago I\\'d see children walkin\\' the streets of our Texas towns with green hair and bones in their noses I just flat out wouldn\\'t of believed you.\\nBELL: Signs and wonders. But I think once you stop hearin\\' sir and madam the rest is soon to follow.\\nROSCOE: It\\'s the tide. It\\'s the dismal tide. It is not the one thing.\\nBELL: Not the one thing. I used to think I could at least some way put things right. I don\\'t feel that way no more. A beat. ...I don\\'t know what I do feel like.\\nROSCOE: Try \"old\" on for size.\\n\\n', 'answer': 'Yessir. It may be that. In a nutshell.', 'gold_tag': 'BELL is disillusioned or dispirited', 'last_speaker': 'BELL'}\n",
      "Last word -> BELL : \"Yessir. It may be that. In a nutshell.\"\n",
      "prediction :  I'm not old.\n",
      "Real answer : Yessir. It may be that. In a nutshell.\n",
      "Bert Score : {'precision': [0.8821640014648438], 'recall': [0.8489735126495361], 'f1': [0.8652505874633789], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 106.63056262165667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSCOE: None of that explains your man though.\\nBELL: Uh-huh.\\nROSCOE: He is just a goddamn homicidal lunatic, Ed Tom.\\nBELL: I'm not sure he's a lunatic.\\nROSCOE: Well what would you call him.\\nBELL: I don't know. Sometimes I think he's pretty much a ghost.\\nROSCOE: He's real all right.\\nBELL: Oh yes.\\nROSCOE: All that at the Eagle Hotel. It's beyond everything.\\nBELL: Yes, he has some hard bark on him.\\nROSCOE: That don't hardly say it. He shoots the desk clerk one day, and walks right back in the next and shoots a retired army colonel.\\nBELL: Hard to believe.\\n\\n\", 'answer': \"Strolls right back into a crime scene. Who would do such a thing? How do you defend against it? ...Good trip Ed Tom. I'm sorry we couldn't help your boy.\", 'gold_tag': 'ROSCOE possibly indicates a close personal or professional connection to the crimes discussed', 'last_speaker': 'ROSCOE'}\n",
      "Last word -> ROSCOE : \"Strolls right back into a crime scene. Who would do such a thing? How do you defend against it? ...Good trip Ed Tom. I'm sorry we couldn't help your boy.\"\n",
      "prediction :  He's got a mean streak.\n",
      "Real answer : Strolls right back into a crime scene. Who would do such a thing? How do you defend against it? ...Good trip Ed Tom. I'm sorry we couldn't help your boy.\n",
      "Bert Score : {'precision': [0.8589949607849121], 'recall': [0.8262888789176941], 'f1': [0.8423245549201965], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05263157894736842, 'rouge2': 0.0, 'rougeL': 0.05263157894736842, 'rougeLsum': 0.05263157894736842}\n",
      "bleu 1/2 : 0.0013475893998170934 0.0004764448014328883\n",
      "ppl : 34.36340917458154\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARTHUR: Are they really with-holding some of the Mars photos?\\nWENDELL: I don't know, man. Jesus... what's that smell?\\nARTHUR: It's a salinic compound.\\nWENDELL: What are you making?\\nARTHUR: Christmas present for Norma.\\nWENDELL: A new prosthesis for her foot?\\nARTHUR: Yep.\\nWENDELL: What did you change up this time?\\n\\n\", 'answer': \"The compound they're developing for the pilot chairs on the space shuttle.\", 'gold_tag': 'ARTHUR is involved in scientific work, working with compounds for pilot chairs on the space shuttle', 'last_speaker': 'ARTHUR'}\n",
      "Last word -> ARTHUR : \"The compound they're developing for the pilot chairs on the space shuttle.\"\n",
      "prediction :  A few things. First, I made the foot larger to accommodate her lymphedema.\n",
      "Real answer : The compound they're developing for the pilot chairs on the space shuttle.\n",
      "Bert Score : {'precision': [0.8457801342010498], 'recall': [0.8569620847702026], 'f1': [0.8513343334197998], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307693, 'rouge2': 0.0, 'rougeL': 0.07692307692307693, 'rougeLsum': 0.07692307692307693}\n",
      "bleu 1/2 : 0.07692307692307693 0.025318484177091663\n",
      "ppl : 47.6874779247792\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nARTHUR: She had to sit there in a hospital bed in the same position for six months, waiting for it to heal.\\nWENDELL: Jesus. I hope she sued this idiot.\\nARTHUR: Oh yeah. Her family sued. They won.\\nWENDELL: What was the settlement?\\n\\n', 'answer': 'Forty thousand dollars.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ARTHUR'}\n",
      "Last word -> ARTHUR : \"Forty thousand dollars.\"\n",
      "prediction :  Five hundred thousand dollars.\n",
      "Real answer : Forty thousand dollars.\n",
      "Bert Score : {'precision': [0.953447699546814], 'recall': [0.9802782535552979], 'f1': [0.9666768312454224], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.5714285714285715, 'rouge2': 0.4, 'rougeL': 0.5714285714285715, 'rougeLsum': 0.5714285714285715}\n",
      "bleu 1/2 : 0.5 0.408248290463863\n",
      "ppl : 309.7334383835793\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWENDELL: How's the commute back to Richmond?\\nARTHUR: Not too bad. Maybe an hour and twenty minutes.\\n\\n\", 'answer': 'Tell Norma I said hello.', 'gold_tag': \"WENDELL knows Norma's commute details , WENDELL knows ARTHUR's commute details , WENDELL and ARTHUR both know Norma\", 'last_speaker': 'WENDELL'}\n",
      "Last word -> WENDELL : \"Tell Norma I said hello.\"\n",
      "prediction :  How far is it to Richmond?\n",
      "Real answer : Tell Norma I said hello.\n",
      "Bert Score : {'precision': [0.8142871260643005], 'recall': [0.855603814125061], 'f1': [0.8344343900680542], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 163.52701197716976\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCARLOS: First time? Best not bitch up. Wind up someone's luggage that way.\\nEVAN: Can you protect me?\\n\\n\", 'answer': \"Jesus himself couldn't make me take on the Brotherhood. When they come, just put your mind in another place, man. Be somewhere else.\", 'gold_tag': \"CARLOS has knowledge about 'the Brotherhood' , CARLOS suggests a possible association with groups, gangs, or criminal activity , EVAN is relatively new or inexperienced in the current environment\", 'last_speaker': 'CARLOS'}\n",
      "Last word -> CARLOS : \"Jesus himself couldn't make me take on the Brotherhood. When they come, just put your mind in another place, man. Be somewhere else.\"\n",
      "prediction :  No. I can't protect you.\n",
      "Real answer : Jesus himself couldn't make me take on the Brotherhood. When they come, just put your mind in another place, man. Be somewhere else.\n",
      "Bert Score : {'precision': [0.903823733329773], 'recall': [0.850487232208252], 'f1': [0.8763446807861328], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06666666666666667, 'rouge2': 0.0, 'rougeL': 0.06666666666666667, 'rougeLsum': 0.06666666666666667}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 68.4811609834154\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEVAN: You\\'re religious Carlos, you believe that bit about \"the Lord works in mysterious ways?\"\\nCARLOS: Straight up.\\nEVAN: Because I think he sent me to your cell on purpose. For you to help me.\\nCARLOS: Shit. I knew you were crazy.\\n\\n', 'answer': \"I ain't bullshitting. Jesus speaks to me in my dreams. Pack of smokes says I can prove it to you.\", 'gold_tag': 'EVAN claims to have religious visions', 'last_speaker': 'EVAN'}\n",
      "Last word -> EVAN : \"I ain't bullshitting. Jesus speaks to me in my dreams. Pack of smokes says I can prove it to you.\"\n",
      "prediction :  I can't help but wonder why you're here. What did you do?\n",
      "Real answer : I ain't bullshitting. Jesus speaks to me in my dreams. Pack of smokes says I can prove it to you.\n",
      "Bert Score : {'precision': [0.8453347682952881], 'recall': [0.8361615538597107], 'f1': [0.8407231569290161], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22857142857142854, 'rouge2': 0.060606060606060615, 'rougeL': 0.17142857142857143, 'rougeLsum': 0.17142857142857143}\n",
      "bleu 1/2 : 0.042784759919382666 0.01413134111126129\n",
      "ppl : 14.195148040976145\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCARLOS: Oh sweet Jesus. It's true. It's a miracle! A miracle! Your hands. The stigmata!\\nEVAN: What did you see? What did it look like?\\nCARLOS: Signs of the Lord. They just appeared out of nowhere. I thought you were loco!\\n\\n\", 'answer': 'So you believe me?', 'gold_tag': 'EVAN is seeking validation or confirmation for his condition from CARLOS', 'last_speaker': 'EVAN'}\n",
      "Last word -> EVAN : \"So you believe me?\"\n",
      "prediction :  I am.\n",
      "Real answer : So you believe me?\n",
      "Bert Score : {'precision': [0.9042896032333374], 'recall': [0.8366630673408508], 'f1': [0.8691628575325012], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 759.6279032982686\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHEATHER MCNAMARA: Veronica. What are you doing tonight?\\nVERONICA: Mourning. Maybe watch some T.V. Why?\\nHEATHER MCNAMARA: Ram asked me out, but he wants to have a date.\\nVERONICA: Heather, I've got something going with J.D.\\n\\n\", 'answer': \"Please Veronica. Put Billy the Kid on hold tonight, I'll never forget it.\", 'gold_tag': 'HEATHER MCNAMARA seeks help from her friends in navigating this romantic prospect', 'last_speaker': 'HEATHER MCNAMARA'}\n",
      "Last word -> HEATHER MCNAMARA : \"Please Veronica. Put Billy the Kid on hold tonight, I'll never forget it.\"\n",
      "prediction :  You do?\n",
      "Real answer : Please Veronica. Put Billy the Kid on hold tonight, I'll never forget it.\n",
      "Bert Score : {'precision': [0.8237597942352295], 'recall': [0.809329628944397], 'f1': [0.8164809346199036], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 816.054875193869\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHEATHER MCNAMARA: Don't worry, Ram's been so sweet lately, consoling me and stuff. It'll be really very. Promise.\\n\\n\", 'answer': \"All right, but I hope it isn't going to be one of those nights where they get shitfaced and take us to a pasture to tip cows.\", 'gold_tag': 'VERONICA has concerns about an upcoming event that she fears will involve irresponsible behavior , Shared memory: The shared memory between the two involves previous instances of Ram and possibly others behaving irresponsibly after drinking', 'last_speaker': 'VERONICA'}\n",
      "Last word -> VERONICA : \"All right, but I hope it isn't going to be one of those nights where they get shitfaced and take us to a pasture to tip cows.\"\n",
      "prediction :  So, Heather, you're really going to wear that?\n",
      "Real answer : All right, but I hope it isn't going to be one of those nights where they get shitfaced and take us to a pasture to tip cows.\n",
      "Bert Score : {'precision': [0.8483102321624756], 'recall': [0.8434621691703796], 'f1': [0.8458791971206665], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10810810810810811, 'rouge2': 0.05714285714285714, 'rougeL': 0.10810810810810811, 'rougeLsum': 0.10810810810810811}\n",
      "bleu 1/2 : 0.023253622302665873 0.017578086198365435\n",
      "ppl : 28.029310354311182\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHEATHER MCNAMARA: Give me a break. What are you trying to do? Kill me?\\nVERONICA: What were you trying to do? Sleep?\\nHEATHER MCNAMARA: Suicide is a private thing.\\nVERONICA: You're giving your life away to become a goddamn statistic in U.S. Fucking A Today. That's got to be the least private thing I can think of. If everyone jumped off a bridge, young lady, would you?\\nHEATHER MCNAMARA: Probably....\\nVERONICA: Hey now, if you were happy every day of your life, you wouldn't be a human being, you'd be a game show host.\\nHEATHER MCNAMARA: Let's knock off early. Go to the mall. Something lame like that.\\n\\n\", 'answer': 'Sure.', 'gold_tag': 'VERONICA is willing to engage in mundane activities with friends', 'last_speaker': 'VERONICA'}\n",
      "Last word -> VERONICA : \"Sure.\"\n",
      "prediction :  Heather, you are not going to jump off a bridge, are you?\n",
      "Real answer : Sure.\n",
      "Bert Score : {'precision': [0.8105089664459229], 'recall': [0.9316349029541016], 'f1': [0.8668612241744995], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 27.30989441232272\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRIS: Well, I don't know what a Koran looks like but I can describe what he was carrying-- it was pressed metal, fired 7.62s and looked just like an AK-47.\\n\\n\", 'answer': \"Listen up ladies and genitals. The Legend here would like you to know that when it comes to sniping it's better to be lucky than good! Our boy here has a Texas horseshoe crammed so far up his ass that--\", 'gold_tag': 'BIGGLES has a crude sense of humor , BIGGLES has a position of authority among the group , CHRIS is from Texas', 'last_speaker': 'BIGGLES'}\n",
      "Last word -> BIGGLES : \"Listen up ladies and genitals. The Legend here would like you to know that when it comes to sniping it's better to be lucky than good! Our boy here has a Texas horseshoe crammed so far up his ass that--\"\n",
      "prediction :  That's a damn good description. I'll check it out.\n",
      "Real answer : Listen up ladies and genitals. The Legend here would like you to know that when it comes to sniping it's better to be lucky than good! Our boy here has a Texas horseshoe crammed so far up his ass that--\n",
      "Bert Score : {'precision': [0.8679653406143188], 'recall': [0.7998601198196411], 'f1': [0.8325222134590149], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.19230769230769232, 'rouge2': 0.0, 'rougeL': 0.11538461538461536, 'rougeLsum': 0.11538461538461536}\n",
      "bleu 1/2 : 0.007093887074421266 0.0016824630464399694\n",
      "ppl : 23.093956304625898\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBIGGLES: I bought the ring.\\nCHRIS: Here?\\nBIGGLES: They're cheaper here.\\nCHRIS: You want some savage's ring? What if it's a blood diamond?\\nBIGGLES: What the fuck do you care? You spilled more blood than anyone!\\nCHRIS: Not for a rock.\\nBIGGLES: Whatever, man.\\nCHRIS: Ease off, don't get too close. You gonna tell her where it came from?\\n\\n\", 'answer': \"Hell no! I'll tell her I got from Zales.\", 'gold_tag': \"BIGGLES is secretive, planning not to tell his partner about the ring's origin\", 'last_speaker': 'BIGGLES'}\n",
      "Last word -> BIGGLES : \"Hell no! I'll tell her I got from Zales.\"\n",
      "prediction :  No.\n",
      "Real answer : Hell no! I'll tell her I got from Zales.\n",
      "Bert Score : {'precision': [0.92283034324646], 'recall': [0.819974422454834], 'f1': [0.8683672547340393], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1275.3241709894667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRIS: The Butcher has his peepers out.\\nBIGGLES: time you got a shot try not to miss.\\nCHRIS: I coulda taken him in that alley if I didn't have to save your ass--\\n\\n\", 'answer': 'Whatever helps you sleep at night.', 'gold_tag': 'BIGGLES is somewhat sarcastic', 'last_speaker': 'BIGGLES'}\n",
      "Last word -> BIGGLES : \"Whatever helps you sleep at night.\"\n",
      "prediction :  you're just as crazy as he is.\n",
      "Real answer : Whatever helps you sleep at night.\n",
      "Bert Score : {'precision': [0.8499053120613098], 'recall': [0.8598616123199463], 'f1': [0.8548544645309448], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714288, 'rouge2': 0.0, 'rougeL': 0.14285714285714288, 'rougeLsum': 0.14285714285714288}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 30.24102590730719\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBIGGLES: You gonna be my best man?\\nCHRIS: Is it just me? Or other guys too?\\n\\n', 'answer': 'You fucking egomaniac--', 'gold_tag': 'Everyday Language', 'last_speaker': 'BIGGLES'}\n",
      "Last word -> BIGGLES : \"You fucking egomaniac--\"\n",
      "prediction :  I was thinking of it.\n",
      "Real answer : You fucking egomaniac--\n",
      "Bert Score : {'precision': [0.8567862510681152], 'recall': [0.7852722406387329], 'f1': [0.8194719552993774], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 164.4400744958911\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBIGGLES: That should do it.\\nCHRIS: What the fuck!? How'd he survive--\\n\\n\", 'answer': \"Rubber junk-man's got your horseshoe. --need a two block perimeter around the area. No one gets in or out.\", 'gold_tag': 'BIGGLES instructed to establish a perimeter around the area', 'last_speaker': 'BIGGLES'}\n",
      "Last word -> BIGGLES : \"Rubber junk-man's got your horseshoe. --need a two block perimeter around the area. No one gets in or out.\"\n",
      "prediction :  He's got a good head on his shoulders, Chris. He's got a good head on his shoulders.\n",
      "Real answer : Rubber junk-man's got your horseshoe. --need a two block perimeter around the area. No one gets in or out.\n",
      "Bert Score : {'precision': [0.8342784643173218], 'recall': [0.8436023592948914], 'f1': [0.8389145731925964], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15, 'rouge2': 0.052631578947368425, 'rougeL': 0.15, 'rougeLsum': 0.15}\n",
      "bleu 1/2 : 0.10458938416503243 0.024106661926760035\n",
      "ppl : 6.932367969722847\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBIGGLES: How the hell'd he make that?\\nCHRIS: He didn't--\\nBIGGLES: So much for leading us to the Butcher.\\n\\n\", 'answer': 'So much for him having my horseshoe.', 'gold_tag': 'Shared memories', 'last_speaker': 'CHRIS'}\n",
      "Last word -> CHRIS : \"So much for him having my horseshoe.\"\n",
      "prediction :  He didn't make it, okay?\n",
      "Real answer : So much for him having my horseshoe.\n",
      "Bert Score : {'precision': [0.8480653166770935], 'recall': [0.8316712975502014], 'f1': [0.8397883176803589], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 44.3521306553294\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRIS: out how much your spent.\\nBIGGLES: She's not like that.\\nCHRIS: They're all like that.\\nBIGGLES: It's giant, bro. Four karats. It had to belong to one of Saddam's bitches--\\nCHRIS: No!-- Biggles is down. Man down. No, buddy. No! Stay with me-- Cover! I need cover. He's picking us off.\\n\\n\", 'answer': \"I'm got it. I got it-- I can walk--\", 'gold_tag': \"BIGGLES is resilient and determined, insisting he can walk despite being injured , BIGGLES's temporal information - BIGGLES's immediate situation involves being injured and needing to recover\", 'last_speaker': 'BIGGLES'}\n",
      "Last word -> BIGGLES : \"I'm got it. I got it-- I can walk--\"\n",
      "prediction :  Cover! Chris, I got one.\n",
      "Real answer : I'm got it. I got it-- I can walk--\n",
      "Bert Score : {'precision': [0.8752315044403076], 'recall': [0.8591516017913818], 'f1': [0.8671169877052307], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.26666666666666666, 'rouge2': 0.15384615384615383, 'rougeL': 0.26666666666666666, 'rougeLsum': 0.26666666666666666}\n",
      "bleu 1/2 : 0.17973158564688863 0.14209029452944894\n",
      "ppl : 404.3620956346096\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRIS: Hey, buddy--\\nBIGGLES: Chris? Where are you?\\nCHRIS: I'm right here just give me a minute-- Just blind as a bat, huh?\\nBIGGLES: Yeah... It fucking blows. They're gonna fix my face though.\\nCHRIS: That's good. Your face always needed a little fixing. I heard you proposed? Did you tell Kelly the diamond was from Zales?\\nBIGGLES: Naw, I bought a new one. A small one. Her dad helped me out.\\nCHRIS: Nice.\\nBIGGLES: She wouldn't leave me, bro. I told her to go-- but she wouldn't leave.\\nCHRIS: No she's not. How can you say that? She's getting you. All four inches.\\nBIGGLES: I'm glad this happened to me and not you. No way you could've handled it.\\nCHRIS: You're probably right.\\nBIGGLES: They say you're the deadliest sniper in U.S. Military history.\\nCHRIS: Is that what they say? The bad guys fled up into to Sadr City.\\nBIGGLES: You're not going back?\\nCHRIS: We're gonna wall `em in and hunt `em down.\\nBIGGLES: You don't have to do this.\\nCHRIS: Yes I do. You're my brother and they're going to pay for what they did to you. His mind made up. Biggles moved by it.\\n\\n\", 'answer': 'Hooyah, Legend. Hooyah--', 'gold_tag': 'Everyday Language', 'last_speaker': 'BIGGLES'}\n",
      "Last word -> BIGGLES : \"Hooyah, Legend. Hooyah--\"\n",
      "prediction :  I know you're going to get me out of here.\n",
      "Real answer : Hooyah, Legend. Hooyah--\n",
      "Bert Score : {'precision': [0.8417918682098389], 'recall': [0.8168606758117676], 'f1': [0.8291388750076294], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 20.385462132258056\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAM: Nothing yet. I'm sorry. We're still trying to get... Let me call you back. This has been one crazy day. We've got missing pets, dead ostriches. God only knows what's next.\\nCHRIS: I'm sorry about yesterday. Wade is... He knows how to push my buttons.\\nSAM: I wanted to ask you...\\nCHRIS: On a date? I'm kidding. What did you want to ask?\\nSAM: Have you noticed anything strange in the mines? I had spiders in my house. Hector had roaches in his basement. Some mice...\\nCHRIS: How about stampeding rats?\\nSAM: Were they running away from something?\\nCHRIS: Could have been. Never saw them do that before. I guess it qualifies as strange. Sam... Do you want to go out sometime?\\nSAM: Are you asking me out on a date?\\n\\n\", 'answer': \"Only if you're going to say yes.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'CHRIS'}\n",
      "Last word -> CHRIS : \"Only if you're going to say yes.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : Only if you're going to say yes.\n",
      "Bert Score : {'precision': [0.93091881275177], 'recall': [0.8142788410186768], 'f1': [0.8687010407447815], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAM: I guess I should watch more 'Oprah.' It must be a textbook 'no-dad' kind of thing.\\nCHRIS: That one looks kind of scratchy.\\nSAM: All Jason cared about was getting out and starting over. I guess that included buying a new wardrobe.\\nCHRIS: Gladys thought I should sell... but you know... I never wanted to get rich. If it was about the money, I would have sold out to Wade a long time ago. I think I just wanted to prove the gold was down there. That my family wasn't crazy to keep looking. Even after we'd lost so much. And now... she's gone, too.\\nSAM: I'm sorry, Chris.\\nCHRIS: Do you know what I'm trying to say?\\nSAM: It wasn't about spending the gold, it was about finding it.\\nCHRIS: That's right. That's exactly right. Remind me never to let you do my laundry.\\n\\n\", 'answer': 'They look great.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"They look great.\"\n",
      "prediction :  I know.\n",
      "Real answer : They look great.\n",
      "Bert Score : {'precision': [0.888164222240448], 'recall': [0.8938551545143127], 'f1': [0.8910006284713745], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 663.9337011017111\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHRIS: Cover me!\\n\\n', 'answer': 'What are you going to do?! Hurry! Hold that thought.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"What are you going to do?! Hurry! Hold that thought.\"\n",
      "prediction :  No.\n",
      "Real answer : What are you going to do?! Hurry! Hold that thought.\n",
      "Bert Score : {'precision': [0.9237251281738281], 'recall': [0.810011088848114], 'f1': [0.8631388545036316], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1275.3241709894667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAM: Hi.\\nCHRIS: I just stopped by to see how you were holdin' up.\\nSAM: I'm okay.\\nCHRIS: Sorry about the other night... I DIDN'T-\\nSAM: I was just upset. I shouldn't have snapped at you like that.\\nCHRIS: So what are you still doin' here? I figured you woulda hopped on a bus by now.\\nSAM: I'm gonna be taking off soon, I think. I just gotta figure some stuff out. It's quiet here.\\nCHRIS: I don't know if you're doin' anything later on, but...\\nSAM: I was just on my way out. What were you gonna say?\\nCHRIS: Nothin'.\\nSAM: Okay, well... I'll see you later?\\nCHRIS: Yeah, sure.\\nSAM: Bye.\\n\\n\", 'answer': 'Bye.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CHRIS'}\n",
      "Last word -> CHRIS : \"Bye.\"\n",
      "prediction :  How are you doing?\n",
      "Real answer : Bye.\n",
      "Bert Score : {'precision': [0.8137021064758301], 'recall': [0.92415452003479], 'f1': [0.8654183745384216], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 104.82684509399363\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBLAIREAU: H�, et moi ?\\nVICTOR: Blaireau !\\nBLAIREAU: Hein ?\\nVICTOR: Et ben, c'est pour toi.\\n\\n\", 'answer': 'Encore ? Un par jour ?', 'gold_tag': 'BLAIREAU receives something on a daily basis , The mention of \"Un par jour?\" by BLAIREAU suggests a daily occurrence', 'last_speaker': 'BLAIREAU'}\n",
      "Last word -> BLAIREAU : \"Encore ? Un par jour ?\"\n",
      "prediction :  Quoi ?\n",
      "Real answer : Encore ? Un par jour ?\n",
      "Bert Score : {'precision': [0.8301922678947449], 'recall': [0.8040909171104431], 'f1': [0.8169332146644592], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0.06766764161830635 0.030261889307125377\n",
      "ppl : 1747.721586063303\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVICTOR: Blaireau !\\nBLAIREAU: Hein ?\\nVICTOR: Encore un paquet pour toi.\\n\\n', 'answer': \"Deux par jour ? Il prend le colis et �clate de rire en compagnie de tous les d�tenus qui rient avec lui. Blaireau lit l'inscription sur le colis. � Protection de l'innocence �. Et bien, vous voyez bien que je suis innocent ?\", 'gold_tag': 'BLAIREAU receives packages often , BLAIREAU has a sense of humor', 'last_speaker': 'BLAIREAU'}\n",
      "Last word -> BLAIREAU : \"Deux par jour ? Il prend le colis et �clate de rire en compagnie de tous les d�tenus qui rient avec lui. Blaireau lit l'inscription sur le colis. � Protection de l'innocence �. Et bien, vous voyez bien que je suis innocent ?\"\n",
      "prediction :  Bonjour ?\n",
      "Real answer : Deux par jour ? Il prend le colis et �clate de rire en compagnie de tous les d�tenus qui rient avec lui. Blaireau lit l'inscription sur le colis. � Protection de l'innocence �. Et bien, vous voyez bien que je suis innocent ?\n",
      "Bert Score : {'precision': [0.802954375743866], 'recall': [0.7518582344055176], 'f1': [0.7765666842460632], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 6.250764331933713e-10 2.7954267915069685e-10\n",
      "ppl : 648.763401929055\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVICTOR: Allons, allons !\\n\\n', 'answer': 'Je me plaindrai au gouvernement !', 'gold_tag': 'Everyday Language', 'last_speaker': 'BLAIREAU'}\n",
      "Last word -> BLAIREAU : \"Je me plaindrai au gouvernement !\"\n",
      "prediction :  Allons where?\n",
      "Real answer : Je me plaindrai au gouvernement !\n",
      "Bert Score : {'precision': [0.8050187826156616], 'recall': [0.7630881071090698], 'f1': [0.7834928035736084], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3800.741252456601\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVICTOR: Allez !\\n\\n', 'answer': 'Non ! Non ! Je suis innocent ! Je suis innocent ! Oh !... Quand je sortirai, �a fera du vilain ! Je suis innocent !...', 'gold_tag': \"BLAIREAU asserts his innocence multiple times, expressing passion and defiance , BLAIREAU threatens retaliation once he's released , BLAIREAU anticipates a future time when he will be released and will retaliate\", 'last_speaker': 'BLAIREAU'}\n",
      "Last word -> BLAIREAU : \"Non ! Non ! Je suis innocent ! Je suis innocent ! Oh !... Quand je sortirai, �a fera du vilain ! Je suis innocent !...\"\n",
      "prediction :  Alright.\n",
      "Real answer : Non ! Non ! Je suis innocent ! Je suis innocent ! Oh !... Quand je sortirai, �a fera du vilain ! Je suis innocent !...\n",
      "Bert Score : {'precision': [0.9333676695823669], 'recall': [0.74294114112854], 'f1': [0.8273382186889648], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 599.29608080544\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROBIN: We make a fine army, do we not, a fool.\\nASLAN: A fine, wet army. I have never witnessed a storm of such duration. When does summer come to this land?\\nROBIN: This is summer.\\nASLAN: Then Allah truly is great.\\nROBIN: Why, pray?\\nASLAN: No food, no shelter, and weather that would curse the end of the earth. We will all quickly be dead, and I shall be rid of my vow.\\nROBIN: You despair too soon, Aslan. We shall find food and shelter here among friends.\\nASLAN: What is this place?\\n\\n', 'answer': \"Peter's home. It is nearly seven years since we left here together.\", 'gold_tag': 'ROBIN is familiar with the harsh weather conditions they are experiencing , ROBIN has a connection to a person named Peter , ROBIN and ASLAN left a location  together seven years ago , ROBIN is revisiting a place after nearly seven years', 'last_speaker': 'ROBIN'}\n",
      "Last word -> ROBIN : \"Peter's home. It is nearly seven years since we left here together.\"\n",
      "prediction :  A barrow.\n",
      "Real answer : Peter's home. It is nearly seven years since we left here together.\n",
      "Bert Score : {'precision': [0.8666672706604004], 'recall': [0.8500115871429443], 'f1': [0.8582586646080017], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1309.5142635394634\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nASLAN: You should not have left without me, Englishman.\\nROBIN: How so? You have not raised a finger to protect me.\\nASLAN: Before I had a choice.\\nROBIN: It was my choice to do this alone.\\nASLAN: A foolish risk. If you had been killed, I would be cursed for eternity for failing to fulfil my pledge.\\n\\n', 'answer': \"Aslan, if I didn't know better, I would swear you were worried about me.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ROBIN'}\n",
      "Last word -> ROBIN : \"Aslan, if I didn't know better, I would swear you were worried about me.\"\n",
      "prediction :  So you think I'm just going to sit here and do nothing while you go off on your own?\n",
      "Real answer : Aslan, if I didn't know better, I would swear you were worried about me.\n",
      "Bert Score : {'precision': [0.8384461402893066], 'recall': [0.8311882019042969], 'f1': [0.834801435470581], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1142857142857143, 'rouge2': 0.0, 'rougeL': 0.1142857142857143, 'rougeLsum': 0.1142857142857143}\n",
      "bleu 1/2 : 0.05263157894736841 0.017099639201419235\n",
      "ppl : 10.245171744180414\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nASLAN: Here they come.\\nROBIN: How many?\\nASLAN: Two wagons. Twenty escort.\\n\\n', 'answer': 'Twenty? They usually have five.', 'gold_tag': \"ROBIN relies on ASLAN's reports , ROBIN is knowledgeable about usual escort numbers , ASLAN and ROBIN have previous experience with wagon escorts\", 'last_speaker': 'ROBIN'}\n",
      "Last word -> ROBIN : \"Twenty? They usually have five.\"\n",
      "prediction :  Twenty?\n",
      "Real answer : Twenty? They usually have five.\n",
      "Bert Score : {'precision': [0.9214975833892822], 'recall': [0.8671824932098389], 'f1': [0.893515408039093], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.33333333333333337, 'rouge2': 0.0, 'rougeL': 0.33333333333333337, 'rougeLsum': 0.33333333333333337}\n",
      "bleu 1/2 : 0.01831563888873418 0.00579191356895553\n",
      "ppl : 1658.8270630759664\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROBIN: Er, about ten. Why scare them? They can't count anyway.\\nASLAN: And they call me the barbarian.\\n\\n\", 'answer': \"Let's go.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ROBIN'}\n",
      "Last word -> ROBIN : \"Let's go.\"\n",
      "prediction :  I think you are the barbarian.\n",
      "Real answer : Let's go.\n",
      "Bert Score : {'precision': [0.8660895824432373], 'recall': [0.8802773952484131], 'f1': [0.8731258511543274], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 89.94770784068517\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nASLAN: If it was Jehovah who created this brew, he is truly wise. He built the punishment into the crime.\\n\\n', 'answer': 'They need help.', 'gold_tag': 'ROBIN cares about the welfare of others', 'last_speaker': 'ROBIN'}\n",
      "Last word -> ROBIN : \"They need help.\"\n",
      "prediction :  I think the punishment is more than sufficient.\n",
      "Real answer : They need help.\n",
      "Bert Score : {'precision': [0.8557224273681641], 'recall': [0.9061589241027832], 'f1': [0.8802187442779541], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 75.57486746127223\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROBIN: Are you sure it was a Druid mask? Damn them to hell! They must have Marian. Do you know where they meet?\\nASLAN: We will go there.\\nROBIN: No! You stay here, dammit! I will go alone.\\nASLAN: You forget yourself. I am not your servant.\\nROBIN: Then be my friend. There are women and children here in greater need of your courage.\\n\\n', 'answer': 'Take my eyes, then.', 'gold_tag': 'ASLAN offers his eyes to Robin', 'last_speaker': 'ASLAN'}\n",
      "Last word -> ASLAN : \"Take my eyes, then.\"\n",
      "prediction :  I am not a man. I do not have courage. I am a lion. I will go with you.\n",
      "Real answer : Take my eyes, then.\n",
      "Bert Score : {'precision': [0.8594975471496582], 'recall': [0.8584471940994263], 'f1': [0.8589720726013184], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 17.42876273033224\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROBIN: You have fulfilled your vow. Now you can leave.\\nASLAN: Your gratitude warms my heart.\\nROBIN: You ignored my request.\\nASLAN: It is fortunate that I did.\\nROBIN: Because of you, another good man\\nASLAN: He urged me to bring him. He was a brave man and I grieve for him. Praise be to Allah that I do not grieve for you also. Or for my broken vow.\\nROBIN: To hell with your damn vow.\\nASLAN: I am glad you are feeling better.\\n\\n', 'answer': 'The forest! Ride!', 'gold_tag': 'ROBIN is more pragmatically concerned with the safety of the group', 'last_speaker': 'ROBIN'}\n",
      "Last word -> ROBIN : \"The forest! Ride!\"\n",
      "prediction :  What the hell do you know about feeling better?\n",
      "Real answer : The forest! Ride!\n",
      "Bert Score : {'precision': [0.8246459364891052], 'recall': [0.8535493016242981], 'f1': [0.8388487100601196], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 90.6032200423044\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROBIN: Wulf, stay here. I need your What are you doing? Out of my way!\\nASLAN: I saved your life. I will not let you give it away for no purpose.\\nROBIN: Out of my way, damn you!\\n\\n', 'answer': 'Does the witch still have possession of your senses? If we meet up with the survivors we may yet give them some help. And do some damage to the enemy.', 'gold_tag': \"There's a shared implication of a previous encounter with a witch impacting Robin's behavior\", 'last_speaker': 'ASLAN'}\n",
      "Last word -> ASLAN : \"Does the witch still have possession of your senses? If we meet up with the survivors we may yet give them some help. And do some damage to the enemy.\"\n",
      "prediction :  You must give it up.\n",
      "Real answer : Does the witch still have possession of your senses? If we meet up with the survivors we may yet give them some help. And do some damage to the enemy.\n",
      "Bert Score : {'precision': [0.8747304677963257], 'recall': [0.8487691879272461], 'f1': [0.8615543246269226], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1142857142857143, 'rouge2': 0.0, 'rougeL': 0.05714285714285715, 'rougeLsum': 0.05714285714285715}\n",
      "bleu 1/2 : 0.0013475893998170934 0.0004764448014328883\n",
      "ppl : 106.68279365033585\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROBIN: You were an honor to your countrymen today, Aslan. You fought better than twenty English knights.\\nASLAN: This war is the God of Abraham against the forces of evil.\\n\\n', 'answer': 'Well, the war is over. There is too much blood on my hands.', 'gold_tag': \"ROBIN recognizes the war's end , ROBIN shows guilt and regret over the blood spilled during the war , ROBIN's temporal information: Robin states that the war has ended, signaling a transition from a period of conflict to one of peace\", 'last_speaker': 'ROBIN'}\n",
      "Last word -> ROBIN : \"Well, the war is over. There is too much blood on my hands.\"\n",
      "prediction :  I'm not sure what you mean.\n",
      "Real answer : Well, the war is over. There is too much blood on my hands.\n",
      "Bert Score : {'precision': [0.8442459106445312], 'recall': [0.8540424108505249], 'f1': [0.8491159081459045], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18.15251205097634\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nASLAN: No, friend. It was you who gave\\nROBIN: I gave them nothing but false hope. Tomorrow we will disperse. These people can move south and start over. You must go home and win your Jasmina.\\nASLAN: And you?\\nROBIN: I am no longer your responsibility.\\nASLAN: That is for me to decide.\\n\\n', 'answer': \"Damn you, Arab. I want you out of my life. Can't you understand that? Go home. Go back to your own kind. Damn you, too, Father. You reared a coward and a fool.\", 'gold_tag': \"ROBIN has a volatile relationship with ASLAN and his own past , ASLAN is potentially Arab based on ROBIN's words , ROBIN's mention of his father suggests a troubled family life\", 'last_speaker': 'ROBIN'}\n",
      "Last word -> ROBIN : \"Damn you, Arab. I want you out of my life. Can't you understand that? Go home. Go back to your own kind. Damn you, too, Father. You reared a coward and a fool.\"\n",
      "prediction :  I'm not going to be responsible for this.\n",
      "Real answer : Damn you, Arab. I want you out of my life. Can't you understand that? Go home. Go back to your own kind. Damn you, too, Father. You reared a coward and a fool.\n",
      "Bert Score : {'precision': [0.8627355098724365], 'recall': [0.83976149559021], 'f1': [0.8510935306549072], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09302325581395347, 'rouge2': 0.0, 'rougeL': 0.09302325581395347, 'rougeLsum': 0.09302325581395347}\n",
      "bleu 1/2 : 0.005492116702925928 0.0018566743195773602\n",
      "ppl : 27.668336096408343\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVIVIAN: Kit, he wants me to stay the whole week. And you know what he's gonna give me ? Guess. You'll never guess. Three thousand dollars.\\n\\n\", 'answer': 'Bullshit !', 'gold_tag': 'Kit displays skepticism and surprise , Kit suggests familiarity with such circumstances', 'last_speaker': 'KIT'}\n",
      "Last word -> KIT : \"Bullshit !\"\n",
      "prediction :  Oh, great.\n",
      "Real answer : Bullshit !\n",
      "Bert Score : {'precision': [0.8458518981933594], 'recall': [0.8057276606559753], 'f1': [0.8253023028373718], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 187.82368434650027\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVIVIAN: Now, one more thing. Where do I go for the clothes ? Good stuff, on him.\\n\\n', 'answer': 'In Beverly Hills ? VIVIAN (voice over on the phone) Yeah.', 'gold_tag': 'VIVIAN is looking for high-quality clothes , VIVIAN is possibly preparing for an event or occasion , VIVIAN is coordinating or planning for something , VIVIAN seems to be preparing for a future event', 'last_speaker': 'KIT'}\n",
      "Last word -> KIT : \"In Beverly Hills ? VIVIAN (voice over on the phone) Yeah.\"\n",
      "prediction :  Oh, you don't have to go anywhere.\n",
      "Real answer : In Beverly Hills ? VIVIAN (voice over on the phone) Yeah.\n",
      "Bert Score : {'precision': [0.8462836742401123], 'recall': [0.8091515898704529], 'f1': [0.8273011445999146], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 28.313365139486766\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVIVIAN: Listen, I've been calling you.\\nKIT: Yeah, I know. They told me at the Banana you were looking for me.\\nVIVIAN: You were supposed to come by Tuesday. I left the money at the desk.\\nKIT: I was hiding out from Carlos.\\nVIVIAN: Well, if you picked up the money, you wouldn't have to hide.\\nKIT: Hey, I was busy. I had a life, you know. Nino got beat up. We had to visit him in the hospital. Rachel got arrested. It was a mess. Anyway, I got the money. Thank you very much for saving my ass. Now Carlos can get off of it. You know, he was talking about you last night. He would bust something if he saw you in this outfit. I was afraid to hug you up there. I might wrinkle you ! You look really good. No, something with shade. You clean up real nice. You sure don't fit in down on the Boulevard looking like you do, not that you ever did.\\nVIVIAN: Well, thanks, but it's easy to clean up when you got money. Tomorrow.\\nKIT: You get to keep the clothes ?\\nVIVIAN: Yeah. Edward asked me if I wanted to see him again. But I think... I think definitely no. I mean, it's just another week, right ?\\nKIT: �Definitely no�.\\nVIVIAN: Yeah.\\nKIT: Oh, no.\\nVIVIAN: What ?\\nKIT: I know this weepy look on your face.\\nVIVIAN: Oh, no, you don't !\\nKIT: You fell in love with him.\\nVIVIAN: No. Kit, please. Stop it.\\nKIT: You've fallen in love with him ?\\nVIVIAN: Kit !\\nKIT: Did you kiss him ? On the mouth ?\\nVIVIAN: Uh, yeah, yeah... I did.\\nKIT: You kissed him on the mouth ?\\nVIVIAN: I did. It was nice.\\nKIT: Did I not teach you anything ?\\nVIVIAN: Look, I'm not stupid, okay ? I'm... I'm not in love with him. I just... I like him.\\nKIT: You like him ?\\nVIVIAN: Yeah.\\nKIT: You definitely like him. Well, he's not a bum. He's a rich, classy guy.\\nVIVIAN: Who's gonna break my heart, right ?\\nKIT: Oh, no. Come on. You don't know that. Hey, he asked you, right ? Maybe you guys could, like, um, you know, get a house together. Like, buy some diamonds and a horse. I don't know. Anyway, it could work. It happens.\\nVIVIAN: When does it happen, Kit ? When does it really happen ? Who does it really work out for ? Did it work out for Skinny Marie or Rachel ? No !\\nKIT: Those were very specific cases of crackheads.\\nVIVIAN: I just wanna know who it works out for. You give me one example of somebody that we know that it happened for.\\nKIT: Name someone ?\\nVIVIAN: Yeah, one person that it worked out for.\\nKIT: You want me to give you a name or something.\\nVIVIAN: Yeah. I'd like to know.\\n\\n\", 'answer': 'Oh, God, the pressure of a name. Cinder-fucking-rella.', 'gold_tag': 'KIT has street smarts, navigating tough situations and being mindful of appearances', 'last_speaker': 'KIT'}\n",
      "Last word -> KIT : \"Oh, God, the pressure of a name. Cinder-fucking-rella.\"\n",
      "prediction :  Okay, how about... how about Mr. Green ?\n",
      "Real answer : Oh, God, the pressure of a name. Cinder-fucking-rella.\n",
      "Bert Score : {'precision': [0.8267444968223572], 'recall': [0.8142733573913574], 'f1': [0.8204615116119385], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 212.0361305268255\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIT: We look so dopey. San Francisco's not that great, you know. It's bad climate. It's foggy. It's unpredictable.\\nVIVIAN: I'll wear a sweater.\\nKIT: What are you gonna do there ?\\nVIVIAN: Get a job. Finish high school. I got things I can do. I used to make pretty good grades in high school.\\nKIT: Yeah, I could see that about you. I could see that.\\nVIVIAN: Sure you won't come with me ?\\nKIT: And leave all this ? Not in a million.\\nVIVIAN: Come here.\\nKIT: Whoa. Whoa. What is this ?\\nVIVIAN: It's part of the Edward Lewis scholarship fund. We think you got a lot of potential, Kit De Luca.\\nKIT: You do ? You think I got potential ?\\nVIVIAN: Oh, yeah. Don't let anybody tell you different, okay ?\\nKIT: Okay.\\nVIVIAN: Take care of you.\\nKIT: No, I can't, I can't. It's your favorite. What time's your bus ?\\nVIVIAN: An hour.\\nKIT: Yeah, well, I gotta split, 'cause good-byes make me crazy. So, take care of you.\\n\\n\", 'answer': 'Whoa.', 'gold_tag': 'Everyday Language', 'last_speaker': 'VIVIAN'}\n",
      "Last word -> VIVIAN : \"Whoa.\"\n",
      "prediction :  Kit, I can't do it.\n",
      "Real answer : Whoa.\n",
      "Bert Score : {'precision': [0.8451474905014038], 'recall': [0.8710213899612427], 'f1': [0.8578894138336182], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 51.38199919579586\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDEVANEY: So, you won't protect Rachel Marron just because she's in show business?\\nFRANK: I don't do celebrities.\\nDEVANEY: But the biggest money's in show business people. Do you really do these things?\\nFRANK: Isn't she the one who collects dolls?\\nDEVANEY: Farmer, Rachel Marron is one of the most famous people in America. She's won every music award invented. She's got the number one song in the country right now and she'll probably be nominated for an Oscar in her very Yes. She collects dolls.\\nFRANK: I thought I knew who she was.\\nDEVANEY: You're probably deadly with these things, aren't you?\\nFRANK: Deadly.\\nDEVANEY: Show me. Why are you resisting this job? $2,500.\\nFRANK: There are several good men available for that kind of money. Have you talked to Fitzgerald or Racine? Portman?\\nDEVANEY: Yeah. Portman was interested... ... but we're told you're the best.\\nFRANK: There's no such thing.\\nDEVANEY: Farmer, we're talking about a very frightened lady. With a seven-year old son. Believe me, I wouldn't be here if I didn't think this was for real. Farmer, she begged me to get you.\\nFRANK: All right. I'll come and I'll look the situation over. If I take it, it's three thousand a week.\\nDEVANEY: Okay. You must be very deadly for three grand a week.\\n\\n\", 'answer': 'Shit. Sorry. Better not stand right behind me.', 'gold_tag': \"FRANK is a professional bodyguard with a reputation for being 'deadly'\", 'last_speaker': 'FRANK'}\n",
      "Last word -> FRANK : \"Shit. Sorry. Better not stand right behind me.\"\n",
      "prediction :  You're damn right I am.\n",
      "Real answer : Shit. Sorry. Better not stand right behind me.\n",
      "Bert Score : {'precision': [0.8190993070602417], 'recall': [0.8600133657455444], 'f1': [0.8390578627586365], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714288, 'rouge2': 0.0, 'rougeL': 0.14285714285714288, 'rougeLsum': 0.14285714285714288}\n",
      "bleu 1/2 : 0.10976232721880529 0.03880684294761699\n",
      "ppl : 18.827336576860848\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDEVANEY: Farmer, will you wait a minute? I should have told you more. I'm sorry but I was afraid she wouldn't go through with it. I thought I'd let the two of you work it out... come to an understanding.\\nFRANK: We did.\\n\\n\", 'answer': \"She's not a bad person, and whether she knows it or not, she needs you. You've come this far... Would you just wait here for one minute. I want to show you something. Please,\", 'gold_tag': 'DEVANEY cares about a \"she\" character, suggesting empathy and responsibility , DEVANEY instructs FRANK to \"wait here for one minute\", indicating a near future expectation', 'last_speaker': 'DEVANEY'}\n",
      "Last word -> DEVANEY : \"She's not a bad person, and whether she knows it or not, she needs you. You've come this far... Would you just wait here for one minute. I want to show you something. Please,\"\n",
      "prediction :  That's all right.\n",
      "Real answer : She's not a bad person, and whether she knows it or not, she needs you. You've come this far... Would you just wait here for one minute. I want to show you something. Please,\n",
      "Bert Score : {'precision': [0.8653185963630676], 'recall': [0.8162452578544617], 'f1': [0.8400658369064331], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.049999999999999996, 'rouge2': 0.0, 'rougeL': 0.049999999999999996, 'rougeLsum': 0.049999999999999996}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 57.05383982775231\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDEVANEY: ...She won't give you any static, Frank, you've got my word on that.\\nFRANK: Sure she will.\\nDEVANEY: So what job's perfect? You're a bodyguard, aren't you?\\n\\n\", 'answer': \"Yeah. Devaney, if you ever lie to me again, I'll take you apart.\", 'gold_tag': 'FRANK threatens DEVANEY , FRANK suggests an assertive personality', 'last_speaker': 'FRANK'}\n",
      "Last word -> FRANK : \"Yeah. Devaney, if you ever lie to me again, I'll take you apart.\"\n",
      "prediction :  Uh-huh.\n",
      "Real answer : Yeah. Devaney, if you ever lie to me again, I'll take you apart.\n",
      "Bert Score : {'precision': [0.79225754737854], 'recall': [0.8384990692138672], 'f1': [0.8147227168083191], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 98.24153081040103\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFRANK: Thuringer, this is Farmer. Where's your man on the door to the suite? Well get someone up here. He doesn't know.\\n\\n\", 'answer': 'Where are you going?', 'gold_tag': \"DEVANEY asks questions , DEVANEY indicates a sincere interest in FRANK's activities\", 'last_speaker': 'DEVANEY'}\n",
      "Last word -> DEVANEY : \"Where are you going?\"\n",
      "prediction :  He's dead. He's dead, Farmer.\n",
      "Real answer : Where are you going?\n",
      "Bert Score : {'precision': [0.8506935238838196], 'recall': [0.8268568515777588], 'f1': [0.8386058211326599], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 26.955678578411458\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFRANK: I'm through. I'll get you back to\\nDEVANEY: She got another call, while you were downstairs and she answered it herself. It was him, Frank. Same guy.\\nFRANK: I don't care.\\nDEVANEY: Farmer, it really shook her up. She thought it was going to be\\nFRANK: Save it, Devaney. The people who hire me don't have to be convinced to save their own lives. Call me when she's ready to go down.\\n\\n\", 'answer': 'Farmer --', 'gold_tag': 'Everyday Language', 'last_speaker': 'DEVANEY'}\n",
      "Last word -> DEVANEY : \"Farmer --\"\n",
      "prediction :  I'll call you when she's ready.\n",
      "Real answer : Farmer --\n",
      "Bert Score : {'precision': [0.8228839635848999], 'recall': [0.7521158456802368], 'f1': [0.7859100103378296], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 28.25998584935954\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKYLE: Oh, Jesus, I'm sorry. God, if anyone should know not to do that, it's me. I'm sorry. O.K.? Sad, huh? She's been here six months. Her name's TIFFANY.\\nKIRSTY: What's the matter with her?\\nKYLE: Almost complete withdrawal. She hasn't said a word for nearly two years.\\nKIRSTY: God, that's terrible.\\n\\n\", 'answer': \"Yeah. Doctor Malahide's got her doing these jig-saws and things, though. Says it's helping to bring her out.\", 'gold_tag': 'KYLE knows about therapeutic activities for patients', 'last_speaker': 'KYLE'}\n",
      "Last word -> KYLE : \"Yeah. Doctor Malahide's got her doing these jig-saws and things, though. Says it's helping to bring her out.\"\n",
      "prediction : Yeah, it is. I've tried everything. I've tried every type of therapy, every drug, everything. I've even tried to get her to talk to me.\n",
      "Real answer : Yeah. Doctor Malahide's got her doing these jig-saws and things, though. Says it's helping to bring her out.\n",
      "Bert Score : {'precision': [0.8631166219711304], 'recall': [0.8657397031784058], 'f1': [0.8644261956214905], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16326530612244897, 'rouge2': 0.0, 'rougeL': 0.16326530612244897, 'rougeLsum': 0.16326530612244897}\n",
      "bleu 1/2 : 0.07999999999999999 0.01825741858350553\n",
      "ppl : 6.486861037597482\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKYLE: Anyway, let's concentrate on you for a moment. Wanna suck on this for me?\\nKIRSTY: Hey, good joke, Kyle. Do you always come on to the mentally ill?\\nKYLE: Shit. Sorry. Here's the\\n\\n\", 'answer': \"Jesus, I'm glad I'm not paying for this place. Daddy...\", 'gold_tag': \"KIRSTY refers to a 'Daddy', suggesting she has family connections\", 'last_speaker': 'KIRSTY'}\n",
      "Last word -> KIRSTY : \"Jesus, I'm glad I'm not paying for this place. Daddy...\"\n",
      "prediction :  No, I don't think so.\n",
      "Real answer : Jesus, I'm glad I'm not paying for this place. Daddy...\n",
      "Bert Score : {'precision': [0.8532670736312866], 'recall': [0.8512177467346191], 'f1': [0.8522412180900574], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.499148283028735\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIRSTY: I...I had a visitor.\\nKYLE: What?\\nKIRSTY: Oh, Jesus. I can't explain. It's ...it's. I don't know how to\\nKYLE: Kirsty, I'm sorry... don't understand. I...\\nKIRSTY: I know. No-one can. But I have to save him. Where's the other doctor? He said He'd listen. He promised.\\nKYLE: Dr. Malahide. Yes. Look, I'll fetch him. You take it easy. I'm sure he can help.\\nKIRSTY: Help. No, no-one can help. I just want someone to listen or I WILL go crazy.\\nKYLE: If anyone can help, HE can.\\n\\n\", 'answer': 'Yeah? He got a ticket to Hell?', 'gold_tag': 'Everyday Language', 'last_speaker': 'KIRSTY'}\n",
      "Last word -> KIRSTY : \"Yeah? He got a ticket to Hell?\"\n",
      "prediction :  I know.\n",
      "Real answer : Yeah? He got a ticket to Hell?\n",
      "Bert Score : {'precision': [0.8704484105110168], 'recall': [0.8432726860046387], 'f1': [0.8566451072692871], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 663.9337011017111\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIRSTY: Shit, Kyle. This is getting to be a habit. What is it, some kind of shock-therapy? Oh, Jesus. What is it?\\n\\n', 'answer': \"It's all true.\", 'gold_tag': 'KYLE exposes truths , KYLE exposes truths even if they might be shocking or disturbing , KIRSTY and KYLE seem to have previously experienced shocking or uncomfortable situations together', 'last_speaker': 'KYLE'}\n",
      "Last word -> KYLE : \"It's all true.\"\n",
      "prediction :  You're just not getting it, are you?\n",
      "Real answer : It's all true.\n",
      "Bert Score : {'precision': [0.8350284695625305], 'recall': [0.8622511625289917], 'f1': [0.8484214544296265], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.131938388854717\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKYLE: You O.K.? Kirsty? You 0. K.?\\nKIRSTY: No bad dreams.\\nKYLE: So you slept O.K.?\\nKIRSTY: As much as that bed of nails allowed.\\nKYLE: Well, the sofa isn't often used for sleeping on...\\nKIRSTY: Oh yeah? On your own a lot, Huh?\\nKYLE: Like the robe? I think I need to talk. About what I saw.\\nKIRSTY: You thought I was crazy, didn't you?\\nKYLE: Jesus, yes! What do you expect. I mean, God, I still do! It's just that now I'm crazy too.\\nKIRSTY: And you're sure it was a woman?\\nKYLE: God, I wish I could say no. This is going to do terrible things to my attitude, you know.\\nKIRSTY: Don't worry about it. Your attitude sucks anyway.\\nKYLE: Hey, so for it. Don't let pity stop you. I'm down. Nail me.\\nKIRSTY: What can I do? How can I save him? The box. I need the box.\\nKYLE: The box? Like in your story? Like in his house?\\nKIRSTY: What?\\nKYLE: The Boxes. In the House. I told you.\\nKIRSTY: What do you mean?\\nKYLE: The boxes! I TOLD you.\\nKIRSTY: You DIDN'T tell me. Do you mean Malahide's got...\\nKYLE: Yeah. The things you were talking about.\\nKIRSTY: I'm going.\\nKYLE: Wait a minute. What do you mean, 'I'm going?' TO the HOUSE?\\nKIRSTY: Get out of the way.\\nKYLE: Are you crazy?\\nKIRSTY: I don't know, Kyle. You're the fucking expert. Now get out of the way!\\nKYLE: WHY?\\nKIRSTY: Because I'm going to get my father! I'm going to get my father.\\nKYLE: Two seconds. Just two seconds. Don't move. O.K. Let's go.\\nKIRSTY: Kyle, you don't have...\\n\\n\", 'answer': \"I KNOW I don't have to. It's just my time of the month to be a complete fucking idiot. O.K.?\", 'gold_tag': 'KYLE may be a logical person', 'last_speaker': 'KYLE'}\n",
      "Last word -> KYLE : \"I KNOW I don't have to. It's just my time of the month to be a complete fucking idiot. O.K.?\"\n",
      "prediction :  I don't have anything. I'm not your friend. I'm not going anywhere with you.\n",
      "Real answer : I KNOW I don't have to. It's just my time of the month to be a complete fucking idiot. O.K.?\n",
      "Bert Score : {'precision': [0.8599085807800293], 'recall': [0.8403444290161133], 'f1': [0.8500139713287354], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.15789473684210525, 'rougeL': 0.19999999999999998, 'rougeLsum': 0.19999999999999998}\n",
      "bleu 1/2 : 0.13959408375665475 0.11828065604208322\n",
      "ppl : 10.8652908972937\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTEW: Here it is. Pray for me, Gallagher. Pray for me. Hold everything . . . Stew, your hands are shaking. You've been drinking again. Here they come! There's the third one. If I don't get the last one, there's a certain sob sister I know that's going to get a kick right in the . . . oh! Whoops, almost had that.\\nCONROY: What? The screen?\\n\\n\", 'answer': 'Gallagher! I made it!', 'gold_tag': 'Everyday Language', 'last_speaker': 'STEW'}\n",
      "Last word -> STEW : \"Gallagher! I made it!\"\n",
      "prediction :  Yeah. I'm going to be a star. I'm going to be a star.\n",
      "Real answer : Gallagher! I made it!\n",
      "Bert Score : {'precision': [0.8851374387741089], 'recall': [0.8685817122459412], 'f1': [0.8767814636230469], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473685, 'rouge2': 0.0, 'rougeL': 0.10526315789473685, 'rougeLsum': 0.10526315789473685}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 10.066860839868731\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCONROY: Come over here! Look, I quit! Yeah?\\nSTEW: Yeah.\\nCONROY: Yeah?\\nSTEW: You're always picking on me. It took me three hours to get those little gadgets in those holes, and you screw it up in a minute. Hey, look! Mmm, not as easy as it looks, is it?\\nCONROY: Aagh! No wonder you're batty. Would it be imposing too much upon you if I asked you to do a little work today? Just to sort of break the monotony?\\nSTEW: With me you can always do business. It isn't a question of knowing what to do, it's knowing how to get in one that counts.\\nCONROY: Yeah, yeah. Okay, okay. Yeah, little Gloria.\\nSTEW: into the Schuyler kid, eh?\\nCONROY: Right - for the first time this year.\\nSTEW: Well - it's only April.\\nCONROY: Come on, get going, get going!\\nSTEW: Get going where? I can write that yarn without stepping out of the office.\\nCONROY: Yeah - and get us into a million dollar time. Now, you get over there and get a statement out of the old lady, the sister, or the kid. Any of them - but get it.\\n\\n\", 'answer': \"All right. Give me a voucher for expenses. I know those bluenoses. Their ancestors refused to come over on the Mayflower because they didn't want to rub elbows with the tourists. So they swam over.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'STEW'}\n",
      "Last word -> STEW : \"All right. Give me a voucher for expenses. I know those bluenoses. Their ancestors refused to come over on the Mayflower because they didn't want to rub elbows with the tourists. So they swam over.\"\n",
      "prediction :  I'm not getting any statement from the kid.\n",
      "Real answer : All right. Give me a voucher for expenses. I know those bluenoses. Their ancestors refused to come over on the Mayflower because they didn't want to rub elbows with the tourists. So they swam over.\n",
      "Bert Score : {'precision': [0.8587725162506104], 'recall': [0.8277516961097717], 'f1': [0.8429768681526184], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08888888888888888, 'rouge2': 0.0, 'rougeL': 0.08888888888888888, 'rougeLsum': 0.08888888888888888}\n",
      "bleu 1/2 : 0.004277264788958255 0.0014459794139954157\n",
      "ppl : 90.86896171091553\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTEW: Me?\\nCONROY: You double-crossing hound! Come over here!\\nSTEW: Now listen boss, if you're going to kick about that expense account�\\nCONROY: Do you call yourself a reporter? the bright lad that's never been scooped!\\nSTEW: Not on my own beat, no.\\nCONROY: No? Well, where were you when that happened? Not knowing what it is all about, Stew, I've heard of people being scooped on their own funerals, but this! Holy mackerel! Why, it's news when Anne Schuyler gets her fingernails manicured, but this! She gets married to one of our own reporters and the Tribune beat us to it! Well! What do you guys want? Go on, get back to your desks. Go back to your Now don't tell me you were drunk at the time and don't remember! Or is this No, no - it's true, all right, only we didn't want to get it in print yet, that's all. Why not?\\nSTEW: Well, you see, I've acquired one of those new mother-in-laws, and we were afraid she wouldn't understand the whole idea. So we were going to wait till she went to Europe.\\nCONROY: What do I care about your mother-in-law! You're still working for this paper, aren't you! Or are you?\\nSTEW: Yes, sir.\\nCONROY: Well, it's your business to get news! And here you had a story right in your own lap and you let the Tribune scoop us on it. Making a first class Grade A monkey out of me. If it ever happens again - just don't bother about coming back. That's all.\\n\\n\", 'answer': \"Thanks for your congratulations. What's the matter with you mugs? Can't a guy get married without all this?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'STEW'}\n",
      "Last word -> STEW : \"Thanks for your congratulations. What's the matter with you mugs? Can't a guy get married without all this?\"\n",
      "prediction :  It's your business to get news!\n",
      "Real answer : Thanks for your congratulations. What's the matter with you mugs? Can't a guy get married without all this?\n",
      "Bert Score : {'precision': [0.8043138980865479], 'recall': [0.809209406375885], 'f1': [0.8067542314529419], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2222222222222222, 'rouge2': 0.0, 'rougeL': 0.14814814814814817, 'rougeLsum': 0.14814814814814817}\n",
      "bleu 1/2 : 0.045111761078870896 0.011050079604157968\n",
      "ppl : 150.33849502506388\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMARY: Are you in there, Harry?\\nHARRY: Be right out.\\nMARY: I hope you're not using the toilet. It's broken.\\nHARRY: Huh?\\nMARY: It doesn't flush.\\n\\n\", 'answer': 'Um, no, I was just... shaving.', 'gold_tag': 'HARRY is suggested to be shaving', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"Um, no, I was just... shaving.\"\n",
      "prediction :  Oh, I see.\n",
      "Real answer : Um, no, I was just... shaving.\n",
      "Bert Score : {'precision': [0.8757750988006592], 'recall': [0.8444650769233704], 'f1': [0.8598352074623108], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2222222222222222, 'rouge2': 0.0, 'rougeL': 0.2222222222222222, 'rougeLsum': 0.2222222222222222}\n",
      "bleu 1/2 : 0.12262648039048077 0.04749303163563625\n",
      "ppl : 68.32818314572262\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMARY: Shaving?\\nHARRY: Yeah! I was running a little late. Thought this would save time.\\n\\n', 'answer': \"Okay. Well I'll be in the living room whenever you're ready.\", 'gold_tag': \"MARY is patient and understanding , MARY responds to Harry's unusual behavior with acceptance\", 'last_speaker': 'MARY'}\n",
      "Last word -> MARY : \"Okay. Well I'll be in the living room whenever you're ready.\"\n",
      "prediction :  It doesn't work like that.\n",
      "Real answer : Okay. Well I'll be in the living room whenever you're ready.\n",
      "Bert Score : {'precision': [0.8394640684127808], 'recall': [0.8311682939529419], 'f1': [0.835295557975769], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 31.30420793215218\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHARRY: Uh... just cleaning my teeth. Give me a minute, Mary, I'll be right with you.\\nMARY: Sorry, but something important's come up and I have to run out. It's sort of an emergency. I'll explain later.\\nHARRY: But Mary --\\nMARY: --I'm really sorry, Harry. I promise we'll do this another time.\\n\\n\", 'answer': 'Great...', 'gold_tag': 'Everyday Language', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"Great...\"\n",
      "prediction :  Mary, wait.\n",
      "Real answer : Great...\n",
      "Bert Score : {'precision': [0.8646414279937744], 'recall': [0.838543176651001], 'f1': [0.851392388343811], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2633.4134335936797\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMATT: What? Wh-where?\\nSARA: Honey? You alright?\\n\\n', 'answer': 'Yeah. Just a dream. I guess.', 'gold_tag': 'MATT has just experienced a dream', 'last_speaker': 'MATT'}\n",
      "Last word -> MATT : \"Yeah. Just a dream. I guess.\"\n",
      "prediction :  I’m okay. I just saw something. I was walking through the park and I saw this old man.\n",
      "Real answer : Yeah. Just a dream. I guess.\n",
      "Bert Score : {'precision': [0.85756516456604], 'recall': [0.8932567238807678], 'f1': [0.8750471472740173], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16, 'rouge2': 0.0, 'rougeL': 0.16, 'rougeLsum': 0.16}\n",
      "bleu 1/2 : 0.05555555555555554 0.018077538151554672\n",
      "ppl : 15.06614638921238\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSARA: Honey? You feeling alright?\\nMATT: Mom!\\nSARA: What now?\\n\\n', 'answer': 'Um, nothing - just, thanks - for', 'gold_tag': 'MATT displayed gratitude towards his mother in this conversation , MATT possibly indicates a respectful and appreciative nature', 'last_speaker': 'MATT'}\n",
      "Last word -> MATT : \"Um, nothing - just, thanks - for\"\n",
      "prediction :  I can't breathe.\n",
      "Real answer : Um, nothing - just, thanks - for\n",
      "Bert Score : {'precision': [0.8620299696922302], 'recall': [0.7916341423988342], 'f1': [0.8253336548805237], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 34.94850473322591\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMATT: It hurts! Oh God it hurts!\\nSARA: What have you done to yourself!?\\n\\n', 'answer': 'I didn’t! I didn’t!', 'gold_tag': 'Everyday Language', 'last_speaker': 'MATT'}\n",
      "Last word -> MATT : \"I didn’t! I didn’t!\"\n",
      "prediction :  I told you. I had to do it.\n",
      "Real answer : I didn’t! I didn’t!\n",
      "Bert Score : {'precision': [0.8889321088790894], 'recall': [0.8431130051612854], 'f1': [0.8654165267944336], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0.25 0.059761430466719695\n",
      "ppl : 52.53096961296974\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBUD: I can't believe you were dumb enough to come down. Now you're stuck here for the storm... dumb, hot-rod... dumb.\\n\\n\", 'answer': \"Look, I didn't come down here to fight.\", 'gold_tag': \"LINDSEY is portrayed as brave or reckless , LINDSEY is in a conflict with BUD , LINDSEY doesn't want to fight\", 'last_speaker': 'LINDSEY'}\n",
      "Last word -> LINDSEY : \"Look, I didn't come down here to fight.\"\n",
      "prediction :  What do you want me to do?\n",
      "Real answer : Look, I didn't come down here to fight.\n",
      "Bert Score : {'precision': [0.8553308248519897], 'recall': [0.8584213256835938], 'f1': [0.8568732738494873], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.12383969996431167 0.04229931028018368\n",
      "ppl : 21.92352315085215\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBUD: Then why'd you come down?\\nLINDSEY: You need me. Nobody knows the systems on this rig better than I do. What is something was to go wrong after the Explorer clears off? What would have you done?\\n\\n\", 'answer': \"Wow, you're right! Us poor dumb ol' boys might've had to think for ourselves. Coulda been a disaster.\", 'gold_tag': 'BUD is a sarcastic person', 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"Wow, you're right! Us poor dumb ol' boys might've had to think for ourselves. Coulda been a disaster.\"\n",
      "prediction :  I'd have called the company.\n",
      "Real answer : Wow, you're right! Us poor dumb ol' boys might've had to think for ourselves. Coulda been a disaster.\n",
      "Bert Score : {'precision': [0.882371187210083], 'recall': [0.8341906666755676], 'f1': [0.8576048016548157], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 166.4382717226298\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBUD: You wanna know what I think?\\nLINDSEY: Not particularly. Jeez, look where this is set! Morons.\\nBUD: I think you were worried about me.\\nLINDSEY: That must be it.\\nBUD: No, I think you were. Come on, admit it.\\nLINDSEY: I was worried about the rig. I've got over four years invested in this project.\\nBUD: Oh, yeah, right... and you only had three years with me.\\n\\n\", 'answer': \"You've got to have priorities.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'LINDSEY'}\n",
      "Last word -> LINDSEY : \"You've got to have priorities.\"\n",
      "prediction :  I'm sorry. I didn't mean to be so cold.\n",
      "Real answer : You've got to have priorities.\n",
      "Bert Score : {'precision': [0.8576244711875916], 'recall': [0.8667609691619873], 'f1': [0.8621684312820435], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352942, 'rouge2': 0.0, 'rougeL': 0.11764705882352942, 'rougeLsum': 0.11764705882352942}\n",
      "bleu 1/2 : 0.11111111111111109 0.03726779962499649\n",
      "ppl : 13.032021425682709\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBUD: My bunk\\'s the only one I can guarantee won\\'t be occupied. You can grab a couple hours before we get there.\\nLINDSEY: What are you still wearing that for?\\nBUD: I don\\'t know. Divorce ain\\'t final. Forgot to take it off.\\nLINDSEY: I haven\\'t worn mine in months.\\nBUD: Yeah, what\\'s-his-name wouldn\\'t like it. The\\nLINDSEY: Do you always have to call him that? The Suit? It makes you sound like such a hick. His name is Michael.\\nBUD: So what about \"Michael\" then... Mr. Brooks Brothers... Mr. BMW. You still seeing him?\\nLINDSEY: No, I haven\\'t seen him in a few weeks.\\nBUD: What happened?\\nLINDSEY: Bud, why are you doing this? It\\'s not part of you life any more.\\nBUD: I\\'ll tell you what happened... you woke up one day and realized the guy never made you laugh.\\n\\n', 'answer': \"You're right, Bud. It was just that simple. Aren't you clever? You should get your own show... Ask Dr. Bud, advice to the lovelorn from three hundred fathoms. AAAARRRGGH! Shit.\", 'gold_tag': 'LINDSEY gets frustrated easily , LINDSEY uses sarcasm as a defense mechanism', 'last_speaker': 'LINDSEY'}\n",
      "Last word -> LINDSEY : \"You're right, Bud. It was just that simple. Aren't you clever? You should get your own show... Ask Dr. Bud, advice to the lovelorn from three hundred fathoms. AAAARRRGGH! Shit.\"\n",
      "prediction :  He did too.\n",
      "Real answer : You're right, Bud. It was just that simple. Aren't you clever? You should get your own show... Ask Dr. Bud, advice to the lovelorn from three hundred fathoms. AAAARRRGGH! Shit.\n",
      "Bert Score : {'precision': [0.8652693629264832], 'recall': [0.7939411997795105], 'f1': [0.8280720710754395], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 652.5821320110208\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINDSEY: Got it! It's dropping straight to us.\\n\\n\", 'answer': \"Rig for impact! Seal all exterior hatches. Move it! Let's go!\", 'gold_tag': 'BUD is in a position of authority and decisiveness , BUD is likely related to a job in a high-stakes environment such as deep-sea exploration or military operations', 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"Rig for impact! Seal all exterior hatches. Move it! Let's go!\"\n",
      "prediction :  It is?\n",
      "Real answer : Rig for impact! Seal all exterior hatches. Move it! Let's go!\n",
      "Bert Score : {'precision': [0.819083034992218], 'recall': [0.8114769458770752], 'f1': [0.8152623176574707], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1292.0091690792497\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBUD: Jesus, Lindsey--\\nLINDSEY: Bud, something really important is happening here.\\nBUD: Look. I'm just trying to hold this situation together. I can't allow you to cause this kind of hysteria--\\nLINDSEY: Who's hysterical? Nobody's hysterical!\\nBUD: All I'm saying is when you're hanging on by your fingernails, you don't go waving you arms around.\\nLINDSEY: I saw something! I'm not going to go back there and say I didn't see it when I did. I'm sorry.\\nBUD: God, you are the most stubborn woman I ever knew.\\nLINDSEY: I need you to believe me, Bud. Look at me. Do I seem stressed out? Any of the symptoms of pressure sickness, any tremors, slurred speech?\\nBUD: No.\\nLINDSEY: Bud, this is me, Lindsey. Okay? You know me better than anybody in the world. Now watch my lips... I saw these things. I touched one of them. And it wasn't some clunky steel can like we would build... it glided. It was the most beautiful thing I've ever seen. It was a machine, but it seems almost alive. Like a... dance of light. Bud, you have to trust me... please. I don't think they mean us harm. I don't know how I know that, it's just a feeling.\\nBUD: How can I go on a feeling? You think Coffey's going to go on you 'feeling'?\\nLINDSEY: We all see what we want to see... Coffey looks and he sees Russians, he sees hate and fear. Bud, you have to look with better eyes than that.\\n\\n\", 'answer': \"I can't, Lindsey. I'm sorry. How can I?\", 'gold_tag': 'BUD is skeptical and pragmatic', 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"I can't, Lindsey. I'm sorry. How can I?\"\n",
      "prediction : ::: sighs :::::\n",
      "Real answer : I can't, Lindsey. I'm sorry. How can I?\n",
      "Bert Score : {'precision': [0.7415380477905273], 'recall': [0.8196980953216553], 'f1': [0.7786616086959839], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 82.18436776311535\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBUD: I think it likes you.\\n\\n', 'answer': 'Seawater. Show off.', 'gold_tag': 'Everyday Language', 'last_speaker': 'LINDSEY'}\n",
      "Last word -> LINDSEY : \"Seawater. Show off.\"\n",
      "prediction :  Why?\n",
      "Real answer : Seawater. Show off.\n",
      "Bert Score : {'precision': [0.8540754318237305], 'recall': [0.8426099419593811], 'f1': [0.848304033279419], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3142.135932895678\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINDSEY: You owe me one, Virgil.\\n\\n', 'answer': \"Can we negotiate later? There's Big Geek.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"Can we negotiate later? There's Big Geek.\"\n",
      "prediction :  What's that?\n",
      "Real answer : Can we negotiate later? There's Big Geek.\n",
      "Bert Score : {'precision': [0.8274221420288086], 'recall': [0.8229146003723145], 'f1': [0.8251622319221497], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 87.94740186916538\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINDSEY: You did okay, back there. I was fairly impressed.\\nBUD: Not good enough. We still gotta catch Big Geek.\\nLINDSEY: Not in this thing.\\nBUD: You totaled it, huh?\\nLINDSEY: Yeah. So sue me.\\nBUD: It's flooding like a son of the bitch.\\nLINDSEY: You noticed. Deepcore, Deepcore, this is Cab One, over.\\nBUD: Try again.\\nLINDSEY: Deepcore, this is Cab One. We need assistance, over. Deepcore, this-- Well, that's that.\\nBUD: Wonderful.\\nLINDSEY: Over there. It's the rig.\\nBUD: Good hundred yards, I'd say.\\nLINDSEY: They'll come out after us.\\nBUD: Yeah, but it's gonna take them a while to find us. We better get this flooding stopped.\\nLINDSEY: You see where it's coming in?\\nBUD: Somewhere behind this panel. Hold this. Can't get to it. Have to pull this panel off. You go any tools?\\nLINDSEY: I don't know, look around.\\nBUD: Nothing. Son of a bitch. All I need's a goddamn crescent wrench. Son of a bitch!\\nLINDSEY: Calm down, Bud.\\nBUD: Okay... okay. We gotta get you out of here.\\nLINDSEY: How?\\nBUD: I don't know how!\\nLINDSEY: We've only got one suit.\\nBUD: I know! I know! But we better come up with something.\\nLINDSEY: Aaargh!! I'm freezing! Okay, look, you swim to the rig and come back with another suit.\\nBUD: Seven, eight minute swim each way... not enough time. Look at this... Time I get back you'll be-- Alright, put this on.\\nLINDSEY: What, you growing gills all of a sudden? You got it on, keep it on.\\nBUD: Don't argue, goddamnit, just--\\nLINDSEY: No way! Forget it. Not an option.\\nBUD: Lindsey, just put the thing on and shut up--\\nLINDSEY: NO!! Now be logical, Bud, you're--\\nBUD: FUCK LOGIC!!\\nLINDSEY: Listen... will you listen to me for a second!? You're for the suit on and you're a better swimmer than me. Right? So I got a plan...\\nBUD: What's the plan?\\nLINDSEY: I drown, you tow me back to the rig-- Look, this water is only a couple degrees above freezing. I drown. I go into deep hypothermia... my blood like icewater. I can maybe be revived after ten, fifteen minutes. You got all the stuff to do it on the rig.\\nBUD: It is insane.\\nLINDSEY: It's the only way, Bud. Now trust me.\\nBUD: Jesus, I don't believe this is happening. Oh God, Lins... I--\\nLINDSEY: Tell me later. This is maybe not such a great plan, is it? Hold me. Hold me, Bud... I'm so scared...\\n\\n\", 'answer': 'NOOOOO!!!', 'gold_tag': 'Everyday Language', 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"NOOOOO!!!\"\n",
      "prediction :  I'm here. I'm here. I'm here, Lindsey. It's okay. I got you. I'm here. You're safe. You're safe.\n",
      "Real answer : NOOOOO!!!\n",
      "Bert Score : {'precision': [0.8195382952690125], 'recall': [0.7891467809677124], 'f1': [0.8040555119514465], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5.3367071630306615\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINDSEY: Hey... big boys don't cry, remember?\\nBUD: Hi, lady.\\nLINDSEY: Hi, tough guy. I guess it worked, huh?\\nBUD: 'Course is worked. You're never wrong, are you? How d'you feel.\\nLINDSEY: I've been better. Next time it's your turn, okay?\\n\\n\", 'answer': 'Well, you got that right.', 'gold_tag': 'BUD is portrayed as a tough guy', 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"Well, you got that right.\"\n",
      "prediction :  Sure.\n",
      "Real answer : Well, you got that right.\n",
      "Bert Score : {'precision': [0.9515312314033508], 'recall': [0.8240946531295776], 'f1': [0.8832398653030396], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 940.7736565945374\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICKY: You’ve worked with Elliot?\\nPAISLEY: I was in the fish-market play. What happened to him?\\nNICKY: There was a review.\\nPAISLEY: I think I remember. Not one of Steven’s finer moments.\\nNICKY: Oh. You know him.\\nPAISLEY: A little.\\nNICKY: And he has finer moments now and then.\\nPAISLEY: He has -- something. A funny little quality I find --\\nNICKY: Endearing.\\nPAISLEY: Engaging.\\nNICKY: Elliot wants to kill him with a railroad spike.\\nPAISLEY: A little drastic maybe?\\nNICKY: Say it again.\\nPAISLEY: What?\\nNICKY: You know what.\\nPAISLEY: Alla puttanesca.\\n\\n', 'answer': 'One more time.', 'gold_tag': 'Everyday Language', 'last_speaker': 'NICKY'}\n",
      "Last word -> NICKY : \"One more time.\"\n",
      "prediction :  How about you? You were in the fish-market play.\n",
      "Real answer : One more time.\n",
      "Bert Score : {'precision': [0.8518391847610474], 'recall': [0.869880735874176], 'f1': [0.8607653975486755], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 176.75382715294452\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAISLEY: I was one of those silent, listening children. Glued to the\\nNICKY: I was all noise. Played the radio loud. Battled constantly with my brother and sister. Here I am, world.\\nPAISLEY: I hear good things about the new play.\\nNICKY: So do I. Over and over.\\nPAISLEY: Peter Redmond is an actor I admire enormously.\\nNICKY: Would you like to meet him?\\nPAISLEY: He doesn’t want to meet some out-of- work ingenue.\\nNICKY: I’m trying to prolong our afternoon. In case you haven’t noticed.\\nPAISLEY: The fact is, I have to get going.\\nNICKY: Is it true?\\nPAISLEY: Is what true?\\nNICKY: He wears a disguise.\\nPAISLEY: Steven goes to extremes to protect his privacy. No friends. No phone.\\nNICKY: But you’re his friend.\\n\\n', 'answer': 'Sort of. Sometimes. You’re not building an obsession about Steven, are you? Look. I understand opening- night jitters, but you’ve got one of the great actors in American theater starring in your play.', 'gold_tag': 'Everyday Language', 'last_speaker': 'PAISLEY'}\n",
      "Last word -> PAISLEY : \"Sort of. Sometimes. You’re not building an obsession about Steven, are you? Look. I understand opening- night jitters, but you’ve got one of the great actors in American theater starring in your play.\"\n",
      "prediction :  Yes.\n",
      "Real answer : Sort of. Sometimes. You’re not building an obsession about Steven, are you? Look. I understand opening- night jitters, but you’ve got one of the great actors in American theater starring in your play.\n",
      "Bert Score : {'precision': [0.9109145402908325], 'recall': [0.8144838213920593], 'f1': [0.8600045442581177], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2104.611116571625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAISLEY: Do you think he can do it?\\nNICKY: I don’t know.\\nPAISLEY: He’s a very sweet man.\\nNICKY: Where are you going now?\\nPAISLEY: Home.\\nNICKY: Someone waiting for you?\\nPAISLEY: No one’s waiting.\\nNICKY: There’s a certain kind of wounded young man who uses his oddness to get laid. Is that our Steven?\\nPAISLEY: If I’m sleeping with him, and I haven’t said I am, then so what?\\nNICKY: So everything. That’s so what. So I begin to hate him. So I want to do him grave harm.\\nPAISLEY: But you don’t even know me. How can you care what I do with whom?\\nNICKY: I know you both. Enough. How much knowledge does it take before a man\\nPAISLEY: Do you want to talk about doing crazy things.\\nNICKY: Yes.\\n\\n', 'answer': 'Never mind.', 'gold_tag': 'Everyday Language', 'last_speaker': 'PAISLEY'}\n",
      "Last word -> PAISLEY : \"Never mind.\"\n",
      "prediction :  I've always been the one who gets hurt.\n",
      "Real answer : Never mind.\n",
      "Bert Score : {'precision': [0.851526141166687], 'recall': [0.888443112373352], 'f1': [0.8695930242538452], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 36.40726292884818\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAUL: What's wrong?\\nANNA: Nothing.\\n\\n\", 'answer': \"You used to enjoy it. Now it's... ...it's like fucking a corpse. Shit. I'm sorry. That was--\", 'gold_tag': 'PAUL has been intimately involved with ANNA , PAUL displays poor communication skills , PAUL has an inability to address conflicts , PAUL uses inappropriate language , Shared memories: Paul recalls a time when Anna used to enjoy their collective activity', 'last_speaker': 'PAUL'}\n",
      "Last word -> PAUL : \"You used to enjoy it. Now it's... ...it's like fucking a corpse. Shit. I'm sorry. That was--\"\n",
      "prediction :  It seems like something's on your mind.\n",
      "Real answer : You used to enjoy it. Now it's... ...it's like fucking a corpse. Shit. I'm sorry. That was--\n",
      "Bert Score : {'precision': [0.8443509340286255], 'recall': [0.8386112451553345], 'f1': [0.8414713144302368], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.21428571428571425, 'rouge2': 0.0, 'rougeL': 0.14285714285714288, 'rougeLsum': 0.14285714285714288}\n",
      "bleu 1/2 : 0.03423586234882512 0.011693773197286032\n",
      "ppl : 39.03324389368358\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNA: Paul?\\nPAUL: Baby. Thank God.\\nANNA: You came back for me.\\nPAUL: I came back for you. You're safe now.\\nANNA: Promise?\\n\\n\", 'answer': 'Promise. Anna? Anna!', 'gold_tag': 'PAUL promises ANNA , PAUL is calling for ANNA', 'last_speaker': 'PAUL'}\n",
      "Last word -> PAUL : \"Promise. Anna? Anna!\"\n",
      "prediction :  I promise.\n",
      "Real answer : Promise. Anna? Anna!\n",
      "Bert Score : {'precision': [0.8789488077163696], 'recall': [0.848800539970398], 'f1': [0.86361163854599], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4, 'rouge2': 0.0, 'rougeL': 0.4, 'rougeLsum': 0.4}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1927.4118517739469\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNA: Are we going home? Or do you want to make love here?\\nPAUL: Where did you go?\\nANNA: I've been waiting for you. I missed you so much. I love you. I always did.\\nPAUL: What was that?\\nANNA: It's only the scissors...\\nPAUL: Scissors? What scissors?\\n\\n\", 'answer': \"Scissors. For your clothes. Eliot just put them on the table. You're safe now. We're finally together.\", 'gold_tag': 'ANNA was in a situation involving scissors and clothes, possibly related to her daily activities or job , PAUL has a close relationship with ANNA', 'last_speaker': 'ANNA'}\n",
      "Last word -> ANNA : \"Scissors. For your clothes. Eliot just put them on the table. You're safe now. We're finally together.\"\n",
      "prediction :  I've got the scissors. I've got the scissors.\n",
      "Real answer : Scissors. For your clothes. Eliot just put them on the table. You're safe now. We're finally together.\n",
      "Bert Score : {'precision': [0.8703890442848206], 'recall': [0.8634747266769409], 'f1': [0.8669180870056152], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13793103448275862, 'rouge2': 0.0, 'rougeL': 0.13793103448275862, 'rougeLsum': 0.13793103448275862}\n",
      "bleu 1/2 : 0.040581558419793724 0.013719070704801007\n",
      "ppl : 12.636182808714162\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOLLY: No.\\nKIT: Well, I was just messing around over there, thought I'd come over and say hello to you. (smiling) I'll try anything once. (pause) What's your name? I said mine. Listen, Holly. you want to take a walk with me?\\nHOLLY: What for?\\n\\n\", 'answer': \"Well. I got some stuff to say. Guess I'm kind of lucky that way. Most people don't have anything on their minds, do they?\", 'gold_tag': 'KIT is shown as a risk-taker , KIT feels superior to others', 'last_speaker': 'KIT'}\n",
      "Last word -> KIT : \"Well. I got some stuff to say. Guess I'm kind of lucky that way. Most people don't have anything on their minds, do they?\"\n",
      "prediction :  Because I'm here and I'm bored. I'm a very bored man.\n",
      "Real answer : Well. I got some stuff to say. Guess I'm kind of lucky that way. Most people don't have anything on their minds, do they?\n",
      "Bert Score : {'precision': [0.8817074298858643], 'recall': [0.8517408967018127], 'f1': [0.866465151309967], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15, 'rouge2': 0.052631578947368425, 'rougeL': 0.15, 'rougeLsum': 0.15}\n",
      "bleu 1/2 : 0.02788368705241425 0.009247972772454902\n",
      "ppl : 22.51782381456407\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOLLY: Did it go the way it 'uz supposed to?\\nKIT: Yeah.\\nHOLLY: Is that all there is to it?\\nKIT: Yeah.\\nHOLLY: Gosh, what was everybody talking about?\\nKIT: Don't ask me.\\nHOLLY: Well. I'm glad it's over... For a while I was afraid I might die before it happened... Had a wreck, some deal like that.\\nKIT: You see where that tree fell in the water?\\n\\n\", 'answer': \"Yeah... The river must've washed the roots away... You don't care about anything I say, though.\", 'gold_tag': 'HOLLY shows some understanding of nature by observing how the river managed to wash away the roots of a tree , HOLLY feels that KIT is not interested in her feelings or what she says', 'last_speaker': 'HOLLY'}\n",
      "Last word -> HOLLY : \"Yeah... The river must've washed the roots away... You don't care about anything I say, though.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : Yeah... The river must've washed the roots away... You don't care about anything I say, though.\n",
      "Bert Score : {'precision': [0.9576817750930786], 'recall': [0.8245147466659546], 'f1': [0.8861230611801147], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473684, 'rouge2': 0.0, 'rougeL': 0.10526315789473684, 'rougeLsum': 0.10526315789473684}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIT: You know what I think?\\nHOLLY: What?\\nKIT: That we should crunch our hands with this stone. That way we'd never forget what happened today.\\nHOLLY: But it would hurt.\\nKIT: Well, that's the point, stupid.\\nHOLLY: Don't call me stupid.\\n\\n\", 'answer': \"Okay, but I'm going to keep it for a souvenir...\", 'gold_tag': 'KIT is adventurous', 'last_speaker': 'KIT'}\n",
      "Last word -> KIT : \"Okay, but I'm going to keep it for a souvenir...\"\n",
      "prediction :  Sorry. Holly, we need to get out of here.\n",
      "Real answer : Okay, but I'm going to keep it for a souvenir...\n",
      "Bert Score : {'precision': [0.8859679698944092], 'recall': [0.8534984588623047], 'f1': [0.8694301843643188], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09999999999999999, 'rouge2': 0.0, 'rougeL': 0.09999999999999999, 'rougeLsum': 0.09999999999999999}\n",
      "bleu 1/2 : 0.09942659075715217 0.03334869235560668\n",
      "ppl : 49.462194937675555\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIT: Hey, where you going?\\n\\n', 'answer': 'Daddy... This is Holly... Are you going to be okay?', 'gold_tag': 'Everyday Language', 'last_speaker': 'HOLLY'}\n",
      "Last word -> HOLLY : \"Daddy... This is Holly... Are you going to be okay?\"\n",
      "prediction :  To the store.\n",
      "Real answer : Daddy... This is Holly... Are you going to be okay?\n",
      "Bert Score : {'precision': [0.8778168559074402], 'recall': [0.7983636260032654], 'f1': [0.8362071514129639], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 756.3413777919834\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOLLY: Are you sure?\\n\\n', 'answer': \"You don't believe me, see for yourself.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'KIT'}\n",
      "Last word -> KIT : \"You don't believe me, see for yourself.\"\n",
      "prediction :  Yes, I am sure.\n",
      "Real answer : You don't believe me, see for yourself.\n",
      "Bert Score : {'precision': [0.8520007729530334], 'recall': [0.8259992599487305], 'f1': [0.8387985825538635], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 46.16164540237781\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOLLY: Listen, maybe we ought to tell somebody about this.\\nKIT: You said that once already... Too late now.\\nHOLLY: Why?\\nKIT: They're not going to listen to me. You either. Are you kidding?\\nHOLLY: Suppose the neighbors heard the noise?\\n\\n\", 'answer': \"Wouldn't be funny... Listen, I'll be back in a while. Oh... You want to call the police, that's fine. Just won't be so hot for me.\", 'gold_tag': 'KIT plans to leave for a while and is aware he might face trouble with the police , KIT is in a situation that positions him against the law', 'last_speaker': 'KIT'}\n",
      "Last word -> KIT : \"Wouldn't be funny... Listen, I'll be back in a while. Oh... You want to call the police, that's fine. Just won't be so hot for me.\"\n",
      "prediction :  They're not going to believe us. They'll say we're crazy.\n",
      "Real answer : Wouldn't be funny... Listen, I'll be back in a while. Oh... You want to call the police, that's fine. Just won't be so hot for me.\n",
      "Bert Score : {'precision': [0.8664835095405579], 'recall': [0.8271826505661011], 'f1': [0.8463770747184753], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09302325581395349, 'rouge2': 0.0, 'rougeL': 0.046511627906976744, 'rougeLsum': 0.046511627906976744}\n",
      "bleu 1/2 : 0.020189651799465542 0.006729883933155182\n",
      "ppl : 9.04859537996179\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIT: That guy must pay through the nose to keep this place up... Lawn, the gas and electric... Bagworms. Plus the upkeep on the cars... Yeah, you get a little money in your pocket, you think all your problems are solved. Well, let me tell you, they're not.\\nHOLLY: I'd like to get out of here.\\n\\n\", 'answer': 'Soon as I start the car... and fix my hat.', 'gold_tag': 'KIT plans to start the car soon, implying an imminent departure', 'last_speaker': 'KIT'}\n",
      "Last word -> KIT : \"Soon as I start the car... and fix my hat.\"\n",
      "prediction :  Well, you can't.\n",
      "Real answer : Soon as I start the car... and fix my hat.\n",
      "Bert Score : {'precision': [0.8490819931030273], 'recall': [0.8376632928848267], 'f1': [0.8433340191841125], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 42.25047630745292\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOLLY: That's Montana over there.\\nKIT: I never been to Montana... Acquaintance of mine has, but I hadn't... Never had any reason to.\\n\\n\", 'answer': \"State bird's a meadowlark.\", 'gold_tag': \"Montana's state bird is the meadowlark\", 'last_speaker': 'HOLLY'}\n",
      "Last word -> HOLLY : \"State bird's a meadowlark.\"\n",
      "prediction :  It's a beautiful state.\n",
      "Real answer : State bird's a meadowlark.\n",
      "Bert Score : {'precision': [0.9046726822853088], 'recall': [0.858501136302948], 'f1': [0.8809823989868164], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.6, 'rouge2': 0.25, 'rougeL': 0.4000000000000001, 'rougeLsum': 0.4000000000000001}\n",
      "bleu 1/2 : 0.25 0.09128709291752769\n",
      "ppl : 102.89101590588128\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIT: You want to give me a little slack here? Don't worry now.. I'm going to get you off these charges... There's a whole lot of other boys out there. You're going to have a lot of fun. Boy, we rang the bells, didn't we? I'll say one thing, though... That guy with the deaf maid? He's just lucky he's not dead, too. Course it's too bad about your dad.\\nHOLLY: Yeah.\\n\\n\", 'answer': \"We're going to have to sit down, and talk about that sometime.\", 'gold_tag': \"KIT implies a future discussion about HOLLY's dad\", 'last_speaker': 'KIT'}\n",
      "Last word -> KIT : \"We're going to have to sit down, and talk about that sometime.\"\n",
      "prediction :  Hey, you want to get something? I'll get you something.\n",
      "Real answer : We're going to have to sit down, and talk about that sometime.\n",
      "Bert Score : {'precision': [0.845037579536438], 'recall': [0.8605234622955322], 'f1': [0.8527101874351501], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08333333333333334, 'rouge2': 0.0, 'rougeL': 0.08333333333333334, 'rougeLsum': 0.08333333333333334}\n",
      "bleu 1/2 : 0.08187307530779821 0.027291025102599408\n",
      "ppl : 18.630373699093337\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFISK: I don't suppose anybody would pay I don't suppose anybody would pay three million just for you. three million just for you.\\nJACK: Drop it! Drop it!\\n\\n\", 'answer': \"Pop quiz, hotshot. Terrorist Pop quiz, hotshot. Terrorist holding a police hostage. He's holding a police hostage. He's got enough dynamite strapped to got enough dynamite strapped to his chest to blow the building in his chest to blow the building in half. What do you do? half. What do you do?\", 'gold_tag': \"FISK casually references hostage situations and explosives , JACK is likely in a position of authority or law enforcement , JACK's response and potential involvement in a hostage situation imply his role\", 'last_speaker': 'FISK'}\n",
      "Last word -> FISK : \"Pop quiz, hotshot. Terrorist Pop quiz, hotshot. Terrorist holding a police hostage. He's holding a police hostage. He's got enough dynamite strapped to got enough dynamite strapped to his chest to blow the building in his chest to blow the building in half. What do you do? half. What do you do?\"\n",
      "prediction :  I'm sorry, Jack. I'm sorry, Jack. I'm just trying to do my job.\n",
      "Real answer : Pop quiz, hotshot. Terrorist Pop quiz, hotshot. Terrorist holding a police hostage. He's holding a police hostage. He's got enough dynamite strapped to got enough dynamite strapped to his chest to blow the building in his chest to blow the building in half. What do you do? half. What do you do?\n",
      "Bert Score : {'precision': [0.8580042719841003], 'recall': [0.8130150437355042], 'f1': [0.8349040150642395], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05714285714285714, 'rouge2': 0.0, 'rougeL': 0.05714285714285714, 'rougeLsum': 0.05714285714285714}\n",
      "bleu 1/2 : 0.0076595489796713765 0.001782663009652276\n",
      "ppl : 9.6301910874093\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACK: There's gonna be fifty cops There's gonna be fifty cops waiting for us in the basement. waiting for us in the basement.\\n\\n\", 'answer': \"Standard flanking deployment, Standard flanking deployment, right? right? Maybe we'll just get off on the Maybe we'll just get off on the third floor.\", 'gold_tag': 'FISK is knowledgeable about tactical strategies in adversarial scenarios', 'last_speaker': 'FISK'}\n",
      "Last word -> FISK : \"Standard flanking deployment, Standard flanking deployment, right? right? Maybe we'll just get off on the Maybe we'll just get off on the third floor.\"\n",
      "prediction :  What?\n",
      "Real answer : Standard flanking deployment, Standard flanking deployment, right? right? Maybe we'll just get off on the Maybe we'll just get off on the third floor.\n",
      "Bert Score : {'precision': [0.852593183517456], 'recall': [0.7785091400146484], 'f1': [0.8138687610626221], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACK: JACK\\nFISK: What do you think, Jack? You What do you think, Jack? You think if you can find all the think if you can find all the driver's teeth they'll give you driver's teeth they'll give you another medal? another medal?\\n\\n\", 'answer': 'Jesus... Jesus...', 'gold_tag': 'Everyday Language', 'last_speaker': 'JACK'}\n",
      "Last word -> JACK : \"Jesus... Jesus...\"\n",
      "prediction :  Another medal? I don't want another medal. I want to get out of here.\n",
      "Real answer : Jesus... Jesus...\n",
      "Bert Score : {'precision': [0.8459383249282837], 'recall': [0.8247292637825012], 'f1': [0.8351991772651672], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.961122201228925\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSALVADOR: It’s been so long!\\nFEDERICO: Yes. Would you have recognized me if you’d seen me in the street?\\nSALVADOR: I’d have had to look closely, but yes. Your eyes are the same.\\n\\n', 'answer': 'I’m sorry I got you out of bed.', 'gold_tag': 'Everyday Language', 'last_speaker': 'FEDERICO'}\n",
      "Last word -> FEDERICO : \"I’m sorry I got you out of bed.\"\n",
      "prediction :  It’s been so long.\n",
      "Real answer : I’m sorry I got you out of bed.\n",
      "Bert Score : {'precision': [0.876579761505127], 'recall': [0.8774334192276001], 'f1': [0.8770063519477844], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 66.9249788415293\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFEDERICO: This is Mauro, the younger one. This is Federico. He’s 22 now.\\nSALVADOR: He looks very like you.\\nFEDERICO: Yes. He’s the one I told. at the Federico in the photo and at the one next to him, his father. And indeed they’re identical, except for the age difference.\\nSALVADOR: They’re both very handsome.\\n\\n', 'answer': '(More relaxed) You have to come to Buenos Aires. You’ll love the city and I’m sure it’ll inspire you. I want you to meet my family and eat in my restaurant. We’ll get drunk together. commit himself.', 'gold_tag': 'FEDERICO owns a restaurant in Buenos Aires , SALVADOR can potentially be inspired by the city of Buenos Aires and its culture', 'last_speaker': 'FEDERICO'}\n",
      "Last word -> FEDERICO : \"(More relaxed) You have to come to Buenos Aires. You’ll love the city and I’m sure it’ll inspire you. I want you to meet my family and eat in my restaurant. We’ll get drunk together. commit himself.\"\n",
      "prediction :  Yes, we all are.\n",
      "Real answer : (More relaxed) You have to come to Buenos Aires. You’ll love the city and I’m sure it’ll inspire you. I want you to meet my family and eat in my restaurant. We’ll get drunk together. commit himself.\n",
      "Bert Score : {'precision': [0.8382591605186462], 'recall': [0.8208093643188477], 'f1': [0.8294425010681152], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.04444444444444444, 'rouge2': 0.0, 'rougeL': 0.04444444444444444, 'rougeLsum': 0.04444444444444444}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 112.01958320493699\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSALVADOR: Have a good trip.\\nFEDERICO: I’ll call to remind you.\\n\\n', 'answer': 'Yes.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SALVADOR'}\n",
      "Last word -> SALVADOR : \"Yes.\"\n",
      "prediction :  I’ll be in touch.\n",
      "Real answer : Yes.\n",
      "Bert Score : {'precision': [0.8254294395446777], 'recall': [0.9287043809890747], 'f1': [0.8740267157554626], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 76.74940655821368\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOWER: Where are we going? What are we doing-\\nNADIA: i Shush! We're waiting.\\nBOWER: Waiting for what-?\\nNADIA: Quiet!\\nBOWER: SHIT-\\n\\n\", 'answer': 'Ssssht!', 'gold_tag': 'NADIA displays control', 'last_speaker': 'NADIA'}\n",
      "Last word -> NADIA : \"Ssssht!\"\n",
      "prediction :  Shush!\n",
      "Real answer : Ssssht!\n",
      "Bert Score : {'precision': [0.8939746618270874], 'recall': [0.8356223106384277], 'f1': [0.8638141751289368], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1146.0438929099516\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNADIA: We can't get through this way.\\nBOWER: I'd prefer to stay on foot.\\nNADIA: It's the safest way to travel. And there's only one other way to get through that I know of.\\n\\n\", 'answer': 'And what is that?', 'gold_tag': 'Everyday Language', 'last_speaker': 'BOWER'}\n",
      "Last word -> BOWER : \"And what is that?\"\n",
      "prediction :  Where is it?\n",
      "Real answer : And what is that?\n",
      "Bert Score : {'precision': [0.9266926050186157], 'recall': [0.9195995330810547], 'f1': [0.9231324195861816], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0.23884377019126307 0.09250379442961536\n",
      "ppl : 174.2286370215664\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOWER: Where are we?\\n\\n', 'answer': 'Main corridor. Hyper-sleep chamber, Personnel. Keep your light down.', 'gold_tag': 'NADIA has knowledge of the location they are in , NADIA may work in the facility they are occupying', 'last_speaker': 'NADIA'}\n",
      "Last word -> NADIA : \"Main corridor. Hyper-sleep chamber, Personnel. Keep your light down.\"\n",
      "prediction :  I’m not sure.\n",
      "Real answer : Main corridor. Hyper-sleep chamber, Personnel. Keep your light down.\n",
      "Bert Score : {'precision': [0.8360923528671265], 'recall': [0.86866694688797], 'f1': [0.8520684242248535], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 72.4758002194995\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOWER: What the hell happened to them!? What the hell are those things!?\\n\\n', 'answer': 'Shut-up!', 'gold_tag': 'NADIA is assertive , NADIA is irritated', 'last_speaker': 'NADIA'}\n",
      "Last word -> NADIA : \"Shut-up!\"\n",
      "prediction :  It is called a \"T-1000\". It is a new type of terminator.\n",
      "Real answer : Shut-up!\n",
      "Bert Score : {'precision': [0.8469586968421936], 'recall': [0.8689202666282654], 'f1': [0.8577989339828491], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 19.709265925750177\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOWER: Com'on...\\nNADIA: Bower...?\\n\\n\", 'answer': \"I'm going as fast as I can-\", 'gold_tag': \"BOWER's temporal information indicates he is under time pressure\", 'last_speaker': 'BOWER'}\n",
      "Last word -> BOWER : \"I'm going as fast as I can-\"\n",
      "prediction :  Yeah.\n",
      "Real answer : I'm going as fast as I can-\n",
      "Bert Score : {'precision': [0.9326521754264832], 'recall': [0.7809631824493408], 'f1': [0.8500939011573792], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOWER: Go... GO! GO!\\n\\n', 'answer': 'You snake bastard- OPEN IT!', 'gold_tag': 'Everyday Language', 'last_speaker': 'NADIA'}\n",
      "Last word -> NADIA : \"You snake bastard- OPEN IT!\"\n",
      "prediction :  Don't be afraid.\n",
      "Real answer : You snake bastard- OPEN IT!\n",
      "Bert Score : {'precision': [0.8897117972373962], 'recall': [0.8389242887496948], 'f1': [0.8635720014572144], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 88.8965212774464\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNADIA: NO!? Are you crazy-\\n\\n', 'answer': 'GET IN!', 'gold_tag': 'Everyday Language', 'last_speaker': 'BOWER'}\n",
      "Last word -> BOWER : \"GET IN!\"\n",
      "prediction :  I'm sorry, Nadia. I didn't mean to hurt you.\n",
      "Real answer : GET IN!\n",
      "Bert Score : {'precision': [0.8244630098342896], 'recall': [0.8320364952087402], 'f1': [0.8282324075698853], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.584953528357175\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNADIA: Not like this! I can't- like this!\\nBOWER: Hold on!\\nNADIA: I What are you doing!?\\nBOWER: 1 Put it on!\\n\\n\", 'answer': \"No! I can't- Not like this! I'm not going to wake up and drowned-\", 'gold_tag': \"NADIA's character displays fear in a stressful situation , NADIA is in fear of drowning soon\", 'last_speaker': 'NADIA'}\n",
      "Last word -> NADIA : \"No! I can't- Not like this! I'm not going to wake up and drowned-\"\n",
      "prediction :  Put what on?\n",
      "Real answer : No! I can't- Not like this! I'm not going to wake up and drowned-\n",
      "Bert Score : {'precision': [0.7995091676712036], 'recall': [0.7819852828979492], 'f1': [0.7906501293182373], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 819.0925792581228\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBOWER: Hey...? Hey?\\nNADIA: Where are we? What happened?\\n\\n', 'answer': \"It's all right. It's safe to wake up this time.\", 'gold_tag': 'BOWER seemingly understands the current situation', 'last_speaker': 'BOWER'}\n",
      "Last word -> BOWER : \"It's all right. It's safe to wake up this time.\"\n",
      "prediction :  We were attacked. The last thing I remember is being dragged into this cave.\n",
      "Real answer : It's all right. It's safe to wake up this time.\n",
      "Bert Score : {'precision': [0.8693780899047852], 'recall': [0.858635663986206], 'f1': [0.8639734983444214], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307691, 'rouge2': 0.0, 'rougeL': 0.07692307692307691, 'rougeLsum': 0.07692307692307691}\n",
      "bleu 1/2 : 0.07142857142857141 0.023440361546924773\n",
      "ppl : 21.841024603545616\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWARDADDY: Okay. Button up. There might be a wolf hiding in the sheep. Kid, cast an eyeball on ‘em. Anyone makes a move you cut them right in half. Do what you need to do. If people are in the way, that’s their problem. You copy?\\n\\n', 'answer': 'I copy.', 'gold_tag': 'NORMAN is a subordinate , NORMAN likely is a novice due to the instruction he needs', 'last_speaker': 'NORMAN'}\n",
      "Last word -> NORMAN : \"I copy.\"\n",
      "prediction :  Copy.\n",
      "Real answer : I copy.\n",
      "Bert Score : {'precision': [0.9605492353439331], 'recall': [0.904596209526062], 'f1': [0.9317334294319153], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.6666666666666666, 'rouge2': 0.0, 'rougeL': 0.6666666666666666, 'rougeLsum': 0.6666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3641.9706063619174\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWARDADDY: They knew we were coming. So they got drunk as Lords and shot themselves at sun up.\\nNORMAN: Why are you showing me this?\\n\\n', 'answer': 'You know why.', 'gold_tag': 'Everyday Language', 'last_speaker': 'WARDADDY'}\n",
      "Last word -> WARDADDY : \"You know why.\"\n",
      "prediction :  You need to know the truth.\n",
      "Real answer : You know why.\n",
      "Bert Score : {'precision': [0.9005514979362488], 'recall': [0.9018173217773438], 'f1': [0.9011839628219604], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4444444444444444, 'rouge2': 0.0, 'rougeL': 0.4444444444444444, 'rougeLsum': 0.4444444444444444}\n",
      "bleu 1/2 : 0.3333333333333333 0.08164965809277261\n",
      "ppl : 63.78609507727102\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWARDADDY: Why good evening, Norman. Why aren’t you at your post?\\nNORMAN: They’re coming.\\nWARDADDY: Who’s coming?\\nNORMAN: The Germans\\nWARDADDY: How many?\\nNORMAN: More than I can count.\\n\\n', 'answer': 'I’m sure it’s some bums looking for someone to surrender to. Keep working. I’ll be right back. Wardaddy and Norman head up the road...', 'gold_tag': 'WARDADDY dismisses the situation as \"some bums looking for someone to surrender to\" , WARDADDY instructs NORMAN to keep working', 'last_speaker': 'WARDADDY'}\n",
      "Last word -> WARDADDY : \"I’m sure it’s some bums looking for someone to surrender to. Keep working. I’ll be right back. Wardaddy and Norman head up the road...\"\n",
      "prediction :  I think you should get your ass on that bike and get the hell out of here.\n",
      "Real answer : I’m sure it’s some bums looking for someone to surrender to. Keep working. I’ll be right back. Wardaddy and Norman head up the road...\n",
      "Bert Score : {'precision': [0.8673778772354126], 'recall': [0.8417544960975647], 'f1': [0.8543741106987], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13636363636363638, 'rouge2': 0.0, 'rougeL': 0.13636363636363638, 'rougeLsum': 0.13636363636363638}\n",
      "bleu 1/2 : 0.07793883945810896 0.01796401488334622\n",
      "ppl : 13.887955816133694\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCARRIE: You dropped this.\\n\\n', 'answer': \"Early Grayce if this ain't your lucky day.\", 'gold_tag': 'ADELE knows Early Grayce', 'last_speaker': 'ADELE'}\n",
      "Last word -> ADELE : \"Early Grayce if this ain't your lucky day.\"\n",
      "prediction :  Where is it?\n",
      "Real answer : Early Grayce if this ain't your lucky day.\n",
      "Bert Score : {'precision': [0.8330694437026978], 'recall': [0.809924304485321], 'f1': [0.8213338851928711], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 174.2286370215664\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADELE: I used to smoke before I met Early. But he broke me of that.\\n\\n', 'answer': 'Broke you?', 'gold_tag': \"CARRIE is inquisitive, demonstrated by her questioning ADELE's statement , This could indicate a questioning nature or an interest in ADELE's experiences\", 'last_speaker': 'CARRIE'}\n",
      "Last word -> CARRIE : \"Broke you?\"\n",
      "prediction :  That's good.\n",
      "Real answer : Broke you?\n",
      "Bert Score : {'precision': [0.8700903654098511], 'recall': [0.8126705884933472], 'f1': [0.8404008746147156], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 88.55636485172964\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADELE: Early don't think women should smoke or curse or drink liquor.\\nCARRIE: So you don't do any of those things.\\nADELE: Better not, or Early'd whip me.\\n\\n\", 'answer': 'He whips you?', 'gold_tag': 'CARRIE is questioning and assertive', 'last_speaker': 'CARRIE'}\n",
      "Last word -> CARRIE : \"He whips you?\"\n",
      "prediction :  So you're gonna try to act like a lady.\n",
      "Real answer : He whips you?\n",
      "Bert Score : {'precision': [0.8465216159820557], 'recall': [0.8487722873687744], 'f1': [0.8476454615592957], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 35.70575567519015\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCARRIE: You know I can fix that haircut for you, if you want?\\n\\n', 'answer': 'You can?', 'gold_tag': 'ADELE might have a haircut that could potentially be improved', 'last_speaker': 'ADELE'}\n",
      "Last word -> ADELE : \"You can?\"\n",
      "prediction :  No, thank you. I'm happy with it.\n",
      "Real answer : You can?\n",
      "Bert Score : {'precision': [0.8275231122970581], 'recall': [0.8229789733886719], 'f1': [0.8252448439598083], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 29.671868928651037\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADELE: How do you get your cigarette to stay there like that.\\nCARRIE: I'm cool.\\nADELE: Could I try that? What's this?\\nCARRIE: It's a portfolio of my work.\\nADELE: Your pictures. Can I see 'em?\\nCARRIE: Sure.\\nADELE: Jesus! You took this picture?\\nCARRIE: Took 'em all. That's me.\\nADELE: No it is not!\\nCARRIE: Hold still.\\nADELE: Sorry. Boy I'll tell ya, if Early found a picture of me like that I'd be black and blue for a week.\\nCARRIE: You shouldn't let him do that to you...\\nADELE: Do what?\\nCARRIE: Adele... are you serious?\\nADELE: You think Early's bad to me, don't you?\\nCARRIE: Yeah.\\n\\n\", 'answer': \"Well... You're wrong. I ain't saying Early ain't never hit me... but he never hurt me. ...When I was fourteen years old three boys raped me in the back of a truck, and beat me so bad I was in bed for almost four months... ...I feel safe with Early, most the time he treats me pretty good. And I know he wouldn't let nothin' like that ever happen to me again... Hey, that ain't so bad now.\", 'gold_tag': 'ADELE has a past history of serious physical and sexual abuse , ADELE views her relationship with Early as somewhat protective , ADELE claims Early treats her \"pretty good\" most of the time , ADELE believes Early would protect her from the kind of assault she experienced when she was fourteen years old', 'last_speaker': 'ADELE'}\n",
      "Last word -> ADELE : \"Well... You're wrong. I ain't saying Early ain't never hit me... but he never hurt me. ...When I was fourteen years old three boys raped me in the back of a truck, and beat me so bad I was in bed for almost four months... ...I feel safe with Early, most the time he treats me pretty good. And I know he wouldn't let nothin' like that ever happen to me again... Hey, that ain't so bad now.\"\n",
      "prediction :  You think he's bad to me?\n",
      "Real answer : Well... You're wrong. I ain't saying Early ain't never hit me... but he never hurt me. ...When I was fourteen years old three boys raped me in the back of a truck, and beat me so bad I was in bed for almost four months... ...I feel safe with Early, most the time he treats me pretty good. And I know he wouldn't let nothin' like that ever happen to me again... Hey, that ain't so bad now.\n",
      "Bert Score : {'precision': [0.8565810918807983], 'recall': [0.8089643716812134], 'f1': [0.8320920467376709], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.022727272727272724, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 2.0480707844427363e-06 5.016728378986382e-07\n",
      "ppl : 99.11063047653491\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADELE: My momma's a beautician. Guess that's where I get it from. She wouldn't hear of my moving in with Early... on account of his just getting out of jail and all. Ain't seen her in nearly a year now. I wish she'd call me, just once.\\nCARRIE: What's Early been in jail for?\\nADELE: Carryin' a gun.\\nCARRIE: ...Anything else?\\nADELE: An' resistin' arrest... At least that's what the Police said.\\nCARRIE: Jeez... Adele!\\nADELE: I'd better be goin'. It's late.\\n\\n\", 'answer': 'Great.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CARRIE'}\n",
      "Last word -> CARRIE : \"Great.\"\n",
      "prediction :  You don't have to go.\n",
      "Real answer : Great.\n",
      "Bert Score : {'precision': [0.8408827185630798], 'recall': [0.9393835663795471], 'f1': [0.8874081373214722], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 30.811049419505586\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCARRIE: Adele, listen to me... Early's sick; he should be in a hospital. The police are after him, he's a murderer!\\nADELE: ...That's not true.\\nCARRIE: What?\\n\\n\", 'answer': \"That's not true!\", 'gold_tag': \"ADELE is in denial about Early's actions\", 'last_speaker': 'ADELE'}\n",
      "Last word -> ADELE : \"That's not true!\"\n",
      "prediction :  He's not a murderer, he's not sick, he's my husband!\n",
      "Real answer : That's not true!\n",
      "Bert Score : {'precision': [0.8463844060897827], 'recall': [0.8946601152420044], 'f1': [0.8698529601097107], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23529411764705882, 'rouge2': 0.13333333333333333, 'rougeL': 0.23529411764705882, 'rougeLsum': 0.23529411764705882}\n",
      "bleu 1/2 : 0.10000000000000002 0.03333333333333335\n",
      "ppl : 15.461952664384913\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMAL: Looks like Arthur's taste.\\nCOBB: Actually, Mr. Saito is partial to postwar British painters. Would you sit down?\\nMAL: Tell me... Do the children miss me?\\nCOBB: You can't imagine.\\nMAL: What're you doing?\\n\\n\", 'answer': 'Getting some air. Stay seated. Please.', 'gold_tag': 'Everyday Language', 'last_speaker': 'COBB'}\n",
      "Last word -> COBB : \"Getting some air. Stay seated. Please.\"\n",
      "prediction :  I'm just trying to get you to talk.\n",
      "Real answer : Getting some air. Stay seated. Please.\n",
      "Bert Score : {'precision': [0.8518382906913757], 'recall': [0.8808705806732178], 'f1': [0.8661112189292908], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 20.835545216187107\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMAL: you PROMISED! YOU SAID WE'D BE TOGETHER!-\\nCOBB: We can. We will. But I need you to stay here for now-\\nMAL: YOU SAID WE'D GROW OLD TOGETHER!-\\nCOBB: I'll come back. I need you to stay here on your own for now. Just while I do this job. Then we can be together-\\n\\n\", 'answer': \"WE'LL BE TOGETHER-YOU PROMISED!-\", 'gold_tag': \"MAL feels betrayed by COBB's temporary departure and demands his presence , COBB is committed to the promise he made to MAL about their future together\", 'last_speaker': 'MAL'}\n",
      "Last word -> MAL : \"WE'LL BE TOGETHER-YOU PROMISED!-\"\n",
      "prediction :  NO! I'M NOT GOING TO BE ALONE!-\n",
      "Real answer : WE'LL BE TOGETHER-YOU PROMISED!-\n",
      "Bert Score : {'precision': [0.8788508176803589], 'recall': [0.8485391139984131], 'f1': [0.8634290099143982], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714288, 'rouge2': 0.0, 'rougeL': 0.14285714285714288, 'rougeLsum': 0.14285714285714288}\n",
      "bleu 1/2 : 0.14285714285714285 0.048795003647426664\n",
      "ppl : 29.697205823009128\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOBB: Resilient... Highly contagious, and an idea can grow. The smallest seed of an idea can grow to define or destroy your world...\\n\\n', 'answer': 'The smallest idea, such as... \"Your world is not real.\" A simple little thought that changes everything...', 'gold_tag': \"MAL is responsive and sharp , MAL expands on COBB's assertions , MAL shows her understanding of how reality can be distorted , MAL has a possible cognitive or philosophical background\", 'last_speaker': 'MAL'}\n",
      "Last word -> MAL : \"The smallest idea, such as... \"Your world is not real.\" A simple little thought that changes everything...\"\n",
      "prediction :  It's not an idea, it's a virus.\n",
      "Real answer : The smallest idea, such as... \"Your world is not real.\" A simple little thought that changes everything...\n",
      "Bert Score : {'precision': [0.8783683776855469], 'recall': [0.8501936793327332], 'f1': [0.8640514016151428], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23076923076923078, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0.06847172469765024 0.016537492650916898\n",
      "ppl : 19.820953495066426\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMAL: So certain of your world. Of what's real. Do you think he is- Or do you think he's as lost as I was?\\nCOBB: I know what's real.\\nMAL: What are the distinguishing characteristics of a dream? Mutable laws of physics? Tell that to the quantum physicists. Reappearance of the dead? What about heaven and hell? Persecution of the dreamer, the creator, the messiah? They crucified Christ, didn't they?\\nCOBB: I know what's real.\\nMAL: No creeping doubts? Not feeling persecuted, Dom? Chased around the globe by anonymous corporations and police forces? The way the Admit it, Dom. You don't believe in one reality anymore. So choose. Choose your reality like I did. Choose to be here. Choose me.\\nCOBB: I have chosen, Mal. Our children. I have to get back to them. Because you left them. You left us.\\nMAL: You're wrong, Dom. You're confused... our children are here- And you'd like to see their faces again, wouldn't you, Dom?\\n\\n\", 'answer': 'Our real children are waiting for me up above. And we-', 'gold_tag': 'COBB needs to return to his children', 'last_speaker': 'COBB'}\n",
      "Last word -> COBB : \"Our real children are waiting for me up above. And we-\"\n",
      "prediction :  Yes.\n",
      "Real answer : Our real children are waiting for me up above. And we-\n",
      "Bert Score : {'precision': [0.9173669219017029], 'recall': [0.8233997821807861], 'f1': [0.8678471446037292], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2104.611116571625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMAL: We'd be together forever. You promised me.\\nCOBB: I know. But we can't. And I'm sorry.\\nMAL: You remember when you asked me to marry you? You said you dreamt that we'd grow old together.\\n\\n\", 'answer': 'And we did... I miss you more than I can bear... but we had our time together. And now I have to let go...', 'gold_tag': 'COBB is depicted as remorseful , COBB acknowledges their past together , COBB has accepted the need to move on , COBB is at the brink of moving on and leaving the past behind', 'last_speaker': 'COBB'}\n",
      "Last word -> COBB : \"And we did... I miss you more than I can bear... but we had our time together. And now I have to let go...\"\n",
      "prediction :  I know.\n",
      "Real answer : And we did... I miss you more than I can bear... but we had our time together. And now I have to let go...\n",
      "Bert Score : {'precision': [0.870922327041626], 'recall': [0.8189845085144043], 'f1': [0.8441553115844727], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307693, 'rouge2': 0.0, 'rougeL': 0.07692307692307693, 'rougeLsum': 0.07692307692307693}\n",
      "bleu 1/2 : 8.35085039512283e-06 3.7346138306851253e-06\n",
      "ppl : 663.9337011017111\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIRK: Hi . . . I'm Eddie . . . No, no.\\nREED: Oh, I thought Jack said you did. You wanna drink? Marguerita?\\nDIRK: Great.\\nREED: Can I ask you something?\\nDIRK: Uh-huh.\\nREED: Do you work out?\\nDIRK: Yeah.\\nREED: You look like it. Whadda you squat? Super, super.\\nDIRK: You?\\nREED: No b.s. Where do you work out? Cool. Cool. You ever go to Vince's out here -- no you couldn't, I would've seen you. Here we go . . . taste that.\\nDIRK: Rock and Roll. You tell me first.\\nREED: You first.\\nDIRK: You didn't say it . . .\\n\\n\", 'answer': '. . . neither did you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'REED'}\n",
      "Last word -> REED : \". . . neither did you.\"\n",
      "prediction :  I did.\n",
      "Real answer : . . . neither did you.\n",
      "Bert Score : {'precision': [0.9222279787063599], 'recall': [0.848195493221283], 'f1': [0.8836638927459717], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4, 'rouge2': 0.0, 'rougeL': 0.4, 'rougeLsum': 0.4}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1029.4573816212355\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIRK: No, no. Watch this Jacknife.\\n\\n', 'answer': 'Great. Check this out.', 'gold_tag': 'Everyday Language', 'last_speaker': 'REED'}\n",
      "Last word -> REED : \"Great. Check this out.\"\n",
      "prediction :  I think you're wrong.\n",
      "Real answer : Great. Check this out.\n",
      "Bert Score : {'precision': [0.8579049110412598], 'recall': [0.8933879137039185], 'f1': [0.8752869367599487], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 45.48348056285368\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nREED: Ouch.\\nDIRK: You gotta try and bring your legs\\n\\n', 'answer': 'Yeah.', 'gold_tag': 'Everyday Language', 'last_speaker': 'REED'}\n",
      "Last word -> REED : \"Yeah.\"\n",
      "prediction : I can't.\n",
      "Real answer : Yeah.\n",
      "Bert Score : {'precision': [0.8747259378433228], 'recall': [0.9408257007598877], 'f1': [0.9065725803375244], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 38.787507410379604\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIRK: That's right.\\n\\n\", 'answer': \"C'mon, Brock. Let's go out and get some of that Saturday Night Beaver --\", 'gold_tag': 'REED suggests it is a Saturday night', 'last_speaker': 'REED'}\n",
      "Last word -> REED : \"C'mon, Brock. Let's go out and get some of that Saturday Night Beaver --\"\n",
      "prediction :  Where is it?\n",
      "Real answer : C'mon, Brock. Let's go out and get some of that Saturday Night Beaver --\n",
      "Bert Score : {'precision': [0.8345919251441956], 'recall': [0.8021668791770935], 'f1': [0.81805819272995], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 174.2286370215664\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIRK: Ohhh . . . do it again, mayble I'll\\n\\n\", 'answer': 'Make another move, motherfucker', 'gold_tag': 'Everyday Language', 'last_speaker': 'REED'}\n",
      "Last word -> REED : \"Make another move, motherfucker\"\n",
      "prediction :  You're gonna take that as a compliment?\n",
      "Real answer : Make another move, motherfucker\n",
      "Bert Score : {'precision': [0.8286404013633728], 'recall': [0.804914653301239], 'f1': [0.8166052103042603], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18.887938258569655\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIRK: C'mon, man, c'mon, c'mon, alright -- I can't let you take the tapes until\\nREED: That's not my problem. My job is to\\n\\n\", 'answer': 'OK: Wait a minute -- have you heard my tape?', 'gold_tag': 'Everyday Language', 'last_speaker': 'DIRK'}\n",
      "Last word -> DIRK : \"OK: Wait a minute -- have you heard my tape?\"\n",
      "prediction :  To get you off the hook, to get you out of this mess, to get you back on the street and make sure you don't get caught.\n",
      "Real answer : OK: Wait a minute -- have you heard my tape?\n",
      "Bert Score : {'precision': [0.8323804140090942], 'recall': [0.8315067887306213], 'f1': [0.8319433331489563], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05405405405405406, 'rouge2': 0.0, 'rougeL': 0.05405405405405406, 'rougeLsum': 0.05405405405405406}\n",
      "bleu 1/2 : 0.037037037037037035 0.01193524790065722\n",
      "ppl : 11.272021745619467\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIRK: What?\\nREED: You know that kid Johnny Doe?\\nDIRK: No.\\nREED: Y'know, the kid from --\\nDIRK: What about him?\\nREED: Yeah. He's dead. Can you believe that?\\n\\n\", 'answer': \"That's gotta hurt, goin' through a windshield. It's tough luck.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'DIRK'}\n",
      "Last word -> DIRK : \"That's gotta hurt, goin' through a windshield. It's tough luck.\"\n",
      "prediction :  I don't know what you're talking about.\n",
      "Real answer : That's gotta hurt, goin' through a windshield. It's tough luck.\n",
      "Bert Score : {'precision': [0.8348106145858765], 'recall': [0.8336980938911438], 'f1': [0.8342539668083191], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 7.684915901628314\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nREED: Where you goin'?\\n\\n\", 'answer': 'Gotta go kick some ass, man.', 'gold_tag': 'DIRK plans to kick some ass soon', 'last_speaker': 'DIRK'}\n",
      "Last word -> DIRK : \"Gotta go kick some ass, man.\"\n",
      "prediction :  Just gettin' some fresh air.\n",
      "Real answer : Gotta go kick some ass, man.\n",
      "Bert Score : {'precision': [0.8573302030563354], 'recall': [0.870279848575592], 'f1': [0.8637564182281494], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1818181818181818, 'rouge2': 0.0, 'rougeL': 0.1818181818181818, 'rougeLsum': 0.1818181818181818}\n",
      "bleu 1/2 : 0.1637461506155964 0.05789300674674099\n",
      "ppl : 43.35052522395576\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nREED: How fast were you going?\\nDIRK: Shit, yeah. I'm lucky I'm not dead.\\nREED: At least it's driveable.\\nDIRK: You can't just drive a Corvette down\\nREED: How you gonna pay for it?\\n\\n\", 'answer': \"-- I'll find a way to pay for it. My car has got to get fixed. I dunno. I mean it . . . let's go kick that guy's ass\", 'gold_tag': 'DIRK shows determination in making sure his car gets fixed , DIRK is faced with the immediate need to find a way to pay for his car repairs , DIRK has a penchant for confrontation', 'last_speaker': 'DIRK'}\n",
      "Last word -> DIRK : \"-- I'll find a way to pay for it. My car has got to get fixed. I dunno. I mean it . . . let's go kick that guy's ass\"\n",
      "prediction :  I don't know.\n",
      "Real answer : -- I'll find a way to pay for it. My car has got to get fixed. I dunno. I mean it . . . let's go kick that guy's ass\n",
      "Bert Score : {'precision': [0.8738242387771606], 'recall': [0.8288915157318115], 'f1': [0.85076504945755], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0606060606060606, 'rouge2': 0.0, 'rougeL': 0.0606060606060606, 'rougeLsum': 0.0606060606060606}\n",
      "bleu 1/2 : 4.1136601362226516e-05 1.5932137199547668e-05\n",
      "ppl : 52.19149636039691\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nREED: I am.\\nDIRK: Me? Yeah . . . yeah, I'm ready. I was born ready. I know, but why?\\n\\n\", 'answer': 'Lemme do the talking --', 'gold_tag': 'Everyday Language', 'last_speaker': 'REED'}\n",
      "Last word -> REED : \"Lemme do the talking --\"\n",
      "prediction :  I don't know.\n",
      "Real answer : Lemme do the talking --\n",
      "Bert Score : {'precision': [0.833236813545227], 'recall': [0.783646821975708], 'f1': [0.8076813817024231], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 52.19149636039691\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRICK: I took off work to be here.\\nCINDY: Thank you.\\nRICK: So, what do you want?\\nCINDY: I want to see your boys.\\nRICK: I don't think that's a good idea.\\nCINDY: I'm their mother.\\nRICK: You forfeited that obligation, remember?\\nCINDY: That's not fair!\\nRICK: You abandoned your kids!\\nCINDY: I did not. I left them in the care of their loving father. There's a difference.\\nRICK: Is there?\\nCINDY: I just want to see the boys.\\nRICK: You think they even know who you are?\\nCINDY: I'm their mother.\\nRICK: You keep saying that.\\n\\n\", 'answer': 'I know things can never go back to the way they were before.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CINDY'}\n",
      "Last word -> CINDY : \"I know things can never go back to the way they were before.\"\n",
      "prediction :  Maybe I should bring some clothes for them.\n",
      "Real answer : I know things can never go back to the way they were before.\n",
      "Bert Score : {'precision': [0.8758617639541626], 'recall': [0.8493768572807312], 'f1': [0.8624160289764404], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809525, 'rouge2': 0.0, 'rougeL': 0.09523809523809525, 'rougeLsum': 0.09523809523809525}\n",
      "bleu 1/2 : 0.0669076785648738 0.02261892368524442\n",
      "ppl : 85.57941461976715\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRICK: Huh?\\n\\n', 'answer': \"Let's keep the attorneys out of this and settle things like civil adults.\", 'gold_tag': 'CINDY favors amicable resolution over legal confrontations , CINDY is a logical problem-solver', 'last_speaker': 'CINDY'}\n",
      "Last word -> CINDY : \"Let's keep the attorneys out of this and settle things like civil adults.\"\n",
      "prediction :  Can I talk to you?\n",
      "Real answer : Let's keep the attorneys out of this and settle things like civil adults.\n",
      "Bert Score : {'precision': [0.8456085920333862], 'recall': [0.8268166184425354], 'f1': [0.8361070156097412], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 68.22003335963667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRICK: Three hours.\\n\\n', 'answer': \"They'll be here.\", 'gold_tag': 'CINDY is expecting visitors in three hours', 'last_speaker': 'CINDY'}\n",
      "Last word -> CINDY : \"They'll be here.\"\n",
      "prediction :  Wow, that's a lot of time.\n",
      "Real answer : They'll be here.\n",
      "Bert Score : {'precision': [0.8502875566482544], 'recall': [0.8590471744537354], 'f1': [0.8546448945999146], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 20.852615846409225\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGOOSE: CLOSURE.\\n\\n', 'answer': \"I'LL I.D. HIM, YOU HOOK 'EM.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MAVERICK'}\n",
      "Last word -> MAVERICK : \"I'LL I.D. HIM, YOU HOOK 'EM.\"\n",
      "prediction :  What are you doing?\n",
      "Real answer : I'LL I.D. HIM, YOU HOOK 'EM.\n",
      "Bert Score : {'precision': [0.8114997148513794], 'recall': [0.8287450671195984], 'f1': [0.8200317025184631], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 72.29521208294543\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGOOSE: Cougar!\\n\\n', 'answer': 'Cougar? STINGER (O.S.) Maverick, Goose...Come in here.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MAVERICK'}\n",
      "Last word -> MAVERICK : \"Cougar? STINGER (O.S.) Maverick, Goose...Come in here.\"\n",
      "prediction :  Goose!\n",
      "Real answer : Cougar? STINGER (O.S.) Maverick, Goose...Come in here.\n",
      "Bert Score : {'precision': [0.8287859559059143], 'recall': [0.7992508411407471], 'f1': [0.8137505054473877], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.19999999999999998, 'rouge2': 0.0, 'rougeL': 0.19999999999999998, 'rougeLsum': 0.19999999999999998}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1690.6091081193172\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGOOSE: Ahhh...A little high on the left, don't you think?\\nMAVERICK: Right.\\nGOOSE: Right. Much better. ...Ahhh...what do you call this?\\nMAVERICK: It's a victory roll.\\n\\n\", 'answer': \"I wouldn't call it victory. It's more like...self immolation.\", 'gold_tag': 'GOOSE exhibits a sense of humor', 'last_speaker': 'GOOSE'}\n",
      "Last word -> GOOSE : \"I wouldn't call it victory. It's more like...self immolation.\"\n",
      "prediction :  It's a victory roll.\n",
      "Real answer : I wouldn't call it victory. It's more like...self immolation.\n",
      "Bert Score : {'precision': [0.8897364735603333], 'recall': [0.8479166030883789], 'f1': [0.8683233261108398], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.35294117647058826, 'rouge2': 0.13333333333333333, 'rougeL': 0.23529411764705882, 'rougeLsum': 0.23529411764705882}\n",
      "bleu 1/2 : 0.07162619921504752 0.02615419001229357\n",
      "ppl : 246.26500558195934\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGOOSE: Hi...Hi there. How ya doing in there? Mav... Ahhh...you know, at one point I did want a Navy career.\\nMAVERICK: Come on, relax...\\nGOOSE: You see all those guys with gold on their shoulders!!?... Oh, no, I think that was Johnson, Air Boss of the Kitty Hawk!\\nMAVERICK: Come on, we beat an instructor. How many times in your life do you get to do a victory roll?\\n\\n', 'answer': 'Just once, if they take your plane away.', 'gold_tag': 'Everyday Language', 'last_speaker': 'GOOSE'}\n",
      "Last word -> GOOSE : \"Just once, if they take your plane away.\"\n",
      "prediction :  I'll tell you something, I don't know how many times I've been in a cockpit...\n",
      "Real answer : Just once, if they take your plane away.\n",
      "Bert Score : {'precision': [0.8158683776855469], 'recall': [0.855548620223999], 'f1': [0.8352375030517578], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.261713102048121\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMAVERICK: What's the range, Goose. I've got a good tone.\\n\\n\", 'answer': \"Two bogies ! Three o'clock high,\", 'gold_tag': \"GOOSE is a fighter jet co-pilot , GOOSE responds promptly to MAVERICK's requests for information\", 'last_speaker': 'GOOSE'}\n",
      "Last word -> GOOSE : \"Two bogies ! Three o'clock high,\"\n",
      "prediction :  100 miles, Maverick.\n",
      "Real answer : Two bogies ! Three o'clock high,\n",
      "Bert Score : {'precision': [0.8635806441307068], 'recall': [0.8279132843017578], 'f1': [0.845370888710022], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 86.96602463152948\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJENNIE: Everything's going to be alright - we just need to get you home.\\nVIRGIL: No, no - I can't go home. I need to be here - see the therapist - doctor's. I want to be here.\\nJENNIE: But I can't stay here - and you can't do this alone--who's going to take care.. .? Amy? She's going to look after you?\\nVIRGIL: I'm not blind anymore - and I'm not going to let someone I care about walk out of my life again.\\nJENNIE: It's not your fault he left. You can't keep blaming yourself.\\n\\n\", 'answer': \"I'm staying here.\", 'gold_tag': 'VIRGIL has experienced loss in his past', 'last_speaker': 'VIRGIL'}\n",
      "Last word -> VIRGIL : \"I'm staying here.\"\n",
      "prediction :  I know it's not my fault - but I can't help it. I can't help it.\n",
      "Real answer : I'm staying here.\n",
      "Bert Score : {'precision': [0.8477654457092285], 'recall': [0.9035688638687134], 'f1': [0.8747780919075012], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0909090909090909, 'rouge2': 0.0, 'rougeL': 0.0909090909090909, 'rougeLsum': 0.0909090909090909}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 9.869836705622994\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVIRGIL: You want to tell me what we're doing here?\\nJENNIE: That's him. That's our Father.\\nVIRGIL: I can't - I can't see him.\\nJENNIE: I thought your eyes were better.\\nVIRGIL: No. I - I don't want to see him. My eyes aren't good enough - not yet - he won't understand. It won't be enough.\\nJENNIE: He's our father. He heard about the operation and he's asked to see you. Look here he comes.\\n\\n\", 'answer': \"GODDAMIT Jennie - I don't want to see him - I don't even know why you brought me here.\", 'gold_tag': 'VIRGIL harbors some resentment or fear towards his father, suggesting a strained relationship', 'last_speaker': 'VIRGIL'}\n",
      "Last word -> VIRGIL : \"GODDAMIT Jennie - I don't want to see him - I don't even know why you brought me here.\"\n",
      "prediction :  I can't.\n",
      "Real answer : GODDAMIT Jennie - I don't want to see him - I don't even know why you brought me here.\n",
      "Bert Score : {'precision': [0.8803653717041016], 'recall': [0.8054913878440857], 'f1': [0.8412656188011169], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0.00010173418450532208 4.5496910437881206e-05\n",
      "ppl : 127.82165926513017\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJENNIE: Mom and dad. Everything's as you left it.\\n\\n\", 'answer': \"Jen - I'm pretty tired - I'd like to be alone.\", 'gold_tag': \"VIRGIL is tired , VIRGIL prefers solitude at the moment , VIRGIL's tiredness is a temporary condition\", 'last_speaker': 'VIRGIL'}\n",
      "Last word -> VIRGIL : \"Jen - I'm pretty tired - I'd like to be alone.\"\n",
      "prediction :  I'm glad.\n",
      "Real answer : Jen - I'm pretty tired - I'd like to be alone.\n",
      "Bert Score : {'precision': [0.8889265060424805], 'recall': [0.8442317843437195], 'f1': [0.8660028576850891], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.16666666666666669, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0.005554498269121153 0.0024840471421319643\n",
      "ppl : 129.4314697945382\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVIRGIL: Beyond all the stores - past firehouse.\\nJENNIE: Well - there's nothing really - you know that. ~\\nVIRGIL: No! You told me that's all there was. That's wrong. There's a helluva lot out there.\\nJENNIE: I told you what you needed to know.\\nVIRGIL: What was within my reach. Isn't there anything more that vou want?\\nJENNIE: Is this about our father - he called told me...\\nVIRGIL: No. This isn't about him. Jennie - you've spent your whole life as blind as I was. The world doesn't stop within our reach.\\nJENNIE: Virgil, please. This is your home. Stop thinking about what's out there - things that will never matter to you. You're safe here where everyone...\\nVIRGIL: Where everyone what!?\\nJENNIE: Knows you.\\n\\n\", 'answer': \"Can protect me?! (beat) Jennie, this place was a wonderful safe haven for me growing up. I know that. And I can only imagine what you gave up to keep this world for me. I thank you and love you from the bottom of my soul. But now I want to give you your life back. You can I'm reaching out, Jennie.\", 'gold_tag': 'VIRGIL feels grateful for what JENNIE has done for him , VIRGIL wants to give JENNIE her life back', 'last_speaker': 'VIRGIL'}\n",
      "Last word -> VIRGIL : \"Can protect me?! (beat) Jennie, this place was a wonderful safe haven for me growing up. I know that. And I can only imagine what you gave up to keep this world for me. I thank you and love you from the bottom of my soul. But now I want to give you your life back. You can I'm reaching out, Jennie.\"\n",
      "prediction :  You're wrong. You're wrong, Jennie. You're wrong.\n",
      "Real answer : Can protect me?! (beat) Jennie, this place was a wonderful safe haven for me growing up. I know that. And I can only imagine what you gave up to keep this world for me. I thank you and love you from the bottom of my soul. But now I want to give you your life back. You can I'm reaching out, Jennie.\n",
      "Bert Score : {'precision': [0.8647092580795288], 'recall': [0.8136659860610962], 'f1': [0.8384114503860474], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1095890410958904, 'rouge2': 0.0, 'rougeL': 0.0821917808219178, 'rougeLsum': 0.0821917808219178}\n",
      "bleu 1/2 : 5.528256352055147e-05 1.8882590220370838e-05\n",
      "ppl : 16.440263218291587\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLEV: I am Cosmonaut Lev Andropov, what your name?\\nA.J.: My name is A.J.\\n\\n', 'answer': 'You just blew up my home.', 'gold_tag': 'Everyday Language', 'last_speaker': 'LEV'}\n",
      "Last word -> LEV : \"You just blew up my home.\"\n",
      "prediction :  A.J.! You are the first human to ever make it to orbit!\n",
      "Real answer : You just blew up my home.\n",
      "Bert Score : {'precision': [0.8552008867263794], 'recall': [0.8664529323577881], 'f1': [0.8607901334762573], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473684, 'rouge2': 0.0, 'rougeL': 0.10526315789473684, 'rougeLsum': 0.10526315789473684}\n",
      "bleu 1/2 : 0.08333333333333333 0.027524094128159027\n",
      "ppl : 47.022915735494195\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLEV: What happened to the others....\\n\\n', 'answer': \"Freedom, come in, over. Freedom, come in, over.... Freedom...? It's you and me.\", 'gold_tag': 'A.J. is a proactive communicator , A.J. is concerned about the well-being of his team', 'last_speaker': 'A.J.'}\n",
      "Last word -> A.J. : \"Freedom, come in, over. Freedom, come in, over.... Freedom...? It's you and me.\"\n",
      "prediction :  They were all killed.\n",
      "Real answer : Freedom, come in, over. Freedom, come in, over.... Freedom...? It's you and me.\n",
      "Bert Score : {'precision': [0.8708743453025818], 'recall': [0.8082768321037292], 'f1': [0.8384087681770325], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 177.89523013536927\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLEV: I feel like Skywalker Luke when he learned Darth Vader his father. What I should do?\\nA.J.: Get up, we got work to do.\\nLEV: A.J., let me cash in my chips.\\n\\n', 'answer': \"Lev, we're getting off this rock, if I have to drag your ass the whole way. Now get up! C'MON LEV, PUT YOUR WEIGHT INTO IT!\", 'gold_tag': \"A.J.'s job involves challenging physical work , A.J.'s job is possibly related to an emergency or survival scenario , LEV is displaying signs of exhaustion or demoralization\", 'last_speaker': 'A.J.'}\n",
      "Last word -> A.J. : \"Lev, we're getting off this rock, if I have to drag your ass the whole way. Now get up! C'MON LEV, PUT YOUR WEIGHT INTO IT!\"\n",
      "prediction :  You're not going anywhere.\n",
      "Real answer : Lev, we're getting off this rock, if I have to drag your ass the whole way. Now get up! C'MON LEV, PUT YOUR WEIGHT INTO IT!\n",
      "Bert Score : {'precision': [0.8779680132865906], 'recall': [0.8055094480514526], 'f1': [0.840179443359375], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06060606060606061, 'rouge2': 0.0, 'rougeL': 0.06060606060606061, 'rougeLsum': 0.06060606060606061}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 52.15233916306354\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLEV: Wait A.J.! We drive over nuclear weapon and we finished before we started.\\n\\n', 'answer': 'So move it.', 'gold_tag': 'A.J. responds with direct orders', 'last_speaker': 'A.J.'}\n",
      "Last word -> A.J. : \"So move it.\"\n",
      "prediction :  I can't believe you're so calm about this.\n",
      "Real answer : So move it.\n",
      "Bert Score : {'precision': [0.8444600105285645], 'recall': [0.9010916352272034], 'f1': [0.8718571662902832], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.346785058806848\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSCOTT: Deckard? Who’s Deckard?\\nMYLES: It’s just my screenname.\\nSCOTT: You told her you’re a graduate student? Graduate of what, junior high?\\nMYLES: Shut up. We talk like EVERY day. It’s like we’re dating.\\nSCOTT: Yahoo chat rooms don’t count. She’s never even seen you. Now what are you doing?\\nMYLES: Hold on. Just gimmie a second.\\nSCOTT: Oh my God, look!\\nMYLES: What?\\nSCOTT: Over there, that girl’s HOT!\\nMYLES: What girl?\\nSCOTT: And check THAT out, three tacos for a dollar. And there, 9 different movies in one place!\\nMYLES: What, are you stoned?\\nSCOTT: Oh sorry, you’re right. There are no real girls, tacos or movies here.... BECAUSE WE’RE STILL IN YOUR FUCKING ROOM!\\n\\n', 'answer': 'Okay, okay. I’m logging off.', 'gold_tag': \"MYLES's defensive comments suggest he is sensitive about his online activities\", 'last_speaker': 'MYLES'}\n",
      "Last word -> MYLES : \"Okay, okay. I’m logging off.\"\n",
      "prediction : I know, man. It’s just a little too much. I can’t do this all day.\n",
      "Real answer : Okay, okay. I’m logging off.\n",
      "Bert Score : {'precision': [0.8763374090194702], 'recall': [0.8972113132476807], 'f1': [0.8866515159606934], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913045, 'rouge2': 0.0, 'rougeL': 0.08695652173913045, 'rougeLsum': 0.08695652173913045}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 10.606607294641625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMYLES: There she is.\\nSCOTT: Dude, she’s like 20 years old.\\nMYLES: So what. I have a college level vocabulary.\\nSCOTT: And she’s not even the best looking of the three. Donna’s the hottie.\\nMYLES: Oh - I can’t even talk to you. You - you have NO appreciation for -\\nSCOTT: And Jen’s got a WAY bigger rack.\\nMYLES: Sara’s a really nice girl. Someone I can relate to. YOU wouldn’t understand.\\nSCOTT: Oh my God. You’re pussy whipped. No, it’s worse... You’ve been CYBER- WHIPPED! Hey, were’s your costume?\\nMYLES: I’m not going out tonight. I promised to watch her first episode. She’s really nervous about it.\\nSCOTT: No. No. Micki Stern’s party is tonight... you know that.\\nMYLES: Oh right. I guess I forgot.\\nSCOTT: Forgot? Do you have any idea what it means for two FRESHMEN to get in? It’s never happened before. Do you know what I had to GO THROUGH to get us invited?\\nMYLES: Go through? Your sister invited us so you wouldn’t tell your mom about her tatoo.\\n\\n', 'answer': 'The point is, Myles Barton, you can either sit in your room playing in the magical world of make believe. OR... you can come with me to this party and learn to walk like a man.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SCOTT'}\n",
      "Last word -> SCOTT : \"The point is, Myles Barton, you can either sit in your room playing in the magical world of make believe. OR... you can come with me to this party and learn to walk like a man.\"\n",
      "prediction :  That’s it! I can’t take it anymore. What’s wrong with you? I’m your best friend, and you’re not even TRYING! You’re just sitting there like a PUSSY! What’s wrong with you?\n",
      "Real answer : The point is, Myles Barton, you can either sit in your room playing in the magical world of make believe. OR... you can come with me to this party and learn to walk like a man.\n",
      "Bert Score : {'precision': [0.8379933834075928], 'recall': [0.8415670990943909], 'f1': [0.8397764563560486], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.21621621621621623, 'rouge2': 0.02777777777777778, 'rougeL': 0.13513513513513511, 'rougeLsum': 0.13513513513513511}\n",
      "bleu 1/2 : 0.13726531575310089 0.06240164389783082\n",
      "ppl : 5.749160452388982\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSCOTT: God, it’s like crack cocaine with you.\\nMYLES: It’s starting in a couple minutes.\\n\\n', 'answer': 'Please. PLEASE don’t embarrass me tonight.', 'gold_tag': \"SCOTT cares about social appearances , SCOTT is anxious about potential embarrassment , SCOTT suggests sensitivity to the opinions of others , SCOTT's temporal information\", 'last_speaker': 'SCOTT'}\n",
      "Last word -> SCOTT : \"Please. PLEASE don’t embarrass me tonight.\"\n",
      "prediction :  You’re insane, man.\n",
      "Real answer : Please. PLEASE don’t embarrass me tonight.\n",
      "Bert Score : {'precision': [0.8945258855819702], 'recall': [0.8865787386894226], 'f1': [0.8905346393585205], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 61.723776915161075\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMYLES: Scott, what are we doing here?\\n\\n', 'answer': 'Hey, be cool. All right?', 'gold_tag': \"SCOTT is a calm and composed individual , SCOTT's response suggests his demeanor\", 'last_speaker': 'SCOTT'}\n",
      "Last word -> SCOTT : \"Hey, be cool. All right?\"\n",
      "prediction :  I'm here to see if I can find any clues about what happened to the shuttle.\n",
      "Real answer : Hey, be cool. All right?\n",
      "Bert Score : {'precision': [0.8349120616912842], 'recall': [0.8338220119476318], 'f1': [0.8343666791915894], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.463386237633056\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDANNY: Morning. I didn't know if you like your eggs over easy or scrambled, so I made... Wait...\\nCAT: I shouldn't have done this.\\nDANNY: Done what?\\nCAT: Any of it.\\nDANNY: Why?\\nCAT: Because.\\nDANNY: Can we talk about it?\\nCAT: We already talked. I'm late.\\nDANNY: I made breakfast.\\n\\n\", 'answer': \"I don't like eggs. Now you know something else about me.\", 'gold_tag': 'CAT dislikes eggs', 'last_speaker': 'CAT'}\n",
      "Last word -> CAT : \"I don't like eggs. Now you know something else about me.\"\n",
      "prediction :  You shouldn't have.\n",
      "Real answer : I don't like eggs. Now you know something else about me.\n",
      "Bert Score : {'precision': [0.8771448135375977], 'recall': [0.8490328192710876], 'f1': [0.8628599047660828], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 76.67215266681778\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDANNY: Hello?\\nCAT: It's me.\\n\\n\", 'answer': \"Oh my god! I can't believe it! Hello you.\", 'gold_tag': 'DANNY has a strong emotional connection to CAT', 'last_speaker': 'DANNY'}\n",
      "Last word -> DANNY : \"Oh my god! I can't believe it! Hello you.\"\n",
      "prediction :  Oh, hey.\n",
      "Real answer : Oh my god! I can't believe it! Hello you.\n",
      "Bert Score : {'precision': [0.882286548614502], 'recall': [0.8215837478637695], 'f1': [0.8508538603782654], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666669, 'rouge2': 0.0, 'rougeL': 0.16666666666666669, 'rougeLsum': 0.16666666666666669}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 161.34596815996963\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCAT: Are you busy?\\nDANNY: No. I...no.\\n\\n', 'answer': 'I was just sitting here, looking out the window. And I thought...where are you?', 'gold_tag': 'CAT is contemplative , CAT looks out the window , CAT initiates the conversation', 'last_speaker': 'CAT'}\n",
      "Last word -> CAT : \"I was just sitting here, looking out the window. And I thought...where are you?\"\n",
      "prediction :  Come on. It's just you and me.\n",
      "Real answer : I was just sitting here, looking out the window. And I thought...where are you?\n",
      "Bert Score : {'precision': [0.8821810483932495], 'recall': [0.8564506769180298], 'f1': [0.8691254258155823], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.26086956521739135, 'rouge2': 0.0, 'rougeL': 0.1739130434782609, 'rougeLsum': 0.1739130434782609}\n",
      "bleu 1/2 : 0.05255420588163462 0.017950678673773812\n",
      "ppl : 27.124747696746777\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK: Oh, it's on.\\n\\n\", 'answer': 'Hells yeah!', 'gold_tag': 'Everyday Language', 'last_speaker': 'DALE'}\n",
      "Last word -> DALE : \"Hells yeah!\"\n",
      "prediction :  It's on?\n",
      "Real answer : Hells yeah!\n",
      "Bert Score : {'precision': [0.8281431794166565], 'recall': [0.800067663192749], 'f1': [0.8138633966445923], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 228.8943265246732\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK: Look out. Let me try this.\\nDALE: I guess we should've emptied the Dustbuster before we used it.\\n\\n\", 'answer': 'You think?', 'gold_tag': 'Everyday Language', 'last_speaker': 'NICK'}\n",
      "Last word -> NICK : \"You think?\"\n",
      "prediction :  Ugh.\n",
      "Real answer : You think?\n",
      "Bert Score : {'precision': [0.8483700752258301], 'recall': [0.7836594581604004], 'f1': [0.8147318959236145], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1206.3781942811167\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK: energy? Oh yeah. What's up, Dale?\\nDALE: Harken just left his house. I'm going in.\\nNICK: Good luck, man.\\n\\n\", 'answer': 'Thanks.', 'gold_tag': 'DALE is showing his determination and courage', 'last_speaker': 'DALE'}\n",
      "Last word -> DALE : \"Thanks.\"\n",
      "prediction :  I'm going to kill him.\n",
      "Real answer : Thanks.\n",
      "Bert Score : {'precision': [0.8689720034599304], 'recall': [0.9415236711502075], 'f1': [0.9037942290306091], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 40.695387996237805\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDALE: Nick?\\nNICK: What?\\nDALE: I'm not sure if I can do this. In Harken's bathroom. About to pour the nuts in his shampoo. But, I just... I know he's a real shithead, but he's still a person, y'know?\\nNICK: rat poison, Yeah. I know.\\nDALE: What should I do? Should I do it?\\nNICK: What the fuck?!\\nDALE: What?\\nNICK: It's Harken. He's here!\\nDALE: At Pellit's?! Why?!\\nNICK: I don't know. He's knocking on his door!\\n\\n\", 'answer': 'How would Harken even know Pellit?', 'gold_tag': 'Shared memories: DALE and NICK share the mutual knowledge and experience of their oppressive boss, Harken.', 'last_speaker': 'DALE'}\n",
      "Last word -> DALE : \"How would Harken even know Pellit?\"\n",
      "prediction :  Oh, shit.\n",
      "Real answer : How would Harken even know Pellit?\n",
      "Bert Score : {'precision': [0.8792822957038879], 'recall': [0.8157864809036255], 'f1': [0.8463451266288757], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 122.31277545247416\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK: Oh my god oh my god oh my god...\\nDALE: What? What? What?!\\nNICK: He shot him. Harken shot Pellit!\\nDALE: Oh my god. Is he dead?!\\n\\n', 'answer': 'Shhhh! Fuck!', 'gold_tag': 'Everyday Language', 'last_speaker': 'NICK'}\n",
      "Last word -> NICK : \"Shhhh! Fuck!\"\n",
      "prediction :  Yes. Yes he is. I saw it happen. I'm so sorry.\n",
      "Real answer : Shhhh! Fuck!\n",
      "Bert Score : {'precision': [0.847553551197052], 'recall': [0.7932510375976562], 'f1': [0.8195037841796875], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.057414206237922\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK: Harken's gone.\\nDALE: What about Pellit? Shit! What do we do?!\\n\\n\", 'answer': \"I've got to get out of here before someone sees me! Meet me at the bar. I'll call Kurt.\", 'gold_tag': 'NICK is cautious and more of a planner , NICK wants to leave the scene immediately to avoid being seen , DALE reacts quickly to changes without necessarily thinking things through , DALE is in a state of panic at the moment', 'last_speaker': 'NICK'}\n",
      "Last word -> NICK : \"I've got to get out of here before someone sees me! Meet me at the bar. I'll call Kurt.\"\n",
      "prediction :  Get the fuck out of here! Get the fuck out!\n",
      "Real answer : I've got to get out of here before someone sees me! Meet me at the bar. I'll call Kurt.\n",
      "Bert Score : {'precision': [0.8863467574119568], 'recall': [0.8679467439651489], 'f1': [0.8770502805709839], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3225806451612903, 'rouge2': 0.13793103448275865, 'rougeL': 0.3225806451612903, 'rougeLsum': 0.3225806451612903}\n",
      "bleu 1/2 : 0.12197089792217974 0.07422912461237537\n",
      "ppl : 12.435825793310372\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHIRON: Come on Chiron.\\nKEVIN: Chiron, what you doing man?\\nCHIRON: Huh?\\nKEVIN: You just standing there straight spaced. School been out, nigga, you ain’t goin’ home?\\nCHIRON: What you still doing here?\\nKEVIN: Detention. Aimes caught me with this trick in the stairway.\\nCHIRON: What?\\nKEVIN: Yup.\\nCHIRON: With who?\\nKEVIN: Damn you nosy, Chiron.\\nCHIRON: Oh sorry, my bad.\\nKEVIN: All I wanted was some quick head you know, but this chick all like ‘Hit that shit Kevin. Hit it with that big dick- Why she had to compliment a nigga? So I was like aight... we can do this. I started banging her back out... she started making all this fucking noise though. Mr. Aimes walked in and went all Five-O, almost had my ass suspended, but I told him we was childhood sweethearts and all that, talked it all out. So I just got detention. Eh, but that shit stay between us, yeah? I know you can keep a secret. But real talk, I gotta go before this fool change his mind.\\nCHIRON: Alright Kevin.\\n\\n', 'answer': 'Later, Black. Off Chiron...', 'gold_tag': 'Everyday Language', 'last_speaker': 'KEVIN'}\n",
      "Last word -> KEVIN : \"Later, Black. Off Chiron...\"\n",
      "prediction :  C’mon, nigga.\n",
      "Real answer : Later, Black. Off Chiron...\n",
      "Bert Score : {'precision': [0.8002923130989075], 'recall': [0.8445125818252563], 'f1': [0.8218080401420593], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 160.078837397101\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHIRON: Whose car this is?\\nKEVIN: Who you in it with?\\nCHIRON: How you got a car?\\nKEVIN: With money, how else you get a car? Boy I swear, for somebody who grew up in the hood you green as hell. That’s why I like you though. You live in the Beans, right?\\nCHIRON: Yeah.\\nKEVIN: What’s wrong?\\nCHIRON: Nothing.\\n\\n', 'answer': 'You sure? You never did nothing like that, huh? Yeah. I figured.', 'gold_tag': 'KEVIN shows familiarity with CHIRON, playfully mocking him for his lack of street-smartness', 'last_speaker': 'KEVIN'}\n",
      "Last word -> KEVIN : \"You sure? You never did nothing like that, huh? Yeah. I figured.\"\n",
      "prediction : You good?\n",
      "Real answer : You sure? You never did nothing like that, huh? Yeah. I figured.\n",
      "Bert Score : {'precision': [0.8465026021003723], 'recall': [0.8258253335952759], 'f1': [0.8360361456871033], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.0033689734995427335 0.001506650751874582\n",
      "ppl : 1442.3599865679905\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHIRON: Thanks for the ride.\\nKEVIN: No problem, Black. See you around.\\n\\n', 'answer': 'Yeah... see you around.', 'gold_tag': 'CHIRON shows politeness', 'last_speaker': 'CHIRON'}\n",
      "Last word -> CHIRON : \"Yeah... see you around.\"\n",
      "prediction :  You got a cell phone?\n",
      "Real answer : Yeah... see you around.\n",
      "Bert Score : {'precision': [0.8199604749679565], 'recall': [0.8291349411010742], 'f1': [0.8245221972465515], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.22222222222222224, 'rougeLsum': 0.22222222222222224}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 200.93929234801485\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Yes. Sorry to wake you up. I wasn't asleep. Did your wife come home last night? No.\\nDERM: Did she go to work today? Why don't you let me? Hi, this is Detective Derm of the Seattle Police. I was could you please ask her to call me. My number is 734-9722, extension 38. Thank you. Bye. She hasn't called here at all? No.\\nED: I was up late last night. about you. You don't come in. You don't call. No, seriously, we just want to make sure you're OK. Don't worry about your students. Marie's covering for you. But give us a call, OK? Bye.\\n\\n\", 'answer': \"You're a teacher too?\", 'gold_tag': 'ED is a teacher', 'last_speaker': 'DERM'}\n",
      "Last word -> DERM : \"You're a teacher too?\"\n",
      "prediction :  Good morning.\n",
      "Real answer : You're a teacher too?\n",
      "Bert Score : {'precision': [0.8690873980522156], 'recall': [0.8216356039047241], 'f1': [0.8446956276893616], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 836.7757250924997\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Sure. Here. I didn't tell her about my wife. I didn't see any reason to.\\n\\n\", 'answer': 'Could I trouble you for a glass of water?', 'gold_tag': 'Everyday Language', 'last_speaker': 'DERM'}\n",
      "Last word -> DERM : \"Could I trouble you for a glass of water?\"\n",
      "prediction :  Did you know that she was married?\n",
      "Real answer : Could I trouble you for a glass of water?\n",
      "Bert Score : {'precision': [0.8638644218444824], 'recall': [0.8648785352706909], 'f1': [0.8643711805343628], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.10735389901075512 0.03666833725656689\n",
      "ppl : 58.815233930189244\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: No.\\nDERM: Excuse me? privacy, but you must understand: my first priority is finding your wife. There is still a great deal to go over. We might want to notify the press.\\nED: The press?\\nDERM: those kinds of conclusions. She could have simply decided that she needed some time alone. We have to consider every possibility. I don't want to argue with you. We're trying to help you. This is our job.\\nED: Sure. Here. Take them all.\\n\\n\", 'answer': 'There are some things it may be better not to know, especially if your wife comes back.', 'gold_tag': 'DERM exhibits a professional and slightly persistent attitude', 'last_speaker': 'DERM'}\n",
      "Last word -> DERM : \"There are some things it may be better not to know, especially if your wife comes back.\"\n",
      "prediction :  I will. I'll get the paperwork started.\n",
      "Real answer : There are some things it may be better not to know, especially if your wife comes back.\n",
      "Bert Score : {'precision': [0.8863670825958252], 'recall': [0.8678025603294373], 'f1': [0.876986563205719], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 39.30982378755476\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Yes. It broke when I fell on it.\\nDERM: You haven't been answering your phone. Could you please leave the phone on from now on? Yes. I thought I was. OK. Thank you.\\n\\n\", 'answer': 'Yes. Thank you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Yes. Thank you.\"\n",
      "prediction :  It's broken.\n",
      "Real answer : Yes. Thank you.\n",
      "Bert Score : {'precision': [0.8715221285820007], 'recall': [0.8729881048202515], 'f1': [0.872254490852356], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 148.0577592404345\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Yes, hi.\\n\\n', 'answer': \"At the school? Yes. We arrested him there. He'll come up for\", 'gold_tag': \"DERM works as a law enforcement officer , DERM's role is possibly a detective or police officer , ED has some connection to a school , The connection could be as an employee or a student\", 'last_speaker': 'DERM'}\n",
      "Last word -> DERM : \"At the school? Yes. We arrested him there. He'll come up for\"\n",
      "prediction :  Hi.\n",
      "Real answer : At the school? Yes. We arrested him there. He'll come up for\n",
      "Bert Score : {'precision': [0.9127166271209717], 'recall': [0.8280618786811829], 'f1': [0.8683308362960815], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3624.1133783400123\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nAMOS: Good morning. How's the porridge, you like it?\\nRAMIREZ: 'Morning. It's not bad.\\nAMOS: Good... finish everything in the pot.\\nRAMIREZ: There's got to be like... eight helpings in there maybe...\\n\\n\", 'answer': 'No questions... Just do.', 'gold_tag': 'AMOS is a person of authority', 'last_speaker': 'AMOS'}\n",
      "Last word -> AMOS : \"No questions... Just do.\"\n",
      "prediction :  Seven.\n",
      "Real answer : No questions... Just do.\n",
      "Bert Score : {'precision': [0.9199719429016113], 'recall': [0.8470677733421326], 'f1': [0.8820158839225769], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3942.0649079115965\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nAMOS: Name and place of birth!\\nRAMIREZ: Illich Ramirez. Caracas, Venezuela.\\nAMOS: Your father?\\nRAMIREZ: Doctor Jose Altagracia Ramirez... Do you have to smoke that cigar?\\n\\n', 'answer': \"Yes. Carlos' father abandoned him and his mother because he wanted to be a playboy. Your father abandoned you in effect, when he was sent to prison. Either way, it's a lonely child missing his father. I want you to take what you know of your real father and superimpose it onto this the image of Carlos' father, so when you talk of one you are talking of the other with the same emotion... the same love, the same resentment... the same sadness, the same anger.\", 'gold_tag': \"AMOS has knowledge about Carlos' father and Ramirez's personal life , RAMIREZ's father was sent to prison , RAMIREZ was left effectively abandoned , RAMIREZ has a mix of emotions including love, resentment, sadness, and anger\", 'last_speaker': 'AMOS'}\n",
      "Last word -> AMOS : \"Yes. Carlos' father abandoned him and his mother because he wanted to be a playboy. Your father abandoned you in effect, when he was sent to prison. Either way, it's a lonely child missing his father. I want you to take what you know of your real father and superimpose it onto this the image of Carlos' father, so when you talk of one you are talking of the other with the same emotion... the same love, the same resentment... the same sadness, the same anger.\"\n",
      "prediction :  The only reason I brought it along is because you asked me to.\n",
      "Real answer : Yes. Carlos' father abandoned him and his mother because he wanted to be a playboy. Your father abandoned you in effect, when he was sent to prison. Either way, it's a lonely child missing his father. I want you to take what you know of your real father and superimpose it onto this the image of Carlos' father, so when you talk of one you are talking of the other with the same emotion... the same love, the same resentment... the same sadness, the same anger.\n",
      "Bert Score : {'precision': [0.8481618165969849], 'recall': [0.8179728984832764], 'f1': [0.8327938914299011], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11999999999999998, 'rouge2': 0.0, 'rougeL': 0.05999999999999999, 'rougeLsum': 0.05999999999999999}\n",
      "bleu 1/2 : 0.0011204335036563724 0.00018438990656974706\n",
      "ppl : 36.326427596266825\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nAMOS: Jack doesn't know that we're having this talk and I don't want him to know... understand?\\nRAMIREZ: Okay...\\nAMOS: Nothing can make you ready for combat but combat. Jack would be against me telling you this... He would say you shouldn't have a thought in your head that we haven't put there but you're not just a box that we're going to fill up with our own ideas. You have a right to know certain things.\\nRAMIREZ: I appreciate that Amos... a lot. It's funny, I started out hating you... I mean I'm still gonna sue you, don't think you're off the hook for my broken ribs, but...\\nAMOS: But now you love me and we're going to run away to San Francisco and find a reformed rabbi to perform a mixed gay marriage. Listen to me... You're going to feel more alone than you've ever felt in your life. It will hit you all of a sudden and you'll think your heart's going to jump out of your chest, you'll think everyone around you can hear your heart beating, and that everyone around you is an enemy agent. I want you to be prepared for that. So you can deal with it. Understand?\\nRAMIREZ: Yes.\\nAMOS: We had an agent... the best we ever had in training. We were going to infiltrate him into Beirut and then use him to penetrate the PFLP. No student ever scored higher than this man... We set up his cover for six months in Argentina. He was perfect. And then we sent him to Beirut. He got off the plane, went to his hotel, went up to his room and had a nervous breakdown. We had to mount an operation to send in a man posing as a doctor so we could drug him and get him out on a plane. Okay? Now you understand? Nothing prepares you. I want you to know that so when it hits you, you don't panic, you feel the fear and then get rid of it.\\nRAMIREZ: Jesus...\\nAMOS: You splash some water on your face. that mirror, I don't want you to find Annibal Ramirez. You find Carlos. If you find Carlos, that's what everyone else will find too. And if you find Carlos and anything goes wrong, he's the one who can get you\\nRAMIREZ: I got a wife I got to go back to when this is over. I got kids I got to go back to when this is over. I want to go back as Annibal Ramirez... not Carlos.\\nAMOS: You will... you'll need a time of decompression and it will be hard at first, but you will. Because inside you aren't Carlos... you aren't a terrorist. But right now, in order to save your life, you've got to be. You've got to look in the mirror and find Carlos. Do you understand?\\nRAMIREZ: I do.\\n\\n\", 'answer': \"You won't be able to go in with a gun... too risky... so we're going to have to get one to you once you're in place. How I don't know yet... But we'll get one to you. You'll make your way out by boat. We'll be on it. But we won't be able to help if anything goes wrong. We'll make our way down the coast to a friendly state and then fly back to London, and from there back to the U.S.\", 'gold_tag': 'AMOS is knowledgeable about the effects of combat stress', 'last_speaker': 'AMOS'}\n",
      "Last word -> AMOS : \"You won't be able to go in with a gun... too risky... so we're going to have to get one to you once you're in place. How I don't know yet... But we'll get one to you. You'll make your way out by boat. We'll be on it. But we won't be able to help if anything goes wrong. We'll make our way down the coast to a friendly state and then fly back to London, and from there back to the U.S.\"\n",
      "prediction :  I have to leave now.\n",
      "Real answer : You won't be able to go in with a gun... too risky... so we're going to have to get one to you once you're in place. How I don't know yet... But we'll get one to you. You'll make your way out by boat. We'll be on it. But we won't be able to help if anything goes wrong. We'll make our way down the coast to a friendly state and then fly back to London, and from there back to the U.S.\n",
      "Bert Score : {'precision': [0.878550112247467], 'recall': [0.8189277648925781], 'f1': [0.8476918935775757], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.061224489795918366, 'rouge2': 0.020833333333333332, 'rougeL': 0.040816326530612256, 'rougeLsum': 0.040816326530612256}\n",
      "bleu 1/2 : 1.0072965179973961e-07 6.502071064827725e-08\n",
      "ppl : 107.0578059189355\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDONNIE: --which is why they need to meet you.\\nJORDAN: You gotta get `em fired up so they'll push the shit out of this stock.\\n\\n\", 'answer': 'Let them feel your passion.', 'gold_tag': 'DONNIE is likely a strategist or motivator , DONNIE is seen as needing to inspire others', 'last_speaker': 'DONNIE'}\n",
      "Last word -> DONNIE : \"Let them feel your passion.\"\n",
      "prediction :  --the more you push it, the more they'll get.\n",
      "Real answer : Let them feel your passion.\n",
      "Bert Score : {'precision': [0.8624379634857178], 'recall': [0.897153913974762], 'f1': [0.8794534802436829], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 42.93030511926681\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJORDAN: Donnie. Donnie, wake up.\\nDONNIE: Nuuhh?\\nJORDAN: Untie me, shitbag. You think this is funny?\\nDONNIE: I didn't tie you, the captain did. He almost tasered you.\\n\\n\", 'answer': 'Why?', 'gold_tag': 'JORDAN is somewhat irritable or aggravated', 'last_speaker': 'JORDAN'}\n",
      "Last word -> JORDAN : \"Why?\"\n",
      "prediction :  Where is he?\n",
      "Real answer : Why?\n",
      "Bert Score : {'precision': [0.8823798298835754], 'recall': [0.9300751686096191], 'f1': [0.9055999517440796], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 226.1628040189462\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJORDAN: Start with one, see how it goes?\\n\\n', 'answer': \"My guy says one's all we'll need. Salut'.\", 'gold_tag': 'DONNIE trusts his source', 'last_speaker': 'DONNIE'}\n",
      "Last word -> DONNIE : \"My guy says one's all we'll need. Salut'.\"\n",
      "prediction :  Sure.\n",
      "Real answer : My guy says one's all we'll need. Salut'.\n",
      "Bert Score : {'precision': [0.9236622452735901], 'recall': [0.818396806716919], 'f1': [0.8678492307662964], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 940.7736565945374\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJORDAN: You feeling anything?\\nDONNIE: Nope. Thirty five minutes.\\n\\n', 'answer': \"Maybe we've built up a tolerance all these years?\", 'gold_tag': 'Shared memories: Jordan refers to a period over many years in which he and Donnie may have built a tolerance', 'last_speaker': 'JORDAN'}\n",
      "Last word -> JORDAN : \"Maybe we've built up a tolerance all these years?\"\n",
      "prediction :  Let me know when you feel something.\n",
      "Real answer : Maybe we've built up a tolerance all these years?\n",
      "Bert Score : {'precision': [0.8450628519058228], 'recall': [0.8178284168243408], 'f1': [0.8312225937843323], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 71.75285836244879\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMA�TRE GUILLOCHE: Cinquante-quatre !\\nBLAIREAU: Cinquante-quatre !\\n\\n', 'answer': 'Belle pi�ce !', 'gold_tag': 'Everyday Language', 'last_speaker': 'MA�TRE GUILLOCHE'}\n",
      "Last word -> MA�TRE GUILLOCHE : \"Belle pi�ce !\"\n",
      "prediction :  Je vais vous dire, mon cher Blaireau. Je vais vous dire.\n",
      "Real answer : Belle pi�ce !\n",
      "Bert Score : {'precision': [0.7769618034362793], 'recall': [0.7766069173812866], 'f1': [0.7767843008041382], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 29.33867838371585\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMA�TRE GUILLOCHE: Peu de mots suffiront � ma plaidoirie. Indulgence ou pardon, pardon ou indulgence.\\n\\n', 'answer': 'Tr�s bien.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BLAIREAU'}\n",
      "Last word -> BLAIREAU : \"Tr�s bien.\"\n",
      "prediction :  M. Blaireau, the advocate for the accused.\n",
      "Real answer : Tr�s bien.\n",
      "Bert Score : {'precision': [0.8330984115600586], 'recall': [0.8057369589805603], 'f1': [0.819189190864563], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 145.3866608843921\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMA�TRE GUILLOCHE: Cette f�te est pour vous, Blaireau.\\nBLAIREAU: Mais il fallait pas, mais c'est trop !\\nMA�TRE GUILLOCHE: H�, tenez.\\n\\n\", 'answer': \"Mais tout �a, c'est pour moi ?\", 'gold_tag': \"BLAIREAU is surprised by the attention or gifts he's receiving\", 'last_speaker': 'BLAIREAU'}\n",
      "Last word -> BLAIREAU : \"Mais tout �a, c'est pour moi ?\"\n",
      "prediction :  Oh, merci, monsieur.\n",
      "Real answer : Mais tout �a, c'est pour moi ?\n",
      "Bert Score : {'precision': [0.8300209641456604], 'recall': [0.7880386114120483], 'f1': [0.8084850907325745], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 67.13842895882944\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPOPS: What are you two squawking about?\\n\\n', 'answer': \"Pops, whatever you do, don't open the door!\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SPRITTLE'}\n",
      "Last word -> SPRITTLE : \"Pops, whatever you do, don't open the door!\"\n",
      "prediction :  He's just trying to get me to talk about it, but I'm not.\n",
      "Real answer : Pops, whatever you do, don't open the door!\n",
      "Bert Score : {'precision': [0.8664604425430298], 'recall': [0.8527486324310303], 'f1': [0.8595498204231262], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.160213459120682\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSPRITTLE: Oh yeah!\\n\\n', 'answer': \".that's my boy.\", 'gold_tag': \"POPS takes pride in his son's achievements\", 'last_speaker': 'POPS'}\n",
      "Last word -> POPS : \".that's my boy.\"\n",
      "prediction :  Yo, you got a minute, man?\n",
      "Real answer : .that's my boy.\n",
      "Bert Score : {'precision': [0.8304758071899414], 'recall': [0.8617515563964844], 'f1': [0.8458245992660522], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 39.13308784742407\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSPRITTLE: That cheater! He's using a spear\\nPOPS: Sprittle, we don't know that.\\n\\n\", 'answer': 'I do! Cannonball Taylor is nothing but a big cheater!', 'gold_tag': 'SPRITTLE shows a certain level of assertiveness and conviction in his beliefs', 'last_speaker': 'SPRITTLE'}\n",
      "Last word -> SPRITTLE : \"I do! Cannonball Taylor is nothing but a big cheater!\"\n",
      "prediction :  It's true. I can see it.\n",
      "Real answer : I do! Cannonball Taylor is nothing but a big cheater!\n",
      "Bert Score : {'precision': [0.8820430040359497], 'recall': [0.8441016674041748], 'f1': [0.8626553416252136], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.08556951983876535 0.029642151188002917\n",
      "ppl : 25.017573165784732\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSLOAN: How was it?\\nDELACROIX: Why didn't you tell me about this staff meeting?\\nSLOAN: Nobody told me anything.\\nDELACROIX: What good are you if you don't tell me stuff like this?\\n\\n\", 'answer': \"It wasn't my fault. If I would have known, I would have known.\", 'gold_tag': 'SLOAN reveals that she is not always given necessary information', 'last_speaker': 'SLOAN'}\n",
      "Last word -> SLOAN : \"It wasn't my fault. If I would have known, I would have known.\"\n",
      "prediction :  Well, I'm not supposed to be in the office on Friday. I'm supposed to be in the hospital.\n",
      "Real answer : It wasn't my fault. If I would have known, I would have known.\n",
      "Bert Score : {'precision': [0.866870641708374], 'recall': [0.8617039322853088], 'f1': [0.8642796277999878], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.799258040975952\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDELACROIX: Manray!\\nSLOAN: Manray!\\nDELACROIX: How did you know?\\nSLOAN: It hit me like a ton of bricks.\\nDELACROIX: How can this be? You and me at the same time, the exact same thought. It's scary.\\n\\n\", 'answer': 'The idea was out there in the universe. Now what?', 'gold_tag': 'Everyday Language', 'last_speaker': 'SLOAN'}\n",
      "Last word -> SLOAN : \"The idea was out there in the universe. Now what?\"\n",
      "prediction :  I know. It's like a connection.\n",
      "Real answer : The idea was out there in the universe. Now what?\n",
      "Bert Score : {'precision': [0.886695146560669], 'recall': [0.8578019142150879], 'f1': [0.87200927734375], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 66.01719115839147\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDELACROIX: Manray was under our nose the whole time.\\nSLOAN: Do you know how you will use him?\\nDELACROIX: Not yet, but this thing will never get made.\\nSLOAN: You lost me.\\nDELACROIX: Dunwitty wants a Coon show. And that's what I'm going to give him, it's going to be so racist, so negative, he won't have the balls to put it on the air. Hence I'll prove my point.\\nSLOAN: What point is that?\\nDELACROIX: The point being that him, the networks don't want Black people on television unless they are buffoons.\\nSLOAN: Sounds risky to me.\\nDELACROIX: You getting cold feet?\\nSLOAN: I'm in till the end.\\nDELACROIX: Good. I'm going to need your support.\\nSLOAN: Can't you just quit? Walk away?\\n\\n\", 'answer': \"And lose out on my money? The only way I get paid is if I get fired. And that's what I intend to do.\", 'gold_tag': 'DELACROIX is financially motivated, as he only receives payment if he is fired', 'last_speaker': 'DELACROIX'}\n",
      "Last word -> DELACROIX : \"And lose out on my money? The only way I get paid is if I get fired. And that's what I intend to do.\"\n",
      "prediction :  No. I can't.\n",
      "Real answer : And lose out on my money? The only way I get paid is if I get fired. And that's what I intend to do.\n",
      "Bert Score : {'precision': [0.8915666341781616], 'recall': [0.8243033289909363], 'f1': [0.8566166162490845], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06896551724137932, 'rouge2': 0.0, 'rougeL': 0.06896551724137932, 'rougeLsum': 0.06896551724137932}\n",
      "bleu 1/2 : 0.0003039606551848387 0.00011772345554331757\n",
      "ppl : 89.97142936451796\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSLOAN: Maybe something happened to them. Maybe they're lying in an alley bleed to death.\\nDELACROIX: Manray better not be bleeding to death. I need him. After we're done he can do whatever he wants to do, until then, he's ours.\\n\\n\", 'answer': \"You're beginning to sound like Dunwitty.\", 'gold_tag': 'SLOAN is quick to criticize when she perceives ethical lines being crossed', 'last_speaker': 'SLOAN'}\n",
      "Last word -> SLOAN : \"You're beginning to sound like Dunwitty.\"\n",
      "prediction :  He's gone.\n",
      "Real answer : You're beginning to sound like Dunwitty.\n",
      "Bert Score : {'precision': [0.9112323522567749], 'recall': [0.8545403480529785], 'f1': [0.8819762468338013], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 113.04819108065567\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSLOAN: We both lied to him.\\nDELACROIX: What do you want me to say?\\n\\n', 'answer': \"Just don't lie to me.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SLOAN'}\n",
      "Last word -> SLOAN : \"Just don't lie to me.\"\n",
      "prediction :  You're the one who got him involved in this.\n",
      "Real answer : Just don't lie to me.\n",
      "Bert Score : {'precision': [0.8714821338653564], 'recall': [0.8731018304824829], 'f1': [0.8722912073135376], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.717616137936673\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSLOAN: Divine inspiration?\\nDELACROIX: I was trying to be nice.\\nSLOAN: I want to apologize about my brother and the Mau-Mau's. I should not have imposed them on you.\\n\\n\", 'answer': \"C'mon. You were only doing what family is supposed to be doing for family. You gave your brother a shot. That's all anybody can ask for, an opportunity, a chance, a shot. He got his.\", 'gold_tag': 'DELACROIX believes in the concept of family helping family , DELACROIX values opportunities and chances', 'last_speaker': 'DELACROIX'}\n",
      "Last word -> DELACROIX : \"C'mon. You were only doing what family is supposed to be doing for family. You gave your brother a shot. That's all anybody can ask for, an opportunity, a chance, a shot. He got his.\"\n",
      "prediction :  No, it's fine. It was a good distraction from my own head.\n",
      "Real answer : C'mon. You were only doing what family is supposed to be doing for family. You gave your brother a shot. That's all anybody can ask for, an opportunity, a chance, a shot. He got his.\n",
      "Bert Score : {'precision': [0.8645797371864319], 'recall': [0.8244279623031616], 'f1': [0.8440265655517578], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0.012258038949414737 0.00404869701444397\n",
      "ppl : 26.843278624563855\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDELACROIX: Who's side are you on?\\n\\n\", 'answer': \"I'm sorry, I can't help it. It's too funny.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SLOAN'}\n",
      "Last word -> SLOAN : \"I'm sorry, I can't help it. It's too funny.\"\n",
      "prediction :  I'm on the side of the truth.\n",
      "Real answer : I'm sorry, I can't help it. It's too funny.\n",
      "Bert Score : {'precision': [0.8902060985565186], 'recall': [0.8614083528518677], 'f1': [0.87557053565979], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.1111111111111111, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0.10735389901075512 0.03666833725656689\n",
      "ppl : 33.3499805762911\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSLOAN: So you have your small victory, now what?\\n\\n', 'answer': \"A small victory isn't that small when you've been use to losing.\", 'gold_tag': 'DELACROIX is used to losing , DELACROIX indicates a period of past struggles or failures', 'last_speaker': 'DELACROIX'}\n",
      "Last word -> DELACROIX : \"A small victory isn't that small when you've been use to losing.\"\n",
      "prediction :  Now we have to get it out.\n",
      "Real answer : A small victory isn't that small when you've been use to losing.\n",
      "Bert Score : {'precision': [0.856278657913208], 'recall': [0.8278514742851257], 'f1': [0.8418251276016235], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809523, 'rouge2': 0.0, 'rougeL': 0.09523809523809523, 'rougeLsum': 0.09523809523809523}\n",
      "bleu 1/2 : 0.06993452279385044 0.023887187063648833\n",
      "ppl : 83.91803634866129\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDELACROIX: Why'd you do that?\\nSLOAN: I don't want to hear it.\\nDELACROIX: How long have you and Hambone been hangin' out?\\nSLOAN: You're the one that put us together. We're friends.\\nDELACROIX: That crazy brother of yours doesn't think so.\\nSLOAN: He's just playing big brother.\\nDELACROIX: Oh, is he? You getting jiggy with Mantan?\\nSLOAN: Please don't go there.\\nDELACROIX: Dunwitty and I feel you've been getting too close to him, getting his mind all messed up.\\nSLOAN: I can't lie to him. If he asks me something, I tell him what I think.\\nDELACROIX: Do you have to be so damn forthright?\\nSLOAN: DeLa, you should try it sometime. Come into the light.\\nDELACROIX: Light?\\nSLOAN: That which has been hidden in darkness is now in the light. This bucket of blood.\\n\\n\", 'answer': 'You can talk all that mumbo jumbo if you want to but your hands are much bloody. I know where I made my big mistake. I have a general rule, never get involved romantically with somebody crazier than you.', 'gold_tag': 'DELACROIX is frustrated, interrogative, and wary of personal mistakes made in the past', 'last_speaker': 'DELACROIX'}\n",
      "Last word -> DELACROIX : \"You can talk all that mumbo jumbo if you want to but your hands are much bloody. I know where I made my big mistake. I have a general rule, never get involved romantically with somebody crazier than you.\"\n",
      "prediction :  What are you talking about?\n",
      "Real answer : You can talk all that mumbo jumbo if you want to but your hands are much bloody. I know where I made my big mistake. I have a general rule, never get involved romantically with somebody crazier than you.\n",
      "Bert Score : {'precision': [0.8221819400787354], 'recall': [0.8035634756088257], 'f1': [0.8127661347389221], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09090909090909091, 'rouge2': 0.0, 'rougeL': 0.09090909090909091, 'rougeLsum': 0.09090909090909091}\n",
      "bleu 1/2 : 0.0004455100591379213 0.00011137751478448034\n",
      "ppl : 58.2916451132753\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDELACROIX: This is crazy.\\n\\n', 'answer': \"That's why it will be so much fun.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SLOAN'}\n",
      "Last word -> SLOAN : \"That's why it will be so much fun.\"\n",
      "prediction :  It's not that crazy.\n",
      "Real answer : That's why it will be so much fun.\n",
      "Bert Score : {'precision': [0.864607572555542], 'recall': [0.8654578328132629], 'f1': [0.8650325536727905], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.42857142857142855, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 47.97735880157551\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSLOAN: That was a mistake, but I don't regret it.\\nDELACROIX: The first and only time. A big mistake. I'm gonna have to ask you not to see Mantan anymore.\\nSLOAN: Work related or otherwise?\\nDELACROIX: Otherwise. I trust you know the difference. You're an intelligent woman, finished at NYU. And that's how you got me in the first place.\\n\\n\", 'answer': 'I want you to please view this. It may save your Life.', 'gold_tag': 'SLOAN urges DELACROIX to view something that could potentially save his life', 'last_speaker': 'SLOAN'}\n",
      "Last word -> SLOAN : \"I want you to please view this. It may save your Life.\"\n",
      "prediction :  How did you get in the first place?\n",
      "Real answer : I want you to please view this. It may save your Life.\n",
      "Bert Score : {'precision': [0.8061122894287109], 'recall': [0.843258798122406], 'f1': [0.8242672085762024], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1, 'rouge2': 0.0, 'rougeL': 0.1, 'rougeLsum': 0.1}\n",
      "bleu 1/2 : 0.07581633246407919 0.02563059838397131\n",
      "ppl : 49.65386663655461\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVICTOR: Oh.\\nCAROLINE: I'm sorry. Did I startle you?\\nVICTOR: Yeah. I didn't--\\nCAROLINE: Do you have a few minutes? My business won't take long.\\nVICTOR: Sure. Come on in.\\n\\n\", 'answer': 'Thank you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CAROLINE'}\n",
      "Last word -> CAROLINE : \"Thank you.\"\n",
      "prediction :  So, how have you been?\n",
      "Real answer : Thank you.\n",
      "Bert Score : {'precision': [0.8313575983047485], 'recall': [0.9046667814254761], 'f1': [0.8664643168449402], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 44.403636581748835\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCAROLINE: There's one more sacrifice you need to make.\\n\\n\", 'answer': 'What are you doing? What do you want?', 'gold_tag': 'Everyday Language', 'last_speaker': 'VICTOR'}\n",
      "Last word -> VICTOR : \"What are you doing? What do you want?\"\n",
      "prediction :  What is it?\n",
      "Real answer : What are you doing? What do you want?\n",
      "Bert Score : {'precision': [0.909700334072113], 'recall': [0.8719251751899719], 'f1': [0.8904122710227966], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0.06295853427918728 0.024383735476492117\n",
      "ppl : 140.93475091067572\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVICTOR: What do you want? You want money? I'll give you whatever you want.\\nCAROLINE: I just want one tiny little insignificant thing.\\nVICTOR: What?\\n\\n\", 'answer': 'Your life.', 'gold_tag': \"CAROLINE displays a desire for VICTOR's life\", 'last_speaker': 'CAROLINE'}\n",
      "Last word -> CAROLINE : \"Your life.\"\n",
      "prediction :  Your autograph.\n",
      "Real answer : Your life.\n",
      "Bert Score : {'precision': [0.8763577938079834], 'recall': [0.9145055413246155], 'f1': [0.895025372505188], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.5, 'rouge2': 0.0, 'rougeL': 0.5, 'rougeLsum': 0.5}\n",
      "bleu 1/2 : 0.5 0.223606797749979\n",
      "ppl : 1152.9623157926744\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMAX: Alex. The first unit to respond must’ve scared them away before they could do the same thing to you. Pretty remarkable, considering your luck. He was trying to tell me something.\\nBB: Was he alive when you showed up? Did you get a look at the guys who--\\nMAX: No. I get flashes, but it’s...wrong.\\nBB: I hate to say it, but you need to come up with something better than that. They’ve got nothing for leads, so the whole force has you pegged as the prime suspect.\\n\\n', 'answer': 'You tell them where to find me. No need. The funeral starts in an hour. What I need is to borrow some dress blues. Can you help me out? Yeah. My office is on the way.', 'gold_tag': \"MAX indicates that a funeral he plans to attend starts in an hour , MAX is attending a funeral , BB has access to 'dress blues'\", 'last_speaker': 'MAX'}\n",
      "Last word -> MAX : \"You tell them where to find me. No need. The funeral starts in an hour. What I need is to borrow some dress blues. Can you help me out? Yeah. My office is on the way.\"\n",
      "prediction :  If you had any idea how many cops were on this case, you’d be getting a call from the chief of police right now.\n",
      "Real answer : You tell them where to find me. No need. The funeral starts in an hour. What I need is to borrow some dress blues. Can you help me out? Yeah. My office is on the way.\n",
      "Bert Score : {'precision': [0.8366516828536987], 'recall': [0.8382479548454285], 'f1': [0.8374490737915039], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13114754098360656, 'rouge2': 0.0, 'rougeL': 0.09836065573770492, 'rougeLsum': 0.09836065573770492}\n",
      "bleu 1/2 : 0.07581633246407919 0.01413981891318001\n",
      "ppl : 11.300854686606817\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMAX: Alex found something out about what happened to her. Something new. There’s no way. He would have told us. He was trying, right before he died...\\nBB: Listen, okay? Why don’t you come back with me, let Beth make up the guest room for you. Just for tonight. You need to take some time. Get some sleep, heal up. See if it still feels real after that...\\n\\n', 'answer': 'It’s real.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MAX'}\n",
      "Last word -> MAX : \"It’s real.\"\n",
      "prediction :  No. I can’t. I can’t leave him here.\n",
      "Real answer : It’s real.\n",
      "Bert Score : {'precision': [0.8823821544647217], 'recall': [0.8949140310287476], 'f1': [0.888603925704956], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 27.195382019029974\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMAX: Go a little further, read what they did to the bodies. It’s the same as what happened to Alex and that girl. Where did you get this? Michelle. It’s all in her notes: people describing fevers, hallucinations...their lymph something’s been choking them. The angels they all talk about? Michelle talks about eye spasms that make things seem to flutter. Mixed with the other delusions, that starts looking like wings... She wasn’t seeing them. She was trying to figure out why other people were. Somebody at Aesir knows what-- Oh, my God. It’s me. I killed Alex. What are you talking about? He came to me about six months ago, asking about one of the executives at Aesir. At the time I had no reason to connect it to Michelle, I just thought... I tried to warn him, this guy has connections to some scary people-- Who? What’s his name?\\n\\n', 'answer': 'Jason Colvin. He used to be the head of the pharmaceutical division, but he’s moved up over the last few years. I guess Michelle probably reported directly to him... You’ve got copies of this stuff, right? Be careful, Max.', 'gold_tag': 'BB used to work in the pharmaceutical division in Aesir , BB has recently moved up the ranks , BB likely had professional interactions with Michelle , Shared memories, MAX has connections with scary people and is involved in investigative work , MAX feels guilty about the death of Alex , Michelle, who might be a close one, has passed away , MAX reveals that Alex approached him six months ago', 'last_speaker': 'BB'}\n",
      "Last word -> BB : \"Jason Colvin. He used to be the head of the pharmaceutical division, but he’s moved up over the last few years. I guess Michelle probably reported directly to him... You’ve got copies of this stuff, right? Be careful, Max.\"\n",
      "prediction :  Alex?\n",
      "Real answer : Jason Colvin. He used to be the head of the pharmaceutical division, but he’s moved up over the last few years. I guess Michelle probably reported directly to him... You’ve got copies of this stuff, right? Be careful, Max.\n",
      "Bert Score : {'precision': [0.8287680745124817], 'recall': [0.7935731410980225], 'f1': [0.8107888698577881], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 6709.701978528875\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPHIL: We tried the big vaporware number, Gary, it's no-sale.\\nRANDY: Can we buy into their IPO? Or is that a Justice Dept. problem?\\n\\n\", 'answer': \"There is no public offering. The guy who wrote it joined some freakazoid cult in San Luis Obispo. 'Wrote this just to run their web site.\", 'gold_tag': 'PHIL is knowledgeable about the industry landscape , PHIL has a network of contacts', 'last_speaker': 'PHIL'}\n",
      "Last word -> PHIL : \"There is no public offering. The guy who wrote it joined some freakazoid cult in San Luis Obispo. 'Wrote this just to run their web site.\"\n",
      "prediction :  I don't think they're gonna go public. I think they're gonna be the Microsoft of the future.\n",
      "Real answer : There is no public offering. The guy who wrote it joined some freakazoid cult in San Luis Obispo. 'Wrote this just to run their web site.\n",
      "Bert Score : {'precision': [0.8559062480926514], 'recall': [0.8337917327880859], 'f1': [0.844704270362854], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913043, 'rouge2': 0.0, 'rougeL': 0.08695652173913043, 'rougeLsum': 0.08695652173913043}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.611151002900005\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRANDY: Maybe he'll get back to work.\\nPHIL: Speaking of which...\\n\\n\", 'answer': 'Yeah, yeah.', 'gold_tag': 'Everyday Language', 'last_speaker': 'RANDY'}\n",
      "Last word -> RANDY : \"Yeah, yeah.\"\n",
      "prediction :  What?\n",
      "Real answer : Yeah, yeah.\n",
      "Bert Score : {'precision': [0.8461133241653442], 'recall': [0.8407585620880127], 'f1': [0.8434274196624756], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPHIL: Did you download Corey? In San Jose?\\nRANDY: Damn. 'Have to go back over there. Be so much easier if we could walk in the front door.\\n\\n\", 'answer': \"You don't look anything like a three- year-old.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'PHIL'}\n",
      "Last word -> PHIL : \"You don't look anything like a three- year-old.\"\n",
      "prediction :  Maybe we could get a couple of cars and drive in.\n",
      "Real answer : You don't look anything like a three- year-old.\n",
      "Bert Score : {'precision': [0.8556581735610962], 'recall': [0.855962872505188], 'f1': [0.8558104634284973], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809525, 'rouge2': 0.0, 'rougeL': 0.09523809523809525, 'rougeLsum': 0.09523809523809525}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 41.56576210458418\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJASON: Big boat.\\nGABRIELLA: ugly, isn't it.\\nJASON: The fittings are definitely -- yeah on the ugly side. But damn, she's solid.\\nGABRIELLA: Oh, a boat type.\\nJASON: I like.boats. So where you headed?\\nGABRIELLA: I'm not going, 'I can't go.\\nJASON: They don't want to take the baby.\\nGABRIELLA: I•don't have a green card, I can't leave the country. Baby goes with an American nurse. I house-sit. It's fine.\\nJASON: You don't like them.\\nGABRIELLA: God. I'm obvious. I just don't like working for people, but that's life.\\nJASON: Doesn't have to be.\\nGABRIELLA: Maybe not with a rich stepfather.\\nJASON: Worst kind.\\nGABRIELLA: No. You don't appreciate what you have, Jason. It's very poor where I came from.\\nJASON: Where's that?\\nGABRIELLA: Venezuela. Do I look it?\\nJASON: I don't know, I never been there.\\nGABRIELLA: Well, I don't. My mother's Indian. The India kind of Indian. Imagine a house where the father asks 'What's for dinner' in Spanish, and the mother answers 'Curry' in Hindi. 'Que hay para cenar' she says, 'Murgee, masala, ghaal.' He says, 'No es importante.' No wonder I'm nuts.\\nJASON: You don't seem too nuts.\\n\\n\", 'answer': \"You don't know mel\", 'gold_tag': 'Everyday Language', 'last_speaker': 'GABRIELLA'}\n",
      "Last word -> GABRIELLA : \"You don't know mel\"\n",
      "prediction :  I am. But I don't think I'm crazy enough to be institutionalized. That's what you want to hear, isn't it? That I'm a little crazy, but not too crazy?\n",
      "Real answer : You don't know mel\n",
      "Bert Score : {'precision': [0.8022891283035278], 'recall': [0.8359344005584717], 'f1': [0.8187662959098816], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615385, 'rouge2': 0.054054054054054064, 'rougeL': 0.10256410256410256, 'rougeLsum': 0.10256410256410256}\n",
      "bleu 1/2 : 0.03448275862068965 0.011097419040461881\n",
      "ppl : 5.719574065855157\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJASON: Did you do something? Or was it just...\\nGABRIELLA: Just. They said they.were -- downsizing.\\nJASON: Like they're a factory?\\nGABRIELLA: The size of their staff? It is.\\nJASON: Hang a left.\\nGABRIELLA: Not for the wharf.\\nJASON: I know. Just turn!\\nGABRIELLA: Idiot!\\n\\n\", 'answer': '-- Cool.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JASON'}\n",
      "Last word -> JASON : \"-- Cool.\"\n",
      "prediction :  You said they're downsizing.\n",
      "Real answer : -- Cool.\n",
      "Bert Score : {'precision': [0.867739200592041], 'recall': [0.8699154853820801], 'f1': [0.8688259720802307], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 84.50361216851428\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJASON: You can learn on the fish around here, but you can't eat 'em. They're junk fish.\\nGABRIELLA: Will you teach me?\\nJASON: Oh, you think you're ready for that kind of commitment?\\nGABRIELLA: I'm only investing an afternoon. Where are we?\\nJASON: My father used to bring me here.\\nGABRIELLA: No more?\\nJASON: He's dead. He drowned in a storm. He was a fisherman.\\nGABRIELLA: I don't know if I would like boats after that.\\nJASON: I feel close to him when I'm on the water.\\nGABRIELLA: How old were you?\\n\\n\", 'answer': \"-- Eight. I'd just turned eight.\", 'gold_tag': \"JASON's father passed away when he was eight\", 'last_speaker': 'JASON'}\n",
      "Last word -> JASON : \"-- Eight. I'd just turned eight.\"\n",
      "prediction :  Ten.\n",
      "Real answer : -- Eight. I'd just turned eight.\n",
      "Bert Score : {'precision': [0.9415810108184814], 'recall': [0.8590835332870483], 'f1': [0.8984424471855164], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 8399.750957084641\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGABRIELLA: I can't.\\nJASON: You waited long enough to tell me.\\nGABRIELLA: Because it felt good, and I'm an idiot!\\nJASON: No, you're not.\\nGABRIELLA: I want to go back now. Can we go back, please?\\nJASON: ... Sure. I'm sorry.\\nGABRIELLA: What?\\nJASON: I'm sorry!\\n\\n\", 'answer': 'Me, too.', 'gold_tag': 'GABRIELLA seeks reassurance', 'last_speaker': 'GABRIELLA'}\n",
      "Last word -> GABRIELLA : \"Me, too.\"\n",
      "prediction :  ... Why?\n",
      "Real answer : Me, too.\n",
      "Bert Score : {'precision': [0.8284518718719482], 'recall': [0.8661081790924072], 'f1': [0.8468616008758545], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3741.8982968257546\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGABRIELLA: Are you going to kill me, too?\\nJASON: No!\\nGABRIELLA: You'll have to. I'll know. I'll be a witness. I'll know you planned it.\\nJASON: -- Would you do that?\\nGABRIELLA: I like-you too much to let you kill him. I need him, Jason.\\nJASON: You don't -- you don't!\\nGABRIELLA: I'm not going back to Caracas! You don't know how we live there. You have to leave now, Jason.\\nJASON: What are you talking about? This is my home. I'm home.\\nGABRIELLA: This is not your room, though, is it.\\nJASON: You're never going to marry him, Gabriella.\\n\\n\", 'answer': 'Watch me.', 'gold_tag': 'Everyday Language', 'last_speaker': 'GABRIELLA'}\n",
      "Last word -> GABRIELLA : \"Watch me.\"\n",
      "prediction :  Why?\n",
      "Real answer : Watch me.\n",
      "Bert Score : {'precision': [0.8704856634140015], 'recall': [0.9136300086975098], 'f1': [0.8915361166000366], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3142.135932895678\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGABRIELLA: Okay. Here I am. What is it? Do you know how much a cab costs?\\nJASON: I saw a guy following me... I thought you weren\\'t safe. I was going to tell you to go stay at your -- Hey!\\nGABRIELLA: I\\'m so sick of this. You\\'d say anything! WHAT --\\nJASON: Read it. at the bottom of the page reads, \"Duchess of Windsor Duchess herself in her glory days, necklace around her throat.\\nGABRIELLA: There is such a thing as justicel Dina\\'s necklace. Couldn\\'t happen to a better person.\\nJASON: Alex stole it.\\nGABRIELLA: You really hate him.\\nJASON: The reason I know is because I stole it from him.\\nGABRIELLA: ... The sonofabitch. That\\'s why he went out with me. He was trying to use me! They\\'ll think I\\'m part of it! The maid who got fired??\\nJASON: You weren\\'t a maid.\\nGABRIELLA: What difference does it make??\\n\\n', 'answer': \"We're going to the Gulf. He throws money down for the check.\", 'gold_tag': 'JASON has access to significant amounts of money', 'last_speaker': 'JASON'}\n",
      "Last word -> JASON : \"We're going to the Gulf. He throws money down for the check.\"\n",
      "prediction :  So you're not going to do anything about it?\n",
      "Real answer : We're going to the Gulf. He throws money down for the check.\n",
      "Bert Score : {'precision': [0.835341215133667], 'recall': [0.8556202054023743], 'f1': [0.8453590869903564], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2608695652173913, 'rouge2': 0.09523809523809525, 'rougeL': 0.2608695652173913, 'rougeLsum': 0.2608695652173913}\n",
      "bleu 1/2 : 0.15922918012750872 0.11942188509563156\n",
      "ppl : 21.810884702083985\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRANSOM: ...you're not giving up your family's fortune!\\n\\n\", 'answer': 'You are not giving up the family fortune.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BLANC'}\n",
      "Last word -> BLANC : \"You are not giving up the family fortune.\"\n",
      "prediction :  I'm not going to give up my family's fortune.\n",
      "Real answer : You are not giving up the family fortune.\n",
      "Bert Score : {'precision': [0.9546995162963867], 'recall': [0.9705623388290405], 'f1': [0.9625656008720398], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4210526315789474, 'rouge2': 0.0, 'rougeL': 0.4210526315789474, 'rougeLsum': 0.4210526315789474}\n",
      "bleu 1/2 : 0.3333333333333333 0.06454972243679029\n",
      "ppl : 28.812294073696492\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRANSOM: You've come this far!\\n\\n\", 'answer': 'You have come this far. Just one step further. Just one last act, in for a penny, in for a pound. You decide. You are in.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BLANC'}\n",
      "Last word -> BLANC : \"You have come this far. Just one step further. Just one last act, in for a penny, in for a pound. You decide. You are in.\"\n",
      "prediction :  Yes.\n",
      "Real answer : You have come this far. Just one step further. Just one last act, in for a penny, in for a pound. You decide. You are in.\n",
      "Bert Score : {'precision': [0.9184786081314087], 'recall': [0.8233789205551147], 'f1': [0.8683326840400696], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2104.611116571625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRANSOM: ...you're not going to give up the money.\\n\\n\", 'answer': 'You are not going to give up the money.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BLANC'}\n",
      "Last word -> BLANC : \"You are not going to give up the money.\"\n",
      "prediction :  Oh, you think I'm going to give up the money?\n",
      "Real answer : You are not going to give up the money.\n",
      "Bert Score : {'precision': [0.8879959583282471], 'recall': [0.9337084889411926], 'f1': [0.9102786779403687], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.7000000000000001, 'rouge2': 0.5555555555555556, 'rougeL': 0.7000000000000001, 'rougeLsum': 0.7000000000000001}\n",
      "bleu 1/2 : 0.5 0.4714045207910317\n",
      "ppl : 28.57771668847132\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATE: What are you watching?\\nHOLLY: Celebrity Dance -\\n\\n', 'answer': '- Nope.', 'gold_tag': 'NATE is not interested in Celebrity Dance', 'last_speaker': 'NATE'}\n",
      "Last word -> NATE : \"- Nope.\"\n",
      "prediction :  I can't believe that's on TV.\n",
      "Real answer : - Nope.\n",
      "Bert Score : {'precision': [0.8410003185272217], 'recall': [0.8764938712120056], 'f1': [0.8583802580833435], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 38.373111270892245\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATE: OK, so we've got a year. That gives us some time to save and get ready.\\n\\n\", 'answer': \"What do you mean? We're ready now.\", 'gold_tag': \"HOLLY believes she is ready to start a family now with NATE , HOLLY's temporal information\", 'last_speaker': 'HOLLY'}\n",
      "Last word -> HOLLY : \"What do you mean? We're ready now.\"\n",
      "prediction :  That's right.\n",
      "Real answer : What do you mean? We're ready now.\n",
      "Bert Score : {'precision': [0.8721978664398193], 'recall': [0.8363046050071716], 'f1': [0.8538742065429688], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 65.67370267700424\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOLLY: This is it. This is the one.\\nNATE: What?! No. We're not buying. We're just looking.\\nHOLLY: But can't you picture it? The couch here, you and your keyboard over there, singing at our Christmas party.\\nNATE: Are you effin crazy?/ First, we gotta deal with the baby/ Then we can talk house, my lovely spouse -\\nHOLLY: Home, let me come home home home -\\nNATE: - Oh no, uh-uh. You're not allowed to use that song against me. I'm the one who put it on your iPod.\\nHOLLY: I know. It's a good one.\\nNATE: Yeah. I'm trying to get it placed in our United Airlines ad.\\nHOLLY: Nate. This is the one.\\n\\n\", 'answer': \"We're just looking.\", 'gold_tag': 'NATE prefers to only look at homes rather than buying them right away', 'last_speaker': 'NATE'}\n",
      "Last word -> NATE : \"We're just looking.\"\n",
      "prediction :  Yeah?\n",
      "Real answer : We're just looking.\n",
      "Bert Score : {'precision': [0.8420846462249756], 'recall': [0.8325908184051514], 'f1': [0.8373108506202698], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 4743.506449578175\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOLLY: The agency called! This is it!\\n\\n', 'answer': \"Already!? It's supposed to be at least six months. Not two.\", 'gold_tag': 'NATE is aware of the expected timeline regarding their interaction with the agency , NATE is under the impression that they had at least six months before hearing from the agency', 'last_speaker': 'NATE'}\n",
      "Last word -> NATE : \"Already!? It's supposed to be at least six months. Not two.\"\n",
      "prediction :  Really?\n",
      "Real answer : Already!? It's supposed to be at least six months. Not two.\n",
      "Bert Score : {'precision': [0.8883298635482788], 'recall': [0.8245999813079834], 'f1': [0.8552793264389038], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 427.58461507510566\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATE: I realize how much you've been doing, between work and getting everything ready for the baby, and -\\nHOLLY: - Nate, about work. I -\\n\\n\", 'answer': '- No shop-talk tonight. I just wanna remind you we can still kick it Nate and Holly-style.', 'gold_tag': 'NATE enjoys spending quality time with Holly without talking about work', 'last_speaker': 'NATE'}\n",
      "Last word -> NATE : \"- No shop-talk tonight. I just wanna remind you we can still kick it Nate and Holly-style.\"\n",
      "prediction :  No, no, no. I'm the one who's been out of the loop, and I think I need to be here. I need to be here for you. I'm not going to leave you alone.\n",
      "Real answer : - No shop-talk tonight. I just wanna remind you we can still kick it Nate and Holly-style.\n",
      "Bert Score : {'precision': [0.835580587387085], 'recall': [0.839880108833313], 'f1': [0.8377248644828796], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14545454545454545, 'rouge2': 0.0, 'rougeL': 0.1090909090909091, 'rougeLsum': 0.1090909090909091}\n",
      "bleu 1/2 : 0.08823529411764706 0.01635174850419321\n",
      "ppl : 7.1541440708476625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAREN: Hello, Billy ! Thank God. She's there. Are you all right ?\\nANDY: Ask her about the mask.\\n\\n\", 'answer': 'You want to tap something through ?', 'gold_tag': 'KAREN is caring', 'last_speaker': 'KAREN'}\n",
      "Last word -> KAREN : \"You want to tap something through ?\"\n",
      "prediction :  Andy, what are you talking about?\n",
      "Real answer : You want to tap something through ?\n",
      "Bert Score : {'precision': [0.8466252088546753], 'recall': [0.821456789970398], 'f1': [0.833851158618927], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 62.280955761719234\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANDY: Well, I've never been more embarrassed in my entire life.\\nKAREN: I don't get it. I mean, Billy's a pro. She'd know the difference between a real murder and a gag.\\nANDY: Please, has she even seen a real murder ?\\nKAREN: That's my point. If what she saw tonight was real, then she has seen the difference, right ?\\nANDY: Oh, come on, honey. We all bought the guy cutting me up tonight. Even I believed it.\\nKAREN: Because you're a wuss.\\nANDY: I'm gonna let that slide. No offense, Billy, but I'd like to re-shoot the stuff today using that guy's knife.\\nKAREN: It was her knife. God !\\nANDY: Whatever. It looked good.\\n\\n\", 'answer': 'Shut up.', 'gold_tag': 'Everyday Language', 'last_speaker': 'KAREN'}\n",
      "Last word -> KAREN : \"Shut up.\"\n",
      "prediction :  You know, I think you should talk to Billy. I'm sure she's got a great explanation for all of this.\n",
      "Real answer : Shut up.\n",
      "Bert Score : {'precision': [0.8286340236663818], 'recall': [0.88257896900177], 'f1': [0.854756236076355], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.360826610333001\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANDY: Please, Billy, take some of mine. You'll feel better. Okay. Could you pass me the salt, please ?\\nKAREN: You could at least make the effort.\\nANDY: Listen... I'm sorry. All I can think about now is the movie, but as soon as we get back, I promise, I'll learn.\\nKAREN: How often have I heard that ?\\nANDY: Come on. I can understand some of what she's saying.\\nKAREN: What ?\\nANDY: Okay, how about this ? Means �makeup�, right ?\\nKAREN: Wrong. It means somebody's look, the expression on their face.\\nANDY: That was close.\\n\\n\", 'answer': \"What Billy said she'll never forget the look on the girl's face tonight from the moment she knew she was gonna die. She said the pain and the terror was real. You can't act that.\", 'gold_tag': \"KAREN is willing to discuss serious topics such as the look of terror on a dying girl's face\", 'last_speaker': 'KAREN'}\n",
      "Last word -> KAREN : \"What Billy said she'll never forget the look on the girl's face tonight from the moment she knew she was gonna die. She said the pain and the terror was real. You can't act that.\"\n",
      "prediction :  I don't know why I'm even talking to you.\n",
      "Real answer : What Billy said she'll never forget the look on the girl's face tonight from the moment she knew she was gonna die. She said the pain and the terror was real. You can't act that.\n",
      "Bert Score : {'precision': [0.8433835506439209], 'recall': [0.8349792957305908], 'f1': [0.8391603231430054], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08163265306122448, 'rouge2': 0.0, 'rougeL': 0.04081632653061224, 'rougeLsum': 0.04081632653061224}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.827375288698315\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAREN: No, honestly, you can come back to our place, and we'll set up the couch if you want. You're not on one of your �I'll show her how independent I am� kicks, are you ?\\nANDY: Honey, you coming or what ?\\nKAREN: Andy, don't you care about her ?\\nANDY: I don't care ? I don't care ? Fine, fine. I'm calling the American Embassy tonight, okay ?\\nKAREN: It's the weekend. They're closed.\\n\\n\", 'answer': \"Not for us. My dad gave me the duty officer's direct number before we left, just in case. So say goodbye.\", 'gold_tag': \"ANDY's father was given a direct number to a duty officer at the embassy, indicating a preferable treatment\", 'last_speaker': 'ANDY'}\n",
      "Last word -> ANDY : \"Not for us. My dad gave me the duty officer's direct number before we left, just in case. So say goodbye.\"\n",
      "prediction :  I'll get the 24-hour emergency number.\n",
      "Real answer : Not for us. My dad gave me the duty officer's direct number before we left, just in case. So say goodbye.\n",
      "Bert Score : {'precision': [0.8905006051063538], 'recall': [0.8623197674751282], 'f1': [0.8761836886405945], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0.013680833103983134 0.0047391796051938035\n",
      "ppl : 28.45993054820144\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAREN: Billy ! Okay, that's it. I'm going there.\\n\\n\", 'answer': 'What ?', 'gold_tag': 'Everyday Language', 'last_speaker': 'ANDY'}\n",
      "Last word -> ANDY : \"What ?\"\n",
      "prediction :  Wait, Karen.\n",
      "Real answer : What ?\n",
      "Bert Score : {'precision': [0.870776891708374], 'recall': [0.8182557821273804], 'f1': [0.8436997532844543], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 457.1316344408462\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAREN: My...\\nANDY: Oh, my God, it's trashed !\\nKAREN: Billy, where are you ?\\n\\n\", 'answer': \"I'll call the police !\", 'gold_tag': 'ANDY is willing to take immediate action in a crisis', 'last_speaker': 'ANDY'}\n",
      "Last word -> ANDY : \"I'll call the police !\"\n",
      "prediction :  Karen, don't move.\n",
      "Real answer : I'll call the police !\n",
      "Bert Score : {'precision': [0.8649337291717529], 'recall': [0.858142614364624], 'f1': [0.8615248203277588], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 97.67298242651026\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANDY: Right. Let's get out of here. Delta three. Delta three.\\nKAREN: Answer it.\\nANDY: Why ?\\nKAREN: They may say something about Billy. WARTSCHUK (voice over from the talkie) Delta three. Da.\\nANDY: Da. Da.\\nKAREN: I got something about studio. Come on. Look out !\\nANDY: Mmm... It's not what you think. What do you say ?... How do you ?... In Russian, what ?... What ? What does that mean ?\\nKAREN: Hel...\\nANDY: Hello ? We need help ! I'm a director, and I'm making a movie here. This is not a movie. Put the gun away. You look like a hit man. He thinks we're gonna kill him !\\nKAREN: We're not gonna kill you !\\nANDY: This is not even ours !\\nKAREN: The policemen wanted to kill us ! We gotta get out of here.\\nANDY: Well, I think we should call the cops.\\nKAREN: Are you crazy ?\\nANDY: Well, we can explain this.\\nKAREN: Explain ? You are crazy. Come on. Here.\\n\\n\", 'answer': \"I'll take these too.\", 'gold_tag': 'ANDY is involved in some sort of conflicted situation', 'last_speaker': 'ANDY'}\n",
      "Last word -> ANDY : \"I'll take these too.\"\n",
      "prediction :  No, no. I'm not going anywhere. I gotta get out of here.\n",
      "Real answer : I'll take these too.\n",
      "Bert Score : {'precision': [0.8552793860435486], 'recall': [0.8569567203521729], 'f1': [0.8561171889305115], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.683213881182205\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANDY: This damn gun, I can't work the safety. Holy shit !\\nKAREN: Around the back. Okay. Jump, Andy. I got you.\\nANDY: What ?\\n\\n\", 'answer': 'I got you. I got you.', 'gold_tag': 'KAREN is supportive and in control of the situation', 'last_speaker': 'KAREN'}\n",
      "Last word -> KAREN : \"I got you. I got you.\"\n",
      "prediction :  I said jump.\n",
      "Real answer : I got you. I got you.\n",
      "Bert Score : {'precision': [0.8806362152099609], 'recall': [0.8646882772445679], 'f1': [0.8725893497467041], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2222222222222222, 'rouge2': 0.0, 'rougeL': 0.2222222222222222, 'rougeLsum': 0.2222222222222222}\n",
      "bleu 1/2 : 0.12262648039048077 0.04749303163563625\n",
      "ppl : 1062.1206729222224\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANDY: Nice night, isn't it ? I'm just taking a piss. Right, you know, just...\\nKAREN: Who the hell is that ?\\n\\n\", 'answer': \"Well, whoever it is, they're coming here.\", 'gold_tag': 'KAREN is concerned about who might be approaching them', 'last_speaker': 'ANDY'}\n",
      "Last word -> ANDY : \"Well, whoever it is, they're coming here.\"\n",
      "prediction :  Karen ? Karen ?\n",
      "Real answer : Well, whoever it is, they're coming here.\n",
      "Bert Score : {'precision': [0.8165204524993896], 'recall': [0.8258130550384521], 'f1': [0.8211404085159302], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 352.8715557461106\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANDY: I can't work the safety.\\nKAREN: Andy, come on.\\nANDY: Yeah, yeah, I'm coming.\\n\\n\", 'answer': 'Hurry !', 'gold_tag': 'KAREN is patient , KAREN is in a hurry or facing a time-sensitive situation', 'last_speaker': 'KAREN'}\n",
      "Last word -> KAREN : \"Hurry !\"\n",
      "prediction :  Don't worry, I'm here for you.\n",
      "Real answer : Hurry !\n",
      "Bert Score : {'precision': [0.8473578691482544], 'recall': [0.8181172609329224], 'f1': [0.8324808478355408], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13.553410229721818\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nREGGIE: You're back tonight?\\nMACY: Yeah. I'll call you, let you know what time.\\nREGGIE: I don't understand why they don't want me there...\\nMACY: It's El Paso... Don't think you're missing much.\\nREGGIE: Well... you keep your eye on that doughy prick in the golf shirt...\\nMACY: I'm supposed to worry about you.\\nREGGIE: This isn't what we do, Kate.\\n\\n\", 'answer': 'We do what we need to do.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MACY'}\n",
      "Last word -> MACY : \"We do what we need to do.\"\n",
      "prediction :  I know that, Reggie. I know that.\n",
      "Real answer : We do what we need to do.\n",
      "Bert Score : {'precision': [0.858077883720398], 'recall': [0.8397198915481567], 'f1': [0.8487996459007263], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 48.26000320103732\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nREGGIE: You're phone's off.\\nMACY: Yep.\\nREGGIE: We gotta go. Those spooks been calling me all morning.\\nMACY: Want some coffee?\\nREGGIE: We gotta go.\\n\\n\", 'answer': 'I have to get dressed. Come up.', 'gold_tag': 'MACY is in the process of getting dressed', 'last_speaker': 'MACY'}\n",
      "Last word -> MACY : \"I have to get dressed. Come up.\"\n",
      "prediction :  Fine. What do you want me to do?\n",
      "Real answer : I have to get dressed. Come up.\n",
      "Bert Score : {'precision': [0.8675692677497864], 'recall': [0.8747708797454834], 'f1': [0.8711552023887634], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0.12500000000000003 0.04225771273642583\n",
      "ppl : 25.298366588361592\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nREGGIE: Gotta get you a new bra, woman. Just saying. You gotta... some nice lacy something.\\nMACY: Been so long since anyone's seen me in a bra, except you... don't look at me like that. No pity, thank you.\\nREGGIE: How was seeing Evan the other day?\\nMACY: ...I don't know.\\nREGGIE: Miss him?\\nMACY: Guy works eighty hours a week and thinks I'm too focused on my job.\\nREGGIE: Mmhmm. And what does that tell you?\\nMACY: Ask me something else.\\nREGGIE: What was it like? On the border.\\nMACY: It's broken ... The whole place. Just ... Lost.\\nREGGIE: Wish you hadn't volunteered for this.\\nMACY: Me too. But... I have to know.\\nREGGIE: Know what?\\nMACY: Could it get that bad here?\\nREGGIE: Well, you sure picked the mother fuckers to show us.\\n\\n\", 'answer': 'Yeah...', 'gold_tag': 'Everyday Language', 'last_speaker': 'MACY'}\n",
      "Last word -> MACY : \"Yeah...\"\n",
      "prediction :  ...That was a bad idea.\n",
      "Real answer : Yeah...\n",
      "Bert Score : {'precision': [0.8756290078163147], 'recall': [0.8356779217720032], 'f1': [0.8551871180534363], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 162.7767402180102\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMACY: Where'd that guy say the safe banks were, Cave Creek?\\nREGGIE: Yeah?\\nMACY: Ever been there?\\nREGGIE: Don't even know where it is...\\nMACY: North of Scottsdale. Horse country...\\nREGGIE: Yeah?\\nMACY: Big saloon there called the Buffalo Chip... Feel like a beer somewhere far away?\\nREGGIE: Why? There an angle here?\\nMACY: Yeah. Angle is me getting drunk and forgetting about today.\\nREGGIE: At the Buffalo Chip? Yeah... I'll go to the Buffalo Chip. Get my two step on... Drive your drunk ass home later...\\n\\n\", 'answer': 'Alright. To the Chip.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MACY'}\n",
      "Last word -> MACY : \"Alright. To the Chip.\"\n",
      "prediction :  Great!\n",
      "Real answer : Alright. To the Chip.\n",
      "Bert Score : {'precision': [0.8760257959365845], 'recall': [0.9057193994522095], 'f1': [0.8906251788139343], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2025.934228480724\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEDWARD: It corners like it's on rails.\\n\\n\", 'answer': 'What ? What does that mean ?', 'gold_tag': 'PHILIP lacks understanding about the analogy used by EDWARD related to car performance , PHILIP is not particularly knowledgeable or interested in cars', 'last_speaker': 'PHILIP'}\n",
      "Last word -> PHILIP : \"What ? What does that mean ?\"\n",
      "prediction :  Yeah, I know. I've been to the track a few times. I've got to say, it's pretty impressive.\n",
      "Real answer : What ? What does that mean ?\n",
      "Bert Score : {'precision': [0.8294583559036255], 'recall': [0.8170258402824402], 'f1': [0.8231951594352722], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 7.661802377651571\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEDWARD: Ah, yes. Very intense young man named David. He plays polo.\\n\\n', 'answer': \"Look, I gotta say this again. I don't like you going alone, you know.\", 'gold_tag': \"Philip expresses concern for Edward , Philip doesn't like Edward going alone\", 'last_speaker': 'PHILIP'}\n",
      "Last word -> PHILIP : \"Look, I gotta say this again. I don't like you going alone, you know.\"\n",
      "prediction :  Polo?\n",
      "Real answer : Look, I gotta say this again. I don't like you going alone, you know.\n",
      "Bert Score : {'precision': [0.8368781805038452], 'recall': [0.8110477924346924], 'f1': [0.8237605094909668], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1833.763743122814\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPHILIP: Fellas, let's finish this up this afternoon, huh ? Jake, set something up with Blair. Around two o'clock, two- thirty, would be good. You were right about Morse. He mortgaged everything he owns, right down to his underwear, to secure a loan from the bank. And it's not just any bank. Plymouth Trust, huh ?\\nEDWARD: Hmm.\\nPHILIP: So, it goes without saying... that your business means a lot more to them than our friend, Mr. Morse. So, all you gotta do is call the bank.\\nEDWARD: Yeah.\\nPHILIP: Edward, excuse me for saying this, but what the hell is wrong with you this week ? Are you giving Morse a chance to get away ?\\nEDWARD: You know what I used to love when I was a kid, Phil ?\\nPHILIP: What ?\\nEDWARD: Blocks. Building blocks. Erector sets.\\nPHILIP: So, I liked Monopoly. Boardwalk, Park Place. Wh-What's the point ?\\nEDWARD: We don't build anything, Phil. We don't make anything.\\n\\n\", 'answer': \"We make money, Edward. We worked for a year on this deal. It's what you said you wanted. I'm handing it to you. Morse's jugular is exposed. It's time for the kill. Let's finish this. Call the bank !\", 'gold_tag': 'Philip is a pragmatic businessman driven by financial success , Shared memories', 'last_speaker': 'PHILIP'}\n",
      "Last word -> PHILIP : \"We make money, Edward. We worked for a year on this deal. It's what you said you wanted. I'm handing it to you. Morse's jugular is exposed. It's time for the kill. Let's finish this. Call the bank !\"\n",
      "prediction :  We're just a bunch of lawyers.\n",
      "Real answer : We make money, Edward. We worked for a year on this deal. It's what you said you wanted. I'm handing it to you. Morse's jugular is exposed. It's time for the kill. Let's finish this. Call the bank !\n",
      "Bert Score : {'precision': [0.8568418622016907], 'recall': [0.8313947319984436], 'f1': [0.8439264893531799], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0.0006811285730773445 0.0002359498590113703\n",
      "ppl : 24.63270663855487\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPHILIP: Edward, please, what was this all about ? Hmm ?\\n\\n', 'answer': \"It's all yours, Phil. Finish it up.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'EDWARD'}\n",
      "Last word -> EDWARD : \"It's all yours, Phil. Finish it up.\"\n",
      "prediction :  I’m sorry, Philip. I’m so sorry.\n",
      "Real answer : It's all yours, Phil. Finish it up.\n",
      "Bert Score : {'precision': [0.862463653087616], 'recall': [0.8704980611801147], 'f1': [0.8664622902870178], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 31.1223006054905\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAM: What are you doing?\\nMOLLY: I felt inspired.\\nSAM: At 2:00 am? You notice Carl's eyes today? They were all over you.\\nMOLLY: What? Are you jealous? Sam, let me tell you something. He's not even looking at me. It's you he idolizes. He doesn't see me at all... Anyway, he's not my type. What are you doing?\\n\\n\", 'answer': 'I feel inspired.', 'gold_tag': \"SAM is observant , SAM mimics Molly's justification for late-night activities , SAM is creatively inspired at an unusual hour\", 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"I feel inspired.\"\n",
      "prediction :  I'm getting you out of here.\n",
      "Real answer : I feel inspired.\n",
      "Bert Score : {'precision': [0.8719854950904846], 'recall': [0.9085856080055237], 'f1': [0.8899093866348267], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 38.78486266910261\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAM: Molly? Molly!\\nMOLLY: Sam? What's the matter? Is something wrong?\\nSAM: Molly!\\n\\n\", 'answer': 'What is it, honey? What is it, honey?', 'gold_tag': 'Everyday Language', 'last_speaker': 'MOLLY'}\n",
      "Last word -> MOLLY : \"What is it, honey? What is it, honey?\"\n",
      "prediction :  Sam? What's the matter? Is something wrong?\n",
      "Real answer : What is it, honey? What is it, honey?\n",
      "Bert Score : {'precision': [0.8711897730827332], 'recall': [0.85897296667099], 'f1': [0.8650382161140442], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 33.140971627035306\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAM: What's happening to me?!\\nMOLLY: Don't leave me. I need you, Sam.\\n\\n\", 'answer': 'Molly! Molly.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"Molly! Molly.\"\n",
      "prediction :  I can't stay here.\n",
      "Real answer : Molly! Molly.\n",
      "Bert Score : {'precision': [0.8683375120162964], 'recall': [0.873195230960846], 'f1': [0.8707595467567444], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 53.36093450372874\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOLLY: Oh God, Sam... I picked up your shirts this morning. I don't know why. Mr. Reynolds said to tell you hello. I broke into tears. It's so hard... I think about you every minute. It's like you're still here, like I can feel you, Sam.\\nSAM: I am here, Moll. I am.\\n\\n\", 'answer': \"Frank, what's wrong? Frank? Sam?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MOLLY'}\n",
      "Last word -> MOLLY : \"Frank, what's wrong? Frank? Sam?\"\n",
      "prediction :  I know. I know you are, Sam.\n",
      "Real answer : Frank, what's wrong? Frank? Sam?\n",
      "Bert Score : {'precision': [0.8542837500572205], 'recall': [0.8392067551612854], 'f1': [0.8466781377792358], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 87.3813678804711\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAM: \"Singing bye bye, Miss American Pie. Drove my Chevy to the levy, but the levy was dry. Them good ol\\' boys were drinkin\\' whiskey and rye, and singing this\\'ll be the day that I...\" You motherfucking bastard! What the hell are you doing here? What are you doing? Molly, no! Get out!\\n\\n', 'answer': \"Frank, what's wrong?\", 'gold_tag': 'MOLLY is unable to discern what is happening , MOLLY is confused', 'last_speaker': 'MOLLY'}\n",
      "Last word -> MOLLY : \"Frank, what's wrong?\"\n",
      "prediction :  \"SAM: \"You're fucking right, I'm not going anywhere.\n",
      "Real answer : Frank, what's wrong?\n",
      "Bert Score : {'precision': [0.8185862898826599], 'recall': [0.8331248164176941], 'f1': [0.8257915377616882], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 19.02416821554629\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nM.J.: Halloran.\\nHELEN: You betrayed me! Now every psychopath in the city knows I'm back in business... You lied to me!\\nM.J.: I did not; the Mouth -- that's what we call Susan Schiffer -- got it on her own.\\nHELEN: Why should I trust you?\\nM.J.: Because I'm all you've got.\\nHELEN: How could you...\\n\\n\", 'answer': 'I like the real smart Helen Hudson a lot, I\\'m Goddamned sick and tired of the hysterical little girl, Helen. You asked your way in -- I don\\'t forget that. You\\'ve got a nickname around here -- \"Deep Throat\" from all the phone calls, I wonder if you know that. Go take a xanax, I\\'ve got to got to work.', 'gold_tag': 'M.J. advises HELEN to take a Xanax, implying she might be anxiety-prone or have trouble managing her stress , HELEN has been nicknamed \"Deep Throat\" due to her frequent phone calls , M.J. is about to go to work', 'last_speaker': 'M.J.'}\n",
      "Last word -> M.J. : \"I like the real smart Helen Hudson a lot, I'm Goddamned sick and tired of the hysterical little girl, Helen. You asked your way in -- I don't forget that. You've got a nickname around here -- \"Deep Throat\" from all the phone calls, I wonder if you know that. Go take a xanax, I've got to got to work.\"\n",
      "prediction :  I'm sorry. I didn't want to hurt you, but I had to protect myself.\n",
      "Real answer : I like the real smart Helen Hudson a lot, I'm Goddamned sick and tired of the hysterical little girl, Helen. You asked your way in -- I don't forget that. You've got a nickname around here -- \"Deep Throat\" from all the phone calls, I wonder if you know that. Go take a xanax, I've got to got to work.\n",
      "Bert Score : {'precision': [0.8646624088287354], 'recall': [0.8113266229629517], 'f1': [0.8371458649635315], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20512820512820512, 'rouge2': 0.02631578947368421, 'rougeL': 0.1794871794871795, 'rougeLsum': 0.1794871794871795}\n",
      "bleu 1/2 : 0.013362089774013071 0.0019610186535820866\n",
      "ppl : 8.023133327592827\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHELEN: ...\"I\\'ll be back...\"\\nM.J.: Yeah. Addressed to you. \"Don\\'t lose your head.\"\\nHELEN: They put Merry Saks on it?!\\nM.J.: He said to send you his regards and to tell you that the Bureau holds you in the highest esteem.\\nHELEN: What I can\\'t believe is that in an earlier life I slept with him! Christ! Any God that loved his people would give women a rewind on their life and an erase button. Just give me a minute here. The letter is addressed to me... You don\\'t feel fear, do you? You\\'re young. You feel like you\\'ll live forever. How wonderful.\\nM.J.: I put my ass on the line, giving you that.\\nHELEN: They weren\\'t going to show it to me?! The arrogance! It\\'s my life!\\nM.J.: It\\'s also the major piece of evidence, and it makes you a key part of his plan. You can\\'t run away from it anymore. Look at the order he\\'s doing them... He did three as the Boston Strangler just to tell us a copycat serial killer was at work. Then he did one like the Hillside Strang- ler. And then one as Son of Sam. To lead us on -- to where and what end? And he\\'s doing more than that -- he\\'s imitating each killer\\'s method as closely as he can -- in details. Injecting Windex. Using .44. Playing Abba.\\nHELEN: It\\'s not chronological: Son of Sam was before Hillside.\\nM.J.: It\\'s clear he thinks he knows me. He lives a fantasy. \\'Helen, don\\'t lose your head.\\' Is that a threat? Does he want to cut off my head? Dahmer cut off heads. Who else? Kemper. Did Gacy? Rivkind? I think Rivkind did.\\n\\n', 'answer': \"He attacks what he feels he can't have. What he feels excluded from...\", 'gold_tag': 'HELEN reflects on her past', 'last_speaker': 'HELEN'}\n",
      "Last word -> HELEN : \"He attacks what he feels he can't have. What he feels excluded from...\"\n",
      "prediction :  No, I'm sure you're right.\n",
      "Real answer : He attacks what he feels he can't have. What he feels excluded from...\n",
      "Bert Score : {'precision': [0.834012508392334], 'recall': [0.8348628878593445], 'f1': [0.8344374299049377], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 20.67424950908302\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHELEN: '...great dark hall of fame... all our greatest killers...' His greatest heroes? He wants to be famous. When they're caught and people like me write about them, we give them a kind of immortality. They get thousands of letters. Ramirez kills eight women and gets a hundred marriage proposals a\\n\\n\", 'answer': 'They get fan letters...', 'gold_tag': \"M.J. is familiar with HELEN's work\", 'last_speaker': 'M.J.'}\n",
      "Last word -> M.J. : \"They get fan letters...\"\n",
      "prediction :  'You know, I've been thinking...'\n",
      "Real answer : They get fan letters...\n",
      "Bert Score : {'precision': [0.852013111114502], 'recall': [0.8699439764022827], 'f1': [0.8608852028846741], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18.41500474788427\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nM.J.: Do those things really help?\\n\\n', 'answer': 'Not a damn bit...', 'gold_tag': 'Everyday Language', 'last_speaker': 'HELEN'}\n",
      "Last word -> HELEN : \"Not a damn bit...\"\n",
      "prediction :  Absolutely! It's amazing how much of a difference it can make.\n",
      "Real answer : Not a damn bit...\n",
      "Bert Score : {'precision': [0.8503497838973999], 'recall': [0.7928407788276672], 'f1': [0.8205889463424683], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 10.713869487636007\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHARRY: You've done this before.\\n\\n\", 'answer': \"I've had my moments.\", 'gold_tag': 'BILLY has experience in certain unknown activities', 'last_speaker': 'BILLY'}\n",
      "Last word -> BILLY : \"I've had my moments.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : I've had my moments.\n",
      "Bert Score : {'precision': [0.9363813400268555], 'recall': [0.8563988208770752], 'f1': [0.8946059346199036], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBILLY: I'm sure they'll have this place rigged.\\nHARRY: How?\\n\\n\", 'answer': \"It'll be something hokey. Houdini'd been proud of you.\", 'gold_tag': \"BILLY references a specific method , HARRY might have a relation to magic or illusionists, considering Billy's comment about Houdini\", 'last_speaker': 'BILLY'}\n",
      "Last word -> BILLY : \"It'll be something hokey. Houdini'd been proud of you.\"\n",
      "prediction :  With traps.\n",
      "Real answer : It'll be something hokey. Houdini'd been proud of you.\n",
      "Bert Score : {'precision': [0.8856881856918335], 'recall': [0.823917031288147], 'f1': [0.8536866903305054], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1404.292229951408\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBILLY: Whoa... I hear Mrs. Swann's quite a babe.\\nHARRY: You heard right.\\nBILLY: You ever been married?\\nHARRY: Yeah. She was killed in a car crash. Her lawyer was driving. She was filing for divorce.\\nBILLY: Why?\\nHARRY: My life was too weird for her.\\nBILLY: I love weird.\\nHARRY: Billy? This was on Miller's forehead. Any idea what it is?\\nBILLY: Nope. What did I tell you? So fucking hokey.\\nHARRY: What have we got here? Grab the files!\\nBILLY: Jesus! I could have lost my fucking hands.\\nHARRY: That would have kept you out of the Magic Circle. Which was presumably the idea. These are about Nix. You go through these. Go on! Wait a minute... That's Butterfield...\\nBILLY: And who's that?\\nHARRY: At a guess? The Puritan. Nix. A Nix specialty?\\nBILLY: I don't know any of these tricks...\\nHARRY: Maybe they're not tricks.\\nBILLY: I mean, there's no instructions-- What do you mean, they're not tricks?\\nHARRY: What did Vinovich say? Something about walking a path between --\\nBILLY: Trickery and divinity. Yeah, he says that all the time.\\nHARRY: That's because he knew. He'd seen these files and knew.\\nBILLY: Knew what? Harry! Where the fuck are you?\\nHARRY: Okay. Hold it right there.\\nBILLY: Get it off me!\\nHARRY: Hokey enough for you?\\nBILLY: I'm out of here, man! Are you coming?\\n\\n\", 'answer': \"I'm coming. Ah, shaddup!\", 'gold_tag': 'Everyday Language', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"I'm coming. Ah, shaddup!\"\n",
      "prediction :  I'm coming.\n",
      "Real answer : I'm coming. Ah, shaddup!\n",
      "Bert Score : {'precision': [0.9879573583602905], 'recall': [0.8947380781173706], 'f1': [0.9390398859977722], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.7499999999999999, 'rouge2': 0.6666666666666666, 'rougeL': 0.7499999999999999, 'rougeLsum': 0.7499999999999999}\n",
      "bleu 1/2 : 0.36787944117144233 0.36787944117144233\n",
      "ppl : 197.7915705664983\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGALLAGHER: Testing, testing...\\nBURCHENAL: Does it work??\\n\\n', 'answer': \"Well, the little green thing lights up. I don't know if it works... This is Ares ground crew, come back. This is Ares ground crew, do you copy?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'GALLAGHER'}\n",
      "Last word -> GALLAGHER : \"Well, the little green thing lights up. I don't know if it works... This is Ares ground crew, come back. This is Ares ground crew, do you copy?\"\n",
      "prediction :  Yes, it works.\n",
      "Real answer : Well, the little green thing lights up. I don't know if it works... This is Ares ground crew, come back. This is Ares ground crew, do you copy?\n",
      "Bert Score : {'precision': [0.9310331344604492], 'recall': [0.8245415091514587], 'f1': [0.8745574355125427], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.06666666666666667, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 8.012315880650468e-05 3.103156597031248e-05\n",
      "ppl : 120.9509825608781\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGALLAGHER: What the hell was that?\\n\\n', 'answer': \"She ditched the 'B' tank. She must be figuring there's an even chance we'll live through the night.\", 'gold_tag': \"BURCHENAL understands their spaceship's mechanics , BURCHENAL has technical knowledge or a profession related to space travel\", 'last_speaker': 'BURCHENAL'}\n",
      "Last word -> BURCHENAL : \"She ditched the 'B' tank. She must be figuring there's an even chance we'll live through the night.\"\n",
      "prediction :  I don't know, sir. It was a strange sound.\n",
      "Real answer : She ditched the 'B' tank. She must be figuring there's an even chance we'll live through the night.\n",
      "Bert Score : {'precision': [0.8550729751586914], 'recall': [0.849014937877655], 'f1': [0.8520331382751465], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 25.872416583145313\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGALLAGHER: We should get outta here.\\nBURCHENAL: Really. We should get going... Jesus...Jesus God...\\nGALLAGHER: He killed Santen.\\nBURCHENAL: Yep.\\nGALLAGHER: Probably figured we were gonna die anyhow.\\nBURCHENAL: Yep. Figured wrong. For now.\\nGALLAGHER: Nobody deserves to die like that.\\n\\n', 'answer': 'No.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BURCHENAL'}\n",
      "Last word -> BURCHENAL : \"No.\"\n",
      "prediction :  I don't think that's how it works.\n",
      "Real answer : No.\n",
      "Bert Score : {'precision': [0.8313087821006775], 'recall': [0.9324527382850647], 'f1': [0.8789806962013245], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.664546031115135\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGALLAGHER: You know, I don't care if I weigh 60 pounds on Mars. I am one tired doggie.\\nBURCHENAL: Ten K short. The sun is a finger above the horizon. Redder than red, breathtakingly beautiful. It's pretty.\\nGALLAGHER: Too bad we're gonna be dead. I can't keep walking in circles. And there's nothing to keep us warm. It's gonna be like trying to live on Mount Everest.\\nBURCHENAL: What would we do if we were on Mount Everest? Thinks a long time.\\nGALLAGHER: I would have brought a tent.\\nBURCHENAL: If we didn't have a tent.\\nGALLAGHER: We don't have a tent.\\nBURCHENAL: Yeah. Yeah, I know.\\nGALLAGHER: I'd guess you'd dig a snow cave. Use the snow for insulation. You've seen the 3Ds.\\nBURCHENAL: Let's dig a snow cave.\\nGALLAGHER: There's no snow.\\n\\n\", 'answer': \"Let's dig a snow cave or we're gonna fucking die.\", 'gold_tag': 'BURCHENAL suggests they adopt survival strategies', 'last_speaker': 'BURCHENAL'}\n",
      "Last word -> BURCHENAL : \"Let's dig a snow cave or we're gonna fucking die.\"\n",
      "prediction :  What do you think will happen if we don't find shelter?\n",
      "Real answer : Let's dig a snow cave or we're gonna fucking die.\n",
      "Bert Score : {'precision': [0.8419750928878784], 'recall': [0.8541073799133301], 'f1': [0.8479978442192078], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08333333333333333, 'rouge2': 0.0, 'rougeL': 0.08333333333333333, 'rougeLsum': 0.08333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 21.52427146702734\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGALLAGHER: What? Is this some kind of cartoon moment where you're imagining I'm a giant chicken and you're going to eat me?\\nBURCHENAL: It's melting The ice on your forehead is melting. The rock's really insulating us. We might not freeze to death.\\nGALLAGHER: Oh. Good. I've never been this tired. I've never hurt this bad. You think dead is worse than this?\\nBURCHENAL: Hell, we'll probably know soon. Shut up. Rest.\\nGALLAGHER: We oughta probably tell someone we're not frozen solid. Yet.\\n\\n\", 'answer': \"We're on the nightside, can't reach Houston. Bowman's dayside for another forty-five.\", 'gold_tag': 'BURCHENAL reveals that they are currently on the nightside, unable to reach Houston', 'last_speaker': 'BURCHENAL'}\n",
      "Last word -> BURCHENAL : \"We're on the nightside, can't reach Houston. Bowman's dayside for another forty-five.\"\n",
      "prediction :  Shut up.\n",
      "Real answer : We're on the nightside, can't reach Houston. Bowman's dayside for another forty-five.\n",
      "Bert Score : {'precision': [0.8886321187019348], 'recall': [0.8164041638374329], 'f1': [0.8509882688522339], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 298.6848430452561\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBURCHENAL: No, I don't know why the worms are here. No, I don't know why we're still alive.\\nGALLAGHER: There's gotta be a reason. A moment, then -\\nBURCHENAL: You're talking about faith, son. Faith is another way of saying I know something you don't know but I can't tell you 'cause it's a secret. But I don't know why I know it. I live in the real world. I've lived there my whole life. I'm comfortable there.\\nGALLAGHER: We're not in the real world. We're on Mars. Nobody gets in a rocket ship to outer space without some kind of faith. Do they?\\n\\n\", 'answer': \"If you think I'm gonna have some kind of weak-ass epiphany for you right here in this cave, you're wrong. Now, why don't you get that light outta my eyes and let me try to rest.\", 'gold_tag': 'BURCHENAL prefers solitude while resting , BURCHENAL expresses a desire to rest', 'last_speaker': 'BURCHENAL'}\n",
      "Last word -> BURCHENAL : \"If you think I'm gonna have some kind of weak-ass epiphany for you right here in this cave, you're wrong. Now, why don't you get that light outta my eyes and let me try to rest.\"\n",
      "prediction :  Faith?\n",
      "Real answer : If you think I'm gonna have some kind of weak-ass epiphany for you right here in this cave, you're wrong. Now, why don't you get that light outta my eyes and let me try to rest.\n",
      "Bert Score : {'precision': [0.8299651145935059], 'recall': [0.7817906141281128], 'f1': [0.8051579594612122], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 620.0475811421034\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBURCHENAL: Son of a bitch. Son of a bitch. We've been asleep for three hours! Forget it. She's dayside again. If she's even still here. We gotta get to Cosmos. Can't see the landmarks.\\n\\n\", 'answer': 'We gotta keep moving.', 'gold_tag': \"GALLAGHER agrees with BURCHENAL's urgency that they need to continue their journey\", 'last_speaker': 'GALLAGHER'}\n",
      "Last word -> GALLAGHER : \"We gotta keep moving.\"\n",
      "prediction :  You're right, sir.\n",
      "Real answer : We gotta keep moving.\n",
      "Bert Score : {'precision': [0.8521016836166382], 'recall': [0.8620539307594299], 'f1': [0.8570489287376404], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 36.023080249673484\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBESTLER: Oh, stand at ease. And, close the I don't have to tell you why your Commandant was relieved of his command here. This prison is a disgrace. Disgrace! The latitude allowed by him will not be tolerated by me. Understand? That includes the staff. I'm going to turn this place into a model prison, a credit to the Reich. Speak up.\\nSCHARFF: Yes, Colonel.\\nBESTLER: This isn't the first prison the SS has had to take over from the military. Military men are too soft to deal with those...\\nSCHARFF: Yes, sir.\\nBESTLER: You were about to say something?\\nSCHARFF: Oh... I... was just going to say that I didn't hold with the soft treatment of the prisoners.\\nBESTLER: Good! Our first order of business is to prepare... Our first order of business is to prepare all non-Aryan prisoners for shipment in two weeks.\\nSCHARFF: Where are they being sent, Colonel?\\nBESTLER: Work camps.\\nSCHARFF: But we have about 40 children, some only babies, with more scheduled to arrive tomorrow or the next day. They're not going to be much use in a work camp.\\n\\n\", 'answer': \"I'm aware of that. This order covers only the adult prisoners over fifteen. We won't have to wet nurse the children for long. Other plans are being made for... What is that?\", 'gold_tag': 'BESTLER is responsible for implementing new policies at the prison', 'last_speaker': 'BESTLER'}\n",
      "Last word -> BESTLER : \"I'm aware of that. This order covers only the adult prisoners over fifteen. We won't have to wet nurse the children for long. Other plans are being made for... What is that?\"\n",
      "prediction :  They're not going to be much use in a work camp.\n",
      "Real answer : I'm aware of that. This order covers only the adult prisoners over fifteen. We won't have to wet nurse the children for long. Other plans are being made for... What is that?\n",
      "Bert Score : {'precision': [0.8611160516738892], 'recall': [0.8353284597396851], 'f1': [0.8480262756347656], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.04347826086956522, 'rouge2': 0.0, 'rougeL': 0.04347826086956522, 'rougeLsum': 0.04347826086956522}\n",
      "bleu 1/2 : 0.013474096939774558 0.004468852393810814\n",
      "ppl : 33.712405866710995\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBESTLER: What is that supposed to be?\\nSCHARFF: That! Well, you see, sir, one of the prisoners used to be a circus clown. Sometimes he gives a little... well... a sort of show -- for the children.\\nBESTLER: A show! Is this a prison camp or a traveling circus! Am I correct in assuming that those of the camp?\\nSCHARFF: Yes, sir.\\nBESTLER: And the... buffoon? A German?\\nSCHARFF: Yes, Colonel.\\nBESTLER: Am I to believe you aren't aware of the general order absolutely forbidding fraternization?\\nSCHARFF: I know about it, sir.\\nBESTLER: Close the window. Just what do you think fraternization means, Lieutenant Scharff ?\\nSCHARFF: Communication. Social contact. Giving aid, talking...\\nBESTLER: How long has this been going on?\\nSCHARFF: Just the last two or three weeks.\\nBESTLER: And the Commandant approved?\\nSCHARFF: Well, sir, children are very hard to handle.\\nBESTLER: This clown! Who is he?\\nSCHARFF: It's... I know. It's Doork, the Great.\\nBESTLER: Not his clown name, you idiot. His number. His identification.\\nSCHARFF: If I have the Colonel's permission to leave, I will check it at once.\\nBESTLER: Later. Right now I want these performances halted. Understand?\\nSCHARFF: Yes, sir.\\nBESTLER: Immediately!\\n\\n\", 'answer': 'Yes, sir !', 'gold_tag': 'SCHARFF is a subordinate to BESTLER', 'last_speaker': 'SCHARFF'}\n",
      "Last word -> SCHARFF : \"Yes, sir !\"\n",
      "prediction :  Yes, sir.\n",
      "Real answer : Yes, sir !\n",
      "Bert Score : {'precision': [0.9825341701507568], 'recall': [0.9339132308959961], 'f1': [0.9576069116592407], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
      "bleu 1/2 : 0.3032653298563167 0.13562437855552414\n",
      "ppl : 196.4543948165058\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBESTLER: Yes. Yes. Yes, I understand perfectly. However, I don't see how we can be held responsible. Our orders were very clear. We were to have the freight car ready to be picked up at midnight. Of course, I'm aware the operation must be kept secret. I just don't have the staff to send down there now and... Yes, I'll wait. The freight car wasn't picked up.\\nSCHARFF: It's still down there on the siding!\\nBESTLER: Some stupid mix up. If they think... Yes, General. Yes, I'm as distressed about the situation as you are. Yes. Personally! Immediately! Yes, General. You can leave it in my hands. Heil Hitler! Who did you leave in charge down there?\\nSCHARFF: Sergeant Hoffman. Very reliable.\\nBESTLER: Apparently not reliable enough. The cargo seems to be raising quite a fuss.\\nSCHARFF: Fifty children, sir! In a boxcar!\\nBESTLER: I know. I know. But the siding isn't far from town. The General doesn't want unauthorized persons getting curious. Understand?\\nSCHARFF: I'll get some men down there right away.\\nBESTLER: Men! You'll get yourself down there. And take at least a dozen guards with you. Don't let anyone get close to that boxcar... under any circumstances. No one !\\nSCHARFF: Yes, sir. Sir? I wondered, sir, if you might have any suggestions as... well... how do we quiet children?\\nBESTLER: Use any method you can, but shut them up. That's an order.\\nSCHARFF: Sir, the clown! The one who amused the children\\nBESTLER: Out of the question. The man's being disciplined for that very thing. We can't change our position now.\\nSCHARFF: No one need know.\\nBESTLER: He'd know.\\nSCHARFF: Sir, if I could guarantee he'd never say anything. You see, sir, he's been trying to get a review of his case. Claims he's here by mistake. I could tell him you would recommend the review.\\nBESTLER: A man who wants something. Good. Very good strategy, Lieutenant. However, when you bring him back here, return him to solitary and keep him there. I've seen the best of men, after several years in solitary, unable to remember even their own names.\\n\\n\", 'answer': 'Then I have your permission to take the clown.', 'gold_tag': 'SCHARFF has to immediately handle the issue of the children in the boxcar and is tasked with bringing the clown back', 'last_speaker': 'SCHARFF'}\n",
      "Last word -> SCHARFF : \"Then I have your permission to take the clown.\"\n",
      "prediction :  Yes, sir.\n",
      "Real answer : Then I have your permission to take the clown.\n",
      "Bert Score : {'precision': [0.855575442314148], 'recall': [0.8439569473266602], 'f1': [0.8497264981269836], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 196.4543948165058\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVIOLET (V.O.): Hundreds, paper-clipped everywhere Then one by one, he ironed all of it.\\n\\n', 'answer': 'Did he sleep?', 'gold_tag': 'Everyday Language', 'last_speaker': 'CORKY (V.O.)'}\n",
      "Last word -> CORKY (V.O.) : \"Did he sleep?\"\n",
      "prediction : \n",
      "Real answer : Did he sleep?\n",
      "Bert Score : {'precision': [0.0], 'recall': [0.0], 'f1': [0.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : nan\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORKY (V.O.): What sound?\\n\\n', 'answer': 'The sound of money.', 'gold_tag': \"VIOLET V.O.'s information implies a familiarity or interest in money , This possibly indicates a role or experience in financial matters\", 'last_speaker': 'VIOLET (V.O.)'}\n",
      "Last word -> VIOLET (V.O.) : \"The sound of money.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction :  A baby crying.\n",
      "Real answer : The sound of money.\n",
      "Bert Score : {'precision': [0.9068498611450195], 'recall': [0.8848618268966675], 'f1': [0.895720899105072], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 397.27649215448474\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVIOLET (V.O.): Waiting for what?\\n\\n', 'answer': \"For the shower. That will be our signal. When he's done with his shower, you will go to the bar.\", 'gold_tag': 'CORKY V.O. is waiting for someone to finish their shower , VIOLET V.O. is to go to the bar after the shower is done', 'last_speaker': 'CORKY (V.O.)'}\n",
      "Last word -> CORKY (V.O.) : \"For the shower. That will be our signal. When he's done with his shower, you will go to the bar.\"\n",
      "prediction :  For the judge to read the verdict.\n",
      "Real answer : For the shower. That will be our signal. When he's done with his shower, you will go to the bar.\n",
      "Bert Score : {'precision': [0.8709513545036316], 'recall': [0.8502010703086853], 'f1': [0.8604511022567749], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2857142857142857, 'rouge2': 0.07692307692307691, 'rougeL': 0.2857142857142857, 'rougeLsum': 0.2857142857142857}\n",
      "bleu 1/2 : 0.08921031160912632 0.04817907476357602\n",
      "ppl : 77.97178917659039\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORKY (V.O.): When you open the door, I'll be there.\\nVIOLET (V.O.): What if he sees you?\\n\\n\", 'answer': \"He won't.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'CORKY (V.O.)'}\n",
      "Last word -> CORKY (V.O.) : \"He won't.\"\n",
      "prediction :  He won't.\n",
      "Real answer : He won't.\n",
      "Bert Score : {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
      "bleu 1/2 : 1.0 1.0\n",
      "ppl : 203.93629678339767\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEAZY: I feel like I don't know what I'm doin' anymore. I don't even know where the money's going.\\nTOMICA: I can help, you know. Show me the files, the bills, the contracts. I know the business, I know how it all works. Let me look. Baby, if you're feelin' this way, Jerry's not doin' right by you.\\n\\n\", 'answer': \"Okay. After New York. Workin' on that International Distribution with Sony. Jerry don't know about that. I wanna keep it that way.\", 'gold_tag': 'EAZY is working on an international distribution with Sony , EAZY has a forthcoming work trip to New York related to a deal with Sony', 'last_speaker': 'EAZY'}\n",
      "Last word -> EAZY : \"Okay. After New York. Workin' on that International Distribution with Sony. Jerry don't know about that. I wanna keep it that way.\"\n",
      "prediction :  I don't know. I just feel like I'm lost in all this.\n",
      "Real answer : Okay. After New York. Workin' on that International Distribution with Sony. Jerry don't know about that. I wanna keep it that way.\n",
      "Bert Score : {'precision': [0.874252200126648], 'recall': [0.8589352369308472], 'f1': [0.8665260076522827], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2162162162162162, 'rouge2': 0.1142857142857143, 'rougeL': 0.2162162162162162, 'rougeLsum': 0.2162162162162162}\n",
      "bleu 1/2 : 0.07243303475117972 0.0169167123228625\n",
      "ppl : 11.565854442188195\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOMICA: You had to know the truth sometime. Now you do.\\n\\n', 'answer': \"Cube tried to warn me. So did Dre. And I didn't listen. I fucked up.\", 'gold_tag': 'EAZY ignored the warning from Cube and Dre , EAZY acknowledges his mistake , EAZY and TOMICA have a shared past where EAZY ignored warnings from Cube and Dre', 'last_speaker': 'EAZY'}\n",
      "Last word -> EAZY : \"Cube tried to warn me. So did Dre. And I didn't listen. I fucked up.\"\n",
      "prediction :  You think I'm gonna start crying and shit?\n",
      "Real answer : Cube tried to warn me. So did Dre. And I didn't listen. I fucked up.\n",
      "Bert Score : {'precision': [0.8274643421173096], 'recall': [0.8710333108901978], 'f1': [0.8486900329589844], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 17.45969757670454\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEAZY: Just glad you're okay. You and the baby.\\nTOMICA: No. We can beat this. Together.\\nEAZY: Yo. Eazy! What the fuck, cuz? People been sayin' some crazy shit. Like you got AIDS or somethin'? Can you believe that? Muthafuckin' Eazy-E got AIDS? Niggas be starting too many rumors, huh?\\n\\n\", 'answer': 'Who was that?', 'gold_tag': 'Everyday Language', 'last_speaker': 'TOMICA'}\n",
      "Last word -> TOMICA : \"Who was that?\"\n",
      "prediction :  Yeah, it's crazy. I can't even go outside without gettin' bombarded with questions. I'm tired of it, man. I don't even know how I got it. I don't even remember how I got it.\n",
      "Real answer : Who was that?\n",
      "Bert Score : {'precision': [0.8065917491912842], 'recall': [0.8248560428619385], 'f1': [0.8156216740608215], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5.41285269716429\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBALIAN: Brace it, brace it. Almaric, tell them to brace it!\\nSIBYLLA: I am on my way to Cana. That is where Jesus changed water to wine. A better trick would to be to change you to a nobleman.\\nBALIAN: In France I used to think that with a few yards of silk I could make an aristocrat of any man, so long as he was useless.\\nSIBYLLA: It seems that I ask your hospitality.\\n\\n', 'answer': 'It is given.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BALIAN'}\n",
      "Last word -> BALIAN : \"It is given.\"\n",
      "prediction :  No. It is no longer possible for you to come to Cana.\n",
      "Real answer : It is given.\n",
      "Bert Score : {'precision': [0.8576383590698242], 'recall': [0.8701375722885132], 'f1': [0.863842785358429], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.26666666666666666, 'rouge2': 0.15384615384615385, 'rougeL': 0.26666666666666666, 'rougeLsum': 0.26666666666666666}\n",
      "bleu 1/2 : 0.16666666666666669 0.12309149097933275\n",
      "ppl : 49.11391467710328\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSIBYLLA: I could stay here...perhaps not forever... but a little while longer.\\nBALIAN: This house is yours.\\nSIBYLLA: Why am I here?\\nBALIAN: I know that Ibelin is not on the way to Cana. Sibylla smiles. Her eyes luminous.\\nSIBYLLA: What else do you know, my lord?\\nBALIAN: I know that your are a princess and that I am no lord. Nor do I wish to be.\\nSIBYLLA: You are a knight.\\nBALIAN: Not proved.\\n\\n', 'answer': 'I do not stay on here with you because I am bored, or wicked. I am here because... in the East... one may decide......because in the East between one person and another there is only light.', 'gold_tag': 'SIBYLLA is in the East by choice, indicating a sense of personal agency and independence', 'last_speaker': 'SIBYLLA'}\n",
      "Last word -> SIBYLLA : \"I do not stay on here with you because I am bored, or wicked. I am here because... in the East... one may decide......because in the East between one person and another there is only light.\"\n",
      "prediction :  It is not proven that you are not.\n",
      "Real answer : I do not stay on here with you because I am bored, or wicked. I am here because... in the East... one may decide......because in the East between one person and another there is only light.\n",
      "Bert Score : {'precision': [0.8621431589126587], 'recall': [0.827468991279602], 'f1': [0.8444502949714661], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.08888888888888889, 'rougeLsum': 0.08888888888888889}\n",
      "bleu 1/2 : 0.011324018783369437 0.0022102221513521595\n",
      "ppl : 74.59462564869294\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSIBYLLA: This is from France, which I have not seen...I have never been to France...This for my brother...This to remind us of death...This I bought the day I saw you...\\nBALIAN: You lie.\\n\\n', 'answer': 'But I’m hungry.', 'gold_tag': 'SIBYLLA has a sense of humor, transitioning from serious remembrance to playful banter about being hungry', 'last_speaker': 'SIBYLLA'}\n",
      "Last word -> SIBYLLA : \"But I’m hungry.\"\n",
      "prediction :  No.\n",
      "Real answer : But I’m hungry.\n",
      "Bert Score : {'precision': [0.9391852617263794], 'recall': [0.8601650595664978], 'f1': [0.8979400992393494], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1275.3241709894667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSIBYLLA: We cannot meet in the city.\\nBALIAN: Then we will leave it.\\nSIBYLLA: Balian...My brother is dying. My son will be King and I his regent. I must rule for my son. Not just in Jerusalem, but Acre, Ascalon, Beirut...\\n\\n', 'answer': 'And Guy?', 'gold_tag': 'Everyday Language', 'last_speaker': 'BALIAN'}\n",
      "Last word -> BALIAN : \"And Guy?\"\n",
      "prediction :  I have a son, too. I will not leave him behind.\n",
      "Real answer : And Guy?\n",
      "Bert Score : {'precision': [0.8455042839050293], 'recall': [0.8244268894195557], 'f1': [0.8348325490951538], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 30.64680775245636\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSIBYLLA: I see a man who could be great, unless he chooses to be “good”. If you do not join with me, I am left with Guy.\\nBALIAN: You would see your husband dead.\\nSIBYLLA: For Jerusalem. For my son. For love.\\nBALIAN: What kind of “love” is that?\\nSIBYLLA: Who are you to refuse a king? You refuse my son.\\nBALIAN: I refuse to do murder. Especially of a man who stands between me and what I want. And Jerusalem. Look into your heart. Do you have any idea of Jerusalem except that it is yours?\\nSIBYLLA: honest answer) It is mine. My grandfather took Jerusalem in blood. I will keep it in the same way, or any way I can, for my family, for my son. I am what I am. I offer you that, and the world...you say no.\\nBALIAN: Do you think I am Guy? That I would sell my sould for “the world”, or even you? Do you think that I am a...thing...that can be used?\\n\\n', 'answer': 'I think you are a man. And I think there will be a day when you wish you had done a little evil, to do a greater good.', 'gold_tag': 'SIBYLLA is willing to do evil for the greater good', 'last_speaker': 'SIBYLLA'}\n",
      "Last word -> SIBYLLA : \"I think you are a man. And I think there will be a day when you wish you had done a little evil, to do a greater good.\"\n",
      "prediction :  (coldly) I know you are not Guy.\n",
      "Real answer : I think you are a man. And I think there will be a day when you wish you had done a little evil, to do a greater good.\n",
      "Bert Score : {'precision': [0.8562761545181274], 'recall': [0.8491201400756836], 'f1': [0.8526831269264221], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17142857142857143, 'rouge2': 0.06060606060606061, 'rougeL': 0.17142857142857143, 'rougeLsum': 0.17142857142857143}\n",
      "bleu 1/2 : 0.02133731501479883 0.013306153723174095\n",
      "ppl : 138.83500171659864\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSIBYLLA: I am still the Queen of Acre, of Tripolis, of Ascalon.\\nBALIAN: And I am still a knight. And that is all.\\nSIBYLLA: What shall I decide?\\n\\n', 'answer': 'It is simple. Decide not to be a Queen and I will come to you.', 'gold_tag': 'BALIAN asks SIBYLLA to renounce her queenship', 'last_speaker': 'BALIAN'}\n",
      "Last word -> BALIAN : \"It is simple. Decide not to be a Queen and I will come to you.\"\n",
      "prediction :  You are not in a position to decide anything.\n",
      "Real answer : It is simple. Decide not to be a Queen and I will come to you.\n",
      "Bert Score : {'precision': [0.881940484046936], 'recall': [0.8709989786148071], 'f1': [0.8764356374740601], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4166666666666667, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0.17113903967753066 0.03314093252785034\n",
      "ppl : 41.07498362611068\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALVY: Boy, those guys in the French Resistance were really brave, you know? Got to listen to Maurice Chevalier sing so much.\\nANNIE: M'm, I don't know, sometimes I ask myself how I'd stand up under torture.\\nALVY: You? You kiddin'? the bed to touch, Annie, who makes a If the Gestapo would take away your Bloomingdale's charge card, you'd tell 'em everything.\\nANNIE: That movie makes me feel guilty.\\nALVY: Yeah, 'cause it's supposed to.\\nANNIE: Alvy, I ...\\nALVY: What-what-what-what's the matter?\\nANNIE: I-you know, I don't wanna.\\nALVY: What-what-I don't ... It's not natural! We're sleeping in a bed together. You know, it's been a long time.\\nANNIE: I know, well, it's just that-you know, I mean, I-I-I-I gotta sing tomorrow night, so I have to rest my voice.\\nALVY: It's always some kind of an excuse. It's- You know, you used to think that I was very sexy. What ... When we first started going out, we had sex constantly ... We're- we're probably listed in the Guinness Book of World Records.\\nANNIE: I know. Well, Alvy, it'll pass, it'll pass, it's just that I'm going through a phase, that's all.\\nALVY: M'm.\\n\\n\", 'answer': \"I mean, you've been married before, you know how things can get. You were very hot for Allison at first.\", 'gold_tag': \"ANNIE is aware of Alvy's past marriage to Allison , Shared memories\", 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"I mean, you've been married before, you know how things can get. You were very hot for Allison at first.\"\n",
      "prediction :  Alvy, I'm sorry.\n",
      "Real answer : I mean, you've been married before, you know how things can get. You were very hot for Allison at first.\n",
      "Bert Score : {'precision': [0.8519650101661682], 'recall': [0.8414702415466309], 'f1': [0.8466851711273193], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 116.50354429886794\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: Alvy, now don't panic. Please.\\nALVY: Look, I told you it was a ... mistake to ever bring a live thing in the house.\\nANNIE: Stop it! Don't ... don't do that! There.\\nALVY: Well, maybe we should just call the police. Dial nine-one-one, it's the lobster squad.\\nANNIE: Come on, Alvy, they're only baby ones, for God's sake.\\nALVY: If they're only babies, then you pick 'em up.\\nANNIE: Oh, all right. All right! It's all right. Here.\\nALVY: Don't give it to me. Don't!\\nANNIE: Oooh! Here! Here!\\nALVY: Look! Look, one crawled behind the refrigerator. It'll turn up in our bed at night. Will you get outta here with that thing? Jesus!\\nANNIE: Get him!\\nALVY: Talk to him. You speak shellfish! Hey, look ... put it in the pot.\\nANNIE: I can't! I can't put him in the pot. I can't put a live thing in hot water.\\nALVY: Gimme! Gimme! Let me do it! What-what's he think we're gonna do, take him to the movies?\\nANNIE: Oh, God! Here yuh go! Oh, good, now he'll think- Aaaah! Okay.\\nALVY: Okay, it's in. It's definitely in the pot!\\nANNIE: All right. All right. All right.\\nALVY: Annie, there's a big lobster behind the refrigerator. I can't get it out. This thing's heavy. Maybe if I put a little dish of butter sauce here with a nutcracker, it will run out the other side, you know what I mean?\\nANNIE: Yeah. I'm gonna get my ... I'm gonna get my camera.\\nALVY: You know, I-I think ... if I could pry this door off ... We shoulda gotten steaks 'cause they don't have legs. They don't run around.\\nANNIE: Great! Great! Goddammit! Ooooh! These are ... p-p-p-pick this lobster up. Hold it, please!\\nALVY: All right! All right! All right! All right! Whatta yuh mean? Are yuh gonna take pictures now?\\nANNIE: It'll make great- Alvy, be- Alvy, it'll be wonderful ... Ooooh, lovely!\\nALVY: All right, here! Oh, God, it's disgusting!\\n\\n\", 'answer': \"Don't be a jerk. One more, Alvy, please, one more picture. Oh, oh, good, good!\", 'gold_tag': 'ANNIE is enthusiastic about taking pictures', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"Don't be a jerk. One more, Alvy, please, one more picture. Oh, oh, good, good!\"\n",
      "prediction :  Don't you think it's lovely?\n",
      "Real answer : Don't be a jerk. One more, Alvy, please, one more picture. Oh, oh, good, good!\n",
      "Bert Score : {'precision': [0.8177385330200195], 'recall': [0.844581127166748], 'f1': [0.8309431076049805], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17391304347826086, 'rouge2': 0.09523809523809522, 'rougeL': 0.17391304347826086, 'rougeLsum': 0.17391304347826086}\n",
      "bleu 1/2 : 0.027067056647322542 0.009569649651041096\n",
      "ppl : 18.467924449363895\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALVY: So, so-well, here's what I wanna know. W-what ... Am I your first big romance?\\nANNIE: Oh ... no, no, no, no, uh, uh. No.\\nALVY: Well, then, w-who was?\\n\\n\", 'answer': \"Oh, well, let's see, there was Dennis, from Chippewa Falls High School.\", 'gold_tag': \"One of ANNIE's previous romantic relationships was with someone named Dennis from Chippewa Falls High School\", 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"Oh, well, let's see, there was Dennis, from Chippewa Falls High School.\"\n",
      "prediction :  Well, I've had a few little things. But, uh, they never lasted very long.\n",
      "Real answer : Oh, well, let's see, there was Dennis, from Chippewa Falls High School.\n",
      "Bert Score : {'precision': [0.8634365797042847], 'recall': [0.8321779370307922], 'f1': [0.8475190997123718], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07142857142857144, 'rouge2': 0.0, 'rougeL': 0.07142857142857144, 'rougeLsum': 0.07142857142857144}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.33706628421492\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: He was creepy.\\nALVY: Yeah, I-I think you\\'re pretty lucky I came along.\\nANNIE: Oh, really? Well, la-de-da!\\nALVY: La-de-da. If I-if anyone had ever told me that I would be taking out a girl who used expressions like \"la-de-da\" . . .\\nANNIE: Oh, that\\'s right. That you really like those New York girls.\\nALVY: Well, no ... not just, not only.\\n\\n', 'answer': \"Oh, I'd say so. You married-\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"Oh, I'd say so. You married-\"\n",
      "prediction :  It's just that I've seen those kind of girls before, and they're not the kind that I like.\n",
      "Real answer : Oh, I'd say so. You married-\n",
      "Bert Score : {'precision': [0.8325517177581787], 'recall': [0.8135505318641663], 'f1': [0.8229414820671082], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07142857142857142, 'rouge2': 0.0, 'rougeL': 0.07142857142857142, 'rougeLsum': 0.07142857142857142}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.126059302620337\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: Hi. Hi, hi.\\nALVY: Hi. Oh, hi. Hi.\\nANNIE: Well, bye. She laughs and backs up slowly\\nALVY: You-you play ... very well.\\nANNIE: Oh, yeah? So do you. Oh, God, whatta- whatta dumb thing to say, right? I mean, you say it, \"You play well,\" and right away ... I have to say well. Oh, oh ... God, Annie. Well ... oh, well ... la-de-da, la-de-da, la-la.\\nALVY: Uh ... you-you wanna lift?\\nANNIE: Oh, why-uh ... y-y-you gotta car?\\nALVY: No, um ... I was gonna take a cab.\\nANNIE: Oh, no, I have a car.\\nALVY: You have a car? So ... I don\\'t understand why ... if you have a car, so then-then wh-why did you say \"Do you have a car?\"... like you wanted a lift?\\nANNIE: I don\\'t ... I don\\'t ... Geez, I don\\'t know, I\\'ve ... I wa- This ... yeah, I got this VW out there ... What a jerk, yeah. Would you like a lift?\\nALVY: Sure. W-w-w-which way yuh goin\\'?\\nANNIE: Me? Oh, downtown!\\nALVY: Down- I\\'m-I\\'m goin\\' uptown.\\nANNIE: Oh, well, I\\'m goin\\' uptown, too.\\nALVY: Uh, well, you just said you were going downtown.\\nANNIE: Yeah, well, I\\'m, but I ...\\nALVY: So sorry.\\nANNIE: I mean, I can go uptown, too. I live uptown, but ... uh, what the hell, I mean, it\\'d be nice having company, you know I mean, I hate driving alone.\\n\\n', 'answer': 'Yeah.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ALVY'}\n",
      "Last word -> ALVY : \"Yeah.\"\n",
      "prediction :  I know what you mean. I hate it, too.\n",
      "Real answer : Yeah.\n",
      "Bert Score : {'precision': [0.8506739139556885], 'recall': [0.9200698137283325], 'f1': [0.8840120434761047], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 32.18835766803505\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALVY: So, how long do you know Janet? Where do you know her from?\\nANNIE: Oh, I'm in her acting class.\\nALVY: Oh - you're an actress.\\nANNIE: Well, I do commercials, sort of ...\\nALVY: I, uh ... well, you're not from New York, right?\\nANNIE: No, Chippewa Falls.\\nALVY: Right! Where?\\nANNIE: Wisconsin.\\nALVY: Uh, you're driving a-\\nANNIE: Uh, don't worry, I'm a very- almost on top of it in the wrong the very last minute) -a very good driver. So, listen-hey, you want some gum, anyway?\\nALVY: No, no thanks. Hey, don't-\\nANNIE: Well, where is it? I-\\nALVY: No, no, no, no, you just ... just watch the road. I'll get it-\\nANNIE: Okay.\\nALVY: -for yuh.\\nANNIE: Okay, that's good. All right.\\nALVY: I'll getcha a piece.\\nANNIE: Yeah ... so, listen-you drive?\\nALVY: Do I drive? Uh, no, I gotta-I gotta problem with driving.\\nANNIE: Oh, you do?\\nALVY: Yeah. I got, uh, I got a license but I have too much hostility.\\nANNIE: Oh, right.\\nALVY: Nice car.\\nANNIE: Huh?\\nALVY: You keep it nice. Can I ask you, is this-is this a sandwich?\\n\\n\", 'answer': 'Huh? Oh, yeah.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"Huh? Oh, yeah.\"\n",
      "prediction :  Uh, yeah, sure.\n",
      "Real answer : Huh? Oh, yeah.\n",
      "Bert Score : {'precision': [0.8905458450317383], 'recall': [0.8927271962165833], 'f1': [0.8916352391242981], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.0, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 54.68084586701279\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: I live over here. Oh, my God! Look! There's a parking space!\\nALVY: That's okay, you ... we-we can walk to the curb from here.\\nANNIE: Don't be funny.\\nALVY: You want your tennis stuff?\\nANNIE: Huh? Oh ... yeah.\\nALVY: You want your gear? Here you go.\\nANNIE: Yeah, thanks. Thanks a lot. Well...\\nALVY: Well, thanks, thank you. You-you're a wonderful tennis player.\\nANNIE: Oh.\\nALVY: You're the worst driver I've ever seen in my life . . . that's including any place ... the worst ... Europe, United ... any place ... Asia.\\nANNIE: Yeah.\\nALVY: And I love what you're wearin'.\\nANNIE: Oh, you do? Yeah? Oh, well, it's uh ... this is, uh ... this tie is a present, from Grammy Hall.\\nALVY: Who? Grammy? Grammy Hall?\\nANNIE: Yeah, my grammy.\\nALVY: You're jo- Whatta yuh kid- What did you do, grow up in a Norman Rockwell painting?\\nANNIE: Yeah, I know.\\nALVY: Your grammy!\\nANNIE: I know, it's pretty silly, isn't it?\\nALVY: Jesus, my-my grammy ... n-never gave gifts, you know. She-she was too busy getting raped by Cossacks.\\nANNIE: Well ...\\nALVY: Well ... thank you again.\\nANNIE: Oh, yeah, yeah.\\nALVY: I'll see yuh.\\nANNIE: Hey, well, listen ... hey, you wanna come upstairs and, uh ... and have a glass of wine and something? Aw, no, I mean ... I mean, you don't have to, you're probably late and everything else ...\\nALVY: No, no, that'll be fine. I don't mind. Sure.\\nANNIE: You sure?\\nALVY: No, I got time.\\nANNIE: Okay.\\nALVY: Sure, I got ... I got nothing, uh, nothing till my analyst's appointment.\\nANNIE: Oh, you see an analyst?\\nALVY: Y-y-yeah, just for fifteen years.\\nANNIE: Fifteen years?\\nALVY: Yeah, uh, I'm gonna give him one more year and then I'm goin' to Lourdes.\\n\\n\", 'answer': \"Fifteen-aw, come on, you're . . . yeah, really?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"Fifteen-aw, come on, you're . . . yeah, really?\"\n",
      "prediction :  I was thinking of goin' to Lourdes myself.\n",
      "Real answer : Fifteen-aw, come on, you're . . . yeah, really?\n",
      "Bert Score : {'precision': [0.8290095329284668], 'recall': [0.7804943323135376], 'f1': [0.8040207624435425], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 69.45888911427826\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALVY: Sylvia Plath.\\nANNIE: M\\'hm...\\nALVY: Interesting poetess whose tragic suicide was misinterpreted as romantic, by the college-girl mentality.\\nANNIE: Oh, yeah.\\nALVY: Oh, sorry.\\nANNIE: Right. Well, I don\\'t know, I mean, uh, some of her poems seem - neat, you know.\\nALVY: Neat?\\nANNIE: Neat, yeah.\\nALVY: Uh, I hate to tell yuh, this is nineteen seventy-five, you know that \"neat\" went out, I would say, at the turn of the century.\\nANNIE: Oh ... oh, well, you see now now, uh, that\\'s my dad, that\\'s Father-and that\\'s my ... brother, Duane.\\nALVY: Duane?\\nANNIE: Yeah, right, Duane-and over there is Grammy Hall, and that\\'s Sadie.\\nALVY: Well, who\\'s Sadie?\\nANNIE: Sadie? Oh, well, Sadie... Sadie met Grammy through, uh, through Grammy\\'s brother George. Uh, George was real sweet, you know, he had that thing. What is that thing where you, uh, where you, uh, fall asleep in the middle of a sentence, you know-what is it? Uh ... Narcolepsy, right, right. Right. So, anyway, so ... George, uh, went to the union, see, to get his free turkey, be-because, uh, the union always gave George this big turkey at Christmas time because he was ... shell-shocked, you know what I mean, in the First World War. Anyway, so, so ... George is standing in line, oh, just a sec ...uh, getting his free turkey, but the thing is, he falls asleep and he never wakes up. So, so... so, he\\'s dead ... he\\'s dead. Yeah. Oh, dear. Well, terrible, huh, wouldn\\'t you say? I mean, that\\'s pretty unfortunate.\\nALVY: Yeah, it\\'s a great story, though, I mean, I... I ... it really made my day. Hey, I think I should get outta here, you know, \\'cause I think I\\'m imposing, you know ...\\nANNIE: Oh, really? Oh, well ... uh, uh, maybe, uh, maybe, we, uh ...\\nALVY: ... and ... uh, yeah, uh ... uh, you know, I-I-I...\\nANNIE: Well, I mean, you don\\'t have to, you know.\\nALVY: No, I know, but ... but, you know, I\\'m all perspired and everything.\\nANNIE: Well, didn\\'t you take, uh ... uh, a shower at the club?\\nALVY: Me? No, no, no, \\'cause I never shower in a public place.\\nANNIE: Why not?\\nALVY: \\'Cause I don\\'t like to get naked in front of another man, you know-it\\'s, uh ...\\nANNIE: Oh, I see, I see.\\nALVY: You know, I don\\'t like to show my body to a man of my gender-\\nANNIE: Yeah. Oh, yeah. Yeah, I see. I guess-\\nALVY: -\\'cause, uh, you never know what\\'s gonna happen.\\nANNIE: Fifteen years, huh?\\nALVY: Fifteen years, yeah.\\nANNIE: Yeah. Oh, God bless!\\nALVY: God bless.\\nANNIE: Well, uh ... You\\'re what Grammy Hall would call a real Jew.\\nALVY: Oh, thank you.\\nANNIE: Yeah, well ... you-She hates Jews. She thinks that they just make money, but let me tell yuh, I mean, she\\'s the one yeah, is she ever. I\\'m tellin\\' yuh.\\nALVY: So, did you do shoot the photographs in there or what?\\nANNIE: Yeah, yeah, I sorta dabble around, you know.\\nALVY: They\\'re ... they\\'re... they\\'re wonderful, you know. They have ... they have, uh ... a ... a quality.\\nANNIE: Well, I-I-I would-I would like to take a serious photography course soon.\\nALVY: Photography\\'s interesting, \\'cause, you know, it\\'s-it\\'s a new art form, and a, uh, a set of aesthetic criteria have not emerged yet.\\nANNIE: Aesthetic criteria? You mean, whether it\\'s, uh, good photo or not?\\nALVY: The-the medium enters in as a condition of the art form itself. That\\'s-\\nANNIE: Well, well, I ... to me-I ... I mean, it\\'s-it\\'s-it\\'s all instinctive, you know. I mean, I just try to uh, feel it, you know? I try to get a sense of it and not think about it so much.\\nALVY: Still, still we- You need a set of aesthetic guide lines to put it in social perspective, I think.\\nANNIE: Well, I don\\'t know. I mean, I guess-I guess you must be sorta late, huh?\\nALVY: You know, I gotta get there and begin whining soon ... otherwise I- Hey ... well, are you busy Friday night?\\nANNIE: Me? Oh, uh. No.\\nALVY: Oh, I\\'m sorry, wait a minute, I have something. Well, what about Saturday night?\\nANNIE: Oh ... nothing. Not-no, no!\\nALVY: Oh, you ... you\\'re very popular, I can see.\\nANNIE: I know.\\nALVY: Gee, boy, what do you have? You have plague?\\nANNIE: Well, I mean, I meet a lot of ... jerks, you know-\\nALVY: Yeah, I meet a lotta jerks, too.\\nANNIE: -what I mean?\\nALVY: I think that\\'s, uh-\\nANNIE: But I\\'m thinking about getting some cats, you know, and then they ... Oh, wait a second-oh, no, no, I mean oh, shoot! No, Saturday night I\\'m gonna- gonna sing. Yeah.\\nALVY: You\\'re gonna sing? Do you sing? Well, no, it isn\\'t No kidding? -this is my first time. Oh, really? Where? I\\'d like to come. Oh, no, no, no, no, no! No, I\\'m interested!\\nANNIE: Oh, no-I mean, I\\'m just a-auditioning sort of at club. I don\\'t-\\nALVY: No, so help me.\\nANNIE: -it\\'s my first time.\\nALVY: That\\'s okay, \\'cause I know exactly what that\\'s like. Listen-\\nANNIE: Yeah.\\n\\n', 'answer': \"-you're gonna like night clubs, they're really a lotta fun.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ALVY'}\n",
      "Last word -> ALVY : \"-you're gonna like night clubs, they're really a lotta fun.\"\n",
      "prediction :  You know, I think I'm in love with you.\n",
      "Real answer : -you're gonna like night clubs, they're really a lotta fun.\n",
      "Bert Score : {'precision': [0.8728171586990356], 'recall': [0.8599236011505127], 'f1': [0.86632239818573], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0909090909090909, 'rouge2': 0.0, 'rougeL': 0.0909090909090909, 'rougeLsum': 0.0909090909090909}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 9.02893954063387\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: I was awful. I'm so ashamed! I can't sing.\\nALVY: Oh, listen, so the audience was a tad restless.\\nANNIE: Whatta you mean, a tad restless? Oh, my God, I mean, they hated me.\\nALVY: No, they didn't. You have a wonderful voice.\\nANNIE: No, I'm gonna quit!\\nALVY: No, I'm not gonna letcha. You have a great voice.\\nANNIE: Really, do you think so, really?\\nALVY: Yeah!\\nANNIE: Yeah?\\nALVY: It's terrific.\\nANNIE: Yeah, you know something? I never even took a lesson, either.\\nALVY: Hey, listen, listen.\\nANNIE: What?\\nALVY: Gimme a kiss.\\nANNIE: Really?\\nALVY: Yeah, why not, because we're just gonna go home later, right?\\nANNIE: Yeah.\\nALVY: And-and uh, there's gonna be all that tension. You know, we never kissed before and I'll never know when to make the right move or anything. So we'll kiss now we'll get it over with and then we'll go eat. Okay?\\nANNIE: Oh, all right.\\nALVY: And we'll digest our food better.\\nANNIE: Okay.\\nALVY: Okay?\\nANNIE: Yeah.\\nALVY: So now we can digest our food.\\nANNIE: We can digest our-\\n\\n\", 'answer': 'Okay. Yeah.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ALVY'}\n",
      "Last word -> ALVY : \"Okay. Yeah.\"\n",
      "prediction :  No, no, no. You can digest your food.\n",
      "Real answer : Okay. Yeah.\n",
      "Bert Score : {'precision': [0.8358789682388306], 'recall': [0.9171556234359741], 'f1': [0.8746331334114075], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 59.950756626310636\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALVY: I'm gonna have a corned beef.\\nANNIE: Yeah ... oh, uh, and I'm gonna have a pastrami on white bread with, uh, mayonnaise and tomatoes and lettuce. Tsch, so, uh, your second wife left you and, uh, were you depressed about that?\\nALVY: Nothing that a few mega-vitamins couldn't cure.\\nANNIE: Oh. And your first wife was Allison?\\nALVY: My first... Yes, she was nice, but you know, uh, it was my fault. I was just... I was too crazy.\\n\\n\", 'answer': 'Oh.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"Oh.\"\n",
      "prediction :  How is that?\n",
      "Real answer : Oh.\n",
      "Bert Score : {'precision': [0.8076550960540771], 'recall': [0.9219467043876648], 'f1': [0.8610246777534485], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 313.4245288435682\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: M\\'m, that was so nice. That was nice.\\nALVY: As Balzac said ...\\nANNIE: H\\'m?\\nALVY: \"There goes another novel.\" Jesus, you were great.\\nANNIE: Oh, yeah?\\nALVY: Yeah.\\nANNIE: Yeah?\\nALVY: Yeah, I\\'m-I\\'m-I\\'m a wreck.\\nANNIE: No. You\\'re a wreck.\\nALVY: Really. I mean it. I-I\\'ll never play the piano again.\\nANNIE: You\\'re really nuts. I don\\'t know, you really thought it was good? Tell me.\\nALVY: Good? I was-\\nANNIE: No.\\nALVY: No, that was the most fun I\\'ve ever had without laughing.\\nANNIE: Here, you want some?\\nALVY: No, no, I-I-i, uh, I don\\'t use any major hallucinogenics because I took a puff like five years ago at a party and\\nANNIE: Yeah?\\nALVY: -tried to take my pants off over my head ... ... my ear.\\nANNIE: Oh, I don\\'t know, I don\\'t really. I don\\'t do it very often, you know, just sort of, er ... relaxes me at first.\\nALVY: M\\'hm. You\\'re not gonna believe this, but-\\n\\n', 'answer': 'What? What?', 'gold_tag': 'Everyday Language', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"What? What?\"\n",
      "prediction :  What?\n",
      "Real answer : What? What?\n",
      "Bert Score : {'precision': [0.9065893888473511], 'recall': [0.886367917060852], 'f1': [0.8963646292686462], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.6666666666666666, 'rouge2': 0.0, 'rougeL': 0.6666666666666666, 'rougeLsum': 0.6666666666666666}\n",
      "bleu 1/2 : 0.36787944117144233 0.11633369384516798\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALVY: Hey?\\nANNIE: H'm?\\nALVY: I-I-I'm gonna buy you these books, I think, because I-I think you should read them. You know, instead of that cat book.\\nANNIE: That's, uh ... that's pretty serious stuff there.\\nALVY: Yeah, 'cause I-I'm, you know, I'm, I'm obsessed with-with, uh, with death, I think. Big-\\nANNIE: Yeah?\\nALVY: -big subject with me, yeah.\\nANNIE: Yeah?\\nALVY: I've a very pessimistic view of life. You should know this about me if we're gonna go out, you know. I-I-I feel that life is-is divided up into the horrible and the miserable.\\nANNIE: M'hm.\\nALVY: Those are the two categories ...\\nANNIE: M'hm.\\nALVY: ... you know, they're- The-the horrible would be like, uh, I don't know, terminal cases, you know?\\nANNIE: M'hm.\\nALVY: And blind people, crippled ...\\nANNIE: Yeah.\\nALVY: I don't-don't know how they get through life. It's amazing to me.\\nANNIE: M'hm.\\nALVY: You know, and the miserable is everyone else. That's-that's all. So-so when you go through life you should be thankful that you're miserable, because that's- You're very lucky ... to be ... ... to be miserable.\\n\\n\", 'answer': 'U-huh.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"U-huh.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : U-huh.\n",
      "Bert Score : {'precision': [0.942533552646637], 'recall': [0.8070343732833862], 'f1': [0.8695368766784668], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALVY: Look, look at that guy.\\nANNIE: M'hm.\\nALVY: There's-there's-there's-there's Mr. When-in-the-Pink, Mr. Miami Beach, there, you know? He's the latest! just came back from the gin-rummy farm last night. He placed third.\\nANNIE: M'hm. Yeah. Yeah.\\nALVY: Look at these guys.\\nANNIE: Yeah.\\nALVY: Oh, that's hilarious. They're back from Fire Island. They're ... they're sort of giving it a chance-you know what I mean?\\nANNIE: Oh! Italian, right?\\nALVY: Yeah, he's the Mafia. Linen Supply Business or Cement and Contract, you know what I mean?\\nANNIE: Oh, yeah.\\nALVY: No, I'm serious. I just got my mustache wet.\\nANNIE: Oh, yeah?\\n\\n\", 'answer': \"And there's the winner of the Truman Capote look-alike contest.\", 'gold_tag': 'ALVY is knowledgeable about different types of people and their lifestyles', 'last_speaker': 'ALVY'}\n",
      "Last word -> ALVY : \"And there's the winner of the Truman Capote look-alike contest.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : And there's the winner of the Truman Capote look-alike contest.\n",
      "Bert Score : {'precision': [0.9303941130638123], 'recall': [0.8469343781471252], 'f1': [0.886704683303833], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: You see, like you and I ...\\nALVY: You are extremely sexy.\\nANNIE: No, I'm not.\\nALVY: Unbelievably sexy. Yes, you are. Because ... you know what you are? You're-you're polymorphously perverse.\\nANNIE: Well, what does-what does that mean? I don't know what that is.\\nALVY: Uh ... uh, you're-you're exceptional in bed because you got -you get pleasure in every part of your body when I touch you.\\nANNIE: Ooooh!\\nALVY: You know what I mean? Like the tip o'your nose, and if I stroke your teeth or your kneecaps ... you get excited.\\nANNIE: Come on. Yeah. You know what? You know, I like you, I really mean it. I really do like you.\\nALVY: You- Do you love me?\\nANNIE: Do I love you?\\nALVY: That's the key question.\\nANNIE: Yeah.\\nALVY: I know you've only known me a short while.\\nANNIE: Well, I certainly ... I think that's very- Yeah, yeah ... yeah. Do you love me?\\nALVY: I-uh, love is, uh, is too weak a word for what...\\nANNIE: Yeah.\\nALVY: - I ... I love you. You know I lo-ove you, I-I love you. I-I have to invent- Of course I love you.\\nANNIE: Yeah.\\nALVY: Don't you think I do?\\n\\n\", 'answer': 'I dunno.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"I dunno.\"\n",
      "prediction :  No, I don't think you do.\n",
      "Real answer : I dunno.\n",
      "Bert Score : {'precision': [0.843955934047699], 'recall': [0.8950043320655823], 'f1': [0.8687308430671692], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.22222222222222224, 'rougeLsum': 0.22222222222222224}\n",
      "bleu 1/2 : 0.16666666666666669 0.05773502691896258\n",
      "ppl : 18.751914834985396\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALVY: Whatta you mean? You're not gonna give up your own apartment, are you?\\nANNIE: Of course.\\nALVY: Yeah, bu-bu-but why?\\nANNIE: Well, I mean, I'm moving in with you, that's why.\\nALVY: Yeah, but you-you got a nice apartment.\\nANNIE: I have a tiny apartment.\\nALVY: Yeah, I know it's small.\\nANNIE: That's right, and it's got bad plumbing and bugs.\\nALVY: All right, granted, it has bad plumbing and bugs, but you-you say that like it's a negative thing. You know, bugs are-are-uh, entomology is a ... ... rapidly growing field.\\nANNIE: You don't want me to live with you?\\nALVY: How- I don't want you to live with me? How- Whose idea was it?\\nANNIE: Mine.\\nALVY: Ye-ah. Was it ... It was yours actually, but, uh, I approved it immediately.\\nANNIE: I guess you think that I talked you into something, huh?\\nALVY: No-what, what ...? I ... we live together, we sleep together, we eat together. Jesus, you don't want it to be like we're married, do yuh?\\nANNIE: How is it any different?\\nALVY: It's different 'cause you keep your own apartment. Because you know it's there, we don't have to go to it, we don't have to deal with it, but it's like a-a-a free-floating life raft ... that we know that we're not married.\\nANNIE: That little apartment is four hundred dollars a month, Alvy.\\nALVY: That place is four hundred dollars a month?\\nANNIE: Yes, it is.\\nALVY: It's-it's got bad plumbing and bugs. Jesus, I'll-My accountant will write it off as a tax deduction, I'll pay for it.\\nANNIE: You don't think I'm smart enough to be serious about.\\nALVY: Hey, don't be ridiculous.\\nANNIE: Then why are you always pushing me to take those college courses like I was dumb or something?\\n\\n\", 'answer': \"'Cause adult education's a wonderful thing. You meet a lotta interesting professors. You know, it's stimulating.\", 'gold_tag': 'ALVY encourages ANNIE to take college courses and values education', 'last_speaker': 'ALVY'}\n",
      "Last word -> ALVY : \"'Cause adult education's a wonderful thing. You meet a lotta interesting professors. You know, it's stimulating.\"\n",
      "prediction :  I'm sorry. I didn't mean to upset you.\n",
      "Real answer : 'Cause adult education's a wonderful thing. You meet a lotta interesting professors. You know, it's stimulating.\n",
      "Bert Score : {'precision': [0.8605427742004395], 'recall': [0.8497012853622437], 'f1': [0.8550876975059509], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07142857142857142, 'rouge2': 0.0, 'rougeL': 0.07142857142857142, 'rougeLsum': 0.07142857142857142}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 8.940127496738425\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: You followed me. I can\\'t believe it!\\nALVY: I didn\\'t follow you!\\nANNIE: You followed me!\\nALVY: Why? \\'Cause I ... was walkin\\' along a block behind you staring at you? That\\'s not following!\\nANNIE: Well, what is your definition of following?\\nALVY: Following is different. I was spying.\\nANNIE: Do you realize how paranoid you are?\\nALVY: Paranoid? I\\'m looking at you. You got your arms around another guy.\\nANNIE: That is the worst kind of paranoia.\\nALVY: Yeah-well, I didn\\'t start out spying. I-I thought I\\'d surprise yuh. Pick you up after school.\\nANNIE: Yeah-well, you wanted to keep the relationship flexible, remember? It\\'s your phrase.\\nALVY: Oh, stop it. But you were having an affair with your college professor. That jerk that teaches that incredible crap course \"Contemporary Crisis in Western Man\"!\\nANNIE: \"Existential Motifs in Russian Literature\"! You\\'re really close.\\nALVY: What\\'s the difference? It\\'s all mental masturbation.\\nANNIE: Oh, well, now we\\'re finally getting to a subject you know something about!\\nALVY: Hey, don\\'t knock masturbation! It\\'s sex with someone I love.\\nANNIE: We\\'re not having an affair. He\\'s married. He just happens to think I\\'m neat.\\nALVY: \"Neat\"! There\\'s that- What are you-twelve years old? That\\'s one o\\' your Chippewa Falls expressions! \"He thinks I\\'m neat.\"\\nANNIE: Who cares? Who cares?\\nALVY: Next thing you know he\\'ll find you keen and peachy, you know? Next thing you know he\\'s got his hand on your ass!\\nANNIE: You\\'ve always had hostility toward David ever since I mentioned him!\\nALVY: David? You call your teacher David?\\nANNIE: It\\'s his name.\\nALVY: Well, listen, that\\'s, a nice bi-it\\'s a biblical name. Right? W-What does he call you? Bathsheba?\\n\\n', 'answer': \"Alvy! Alvy! You're the one who never wanted to make a real commitment. You don't think I'm smart enough! We had that argument just last month, or don't ou remember that day?\", 'gold_tag': 'Shared memories', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"Alvy! Alvy! You're the one who never wanted to make a real commitment. You don't think I'm smart enough! We had that argument just last month, or don't ou remember that day?\"\n",
      "prediction :  You're making fun of me.\n",
      "Real answer : Alvy! Alvy! You're the one who never wanted to make a real commitment. You don't think I'm smart enough! We had that argument just last month, or don't ou remember that day?\n",
      "Bert Score : {'precision': [0.8942079544067383], 'recall': [0.8153654932975769], 'f1': [0.8529686331748962], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809525, 'rouge2': 0.049999999999999996, 'rougeL': 0.09523809523809525, 'rougeLsum': 0.09523809523809525}\n",
      "bleu 1/2 : 0.0009033161885225332 0.00031937050122993454\n",
      "ppl : 36.15464777754888\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: I\\'m home!\\nALVY: Oh, yeah? How\\'d it go?\\nANNIE: down a bag of groceries on the Oh, it was ... really weird. But she\\'s a very nice woman.\\nALVY: Yeah?\\nANNIE: And I didn\\'t have to lie down on the couch, Alvy, she had me sitting up. So I told her about-about the-the family and about my feelings toward men and about my relationship with my brother.\\nALVY: M\\'m.\\nANNIE: And then she mentioned penis envy ... Did you know about that?\\nALVY: Me? I\\'m-I\\'m one of the few males who suffers from that, so, so ... you know.\\nANNIE: M\\'hm.\\nALVY: G-go on, I\\'m interested.\\nANNIE: Well, she said that I was very guilty about my impulses toward marriage, and-and children.\\nALVY: M\\'hm.\\nANNIE: And then I remembered when I was a kid how I accidentally saw my parents making love.\\nALVY: Tsch. Rea- All this happened in the first hour?\\nANNIE: M\\'hm.\\nALVY: That\\'s amazing. I-I-I ... I\\'ve been goin\\' for fifteen years, I-you know, I don\\'t got ... nothing like that in-\\nANNIE: Oh, I told her my dream and then I cried.\\nALVY: You cried? I\\'ve never once cried. Fantastic ...\\nANNIE: Yeah.\\nALVY: I whine. I-I-I sit and I whine.\\nANNIE: In-in ... Alvy, in my dream Frank my face and I can\\'t breathe.\\nALVY: Sinatra?\\nANNIE: Yeah, and he\\'s strangling me ...\\nALVY: Yeah?\\nANNIE: ... and I keep, you know, it\\'s-\\nALVY: Well, well, sure ... because he\\'s a singer and you\\'re a singer, you know, so it\\'s perfect. So you\\'re trying to suffocate yourself. It-it makes perfect sense. Uh, uh, that\\'s a perfect analytic ... kind of insight. Whatta you mean? Me?\\nANNIE: Yeah, yeah, yeah, you. Because in the dream ... I break Sinatra\\'s glasses.\\nALVY: Sinatra had gl- You never said Sinatra had glasses. So whatta you saying that I-I\\'m suffocating you?\\nANNIE: Oh, and God, Alvy, I did ... this really terrible thing to him. Because then when he sang it was in this real high-pitched voice.\\nALVY: Tsch, what\\'d the doctor say?\\nANNIE: Well, she said that I should probably come five times a week. And you know something? I don\\'t think I mind analysis at all. The only question is, Will it change my wife?\\nALVY: Will it change your wife?\\nANNIE: Will it change my life?\\nALVY: Yeah, but you said, \"Will it change my wife\"!\\nANNIE: No, I didn\\'t. I said, \"Will it change my life,\" Alvy.\\nALVY: You said, \"Will it change. . .\" Wife. Will it change ...\\nANNIE: Life. I said, \"life.\"\\nALVY: She said, \"Will it change my wife.\" You heard that because you were there so I\\'m not crazy.\\nANNIE: And, Alvy ... and then I told her about how I didn\\'t think you\\'d ever really take me seriously, because you don\\'t think that I\\'m smart enough.\\n\\n', 'answer': \"Why do you always bring that up? Because I encourage you to take adult-education courses? I think it's a wonderful thing. You meet wonderful, interesting professors'.\", 'gold_tag': \"ALVY is self-aware and admits to whining during his sessions , ALVY encourages ANNIE to take adult-education courses , ALVY is a quick thinker, providing an analysis of ANNIE's dream , ANNIE is questioning her intelligence due to ALVY's encouragement for her to take adult-education courses\", 'last_speaker': 'ALVY'}\n",
      "Last word -> ALVY : \"Why do you always bring that up? Because I encourage you to take adult-education courses? I think it's a wonderful thing. You meet wonderful, interesting professors'.\"\n",
      "prediction :  M'hm.\n",
      "Real answer : Why do you always bring that up? Because I encourage you to take adult-education courses? I think it's a wonderful thing. You meet wonderful, interesting professors'.\n",
      "Bert Score : {'precision': [0.8358444571495056], 'recall': [0.826284646987915], 'f1': [0.8310370445251465], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1805.9744576397727\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALVY: What\\'s- It\\'s me, open up.\\nANNIE: Oh.\\nALVY: Are you okay? What\\'s the matter? Are you all right? What-\\nANNIE: There\\'s a spider in the bathroom.\\nALVY: What? That\\'s what you got me here for at three o\\'clock in the morning, \\'cause there\\'s a spider in the bathroom?\\nANNIE: My God, I mean, you know how I am about insects.\\nALVY: Oooh.\\nANNIE: -I can\\'t sleep with a live thing crawling around in the bathroom.\\nALVY: Kill it! For Go- What\\'s wrong with you? Don\\'t you have a can of Raid in the house?\\nANNIE: No.\\nALVY: I told you a thousand times you should always keep, uh, a lotta insect spray. You never know who\\'s gonna crawl over. Jesus. All right, gimme a magazine. I- \\'cause I\\'m a little tired. You know, you, you joke with-about me, you make fun of me, but I\\'m prepared for anything. An emergency, a tidal wave, an earthquake. Hey, what is this? What? Did you go to a rock concert?\\nANNIE: Yeah.\\nALVY: Oh, yeah, really? Really? How-how\\'d you like it? Was it-was it, I mean, did it ... was it heavy? Did it achieve total heavy-ocity? Or was it, uh...\\nANNIE: It was just great!\\nALVY: Oh, humdinger. When- Well, I got a wonderful idea. Why don\\'tcha get the guy who took you to the rock concert, we\\'ll call him and he can come over and kill the spider. You know, it\\'s a-\\nANNIE: I called you; you wanna help me ... or not? H\\'h? Here.\\nALVY: What is this? What are you, since when do you read the \"National Review\"? What are you turning in to?\\nANNIE: Well, I like to try to get all points of view.\\nALVY: It\\'s wonderful. Then why don\\'tcha get\\nANNIE: Alvy, you\\'re a little hostile, you know that? Not only that, you look thin and tired.\\nALVY: Well, I was in be- It\\'s three o\\'clock in the morning. You, uh, you got me outta bed, I ran over here, I couldn\\'t get a taxi cab. You said it was an emergency, and I didn\\'t ge- I ran up the stairs. Hell - I was a lot more attractive when the evening began. Look, uh, tell- Whatta you- Are you star? Is that possible?\\nANNIE: Would you like a glass of chocolate milk?\\nALVY: Hey, what am I-your son? Whatta you mean? I-I came over TV --_\\nANNIE: I got the good chocolate, Alvy.\\nALVY: Yeah, where is the spider?\\nANNIE: It really is lovely. It\\'s in the bathroom.\\nALVY: Is he in the bathroom?\\nANNIE: Hey, don\\'t squish it, and after it\\'s dead, flush it down the toilet, okay? And flush it a couple o\\' times.\\nALVY: Darling, darling, I\\'ve been killing spiders since I was thirty, okay?\\nANNIE: Oh. What?\\nALVY: Very big spider.\\nANNIE: Yeah?\\nALVY: Two ... Yeah. Lotta, lotta trouble. There\\'s two of \\'em.\\nANNIE: Two?\\nALVY: Yep. I didn\\'t think it was that big, but it\\'s a major spider. You got a broom or something with a-\\nANNIE: Oh, I-I left it at your house.\\nALVY: -snow shovel or anything or something.\\nANNIE: I think I left it there, I\\'m sorry.\\nALVY: Okay, let me have this.\\nANNIE: Well, what are you doing ... what are you doing with-\\nALVY: Honey, there\\'s a spider in your bathroom the size of a Buick.\\nANNIE: Well, okay. Oooh.\\nALVY: Hey, what is this? You got black soap?\\nANNIE: It\\'s for my complexion.\\nALVY: Whatta-whatta yuh joining a minstrel show? Geez. Don\\'t worry! I did it! I killed them both. What-what\\'s the matter? Whatta you- -whatta you sad about? You- What\\'d you want me to do? Capture \\'em and rehabilitate \\'em?\\nANNIE: Oh, don\\'t go, okay? Please.\\nALVY: Whatta you mean, don\\'t go? Whatta-whatta -what\\'s the matter? Whatta you expecting -termites? What\\'s the matter?\\nANNIE: Oh, uh, I don\\'t know. I miss you. Tsch.\\nALVY: Oh, Jesus, really?\\nANNIE: Oh, yeah. Oh. Oh! Alvy?\\nALVY: What?\\nANNIE: Was there somebody in your room when I called you?\\nALVY: W-w-whatta you mean?\\nANNIE: I mean was there another- I thought I heard a voice.\\nALVY: Oh, I had the radio on.\\nANNIE: Yeah?\\nALVY: I\\'m sorry. I had the television set ... I had the television-\\n\\n', 'answer': 'Yeah.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"Yeah.\"\n",
      "prediction :  Oh, okay. It's okay. It's okay.\n",
      "Real answer : Yeah.\n",
      "Bert Score : {'precision': [0.842253565788269], 'recall': [0.9475625157356262], 'f1': [0.8918099403381348], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.39333355401193\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: Alvy, let's never break up again. I don't wanna be apart.\\nALVY: Oh, no, no, I think we're both much too mature for something like that.\\nANNIE: Living together hasn't been so bad, has it?\\nALVY: It's all right for me, it's been terrific, you know? Better than either one of my marriages. See, 'cause. . . 'cause there's just something different about you. I don't know what it is, but it's great.\\nANNIE: You know I think that if you let me, maybe I could help you have more fun, you know? I mean, I know it's hard and ... Yeah.\\nALVY: I don't know.\\nANNIE: Alvy, what about ... what if we go away this weekend, and we could-\\nALVY: Tsch, why don't we get ... why don't we get Rob, and the three of us'll drive into Brooklyn, you know, and we show you the old neighborhood.\\nANNIE: Okay, okay. Okay.\\nALVY: That'd be fun for yuh. Don't you think-\\n\\n\", 'answer': 'Yeah.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"Yeah.\"\n",
      "prediction :  Oh, Alvy, I think it would be wonderful.\n",
      "Real answer : Yeah.\n",
      "Bert Score : {'precision': [0.837526798248291], 'recall': [0.951094388961792], 'f1': [0.8907051086425781], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 66.45421245251293\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: Well, I had a really good day, you know that? It was just a real fine way to spend my birthday.\\nALVY: Ah? Oh, well, your birthday's not till tomorrow, honey, I hate to tell yuh.\\nANNIE: Yeah, but it's real close.\\nALVY: Yeah, but no presents till midnight.\\n\\n\", 'answer': 'Oh, darn it.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"Oh, darn it.\"\n",
      "prediction :  Oh, that's okay. I don't need anything.\n",
      "Real answer : Oh, darn it.\n",
      "Bert Score : {'precision': [0.8467726707458496], 'recall': [0.8605945706367493], 'f1': [0.8536276817321777], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.14285714285714285 0.048795003647426664\n",
      "ppl : 19.60554501492723\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANNIE: This is- Huh?\\nALVY: Happy birthday.\\nANNIE: What is this? Is this a...Present? Are you kidding?\\nALVY: Yeah, hey, why don't yuh try it on?\\nANNIE: Uh, yeah, uh ... t-t-this is more like a present for you, yeah, but it's-\\nALVY: Try it ... it'll add years to our sex life.\\nANNIE: Uh huh. Yeah. Forget it.\\nALVY: Here's a real present.\\nANNIE: What... huh?\\nALVY: Check it out.\\nANNIE: Oh, yeah? What is this, anyway? Let me see. Okay, let's... oooh, God! Oh, you knew I wanted this ... God, it's terrific, God!\\nALVY: Yeah, I know. Just-just put on the watch, and-and ... that thing, and we'll just ...\\n\\n\", 'answer': 'Oh! My God!', 'gold_tag': 'ANNIE is appreciative when she realizes ALVY got her something she wanted', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"Oh! My God!\"\n",
      "prediction :  Yeah.\n",
      "Real answer : Oh! My God!\n",
      "Bert Score : {'precision': [0.953564465045929], 'recall': [0.8035895824432373], 'f1': [0.8721767663955688], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALVY: Whose \"Catcher in the Rye\" is this?\\nANNIE: Well, let\\'s see now ... If it has my name on it, then I guess it\\'s mine.\\nALVY: Oh, it sure has ... You know, you wrote your name in all my books, \\'cause you knew this day was gonna come.\\nANNIE: Well, uh, Alvy, you wanted to break up just as much as I do.\\nALVY: There\\'s no-no question in my mind. I think we\\'re doing the mature thing, without any doubt.\\nANNIE: Now, look, all the books on death and dying are yours and all the poetry books are mine.\\nALVY: This \"Denial of Death\". You remember this?\\nANNIE: Oh-\\nALVY: This is the first book that I got you.\\nANNIE: -God.\\nALVY: Remember that day?\\nANNIE: Right. Geez, I feel like there\\'s a great weight off my back. M\\'mmm.\\nALVY: Thanks, honey.\\nANNIE: Oh, no, no, no, no, no. I mean, you know, no, no, no, I mean, I think it\\'s really important for us to explore new relationships and stuff like that.\\nALVY: There\\'s no-there\\'s no question about that, \\'cause we\\'ve given this ... uh, uh, I think a more than fair shot, you know?\\nANNIE: Yeah, my analyst thinks this move is keen for me.\\nALVY: Yeah, and I-I tru- you know, I trust her, because my-my analyst recommended her.\\nANNIE: Well, why should I put you through all my moods and hang-ups anyway?\\nALVY: Right. And you-and you know what the beauty part is?\\nANNIE: What?\\nALVY: We can always come back together again. Because there\\'s no-there\\'s no problem. \\'Cause ... Right.\\nANNIE: Exactly, but ... exactly. Ooooh!\\nALVY: You know, I-I-I don\\'t think many couples could handle this. You know, they could just break up and remain friends.\\nANNIE: Hey, this one\\'s mine, this button. This one, you rem-\\nALVY: Yeah.\\n\\n', 'answer': 'I guess these are all yours. Impeach, uh, Eisenhower ... Impeach Nixon ... Impeach Lyndon Johnson ... Impeach Ronald Reagan.', 'gold_tag': 'ANNIE has buttons advocating for the impeachment of various political figures', 'last_speaker': 'ANNIE'}\n",
      "Last word -> ANNIE : \"I guess these are all yours. Impeach, uh, Eisenhower ... Impeach Nixon ... Impeach Lyndon Johnson ... Impeach Ronald Reagan.\"\n",
      "prediction :  I'm going to be a little more cautious with my next breakup.\n",
      "Real answer : I guess these are all yours. Impeach, uh, Eisenhower ... Impeach Nixon ... Impeach Lyndon Johnson ... Impeach Ronald Reagan.\n",
      "Bert Score : {'precision': [0.8587756752967834], 'recall': [0.8067599534988403], 'f1': [0.8319554924964905], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06666666666666667, 'rouge2': 0.0, 'rougeL': 0.06666666666666667, 'rougeLsum': 0.06666666666666667}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 21.856870974304737\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOCO: So that's what you're looking for?\\nHELMUT: I'm looking for good TV sister.\\nCOCO: I think I'd be good TV.\\nHELMUT: You're at a great school, getting a great education. Be good at that.\\nCOCO: I am. And when I graduate early with an Economics degree from Manchester it will be the crowning achievement of my Black middle class parents' ambitions.\\nHELMUT: Conflict is a commodity in my industry. Sam's got it. Do you?\\nCOCO: So you want me to start a fight.\\n\\n\", 'answer': \"I don't want you to do anything you wouldn't otherwise do.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'HELMUT'}\n",
      "Last word -> HELMUT : \"I don't want you to do anything you wouldn't otherwise do.\"\n",
      "prediction :  No. I want you to be good at it.\n",
      "Real answer : I don't want you to do anything you wouldn't otherwise do.\n",
      "Bert Score : {'precision': [0.923663854598999], 'recall': [0.889557421207428], 'f1': [0.9062899351119995], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3636363636363637, 'rouge2': 0.2, 'rougeL': 0.3636363636363637, 'rougeLsum': 0.3636363636363637}\n",
      "bleu 1/2 : 0.35588329018524795 0.266912467638936\n",
      "ppl : 55.687401306348136\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOCO: Told you I was good TV.\\nHELMUT: The show I\\'m scouting for... It\\'s called Black Face / White Place. one of \"us\" in a sea of \"them.\"\\nCOCO: Interesting.\\nHELMUT: Interesting? You think they want interesting? Dignified stories of triumph and survival? snatching. I\\'m telling you this because the network is looking to take one of the subjects to series. I got one episode. One shot to find that subject. So if we do this...\\nCOCO: ...we do it all the way. I\\'m guessing Sam turned you down.\\nHELMUT: I think so. She called me a Bojangling Oofta, whatever that means. Everything else she said would\\'ve been bleeped on tv. So look, forty thousand hits on Youtube is good. It\\'s not great.\\n\\n', 'answer': \"I'm about to get a whole lot more.\", 'gold_tag': 'COCO shows confidence in being good TV material and predicts increased attention', 'last_speaker': 'COCO'}\n",
      "Last word -> COCO : \"I'm about to get a whole lot more.\"\n",
      "prediction :  I'm in.\n",
      "Real answer : I'm about to get a whole lot more.\n",
      "Bert Score : {'precision': [0.9242512583732605], 'recall': [0.877620279788971], 'f1': [0.9003323912620544], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.2, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0.024893534183931972 0.01113272692709733\n",
      "ppl : 144.83456157527968\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHELMUT: They'd let you do that?\\n\\n\", 'answer': 'They got no choice. They need me --', 'gold_tag': 'COCO holds a certain level of power or valuable skill , The power or valuable skill held by COCO is required by an unidentified third party', 'last_speaker': 'COCO'}\n",
      "Last word -> COCO : \"They got no choice. They need me --\"\n",
      "prediction :  They'd let you do that?\n",
      "Real answer : They got no choice. They need me --\n",
      "Bert Score : {'precision': [0.8422730565071106], 'recall': [0.8411170840263367], 'f1': [0.8416946530342102], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 70.7545794946429\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOMMODUS: Do you think he's really dying?\\nLUCILLA: He's been dying for ten years.\\nCOMMODUS: I think he's really dying this time. He has to be bled every night now.\\nLUCILLA: How do you know that?\\nCOMMODUS: I've been so informed. If he weren't really dying he wouldn't have sent for us.\\nLUCILLA: Maybe he just misses us.\\nCOMMODUS: And the Senators. He wouldn't have summoned them if --\\nLUCILLA: Peace, Commodus. After two weeks on the road your incessant scheming is hurting my head.\\nCOMMODUS: The first thing I shall do is honor him with games worthy of his majesty.\\n\\n\", 'answer': 'The first thing I shall do is have a hot bath.', 'gold_tag': 'LUCILLA values relaxation, as shown by her wish for a hot bath', 'last_speaker': 'LUCILLA'}\n",
      "Last word -> LUCILLA : \"The first thing I shall do is have a hot bath.\"\n",
      "prediction :  You're thinking of a gladiatorial show.\n",
      "Real answer : The first thing I shall do is have a hot bath.\n",
      "Bert Score : {'precision': [0.8567245006561279], 'recall': [0.863277792930603], 'f1': [0.8599886894226074], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0.07243303475117972 0.025091539267089076\n",
      "ppl : 74.89118732325741\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOMMODUS: All my desires are splitting my head to pieces -- there\\'s so much I want to do -- but all my efforts to show my children they are loved go unappreciated by those dragons in the Senate --\\nLUCILLA: Quiet, brother... Leave the Senate to me. Don\\'t trouble yourself.\\nCOMMODUS: All I want is to be a good father to my people. Why don\\'t they understand that?\\nLUCILLA: Shhh. The tonic will help... Yes, just drink this down.\\nCOMMODUS: I must take a firmer hand with them. They must know their father can be firm. As our father was firm with us.\\nLUCILLA: Our father lost his way. His mistake was believing the old songs of the \"Republic.\" We know better. So let the Senate talk. They have no real power.\\nCOMMODUS: Yes... yes... you always know the way. You were always so wise in these matters... You know if I didn\\'t have my duty to Rome I think I should be an artist. I should go away and paint pictures of the sea and leave all the politics to you... Will you stay with me?\\nLUCILLA: Still afraid of the dark, brother?\\nCOMMODUS: Still. Always. My dreams would terrify the world.\\nLUCILLA: I\\'ll stay with you until you are asleep.\\n\\n', 'answer': 'And after... just sit with me. Keep me safe...', 'gold_tag': 'Everyday Language', 'last_speaker': 'COMMODUS'}\n",
      "Last word -> COMMODUS : \"And after... just sit with me. Keep me safe...\"\n",
      "prediction :  You're my brother... You're my wife... You're my daughter... You're my son.\n",
      "Real answer : And after... just sit with me. Keep me safe...\n",
      "Bert Score : {'precision': [0.840743899345398], 'recall': [0.8538773655891418], 'f1': [0.8472597002983093], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 7.819058044512932\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOMMODUS: Why is he still alive?\\nLUCILLA: I don't know.\\nCOMMODUS: He shouldn't be alive. That vexes me. I am terribly vexed... There, that's better. Do you like the platform here?\\nLUCILLA: Mmm.\\nCOMMODUS: I do too. Simple, elegant... Father would have wanted something more ornate but he's dead now. Maximus Meridas haunts me. I see Father turning away from me and gazing at him. How many times did I suffer that indignity, I wonder?\\nLUCILLA: What are you going to do?\\nCOMMODUS: I'm going to kill him.\\nLUCILLA: Good.\\nCOMMODUS: Oh, you're too clever, Sister. Don't tell me part of you won't weep for him.\\nLUCILLA: When he defies my brother the Emperor, he defies me. But you shouldn't send assassins.\\nCOMMODUS: No?\\nLUCILLA: The people embraced him today. They will be expecting his next match... ... let him die in the arena like the slave he is. Let the people see what comes of defying Caesar.\\n\\n\", 'answer': \"He wounded you deeply, didn't he? Long ago. Nonetheless, your political acumen is, as always, unerring.\", 'gold_tag': 'Shared memories - COMMODUS and LUCILLA shared past experiences of their father showing favoritism towards Maximus Meridas', 'last_speaker': 'COMMODUS'}\n",
      "Last word -> COMMODUS : \"He wounded you deeply, didn't he? Long ago. Nonetheless, your political acumen is, as always, unerring.\"\n",
      "prediction :  Ah, you're a true Roman.\n",
      "Real answer : He wounded you deeply, didn't he? Long ago. Nonetheless, your political acumen is, as always, unerring.\n",
      "Bert Score : {'precision': [0.8738863468170166], 'recall': [0.8320761919021606], 'f1': [0.8524689078330994], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913045, 'rouge2': 0.0, 'rougeL': 0.08695652173913045, 'rougeLsum': 0.08695652173913045}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 71.18527382892032\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLUCILLA: Caesar...\\nCOMMODUS: I am sorry to have kept you away... I needed this time to think...\\nLUCILLA: Of course...\\nCOMMODUS: I limited my world to these four walls so as to let my mind free... again and again my mind settles on but one question... What kind of world are we making when the people of Rome prefer a slave in the arena to their father? It is my responsibility to make the world as it should be. How is it I have made this world?\\nLUCILLA: Brother, do not be influenced by the mob. They are a great, faceless beast --\\nCOMMODUS: They are not \"the mob,\" Lucilla, they are the people. They are my children and all I want to do is love them. Our father loved Maximus... and I love him still... yet he defies me, he tasks me in front of my children. And they love him for it. Just as Marcus loved him for it. Tell me why, Lucilla.\\nLUCILLA: They see themselves in him. They throw in their own sad dreams for them.\\nCOMMODUS: And what do I do but fight for them?! I give them games to please them. I strangle dissent to give them peace. I empower the Praetorians to give them order. What more can I do?! Say I should fight him, in the arena. Let my children see who the Gods truly favor.\\nLUCILLA: And what if he should win?\\nCOMMODUS: A God is more powerful than a man...\\nLUCILLA: Caesar, you let this unduly worry you. At best he is a passing fancy -- he is a name, an image on a banner, ephemeral -- he will be forgotten as the next fancy appears --\\nCOMMODUS: But I need to know -- why do they love him?\\nLUCILLA: Mercy. He will not kill in the arena. He is merciful. As they all wish they were in their own hearts.\\n\\n', 'answer': 'And for that moment in the arena they are merciful too. For a moment... they are Gods. Offering life. But who can be more merciful than the Emperor of Rome?', 'gold_tag': 'COMMODUS sees himself as their father figure and wants to be perceived as a merciful and benevolent ruler', 'last_speaker': 'COMMODUS'}\n",
      "Last word -> COMMODUS : \"And for that moment in the arena they are merciful too. For a moment... they are Gods. Offering life. But who can be more merciful than the Emperor of Rome?\"\n",
      "prediction :  You are right, Lucilla. I will not fight him in the arena. I will fight him in the Senate.\n",
      "Real answer : And for that moment in the arena they are merciful too. For a moment... they are Gods. Offering life. But who can be more merciful than the Emperor of Rome?\n",
      "Bert Score : {'precision': [0.8662474751472473], 'recall': [0.8457520604133606], 'f1': [0.8558771014213562], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2040816326530612, 'rouge2': 0.0851063829787234, 'rougeL': 0.163265306122449, 'rougeLsum': 0.163265306122449}\n",
      "bleu 1/2 : 0.11799748285661452 0.060615444636367186\n",
      "ppl : 16.942167159994842\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBORG QUEEN: You've taken your first step\\nDATA: I do not know what you are referring to.\\nBORG QUEEN: That's because you haven't been properly... stimulated yet. Do you know what this is, Data?\\nDATA: It would appear that you are attempting to graft organic skin\\n\\n\", 'answer': 'What a cold description... for such a beautiful gift.', 'gold_tag': 'BORG QUEEN has capabilities to perform biochemical procedures like grafting organic skin', 'last_speaker': 'BORG QUEEN'}\n",
      "Last word -> BORG QUEEN : \"What a cold description... for such a beautiful gift.\"\n",
      "prediction :  It is not just any skin. It is the skin of your mother.\n",
      "Real answer : What a cold description... for such a beautiful gift.\n",
      "Bert Score : {'precision': [0.8495348691940308], 'recall': [0.8672223687171936], 'f1': [0.8582874536514282], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.534824286476077\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBORG QUEEN: Was that good for you?\\n\\n', 'answer': 'It was... interesting. Do it again... please.', 'gold_tag': 'DATA shows curiosity , DATA shows a willingness to explore unfamiliar experiences', 'last_speaker': 'DATA'}\n",
      "Last word -> DATA : \"It was... interesting. Do it again... please.\"\n",
      "prediction :  Yes, it was.\n",
      "Real answer : It was... interesting. Do it again... please.\n",
      "Bert Score : {'precision': [0.8859461545944214], 'recall': [0.8552237749099731], 'f1': [0.8703138828277588], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4, 'rouge2': 0.25, 'rougeL': 0.4, 'rougeLsum': 0.4}\n",
      "bleu 1/2 : 0.08786571270524224 0.03403024420100487\n",
      "ppl : 133.76713919596187\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBORG QUEEN: How do you feel?\\nDATA: My visual acuity has been reduced by seventy-eight percent... and I can no longer perceive light beyond the ultraviolet or the infrared... But I can see.\\nBORG QUEEN: Until today... your emotions were trapped inside an artificial shell. You didn't know what it was to truly feel. And there's so much more for you to experience. I will guide you into a world of sensation unlike anything you can imagine. All you have to do... is give us access to your neural net.\\nDATA: No. I will not betray my friends.\\nBORG QUEEN: They're not your friends... they've held you back... kept you from your destiny...\\nDATA: That is not true. They have tried to help me.\\nBORG QUEEN: Have they given you what I have given you? Did they even try?\\nDATA: I... do not want this...\\nBORG QUEEN: You're becoming more human all the time, Data. Now you're learning how to lie.\\nDATA: I wish to... go back to the way I was.\\nBORG QUEEN: More lies. Have you ever know a woman? Do you know what it's like to feel against flesh?\\nDATA: My creator did not intend for me to experience these things.\\n\\n\", 'answer': \"I'm your creator now.\", 'gold_tag': 'BORG QUEEN perceives herself as a creator', 'last_speaker': 'BORG QUEEN'}\n",
      "Last word -> BORG QUEEN : \"I'm your creator now.\"\n",
      "prediction :  I am your creator.\n",
      "Real answer : I'm your creator now.\n",
      "Bert Score : {'precision': [0.9858973026275635], 'recall': [0.96357661485672], 'f1': [0.9746091961860657], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.6666666666666665, 'rouge2': 0.28571428571428575, 'rougeL': 0.6666666666666665, 'rougeLsum': 0.6666666666666665}\n",
      "bleu 1/2 : 0.25 0.09128709291752769\n",
      "ppl : 93.37075479772075\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBORG QUEEN: A Borg in all but name.\\nDATA: I am... grateful for what you have given me. But I still do not wish to be assimilated.\\nBORG QUEEN: A universe of sensation is waiting for you... don't you want to explore it... with me?\\nDATA: Yes...\\nBORG QUEEN: Then take the final step... give me the Enterprise... and we can be together... always.\\nDATA: No... I cannot.\\nBORG QUEEN: I've deactivated the sensory\\nDATA: No... no, please... you cannot...\\nBORG QUEEN: You must give me what I want... now. Without the deflector dish, we can no longer send for an early invasion. We must assimilate Earth ourselves. I need this ship. Isn't it better like this...?\\nDATA: Yes... but the Enterprise... my duty...\\nBORG QUEEN: ... is to yourself. Don't make me hurt you again...\\nDATA: No... no, it's so... empty... please... give it back... I need\\n\\n\", 'answer': 'And I need to control this ship. Let me into your mind. In order to access my neural net... you will need to create a positronic interface. I will tell you how.', 'gold_tag': 'BORG QUEEN is a commanding figure who seeks control and assimilation', 'last_speaker': 'BORG QUEEN'}\n",
      "Last word -> BORG QUEEN : \"And I need to control this ship. Let me into your mind. In order to access my neural net... you will need to create a positronic interface. I will tell you how.\"\n",
      "prediction :  No... I cannot.\n",
      "Real answer : And I need to control this ship. Let me into your mind. In order to access my neural net... you will need to create a positronic interface. I will tell you how.\n",
      "Bert Score : {'precision': [0.8943132758140564], 'recall': [0.833294689655304], 'f1': [0.8627263903617859], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05714285714285714, 'rouge2': 0.0, 'rougeL': 0.05714285714285714, 'rougeLsum': 0.05714285714285714}\n",
      "bleu 1/2 : 2.1120235358186548e-05 8.179831981023755e-06\n",
      "ppl : 405.62468635084554\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBORG QUEEN: Eliminate their remaining defenses. I will send Borg to assimilate the rest of the crew. Vulcan?\\n\\n', 'answer': 'No.', 'gold_tag': 'DATA is capable of identifying and responding to inquiries regarding specific subjects', 'last_speaker': 'DATA'}\n",
      "Last word -> DATA : \"No.\"\n",
      "prediction :  I am sorry, Borg Queen. I cannot comply with your request.\n",
      "Real answer : No.\n",
      "Bert Score : {'precision': [0.840213418006897], 'recall': [0.9181647300720215], 'f1': [0.8774612545967102], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.133436364290464\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDATA: I have repaired the weapons array. Phasers are on-line.\\nBORG QUEEN: The targeting lock isn't working.\\nDATA: I do not understand. The optical data network has been repaired, and all systems are functioning.\\nBORG QUEEN: Your diagnostics are in error. I need weapons.\\nDATA: The problem must lie in the interface between Starfleet and Borg technology. Your console may not be configured to handle the data flow.\\nBORG QUEEN: Can you configure it?\\nDATA: I believe so.\\n\\n\", 'answer': 'Do it.', 'gold_tag': 'BORG QUEEN needs her weapons system repaired immediately', 'last_speaker': 'BORG QUEEN'}\n",
      "Last word -> BORG QUEEN : \"Do it.\"\n",
      "prediction :  Do it.\n",
      "Real answer : Do it.\n",
      "Bert Score : {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
      "bleu 1/2 : 1.0 1.0\n",
      "ppl : 1206.7820845332085\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOROTHEA: I'm glad you could make it.\\n\\n\", 'answer': 'Hey, this is a big deal for me. You know what seats like this cost in New York?', 'gold_tag': 'HARRY perceives this event to be a big deal , HARRY has knowledge about the cost of such events in New York', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"Hey, this is a big deal for me. You know what seats like this cost in New York?\"\n",
      "prediction :  It's good to see you too, Dorothea. I'm glad I could come.\n",
      "Real answer : Hey, this is a big deal for me. You know what seats like this cost in New York?\n",
      "Bert Score : {'precision': [0.8399215340614319], 'recall': [0.8445534706115723], 'f1': [0.8422311544418335], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0625, 'rouge2': 0.0, 'rougeL': 0.0625, 'rougeLsum': 0.0625}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.61903920489064\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHARRY: Are they treating you okay?\\nDOROTHEA: I heard what happened. It looks\\nHARRY: I'm sorry I got into this too late. But if you want me to stick around, maybe dig where the cops don't look...\\nDOROTHEA: I don't know where you'd start.\\nHARRY: Well... how about some of the other illusionists?\\nDOROTHEA: They won't tell you anything.\\nHARRY: I can be very persuasive.\\nDOROTHEA: Yes. I think you probably can. We'd need to talk about your fee.\\n\\n\", 'answer': \"Forget the fee. If I find Butterfield, maybe we'll talk about money. If I don't... ...my gamble. Either way... I get to spend some time... here.\", 'gold_tag': \"HARRY is willing to work without immediate payment, showing personal investment in DOROTHEA's issue\", 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"Forget the fee. If I find Butterfield, maybe we'll talk about money. If I don't... ...my gamble. Either way... I get to spend some time... here.\"\n",
      "prediction :  I don't need a fee.\n",
      "Real answer : Forget the fee. If I find Butterfield, maybe we'll talk about money. If I don't... ...my gamble. Either way... I get to spend some time... here.\n",
      "Bert Score : {'precision': [0.8878700733184814], 'recall': [0.8402659296989441], 'f1': [0.8634123206138611], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23529411764705882, 'rouge2': 0.125, 'rougeL': 0.17647058823529413, 'rougeLsum': 0.17647058823529413}\n",
      "bleu 1/2 : 0.0059982307281910814 0.0014995576820477706\n",
      "ppl : 61.70838579883645\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOROTHEA: Harry... I know it's late.\\nHARRY: That's okay.\\nDOROTHEA: How did it go today?\\n\\n\", 'answer': \"I went up to the Magic Castle. You were right. He didn't have a lot of fans up there.\", 'gold_tag': 'HARRY was following up on a lead at the Magic Castle , DOROTHEA and HARRY share knowledge about a person’s lack of popularity at the Magic Castle', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"I went up to the Magic Castle. You were right. He didn't have a lot of fans up there.\"\n",
      "prediction :  It went well. I found the house.\n",
      "Real answer : I went up to the Magic Castle. You were right. He didn't have a lot of fans up there.\n",
      "Bert Score : {'precision': [0.8986912965774536], 'recall': [0.8725512027740479], 'f1': [0.8854283690452576], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2222222222222222, 'rouge2': 0.0, 'rougeL': 0.14814814814814817, 'rougeLsum': 0.14814814814814817}\n",
      "bleu 1/2 : 0.07718241949197957 0.015220578385573807\n",
      "ppl : 92.21450781784404\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHARRY: So why did you marry him?\\nDOROTHEA: That's my business. Harry.\\nHARRY: Just curious. Back to business. Ever heard of a man called Nix? Dorothea?\\nDOROTHEA: Yes... I'm here. And no. I don't know the name.\\nHARRY: What about Jennifer Desiderio?\\nDOROTHEA: It doesn't ring a bell. I have to go.\\nHARRY: Okay. I'll keep digging.\\n\\n\", 'answer': 'Yes. You do that.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DOROTHEA'}\n",
      "Last word -> DOROTHEA : \"Yes. You do that.\"\n",
      "prediction :  Good luck.\n",
      "Real answer : Yes. You do that.\n",
      "Bert Score : {'precision': [0.8927927017211914], 'recall': [0.8858522176742554], 'f1': [0.8893089294433594], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1882.721209526561\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOROTHEA: This is the way he wanted it... no autopsy, no embalming. Nobody meddling with his body... Flesh is a trap. That's what he used to say. Flesh is a trap and magic sets us free. Why did you come back?\\nHARRY: I didn't leave. I was just digging around.\\nDOROTHEA: What did you find?\\nHARRY: Jennifer Desiderio, for one. She threw herself in front of a car this afternoon.\\nDOROTHEA: Oh Christ.\\n\\n\", 'answer': \"Why don't you tell me the truth?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"Why don't you tell me the truth?\"\n",
      "prediction :  Yeah. She was the last person to see him alive.\n",
      "Real answer : Why don't you tell me the truth?\n",
      "Bert Score : {'precision': [0.8661006093025208], 'recall': [0.8284105658531189], 'f1': [0.8468364477157593], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11111111111111112, 'rouge2': 0.0, 'rougeL': 0.11111111111111112, 'rougeLsum': 0.11111111111111112}\n",
      "bleu 1/2 : 0.10000000000000002 0.03333333333333335\n",
      "ppl : 28.253248946821188\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHARRY: Nix ran some kind of cult, right? Some kind of Charlie Manson deal?\\nDOROTHEA: It was more than that, I think.\\nHARRY: He was the real thing, right?\\nDOROTHEA: Swann said he could do stuff, yes.\\nHARRY: Stuff?\\nDOROTHEA: He could get into people's heads. Make them see things. Terrible things. And he could levitate. Juggle fire.\\nHARRY: He taught all this to Swann?\\n\\n\", 'answer': 'Some or it.', 'gold_tag': 'DOROTHEA implies involvement with another character, Swann, who learned from Nix', 'last_speaker': 'DOROTHEA'}\n",
      "Last word -> DOROTHEA : \"Some or it.\"\n",
      "prediction :  Swann was the first to see Nix's power. He was the first to believe.\n",
      "Real answer : Some or it.\n",
      "Bert Score : {'precision': [0.8533607721328735], 'recall': [0.8591418266296387], 'f1': [0.8562415242195129], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 40.940315548215544\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHARRY: So Swann was performing magic. not illusions? And what? You thought he should be using it to cure cancer, not making millions.\\nDOROTHEA: I told you --\\nHARRY: Too much fame. Yeah, I guess that'd turn anybody's head. Including yours.\\nDOROTHEA: No.\\nHARRY: You said you weren't with him for love.\\nDOROTHEA: I wasn't.\\nHARRY: What then?\\nDOROTHEA: I was grateful to him. I owed him my life. And he loved me. He couldn't always show it, but he felt it.\\nHARRY: He thought Nix was coming back, didn't he?\\nDOROTHEA: Shit!\\nHARRY: It's okay.\\nDOROTHEA: No it isn't. You can't help me.\\nHARRY: I'm here, aren't I? Nothing's going to happen to you.\\nDOROTHEA: Nothing?\\n\\n\", 'answer': \"Nothing you don't want.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"Nothing you don't want.\"\n",
      "prediction :  Nothing.\n",
      "Real answer : Nothing you don't want.\n",
      "Bert Score : {'precision': [0.9420517683029175], 'recall': [0.8448448777198792], 'f1': [0.8908042311668396], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.33333333333333337, 'rouge2': 0.0, 'rougeL': 0.33333333333333337, 'rougeLsum': 0.33333333333333337}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2980.6054928636017\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOROTHEA: I was so afraid.\\nHARRY: Don't be. Nix can't hurt you now.\\nDOROTHEA: Are you sure?\\nHARRY: I'm sure. He's dead.\\nDOROTHEA: I know. I'm the one who shot him. I was twelve. Nix took me hostage, to get Swann to come to him.\\nHARRY: And they all came...\\nDOROTHEA: Yes.\\nHARRY: Quaid and Jennifer--\\nDOROTHEA: And Pimm and Swann. Only Nix was ready for them. What was that?\\n\\n\", 'answer': \"It's okay.\", 'gold_tag': 'HARRY tries to calm Dorothea down', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"It's okay.\"\n",
      "prediction :  A gun.\n",
      "Real answer : It's okay.\n",
      "Bert Score : {'precision': [0.8944705128669739], 'recall': [0.8632619976997375], 'f1': [0.8785891532897949], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2335.4224317877665\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHARRY: Valentin?\\nDOROTHEA: Harry? Wait!\\nHARRY: What the hell-? Aah!\\nDOROTHEA: It's him! It's Nix!\\n\\n\", 'answer': 'Valentin! Get some lights on!', 'gold_tag': 'HARRY is calling out for someone named Valentin , HARRY is asking for lights , HARRY might be in a leadership or commanding position', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"Valentin! Get some lights on!\"\n",
      "prediction :  Dorothea, listen. We need to get out of here, now.\n",
      "Real answer : Valentin! Get some lights on!\n",
      "Bert Score : {'precision': [0.854348361492157], 'recall': [0.8358747959136963], 'f1': [0.8450105786323547], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 37.316418460851494\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOROTHEA: Is it finished?\\n\\n', 'answer': 'I think so.', 'gold_tag': 'Everyday Language', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"I think so.\"\n",
      "prediction :  Yes.\n",
      "Real answer : I think so.\n",
      "Bert Score : {'precision': [0.9382740259170532], 'recall': [0.8677245378494263], 'f1': [0.9016212821006775], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2104.611116571625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOROTHEA: Harry-?\\n\\n', 'answer': 'Out! Out!', 'gold_tag': 'Everyday Language', 'last_speaker': 'HARRY'}\n",
      "Last word -> HARRY : \"Out! Out!\"\n",
      "prediction :  Yes?\n",
      "Real answer : Out! Out!\n",
      "Bert Score : {'precision': [0.8870180249214172], 'recall': [0.8305433988571167], 'f1': [0.8578522205352783], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 9554.816423904052\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALABAMA: Oh, look what happened. Oh god, I'm so sorry. Are you OK?\\nCLARENCE: Yeah. I'm fine. It didn't hurt. It's OK. Don't worry about it. Accidents happen.\\nALABAMA: What a wonderful philosophy. Thanks for being such a sweetheart. You could have been a real dick. Excuse me... I hate to bother you again. Would you mind too terribly filling me in on what I missed?\\nCLARENCE: Not at all. I, this guy here, he's Sonny Chiba.\\nALABAMA: The oriental.\\nCLARENCE: The oriental in black. He's an assasin. Now, at the beginning he was hired to kill this guy the cops had. So he got himself arrested. They take him into the police station. And he starts kickin' all the cops' asses. Now, while keepin' them at bay, he finds the guy he was supposed to kill. Does a number on him. Kicks the cops' asses some more. Kicks the bars out of the window. And jumps out into a getaway car that was waiting for him.\\nALABAMA: Want some Goobers?\\nCLARENCE: Thanks a lot.\\nALABAMA: I thought Sonny was the good guy.\\n\\n\", 'answer': \"He ain't so much good guy as he's just a bad motherfucker. Sonny don't be bullshittin'. He fucks dudes up for life. Hold on, a fight scene's coming up.\", 'gold_tag': 'CLARENCE uses informal language such as \"bad motherfucker\" and \"bullshittin\\'\"', 'last_speaker': 'CLARENCE'}\n",
      "Last word -> CLARENCE : \"He ain't so much good guy as he's just a bad motherfucker. Sonny don't be bullshittin'. He fucks dudes up for life. Hold on, a fight scene's coming up.\"\n",
      "prediction :  He is. I am. He was hired to kill the bad guy. Now, the cops were after him because he was supposed to kill this guy.\n",
      "Real answer : He ain't so much good guy as he's just a bad motherfucker. Sonny don't be bullshittin'. He fucks dudes up for life. Hold on, a fight scene's coming up.\n",
      "Bert Score : {'precision': [0.8732618093490601], 'recall': [0.8317787647247314], 'f1': [0.8520156145095825], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1694915254237288, 'rouge2': 0.0, 'rougeL': 0.13559322033898305, 'rougeLsum': 0.13559322033898305}\n",
      "bleu 1/2 : 0.10281038961871805 0.019142252795055856\n",
      "ppl : 18.119576381356616\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALABAMA: Great movie. Action-packed!\\nCLARENCE: My name is Clarence, and what is yours?\\nALABAMA: Alabama Whitman. Pleased to meet ya.\\nCLARENCE: Is that your real name? Really?\\nALABAMA: That's my real name, really. I got proof. See.\\n\\n\", 'answer': \"Well, cut my legs off and call me Shorty. That's a pretty original moniker there, Alabama. Sounds like a Pam Grier movie. She's a sixteen-calibre kitten, equally equipped for killin' an' lovin'! She carried a sawed-off shotgun in her purse, a black belt around her\", 'gold_tag': 'Clarence has a sense of humor , Clarence possibly enjoys movies featuring strong female characters like Pam Grier', 'last_speaker': 'CLARENCE'}\n",
      "Last word -> CLARENCE : \"Well, cut my legs off and call me Shorty. That's a pretty original moniker there, Alabama. Sounds like a Pam Grier movie. She's a sixteen-calibre kitten, equally equipped for killin' an' lovin'! She carried a sawed-off shotgun in her purse, a black belt around her\"\n",
      "prediction :  Wow.\n",
      "Real answer : Well, cut my legs off and call me Shorty. That's a pretty original moniker there, Alabama. Sounds like a Pam Grier movie. She's a sixteen-calibre kitten, equally equipped for killin' an' lovin'! She carried a sawed-off shotgun in her purse, a black belt around her\n",
      "Bert Score : {'precision': [0.934965968132019], 'recall': [0.7833123803138733], 'f1': [0.8524467945098877], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 601.581129635786\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLARENCE: Where's your car? I'll walk you to it.\\nALABAMA: I took a cab.\\nCLARENCE: You took a cab to see three kung fu movies?\\nALABAMA: Sure. Why not?\\nCLARENCE: Nothing. It's just you're a girl after my own heart.\\nALABAMA: What time is it? I suppose you gotta get up early, huh?\\nCLARENCE: No. Not particularly. How come?\\nALABAMA: Well, it's just when I see a really good movie I really like to go out and\\nCLARENCE: I love to get pie after a movie.\\nALABAMA: Would you like to get some pie?\\n\\n\", 'answer': \"I'd love some pie.\", 'gold_tag': 'CLARENCE enjoys kung fu films and has a fondness for pie', 'last_speaker': 'CLARENCE'}\n",
      "Last word -> CLARENCE : \"I'd love some pie.\"\n",
      "prediction :  Sure.\n",
      "Real answer : I'd love some pie.\n",
      "Bert Score : {'precision': [0.9437175393104553], 'recall': [0.8530689477920532], 'f1': [0.8961066007614136], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 940.7736565945374\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLARENCE: Well, enough about the King. How about you?\\nALABAMA: How 'bout me what?\\nCLARENCE: Tell me about yourself. C'mon. What're ya tryin' to be? The Phantom Lady?\\nALABAMA: What do you want to know?\\nCLARENCE: Well, for starters, what do you do? Where're ya from? What's your favorite are your turn-ons and turn-offs? Do you have a fella? What's the story behind you takin' a cab to the most dangerous part of town alone? And, in a theater full of empty seats, why did you sit by me?\\nALABAMA: Ask me them again. One by one.\\nCLARENCE: What do you do?\\nALABAMA: I don't remember.\\nCLARENCE: Where are you from. What's your favorite color? What's your favorite movie star? Would you like a bite of my pie?\\nALABAMA: Yes, I would.\\nCLARENCE: Like it?\\nALABAMA: Very much. Now, where were we?\\nCLARENCE: What kinda music do you like? What are your turn-ons? Turn-offs?\\nALABAMA: I'm sure there must be something, but I don't really remember. The only\\nCLARENCE: Do you have a fella?\\nALABAMA: I'm not sure yet. Ask me again later.\\nCLARENCE: What's the story behind you takin' a cab to the most dangerous part of town alone?\\nALABAMA: Apparently, I was hit on the head with something really heavy, giving me a form of amnesia. When I came to, I didn't know who I was, where I was, or where I came from. Luckily, I had my driver's license or I wouldn't even know my name. I hoped it would tell me where I lived but it had a Tallahassee address on it, and I stopped somebody on the street and they told me I was in Detroit. So that was no help. But I did have some money on me, so I hopped in a cab until I saw somethin' that looked familiar. For some reason, and don't ask me why, that theater looked familiar. So I told him to stop and I got out.\\nCLARENCE: And in a theater full of empty seats, why did you sit by me?\\n\\n\", 'answer': \"Because you looked like a nice guy, and I was a little scared. And I sure couldda used a nice guy about that time, so I spilled my popcorn on you. Aren't you just dazzled by my imagination, lover boy? Where to next?\", 'gold_tag': 'ALABAMA refers to CLARENCE as \"lover boy\" , ALABAMA appears imaginative and slightly playful , ALABAMA experienced a recent traumatic event that led to her amnesia , ALABAMA took a cab to a reportedly dangerous part of town on the day of the conversation', 'last_speaker': 'ALABAMA'}\n",
      "Last word -> ALABAMA : \"Because you looked like a nice guy, and I was a little scared. And I sure couldda used a nice guy about that time, so I spilled my popcorn on you. Aren't you just dazzled by my imagination, lover boy? Where to next?\"\n",
      "prediction :  Ask me again. One by one.\n",
      "Real answer : Because you looked like a nice guy, and I was a little scared. And I sure couldda used a nice guy about that time, so I spilled my popcorn on you. Aren't you just dazzled by my imagination, lover boy? Where to next?\n",
      "Bert Score : {'precision': [0.8501582145690918], 'recall': [0.800808310508728], 'f1': [0.8247457146644592], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.04, 'rouge2': 0.0, 'rougeL': 0.04, 'rougeLsum': 0.04}\n",
      "bleu 1/2 : 0.00034970306968015047 0.00012114069684976399\n",
      "ppl : 194.11249505031236\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALABAMA: Wow. What a swell place to work.\\nCLARENCE: Yeah, I got the key, so I come here at night, hang out, read comic books, play music.\\nALABAMA: How long have you worked here?\\nCLARENCE: Almost four years.\\nALABAMA: That\\'s a long time.\\nCLARENCE: I\\'m hip. But you know, I\\'m comfortable here. It\\'s easy work. I know what\\nALABAMA: Do you get paid a lot?\\nCLARENCE: That\\'s where trouble comes into paradise. But the boss let\\'s you borrow some money if you need it. Wanna see what \"Spiderman\" number one looks like?\\nALABAMA: You bet. How much is that worth?\\nCLARENCE: Four hundred bucks. Well, we sell other things too. Cool stuff. \"Man from U.N.C.L.E.\" Lunch\\nALABAMA: What\\'s that?\\n\\n', 'answer': '\"Spiderman\", number one. The one that started it all. He was just born, remember? This is the first one. You know that guy, Dr. \"Sgt. Fury and His Howling Commandos\". One of the coolest series known to man. They\\'re completely worthless. You can get number one for about four bucks. But that\\'s one of the cool things about them, they\\'re so cheap. Just look at that artwork, will ya. Great stories. Great Characters. Look at this one. Alabama, I\\'d like you to have this.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CLARENCE'}\n",
      "Last word -> CLARENCE : \"\"Spiderman\", number one. The one that started it all. He was just born, remember? This is the first one. You know that guy, Dr. \"Sgt. Fury and His Howling Commandos\". One of the coolest series known to man. They're completely worthless. You can get number one for about four bucks. But that's one of the cool things about them, they're so cheap. Just look at that artwork, will ya. Great stories. Great Characters. Look at this one. Alabama, I'd like you to have this.\"\n",
      "prediction :  It's a TV show. You should watch it.\n",
      "Real answer : \"Spiderman\", number one. The one that started it all. He was just born, remember? This is the first one. You know that guy, Dr. \"Sgt. Fury and His Howling Commandos\". One of the coolest series known to man. They're completely worthless. You can get number one for about four bucks. But that's one of the cool things about them, they're so cheap. Just look at that artwork, will ya. Great stories. Great Characters. Look at this one. Alabama, I'd like you to have this.\n",
      "Bert Score : {'precision': [0.8663491010665894], 'recall': [0.8141065239906311], 'f1': [0.8394157290458679], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06185567010309277, 'rouge2': 0.0, 'rougeL': 0.06185567010309277, 'rougeLsum': 0.06185567010309277}\n",
      "bleu 1/2 : 9.356478735962576e-06 3.1630671251902655e-06\n",
      "ppl : 30.433509011361878\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLARENCE: Five.\\nALABAMA: Oh, you look so cute as little Elvis.\\n\\n', 'answer': 'I finally knew what I wanted when I grew up.', 'gold_tag': \"CLARENCE is a fan of Elvis since young , CLARENCE's career choice was influenced by his love for Elvis\", 'last_speaker': 'CLARENCE'}\n",
      "Last word -> CLARENCE : \"I finally knew what I wanted when I grew up.\"\n",
      "prediction :  I'm not little, I'm a grown man.\n",
      "Real answer : I finally knew what I wanted when I grew up.\n",
      "Bert Score : {'precision': [0.8820144534111023], 'recall': [0.8745834231376648], 'f1': [0.8782832026481628], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2105263157894737, 'rouge2': 0.0, 'rougeL': 0.2105263157894737, 'rougeLsum': 0.2105263157894737}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.762613163543215\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLARENCE: You know when you sat behind me?\\nALABAMA: At the movies?\\nCLARENCE: Uh-huh, I was tryin' to think of somethin' to say to you, then I thought, she doesn't want me bothering her.\\nALABAMA: What would make you think that?\\nCLARENCE: I dunno. I guess I'm just stupid.\\nALABAMA: You're not stupid. Just wrong.\\nCLARENCE: You know, a lot of people have misconceptions of how she died.\\nALABAMA: She OD'd, didn't she?\\nCLARENCE: Yeah, she OD'd. But wasn't on her last legs or anythin'. She didn't take she took.\\nALABAMA: You mean she got a bad batch?\\n\\n\", 'answer': 'That\\'s what happened. In fact, when she died, it was considered to be the happiest time of her life. She\\'d been fucked over so much by men she didn\\'t trust them. She was havin\\' this relationship with this guy and he asked her to marry him. Now, other people had asked to marry her before, but she couldn\\'t be sure whether they really loved her or were just after her money. So, she said no. And the guy says, \"Look, I really love you, and I wanna prove it. So have your lawyers draw up a paper that says no matter what happens, I can never get any of your money, and I\\'ll sign it.\" So she did, and he asked her, and she said yes. And once they were engaged he told her a secret about himself that she never knew: he was a millionaire. ALABAMA So he really loved her? Uh-huh.', 'gold_tag': \"CLARENCE is knowledgeable about a certain unnamed woman's tragic story , CLARENCE is open and candid, sharing personal insecurities and thoughts , ALABAMA is understanding and empathetic towards CLARENCE , ALABAMA asks questions and shows interest\", 'last_speaker': 'CLARENCE'}\n",
      "Last word -> CLARENCE : \"That's what happened. In fact, when she died, it was considered to be the happiest time of her life. She'd been fucked over so much by men she didn't trust them. She was havin' this relationship with this guy and he asked her to marry him. Now, other people had asked to marry her before, but she couldn't be sure whether they really loved her or were just after her money. So, she said no. And the guy says, \"Look, I really love you, and I wanna prove it. So have your lawyers draw up a paper that says no matter what happens, I can never get any of your money, and I'll sign it.\" So she did, and he asked her, and she said yes. And once they were engaged he told her a secret about himself that she never knew: he was a millionaire. ALABAMA So he really loved her? Uh-huh.\"\n",
      "prediction :  Yeah. She got a bad batch.\n",
      "Real answer : That's what happened. In fact, when she died, it was considered to be the happiest time of her life. She'd been fucked over so much by men she didn't trust them. She was havin' this relationship with this guy and he asked her to marry him. Now, other people had asked to marry her before, but she couldn't be sure whether they really loved her or were just after her money. So, she said no. And the guy says, \"Look, I really love you, and I wanna prove it. So have your lawyers draw up a paper that says no matter what happens, I can never get any of your money, and I'll sign it.\" So she did, and he asked her, and she said yes. And once they were engaged he told her a secret about himself that she never knew: he was a millionaire. ALABAMA So he really loved her? Uh-huh.\n",
      "Bert Score : {'precision': [0.8858315944671631], 'recall': [0.7967126369476318], 'f1': [0.8389119505882263], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.024242424242424246, 'rouge2': 0.0, 'rougeL': 0.024242424242424246, 'rougeLsum': 0.024242424242424246}\n",
      "bleu 1/2 : 7.632449485485177e-12 1.8695606727006685e-12\n",
      "ppl : 179.1630559071391\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLARENCE: What\\'s wrong, sweetheart? Did I do something? What did I do?\\nALABAMA: You didn\\'t do nothing.\\nCLARENCE: Did you hurt yourself? Whatd\\'ya do? Step on a thumbtack?\\nALABAMA: Clarence, I\\'ve got something to tell you. I didn\\'t just happen to be at the theater. I was paid to be there.\\nCLARENCE: What are you, a theater checker? You check up on the box office girls. Make sure they\\'re not rippin\\' the place off.\\nALABAMA: I\\'m not a theater checker. I\\'m a call girl.\\nCLARENCE: You\\'re a whore?\\nALABAMA: I\\'m a call girl. There\\'s a difference, ya know. I don\\'t know. Maybe there\\'s not. That place you took me to last night, that\\nCLARENCE: \"Heroes For Sale\"?\\nALABAMA: Yeah, that one. Somebody who works there arranged to have me meet you.\\nCLARENCE: Who?\\nALABAMA: I don\\'t know. I didn\\'t talk with them. The plan was for me to bump into you, pick you up, spend the night, and skip out after you fell asleep. I was gonna write you a note and say that this was my last day in America. That I was leaving on a plane this morning up to Ukraine to marry a rich millionaire, and thank you for making my last day in America my best day.\\nCLARENCE: That dazzling imagination.\\nALABAMA: him know what\\'s what, and if he tells you to go fuck yourself then go back to Drexl and fuck yourself.\"\\nCLARENCE: Who and what is a Drexl?\\nALABAMA: My pimp.\\nCLARENCE: You have a pimp?\\nALABAMA: Uh-huh.\\nCLARENCE: A real live pimp?\\nALABAMA: Uh-huh.\\nCLARENCE: Is he black?\\nALABAMA: He thinks he is. He says his mother was Apache, but I suspect he\\'s lying.\\nCLARENCE: Is he nice?\\nALABAMA: Well, I wouldn\\'t go so far as to call him nice, but he\\'s treated me pretty decent. But I\\'ve only been there about four days. He got a little rough with Arlene the other day.\\nCLARENCE: What did he do to Arlene?\\nALABAMA: Slapped her around a little. Punched her in the stomch. It was pretty scary.\\nCLARENCE: This motherfucker sounds charming! Goddamn it, Alabama, you gotta get the fuck outta there! How much longer did you get hooked up with a douche-bag like this in the first place?\\nALABAMA: At the bus station. He said I\\'d be a perfect call girl. And that he knew an agency in California that, on his recommendation, would handle me. They have a very exclusive clientele: movie stars, big businessmen, total white-collar. And all the girls in the agency get a grand a night. At least five hundred. They drive Porsches, live in condos, have stockbrokers, carry beepers, you know, like Nancy Allen in \"Dressed to Kill\". And when I was ready he\\'d call \\'em, give me a plane ticket, and send me on my way. He says he makes a nice finder\\'s fee for finding them hot prospects. But no one\\'s gonna pay a grand a night for a girl who doesn\\'t know whether to shit or wind her watch. So what I\\'m doin\\' for Drexl now is just sorta learnin\\' the ropes. It seemed like a lotta fun, but I don\\'t really like it much, till last night. You were only my third trick, but you didn\\'t feel like a trick. Since it was a secret, I just pretended I was on a date. An, um, I guess I want a second date.\\nCLARENCE: Thank you. I wanna see you again too. And again, and again, and again. Bama, I know we haven\\'t known each other long, but my parents went together all throughout high school, and they still got a divorce. So, fuck it, you wanna marry me?\\nALABAMA: What?\\nCLARENCE: Will you be my wife?\\nALABAMA: Yes.\\nCLARENCE: You will?\\nALABAMA: You better not be fucking teasing me.\\n\\n', 'answer': \"You better not be fuckin' teasin' me. They seal it with a kiss.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'CLARENCE'}\n",
      "Last word -> CLARENCE : \"You better not be fuckin' teasin' me. They seal it with a kiss.\"\n",
      "prediction :  I'm not. I'm serious.\n",
      "Real answer : You better not be fuckin' teasin' me. They seal it with a kiss.\n",
      "Bert Score : {'precision': [0.8748049736022949], 'recall': [0.8383311629295349], 'f1': [0.8561797738075256], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473684, 'rouge2': 0.0, 'rougeL': 0.10526315789473684, 'rougeLsum': 0.10526315789473684}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 43.036300315303365\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLARENCE: Sweetheart, write down your former address.\\nALABAMA: What?\\nCLARENCE: Write down Drexl's address.\\nALABAMA: Why?\\nCLARENCE: So I can go over there and pick up your things.\\nALABAMA: No, Clarence. Just forget it, babe. I just wanna disappear from there.\\nCLARENCE: Look, sweetheart, he scares you. But I'm not scared of that motherfucker. He can't touch you now. You're completely out of his reach. He poses absolutely no threat to us. So, if he doesn't matter, which he doesn't, it would be stupid to lose your things, now wouldn't it?\\nALABAMA: You don't know him -\\n\\n\", 'answer': \"You don't know me. Not when it comes to shit like this. I have to do this. I need for you to know you can count on me to protect you. Now write down the address.\", 'gold_tag': 'CLARENCE is determined, fearless, and protective , CLARENCE desires to reassure ALABAMA of her safety', 'last_speaker': 'CLARENCE'}\n",
      "Last word -> CLARENCE : \"You don't know me. Not when it comes to shit like this. I have to do this. I need for you to know you can count on me to protect you. Now write down the address.\"\n",
      "prediction :  I know he's a scumbag, but that's not important right now. What's important is that you're safe and that you've got your things. So, what do you say?\n",
      "Real answer : You don't know me. Not when it comes to shit like this. I have to do this. I need for you to know you can count on me to protect you. Now write down the address.\n",
      "Bert Score : {'precision': [0.8488595485687256], 'recall': [0.8616417646408081], 'f1': [0.8552029132843018], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22857142857142856, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.10735389901075512 0.017285619952635844\n",
      "ppl : 6.83634757466191\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLARENCE: I killed him. Help yourself. I got enough. I am fuckin\\' starvin\\'. I think I ordered one of everythin\\'. I am so hungry.\\nALABAMA: Was it him or you?\\nCLARENCE: Yeah. But to be honest, I put myself in that position. When I drove up there I said to myself, \"If I can kill \\'em and get away with it, I\\'ll do it.\" I could. So I did.\\nALABAMA: Is this a joke?\\nCLARENCE: No joke. This is probably the best hamburger I\\'ve ever had. I\\'m serious, I\\'ve never had a hamburger taste this good. Come on, Bama, eat something. You\\'ll feel better. Why are you crying? He\\'s not worth one of your tears. Would you rather it had been me? Do you love him? Do you love him? Do you love him?\\nALABAMA: I think what you did was...\\nCLARENCE: What?\\nALABAMA: I think what you did...\\nCLARENCE: What?\\nALABAMA: ... was so romantic.\\nCLARENCE: I gotta get outta these clothes.\\n\\n', 'answer': \"Clean clothes. There is a god, Clarence. Those aren't my clothes.\", 'gold_tag': 'ALABAMA expresses her belief in God', 'last_speaker': 'ALABAMA'}\n",
      "Last word -> ALABAMA : \"Clean clothes. There is a god, Clarence. Those aren't my clothes.\"\n",
      "prediction :  I think it's so romantic because he was your brother.\n",
      "Real answer : Clean clothes. There is a god, Clarence. Those aren't my clothes.\n",
      "Bert Score : {'precision': [0.845252275466919], 'recall': [0.8617055416107178], 'f1': [0.8533996343612671], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 56.15034243233301\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALABAMA: You did it, Quickdraw. I\\'m so proud of you. You were like a ninja. Did I do my part OK?\\nCLARENCE: Babalouey, you were perfect, I could hardly keep from busting up. You were chillin\\', kind of creepy even. You totally fucked with his head. I\\'m gonna go grab dinner.\\nALABAMA: I\\'m gonna hop in the tub and get all wet, and slippery, and soapy. Then I\\'m gonna lie in the waterbed, not even both to dry off, and watch X-rated movies till you get your ass back to my lovin\\' arms.\\nCLARENCE: We now return to \"Bullit\" already in progress.\\n\\n', 'answer': 'Thank you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ALABAMA'}\n",
      "Last word -> ALABAMA : \"Thank you.\"\n",
      "prediction :  Hey, you got a great show here, man.\n",
      "Real answer : Thank you.\n",
      "Bert Score : {'precision': [0.8537693619728088], 'recall': [0.8999382257461548], 'f1': [0.8762460350990295], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 27.53864093187021\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLARENCE: Ya know, I used to fuckin\\' hate airports.\\nALABAMA: Really?\\nCLARENCE: With a vengeance, I hated them.\\nALABAMA: How come?\\nCLARENCE: I used to live by one back in Dearborn. It\\'s real frustratin\\' to be surrounded by airplanes when you ain\\'t got shit. I hated where I was, but I couldn\\'t do anythin\\' about it. I didn\\'t have enough money. It was tough enough just tryin\\' to pay my rent every month, an\\' here I was livin\\' next to an airport. Whenever I went outside, I saw fuckin\\' planes take off drownin\\' out my show. All day long I\\'m seein\\', hearin\\' people doin\\' what I wanted to do most, but couldn\\'t. ALABAMA What? Leavin\\' Detroit. Goin\\' off on vacations, startin\\' new lives, business trips. Fun, fun, fun, fun. But knowin\\' me and you gonna be nigger-rich gives me a whole new outlook. I love airports now. Me \\'n\\' you can get on any one of those planes out there, and go anywhere we ant.\\nALABAMA: You ain\\'t kiddin\\', we got lives to start over, we should go somewhere where we can really start from scatch.\\nCLARENCE: other countries is like. Besides, it\\'s more dramatic. Where should we fly off to, my little turtledove? ALABAMA Why Cancoon?\\nALABAMA: It\\'s got a nice ring to it. It sounds like a movie. \"Clarence and Alabama Go to Cancoon\". Don\\'t \\'cha think?\\n\\n', 'answer': \"But in my movie, baby, you get the top billing. Don't you worry 'bout anything. It's all gonna work out for us. We deserve it.\", 'gold_tag': 'ALABAMA fantasizes their life as a movie , CLARENCE reassures ALABAMA of her importance , CLARENCE has a positive, hopeful outlook on life', 'last_speaker': 'CLARENCE'}\n",
      "Last word -> CLARENCE : \"But in my movie, baby, you get the top billing. Don't you worry 'bout anything. It's all gonna work out for us. We deserve it.\"\n",
      "prediction :  Yeah, I think.\n",
      "Real answer : But in my movie, baby, you get the top billing. Don't you worry 'bout anything. It's all gonna work out for us. We deserve it.\n",
      "Bert Score : {'precision': [0.8490570187568665], 'recall': [0.821359395980835], 'f1': [0.8349785804748535], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 123.7163266712695\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALABAMA: Sweety?\\n\\n', 'answer': \"I... I can't see you... I've got blood in my eyes...\", 'gold_tag': \"CLARENCE has been involved in a violent incident , CLARENCE's vision is temporarily impaired due to blood in his eyes\", 'last_speaker': 'CLARENCE'}\n",
      "Last word -> CLARENCE : \"I... I can't see you... I've got blood in my eyes...\"\n",
      "prediction :  Yeah?\n",
      "Real answer : I... I can't see you... I've got blood in my eyes...\n",
      "Bert Score : {'precision': [0.863537073135376], 'recall': [0.7937507629394531], 'f1': [0.8271746039390564], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 4743.506449578175\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLARRY: Poor Capa ! You're here for me to pity you.\\nBILL: Hell, yes. It doesn't take Sigmund Freud to figure out I don't care to see the color of my patients' blood.\\nLARRY: I'm a little surprised that this happened to you.\\nBILL: Sure. You always thought I was a cold-hearted son of a bitch.\\nLARRY: Not really, but there is a kind of arrogance here. Bill laughs. Do you really believe that you're responsible for her illness. You were a small recent part of her life.\\nBILL: Yes, that's right, that's right. But it's all too fucking glib for me, Larry. I cannot dispose of this woman that\\nLARRY: Well, you always were a romantic. Are you involved with anyone else ?\\nBILL: No. I am still a romantic. I just don't have anybody to be romantic with. They want to fuck me or marry me... None of them want to love me\\nLARRY: Maybe you don't want to be loved. You had a happy marriage once.\\nBILL: She loved me to death. Then she ran off and loved somebody else to death.\\nLARRY: Of course, there is something else here. To deny red is to deny emotion.\\nBILL: Oh yeah !\\nLARRY: As you know, that could be very dangerous.\\nBILL: Yes, yes, I know. Very dangerous. I know and I have got something broken. I know it's gonna take some time to get fixed.\\nLARRY: You're a pretty good therapist. How long does it take a man like you to forgive himself.\\nBILL: I see you when I get back from Los Angeles.\\nLARRY: Don't run away because of one treatment failure.\\n\\n\", 'answer': \"I'm not running away, Larry, it's just a little trip to Los Angeles. Besides, you can't really run away. It's all up here, isn't it...\", 'gold_tag': \"BILL and LARRY appear to have a past of working together or knowing each other professionally, shown through their knowledge of each other's personality traits and past experiences.\", 'last_speaker': 'BILL'}\n",
      "Last word -> BILL : \"I'm not running away, Larry, it's just a little trip to Los Angeles. Besides, you can't really run away. It's all up here, isn't it...\"\n",
      "prediction :  I'm not running away, Larry. I'm going to be a doctor.\n",
      "Real answer : I'm not running away, Larry, it's just a little trip to Los Angeles. Besides, you can't really run away. It's all up here, isn't it...\n",
      "Bert Score : {'precision': [0.9418252110481262], 'recall': [0.8843061327934265], 'f1': [0.91215980052948], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.37209302325581395, 'rouge2': 0.2439024390243903, 'rougeL': 0.32558139534883723, 'rougeLsum': 0.32558139534883723}\n",
      "bleu 1/2 : 0.15276368772089932 0.11329258297588879\n",
      "ppl : 21.28986959604907\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBILL: I don't think she is a sociopath.\\nLARRY: Well, then how about something simple and snappy like a multiple personality disorder ? You've fallen into a trap. You are not well. She is not well. And to you, Iit feels like a bond.\\nBILL: She's been acting this thing out as if... it's the only way for her to have a life.\\n\\n\", 'answer': 'Or lives.', 'gold_tag': 'Everyday Language', 'last_speaker': 'LARRY'}\n",
      "Last word -> LARRY : \"Or lives.\"\n",
      "prediction :  You can't get out of it because it's all she's got.\n",
      "Real answer : Or lives.\n",
      "Bert Score : {'precision': [0.8330737948417664], 'recall': [0.9072329998016357], 'f1': [0.8685733079910278], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.961583206012577\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLARRY: You really want to go on seeing her, do you ?\\nBILL: Yes, I want to see her.\\nLARRY: In a, a nonprofessional sense ?\\nBILL: In every sense.\\nLARRY: I don't have your magical tuning fork. All I know is that two people are dead... and she seems an excellent suspect. Bill, salmon swim upstream to mate and die. And so do men.\\n\\n\", 'answer': \"Is that what I'm doing?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'BILL'}\n",
      "Last word -> BILL : \"Is that what I'm doing?\"\n",
      "prediction :  I'm not going to die.\n",
      "Real answer : Is that what I'm doing?\n",
      "Bert Score : {'precision': [0.8818420767784119], 'recall': [0.8574235439300537], 'f1': [0.8694613575935364], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.20000000000000004, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0.2 0.07071067811865477\n",
      "ppl : 40.547112941745155\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRENTON: Sorry.\\n\\n', 'answer': 'Shut up.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DIANE'}\n",
      "Last word -> DIANE : \"Shut up.\"\n",
      "prediction :  What?\n",
      "Real answer : Shut up.\n",
      "Bert Score : {'precision': [0.8712714910507202], 'recall': [0.9019601345062256], 'f1': [0.8863502144813538], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIANE: Right. You can't sleep here.\\nRENTON: What? Come on.\\n\\n\", 'answer': \"No argument. You can sleep on the sofa in the living room, or go And don't make any noise.\", 'gold_tag': 'DIANE is assertive , DIANE commands authority in her own space', 'last_speaker': 'DIANE'}\n",
      "Last word -> DIANE : \"No argument. You can sleep on the sofa in the living room, or go And don't make any noise.\"\n",
      "prediction :  I'm sorry. You're not allowed to sleep in the office.\n",
      "Real answer : No argument. You can sleep on the sofa in the living room, or go And don't make any noise.\n",
      "Bert Score : {'precision': [0.8953796029090881], 'recall': [0.8716424703598022], 'f1': [0.8833515644073486], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.06666666666666667, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0.12197089792217974 0.07422912461237537\n",
      "ppl : 19.01925213561609\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIANE: I don't see why not.\\nRENTON: Because it's illegal. No, not holding hands.\\nDIANE: In that case you can do it. You were quite happy to do a lot more\\nRENTON: And that's what's illegal. Do you know what they do to people like me inside? They'd cut my balls off and flush them down the fucking toilet. Easy for you to say.\\nDIANE: Can I see you again?\\nRENTON: Certainly not.\\n\\n\", 'answer': \"If you don't see me again I'll tell the police.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'DIANE'}\n",
      "Last word -> DIANE : \"If you don't see me again I'll tell the police.\"\n",
      "prediction :  I understand.\n",
      "Real answer : If you don't see me again I'll tell the police.\n",
      "Bert Score : {'precision': [0.8828600645065308], 'recall': [0.8376586437225342], 'f1': [0.8596656322479248], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 524.1272433307118\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIANE: Are you clean?\\nRENTON: Yes.\\nDIANE: Is that a promise, then?\\nRENTON: Yes, as a matter of fact, it is. No.\\nDIANE: I wouldn't mind a bit, if it is. Smells like it.\\nRENTON: You're too young.\\n\\n\", 'answer': 'Too young for what?', 'gold_tag': 'DIANE is young, possibly under the age of consent', 'last_speaker': 'DIANE'}\n",
      "Last word -> DIANE : \"Too young for what?\"\n",
      "prediction :  What?\n",
      "Real answer : Too young for what?\n",
      "Bert Score : {'precision': [0.8754522204399109], 'recall': [0.845608115196228], 'f1': [0.8602714538574219], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4, 'rouge2': 0.0, 'rougeL': 0.4, 'rougeLsum': 0.4}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIANE: Whatever. I mean, the guy's dead anyway.\\n\\n\", 'answer': 'She was right. I had to find something new. There was only one thing for it.', 'gold_tag': \"RENTON is in a state of transition , RENTON has to find 'something new' , Finding 'something new' implies adaptability or a search for change , RENTON's temporal information\", 'last_speaker': 'RENTON'}\n",
      "Last word -> RENTON : \"She was right. I had to find something new. There was only one thing for it.\"\n",
      "prediction :  Yeah. I guess so.\n",
      "Real answer : She was right. I had to find something new. There was only one thing for it.\n",
      "Bert Score : {'precision': [0.8439633250236511], 'recall': [0.8293851613998413], 'f1': [0.8366107940673828], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1, 'rouge2': 0.0, 'rougeL': 0.1, 'rougeLsum': 0.1}\n",
      "bleu 1/2 : 0.012446767091965986 0.0045449167361884995\n",
      "ppl : 87.97730774073396\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIANE: Unless you get caught.\\nRENTON: So long as everyone keeps their mouths shut, we'll not be getting caught.\\nDIANE: So why have you told me about it?\\nRENTON: Well, you're not going to tell anyone, are you, and besides, I thought we could meet up afterwards, maybe go somewhere together.\\nDIANE: I've got a boyfriend, Mark.\\nRENTON: What? Steady like? And what age are you? Thirteen? Fourteen? Happy birthday.\\n\\n\", 'answer': \"And you're such a deadbeat, Mark.\", 'gold_tag': \"DIANE views RENTON as a 'deadbeat'\", 'last_speaker': 'DIANE'}\n",
      "Last word -> DIANE : \"And you're such a deadbeat, Mark.\"\n",
      "prediction :  I'm sixteen.\n",
      "Real answer : And you're such a deadbeat, Mark.\n",
      "Bert Score : {'precision': [0.8983256816864014], 'recall': [0.8674731254577637], 'f1': [0.8826298713684082], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 139.60000992776878\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADELE: My daddy always took sauerkraut juice and tobasco sauce for a hangover, mixed in one egg not two, and some tomato juice...\\n\\n', 'answer': \"I'm okay, thanks.\", 'gold_tag': 'BRIAN is currently experiencing a hangover , BRIAN prefers to not use remedies , BRIAN is suffering from a hangover in the present', 'last_speaker': 'BRIAN'}\n",
      "Last word -> BRIAN : \"I'm okay, thanks.\"\n",
      "prediction :  You know what, Adelle?\n",
      "Real answer : I'm okay, thanks.\n",
      "Bert Score : {'precision': [0.8108888268470764], 'recall': [0.8791037797927856], 'f1': [0.8436195850372314], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 116.75447025838452\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRIAN: Adele, what are you doing back here?\\n\\n', 'answer': \"...Lost my purse... Could you help me look for it? It's probably under the seat.\", 'gold_tag': 'ADELE lost her purse , ADELE may be a bit scatterbrained , BRIAN is caring and concerned about ADELE', 'last_speaker': 'ADELE'}\n",
      "Last word -> ADELE : \"...Lost my purse... Could you help me look for it? It's probably under the seat.\"\n",
      "prediction :  I'm sorry, Brian. I didn't mean to scare you.\n",
      "Real answer : ...Lost my purse... Could you help me look for it? It's probably under the seat.\n",
      "Bert Score : {'precision': [0.8639551401138306], 'recall': [0.8467438220977783], 'f1': [0.8552628755569458], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07407407407407407, 'rouge2': 0.0, 'rougeL': 0.07407407407407407, 'rougeLsum': 0.07407407407407407}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.057567240147034\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADELE: ...You can forget about 'em forever and then look at 'em and they're doin' even better than before.\\nBRIAN: Adele... we gotta do something before Early kills someone else.\\nADELE: ...There ain't nothin' can kill 'em. They can live for two even three hundred years.\\nBRIAN: Adele for god sake please lis...\\n\\n\", 'answer': \"There ain't nothing we could do. Once Early sets his mind on somethin', well thats the end of that.\", 'gold_tag': 'ADELE is possibly submissive and fearful', 'last_speaker': 'ADELE'}\n",
      "Last word -> ADELE : \"There ain't nothing we could do. Once Early sets his mind on somethin', well thats the end of that.\"\n",
      "prediction :  I can't listen. I can't listen to this.\n",
      "Real answer : There ain't nothing we could do. Once Early sets his mind on somethin', well thats the end of that.\n",
      "Bert Score : {'precision': [0.8730834126472473], 'recall': [0.8352614045143127], 'f1': [0.8537537455558777], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06666666666666667, 'rouge2': 0.0, 'rougeL': 0.06666666666666667, 'rougeLsum': 0.06666666666666667}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.482060684710998\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZAKAR: It is an honour, Miss Williams. I understand you make a delightful Queen Meander.\\nSARAH: Well, we've just started rehearsal, but how did you know?\\nZAKAR: I was passing through this part of the country and heard that it was going to be done here. This is the first amateur production of the play, which of course is delightful for me.\\nSARAH: You know we were supposed to open tonight, but we got delayed. The firemen had to use the hall.\\nZAKAR: Yes, I know, that's why I wanted to stop by to see you.\\n\\n\", 'answer': \"That's my brother... I'll be right back!\", 'gold_tag': 'SARAH has a brother', 'last_speaker': 'SARAH'}\n",
      "Last word -> SARAH : \"That's my brother... I'll be right back!\"\n",
      "prediction :  Can you help us?\n",
      "Real answer : That's my brother... I'll be right back!\n",
      "Bert Score : {'precision': [0.8487639427185059], 'recall': [0.80843186378479], 'f1': [0.8281071186065674], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 126.92864379376391\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSARAH: Maybe you'd better leave...... I, uh, don't think I care to talk to you about the play.\\nZAKAR: Neither do I.\\nSARAH: What!\\nZAKAR: I'm more concerned about the baby, of course.\\nSARAH: Freddie's just fine.\\nZAKAR: There, isn't that better?\\nSARAH: Uh, sure... but you really have to leave...\\nZAKAR: I'm not just a playwright, as you can see... bring him in here and I'll do some other tricks for him...\\n\\n\", 'answer': \"No! You've got to...\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SARAH'}\n",
      "Last word -> SARAH : \"No! You've got to...\"\n",
      "prediction :  I can't do that...\n",
      "Real answer : No! You've got to...\n",
      "Bert Score : {'precision': [0.8700405955314636], 'recall': [0.8486282229423523], 'f1': [0.8592010736465454], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 60.753453066348\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZAKAR: Now watch this, Freddie... So you're going to be like that, are you, Freddie? Well, you know what that means? It's time to call the goblins!\\nSARAH: What?!!\\nZAKAR: Yes. That's what we do with bad babies... we send for the goblins!! You like goblins, don't'cha, Freddie? But I bet your sister doesn't...\\nSARAH: Where is it?!!!\\nZAKAR: It's in there.\\nSARAH: Impossible!\\nZAKAR: See for yourself.\\nSARAH: How did you do that?!!\\nZAKAR: Magic.\\nSARAH: Oh sure... Where's Freddie?!! Freddie? Where is he?!! Who are you?!!!\\nZAKAR: I've been known by many names... but the one I prefer is Jareth, King of the Goblins!!!\\n\\n\", 'answer': \"I don't believe this!\", 'gold_tag': 'SARAH is startled and disbelieving', 'last_speaker': 'SARAH'}\n",
      "Last word -> SARAH : \"I don't believe this!\"\n",
      "prediction :  What is this place?\n",
      "Real answer : I don't believe this!\n",
      "Bert Score : {'precision': [0.8749618530273438], 'recall': [0.8565101623535156], 'f1': [0.8656377196311951], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.22222222222222224, 'rougeLsum': 0.22222222222222224}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 106.19054158697512\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEVELYN: Whatever you're trying to tell me isn't good, is it. Or it wouldn't be so hard to say.\\nRAFE: The only reason it's hard to say is that I keep thinking I don't have the right to say it. But I've got to because it's true. I love you. That must surprise you.\\nEVELYN: It surprises me that I'm not the only one on this balcony who feels that way.\\nRAFE: There's one thing I have to say. I'm going away.\\nEVELYN: We're all going away.\\nRAFE: I'm going to the war. The real war. Hitler's taken Europe. The Brits are hanging on by their fingernails, and If they lose, there'll be more people killed than anybody can imagine. And not just there, but here.\\nEVELYN: But you're in the U.S. Army, how could you --\\nRAFE: Colonel Doolittle pulled the strings, and put me on loan to the R.A.F. They need pilots, and we need experience. I leave tomorrow.\\nEVELYN: You waited til tonight to tell me?\\nRAFE: I had to tell you in person. Because there's something else I need to say. Evelyn...you know the line -- let's make tonight memorable. What I feel about you makes it impossible for me to say something like that. If I don't come back, I don't want to saddle you with regret and sadness you'll carry the rest of your life.\\nEVELYN: I don't know if you can choose that,\\nRAFE: Maybe not. But I need you to know. I love you. And I will come back. I'll find a way. And then we'll get a chance to know if what I felt the first moment I saw you, and every minute since then, is real.\\n\\n\", 'answer': 'Do one thing for me, before you go.', 'gold_tag': 'Everyday Language', 'last_speaker': 'EVELYN'}\n",
      "Last word -> EVELYN : \"Do one thing for me, before you go.\"\n",
      "prediction :  What made you think that?\n",
      "Real answer : Do one thing for me, before you go.\n",
      "Bert Score : {'precision': [0.8255239725112915], 'recall': [0.8235448002815247], 'f1': [0.824533224105835], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615385, 'rouge2': 0.0, 'rougeL': 0.15384615384615385, 'rougeLsum': 0.15384615384615385}\n",
      "bleu 1/2 : 0.10976232721880529 0.03880684294761699\n",
      "ppl : 86.38612034392276\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRAFE: What else can we do?\\n\\n', 'answer': \"There's nothing you can do here, they'll die or they won't, we just -- There was a sailor, a black man on the West Virginia, named Dorie Miller. I'd like to know if he's alive.\", 'gold_tag': 'Evelyn is likely involved in medical care or emergency response , Evelyn has knowledge of patient outcomes , Evelyn has an interest in the welfare of a specific sailor', 'last_speaker': 'EVELYN'}\n",
      "Last word -> EVELYN : \"There's nothing you can do here, they'll die or they won't, we just -- There was a sailor, a black man on the West Virginia, named Dorie Miller. I'd like to know if he's alive.\"\n",
      "prediction :  I don't know. It's not like we can just go back in time.\n",
      "Real answer : There's nothing you can do here, they'll die or they won't, we just -- There was a sailor, a black man on the West Virginia, named Dorie Miller. I'd like to know if he's alive.\n",
      "Bert Score : {'precision': [0.8614081144332886], 'recall': [0.8346749544143677], 'f1': [0.8478308320045471], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2962962962962963, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0.056644369431785885 0.009321972212670037\n",
      "ppl : 9.894125190747012\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRAFE: What?...\\nEVELYN: They were bringing back a ship full of wounded and needed extra nurses along. I wrote Colonel Doolittle, and told him I needed to see you before you go.\\nRAFE: It must of been a convincing letter.\\nEVELYN: It was. I couldn't have you go away, wherever it is...to war...without knowing something. You think I made a choice, of Danny over you. I didn't. I didn't have a choice. I'm pregnant.\\nRAFE: Does Danny know?\\n\\n\", 'answer': \"I wasn't sure, until the day you turned up alive. I never had a chance to tell him. Now I can't have him thinking about this when he needs to be thinking about his mission, and how to come back from it. I want you thinking about that too. Just come back. Rafe, I see it in your face. You're thinking you don't have anything to live for. Don't you dare think that way. I'll never write a letter, or look at a sunset, without thinking of you. I'll love you my whole life. And I want you to live.\", 'gold_tag': \"EVELYN is caring and considerate , RAFE has strong feelings for EVELYN , RAFE's temporal information - RAFE is about to go to war\", 'last_speaker': 'EVELYN'}\n",
      "Last word -> EVELYN : \"I wasn't sure, until the day you turned up alive. I never had a chance to tell him. Now I can't have him thinking about this when he needs to be thinking about his mission, and how to come back from it. I want you thinking about that too. Just come back. Rafe, I see it in your face. You're thinking you don't have anything to live for. Don't you dare think that way. I'll never write a letter, or look at a sunset, without thinking of you. I'll love you my whole life. And I want you to live.\"\n",
      "prediction : No...No...I was afraid to tell him. I didn't want to hurt him. I know you're going away, and I'm going to stay here, and I know it's wrong, but I couldn't help myself. I love you, Rafe.\n",
      "Real answer : I wasn't sure, until the day you turned up alive. I never had a chance to tell him. Now I can't have him thinking about this when he needs to be thinking about his mission, and how to come back from it. I want you thinking about that too. Just come back. Rafe, I see it in your face. You're thinking you don't have anything to live for. Don't you dare think that way. I'll never write a letter, or look at a sunset, without thinking of you. I'll love you my whole life. And I want you to live.\n",
      "Bert Score : {'precision': [0.8792387247085571], 'recall': [0.8497340679168701], 'f1': [0.8642346262931824], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3178807947019867, 'rouge2': 0.06711409395973154, 'rougeL': 0.19867549668874174, 'rougeLsum': 0.19867549668874174}\n",
      "bleu 1/2 : 0.0640128613072905 0.02545424227665608\n",
      "ppl : 6.339905518240437\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKOENIG: Fritzie usually does the talking and I stand back up. Muscle job?\\n\\n', 'answer': \"Let's try talk job.\", 'gold_tag': 'BUCKY is willing to handle negotiations , BUCKY may have a background in diplomacy or possess solid communication skills', 'last_speaker': 'BUCKY'}\n",
      "Last word -> BUCKY : \"Let's try talk job.\"\n",
      "prediction :  Well, we've been working this case for a long time.\n",
      "Real answer : Let's try talk job.\n",
      "Bert Score : {'precision': [0.8597521781921387], 'recall': [0.862978458404541], 'f1': [0.8613622784614563], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.987871341113387\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKOENIG: I'm bored.\\nBUCKY: This'll just take a minute.\\nKOENIG: I'm gonna take those two guys outside. Maybe they knew the cooze--\\nBUCKY: I'll handle 'em Sarge--\\nKOENIG: No! I'm gonna do it! (beat) Now what do I roust 'em about?\\n\\n\", 'answer': \"I dunno. Ask 'em anything. Alibis. See if Betty ever engaged in prostitution...\", 'gold_tag': 'Bucky is capable of handling situations', 'last_speaker': 'BUCKY'}\n",
      "Last word -> BUCKY : \"I dunno. Ask 'em anything. Alibis. See if Betty ever engaged in prostitution...\"\n",
      "prediction :  I don't know. Just don't be too hard on 'em.\n",
      "Real answer : I dunno. Ask 'em anything. Alibis. See if Betty ever engaged in prostitution...\n",
      "Bert Score : {'precision': [0.8956857323646545], 'recall': [0.8728729486465454], 'f1': [0.8841321468353271], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16, 'rouge2': 0.0, 'rougeL': 0.16, 'rougeLsum': 0.16}\n",
      "bleu 1/2 : 0.07408182206817181 0.024693940689390605\n",
      "ppl : 23.310887731484303\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKOENIG: They didn't do it.\\n\\n\", 'answer': 'No shit Sherlock.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BUCKY'}\n",
      "Last word -> BUCKY : \"No shit Sherlock.\"\n",
      "prediction :  Who?\n",
      "Real answer : No shit Sherlock.\n",
      "Bert Score : {'precision': [0.8517944812774658], 'recall': [0.8495709300041199], 'f1': [0.8506811857223511], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3856.0021279346893\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVICTOR: I think I look younger, don't you?\\nALEX: You look ridiculous.\\nVICTOR: Fine. I don't have an ego. -- As long as I don't match my mug shots. You want to change your mind?\\nALEX: No.\\n\\n\", 'answer': 'After you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'VICTOR'}\n",
      "Last word -> VICTOR : \"After you.\"\n",
      "prediction :  You know, Alex, I'm very good at making things. I'm very good at making things.\n",
      "Real answer : After you.\n",
      "Bert Score : {'precision': [0.8270347714424133], 'recall': [0.8918423652648926], 'f1': [0.8582168817520142], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473684, 'rouge2': 0.0, 'rougeL': 0.10526315789473684, 'rougeLsum': 0.10526315789473684}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.381182093918808\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALEX: Can you fix the thing, Harold? Or does it have to be replaced?\\n\\n', 'answer': \"I'll tell you after I see the condition of the pipes. Coolant might be leaking. Where's the attic access?\", 'gold_tag': 'VICTOR is skilled in maintenance or repair work , VICTOR is particularly skilled with pipes , VICTOR potentially has skills with coolant , VICTOR will soon examine the pipes to determine whether they can be fixed or need to be replaced', 'last_speaker': 'VICTOR'}\n",
      "Last word -> VICTOR : \"I'll tell you after I see the condition of the pipes. Coolant might be leaking. Where's the attic access?\"\n",
      "prediction :  I can fix it.\n",
      "Real answer : I'll tell you after I see the condition of the pipes. Coolant might be leaking. Where's the attic access?\n",
      "Bert Score : {'precision': [0.9135410785675049], 'recall': [0.8578693866729736], 'f1': [0.8848304152488708], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0.005879436464002277 0.0021468666511683054\n",
      "ppl : 195.1810693717658\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALEX: What the fuck are you doing??\\nVICTOR: I always take a photograph of the goods. To avoid any disagreement in the sale. The insurance photo is hopeless. You ask yourself how do they stay in business.\\nALEX: You put me in the shot.\\nVICTOR: Speaking of insurance.\\nALEX: Give me the film, Victor._\\nVICTOR: We'll tear it up together whet. we have the money. Honor among thieves is a myth, you know.\\nALEX: What's this supposed to be?\\nVICTOR: I thought it over. I can't move it. I'm on parole. I'm known. You're not. So you'll fly to Newark, take a shuttle into the city, catch a cab, take a walk, find an address, I'll give you the name -- pas.de probleme, as they say in Bordeaux. He's being condescending.'\\nALEX: Meaning you're too chickenshit to do it yourself.\\nVICTOR: Maybe I am. All right, I am.\\n\\n\", 'answer': \"Fuck... I don't fly economy.\", 'gold_tag': 'ALEX dislikes flying economy class', 'last_speaker': 'ALEX'}\n",
      "Last word -> ALEX : \"Fuck... I don't fly economy.\"\n",
      "prediction :  You're just fuckin' with me.\n",
      "Real answer : Fuck... I don't fly economy.\n",
      "Bert Score : {'precision': [0.8478102684020996], 'recall': [0.8600678443908691], 'f1': [0.8538951277732849], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 20.8780464207193\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALEX: I'll fucking kill her.\\nVICTOR: When do the Reeses come home?\\nALEX: Not for a month. Plenty of time.\\nVICTOR: How long a drive is it?\\nALEX: To the Gulf? Three hours.\\nVICTOR: You're going to need stitches. Do you have a sewing kit?\\nALEX: I'll stop at my doctor's.\\n\\n\", 'answer': 'I darned my own socks in prison.', 'gold_tag': 'VICTOR has served some time in prison', 'last_speaker': 'VICTOR'}\n",
      "Last word -> VICTOR : \"I darned my own socks in prison.\"\n",
      "prediction :  You can't stop at your doctor's.\n",
      "Real answer : I darned my own socks in prison.\n",
      "Bert Score : {'precision': [0.8476275205612183], 'recall': [0.8573641777038574], 'f1': [0.8524680137634277], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 67.42257742829813\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVICTOR: I've called the whole network of fences from here to Tampa.\\nALEX: Let's hope we'll find her before she sells. Hey! What's wrong?\\nVICTOR: This is not a water-view suite in Marbella! Did you notice? There's no fruit and champagne from the management. I don't see Swiss chocolate on the pillows. My masseuse is not at the door. And I am fucking dying, Alex!\\nALEX: Jesus. Victor.\\nVICTOR: I don't intend to cough to death in a county clinic because you screwed up!\\nALEX: That's not fair. The plan was for you to move the necklace. I wouldn't have had the goddamn thing. Come on... sit down... try to relax.\\n\\n\", 'answer': \"I'm not good at giving up things.\", 'gold_tag': 'VICTOR is not good at giving up things', 'last_speaker': 'VICTOR'}\n",
      "Last word -> VICTOR : \"I'm not good at giving up things.\"\n",
      "prediction :  I can't relax! I can't relax!\n",
      "Real answer : I'm not good at giving up things.\n",
      "Bert Score : {'precision': [0.8537452220916748], 'recall': [0.8632262349128723], 'f1': [0.8584595322608948], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 27.214016600133405\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVICTOR: Oh, please. Why?\\nALEX: Just fucking say hello, okay?\\nVICTOR: Hello, dear.\\n\\n', 'answer': \"Happy? Satisfied? I'm working.\", 'gold_tag': 'ALEX is currently working', 'last_speaker': 'ALEX'}\n",
      "Last word -> ALEX : \"Happy? Satisfied? I'm working.\"\n",
      "prediction :  I mean, seriously, you're the one who's been avoiding me.\n",
      "Real answer : Happy? Satisfied? I'm working.\n",
      "Bert Score : {'precision': [0.8393527865409851], 'recall': [0.8515650033950806], 'f1': [0.8454148173332214], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.969349380022326\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALEX: Thanks, honey. I'll call-you tomorrow. G'd'night . And you had no faith..\\n\\n\", 'answer': \"I'll save the party hats until it's in our hands.\", 'gold_tag': \"VICTOR is waiting for a future event, specifically when something is in their hands , ALEX recalls VICTOR's lack of faith\", 'last_speaker': 'VICTOR'}\n",
      "Last word -> VICTOR : \"I'll save the party hats until it's in our hands.\"\n",
      "prediction :  That's right. You had no faith.\n",
      "Real answer : I'll save the party hats until it's in our hands.\n",
      "Bert Score : {'precision': [0.8684240579605103], 'recall': [0.8374187350273132], 'f1': [0.8526396751403809], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473685, 'rouge2': 0.0, 'rougeL': 0.10526315789473685, 'rougeLsum': 0.10526315789473685}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 78.68051554755922\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALEX: Smart lady. She lets Jason make the sale. They get caught, he's underage, and she don't know a thing. I gotta give her credit.\\n\\n\", 'answer': 'You have interesting taste in women.', 'gold_tag': \"VICTOR notes ALEX's taste in women\", 'last_speaker': 'VICTOR'}\n",
      "Last word -> VICTOR : \"You have interesting taste in women.\"\n",
      "prediction :  I can't believe you're so eager to get her in trouble.\n",
      "Real answer : You have interesting taste in women.\n",
      "Bert Score : {'precision': [0.8606195449829102], 'recall': [0.8819148540496826], 'f1': [0.8711370825767517], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.21052631578947367, 'rouge2': 0.0, 'rougeL': 0.21052631578947367, 'rougeLsum': 0.21052631578947367}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 19.289940825898174\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVICTOR: What a thrill.\\nALEX: Easy, easy -- he'll see us.\\n\\n\", 'answer': \"It's raining too hard.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'VICTOR'}\n",
      "Last word -> VICTOR : \"It's raining too hard.\"\n",
      "prediction :  I know.\n",
      "Real answer : It's raining too hard.\n",
      "Bert Score : {'precision': [0.8830438256263733], 'recall': [0.8608652353286743], 'f1': [0.8718134760856628], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 663.9337011017111\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVICTOR: Relax. She's not going anywhere.\\nALEX: I just need to talk to her.\\n\\n\", 'answer': 'Last time you talked, she almost crushed your skull.', 'gold_tag': \"VICTOR has knowledge about ALEX's past incident with the woman , Shared memories: VICTOR reminds ALEX of an incident when a woman, presumably the same one ALEX wants to talk to, almost crushed his skull.\", 'last_speaker': 'VICTOR'}\n",
      "Last word -> VICTOR : \"Last time you talked, she almost crushed your skull.\"\n",
      "prediction :  You're not going to get anywhere.\n",
      "Real answer : Last time you talked, she almost crushed your skull.\n",
      "Bert Score : {'precision': [0.8571056127548218], 'recall': [0.8590916395187378], 'f1': [0.8580974340438843], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 37.38943571273926\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVICTOR: We don't have much time.\\nALEX: We need to get some help!\\n\\n\", 'answer': \"Already on the way, I'm afraid. Open the trunk, please.\", 'gold_tag': 'VICTOR has already arranged for help , VICTOR anticipates a soon arrival of the help he enlisted , ALEX is in need of assistance immediately', 'last_speaker': 'VICTOR'}\n",
      "Last word -> VICTOR : \"Already on the way, I'm afraid. Open the trunk, please.\"\n",
      "prediction :  I'm trying.\n",
      "Real answer : Already on the way, I'm afraid. Open the trunk, please.\n",
      "Bert Score : {'precision': [0.8847365379333496], 'recall': [0.8604777455329895], 'f1': [0.8724385499954224], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.16666666666666669, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0.00915781944436709 0.004095501360654834\n",
      "ppl : 209.93309468344188\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALEX: ... I didn't mean for this to happen.\\n\\n\", 'answer': \"As soon as they see her license they'll call you in Miami.\", 'gold_tag': 'VICTOR expects a call as soon as her license is seen , VICTOR resides in Miami', 'last_speaker': 'VICTOR'}\n",
      "Last word -> VICTOR : \"As soon as they see her license they'll call you in Miami.\"\n",
      "prediction :  I know.\n",
      "Real answer : As soon as they see her license they'll call you in Miami.\n",
      "Bert Score : {'precision': [0.8822283148765564], 'recall': [0.8344182968139648], 'f1': [0.8576574921607971], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 663.9337011017111\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSALLY: We need to talk, Chief Garnett.\\nRED: Call me Red.\\nSALLY: Red. Why are you so hell-bent on embarassing me?\\nRED: I'm hell-bent on one thing. You hang around long enough you'll find that out. Til' then a tough backside and a sense of humor will get you through a lot.\\nSALLY: I have a fine sense of humor, but the one thing I won't do is be your straight man so you can play hero to a bunch of morons who think you're some kind of hillbilly Sherlock Holmes.\\nRED: Awful. Arthur Godfrey says it keeps ya'\\nSALLY: I'd like an answer.\\nRED: This yer' first time out of an office? Thought so. What'd ya' expect ya' signed on for?\\nSALLY: You think I'm what? Some dumb schoolgirl who wandered into the boy's locker room? Well you're wrong. I don't mean to boast, but I happen to be one of the two most intelligent people involved in this fiasco.\\nRED: Didn't ask that. Asked what you expected.\\nSALLY: I expected to be allowed to do the job assigned to me by the Governor.\\nRED: I happen to like the Governor, hunt quail together every year. But deep down he and I know that win, lose or draw this is my ship, not his.\\nSALLY: The Governor as chief executive officer of this state bears ultimate responsibility for...\\nRED: ... Bullshit. Responsibility lies with the one that loses sleep; the one with the most ulcers. This mess turns bloody -- and it might -- all it's gonna cost the Governor is a few votes! Me, I'm the one that's...\\nSALLY: You're the one that what?\\nRED: Tell ya' what. You think I'm makin' a wrong turn you speak up. Might not agree, but I'll listen. As far as stepped on toes and wounded pride, I'll buy everyone a drink when we head for home. Not until. I got more to worry about. That sound fair to you?\\nSALLY: Yes.\\nRED: Well okay then. So who's the other one?\\nSALLY: Other one?\\nRED: If yer' one brain, who's the other?\\n\\n\", 'answer': 'Haynes. He was tested in prison.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SALLY'}\n",
      "Last word -> SALLY : \"Haynes. He was tested in prison.\"\n",
      "prediction :  The other one is me.\n",
      "Real answer : Haynes. He was tested in prison.\n",
      "Bert Score : {'precision': [0.8543872833251953], 'recall': [0.8541423082351685], 'f1': [0.8542647957801819], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 173.73510224278743\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRED: Figger to give 'em another hour of\\nSALLY: Bring back any memories?\\nRED: Too many. They got a file on me, too?\\nSALLY: It's the 60's, Red. They've got a file on everybody.\\nRED: Just caus' it's written down don't make it true.\\nSALLY: You worked as County Sheriff in Amarillo and Austin before you became a Ranger. Right so far? Oh, and it says your name's Cecil.\\nRED: Yeah, well, that's definitely the worst of it.\\nSALLY: Strong... but good. So Cecil... Red. What do you do when you're not at work.\\nRED: The file don't tell ya' that, too?\\nSALLY: Nope.\\nRED: I got a ranch I never visit, nieces I hardly know, a tackle box full of dry lures and a dog that figures he's the owner and I'm the pet. Could have a point, he's there more.\\nSALLY: A confirmed bachelor. Any regrets?\\nRED: Liked to have wet those lures. Maybe a new dog. How'd you get into... whatever the hell it is you do?\\nSALLY: My father's defense lawyer.\\nRED: That explains your mouth.\\nSALLY: Instead of Home Ec, I studied Criminology. When I graduated, my father, with the Governor's help, they, he and my dad... I created a position for myself with the prison system.\\nRED: What's yer' husband think about all this?\\nSALLY: Don't own one.\\nRED: Yer' not careful you'll wind up jus' like me. Old, tired, with nobody around to love ya'.\\nSALLY: Maybe.\\nRED: It's crazy ain't it?\\nSALLY: What's that?\\nRED: Goin' without sleep chasin' after a three time loser and Casper the Friendly Ghost?\\nSALLY: Sleep? That's what retirement's for.\\nRED: Bite your tongue.\\nSALLY: You wanna' know what's really crazy? Hayne's juvenile court record lists you as Amicus Curiae. Silence save the CRICKETS. Friend of the court. Evidence given by a non-party with the intention of swaying usually in written form, but there's no copy attached. Okay, then at least tell me why Haynes got four years for a joyride? What about probation? The boy had a home, a father.\\nRED: What's your file say about him?\\nSALLY: That he was a petty thief who did a little time, got out and stayed pretty clean.\\nRED: There are murderers I'd trust with my mother and petty thieves I wouldn't turn my back on. Your precious files are wrong.\\nSALLY: I'm listening.\\nRED: Hayne's old man was a career criminal with a soft spot for whores. One way or the other he beat the hell outta' every person he ever crossed, screwed or fathered. Judge sends junior home with the old man and you can bet your last dollar that within a year he'll have a rap sheet as long as yer arm. I know kids who did Gatesville, made it through, shaped up. Hell, one's even a priest.\\nSALLY: Still, I don't understand from the file why...\\nRED: -- This job ain't about files and books and second guessin'. Ya get one shot and ya call 'em like you see 'em.\\nSALLY: I'm a bit confused...\\nRED: In Texas the bottom line is who ya' know and what they owe ya. That's how I do my job and how you got yours.\\nSALLY: What are you trying to say?\\n\\n\", 'answer': 'I bought the judge a T-bone and told him to send the boy up. Told him it was the right thing to do. He went along right down the line.', 'gold_tag': 'Everyday Language', 'last_speaker': 'RED'}\n",
      "Last word -> RED : \"I bought the judge a T-bone and told him to send the boy up. Told him it was the right thing to do. He went along right down the line.\"\n",
      "prediction :  I'm sayin' you gotta' know how to play the game.\n",
      "Real answer : I bought the judge a T-bone and told him to send the boy up. Told him it was the right thing to do. He went along right down the line.\n",
      "Bert Score : {'precision': [0.852454423904419], 'recall': [0.8480589389801025], 'f1': [0.8502510190010071], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.027067056647322542 0.006379766434027395\n",
      "ppl : 24.764156764590645\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSALLY: You did everything you could. You know that.\\n\\n', 'answer': \"I don't know nuthin'. Not a damn thing.\", 'gold_tag': 'RED feels uncertain about himself', 'last_speaker': 'RED'}\n",
      "Last word -> RED : \"I don't know nuthin'. Not a damn thing.\"\n",
      "prediction :  I should have been able\n",
      "Real answer : I don't know nuthin'. Not a damn thing.\n",
      "Bert Score : {'precision': [0.8411357998847961], 'recall': [0.8221619129180908], 'f1': [0.8315407037734985], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.10976232721880529 0.03880684294761699\n",
      "ppl : 207.42023116025604\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDRIVER: Damn! This defroster never works...\\nPRETTY TEENAGE GIRL: ...Mmm... feels good.\\nDRIVER: Have a problem with your car?\\n\\n', 'answer': \"No. My problem's with men.\", 'gold_tag': 'PRETTY TEENAGE GIRL has issues with men , PRETTY TEENAGE GIRL indicates a possible history of problematic relationships', 'last_speaker': 'PRETTY TEENAGE GIRL'}\n",
      "Last word -> PRETTY TEENAGE GIRL : \"No. My problem's with men.\"\n",
      "prediction :  It's not my car.\n",
      "Real answer : No. My problem's with men.\n",
      "Bert Score : {'precision': [0.874966561794281], 'recall': [0.885664701461792], 'f1': [0.8802831172943115], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3636363636363636, 'rouge2': 0.0, 'rougeL': 0.1818181818181818, 'rougeLsum': 0.1818181818181818}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 64.13808894366817\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDRIVER: ...sure.\\nPRETTY TEENAGE GIRL: My matches are all wet. You got a\\n\\n', 'answer': \"Yeah. It's here somewhere. It's my wife's car. Ah... there it is.\", 'gold_tag': \"DRIVER is married , DRIVER has access to his wife's car\", 'last_speaker': 'DRIVER'}\n",
      "Last word -> DRIVER : \"Yeah. It's here somewhere. It's my wife's car. Ah... there it is.\"\n",
      "prediction :  ...sure.\n",
      "Real answer : Yeah. It's here somewhere. It's my wife's car. Ah... there it is.\n",
      "Bert Score : {'precision': [0.8669410943984985], 'recall': [0.8457236289978027], 'f1': [0.8562009334564209], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1235.5615167006551\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPRETTY TEENAGE GIRL: What's the matter?\\n\\n\", 'answer': '...nothing.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DRIVER'}\n",
      "Last word -> DRIVER : \"...nothing.\"\n",
      "prediction :  I'm afraid I've got to go.\n",
      "Real answer : ...nothing.\n",
      "Bert Score : {'precision': [0.8150196671485901], 'recall': [0.8893085718154907], 'f1': [0.8505450487136841], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 21.84396172162889\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTARBUCK: Stop!\\nISHMAEL: What d'ye make of it, sir--\\n\\n\", 'answer': 'Hist! Eyes sharp...', 'gold_tag': 'Everyday Language', 'last_speaker': 'STARBUCK'}\n",
      "Last word -> STARBUCK : \"Hist! Eyes sharp...\"\n",
      "prediction :  It's a whale ship.\n",
      "Real answer : Hist! Eyes sharp...\n",
      "Bert Score : {'precision': [0.8705670833587646], 'recall': [0.8410214781761169], 'f1': [0.8555392622947693], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 119.46994604676148\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTARBUCK: Get 'im below!\\nISHMAEL: He won't move, sir! Grabbing a rope, Starbuck hoists Queequeg up.\\n\\n\", 'answer': \"Let's raise 'im up...against the mast!\", 'gold_tag': 'STARBUCK is proactive, making quick decisions and taking immediate action', 'last_speaker': 'STARBUCK'}\n",
      "Last word -> STARBUCK : \"Let's raise 'im up...against the mast!\"\n",
      "prediction :  You're a big help.\n",
      "Real answer : Let's raise 'im up...against the mast!\n",
      "Bert Score : {'precision': [0.8673228025436401], 'recall': [0.8302656412124634], 'f1': [0.848389744758606], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 72.0916256970413\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nISHMAEL: What is it?!...\\n\\n', 'answer': \"St. Elmo's fire!...\", 'gold_tag': \"STARBUCK is knowledgeable about St. Elmo's fire\", 'last_speaker': 'STARBUCK'}\n",
      "Last word -> STARBUCK : \"St. Elmo's fire!...\"\n",
      "prediction :  I think it's a sea monster.\n",
      "Real answer : St. Elmo's fire!...\n",
      "Bert Score : {'precision': [0.8737118244171143], 'recall': [0.8057762384414673], 'f1': [0.8383700251579285], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 35.81327360889667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGEL: Good morning, Jack. It's nice to see you're on time.\\nJACK: I'm all yours.\\nANGEL: How true. You got a clean bill of health from our doctors. Let's see what you can do, OK? This is the main training area for the fighters. Usually, you all train together, but we'll be training alone for the first couple of weeks, however.\\nJACK: Why?\\nANGEL: Jack, don't ask too many questions, OK? When I call out a kick or a punch, you hit through the lights. They measure speed and power. Got that?\\nJACK: You bet.\\nANGEL: Stepping side. Backfist, straight punch. Jack does it. Spinning hook, roundhouse, front kick. Left hook. Right jab. Left uppercut. Now I want to measure your reaction time. Enter the chamber, please. OK! Take a break for a minute, Jack. Not bad. Your numbers are pretty good.\\nJACK: Thanks. Is the test done?\\nANGEL: Not quite yet, Jack.\\nJACK: What... are you doing, Angel?\\nANGEL: Checking vital signs... Not too fast, that's good. A little faster now – you enjoying yourself, Jack? That's good, too...\\nJACK: Angel...?\\nANGEL: Stand still! Best indicator of heart rate activity. Your heart's pumping to beat the band, Jack... My favorite vital sign... Oh, the things you'll see, Jack. We're going to have so much fun training together.\\nJACK: Should we be doing this?\\nANGEL: You'll do whatever I say.\\nJACK: Here? Now?\\nANGEL: We have all the time in the world, Jack. We start for real, training, I mean, tomorrow. Get a good night's sleep, Jack, you'll need it.\\nJACK: What are these?\\nANGEL: Vitamins. Special for the SuperFighters.\\nJACK: I don't like pills.\\n\\n\", 'answer': \"They're vitamins, Jack. Take them.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ANGEL'}\n",
      "Last word -> ANGEL : \"They're vitamins, Jack. Take them.\"\n",
      "prediction :  Jack, you're going to love these. They're for your own good.\n",
      "Real answer : They're vitamins, Jack. Take them.\n",
      "Bert Score : {'precision': [0.842010498046875], 'recall': [0.8848286271095276], 'f1': [0.862888753414154], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3157894736842105, 'rouge2': 0.11764705882352941, 'rougeL': 0.21052631578947367, 'rougeLsum': 0.21052631578947367}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 28.867955451003237\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACK: Did you think that fight tonight went awful fast? I mean, I barely hit him and\\nANGEL: You were great, Jack! They loved you!\\nJACK: Yeah, but was I that great? Am I that good?\\nANGEL: Don't ask me, I'm not exactly impartial...\\nJACK: Yeah, but do you think they're taking it easy on me because I'm new? I don't want anything given to me...\\nANGEL: I want you to give it up to me!\\nJACK: C'mon, Angel. What are you doing?\\nANGEL: You want a fight, you got one.\\nJACK: I've never fought anyone in lace panties before.\\nANGEL: Enjoy it while you can.\\nJACK: Angel...\\nANGEL: Oh, Jack Cody, you sweep me off my feet. C'mon, Jack. Just one time? It doesn't have to mean anything.\\nJACK: Yes, it does. Besides, you're my trainer, and my friend.\\nANGEL: What are friends for? You don't know what you're missing.\\n\\n\", 'answer': \"I'm getting a sneak preview...\", 'gold_tag': 'Everyday Language', 'last_speaker': 'JACK'}\n",
      "Last word -> JACK : \"I'm getting a sneak preview...\"\n",
      "prediction :  You're not going to hit me, are you?\n",
      "Real answer : I'm getting a sneak preview...\n",
      "Bert Score : {'precision': [0.8278220891952515], 'recall': [0.8594086170196533], 'f1': [0.8433197140693665], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 17.523190098948614\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGEL: You're not getting much stronger, Jack. I don't get it. We normally see 25% increase by this time, and you're way behind schedule. What gives?\\nJACK: Got me, Coach. I gotta take a leak... I mean, I have to use the facilities, Ma'am. May I?\\n\\n\", 'answer': \"I'll be right here.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ANGEL'}\n",
      "Last word -> ANGEL : \"I'll be right here.\"\n",
      "prediction :  Sure, kid. You can use the restroom at the far end of the hall. Just make sure you don't miss the next class.\n",
      "Real answer : I'll be right here.\n",
      "Bert Score : {'precision': [0.828729510307312], 'recall': [0.8429083228111267], 'f1': [0.8357588052749634], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 10.281742102799155\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACK: Angel! What's happening?\\nANGEL: What's happening to you, Jack? Why are you getting involved with that son of a bitch...\\nJACK: Aren't you?\\nANGEL: We all are, I guess.\\nJACK: What's going on tonight?\\nANGEL: A cage fight, for the high rollers. Robert wanted me to make sure you got inside...\\n\\n\", 'answer': \"What's that mean, Angel? Hey, Angel, wait up!\", 'gold_tag': 'JACK is attempting to understand the recent changes in his relations and the upcoming fight', 'last_speaker': 'JACK'}\n",
      "Last word -> JACK : \"What's that mean, Angel? Hey, Angel, wait up!\"\n",
      "prediction :  You know me, Angel. I'm not a fighter.\n",
      "Real answer : What's that mean, Angel? Hey, Angel, wait up!\n",
      "Bert Score : {'precision': [0.887825608253479], 'recall': [0.857110321521759], 'f1': [0.8721976280212402], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.185319791390075\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTANDARD: What is it?\\n\\n', 'answer': 'Take a look.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BROUSSARD'}\n",
      "Last word -> BROUSSARD : \"Take a look.\"\n",
      "prediction :  A 100-year-old man.\n",
      "Real answer : Take a look.\n",
      "Bert Score : {'precision': [0.8681321740150452], 'recall': [0.858954131603241], 'f1': [0.8635187149047852], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.024577932500794\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBROUSSARD: I was scanning the horizon to see what I could pick up. Look there, on that screen.\\n\\n', 'answer': \"What is it, I can't -- This is Chaz. All hands topside. Now.\", 'gold_tag': 'STANDARD is in a position of authority , STANDARD is able to give orders to all hands', 'last_speaker': 'STANDARD'}\n",
      "Last word -> STANDARD : \"What is it, I can't -- This is Chaz. All hands topside. Now.\"\n",
      "prediction :  What is it?\n",
      "Real answer : What is it, I can't -- This is Chaz. All hands topside. Now.\n",
      "Bert Score : {'precision': [0.8755162358283997], 'recall': [0.8263362646102905], 'f1': [0.8502156138420105], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.375, 'rouge2': 0.2857142857142857, 'rougeL': 0.375, 'rougeLsum': 0.375}\n",
      "bleu 1/2 : 0.023782662231501606 0.020596389662105096\n",
      "ppl : 140.93475091067572\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTANDARD: Dell, you want to come down, we can figure out where to go from here.\\n\\n', 'answer': 'No, I want to go in.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BROUSSARD'}\n",
      "Last word -> BROUSSARD : \"No, I want to go in.\"\n",
      "prediction :  No, I'm not going to get off the plane, and I'm not going to go to jail.\n",
      "Real answer : No, I want to go in.\n",
      "Bert Score : {'precision': [0.8693252205848694], 'recall': [0.9166496992111206], 'f1': [0.8923604488372803], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.32, 'rouge2': 0.1739130434782609, 'rougeL': 0.32, 'rougeLsum': 0.32}\n",
      "bleu 1/2 : 0.17647058823529413 0.10502100630210073\n",
      "ppl : 8.208938780252636\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKALE: Whoa, did you see that thing?\\n\\n', 'answer': 'Settle down, slow it down...', 'gold_tag': 'Everyday Language', 'last_speaker': 'JEFF'}\n",
      "Last word -> JEFF : \"Settle down, slow it down...\"\n",
      "prediction :  What thing?\n",
      "Real answer : Settle down, slow it down...\n",
      "Bert Score : {'precision': [0.8459984064102173], 'recall': [0.7901405692100525], 'f1': [0.8171160817146301], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3710.824616174205\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEFF: Kale? -- Kale, are you okay?\\nKALE: I think so. Oh my God, dad --\\n\\n', 'answer': \"I'm fine. But you're gonna have to climb out, Kale. Can you do that? That's okay, I've got it -- grab the door, I don't need your ass falling on my face --\", 'gold_tag': \"JEFF is Kale's father , JEFF has a protective and assertive personality , JEFF attempts to guide Kale in an emergency , KALE and Jeff have a close relationship\", 'last_speaker': 'JEFF'}\n",
      "Last word -> JEFF : \"I'm fine. But you're gonna have to climb out, Kale. Can you do that? That's okay, I've got it -- grab the door, I don't need your ass falling on my face --\"\n",
      "prediction :  What happened?\n",
      "Real answer : I'm fine. But you're gonna have to climb out, Kale. Can you do that? That's okay, I've got it -- grab the door, I don't need your ass falling on my face --\n",
      "Bert Score : {'precision': [0.829595685005188], 'recall': [0.7819384336471558], 'f1': [0.8050623536109924], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 636.8826446348882\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEFF: Kale, you have to climb up --\\nKALE: No -- I'm not leaving --\\nJEFF: Kale --\\nKALE: NO -- Dad, please, I've got you --\\n\\n\", 'answer': 'I know --', 'gold_tag': 'Everyday Language', 'last_speaker': 'JEFF'}\n",
      "Last word -> JEFF : \"I know --\"\n",
      "prediction :  Kale, you have to climb up!\n",
      "Real answer : I know --\n",
      "Bert Score : {'precision': [0.7972797155380249], 'recall': [0.7796660661697388], 'f1': [0.7883745431900024], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 143.21969606833034\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRAJA: Oh hi, Mom.\\nMOTHER: What are you doing in the silver drawer?\\n\\n', 'answer': \"Looking for... the TV Guide. Of course. I'm such a fool... Thanks, Mummy. Go to bed.\", 'gold_tag': 'RAJA knows where to find items in the house , RAJA has a somewhat whimsical demeanor , MOTHER is likely a guardian role', 'last_speaker': 'RAJA'}\n",
      "Last word -> RAJA : \"Looking for... the TV Guide. Of course. I'm such a fool... Thanks, Mummy. Go to bed.\"\n",
      "prediction :  I was looking for my favorite pencil.\n",
      "Real answer : Looking for... the TV Guide. Of course. I'm such a fool... Thanks, Mummy. Go to bed.\n",
      "Bert Score : {'precision': [0.870298445224762], 'recall': [0.8407198190689087], 'f1': [0.8552534580230713], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.09090909090909091, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 42.99553353802981\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOTHER: Jeffrey, YOU THIEF!\\nRAJA: Mother... it's not what you think!\\nMOTHER: And why are you wearing that silly costume?\\nRAJA: Because... I'M A SUPERHERO! Oh, Mother, I'm sorry. I know how much you wanted me to be a doctor or a lawyer with a family--but it's just not who I am!\\nMOTHER: But... the silverware?\\nRAJA: I use it... to fight evil.\\nMOTHER: Jeffrey... this is wonderful.\\nRAJA: It is?\\nMOTHER: I always knew that you were special.\\nRAJA: You did?\\n\\n\", 'answer': 'Ever since you were a little boy... Come with me.', 'gold_tag': \"MOTHER and RAJA reminisce about RAJA's uniqueness since his childhood\", 'last_speaker': 'MOTHER'}\n",
      "Last word -> MOTHER : \"Ever since you were a little boy... Come with me.\"\n",
      "prediction :  Yes, I did.\n",
      "Real answer : Ever since you were a little boy... Come with me.\n",
      "Bert Score : {'precision': [0.8587774634361267], 'recall': [0.8278652429580688], 'f1': [0.8430380821228027], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 91.42863472794014\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOTHER: This is for you. Your Great Great Grandmother's wedding silver.\\n\\n\", 'answer': \"Bitchin'.\", 'gold_tag': 'RAJA uses modern, casual language', 'last_speaker': 'RAJA'}\n",
      "Last word -> RAJA : \"Bitchin'.\"\n",
      "prediction :  What is this?\n",
      "Real answer : Bitchin'.\n",
      "Bert Score : {'precision': [0.8377344608306885], 'recall': [0.8050113916397095], 'f1': [0.8210470080375671], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 131.0358716508209\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCARY: So what are we doing here?\\nJOE: Just follow me.\\n\\n', 'answer': \"I've been following you for the last five blocks. What are we doing here?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'CARY'}\n",
      "Last word -> CARY : \"I've been following you for the last five blocks. What are we doing here?\"\n",
      "prediction :  Is this the way to the airport?\n",
      "Real answer : I've been following you for the last five blocks. What are we doing here?\n",
      "Bert Score : {'precision': [0.8657108545303345], 'recall': [0.8448233008384705], 'f1': [0.8551396131515503], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09090909090909091, 'rouge2': 0.0, 'rougeL': 0.09090909090909091, 'rougeLsum': 0.09090909090909091}\n",
      "bleu 1/2 : 0.05255420588163462 0.017950678673773812\n",
      "ppl : 37.64496971878369\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCARY: Joe, I don't understand--\\n\\n\", 'answer': 'Shhh. This way.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JOE'}\n",
      "Last word -> JOE : \"Shhh. This way.\"\n",
      "prediction :  I know you don't, Cary.\n",
      "Real answer : Shhh. This way.\n",
      "Bert Score : {'precision': [0.8221811056137085], 'recall': [0.8544869422912598], 'f1': [0.838022768497467], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 78.29308834915653\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCARY: It's Sheriff Pruitt.\\nJOE: I know. Cary look.\\nCARY: What is this?\\nJOE: We're under the water tower.\\nCARY: It's eating a person.\\nJOE: She's here. We're going to use your firecrackers.\\nCARY: I don't think it's going to hurt it, Joe.\\nJOE: There are other tunnels.\\nCARY: So?\\nJOE: I need you to make noise. Lots of it, right here, in two minutes. Make it loud and make it last-- gimme some sparklers.\\nCARY: -- why-- what are you gonna do--?\\nJOE: Make sure you're gone by the time it blows: you can't be here, you gotta run.\\n\\n\", 'answer': 'Where are you going?', 'gold_tag': 'Everyday Language', 'last_speaker': 'CARY'}\n",
      "Last word -> CARY : \"Where are you going?\"\n",
      "prediction :  I'm not gonna run.\n",
      "Real answer : Where are you going?\n",
      "Bert Score : {'precision': [0.8710538744926453], 'recall': [0.8536795377731323], 'f1': [0.8622791767120361], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 61.65100460917354\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAFFEE: Alright, let's get tough out there!\\nJO: Excuse me.\\nKAFFEE: You want to suit up? We need all the help we can get.\\nJO: No, thank you, I can't throw and catch things.\\nKAFFEE: That's okay, neither can they.\\nJO: I wanted to talk to you about Corporal Dawson and Private Downey.\\nKAFFEE: Say again?\\nJO: Dawson and Downey.\\nKAFFEE: Those names sound like they should mean something to me, but I'm just not --\\nJO: Dawson! Downey! Your clients!\\nKAFFEE: The Cuba thing! Yes! Dawson and Downey. Right. I've done something wrong again, haven't I?\\nJO: I was wondering why two guys have been in a jail cell since this morning while their lawyer is outside hitting a ball.\\nKAFFEE: We need the practice.\\nJO: That wasn't funny.\\nKAFFEE: It was a little funny.\\nJO: Lieutenant, would you feel very insulted if I recommended to your supervisor that he assign different counsel?\\nKAFFEE: Why?\\nJO: I don't think you're fit to handle this defense.\\nKAFFEE: You don't even know me. Ordinarily it takes someone hours to discover I'm not fit to handle a defense. Oh come on, that was damn funny.\\nJO: I do know you. Daniel AlliStair Kaffee, born June 8th, 1964 at Boston Mercy Hospital. Your father's Lionel Kaffee, former Navy Judge Advocate and Attorney General, of the United States, died 1985. You went to Harvard Law on a Navy scholarship, probably because that's what your father wanted you to do, and now you're just treading water for the three years you've gotta serve in the JAG Corps, just kinda layin' low til you can get out and get a real job. And if that's the situation, that's fine, I won't tell anyone. But my feeling is that if this case is handled in the same fast-food, slick-ass, Persian Bazaar manner with which you seem to handle everything else, something's gonna get missed. And I wouldn't be doing my job if I allowed Dawson and Downey to spend any more time in prison than absolutely necessary, because their attorney had pre- resistance.\\nKAFFEE: Wow. I'm sexually aroused, Commander.\\nJO: I don't think your clients murdered anybody.\\nKAFFEE: What are you basing this on?\\nJO: There was no intent.\\nKAFFEE: The doctor's report says that Santiago died of asphyxiation brought on by acute lactic acidosis, and that the nature of the acidosis strongly suggests poisoning. Now, I don't know what any of that means, but it sounds pretty bad.\\nJO: Santiago died at one a.m. At three the doctor was unable to determine the cause of death, but two hours later he said it was poison.\\nKAFFEE: Oh, now I see what you're saying.\\nJO: I'm gonna speak to your supervisor.\\nKAFFEE: Okay. You go straight up Pennsylvania\\nJO: Thank you.\\nKAFFEE: I don't think you'll have much luck, though. I was assigned by Division, remember? Somebody over there thinks I'm a good lawyer. So while I appreciate your interest and admire your enthusiasm, I think I can pretty much handle things myself.\\n\\n\", 'answer': 'Do you know what a code red is? What a pity.', 'gold_tag': 'JO is a Commander , JO is committed to her job', 'last_speaker': 'JO'}\n",
      "Last word -> JO : \"Do you know what a code red is? What a pity.\"\n",
      "prediction :  If you're right, you could be in for a world of trouble.\n",
      "Real answer : Do you know what a code red is? What a pity.\n",
      "Bert Score : {'precision': [0.860379695892334], 'recall': [0.8713862299919128], 'f1': [0.8658479452133179], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666669, 'rouge2': 0.0, 'rougeL': 0.16666666666666669, 'rougeLsum': 0.16666666666666669}\n",
      "bleu 1/2 : 0.16666666666666669 0.03892494720807617\n",
      "ppl : 12.996748008473128\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJO: Hi there.\\nKAFFEE: Any luck getting me replaced?\\nJO: Is there anyone in this command that you don't either drink or play softball with?\\nKAFFEE: Commander --\\nJO: Listen, I came to make peace. We started off on the wrong foot. What do you say? Friends?\\nKAFFEE: Look, I don't --\\nJO: By the way, I brought Downey some comic books he was asking for. The kid, Kaffee, I swear, he doesn't know where he is, he doesn't even know why he's been arrested.\\nKAFFEE: Commander --\\nJO: You can call me Joanne.\\nKAFFEE: Joanne --\\nJO: or Jo.\\nKAFFEE: Jo?\\nJO: Yes.\\nKAFFEE: Jo, if you ever speak to a client of mine again without my permission, I'll have you disbarred. Friends?\\nJO: I had authorization.\\nKAFFEE: From where?\\nJO: Downey's closest living relative, Ginny Miller, his aunt on his mother's side.\\nKAFFEE: You got authorization from Aunt Ginny?\\nJO: I gave her a call like you asked. Very nice woman, we talked for about an hour.\\nKAFFEE: You got authorization from Aunt Ginny.\\nJO: Perfectly within my province.\\nKAFFEE: Does Aunt Ginny have a barn? We can hold the trial there. I can sew the costumes, and maybe his Uncle Goober can be the judge.\\nJO: I'm going to Cuba with you tomorrow.\\n\\n\", 'answer': \"And the hits just keep on comin'.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'KAFFEE'}\n",
      "Last word -> KAFFEE : \"And the hits just keep on comin'.\"\n",
      "prediction :  Cuba?\n",
      "Real answer : And the hits just keep on comin'.\n",
      "Bert Score : {'precision': [0.849869966506958], 'recall': [0.7778142690658569], 'f1': [0.8122471570968628], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5104.126471296465\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAFFEE: Lt. Kendrick, the type of disciplinary action, or \"training\\'\\' as you say --\\nJO: Object.\\nKAFFEE: Please the Court, I maintain that nothing could be more relevant than what the defendants learned by the example of, among others, the witness.\\n\\n', 'answer': 'Nice.', 'gold_tag': 'JO is a lawyer', 'last_speaker': 'JO'}\n",
      "Last word -> JO : \"Nice.\"\n",
      "prediction :  Object.\n",
      "Real answer : Nice.\n",
      "Bert Score : {'precision': [0.9942753911018372], 'recall': [0.9942753911018372], 'f1': [0.9942753911018372], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 948.6528583888139\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJO: I'm sorry to bother you, I should've called first.\\nKAFFEE: No, I was just watching a baseball game.\\nJO: I was wondering if -- how you'd feel about my taking you to dinner tonight.\\nKAFFEE: Jo, are you asking me out on a date?\\nJO: No.\\nKAFFEE: It sounded like you were asking me out on a date.\\nJO: I wasn't.\\nKAFFEE: I've been asked out on dates before, and that's what it sounded like.\\n\\n\", 'answer': 'Do you like seafood? I know a good seafood place.', 'gold_tag': 'JO likes seafood , JO knows a good seafood place', 'last_speaker': 'JO'}\n",
      "Last word -> JO : \"Do you like seafood? I know a good seafood place.\"\n",
      "prediction :  Oh, I see.\n",
      "Real answer : Do you like seafood? I know a good seafood place.\n",
      "Bert Score : {'precision': [0.8446871638298035], 'recall': [0.8497782349586487], 'f1': [0.84722501039505], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0.03232398928813501 0.012519027219593387\n",
      "ppl : 68.32818314572262\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKAFFEE: Is Sam here?\\nJO: Not yet.\\nKAFFEE: Where is he?\\nJO: He's on his way.\\nKAFFEE: Did he got the guys?\\n\\n\", 'answer': 'Yes. Listen, can I talk to you for a second?', 'gold_tag': 'Everyday Language', 'last_speaker': 'JO'}\n",
      "Last word -> JO : \"Yes. Listen, can I talk to you for a second?\"\n",
      "prediction :  He did.\n",
      "Real answer : Yes. Listen, can I talk to you for a second?\n",
      "Bert Score : {'precision': [0.8839421272277832], 'recall': [0.8123512268066406], 'f1': [0.8466359376907349], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1007.3007683769935\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJIM: How did you know? How did you know he was infected? 22.\\nSELENA: The blood.\\nJIM: The blood was everywhere. On me, on you, and...\\nSELENA: I didn't know he was infected. Okay? I didn't know. He knew. I could see it in his face. You need to understand, if someone gets infected, you've got somewhere between ten and twenty seconds to kill them. They might be your brother or your sister or your oldest friend. It makes no difference Just so as you know, if it happens to you, I'll do it in a heartbeat.\\nJIM: How long had you known him?\\n\\n\", 'answer': \"Five days. Or six. Does it matter? He was full of plans. Long-distance weapons, so they don't get close. A newsagent's with a metal grill, so you can sleep. Petrol bombs, so the blood doesn't splash. Got a plan yet, Jim? You want us to find a cure and save the world? Or fall in love and fuck? Plans are pointless. Staying alive is as good as it gets. Shhh.\", 'gold_tag': \"SELENA's temporal information: Selena has been with the infected person for five or six days\", 'last_speaker': 'SELENA'}\n",
      "Last word -> SELENA : \"Five days. Or six. Does it matter? He was full of plans. Long-distance weapons, so they don't get close. A newsagent's with a metal grill, so you can sleep. Petrol bombs, so the blood doesn't splash. Got a plan yet, Jim? You want us to find a cure and save the world? Or fall in love and fuck? Plans are pointless. Staying alive is as good as it gets. Shhh.\"\n",
      "prediction :  Two years.\n",
      "Real answer : Five days. Or six. Does it matter? He was full of plans. Long-distance weapons, so they don't get close. A newsagent's with a metal grill, so you can sleep. Petrol bombs, so the blood doesn't splash. Got a plan yet, Jim? You want us to find a cure and save the world? Or fall in love and fuck? Plans are pointless. Staying alive is as good as it gets. Shhh.\n",
      "Bert Score : {'precision': [0.9124350547790527], 'recall': [0.8013101816177368], 'f1': [0.8532697558403015], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1236.8683787134353\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSELENA: Need a break?\\nJIM: No. You?\\nSELENA: No.\\nJIM: I do need a break, by the way.\\nSELENA: What's up?\\nJIM: Nothing. I've got a headache.\\nSELENA: Bad?\\nJIM: Pretty bad.\\nSELENA: Why didn't you say something before?\\nJIM: Because I didn't think you'd give a shit.\\nSELENA: You've got no fat on you, and all you've had to eat is sugar. So you're crashing. Unfortunately, there isn't a lot we can do about that... ...except pump you full painkillers, and give you more sugar to eat. As for the sugar: Lilt or Tango?\\nJIM: ...Do you have Sprite?\\nSELENA: Actually, I did have a can of Sprite, but...\\nJIM: Jesus!\\n\\n\", 'answer': \"Quiet. That's an infected. They're in.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SELENA'}\n",
      "Last word -> SELENA : \"Quiet. That's an infected. They're in.\"\n",
      "prediction : What's wrong?\n",
      "Real answer : Quiet. That's an infected. They're in.\n",
      "Bert Score : {'precision': [0.8236872553825378], 'recall': [0.8712302446365356], 'f1': [0.8467919826507568], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 83.29170597890995\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSELENA: Come on!\\n\\n', 'answer': \"I can't.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'JIM'}\n",
      "Last word -> JIM : \"I can't.\"\n",
      "prediction :  I know.\n",
      "Real answer : I can't.\n",
      "Bert Score : {'precision': [0.9014896154403687], 'recall': [0.8995177745819092], 'f1': [0.900502622127533], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4, 'rouge2': 0.0, 'rougeL': 0.4, 'rougeLsum': 0.4}\n",
      "bleu 1/2 : 0.5 0.223606797749979\n",
      "ppl : 663.9337011017111\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSELENA: Very spruce.\\nJIM: Very shredded.\\nSELENA: Uh-huh.\\nJIM: So what do you make of them?\\nSELENA: They're desperate. Probably need us more than we need them.\\nJIM: ...I think they're good people.\\nSELENA: Good people?\\nJIM: Yeah.\\nSELENA: Well, that's nice. But you should be more concerned about whether they're going to slow you down.\\nJIM: Right. Because if they slowed you down...\\nSELENA: I'd leave them behind.\\nJIM: In a heartbeat.\\nSELENA: Yeah.\\nJIM: I wouldn't.\\nSELENA: Then you're going to wind up getting yourself killed. I'm going to get some sleep.\\nJIM: Selena - you think I don't get it. But I do get it. And I know I'd be dead already if I hadn't met you.\\nSELENA: Sure.\\nJIM: No, look - I mean thank you.\\nSELENA: And I mean sure. Good night, Jim.\\n\\n\", 'answer': 'Good night.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JIM'}\n",
      "Last word -> JIM : \"Good night.\"\n",
      "prediction :  What is it?\n",
      "Real answer : Good night.\n",
      "Bert Score : {'precision': [0.8397267460823059], 'recall': [0.8830942511558533], 'f1': [0.8608646392822266], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 140.93475091067572\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSELENA: Stay close, Jim.\\nJIM: ...What?\\n\\n', 'answer': 'You heard.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SELENA'}\n",
      "Last word -> SELENA : \"You heard.\"\n",
      "prediction :  If you stay here, you'll be safe.\n",
      "Real answer : You heard.\n",
      "Bert Score : {'precision': [0.8473231196403503], 'recall': [0.8866651058197021], 'f1': [0.8665478229522705], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.927692358099215\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSELENA: Where are you going? We've got enough food.\\n\\n\", 'answer': 'We don\\'t have any cheeseburgers. \"Stay close.\" It\\'s like going on holiday with your fucking aunt.', 'gold_tag': 'JIM likes cheeseburgers , JIM is disgruntled and uses coarse language', 'last_speaker': 'JIM'}\n",
      "Last word -> JIM : \"We don't have any cheeseburgers. \"Stay close.\" It's like going on holiday with your fucking aunt.\"\n",
      "prediction :  I can't just sit here and do nothing. I've got to go out there and find out what's happening.\n",
      "Real answer : We don't have any cheeseburgers. \"Stay close.\" It's like going on holiday with your fucking aunt.\n",
      "Bert Score : {'precision': [0.8516238927841187], 'recall': [0.8376402258872986], 'f1': [0.8445742130279541], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09999999999999999, 'rouge2': 0.0, 'rougeL': 0.09999999999999999, 'rougeLsum': 0.09999999999999999}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5.8277246895465025\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJIM: You know what I was thinking?\\nSELENA: You were thinking that you'll never hear another piece of original music ever again. You'll never read a book that isn't already written. Or see a film that isn't already shot.\\nJIM: That's what you were thinking.\\nSELENA: No... I was thinking I was wrong.\\nJIM: About what?\\nSELENA: All the death, all the shit - it doesn't really mean anything for Frank and Hannah. Because she's got her dad, and he's got his daughter, so... it's okay. I was wrong when I told you that staying alive is as good as it gets.\\nJIM: That's what I was thinking.\\nSELENA: ...Was it?\\nJIM: Uh-huh. You stole my thought.\\nSELENA: Sorry.\\n\\n\", 'answer': 'Ah, keep it.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JIM'}\n",
      "Last word -> JIM : \"Ah, keep it.\"\n",
      "prediction :  It's okay. I was thinking the same thing.\n",
      "Real answer : Ah, keep it.\n",
      "Bert Score : {'precision': [0.8510826826095581], 'recall': [0.885379433631897], 'f1': [0.8678923845291138], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 19.152912740157785\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJIM: Try the horn.\\n\\n', 'answer': \"Don't. We might attract the wrong kind of attention.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SELENA'}\n",
      "Last word -> SELENA : \"Don't. We might attract the wrong kind of attention.\"\n",
      "prediction :  I don’t know what you’re talking about.\n",
      "Real answer : Don't. We might attract the wrong kind of attention.\n",
      "Bert Score : {'precision': [0.8453027009963989], 'recall': [0.868233323097229], 'f1': [0.8566145896911621], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2105263157894737, 'rouge2': 0.11764705882352941, 'rougeL': 0.2105263157894737, 'rougeLsum': 0.2105263157894737}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 10.554482946559027\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJIM: ...So how is she?\\nSELENA: She's lost her dad. That's how she is. It's all fucked, Jim.\\nJIM: Hey, don't...do that. Look, Hannah... Hannah's what Frank said she was. Tough. Strong. And just like me, just like you, she will cope...\\n\\n\", 'answer': \"Shut up, Jim. Just shut up. I don't want her to fucking cope. I want her to be okay. And when Hannah had her dad, it was all okay. Remember? And when it was okay for them, it was okay for us. And now it's all fucked.\", 'gold_tag': 'Selena is protective of Hannah , Selena desires a return to a time when things were \"okay\" , Jim and Selena recall a time when Hannah was with her dad and everything was okay for both Hannah and them', 'last_speaker': 'SELENA'}\n",
      "Last word -> SELENA : \"Shut up, Jim. Just shut up. I don't want her to fucking cope. I want her to be okay. And when Hannah had her dad, it was all okay. Remember? And when it was okay for them, it was okay for us. And now it's all fucked.\"\n",
      "prediction :  Don't tell me how to cope, Jim. I know how to cope. And so does Hannah.\n",
      "Real answer : Shut up, Jim. Just shut up. I don't want her to fucking cope. I want her to be okay. And when Hannah had her dad, it was all okay. Remember? And when it was okay for them, it was okay for us. And now it's all fucked.\n",
      "Bert Score : {'precision': [0.9023371934890747], 'recall': [0.8635696172714233], 'f1': [0.8825278878211975], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.27272727272727276, 'rouge2': 0.03125, 'rougeL': 0.24242424242424243, 'rougeLsum': 0.24242424242424243}\n",
      "bleu 1/2 : 0.05402387216304498 0.007203182955072665\n",
      "ppl : 19.181766767035562\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJIM: Get up. Get up!\\nSELENA: Wha...\\nJIM: We've got to get out of here!\\nSELENA: But we...\\n\\n\", 'answer': \"We're leaving. Now! NOW!\", 'gold_tag': \"JIM's temporal information - Jim is in a hurry, indicating a time-sensitive situation\", 'last_speaker': 'JIM'}\n",
      "Last word -> JIM : \"We're leaving. Now! NOW!\"\n",
      "prediction :  Come on!\n",
      "Real answer : We're leaving. Now! NOW!\n",
      "Bert Score : {'precision': [0.8610131144523621], 'recall': [0.8590184450149536], 'f1': [0.8600146770477295], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 893.852532969127\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSELENA: We're going to crash! We're going to crash!\\n\\n\", 'answer': 'Just fucking do it!', 'gold_tag': 'Everyday Language', 'last_speaker': 'JIM'}\n",
      "Last word -> JIM : \"Just fucking do it!\"\n",
      "prediction :  No, we're not. We're going to be okay.\n",
      "Real answer : Just fucking do it!\n",
      "Bert Score : {'precision': [0.8541110754013062], 'recall': [0.8475901484489441], 'f1': [0.8508381843566895], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 19.99585739178636\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRICHARD: Thank you.\\n\\n', 'answer': \"The doctor's here.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ANWAR'}\n",
      "Last word -> ANWAR : \"The doctor's here.\"\n",
      "prediction :  I'm glad you think so.\n",
      "Real answer : The doctor's here.\n",
      "Bert Score : {'precision': [0.8380983471870422], 'recall': [0.8680325746536255], 'f1': [0.8528028726577759], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.44381202957649\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRICHARD: Anwar...Anwar...\\nANWAR: What happened?\\nRICHARD: We've got to get her out of here. Where's the clinic?\\nANWAR: In Alnif, an hour and a half away from here.\\n\\n\", 'answer': 'Can you get us a car we can take her in?', 'gold_tag': \"RICHARD's questions suggest he might be a foreigner or unfamiliar with the local areas\", 'last_speaker': 'RICHARD'}\n",
      "Last word -> RICHARD : \"Can you get us a car we can take her in?\"\n",
      "prediction :  We can't take her out of here.\n",
      "Real answer : Can you get us a car we can take her in?\n",
      "Bert Score : {'precision': [0.8754154443740845], 'recall': [0.8612912893295288], 'f1': [0.8682959079742432], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4210526315789474, 'rouge2': 0.23529411764705882, 'rougeL': 0.4210526315789474, 'rougeLsum': 0.4210526315789474}\n",
      "bleu 1/2 : 0.16134803485935978 0.12323159716256497\n",
      "ppl : 43.42194076392569\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANWAR: Good luck, mister...\\nRICHARD: Thank you for everything.\\n\\n', 'answer': 'No sir, no... Allah be with you.', 'gold_tag': 'ANWAR expresses religious well-wishes', 'last_speaker': 'ANWAR'}\n",
      "Last word -> ANWAR : \"No sir, no... Allah be with you.\"\n",
      "prediction :  You're welcome.\n",
      "Real answer : No sir, no... Allah be with you.\n",
      "Bert Score : {'precision': [0.8604044914245605], 'recall': [0.8198733925819397], 'f1': [0.8396501541137695], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 74.10636759224718\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDENNIS: Gentlemen, we're stood down for a while. Let's take the extra time to double-double check everything. Let's make this mission our best one yet. Okay, Luke, let's do the pre- flight check again. Fuel Transfer Valves.\\nLUKE: Did you hear? There's a complete cloud cover over Bremen. We're not going anywhere!\\nDENNIS: Fuel Transfer Valves.\\nLUKE: Off! They were off before! They're still off!\\n\\n\", 'answer': 'Intercoolers.', 'gold_tag': \"DENNIS's temporal information\", 'last_speaker': 'DENNIS'}\n",
      "Last word -> DENNIS : \"Intercoolers.\"\n",
      "prediction :  Let's go! We've got to get the fuel transfer valves open!\n",
      "Real answer : Intercoolers.\n",
      "Bert Score : {'precision': [0.8298132419586182], 'recall': [0.8597266674041748], 'f1': [0.8445051312446594], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 39.39196302846275\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLUKE: Let's do the preflight check again for good luck.\\nDENNIS: Luke, if we could decide right now, do we go or do we stay... what would you choose?\\n\\n\", 'answer': \"Are you kidding? Go! I can't wait! Fuel transfer valves. Open.\", 'gold_tag': 'LUKE portrays confidence and eagerness , LUKE prefers action', 'last_speaker': 'LUKE'}\n",
      "Last word -> LUKE : \"Are you kidding? Go! I can't wait! Fuel transfer valves. Open.\"\n",
      "prediction :  We have to go.\n",
      "Real answer : Are you kidding? Go! I can't wait! Fuel transfer valves. Open.\n",
      "Bert Score : {'precision': [0.8868545293807983], 'recall': [0.8341195583343506], 'f1': [0.8596790432929993], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 161.4811239189632\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDENNIS: Luke, don't worry. Danny'll be okay.\\n\\n\", 'answer': \"It's such a waste. The whole fucking...\", 'gold_tag': 'LUKE feels that the situation is wasteful , DENNIS and LUKE both know and are concerned about Danny', 'last_speaker': 'LUKE'}\n",
      "Last word -> LUKE : \"It's such a waste. The whole fucking...\"\n",
      "prediction :  No, he won't.\n",
      "Real answer : It's such a waste. The whole fucking...\n",
      "Bert Score : {'precision': [0.8654289245605469], 'recall': [0.8399879932403564], 'f1': [0.8525187373161316], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 65.91700520747891\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDENNIS: Luke, don't take the world on your shoulders. You didn't start the war. All we can do is try to do our best. We're not perfect. When this is all over, we'll go back home...\\nLUKE: Fire on number three!\\n\\n\", 'answer': 'Cut fuel, feather prop. Fire extinguisher. Call out those fighters!', 'gold_tag': 'DENNIS maintains a calm demeanor in stressful situations , DENNIS is likely a senior officer or team leader', 'last_speaker': 'DENNIS'}\n",
      "Last word -> DENNIS : \"Cut fuel, feather prop. Fire extinguisher. Call out those fighters!\"\n",
      "prediction :  Luke, no! We can't just fire on them. We can't even see them!\n",
      "Real answer : Cut fuel, feather prop. Fire extinguisher. Call out those fighters!\n",
      "Bert Score : {'precision': [0.8317402601242065], 'recall': [0.8490907549858093], 'f1': [0.8403259515762329], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.268817481212725\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDENNIS: Crew, we're at ten thousand feet. We can come off oxygen. Thanks, Luke.\\n\\n\", 'answer': 'Once in a while I do something right.', 'gold_tag': \"LUKE is part of the same crew as DENNIS , LUKE's comment suggests he might not always succeed, indicating a self-deprecating or modest nature\", 'last_speaker': 'LUKE'}\n",
      "Last word -> LUKE : \"Once in a while I do something right.\"\n",
      "prediction :  No problem.\n",
      "Real answer : Once in a while I do something right.\n",
      "Bert Score : {'precision': [0.8771830797195435], 'recall': [0.8442956209182739], 'f1': [0.8604252338409424], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 450.5052282015977\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLUKE: We're losing number four.\\nDENNIS: Are we out of fuel?\\nLUKE: The gauge is shot out. How long can we fly on one engine?\\n\\n\", 'answer': \"I don't know. I guess we'll find out.\", 'gold_tag': \"DENNIS's job requires knowledge about aircraft and their operation\", 'last_speaker': 'DENNIS'}\n",
      "Last word -> DENNIS : \"I don't know. I guess we'll find out.\"\n",
      "prediction :  We can't make it. We're going to crash.\n",
      "Real answer : I don't know. I guess we'll find out.\n",
      "Bert Score : {'precision': [0.8622469305992126], 'recall': [0.8607988357543945], 'f1': [0.8615222573280334], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20000000000000004, 'rouge2': 0.0, 'rougeL': 0.20000000000000004, 'rougeLsum': 0.20000000000000004}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 19.684395434383216\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDENNIS: Wing flaps.\\nLUKE: Up.\\nDENNIS: Tail wheel.\\nLUKE: Unlocked.\\nDENNIS: Generators.\\n\\n', 'answer': 'Off.', 'gold_tag': \"LUKE responds confidently to DENNIS's commands , LUKE indicates an understanding of aviation systems\", 'last_speaker': 'LUKE'}\n",
      "Last word -> LUKE : \"Off.\"\n",
      "prediction :  Ready.\n",
      "Real answer : Off.\n",
      "Bert Score : {'precision': [0.9991397857666016], 'recall': [0.9991397857666016], 'f1': [0.9991397857666016], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 625.7697467369824\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPETER: This way. Come on.\\nSHERMAN: Uh. I don't normally ride the subway.\\n\\n\", 'answer': \"Me either. Especially on a first date. But we don't really have a choice.\", 'gold_tag': 'PETER expresses a dislike for taking the subway', 'last_speaker': 'PETER'}\n",
      "Last word -> PETER : \"Me either. Especially on a first date. But we don't really have a choice.\"\n",
      "prediction :  It's okay. We'll be there in no time.\n",
      "Real answer : Me either. Especially on a first date. But we don't really have a choice.\n",
      "Bert Score : {'precision': [0.8491256237030029], 'recall': [0.8488365411758423], 'f1': [0.8489810824394226], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 17.6120310111354\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPETER: Are you alright?\\nSHERMAN: Oh, fine. Yes, thanks.\\nPETER: Look, I owe you an apology...\\nSHERMAN: No, you were very helpful.\\nPETER: You don't know who I am.\\nSHERMAN: That's alright. Thanks. I should go.\\nPETER: Go where?\\nSHERMAN: Well...\\nPETER: Look. Sit down. Just sit down a minute. I'll get you home. * Would you like a drink? I happen to have a little something...\\nSHERMAN: Uh. No. Thanks.\\nPETER: Go on. Fuck it. What are they going to do? Arrest you?\\nSHERMAN: Does this train go anywhere near Park Avenue?\\nPETER: Not in a million years.\\nSHERMAN: My father took the subway every * day of his life. *\\nPETER: Yeah. But he didn't live in the * South Bronx. Did he? *\\nSHERMAN: No. I look terrible.\\nPETER: You look like shit. And you smell, too.\\nSHERMAN: I think, when I was in the jail, I pissed in my pants.\\nPETER: Take it easy.\\nSHERMAN: I'm alright.\\nPETER: Yeah.\\nSHERMAN: I can't think.\\n\\n\", 'answer': \"It's okay. Have another drink.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'PETER'}\n",
      "Last word -> PETER : \"It's okay. Have another drink.\"\n",
      "prediction :  What is it?\n",
      "Real answer : It's okay. Have another drink.\n",
      "Bert Score : {'precision': [0.8317773342132568], 'recall': [0.8598494529724121], 'f1': [0.8455804586410522], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2222222222222222, 'rouge2': 0.0, 'rougeL': 0.2222222222222222, 'rougeLsum': 0.2222222222222222}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 140.93475091067572\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSHERMAN: ... and then this newspaper thing started, this Peter Fallow person, and all the facts were wrong, total disregard for the truth. Why do they do this?\\nPETER: This is you. You'll be right on\\nSHERMAN: They call me by my first name. Like they know me. Like they own me. Newspapers, lawyers, police, people I don't even know. How did I get to be so important?\\nPETER: You're not important. You're just dinner. You know what I mean? And a week from now, a month -- nobody is even going to remember what they ate.\\nSHERMAN: I should have called the police right away, when it happened. But I couldn't you see? It wasn't really my decision.\\nPETER: How do you mean?\\nSHERMAN: I mean, I wasn't driving the car.\\n\\n\", 'answer': 'What?! Wait a minute! Wait a minute!', 'gold_tag': 'Everyday Language', 'last_speaker': 'PETER'}\n",
      "Last word -> PETER : \"What?! Wait a minute! Wait a minute!\"\n",
      "prediction :  So?\n",
      "Real answer : What?! Wait a minute! Wait a minute!\n",
      "Bert Score : {'precision': [0.8834550380706787], 'recall': [0.7945969104766846], 'f1': [0.8366733193397522], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 9394.974007980272\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTROY: I have a daughter.\\nSA'ID: Very nice for you, bro. She is safe in Ohio without the bombs and concrete and all this shit --\\n\\n\", 'answer': \"I'm not from Ohio.\", 'gold_tag': 'TROY is not from Ohio', 'last_speaker': 'TROY'}\n",
      "Last word -> TROY : \"I'm not from Ohio.\"\n",
      "prediction :  She's not in Ohio.\n",
      "Real answer : I'm not from Ohio.\n",
      "Bert Score : {'precision': [0.9599716663360596], 'recall': [0.9599716663360596], 'f1': [0.9599716663360596], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4000000000000001, 'rouge2': 0.0, 'rougeL': 0.4000000000000001, 'rougeLsum': 0.4000000000000001}\n",
      "bleu 1/2 : 0.5 0.12909944487358058\n",
      "ppl : 160.58403170010138\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTROY: Krystal.\\nSA'ID: What makes you decide to tell me about Krystal, my main man?\\nTROY: Because we're both fathers.\\n\\n\", 'answer': \"I'm not a father no more, dude, remember? My son is dead now. Can you think how it feels inside your heart if I bomb your daughter?\", 'gold_tag': \"SA'ID was a father , SA'ID's son has died , SA'ID is currently feeling significant grief and anger\", 'last_speaker': \"SA'ID\"}\n",
      "Last word -> SA'ID : \"I'm not a father no more, dude, remember? My son is dead now. Can you think how it feels inside your heart if I bomb your daughter?\"\n",
      "prediction :  I'm just a father.\n",
      "Real answer : I'm not a father no more, dude, remember? My son is dead now. Can you think how it feels inside your heart if I bomb your daughter?\n",
      "Bert Score : {'precision': [0.9212388396263123], 'recall': [0.8393864631652832], 'f1': [0.8784099817276001], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.24242424242424243, 'rouge2': 0.12903225806451613, 'rougeL': 0.24242424242424243, 'rougeLsum': 0.24242424242424243}\n",
      "bleu 1/2 : 0.0015913903982548334 0.0004108952339836906\n",
      "ppl : 71.93953520133128\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSA'ID: It's a total waste for your army to come to Iraq, right. It's okay, you can tell me. What did we do? Tell me, you're safe.\\n\\n\", 'answer': 'I heard about some bad shit that happened in Kuwait.', 'gold_tag': 'TROY is aware of conflict-related incidents , TROY has a military background', 'last_speaker': 'TROY'}\n",
      "Last word -> TROY : \"I heard about some bad shit that happened in Kuwait.\"\n",
      "prediction :  I can't tell you.\n",
      "Real answer : I heard about some bad shit that happened in Kuwait.\n",
      "Bert Score : {'precision': [0.8573921918869019], 'recall': [0.8659784197807312], 'f1': [0.8616639375686646], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0.055782540037107455 0.020368903662172547\n",
      "ppl : 53.718323229696054\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSA'ID: Yes, bad things happened. I'm not proud of that.\\nTROY: So who's got the sick country?\\nSA'ID: Maybe Saddam is very crazy, right? And then you are crazy to bomb all of Iraq.\\nTROY: Too much bombing is crazy, but not saving Kuwait.\\nSA'ID: You come here to save Kuwait people?\\nTROY: Yes.\\nSA'ID: Really? Get the oil. Interrogation Guard #2 dips a bucket into an oil drum. Lots of people in trouble around this world, my man. You don't fight no fahking war for them.\\nTROY: You invaded another country. You can't do that.\\nSA'ID: Why not, dude?\\nTROY: It makes the world crazy. You got to keep it stable.\\nSA'ID: For what? Your pickup truck?\\nTROY: For stability. Stabilize the region.\\n\\n\", 'answer': \"This is your fahking stability, my main man. Sa'id uses the CD as a ramp to pour crude oil into Troy's mouth from the bucket.\", 'gold_tag': \"Sa'id's mention of the oil suggests a familiarity with or involvement in the oil industry\", 'last_speaker': \"SA'ID\"}\n",
      "Last word -> SA'ID : \"This is your fahking stability, my main man. Sa'id uses the CD as a ramp to pour crude oil into Troy's mouth from the bucket.\"\n",
      "prediction :  You think you're doing the right thing?\n",
      "Real answer : This is your fahking stability, my main man. Sa'id uses the CD as a ramp to pour crude oil into Troy's mouth from the bucket.\n",
      "Bert Score : {'precision': [0.8409037590026855], 'recall': [0.8217044472694397], 'f1': [0.8311932682991028], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05714285714285714, 'rouge2': 0.0, 'rougeL': 0.05714285714285714, 'rougeLsum': 0.05714285714285714}\n",
      "bleu 1/2 : 0.010918040998681154 0.0037292209524738052\n",
      "ppl : 29.482312080013237\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAUL: I guess sometimes the past just catches up with you, whether you\\nELAINE: Was it the film? It was, wasn't it?\\nPAUL: I haven't spoken of these things in a long time, Ellie. Over sixty years.\\nELAINE: Paul. I'm your friend.\\nPAUL: Yes. Yes you are. I ever tell you I was a prison guard during the depression?\\nELAINE: You've mentioned it.\\n\\n\", 'answer': \"Did I mention I was in charge of death row? That I supervised all the executions? They usually call death row the Last Mile, but we called ours the Green Mile, because the floor was the color of faded limes. We had the electric chair then. Old Sparky, we called it. I've lived a lot of years, Ellie, but 1935 takes the prize. That was the year I had the worst urinary infection of my life. That was also the year of John Coffey, and the two dead girls...\", 'gold_tag': \"PAUL was in charge of death row where he supervised executions , PAUL reflects on past experiences that occurred over sixty years ago and specifically cites the year 1935 as significant , The John Coffey incident and the deaths of two girls occurred in the same year as PAUL's urinary infection\", 'last_speaker': 'PAUL'}\n",
      "Last word -> PAUL : \"Did I mention I was in charge of death row? That I supervised all the executions? They usually call death row the Last Mile, but we called ours the Green Mile, because the floor was the color of faded limes. We had the electric chair then. Old Sparky, we called it. I've lived a lot of years, Ellie, but 1935 takes the prize. That was the year I had the worst urinary infection of my life. That was also the year of John Coffey, and the two dead girls...\"\n",
      "prediction :  I had a man under my care. He was a very good man. A man of great integrity. He was the only man I ever trusted.\n",
      "Real answer : Did I mention I was in charge of death row? That I supervised all the executions? They usually call death row the Last Mile, but we called ours the Green Mile, because the floor was the color of faded limes. We had the electric chair then. Old Sparky, we called it. I've lived a lot of years, Ellie, but 1935 takes the prize. That was the year I had the worst urinary infection of my life. That was also the year of John Coffey, and the two dead girls...\n",
      "Bert Score : {'precision': [0.863824725151062], 'recall': [0.8180992603302002], 'f1': [0.8403404355049133], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15517241379310348, 'rouge2': 0.03508771929824561, 'rougeL': 0.12068965517241378, 'rougeLsum': 0.12068965517241378}\n",
      "bleu 1/2 : 0.030685996032206474 0.014751990951040664\n",
      "ppl : 11.401635708484395\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAUL: That was the last execution I ever took part in. Just couldn't do it anymore after that. Brutal either. We both transferred out, took jobs with Boys' Correctional. That was all right. Catch 'em young, that became my motto. Might even have done some good. You don't believe me.\\nELAINE: I don't imagine you would lie to me, Paul. It's just that...\\nPAUL: ...It's quite a story.\\nELAINE: Yes. Quite a story. One thing I don't understand. You said you and Jan had a grownup son in 1935. Is that right? But if that's true...\\n\\n\", 'answer': \"The math doesn't work, does it? You feel up to a walk?\", 'gold_tag': 'The conversation suggests a timeline discrepancy regarding the age of his son', 'last_speaker': 'PAUL'}\n",
      "Last word -> PAUL : \"The math doesn't work, does it? You feel up to a walk?\"\n",
      "prediction : ...You're right. You don't believe me. That's all right. You don't have to.\n",
      "Real answer : The math doesn't work, does it? You feel up to a walk?\n",
      "Bert Score : {'precision': [0.8564919829368591], 'recall': [0.8509403467178345], 'f1': [0.8537071943283081], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20000000000000004, 'rouge2': 0.0, 'rougeL': 0.20000000000000004, 'rougeLsum': 0.20000000000000004}\n",
      "bleu 1/2 : 0.07692307692307693 0.025318484177091663\n",
      "ppl : 5.8829894551266\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAUL: There. It's in there.\\nELAINE: Paul? This thing you want to show me. Is it scary?\\n\\n\", 'answer': 'Scary? No. Not really.', 'gold_tag': 'Everyday Language', 'last_speaker': 'PAUL'}\n",
      "Last word -> PAUL : \"Scary? No. Not really.\"\n",
      "prediction :  No. It's not scary. It's beautiful.\n",
      "Real answer : Scary? No. Not really.\n",
      "Bert Score : {'precision': [0.8931135535240173], 'recall': [0.8820129632949829], 'f1': [0.8875285983085632], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.5, 'rouge2': 0.0, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0.16666666666666669 0.05773502691896258\n",
      "ppl : 23.465632174001037\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCLAUDE: Here. Sorry.\\nMARGOT: That was quick.\\nCLAUDE: I sat next to the wrong person.\\nMARGOT: Really? Where?\\nCLAUDE: Please don't look. She'll see you.\\nMARGOT: Careful with my blouse. I don't know. I think she doesn't know anyone anymore.\\nCLAUDE: How long has she known Malcolm?\\nMARGOT: Only a year.\\nCLAUDE: Is that short?\\nMARGOT: Would you marry someone you'd only known a year?\\nCLAUDE: I'm not going to ever get married.\\nMARGOT: I can't say I have a lot of hope for the whole thing.\\nCLAUDE: Why are we going then?\\nMARGOT: We're supporting her.\\nCLAUDE: I thought she wasn't speaking to you.\\n\\n\", 'answer': \"No...no...I wasn't speaking to her, but I'm over it.\", 'gold_tag': 'Margot has recently had a conflict with someone who she has reconciled with , Margot reveals a conflict she had been involved in but has since moved past it', 'last_speaker': 'MARGOT'}\n",
      "Last word -> MARGOT : \"No...no...I wasn't speaking to her, but I'm over it.\"\n",
      "prediction :  I think she's worried about what you're going to say to her.\n",
      "Real answer : No...no...I wasn't speaking to her, but I'm over it.\n",
      "Bert Score : {'precision': [0.8780273795127869], 'recall': [0.8659133911132812], 'f1': [0.871928334236145], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.08, 'rougeL': 0.22222222222222224, 'rougeLsum': 0.22222222222222224}\n",
      "bleu 1/2 : 0.08333333333333333 0.027524094128159027\n",
      "ppl : 13.469066413879354\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMARGOT: Are you asleep?\\nCLAUDE: Yes.\\nMARGOT: Will you remember this?\\nCLAUDE: Yes.\\nMARGOT: I just talked to your dad... I'm only going to tell you if you won't remember.\\nCLAUDE: Okay.\\nMARGOT: Everyone finds you so funny and charming. I always get compliments about you. Are you having fun? Is it nice to see Pauline?\\nCLAUDE: Yeah, I really like her.\\nMARGOT: Yeah. She is crazy though.\\nCLAUDE: In what way?\\nMARGOT: She's really berserk. Maybe it's hormones. You don't notice anything different about Pauline?\\nCLAUDE: No.\\nMARGOT: She's pregnant -- she told me. But she's keeping it a secret -- I mean from Malcolm and even Ingrid. Which I think is unforgiveable. Now she'll have to marry him. What's she planning -- to get married and not drink champagne? Then she'll just be lying. I guess she's afraid she'll miscarry. She probably will. I think on some level she's ambivalent about the marriage and that's why she's not telling him.\\nCLAUDE: Are you stoned, Mom?\\nMARGOT: Maybe a little.\\n\\n\", 'answer': \"I don't like it.\", 'gold_tag': \"MARGOT has a fixation on Pauline's situation\", 'last_speaker': 'CLAUDE'}\n",
      "Last word -> CLAUDE : \"I don't like it.\"\n",
      "prediction :  You think I'm funny?\n",
      "Real answer : I don't like it.\n",
      "Bert Score : {'precision': [0.858185350894928], 'recall': [0.8850228786468506], 'f1': [0.8713975548744202], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20000000000000004, 'rouge2': 0.0, 'rougeL': 0.20000000000000004, 'rougeLsum': 0.20000000000000004}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 38.69224419681795\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMARGOT: I think you smell nice. You smell real.\\nCLAUDE: I stink.\\nMARGOT: It causes cancer.\\nCLAUDE: Underarm deodorant?\\nMARGOT: Yes. It's got chemicals and things that are extremely harmful.\\nCLAUDE: I'm not going to die from underarm cancer.\\nMARGOT: No, you'll get it somewhere else. Like your stomach or your testicles.\\nCLAUDE: Testicles.\\nMARGOT: Don't laugh, that's a serious thing. Who told you this, anyway? Maisy?\\nCLAUDE: Yeah.\\nMARGOT: I hope you're not interested in that girl. I find her insufferable.\\nCLAUDE: What does that mean?\\nMARGOT: It means I can't suffer her. She's loud and stupid. She goes on about things of which she knows nothing about.\\nCLAUDE: She got into Harvard early.\\nMARGOT: Stupid people get into Harvard early all the time.\\nCLAUDE: Where did you go again?\\nMARGOT: Barnard. I just don't think you should do anything with her.\\nCLAUDE: We're just friends.\\nMARGOT: If you do, use a condom.\\nCLAUDE: Where are you going?\\nMARGOT: Out with Paul and Malcolm and Dick.\\n\\n\", 'answer': 'Are kids coming?', 'gold_tag': 'Everyday Language', 'last_speaker': 'CLAUDE'}\n",
      "Last word -> CLAUDE : \"Are kids coming?\"\n",
      "prediction :  Why can't I come?\n",
      "Real answer : Are kids coming?\n",
      "Bert Score : {'precision': [0.8599330186843872], 'recall': [0.8905075788497925], 'f1': [0.8749532699584961], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 93.85310814806132\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMARGOT: Woa, don't run so fast.\\nCLAUDE: There's a boy! He bit me!\\nMARGOT: Who bit you? Let me see. I'm calling the police.\\nCLAUDE: No, don't! It'll get worse. Why did you say anything to them?\\nMARGOT: Claude, this isn't my fault.\\nCLAUDE: That boy bit me because you couldn't keep your fat mouth shut.\\nMARGOT: Claude, you're being a jerk.\\n\\n\", 'answer': 'You shit in your shoes and then you fuck them!', 'gold_tag': \"CLAUDE's language suggests strong emotions and dissatisfaction\", 'last_speaker': 'CLAUDE'}\n",
      "Last word -> CLAUDE : \"You shit in your shoes and then you fuck them!\"\n",
      "prediction :  I'm sorry, Margot. I'm just really scared.\n",
      "Real answer : You shit in your shoes and then you fuck them!\n",
      "Bert Score : {'precision': [0.8384021520614624], 'recall': [0.8267724514007568], 'f1': [0.8325467109680176], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 27.37433339214454\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMARGOT: I need to be alone right now, okay?\\nCLAUDE: What's wrong?\\nMARGOT: I don't know. I'll tell you sometime. Go on.\\nCLAUDE: Are you sure?\\nMARGOT: Yes. Go with mom. I'll see you later.\\nCLAUDE: You said, mom.\\n\\n\", 'answer': 'But you know what I mean. Go with Pauline. Jesus, do I...do I need to spell it out for you? Go. With. Her.', 'gold_tag': \"MARGOT exhibits impatience when mistakes are made regarding terminology , MARGOT's temporal information\", 'last_speaker': 'MARGOT'}\n",
      "Last word -> MARGOT : \"But you know what I mean. Go with Pauline. Jesus, do I...do I need to spell it out for you? Go. With. Her.\"\n",
      "prediction :  Go with mom.\n",
      "Real answer : But you know what I mean. Go with Pauline. Jesus, do I...do I need to spell it out for you? Go. With. Her.\n",
      "Bert Score : {'precision': [0.8839021921157837], 'recall': [0.8075318932533264], 'f1': [0.8439928889274597], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14814814814814814, 'rouge2': 0.08, 'rougeL': 0.14814814814814814, 'rougeLsum': 0.14814814814814814}\n",
      "bleu 1/2 : 0.0008484225342265386 0.0007347554677833547\n",
      "ppl : 1901.3776412278928\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPRESIDENT GRANT: Yes, Dr. Loveless, what can I do for you today?\\nLOVELESS: I have a humble abode nearby, and I hope you'll accept my hospitality. I have a little proposition to make.\\nPRESIDENT GRANT: What proposition is that?\\nLOVELESS: The unconditional and immediate surrender of the United States of America to the Loveless Alliance.\\n\\n\", 'answer': \"I didn't realize we were at war.\", 'gold_tag': \"PRESIDENT GRANT feels surprised and uninformed about the supposed 'war'\", 'last_speaker': 'PRESIDENT GRANT'}\n",
      "Last word -> PRESIDENT GRANT : \"I didn't realize we were at war.\"\n",
      "prediction :  Well, Dr. Loveless, I think you know that's not possible. I can't surrender the country.\n",
      "Real answer : I didn't realize we were at war.\n",
      "Bert Score : {'precision': [0.8380457162857056], 'recall': [0.8644771575927734], 'f1': [0.8510562777519226], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15999999999999998, 'rouge2': 0.0, 'rougeL': 0.15999999999999998, 'rougeLsum': 0.15999999999999998}\n",
      "bleu 1/2 : 0.06666666666666667 0.02182178902359924\n",
      "ppl : 23.13283402174656\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLOVELESS: Mr. President, I'll ask you once again. Sign the surrender or I decimate this town!\\nPRESIDENT GRANT: You've had my answer.\\n\\n\", 'answer': \"I find the sound of people screaming while they get blown to smithereens, ruins the ear for music. Don't you? Commence firing!\", 'gold_tag': 'LOVELESS has a cold indifference towards causing harm to others', 'last_speaker': 'LOVELESS'}\n",
      "Last word -> LOVELESS : \"I find the sound of people screaming while they get blown to smithereens, ruins the ear for music. Don't you? Commence firing!\"\n",
      "prediction :  Mr. President, you're a brave man, but you're not foolish. You know what will happen if you don't sign that surrender.\n",
      "Real answer : I find the sound of people screaming while they get blown to smithereens, ruins the ear for music. Don't you? Commence firing!\n",
      "Bert Score : {'precision': [0.8462256193161011], 'recall': [0.815077006816864], 'f1': [0.8303593397140503], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1276595744680851, 'rouge2': 0.04444444444444444, 'rougeL': 0.0851063829787234, 'rougeLsum': 0.0851063829787234}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.513463722189638\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPRESIDENT GRANT: Well, I'll be damned... it's West and Gordon... flying! Keep that surrender handy. I think you're going to need it!\\n\\n\", 'answer': \"Don't be too sure... I'm through with diplomacy... Take him away and kill him!\", 'gold_tag': 'LOVELESS is a villainous character , LOVELESS chooses to abandon diplomacy and resort to violence', 'last_speaker': 'LOVELESS'}\n",
      "Last word -> LOVELESS : \"Don't be too sure... I'm through with diplomacy... Take him away and kill him!\"\n",
      "prediction :  Mr. President!\n",
      "Real answer : Don't be too sure... I'm through with diplomacy... Take him away and kill him!\n",
      "Bert Score : {'precision': [0.8818879723548889], 'recall': [0.8156960010528564], 'f1': [0.8475015163421631], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 371.8155520332977\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCASALS (V.O.): M. C. U.\\nHANNA: Bobby, it's me.\\nCASALS (V.O.): Boss, whoever's fencing the Bearer Bonds is either highline or out- of-town. Everyone's talking about it. No one knows about it. Schwartz went through the indexes on recent surveillance tapes? No armored cars. No witnesses\\nHANNA: Albert Torena call me back?\\n\\n\", 'answer': 'No.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CASALS (V.O.)'}\n",
      "Last word -> CASALS (V.O.) : \"No.\"\n",
      "prediction :  No.\n",
      "Real answer : No.\n",
      "Bert Score : {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 1.0, 'rouge2': 0.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
      "bleu 1/2 : 1.0 0.316227766016838\n",
      "ppl : 1275.3241709894667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHANNA: Casals come in.\\nCASALS (V.O.): Vincent. I'm in the southeast stairwell.\\nHANNA: What's the situation?\\n\\n\", 'answer': 'Three teams are moving up the other three stairwells to the', 'gold_tag': 'CASALS V.O. is participating in a strategic operation', 'last_speaker': 'CASALS (V.O.)'}\n",
      "Last word -> CASALS (V.O.) : \"Three teams are moving up the other three stairwells to the\"\n",
      "prediction :  The feds are all over the building.\n",
      "Real answer : Three teams are moving up the other three stairwells to the\n",
      "Bert Score : {'precision': [0.9017085433006287], 'recall': [0.8708302974700928], 'f1': [0.886000394821167], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.33333333333333326, 'rouge2': 0.0, 'rougeL': 0.2222222222222222, 'rougeLsum': 0.2222222222222222}\n",
      "bleu 1/2 : 0.16134803485935978 0.03896925267340483\n",
      "ppl : 107.19674966490456\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHANNA: It means he knew we were here and came anyway.\\nCASALS (V.O.): I got two Special Weapons Teams deployed at the front and back exits. Choppers. On their way. You want a command center in the...\\n\\n', 'answer': \"Yeah, yeah, that's fine. Stay on it. 10-4. For some reason Hanna's disinterested. He's moving down a trying to see through, past, around everything. We don't\", 'gold_tag': 'HANNA is a commanding figure, possibly a senior officer , HANNA exhibits a focused, somewhat disinterested personality , HANNA is trying to see beyond the immediate situation , HANNA, despite being updated on the situation, appears somewhat disinterested and is physically moving', 'last_speaker': 'HANNA'}\n",
      "Last word -> HANNA : \"Yeah, yeah, that's fine. Stay on it. 10-4. For some reason Hanna's disinterested. He's moving down a trying to see through, past, around everything. We don't\"\n",
      "prediction :  No. I want to be on the roof.\n",
      "Real answer : Yeah, yeah, that's fine. Stay on it. 10-4. For some reason Hanna's disinterested. He's moving down a trying to see through, past, around everything. We don't\n",
      "Bert Score : {'precision': [0.8912261724472046], 'recall': [0.8284881711006165], 'f1': [0.8587127923965454], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10256410256410256, 'rouge2': 0.0, 'rougeL': 0.05128205128205128, 'rougeLsum': 0.05128205128205128}\n",
      "bleu 1/2 : 0.026349806140466083 0.00629880842990003\n",
      "ppl : 73.65929923704768\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPRESIDENT: Why the hell wasn't I told about this place?\\n\\n\", 'answer': 'Two words, Mr. President. Plausible deniability.', 'gold_tag': 'NIMZIKI is in a position where he has knowledge of classified information', 'last_speaker': 'NIMZIKI'}\n",
      "Last word -> NIMZIKI : \"Two words, Mr. President. Plausible deniability.\"\n",
      "prediction :  Mr. President, the existence of this place is classified. I'm sure you'll understand once you see what we've found.\n",
      "Real answer : Two words, Mr. President. Plausible deniability.\n",
      "Bert Score : {'precision': [0.8470170497894287], 'recall': [0.871741771697998], 'f1': [0.8592015504837036], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714288, 'rouge2': 0.07692307692307693, 'rougeL': 0.14285714285714288, 'rougeLsum': 0.14285714285714288}\n",
      "bleu 1/2 : 0.05263157894736841 0.017099639201419235\n",
      "ppl : 13.499572703771378\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNIMZIKI: We got the bastards!\\n\\n', 'answer': 'Can they see it? Did it destroy the target?', 'gold_tag': \"PRESIDENT's temporal information\", 'last_speaker': 'PRESIDENT'}\n",
      "Last word -> PRESIDENT : \"Can they see it? Did it destroy the target?\"\n",
      "prediction :  That's great! We've finally got the ones who killed your son.\n",
      "Real answer : Can they see it? Did it destroy the target?\n",
      "Bert Score : {'precision': [0.8663048148155212], 'recall': [0.8712019324302673], 'f1': [0.8687464594841003], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09090909090909093, 'rouge2': 0.0, 'rougeL': 0.09090909090909093, 'rougeLsum': 0.09090909090909093}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 38.797958676686015\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPRESIDENT: Call them back.\\nNIMZIKI: The other bombers might have more luck. We shouldn't just give up...\\n\\n\", 'answer': 'I said call them back.', 'gold_tag': 'PRESIDENT is assertive , PRESIDENT holds a position of power', 'last_speaker': 'PRESIDENT'}\n",
      "Last word -> PRESIDENT : \"I said call them back.\"\n",
      "prediction :  We can't afford to take that risk. We'll call them back.\n",
      "Real answer : I said call them back.\n",
      "Bert Score : {'precision': [0.889378547668457], 'recall': [0.9304927587509155], 'f1': [0.9094712138175964], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.33333333333333337, 'rouge2': 0.25, 'rougeL': 0.33333333333333337, 'rougeLsum': 0.33333333333333337}\n",
      "bleu 1/2 : 0.2727272727272727 0.2335496832484569\n",
      "ppl : 27.482620144099307\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOWARD: Hang on.\\n\\n', 'answer': 'Oh my God.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MARY'}\n",
      "Last word -> MARY : \"Oh my God.\"\n",
      "prediction :  Okay.\n",
      "Real answer : Oh my God.\n",
      "Bert Score : {'precision': [0.9329368472099304], 'recall': [0.8234596848487854], 'f1': [0.874786376953125], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2086.293093463323\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOWARD: We'll just have to wait for this to pass, then we'll keep going. It'll be okay.\\n\\n\", 'answer': 'Crap!', 'gold_tag': 'Everyday Language', 'last_speaker': 'MARY'}\n",
      "Last word -> MARY : \"Crap!\"\n",
      "prediction :  What if it doesn't pass? What if it gets worse?\n",
      "Real answer : Crap!\n",
      "Bert Score : {'precision': [0.8207919001579285], 'recall': [0.8678901195526123], 'f1': [0.8436841368675232], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.218333941214485\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOWARD: Barium... I spy with my little She barely has the energy to get the word out.\\nMARY: Cobalt. Mother Teresa.\\nHOWARD: My best seller. I'm an apple sculptor. I went to school for physics but got bored. Now I just make these and sell them on appleheadsrule.com. I was going to give that one to my girlfriend in Bangor but I can make her another one. She'd probably prefer a Stephen Hawking one anyway. Science is her life. Not like my girlfriend in Tacoma. She's really into Jesus. Same as my other girlfriend in Duluth. Maybe I'll meet them in person one day. They're just so far away and I don't get out much, not farther than the apple orchard or the post office anyway.\\nMARY: But you're out now.\\nHOWARD: I saw the people on TV fighting for Baby Peggy. It wasn't far from my house, and the people there looked nice enough, so I went. I thought I had everything I needed at home but then I thought, maybe there's more.\\nMARY: Maybe there is.\\nHOWARD: Can I tell you something? I like your eyeballs.\\nMARY: They're fuscous, that means -\\n\\n\", 'answer': 'Brownish gray. I know.', 'gold_tag': 'Everyday Language', 'last_speaker': 'HOWARD'}\n",
      "Last word -> HOWARD : \"Brownish gray. I know.\"\n",
      "prediction :  Fuscious?\n",
      "Real answer : Brownish gray. I know.\n",
      "Bert Score : {'precision': [0.7873501181602478], 'recall': [0.8552140593528748], 'f1': [0.8198801875114441], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3603.2428131954475\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMARY: \"Eunice, Louisiana. Please...\"\\nHOWARD: M-E-A-T. \"Please meat me there. XO Steve\".\\nMARY: See? He needs me, if only to help with his spelling.\\n\\n', 'answer': 'No kidding.', 'gold_tag': 'Everyday Language', 'last_speaker': 'HOWARD'}\n",
      "Last word -> HOWARD : \"No kidding.\"\n",
      "prediction :  I'm afraid I can't do that, Mary. I have to be in the next room.\n",
      "Real answer : No kidding.\n",
      "Bert Score : {'precision': [0.8395865559577942], 'recall': [0.8691161870956421], 'f1': [0.8540961742401123], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 10.971903962260116\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBALA: What was that thing?\\nZ: How should I know?\\nBALA: I order you to find out where we are!\\nZ: Alright, alright, I\\'ll try to get directions from one of the locals. Excuse me, I -- Pardon me -- And they call them social insects.\\nBALA: Climb up that tree and get a better view! I\\'ve been kidnapped by the village idiot.\\nZ: who gets kidnapped, or the idiot who idiot?\\nBALA: How dare you speak to me like that? I\\'m the Princess!\\nZ: Theoretically, yes. But is the monarchical hierarchy applicable without the underlying social structure to support it?\\nBALA: Of course! It defines society! To deny the precept is to say that order is an arbitrary distinction applied by the society itself!\\nZ: But can there be a society composed of just two ants?\\nBALA: No! There\\'s no such thing as \"just two ants.\" You never see just two ants -- you see a million ants!\\nZ: Look around, sweetheart.\\nBALA: I -- hate -- you.\\nZ: Well I guess that makes us even.\\nBALA: Ha! Don\\'t make me laugh. You\\'re crazy about me! That\\'s why you lied and cheated to get near me!\\nZ: Oh come on, you\\'re the one who came after me -- the swarthy, earthy, sensual worker!\\nBALA: I was slumming it! I danced with you because you were the most pathetic specimen in the place!\\nZ: Is that the same standard you used to choose General Formica?\\nBALA: I didn\\'t choose him. What kind of idiot would... ...choose who she wanted to marry? Now, worker, you shall take me back to the colony, and have your head cut off and stuck on a sharp pole!\\nZ: Well, that\\'s an appealing offer, but...considering the options... You go back. Me, I\\'m going to Insectopia.\\nBALA: Insectopia? You stupid worker, that\\'s just a fairy tale!\\nZ: Yeah, well I have it on a reliable source... that it exists. Now you follow the yellow egg... That direction.\\n\\n', 'answer': \"Worker! Come back here now! That's not a name! That's just a letter! Worker? Oh WORKER? Where are you? Z? Z? Wait for me!!!\", 'gold_tag': 'Everyday Language', 'last_speaker': 'BALA'}\n",
      "Last word -> BALA : \"Worker! Come back here now! That's not a name! That's just a letter! Worker? Oh WORKER? Where are you? Z? Z? Wait for me!!!\"\n",
      "prediction :  ...You're insane!\n",
      "Real answer : Worker! Come back here now! That's not a name! That's just a letter! Worker? Oh WORKER? Where are you? Z? Z? Wait for me!!!\n",
      "Bert Score : {'precision': [0.8435428738594055], 'recall': [0.8069249391555786], 'f1': [0.8248276710510254], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06896551724137931, 'rouge2': 0.0, 'rougeL': 0.06896551724137931, 'rougeLsum': 0.06896551724137931}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 127.19207641468837\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBALA: Water...water... that. My skin's dry, my exoskeleton is cracking...I wish I'd never met you, you ruined my life.\\nZ: I ruined your life? Look, I was perfectly happy until I met you -- alright, I was miserable, but I was happily miserable.\\nBALA: Look out! We're going to die!\\nZ: Come on -- it's gone! What are the chances of that happening again? Well I'll be.\\nBALA: Why didn't I listen to my mother ...why'd I have to go looking for trouble? Any ant would have given their left legs to be in my position...what's wrong with me?\\nZ: Want a list?\\n\\n\", 'answer': 'Wait, I hear something! WATER!!!', 'gold_tag': 'BALA hears something which turns out to be water', 'last_speaker': 'BALA'}\n",
      "Last word -> BALA : \"Wait, I hear something! WATER!!!\"\n",
      "prediction :  No, I don't want to hear it. I'm going to die and you're going to live.\n",
      "Real answer : Wait, I hear something! WATER!!!\n",
      "Bert Score : {'precision': [0.8460595607757568], 'recall': [0.853909969329834], 'f1': [0.8499666452407837], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.12500000000000003 0.028867513459481287\n",
      "ppl : 8.290645258591205\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZ: This lake is huge! And so close to the colony! Think of the vacation potential!\\nBALA: Cut me down a soft leaf so I can take a nap.\\nZ: Listen, \"Princess\", you can\\'t order me around. Out here, you\\'re not the boss anymore -- out here, you\\'re just --\\nBALA: Out here I\\'m just what? Hlllllllp! Stop fooling around in there. Let me go!!! I\\'m going to be rescued soon. I\\'m going to be rescued soon. I\\'m going to be rescued soon.\\nZ: Princess, has it ever occurred to you that they\\'re not going to rescue you?\\nBALA: General Formica won\\'t let me die out here. I\\'m his fiancee.\\nZ: Look. How many other Princesses are there?\\nBALA: Five thousand three hundred and ninety -- no. About five thousand four hundred by now.\\nZ: And only you can become a Queen?\\nBALA: Well...no, but --\\nZ: So what makes you so special?\\n\\n', 'answer': \"Well...I am the oldest. By three seconds... You're right. There are as many Princesses...as there are blades of grass.\", 'gold_tag': 'BALA is the oldest princess among approximately 5400 others', 'last_speaker': 'BALA'}\n",
      "Last word -> BALA : \"Well...I am the oldest. By three seconds... You're right. There are as many Princesses...as there are blades of grass.\"\n",
      "prediction :  I'm not a special person. I'm a special Princess.\n",
      "Real answer : Well...I am the oldest. By three seconds... You're right. There are as many Princesses...as there are blades of grass.\n",
      "Bert Score : {'precision': [0.8870739936828613], 'recall': [0.8244622349739075], 'f1': [0.8546229004859924], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.060606060606060615, 'rouge2': 0.0, 'rougeL': 0.060606060606060615, 'rougeLsum': 0.060606060606060615}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 39.72061101407158\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBALA: I swear, we've passed this blade of grass three times. Face it, Z, we're lost! We must have walked halfway across the world by now! How did I get into this mess...\\nZ: Come on...tell me there wasn't just a little...something between us that first night at the bar. The night we danced.\\n\\n\", 'answer': \"What difference does it make...we're both going to starve to death, or get squished, or set on fire... ...The land of red and white...\", 'gold_tag': 'BALA has a sardonic sense of humor, referencing the \"land of red and white\" as a potential danger', 'last_speaker': 'BALA'}\n",
      "Last word -> BALA : \"What difference does it make...we're both going to starve to death, or get squished, or set on fire... ...The land of red and white...\"\n",
      "prediction :  I'm telling you, Z, it's just the two of us out here! I don't know what you're trying to say!\n",
      "Real answer : What difference does it make...we're both going to starve to death, or get squished, or set on fire... ...The land of red and white...\n",
      "Bert Score : {'precision': [0.8398147821426392], 'recall': [0.8322258591651917], 'f1': [0.8360031247138977], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.24000000000000002, 'rouge2': 0.0, 'rougeL': 0.12000000000000001, 'rougeLsum': 0.12000000000000001}\n",
      "bleu 1/2 : 0.08187307530779821 0.01878297165597829\n",
      "ppl : 9.881797962108738\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZ: Bala!\\nBALA: Z! You came back!\\nZ: Why do they have you tied up here?\\nBALA: There's something going on, Z -- They're having a ceremony to open the Megatunnel...\\nZ: Bala, that -- that lake we found -- I think the tunnel's right underneath it! -- Formica's going to flood the colony!!! That's what he meant when said there were too many ants!\\nBALA: Oh no... Z! what are you doing?\\nZ: I know it's crazy, but -- I can't just leave. Don't argue with me. If I've learned anything, it's that the problems of two people don't add up to a hill of ants in this world. Or beans. Something like that. Anyway, I've got to warn the others. Head for the surface, Bala. If I don't make it, well...we'll always have Insectopia.\\n\\n\", 'answer': 'Z!!! Wait for me!', 'gold_tag': 'Everyday Language', 'last_speaker': 'BALA'}\n",
      "Last word -> BALA : \"Z!!! Wait for me!\"\n",
      "prediction :  Z...Z, no...!\n",
      "Real answer : Z!!! Wait for me!\n",
      "Bert Score : {'precision': [0.8365271091461182], 'recall': [0.8721626400947571], 'f1': [0.8539732694625854], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 818.240400309803\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTANLEY: Who are you supposed to be?\\nGINGER: Hello, Stanley. I'm Ginger.\\nSTANLEY: Is that right?\\nGINGER: For someone the N.S.A. has listed as the most dangerous hacker in America, you sure don't look like much. Don't look so surprised. I know everything there is to know about you, Stan. From your mom's maiden name to how big your... Bank account is.\\nSTANLEY: How'd you get past my dog?\\nGINGER: Boys like me.\\nSTANLEY: Great. What are you selling again?\\nGINGER: Did I say I was selling something? I'm here to help you, Stan. Look at you, you're a mess. My employer wants to meet you. You're not very good at this, are you?\\nSTANLEY: You're fucking up my chi.\\n\\n\", 'answer': \"Can I see that? You need to straighten your left arm. You're bending it. Trust me.\", 'gold_tag': 'GINGER could be a professional in information gathering or spying , STANLEY is practicing some form of martial art or exercise', 'last_speaker': 'GINGER'}\n",
      "Last word -> GINGER : \"Can I see that? You need to straighten your left arm. You're bending it. Trust me.\"\n",
      "prediction :  I'm sorry, Stan.\n",
      "Real answer : Can I see that? You need to straighten your left arm. You're bending it. Trust me.\n",
      "Bert Score : {'precision': [0.8527772426605225], 'recall': [0.8401027917861938], 'f1': [0.8463925719261169], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809523, 'rouge2': 0.0, 'rougeL': 0.09523809523809523, 'rougeLsum': 0.09523809523809523}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 99.23291926500595\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTANLEY: What are you doing here? Judas.\\nGINGER: Hello, Stanley.\\nSTANLEY: Look, I'm beginning to lose my sense of humor about --\\nGINGER: Let's cut through the bullshit, Stan. If you ever want to have a chance in hell of getting your daughter back you'll shut up and listen. Unless of course you want to stay here in your pathetic, loser life while she learns what\\nSTANLEY: Do me the courtesy of not confusing your own childhood with my daughter's.\\nGINGER: Look at your situation, Stanley. For twenty months you've been in court six times, each time your custody case has been thrown out. Your situation doesn't look good, sweetheart. How much would it cost to retain the best family lawyer in the country and regain custody of your daughter?\\nSTANLEY: All the way through the jury trial?\\nGINGER: Yeah.\\nSTANLEY: A lot.\\nGINGER: This should get you started. Whattaya have to lose? Just meet him. One time. That's it. You don't like the setup, walk away.\\nSTANLEY: That's it?\\n\\n\", 'answer': \"That's it. And you keep the money.\", 'gold_tag': 'GINGER is assertive and direct', 'last_speaker': 'GINGER'}\n",
      "Last word -> GINGER : \"That's it. And you keep the money.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : That's it. And you keep the money.\n",
      "Bert Score : {'precision': [0.9260859489440918], 'recall': [0.8622256517410278], 'f1': [0.8930155634880066], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTANLEY: Shit!\\nGINGER: Relax, Stanley. You can do this.\\nSTANLEY: Get away from me.\\nGINGER: I want to help you.\\nSTANLEY: Help? Help what, squeegee my brain off the ceiling?\\nGINGER: It was just a test, Stan, you passed.\\nSTANLEY: A test... I don't know why I let you talk me into this. I can't believe how desperate I am.\\nGINGER: I thought you were here saving your daughter, Stanley.\\nSTANLEY: Look... I'd do anything to get Holly back. But, if I end up in a box or back in jail, then I really can't help her, can I? What I should do, is take my money and go back to court.\\nGINGER: Back to court? Back to Melissa's gladiators? You throw a hundred grand at her, she'll throw five back at you. It's not about Holly, it's about beating you.\\nSTANLEY: What I'm thinking about is that you're willing to put a gun to my head to see if I can hack --\\n\\n\", 'answer': \"Sorry... So, let me sum it up for you, Stanley. You live in a trailer. You're a felon, working a dead- end job. You want to get Holly back, Gabriel's your only shot.\", 'gold_tag': 'STANLEY is living in a trailer , STANLEY has committed a felony , STANLEY works a dead-end job , STANLEY is fighting for his daughter, Holly', 'last_speaker': 'GINGER'}\n",
      "Last word -> GINGER : \"Sorry... So, let me sum it up for you, Stanley. You live in a trailer. You're a felon, working a dead- end job. You want to get Holly back, Gabriel's your only shot.\"\n",
      "prediction :  You can't hack anything, Stanley. You're a joke.\n",
      "Real answer : Sorry... So, let me sum it up for you, Stanley. You live in a trailer. You're a felon, working a dead- end job. You want to get Holly back, Gabriel's your only shot.\n",
      "Bert Score : {'precision': [0.8939399719238281], 'recall': [0.8425456881523132], 'f1': [0.8674822449684143], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.13953488372093023, 'rougeL': 0.22222222222222224, 'rougeLsum': 0.22222222222222224}\n",
      "bleu 1/2 : 0.02196846681170371 0.011742639446015621\n",
      "ppl : 34.25212568948728\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGINGER: Don't you have that just-fucked- the-neighbor's-cat look this morning. Problem?\\nSTANLEY: Pretty impressive.\\nGINGER: I thought we went over all that last night.\\nSTANLEY: The book, Ginger.\\nGINGER: Ohhh. Look, no pictures. Get out of my light.\\nSTANLEY: Can I borrow your car? There's something I need to do.\\n\\n\", 'answer': \"If you're going to see your daughter, you might want to reevaluate the way you look. Just a thought.\", 'gold_tag': 'GINGER readily offers advice about appearance , STANLEY has a daughter', 'last_speaker': 'GINGER'}\n",
      "Last word -> GINGER : \"If you're going to see your daughter, you might want to reevaluate the way you look. Just a thought.\"\n",
      "prediction :  Can you do it from here?\n",
      "Real answer : If you're going to see your daughter, you might want to reevaluate the way you look. Just a thought.\n",
      "Bert Score : {'precision': [0.8602128028869629], 'recall': [0.8565855026245117], 'f1': [0.8583952784538269], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307691, 'rouge2': 0.0, 'rougeL': 0.07692307692307691, 'rougeLsum': 0.07692307692307691}\n",
      "bleu 1/2 : 0.01909314066544796 0.006614057941723061\n",
      "ppl : 130.45445105500292\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTANLEY: That's not my problem, is it? You're asking for a lot of faith here, Ging, without givin' me any. You --\\nGINGER: -- Stanley --\\nSTANLEY: -- brought me into this mess --\\nGINGER: -- Stanley --\\n\\n\", 'answer': \"-- I deserve to know who's playing me, Ginger. Who the fuck are you?\", 'gold_tag': \"STANLEY feels played , STANLEY demands to know more about GINGER's identity\", 'last_speaker': 'STANLEY'}\n",
      "Last word -> STANLEY : \"-- I deserve to know who's playing me, Ginger. Who the fuck are you?\"\n",
      "prediction :  -- and now you're asking me to trust you?\n",
      "Real answer : -- I deserve to know who's playing me, Ginger. Who the fuck are you?\n",
      "Bert Score : {'precision': [0.8633862137794495], 'recall': [0.8710905909538269], 'f1': [0.8672212958335876], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2608695652173913, 'rouge2': 0.0, 'rougeL': 0.17391304347826086, 'rougeLsum': 0.17391304347826086}\n",
      "bleu 1/2 : 0.1912511402458109 0.03703562405576024\n",
      "ppl : 37.964029457278784\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTANLEY: What do you think? I just watched that maniac murder ten men in the street. I'm just fucking great. It doesn't matter if I get my daughter back if I'm dead. Even if I do survive this, who's gonna keep me out of jail? You?\\nGINGER: I won't let anything happen to you, Stanley. You have to trust me.\\nSTANLEY: Trust you? Two hours ago I found out you're D.E.A. The feds are crawling up my ass and\\nGINGER: Stanley, if we don't find out who he's working for then we're just going to have to do this all over again.\\nSTANLEY: Your little slush fund is not my problem. I'm pulling the plug on this rodeo. Roberts may be an asshole, but he is definitely the\\nGINGER: I've been working on this thing for eight months, and I will not let some jarhead fed fuck up my operation. Please, I know what I'm doing. C'mon, Stanley. You have twelve\\n\\n\", 'answer': \"You're starting to sound just like him.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'STANLEY'}\n",
      "Last word -> STANLEY : \"You're starting to sound just like him.\"\n",
      "prediction :  What do you mean?\n",
      "Real answer : You're starting to sound just like him.\n",
      "Bert Score : {'precision': [0.8110229969024658], 'recall': [0.8251888751983643], 'f1': [0.8180446028709412], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 79.14500084705968\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALI: Where are you taking me?\\nMARCUS: I told you-- to dinner.\\nALI: Dinner? What about Nikki-- What's up with you and Nikki?\\nMARCUS: We're friends.\\nALI: Where I'm from friends don't chew each other's earlobes.\\nMARCUS: Aren't you glad you left? Oh, damn!\\nALI: What?\\nMARCUS: I just remembered I have to make a quick appearance at a party.\\nALI: You just remembered.\\nMARCUS: It's on the way. We'll be quick. Ten minutes, tops. Do you mind?\\nALI: And if I do.\\n\\n\", 'answer': \"Then you've been kidnapped.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"Then you've been kidnapped.\"\n",
      "prediction :  Then we'll just have to stay longer.\n",
      "Real answer : Then you've been kidnapped.\n",
      "Bert Score : {'precision': [0.850114107131958], 'recall': [0.8895909190177917], 'f1': [0.8694045543670654], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615385, 'rouge2': 0.0, 'rougeL': 0.15384615384615385, 'rougeLsum': 0.15384615384615385}\n",
      "bleu 1/2 : 0.14285714285714285 0.048795003647426664\n",
      "ppl : 50.66746095729449\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALI: Marcus -- you can't just take that.\\nMARCUS: SHHH --\\nALI: They're gonna throw us out of here.\\n\\n\", 'answer': 'Not if we sneak out first, come on.', 'gold_tag': 'MARCUS takes risks , MARCUS exhibits a rebellious streak', 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"Not if we sneak out first, come on.\"\n",
      "prediction :  Don't worry about it.\n",
      "Real answer : Not if we sneak out first, come on.\n",
      "Bert Score : {'precision': [0.877768337726593], 'recall': [0.8463727235794067], 'f1': [0.8617846965789795], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 49.351302894790734\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMARCUS: Better?\\nALI: Better.\\nMARCUS: You're gonna be on one of those someday.\\nALI: Yeah, right.\\nMARCUS: Sooner than you think, too. Harold Saint called me today. You made quite an impression on him.\\nALI: Really? What'd he say?\\nMARCUS: He wants to make a demo with you.\\nALI: Are you serious? When??\\nMARCUS: He found a little studio time on Tuesday.\\nALI: This Tuesday?\\nMARCUS: Too soon?\\nALI: No! Oh my god, no, that's amazing. You're amazing.\\nMARCUS: I like making you happy. Your whole face lights up.\\nALI: I think you're way too nice to me.\\nMARCUS: And that's a problem because...\\nALI: I've had a lot to drink. And my judgment is off.\\nMARCUS: Hey, I'm a gentleman. Which means I'd never kiss a lady when she's... vulnerable.\\n\\n\", 'answer': 'Liar.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ALI'}\n",
      "Last word -> ALI : \"Liar.\"\n",
      "prediction :  (chuckles) Yeah, I guess that's true.\n",
      "Real answer : Liar.\n",
      "Bert Score : {'precision': [0.8125115036964417], 'recall': [0.8614997863769531], 'f1': [0.8362888693809509], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13.90141883762155\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMARCUS: Morning.\\nALI: What is this?\\nMARCUS: Now it's a model. But when it grows up, it'll be a mixed-use space: retail and residential.\\nALI: This is the address of the Burlesque Lounge.\\nMARCUS: Best view on the Sunset Strip, with no windows. When I'm done with it, it'll have a thousand.\\nALI: You can't tear down the club.\\nMARCUS: Actually, I can.\\nALI: But what about the history? That place is a landmark.\\nMARCUS: Not according to the city.\\nALI: Does Tess know about this?\\nMARCUS: What Tess knows and doesn't know isn't a big concern of mine.\\nALI: What makes you think she would ever sell the Lounge?\\nMARCUS: She has no choice. She's going under.\\nALI: But that club is her life!\\nMARCUS: Oh, come on, you get this. It's business. It's not personal.\\nALI: Not personal? It's pretty god damn personal for Tess! And Coco and Sean and Alexis. And what about Jesse? And Dave the lighting guy? And what about me? It's pretty God damn personal to me.\\nMARCUS: Where are you going?\\nALI: To the club. Where I work.\\n\\n\", 'answer': 'Ali-- wait!!!', 'gold_tag': 'Everyday Language', 'last_speaker': 'MARCUS'}\n",
      "Last word -> MARCUS : \"Ali-- wait!!!\"\n",
      "prediction :  You can't stop me.\n",
      "Real answer : Ali-- wait!!!\n",
      "Bert Score : {'precision': [0.8345630168914795], 'recall': [0.7816441059112549], 'f1': [0.8072372674942017], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 46.344051679115395\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPERRY BABCOCK: I really don't think we should be leaving him.\\nSANDRA BABCOCK: Perry, you promised me a meal that someone else microwaved. ParaNorman 30.\\n\\n\", 'answer': \"He's probably up there right now fiddling with his ouija, or his orbs, or whatever it is he's got up there. This is not good.\", 'gold_tag': \"PERRY BABCOCK has some knowledge about supernatural or occult activities, such as ouija boards and orbs, suggesting he may be open-minded or superstitionally inclined , PERRY BABCOCK's concern about the present moment is that he feels uncomfortable leaving someone alone with occult items\", 'last_speaker': 'PERRY BABCOCK'}\n",
      "Last word -> PERRY BABCOCK : \"He's probably up there right now fiddling with his ouija, or his orbs, or whatever it is he's got up there. This is not good.\"\n",
      "prediction :  Fine. Let's go.\n",
      "Real answer : He's probably up there right now fiddling with his ouija, or his orbs, or whatever it is he's got up there. This is not good.\n",
      "Bert Score : {'precision': [0.8937892913818359], 'recall': [0.806219220161438], 'f1': [0.8477488160133362], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06451612903225806, 'rouge2': 0.0, 'rougeL': 0.06451612903225806, 'rougeLsum': 0.06451612903225806}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 89.47416193496208\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSANDRA BABCOCK: I really think it might help if you tried to see things from his point of view.\\n\\n', 'answer': \"I don't want to.\", 'gold_tag': 'PERRY BABCOCK is resistant to adopting other perspectives', 'last_speaker': 'PERRY BABCOCK'}\n",
      "Last word -> PERRY BABCOCK : \"I don't want to.\"\n",
      "prediction :  I don't know, Sandra, I just don't see how I can. I mean, he's my son, and he's been in this for so long. I just don't see how I can keep going on like this.\n",
      "Real answer : I don't want to.\n",
      "Bert Score : {'precision': [0.827317476272583], 'recall': [0.8938736915588379], 'f1': [0.8593087792396545], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13043478260869565, 'rouge2': 0.09090909090909091, 'rougeL': 0.13043478260869565, 'rougeLsum': 0.13043478260869565}\n",
      "bleu 1/2 : 0.05555555555555554 0.03984095364447979\n",
      "ppl : 6.281056024625242\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSANDRA BABCOCK: Perry, not believing in the Afterlife is like not believing in Astrology.\\nPERRY BABCOCK: I have no idea what you're talking about. Seriously, where did you learn that?\\n\\n\", 'answer': 'Calm down.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SANDRA BABCOCK'}\n",
      "Last word -> SANDRA BABCOCK : \"Calm down.\"\n",
      "prediction :  I'm a graduate of the University of Chicago.\n",
      "Real answer : Calm down.\n",
      "Bert Score : {'precision': [0.8641546964645386], 'recall': [0.8863095045089722], 'f1': [0.8750919103622437], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 19.13098370231413\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCAL: Can't help but notice that you're I'm getting divorced. Or, in the process. Gonna be single again. Any advice?\\nJACOB: Yeah. Don't start conversations with people while they're pissing.\\n\\n\", 'answer': 'So gay.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CAL'}\n",
      "Last word -> CAL : \"So gay.\"\n",
      "prediction :  I'm sorry. I didn't mean to interrupt.\n",
      "Real answer : So gay.\n",
      "Bert Score : {'precision': [0.8301746845245361], 'recall': [0.8848128318786621], 'f1': [0.8566234111785889], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13.772488765820874\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCAL: This is my youngest, Molly. Her two favorite things are High School Musical and her mother. I hate both of her two favorite things.\\nJACOB: Jacob Palmer. I'd like to buy you a drink, Cal.\\nCAL: I already have a drink.\\nJACOB: Let me buy you a drink, Cal.\\nCAL: Okay. My wife is cheating on me with --\\nJACOB: David Jacobowitz, yes, Cal, I've heard. We've all heard. For the last two nights, I've watched you batter every poor soul in this bar with your sad-sack loser sob story.\\nCAL: You know what, I don't need this CRAP --\\nJACOB: Sit down, Cal.\\nCAL: Okay.\\nJACOB: Cal, I'm going to make you an offer, it's probably the best offer you're ever going to get, and you're extremely drunk, so it's wildly important that you don't answer until I've finished and you've taken a few moments to process what I'm saying. Do you understand? As I said, I've been watching you for two days now and I can say, without hesitation, that you are my life -- don't interrupt, Cal, it's the truth, and you need to hear it. You're sitting there with your Supercut haircut, getting drunk on watered down jacket when you should be wearing a 40L -- I don't know if I want to help you or euthanize you -- stop drinking out of the goddamn straw, Cal. You asked me for advice before, Cal, so I'm going to help you. I don't know why. Maybe I'm just bored. Maybe all my friends have abandoned me for wives and children and labradoodle puppies, who cares why? Why doesn't matter. The point is, you've got a good face, and a good head of hair, and I'm bored as hell and need a project. So if you want, I'm going to help you rediscover your manhood. Do you remember when it was that you lost it? Doesn't matter, we'll find it. And when we do, when I'm through with you, that wife of yours is going to rue the day she decided to give up on you too early. That's my offer. What do you say?\\nCAL: Yeah, okay.\\nJACOB: Mall food court, Thursday, six o'clock.\\nCAL: I'm sorry, what?\\n\\n\", 'answer': 'You ready to go?', 'gold_tag': \"JACOB's temporal information\", 'last_speaker': 'JACOB'}\n",
      "Last word -> JACOB : \"You ready to go?\"\n",
      "prediction :  Mall food court, Thursday, six o'clock. Don't be late.\n",
      "Real answer : You ready to go?\n",
      "Bert Score : {'precision': [0.82914137840271], 'recall': [0.8337365388870239], 'f1': [0.8314326405525208], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 36.74796400132635\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACOB: You're late. Sbarro's?\\nCAL: No thanks. So what exactly are WE --\\nJACOB: How much money can you afford to spend on clothes today?\\nCAL: I dunno. Five hundred?\\nJACOB: Three thousand.\\nCAL: Okay.\\nJACOB: We'll start with shoes. Let me see those sneakers you're wearing. Take them off. Other one too, please?\\nCAL: What the hell!?\\nJACOB: Are you in a fraternity, Cal?\\nCAL: Those were my favorite shoes.\\nJACOB: ARE YOU IN A FRATERNITY, CAL!?\\nCAL: No.\\nJACOB: Are you Steve Jobs?\\nCAL: What?\\nJACOB: ARE YOU THE BILLIONAIRE OWNER OF APPLE COMPUTERS?\\nCAL: No. I'm not Steve Jobs.\\n\\n\", 'answer': \"Then you don't need to walk around in New Balance Sneaker, ever. Let's go.\", 'gold_tag': \"JACOB challenges CAL's choice of footwear\", 'last_speaker': 'JACOB'}\n",
      "Last word -> JACOB : \"Then you don't need to walk around in New Balance Sneaker, ever. Let's go.\"\n",
      "prediction :  Good.\n",
      "Real answer : Then you don't need to walk around in New Balance Sneaker, ever. Let's go.\n",
      "Bert Score : {'precision': [0.9294071197509766], 'recall': [0.8384507298469543], 'f1': [0.8815891146659851], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 6379.513322406738\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCAL: I notice you only button your shirts up, like, halfway. I can't pull that off, right?\\nJACOB: No. Listen, Cal, I'm going to be calling women over to our table shortly.\\nCAL: We should have some background on each other, no? I'm in insurance, more on the corporate side. My kids are --\\nJACOB: Cal, the only thing I care less about than corporate insurance are your kids. Here's the only thing I need to know: how many women have you been with?\\nCAL: Sexually?\\nJACOB: Yes.\\nCAL: In my entire life?\\nJACOB: No, synchronized swimming. Yes, Cal. Sexually.\\nCAL: One.\\nJACOB: Wow, okay... wow. Not at a time? Total?\\nCAL: What? I married young. We met in high school. Tracy was so damn beautiful. You know those women, the ones who can be wildly sexy and unbelievably cute all at once? I never knew how she did that. I still don't know how she does it. Anyway, we had a bit of a hiccup our senior year but we made it --\\nJACOB: Cal, I literally stopped listening at `Tracy.' Okay, here we go.\\nCAL: I miss my wife.\\nJACOB: Shut up, Cal. Hi. Jacob Palmer.\\nCAL: CAL --\\nJACOB: Don't.\\nCAL: -- Weaver.\\n\\n\", 'answer': 'Can I get you a drink, Amy?', 'gold_tag': 'Everyday Language', 'last_speaker': 'JACOB'}\n",
      "Last word -> JACOB : \"Can I get you a drink, Amy?\"\n",
      "prediction :  I know.\n",
      "Real answer : Can I get you a drink, Amy?\n",
      "Bert Score : {'precision': [0.8673479557037354], 'recall': [0.8371427655220032], 'f1': [0.8519777655601501], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.22222222222222224, 'rougeLsum': 0.22222222222222224}\n",
      "bleu 1/2 : 0.0410424993119494 0.018354763685601443\n",
      "ppl : 663.9337011017111\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACOB: ... it would work!\\nCAL: You're out of your mind.\\nJACOB: What do college guys hate? Doing laundry. What do they love? Strippers. It's a strip club where they can do their laundry. And yours isn't? A candy store\\nCAL: Everyone loves the cherry. Look, I'm not rejecting the psuedo- cherry flavors like raspberry or strawberry, anything in the -erry family is allowed. But let's be real here: no one wants the lemon. No one likes the grape.\\nJACOB: I like grape.\\n\\n\", 'answer': \"Well then you can't come to my store.\", 'gold_tag': 'CAL has an interest in owning a candy store', 'last_speaker': 'CAL'}\n",
      "Last word -> CAL : \"Well then you can't come to my store.\"\n",
      "prediction :  I'll give you a dollar for every grape candy you eat.\n",
      "Real answer : Well then you can't come to my store.\n",
      "Bert Score : {'precision': [0.8694169521331787], 'recall': [0.8697397112846375], 'f1': [0.8695783019065857], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809525, 'rouge2': 0.0, 'rougeL': 0.09523809523809525, 'rougeLsum': 0.09523809523809525}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 26.073527422330155\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCAL: Hello?\\nJACOB: Hey, Cal.\\nCAL: Oh. My. God. It's alive.\\nJACOB: I'm sorry. I know I've been out of circulation.\\nCAL: You abandoned me at my time of need.\\nJACOB: I've been a little... things have gotten a bit... I met a woman.\\nCAL: I bet you did.\\nJACOB: No, I mean, I've been spending a lot of time with her. This woman. One woman.\\nCAL: Okay, whatever.\\nJACOB: Actually, tonight... I'm going to meet her mother.\\nCAL: Whoa!!!! Look at you! You do realize you might actually have to answer a question or two about yourself?\\nJACOB: Yes, I realize that, asshole. Gotta go. Grab a beer next week?\\nCAL: You've got my number. Hey. Good for you, by the way.\\n\\n\", 'answer': 'Thanks.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JACOB'}\n",
      "Last word -> JACOB : \"Thanks.\"\n",
      "prediction :  You're still alive.\n",
      "Real answer : Thanks.\n",
      "Bert Score : {'precision': [0.8687442541122437], 'recall': [0.9474998712539673], 'f1': [0.9064145684242249], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 69.55503840136274\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTEVE: Nice outfit.\\nDIANA: Thank you. Now I will show you the way off the island. And you will take me to Ares.\\n\\n', 'answer': 'Deal.', 'gold_tag': 'STEVE is the person who will assist DIANA in her quest in leaving the island', 'last_speaker': 'STEVE'}\n",
      "Last word -> STEVE : \"Deal.\"\n",
      "prediction :  I can't take you to Ares.\n",
      "Real answer : Deal.\n",
      "Bert Score : {'precision': [0.8472195863723755], 'recall': [0.9337471127510071], 'f1': [0.8883813619613647], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 78.08110011679811\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTEVE: Train leaves in a few minutes. Hungry?\\nDIANA: It's cold.\\nSTEVE: It's ice cream.\\nDIANA: It's wonderful. You should be very proud.\\n\\n\", 'answer': \"Forget the countries or the territory or the Generals. This is what we're really fighting for.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'STEVE'}\n",
      "Last word -> STEVE : \"Forget the countries or the territory or the Generals. This is what we're really fighting for.\"\n",
      "prediction :  Why?\n",
      "Real answer : Forget the countries or the territory or the Generals. This is what we're really fighting for.\n",
      "Bert Score : {'precision': [0.8456414937973022], 'recall': [0.8119733333587646], 'f1': [0.8284655213356018], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3142.135932895678\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTEVE: We've got to get a move on. Chief won't wait.\\nDIANA: Chief?\\nSTEVE: Smuggler. Very reputable.\\nDIANA: A liar, a murderer, and now a smuggler?\\nSTEVE: Careful, I might get offended.\\nDIANA: I wasn't referring to you.\\n\\n\", 'answer': 'I went undercover and pretended to be something else, I shot people on your beach, and I smuggled a notebook. Liar, murderer, smuggler. You still coming?', 'gold_tag': \"STEVE is an undercover agent , Both reminisce about STEVE's actions on DIANA's beach\", 'last_speaker': 'STEVE'}\n",
      "Last word -> STEVE : \"I went undercover and pretended to be something else, I shot people on your beach, and I smuggled a notebook. Liar, murderer, smuggler. You still coming?\"\n",
      "prediction :  I'm just a simple man. I like my life simple.\n",
      "Real answer : I went undercover and pretended to be something else, I shot people on your beach, and I smuggled a notebook. Liar, murderer, smuggler. You still coming?\n",
      "Bert Score : {'precision': [0.8775842189788818], 'recall': [0.8366698622703552], 'f1': [0.8566387891769409], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16216216216216214, 'rouge2': 0.0, 'rougeL': 0.10810810810810811, 'rougeLsum': 0.10810810810810811}\n",
      "bleu 1/2 : 0.04037930359893108 0.009517493131464843\n",
      "ppl : 14.975023378054514\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIANA: The gas will kill everyone... everything. What kind of weapon kills innocents?\\n\\n', 'answer': 'In this war? Every kind.', 'gold_tag': 'Steve indicates knowledge about war and its brutalities , Steve is more pragmatic and resigned', 'last_speaker': 'STEVE'}\n",
      "Last word -> STEVE : \"In this war? Every kind.\"\n",
      "prediction :  A weapon.\n",
      "Real answer : In this war? Every kind.\n",
      "Bert Score : {'precision': [0.9003971219062805], 'recall': [0.8374350070953369], 'f1': [0.867775559425354], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2397.8313953429442\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTEVE: She's drawing their fire! Let's go!\\n\\n\", 'answer': \"We're not finished yet.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'DIANA'}\n",
      "Last word -> DIANA : \"We're not finished yet.\"\n",
      "prediction :  I can't. I'm the only one who can stop her.\n",
      "Real answer : We're not finished yet.\n",
      "Bert Score : {'precision': [0.8607023358345032], 'recall': [0.8748939037322998], 'f1': [0.8677400946617126], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18.707014732796914\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIANA: Stay here. I'll go ahead.\\n\\n\", 'answer': 'Go!', 'gold_tag': \"STEVE is agreeable , STEVE follows DIANA's decisions\", 'last_speaker': 'STEVE'}\n",
      "Last word -> STEVE : \"Go!\"\n",
      "prediction :  I'll go with you.\n",
      "Real answer : Go!\n",
      "Bert Score : {'precision': [0.8606977462768555], 'recall': [0.8623620867729187], 'f1': [0.8615290522575378], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.33333333333333337, 'rouge2': 0.0, 'rougeL': 0.33333333333333337, 'rougeLsum': 0.33333333333333337}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 77.5020297810458\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTEVE: Diana! The gas.\\n\\n', 'answer': 'The village.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DIANA'}\n",
      "Last word -> DIANA : \"The village.\"\n",
      "prediction :  What?\n",
      "Real answer : The village.\n",
      "Bert Score : {'precision': [0.8645795583724976], 'recall': [0.8991509675979614], 'f1': [0.8815264701843262], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTEVE: Diana! I have to go.\\nDIANA: What are you saying? Steve, whatever it is, I can do it. Let me do it --\\nSTEVE: No. It has to be me. I can save today, you can save the world. I wish we had more time.\\nDIANA: What?\\n\\n', 'answer': 'I love you.', 'gold_tag': 'Everyday Language', 'last_speaker': 'STEVE'}\n",
      "Last word -> STEVE : \"I love you.\"\n",
      "prediction :  I have to go.\n",
      "Real answer : I love you.\n",
      "Bert Score : {'precision': [0.8710553050041199], 'recall': [0.8958028554916382], 'f1': [0.8832557797431946], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0.25 0.09128709291752769\n",
      "ppl : 221.82564898384223\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nAGNES: I'm Agnes. Hi!\\n\\n\", 'answer': 'Robert. Come in. You write funny texts, Agnes.', 'gold_tag': \"Robert is also known by his name and has a direct way of inviting people into his space , Robert finds Agnes' texts amusing , Agnes communicates through texts , Agnes's texts are perceived as humorous by others\", 'last_speaker': 'ROBERT'}\n",
      "Last word -> ROBERT : \"Robert. Come in. You write funny texts, Agnes.\"\n",
      "prediction :  Hi, Agnes. I'm Robert. I'm happy to meet you.\n",
      "Real answer : Robert. Come in. You write funny texts, Agnes.\n",
      "Bert Score : {'precision': [0.8728995323181152], 'recall': [0.8875848054885864], 'f1': [0.8801808953285217], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3157894736842105, 'rouge2': 0.0, 'rougeL': 0.2105263157894737, 'rougeLsum': 0.2105263157894737}\n",
      "bleu 1/2 : 0.2222222222222222 0.05270462766947299\n",
      "ppl : 19.844666972075238\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nAGNES: You said “prize”.\\n\\n', 'answer': 'Every competition has a prize.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROBERT'}\n",
      "Last word -> ROBERT : \"Every competition has a prize.\"\n",
      "prediction :  The first prize is the first thing you see.\n",
      "Real answer : Every competition has a prize.\n",
      "Bert Score : {'precision': [0.8759934902191162], 'recall': [0.9110898375511169], 'f1': [0.8931970000267029], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 66.62303752271335\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nAGNES: Sorry.\\n\\n', 'answer': 'Pardon me.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROBERT'}\n",
      "Last word -> ROBERT : \"Pardon me.\"\n",
      "prediction :  Don't be sorry.\n",
      "Real answer : Pardon me.\n",
      "Bert Score : {'precision': [0.877334713935852], 'recall': [0.8620718121528625], 'f1': [0.8696362972259521], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 98.90215151978926\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROBERT: ...I don’t open the door for the past.\\nAGNES: I’m not sure I understand.\\nROBERT: That man was a business associate of mine. I don’t have any patience for business these days. Too much pressure. And anyway, I was watching the surveillance camera footage online from the mass shooting last night. Have you seen it? It’s so goddamn awful.\\n\\n', 'answer': 'I don’t have as much time as I thought. I’m sorry. We better start.', 'gold_tag': 'AGNES may be involved in a task , The task requires a set amount of time , AGNES has less time available than she previously expected', 'last_speaker': 'AGNES'}\n",
      "Last word -> AGNES : \"I don’t have as much time as I thought. I’m sorry. We better start.\"\n",
      "prediction :  I haven’t seen it.\n",
      "Real answer : I don’t have as much time as I thought. I’m sorry. We better start.\n",
      "Bert Score : {'precision': [0.8920793533325195], 'recall': [0.8456559181213379], 'f1': [0.8682475686073303], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.19047619047619047, 'rouge2': 0.0, 'rougeL': 0.19047619047619047, 'rougeLsum': 0.19047619047619047}\n",
      "bleu 1/2 : 0.0205212496559747 0.0074933008965149825\n",
      "ppl : 86.81761077533531\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nAGNES: Are you going somewhere?\\nROBERT: No. WE are.\\nAGNES: Together? Where?\\nROBERT: It’s a surprise.\\nAGNES: I don’t like surprises.\\n\\n', 'answer': 'You’ll like this one.', 'gold_tag': 'ROBERT enjoys surprising others', 'last_speaker': 'ROBERT'}\n",
      "Last word -> ROBERT : \"You’ll like this one.\"\n",
      "prediction :  You don’t like surprises?\n",
      "Real answer : You’ll like this one.\n",
      "Bert Score : {'precision': [0.8715336322784424], 'recall': [0.896649956703186], 'f1': [0.8839133977890015], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4000000000000001, 'rouge2': 0.0, 'rougeL': 0.4000000000000001, 'rougeLsum': 0.4000000000000001}\n",
      "bleu 1/2 : 0.25 0.09128709291752769\n",
      "ppl : 55.787812063940606\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nAGNES: I don’t understand why we have to compete already?\\nROBERT: What’s the big deal?\\nAGNES: Who are these people?\\nROBERT: I thought we’d do this to boost your confidence.\\nAGNES: Well, you thought wrong.\\nROBERT: Just focus on what I’m doing.\\nAGNES: I looked you up. I mean, I googled you. On my phone.\\nROBERT: Oh?\\nAGNES: You’re an inventor.\\nROBERT: No. Not really.\\nAGNES: Something with magnets.\\nROBERT: I have a patent under my name. One invention. One good idea that took off. That’s it. I stumbled onto it almost by accident. Haven’t come up with anything since.\\nAGNES: It made your very rich.\\nROBERT: It was a fluke. I’m no inventor. Let’s just do the puzzle.\\nAGNES: Why are people staring at us?\\n\\n', 'answer': 'Okay. Okay. This was a bad idea. I’m sorry. Let’s get out of here.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROBERT'}\n",
      "Last word -> ROBERT : \"Okay. Okay. This was a bad idea. I’m sorry. Let’s get out of here.\"\n",
      "prediction :  Because I’m a celebrity.\n",
      "Real answer : Okay. Okay. This was a bad idea. I’m sorry. Let’s get out of here.\n",
      "Bert Score : {'precision': [0.8748806715011597], 'recall': [0.8754494190216064], 'f1': [0.8751649856567383], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2857142857142857, 'rouge2': 0.10526315789473685, 'rougeL': 0.19047619047619047, 'rougeLsum': 0.19047619047619047}\n",
      "bleu 1/2 : 0.0410424993119494 0.010597127754793961\n",
      "ppl : 69.38331597439294\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROBERT: Mata.\\nAGNES: Sorry. I’m early. I can come back.\\nROBERT: No, not at all. Come in. The elections are too close to call. They think there’s going to be a coup. Go ahead. I’ll be right down.\\n\\n', 'answer': 'Which elections? Where?', 'gold_tag': 'Everyday Language', 'last_speaker': 'AGNES'}\n",
      "Last word -> AGNES : \"Which elections? Where?\"\n",
      "prediction :  I don’t think it’s a good idea, Robert.\n",
      "Real answer : Which elections? Where?\n",
      "Bert Score : {'precision': [0.844153106212616], 'recall': [0.8421134948730469], 'f1': [0.8431320190429688], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 17.114829609599745\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROBERT: Mata, If you've picked up a piece and looked at it, then you shouldn't put it back. You should set it aside. It'll save you time later. Remember?\\n\\n\", 'answer': 'Excuse me.', 'gold_tag': 'Everyday Language', 'last_speaker': 'AGNES'}\n",
      "Last word -> AGNES : \"Excuse me.\"\n",
      "prediction :  Yes, I remember.\n",
      "Real answer : Excuse me.\n",
      "Bert Score : {'precision': [0.8693627119064331], 'recall': [0.8416144847869873], 'f1': [0.8552635908126831], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 107.68704181250325\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nAGNES: Don't even try. It's not going to fit. We’re wasting time.\\nROBERT: Maybe I should just watch you do it then?\\nAGNES: Do what you want.\\nROBERT: I was kidding.\\nAGNES: Don’t kid with me. I don’t have a sense of humor. Never have. Never will. That’s why we get along. All you care about is disasters.\\nROBERT: That’s... actually funny.\\n\\n\", 'answer': 'You’re not listening.', 'gold_tag': 'Everyday Language', 'last_speaker': 'AGNES'}\n",
      "Last word -> AGNES : \"You’re not listening.\"\n",
      "prediction :  You think it’s funny?\n",
      "Real answer : You’re not listening.\n",
      "Bert Score : {'precision': [0.8765701651573181], 'recall': [0.8984420895576477], 'f1': [0.8873713612556458], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.22222222222222224, 'rougeLsum': 0.22222222222222224}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 49.99891830947676\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMITCHELL: Could you keep your eyes on the road?\\nSEAN: Bitchin’ ride.\\nMITCHELL: Yeah, and I don’t want you to crash it. Could you keep your eyes on the road.\\nSEAN: Relax.\\nMITCHELL: Yeah, right -- “relax”. My car is being used to run a drug deal. I’ll just sit back and “relax”. I don’t even know why I’m goin’ with you, let alone letting you drive-- \"The Rules of Attraction\" www.avary.com 117.\\nSEAN: Look, I don’t care either way if we do this deal or not. But you do. Without this deal your girlfriend won’t get her nose candy, and without her nose candy she won’t fuck you. And you know it. Now I have my terms and if you don’t meet them then you get no pussy. So deal with it. How many speakers does this stereo have?\\nMITCHELL: Six. Two in the dash, two in the doors, and two in the rear.\\nSEAN: Preamp and subwoofer?\\nMITCHELL: Trunk.\\n\\n', 'answer': 'Rock and roll.', 'gold_tag': 'SEAN is knowledgeable about car stereo systems', 'last_speaker': 'SEAN'}\n",
      "Last word -> SEAN : \"Rock and roll.\"\n",
      "prediction :  I’m sorry, what?\n",
      "Real answer : Rock and roll.\n",
      "Bert Score : {'precision': [0.8107703924179077], 'recall': [0.8200052976608276], 'f1': [0.8153616786003113], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 64.79629565939454\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: Rupert doesn’t leave home.\\nMITCHELL: I’ll wait in the car.\\nSEAN: No, it’s okay. Rupert’s cool.\\nMITCHELL: I don’t want to go in.\\n\\n', 'answer': 'Just come in. Let’s get this over with.', 'gold_tag': \"SEAN wants to 'get something over with'\", 'last_speaker': 'SEAN'}\n",
      "Last word -> SEAN : \"Just come in. Let’s get this over with.\"\n",
      "prediction :  I know, but you have to.\n",
      "Real answer : Just come in. Let’s get this over with.\n",
      "Bert Score : {'precision': [0.8697289228439331], 'recall': [0.8516156077384949], 'f1': [0.8605769872665405], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 57.1257890043166\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMITCHELL: Are you fuckin’ crazy?!\\nSEAN: How do you define crazy? Suddenly they hear the truck of HOOTING TOWNIES, two blocks\\n\\n', 'answer': 'Oh, God. I don’t want to die on a Friday. Any other night than a Friday. Any other...', 'gold_tag': \"MITCHELL displays fear of dying , MITCHELL's fear of dying is particularly evident on Fridays , MITCHELL indicates a preference not to die on a Friday\", 'last_speaker': 'MITCHELL'}\n",
      "Last word -> MITCHELL : \"Oh, God. I don’t want to die on a Friday. Any other night than a Friday. Any other...\"\n",
      "prediction :  Oh, shit. I thought we were going to get the fuck out of here.\n",
      "Real answer : Oh, God. I don’t want to die on a Friday. Any other night than a Friday. Any other...\n",
      "Bert Score : {'precision': [0.8806523680686951], 'recall': [0.8448036909103394], 'f1': [0.862355649471283], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0.16103084851613267 0.0305099008072058\n",
      "ppl : 11.857377172806627\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSEAN: Wasn’t that fun?\\n\\n', 'answer': 'Jesus, Bateman! You’re an asshole!', 'gold_tag': 'MITCHELL calls Sean an \"asshole\" , MITCHELL shows disdain towards Sean', 'last_speaker': 'MITCHELL'}\n",
      "Last word -> MITCHELL : \"Jesus, Bateman! You’re an asshole!\"\n",
      "prediction :  Yeah, I guess it was.\n",
      "Real answer : Jesus, Bateman! You’re an asshole!\n",
      "Bert Score : {'precision': [0.8508663177490234], 'recall': [0.8166698813438416], 'f1': [0.8334174752235413], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 61.64671272505557\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nREYNOLDS: What happened?\\nHICKS: He's dead. An accident. Hit by a bus.\\nREYNOLDS: What about the tapes?\\nHICKS: We found the originals.\\nREYNOLDS: The originals?\\nHICKS: There was a transfer.\\nREYNOLDS: Am I to understand--\\nHICKS: He never made it to the newspaper, but there was private sector contact.\\nREYNOLDS: Who?\\nHICKS: Several indiscriminates and one primary who we've ID'd as Robert Dean. A Crystal City attorney. Mr. Reynolds? Sir?\\n\\n\", 'answer': 'Contact COINTEL. Profile. Assess the threat. Then cross-check against Zavitz. Red-flag the intersects and anything we can exploit. Also NRO. Pull up the keyhole tapes. I need to own him. I need to own him now.', 'gold_tag': \"REYNOLDS is assertive, analytical, and strategic , REYNOLDS's immediate priority is to profile, assess the threat, and exploit information\", 'last_speaker': 'REYNOLDS'}\n",
      "Last word -> REYNOLDS : \"Contact COINTEL. Profile. Assess the threat. Then cross-check against Zavitz. Red-flag the intersects and anything we can exploit. Also NRO. Pull up the keyhole tapes. I need to own him. I need to own him now.\"\n",
      "prediction : What do you want?\n",
      "Real answer : Contact COINTEL. Profile. Assess the threat. Then cross-check against Zavitz. Red-flag the intersects and anything we can exploit. Also NRO. Pull up the keyhole tapes. I need to own him. I need to own him now.\n",
      "Bert Score : {'precision': [0.8227535486221313], 'recall': [0.8075660467147827], 'f1': [0.8150890469551086], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 41.60278270750395\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nREYNOLDS: 30 minutes ago you said we had him. What in hell's goin' on out there?\\nHICKS: He had help.\\n\\n\", 'answer': 'Help from whom? Christ.', 'gold_tag': 'REYNOLDS is demanding answers from HICKS', 'last_speaker': 'REYNOLDS'}\n",
      "Last word -> REYNOLDS : \"Help from whom? Christ.\"\n",
      "prediction :  How many?\n",
      "Real answer : Help from whom? Christ.\n",
      "Bert Score : {'precision': [0.8485591411590576], 'recall': [0.8434534072875977], 'f1': [0.8459985852241516], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1185.4508853775085\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHICKS: We found two sets of latent prints in the rubble of Brill's studio. One was Dean's. The other, we believe, belongs to Brill.\\nREYNOLDS: We believe?\\nHICKS: Well...his real name's Edward Lyle.\\nREYNOLDS: Lyle?!\\nHICKS: Yes sir.\\nREYNOLDS: You're kidding me.\\nHICKS: No sir.\\nREYNOLDS: Dean's with Lyle.\\nHICKS: And they have the video. That's confirmed.\\nREYNOLDS: So they know everything.\\nHICKS: If they've looked at the video.\\nREYNOLDS: Oh, let's assume that they have.\\nHICKS: If he's with Lyle it means he's got resources.\\n\\n\", 'answer': \"Resources, that's a good point. He's got resources. All we've got is a six-hundred billion dollar organization! Now goddammit, Hicks, you find 'em. You find 'em and you end it now!\", 'gold_tag': 'REYNOLDS is result-oriented , REYNOLDS is prone to frustration at setbacks', 'last_speaker': 'REYNOLDS'}\n",
      "Last word -> REYNOLDS : \"Resources, that's a good point. He's got resources. All we've got is a six-hundred billion dollar organization! Now goddammit, Hicks, you find 'em. You find 'em and you end it now!\"\n",
      "prediction :  You're right.\n",
      "Real answer : Resources, that's a good point. He's got resources. All we've got is a six-hundred billion dollar organization! Now goddammit, Hicks, you find 'em. You find 'em and you end it now!\n",
      "Bert Score : {'precision': [0.8808221817016602], 'recall': [0.8097990155220032], 'f1': [0.8438188433647156], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05263157894736842, 'rouge2': 0.0, 'rougeL': 0.05263157894736842, 'rougeLsum': 0.05263157894736842}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 58.40577433756828\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHICKS: Found him. Kent Island nailed the call five minutes ago. He\\'s stationary.\\nREYNOLDS: Do you have visual?\\nHICKS: Not yet. He\\'s near \"M\" and 34th. I\\'ve got an ELSUR unit on the scene now. A residential building. Twelve units.\\nREYNOLDS: What\\'s your ETA?\\nHICKS: Three minutes. We\\'re going in light. Myself and two others. Everyone else is held back in reserve.\\n\\n', 'answer': 'He walked right up to me in church. At the holiest time of the wear. He approached me in a sanctified place. Kill him now.', 'gold_tag': 'REYNOLDS attends church and values sanctity, suggesting strong religious beliefs , REYNOLDS surfaces a recent past event wherein someone approached him at church , REYNOLDS is in a position to order a kill, indicating a role of authority', 'last_speaker': 'REYNOLDS'}\n",
      "Last word -> REYNOLDS : \"He walked right up to me in church. At the holiest time of the wear. He approached me in a sanctified place. Kill him now.\"\n",
      "prediction :  What's the plan?\n",
      "Real answer : He walked right up to me in church. At the holiest time of the wear. He approached me in a sanctified place. Kill him now.\n",
      "Bert Score : {'precision': [0.8430416584014893], 'recall': [0.8449652194976807], 'f1': [0.844002366065979], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06896551724137932, 'rouge2': 0.0, 'rougeL': 0.06896551724137932, 'rougeLsum': 0.06896551724137932}\n",
      "bleu 1/2 : 0.00021779732662246002 8.43525418857285e-05\n",
      "ppl : 63.65832570008186\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMILLER: Do we have enough time for a weld?\\n\\n', 'answer': \"We don't have time to fart.\", 'gold_tag': 'SMITH O.S. responds with urgency and humor , SMITH O.S. emphasizes the urgency of the situation', 'last_speaker': 'SMITH (O.S.)'}\n",
      "Last word -> SMITH (O.S.) : \"We don't have time to fart.\"\n",
      "prediction :  We’ve got about ten minutes.\n",
      "Real answer : We don't have time to fart.\n",
      "Bert Score : {'precision': [0.8634622097015381], 'recall': [0.8711353540420532], 'f1': [0.8672817945480347], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 126.34405844273432\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMILLER: No one's dying on my watch, Smith! What about the reserve tanks?\\n\\n\", 'answer': \"They're gone.\", 'gold_tag': 'SMITH O.S. responds to directions , SMITH O.S. provides updates on critical situations , SMITH O.S. is possibly the technical or operational person in a team', 'last_speaker': 'SMITH (O.S.)'}\n",
      "Last word -> SMITH (O.S.) : \"They're gone.\"\n",
      "prediction :  Negative.\n",
      "Real answer : They're gone.\n",
      "Bert Score : {'precision': [0.9403335452079773], 'recall': [0.8871117830276489], 'f1': [0.9129476547241211], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1315.6190915601578\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMILLER: Dr. Weir's right. Get on board the Event Horizon. I'll meet you at the airlock.\\nSMITH (O.S.): But...\\n\\n\", 'answer': 'You heard me, Smith. Peters, are you with me?', 'gold_tag': 'MILLER is in a position of authority , MILLER is capable of issuing orders to others', 'last_speaker': 'MILLER'}\n",
      "Last word -> MILLER : \"You heard me, Smith. Peters, are you with me?\"\n",
      "prediction :  No buts.\n",
      "Real answer : You heard me, Smith. Peters, are you with me?\n",
      "Bert Score : {'precision': [0.8451728820800781], 'recall': [0.8369494676589966], 'f1': [0.841041088104248], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1212.7034410524986\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMILLER: Thank you.\\nSMITH (O.S.): Captain, we got a problem.\\n\\n', 'answer': 'Now what?', 'gold_tag': 'Everyday Language', 'last_speaker': 'MILLER'}\n",
      "Last word -> MILLER : \"Now what?\"\n",
      "prediction :  What?\n",
      "Real answer : Now what?\n",
      "Bert Score : {'precision': [0.9491682648658752], 'recall': [0.9094651937484741], 'f1': [0.9288926124572754], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.6666666666666666, 'rouge2': 0.0, 'rougeL': 0.6666666666666666, 'rougeLsum': 0.6666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSMITH (O.S.): Skipper...\\nMILLER: What is it, Smith?\\nSMITH (O.S.): I just saw Weir, I think he was messing around on the Clark.\\nMILLER: Smith, get out of there...\\nSMITH (O.S.): Come again, Skipper?\\n\\n', 'answer': 'One of the explosives is missing from the corridor. I think Weir may have put it on the Clark.', 'gold_tag': 'MILLER is referred to as \"Skipper\" , MILLER is the captain of the ship', 'last_speaker': 'MILLER'}\n",
      "Last word -> MILLER : \"One of the explosives is missing from the corridor. I think Weir may have put it on the Clark.\"\n",
      "prediction :  Weir's on the Clark.\n",
      "Real answer : One of the explosives is missing from the corridor. I think Weir may have put it on the Clark.\n",
      "Bert Score : {'precision': [0.907240629196167], 'recall': [0.8581159710884094], 'f1': [0.8819948434829712], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.1818181818181818, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0.01763830939200683 0.016629557573005865\n",
      "ppl : 418.9150807537358\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAULA: You following me? * I'm kidding. I'm sorry. I saw you upstairs . . . just now. Visiting someone?\\nLEONARD: No. �\\nPAULA: You work here.\\nLEONARD: I live here.\\nPAULA: You're a patient? You don't look like a patient.\\n\\n\", 'answer': \"I don't?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'LEONARD'}\n",
      "Last word -> LEONARD : \"I don't?\"\n",
      "prediction :  I'm not a patient.\n",
      "Real answer : I don't?\n",
      "Bert Score : {'precision': [0.8468583822250366], 'recall': [0.8212882280349731], 'f1': [0.8338773250579834], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 81.35441916300813\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAULA: I don't know if he knows I visit him or not. I don't know that he knows who I am. My mother doesn't think so. She doesn't; come around any more--\\nLEONARD: But you do.\\nPAULA: Sometimes I think I see something. * I think I see a change. And for a * Does that make any sense?\\nLEONARD: s Yes. � *\\nPAULA: Why are you here?\\n\\n\", 'answer': \"' I receive medication. , I'm okay now. * - '\", 'gold_tag': 'LEONARD receives medication , LEONARD believes he is okay now', 'last_speaker': 'LEONARD'}\n",
      "Last word -> LEONARD : \"' I receive medication. , I'm okay now. * - '\"\n",
      "prediction :  I don't know. I just wanted to talk to you.\n",
      "Real answer : ' I receive medication. , I'm okay now. * - '\n",
      "Bert Score : {'precision': [0.8565973043441772], 'recall': [0.8488564491271973], 'f1': [0.8527092933654785], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2222222222222222, 'rouge2': 0.0, 'rougeL': 0.2222222222222222, 'rougeLsum': 0.2222222222222222}\n",
      "bleu 1/2 : 0.09048374180359597 0.03016124726786533\n",
      "ppl : 12.154969796952903\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAULA: Things happen, people are late.\\nLEONARD: They won't be angry.\\n\\n\", 'answer': \"Oh, they'll be angry. What're they going to do, fire me?\", 'gold_tag': 'PAULA works in a job where being late could potentially result in her getting fired , PAULA might hold a position with strict punctuality requirements', 'last_speaker': 'PAULA'}\n",
      "Last word -> PAULA : \"Oh, they'll be angry. What're they going to do, fire me?\"\n",
      "prediction :  They're not angry.\n",
      "Real answer : Oh, they'll be angry. What're they going to do, fire me?\n",
      "Bert Score : {'precision': [0.8953233957290649], 'recall': [0.8473933935165405], 'f1': [0.8706992864608765], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3529411764705882, 'rouge2': 0.0, 'rougeL': 0.23529411764705882, 'rougeLsum': 0.23529411764705882}\n",
      "bleu 1/2 : 0.023161150407600514 0.008970274980764192\n",
      "ppl : 127.35781920937072\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPAULA: .. I worked . . . I had friends (p over . . . I went dancing . . . that's about it . . . I know, I should do something with my life. �\\nLEONARD: Like what? Those are great things. I've never done any of those things.\\nPAULA: You will.\\nLEONARD: They'll never let me out of this place. They shouldn't. I'm not well. I feel well inside when I see you. I wish you could see what's inside. Instead of this.\\nPAULA: I can see it.\\n\\n\", 'answer': 'Goodbye. �', 'gold_tag': 'Everyday Language', 'last_speaker': 'LEONARD'}\n",
      "Last word -> LEONARD : \"Goodbye. �\"\n",
      "prediction :  You can't.\n",
      "Real answer : Goodbye. �\n",
      "Bert Score : {'precision': [0.8902806639671326], 'recall': [0.8864314556121826], 'f1': [0.8883518576622009], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 100.9806306171031\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDANNY: Hi, Linus. Sit down.\\nLINUS: Who are you?\\nDANNY: A friend of Bobby Caldwell's. Sit down. Bobby told me about you. Said you were the best set of hands he ever saw. Didn't expect to find you working wallets on the subway.\\nLINUS: That wasn't work, that was practice.\\nDANNY: You're either in or out, right now.\\nLINUS: What is it?\\nDANNY: A plane ticket. A job offer.\\nLINUS: You're pretty trusting pretty fast.\\nDANNY: Bobby has every faith in you.\\nLINUS: Fathers are like that. He didn't tell you? He doesn't like me trading on his name.\\nDANNY: You do this job, he'll be trading on yours.\\nLINUS: What if I say no?\\nDANNY: We'll get someone else who won't be quite as good. You can go back to feeling up stockbrokers. That's the best lift I've seen you make yet.\\nLINUS: Las Vegas, huh?\\n\\n\", 'answer': \"America's playground.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'DANNY'}\n",
      "Last word -> DANNY : \"America's playground.\"\n",
      "prediction :  What do you think?\n",
      "Real answer : America's playground.\n",
      "Bert Score : {'precision': [0.7961025834083557], 'recall': [0.8472890257835388], 'f1': [0.8208986520767212], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 53.25875838002556\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDANNY: You two ready? What are you doing?\\n\\n', 'answer': 'Coming with you. But...', 'gold_tag': \"LINUS is willing to go along with others' plans\", 'last_speaker': 'LINUS'}\n",
      "Last word -> LINUS : \"Coming with you. But...\"\n",
      "prediction :  No, I'm not ready. I'm not ready to go.\n",
      "Real answer : Coming with you. But...\n",
      "Bert Score : {'precision': [0.8521691560745239], 'recall': [0.8695971965789795], 'f1': [0.8607949614524841], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.626485635071798\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDANNY: I say stay in the van, you stay in\\n\\n', 'answer': 'about enough of I got it.', 'gold_tag': 'LINUS is in a subordinate position , LINUS may be feeling frustrated or misunderstood', 'last_speaker': 'LINUS'}\n",
      "Last word -> LINUS : \"about enough of I got it.\"\n",
      "prediction :  I'm not staying in the van.\n",
      "Real answer : about enough of I got it.\n",
      "Bert Score : {'precision': [0.8698370456695557], 'recall': [0.8588430881500244], 'f1': [0.8643051385879517], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 51.661552059168535\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDANNY: You didn't really think I was gonna sit this one out, did you?\\nLINUS: What, didn't you trust me?\\n\\n\", 'answer': 'I do now.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DANNY'}\n",
      "Last word -> DANNY : \"I do now.\"\n",
      "prediction :  No, I didn't trust you. I trusted the system.\n",
      "Real answer : I do now.\n",
      "Bert Score : {'precision': [0.8551137447357178], 'recall': [0.8680468797683716], 'f1': [0.8615317940711975], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0.11111111111111109 0.03726779962499649\n",
      "ppl : 24.05947474270951\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINUS: How'd you get here?\\nDANNY: Crawlspace. And I had to give away a couple mil.\\n\\n\", 'answer': 'But what about -- I mean, that whole thing with Rusty...', 'gold_tag': 'LINUS is aware of the situation , DANNY and LINUS share the memory of a situation concerning Rusty', 'last_speaker': 'LINUS'}\n",
      "Last word -> LINUS : \"But what about -- I mean, that whole thing with Rusty...\"\n",
      "prediction :  Oh, man. You're gonna get me killed.\n",
      "Real answer : But what about -- I mean, that whole thing with Rusty...\n",
      "Bert Score : {'precision': [0.8421575427055359], 'recall': [0.8114177584648132], 'f1': [0.8265019059181213], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.337921148274376\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINUS: Why'd you make me go through all this? Why not just tell me?\\n\\n\", 'answer': \"Well, where's the fun in that? C'mon: Yen's got about three minutes of air left.\", 'gold_tag': 'DANNY enjoys humor , DANNY is in a position of command , DANNY indicates that Yen has about three minutes of air remaining', 'last_speaker': 'DANNY'}\n",
      "Last word -> DANNY : \"Well, where's the fun in that? C'mon: Yen's got about three minutes of air left.\"\n",
      "prediction :  I was afraid you would make fun of me.\n",
      "Real answer : Well, where's the fun in that? C'mon: Yen's got about three minutes of air left.\n",
      "Bert Score : {'precision': [0.857620894908905], 'recall': [0.8231881856918335], 'f1': [0.8400518894195557], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14814814814814814, 'rouge2': 0.0, 'rougeL': 0.14814814814814814, 'rougeLsum': 0.14814814814814814}\n",
      "bleu 1/2 : 0.11409269311835378 0.027059458097746257\n",
      "ppl : 35.62037972443568\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDANNY: Who do you like tonight?\\nLINUS: Huh?\\nDANNY: Tyson or Lewis.\\nLINUS: The fight...? Lewis. You like Tyson? How strongly do you feel about it?\\nDANNY: You looking for action?\\nLINUS: I'd go in for a buck.\\n\\n\", 'answer': \"A buck it is. Livingston, we're set.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'DANNY'}\n",
      "Last word -> DANNY : \"A buck it is. Livingston, we're set.\"\n",
      "prediction :  You're on.\n",
      "Real answer : A buck it is. Livingston, we're set.\n",
      "Bert Score : {'precision': [0.9050391912460327], 'recall': [0.867267906665802], 'f1': [0.8857510685920715], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 123.88332918711075\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINUS: You ever rappelled before?\\nDANNY: Never. You?\\n\\n', 'answer': 'Nope.', 'gold_tag': 'LINUS has never rappelled before', 'last_speaker': 'LINUS'}\n",
      "Last word -> LINUS : \"Nope.\"\n",
      "prediction :  No. But I've seen it done.\n",
      "Real answer : Nope.\n",
      "Bert Score : {'precision': [0.8722807765007019], 'recall': [0.9535892009735107], 'f1': [0.911124587059021], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 62.44212641819571\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINUS: You alright?\\n\\n', 'answer': \"No, but you're sweet to ask.\", 'gold_tag': 'DANNY is not in good condition , LINUS is empathetic', 'last_speaker': 'DANNY'}\n",
      "Last word -> DANNY : \"No, but you're sweet to ask.\"\n",
      "prediction :  Yep.\n",
      "Real answer : No, but you're sweet to ask.\n",
      "Bert Score : {'precision': [0.9431136250495911], 'recall': [0.8207429647445679], 'f1': [0.8776834011077881], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 908.8374124511863\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINUS: You think Yen made it out okay?\\n\\n', 'answer': \"I'm sure he's fine.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'DANNY'}\n",
      "Last word -> DANNY : \"I'm sure he's fine.\"\n",
      "prediction :  I don't know.\n",
      "Real answer : I'm sure he's fine.\n",
      "Bert Score : {'precision': [0.8723878860473633], 'recall': [0.8647814989089966], 'f1': [0.8685680627822876], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 52.19149636039691\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINUS: Jesus...\\n\\n', 'answer': \"There's a Chinese man with a hundred sixty million dollars behind that door. Let's get him out.\", 'gold_tag': \"DANNY is a strategic individual , DANNY is involved in risky operations, possibly criminal , LINUS is DANNY's accomplice\", 'last_speaker': 'DANNY'}\n",
      "Last word -> DANNY : \"There's a Chinese man with a hundred sixty million dollars behind that door. Let's get him out.\"\n",
      "prediction :  What?\n",
      "Real answer : There's a Chinese man with a hundred sixty million dollars behind that door. Let's get him out.\n",
      "Bert Score : {'precision': [0.830161452293396], 'recall': [0.8035008907318115], 'f1': [0.8166136145591736], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINUS: What's wrong?\\nDANNY: I don't know.\\n\\n\", 'answer': 'You check the batteries?', 'gold_tag': 'Everyday Language', 'last_speaker': 'LINUS'}\n",
      "Last word -> LINUS : \"You check the batteries?\"\n",
      "prediction :  You're right.\n",
      "Real answer : You check the batteries?\n",
      "Bert Score : {'precision': [0.8589040040969849], 'recall': [0.8428520560264587], 'f1': [0.8508023619651794], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 58.40577433756828\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINUS: You know, you lose focus for one second in this game --\\n\\n', 'answer': \"-- and someone gets hurt, yeah yeah. I don't hear Yen complaining.\", 'gold_tag': 'DANNY is familiar with the risks involved in their activities , This familiarity possibly indicates a history with such high-stake endeavors', 'last_speaker': 'DANNY'}\n",
      "Last word -> DANNY : \"-- and someone gets hurt, yeah yeah. I don't hear Yen complaining.\"\n",
      "prediction :  -- and you're dead.\n",
      "Real answer : -- and someone gets hurt, yeah yeah. I don't hear Yen complaining.\n",
      "Bert Score : {'precision': [0.8903931975364685], 'recall': [0.8506659865379333], 'f1': [0.8700763583183289], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.06766764161830635 0.055250398020789834\n",
      "ppl : 138.63356385379055\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBUD: Hey, you guys are milking that job.\\n\\n', 'answer': \"That's cause we love freezin' our butts off out here sooo much, boss.\", 'gold_tag': 'CATFISH has a sarcastic sense of humor', 'last_speaker': 'CATFISH'}\n",
      "Last word -> CATFISH : \"That's cause we love freezin' our butts off out here sooo much, boss.\"\n",
      "prediction :  You're right, BUD.\n",
      "Real answer : That's cause we love freezin' our butts off out here sooo much, boss.\n",
      "Bert Score : {'precision': [0.8761270642280579], 'recall': [0.8196610808372498], 'f1': [0.8469539880752563], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 121.96013733672203\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBUD: Hafta... go on to... the moonpool. Only way.\\nCATFISH: I can't... make it... podner.\\n\\n\", 'answer': 'Okay, Cat. You head back.', 'gold_tag': 'CATFISH is planning to head back in the immediate future', 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"Okay, Cat. You head back.\"\n",
      "prediction :  You can... I can't... You gotta... You gotta...\n",
      "Real answer : Okay, Cat. You head back.\n",
      "Bert Score : {'precision': [0.7737395167350769], 'recall': [0.8605121374130249], 'f1': [0.8148221969604492], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.12500000000000003 0.04225771273642583\n",
      "ppl : 26.548432818229863\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCATFISH: Hey!\\n\\n', 'answer': 'Get the door!', 'gold_tag': 'Everyday Language', 'last_speaker': 'BUD'}\n",
      "Last word -> BUD : \"Get the door!\"\n",
      "prediction :  Hey.\n",
      "Real answer : Get the door!\n",
      "Bert Score : {'precision': [0.9437965154647827], 'recall': [0.834962785243988], 'f1': [0.8860501646995544], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2299.297290806157\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOYLE: Havin' trouble? You're a dumb guinea.\\nRUSSO: How'd I know he had a knife.\\nDOYLE: Never trust a nigger.\\nRUSSO: He coulda been white.\\nDOYLE: Never trust anybody. You goin' sick?\\nRUSSO: Not a chance.\\nDOYLE: Let's popeye around the Chez for a half hour, catch the end of the show and a couple drinks.\\nRUSSO: Some other time Jimmy, I'm beat.\\nDOYLE: Come on -- one drink. Whatta you say?\\nRUSSO: Drink this.\\n\\n\", 'answer': 'Whip it out.', 'gold_tag': 'DOYLE is assertive and enjoys social activities like going out for a drink', 'last_speaker': 'DOYLE'}\n",
      "Last word -> DOYLE : \"Whip it out.\"\n",
      "prediction :  What is it?\n",
      "Real answer : Whip it out.\n",
      "Bert Score : {'precision': [0.8836994767189026], 'recall': [0.8981484174728394], 'f1': [0.8908653259277344], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.0, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 140.93475091067572\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOYLE: I make at least two junk connections at that table in the corner. The guy is the stripe combo, I know him too.\\n\\n', 'answer': 'Hey, I thought we come for a drink.', 'gold_tag': 'RUSSO is interested in social activities such as drinking', 'last_speaker': 'RUSSO'}\n",
      "Last word -> RUSSO : \"Hey, I thought we come for a drink.\"\n",
      "prediction :  What do you do?\n",
      "Real answer : Hey, I thought we come for a drink.\n",
      "Bert Score : {'precision': [0.8318766355514526], 'recall': [0.8346617817878723], 'f1': [0.8332668542861938], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 71.18401792000323\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOYLE: Who is that guy?\\nRUSSO: Policy man in Queens.\\nDOYLE: What about the last of the big-time spenders. You make him?\\nRUSSO: No, you?\\nDOYLE: Hunh-uh. Check the bread. He spreads it like the Russians are in Jersey.\\n\\n', 'answer': 'He probably sells insurance. Owns a chicken farm in Hackensack.', 'gold_tag': \"RUSSO's knowledge of potential suspects and their related professions suggests he has experience in the field\", 'last_speaker': 'RUSSO'}\n",
      "Last word -> RUSSO : \"He probably sells insurance. Owns a chicken farm in Hackensack.\"\n",
      "prediction :  Yeah. He's a smart one. He's got the brains, he's got the dough, and he's got the chops.\n",
      "Real answer : He probably sells insurance. Owns a chicken farm in Hackensack.\n",
      "Bert Score : {'precision': [0.8540281057357788], 'recall': [0.8545814752578735], 'f1': [0.8543046712875366], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12500000000000003, 'rouge2': 0.0, 'rougeL': 0.12500000000000003, 'rougeLsum': 0.12500000000000003}\n",
      "bleu 1/2 : 0.05555555555555554 0.018077538151554672\n",
      "ppl : 6.655593476382973\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOYLE: Whatta you say we wait and give him a tail?\\nRUSSO: Give who a tail?\\nDOYLE: The greaser with the blonde.\\nRUSSO: What for -- you wanna play Hide the Salami with his old lady?\\n\\n', 'answer': 'Come on -- just for fun --', 'gold_tag': 'DOYLE has a playful side', 'last_speaker': 'DOYLE'}\n",
      "Last word -> DOYLE : \"Come on -- just for fun --\"\n",
      "prediction :  No, man, I wanna play Hide the Salami with her.\n",
      "Real answer : Come on -- just for fun --\n",
      "Bert Score : {'precision': [0.8147919178009033], 'recall': [0.816855788230896], 'f1': [0.8158226013183594], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 47.15453897502555\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOYLE: Monica? Who's Monica?\\nRUSSO: A and A, that's all you're interested in -- Arrests and Ass.\\nDOYLE: Cloudy, I'll lay odds he takes us to Little Italy.\\n\\n\", 'answer': \"I'm telling you, Popeye, he owns a bagel mine in the Bronx.\", 'gold_tag': \"RUSSO refers to DOYLE as 'Popeye' , RUSSO has information about a possible suspect\", 'last_speaker': 'RUSSO'}\n",
      "Last word -> RUSSO : \"I'm telling you, Popeye, he owns a bagel mine in the Bronx.\"\n",
      "prediction :  Where's the nearest phone?\n",
      "Real answer : I'm telling you, Popeye, he owns a bagel mine in the Bronx.\n",
      "Bert Score : {'precision': [0.8122647404670715], 'recall': [0.825040340423584], 'f1': [0.8186027407646179], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0.033833820809153176 0.012354364575840592\n",
      "ppl : 37.0318994975047\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOYLE: If that's not a drop or a pickup, I'll open a charge for you at Bloomingdale's.\\nRUSSO: Make it Alexander's, I like the toy department.\\n\\n\", 'answer': \"Toy wit' this will ya.\", 'gold_tag': 'DOYLE has a sarcastic sense of humor , RUSSO has a playful personality', 'last_speaker': 'DOYLE'}\n",
      "Last word -> DOYLE : \"Toy wit' this will ya.\"\n",
      "prediction :  How much?\n",
      "Real answer : Toy wit' this will ya.\n",
      "Bert Score : {'precision': [0.8312008380889893], 'recall': [0.8007487058639526], 'f1': [0.8156906962394714], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1473.4860198141512\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRUSSO: There's about a hundred years' parole time in there night or day.\\nDOYLE: They treat our boy like a king. Wonder why he don't bring his old lady?\\n\\n\", 'answer': \"There's your answer...\", 'gold_tag': 'RUSSO is a keen observer', 'last_speaker': 'RUSSO'}\n",
      "Last word -> RUSSO : \"There's your answer...\"\n",
      "prediction :  He's not supposed to.\n",
      "Real answer : There's your answer...\n",
      "Bert Score : {'precision': [0.8253130912780762], 'recall': [0.8096438646316528], 'f1': [0.8174033761024475], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.22222222222222224, 'rougeLsum': 0.22222222222222224}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 106.96728303714923\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOYLE: Who's the greaser?\\nRUSSO: It's his father.\\nDOYLE: I think we oughta burn him on suspicion.\\nRUSSO: Suspicion of what?\\nDOYLE: Makin' wine in the basement. He looks like that wop stooge used to drive for the Fracisi brothers.\\n\\n\", 'answer': 'Lay off with that wop stuff, will you?', 'gold_tag': \"RUSSO is against DOYLE's prejudiced language\", 'last_speaker': 'RUSSO'}\n",
      "Last word -> RUSSO : \"Lay off with that wop stuff, will you?\"\n",
      "prediction :  He's not the one.\n",
      "Real answer : Lay off with that wop stuff, will you?\n",
      "Bert Score : {'precision': [0.8480385541915894], 'recall': [0.8090802431106567], 'f1': [0.8281014561653137], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 65.36328619647364\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOYLE: That's the third time he come here this week. You got anything on the building?\\nRUSSO: The building's clean. I checked the tenant list -- Don Ameche, the actor lives there -- oh, and somebody else. Do the name Joel Weinstock ring a bell?\\nDOYLE: You're kiddin'\\nRUSSO: No sir -- this is where Joel lives.\\nDOYLE: He was the bank on that shipment outta Mexico three years ago.\\n\\n\", 'answer': \"So I've heard.\", 'gold_tag': 'RUSSO has knowledge about a notorious individual named Joel Weinstock , Shared memories: DOYLE and RUSSO both seem to have knowledge about a previous event, specifically a drug shipment from Mexico banked by Joel Weinstock three years ago', 'last_speaker': 'RUSSO'}\n",
      "Last word -> RUSSO : \"So I've heard.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : So I've heard.\n",
      "Bert Score : {'precision': [0.9186117649078369], 'recall': [0.8456807732582092], 'f1': [0.8806388974189758], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRUSSO: He's goin' to Ward's Island. We'll get spotted. What the hell's he goin' there?\\n\\n\", 'answer': \"Maybe he's goin' to see his brother. Or could be another drop. I guess he gets a free ride.\", 'gold_tag': \"DOYLE has knowledge about a certain individual's habits and likely locations , DOYLE can make educated guesses about other people's actions\", 'last_speaker': 'DOYLE'}\n",
      "Last word -> DOYLE : \"Maybe he's goin' to see his brother. Or could be another drop. I guess he gets a free ride.\"\n",
      "prediction :  He's got a little girl. Her name is Claire.\n",
      "Real answer : Maybe he's goin' to see his brother. Or could be another drop. I guess he gets a free ride.\n",
      "Bert Score : {'precision': [0.8513805866241455], 'recall': [0.8436221480369568], 'f1': [0.8474835753440857], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.07142857142857142, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0.036576998645322836 0.012268298307578937\n",
      "ppl : 26.491842942063307\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRUSSO: Popeye. Popeye.\\nDOYLE: Yeah.\\nRUSSO: It's Cloudy. Open the door.\\nDOYLE: I can't.\\nRUSSO: Why not?\\n\\n\", 'answer': 'Let yourself in.', 'gold_tag': 'RUSSO is capable of letting himself in', 'last_speaker': 'DOYLE'}\n",
      "Last word -> DOYLE : \"Let yourself in.\"\n",
      "prediction :  You're gonna hurt me.\n",
      "Real answer : Let yourself in.\n",
      "Bert Score : {'precision': [0.863624095916748], 'recall': [0.8790818452835083], 'f1': [0.8712844252586365], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 44.86758991232962\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRUSSO: You want the red or the white?\\n\\n', 'answer': 'Pour it in your ear.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DOYLE'}\n",
      "Last word -> DOYLE : \"Pour it in your ear.\"\n",
      "prediction :  The red.\n",
      "Real answer : Pour it in your ear.\n",
      "Bert Score : {'precision': [0.907005786895752], 'recall': [0.8590747117996216], 'f1': [0.8823897838592529], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1929.039277466877\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDOYLE: Timezit?\\n\\n', 'answer': 'Four.', 'gold_tag': 'RUSSO is aware of the current time', 'last_speaker': 'RUSSO'}\n",
      "Last word -> RUSSO : \"Four.\"\n",
      "prediction :  I don't know.\n",
      "Real answer : Four.\n",
      "Bert Score : {'precision': [0.8161113262176514], 'recall': [0.9244973063468933], 'f1': [0.8669297099113464], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 52.19149636039691\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRUSSO: Jimmy? Jimmy?\\nDOYLE: Cover the other side -- Frog Number One is down there.\\nRUSSO: He's gone, Jimmy. Bill is dead.\\n\\n\", 'answer': \"The sonofabitch is in here somewhere. I saw him -- I'm gonna get him.\", 'gold_tag': 'DOYLE is determined and focused , DOYLE is likely working in law enforcement or a role requiring surveillance and tracking', 'last_speaker': 'DOYLE'}\n",
      "Last word -> DOYLE : \"The sonofabitch is in here somewhere. I saw him -- I'm gonna get him.\"\n",
      "prediction : ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "Real answer : The sonofabitch is in here somewhere. I saw him -- I'm gonna get him.\n",
      "Bert Score : {'precision': [0.6295508146286011], 'recall': [0.795430064201355], 'f1': [0.7028356194496155], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1.2402542697342271\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATE: A million, six at 40 cents onna dollar\\'s 640. Here\\'s a hundred forty thou front money. Get you the rest, 2-3 days. What happened out there?\\nNEIL: I don\\'t want to talk about it.\\nNATE: Wait a minute.\\nNEIL: What\\'s the matter?\\nNATE: You know who these belong to?\\nNEIL: \"Malibu Securities ...\\nNATE: You know John Van Zant?\\nNEIL: No.\\nNATE: Malibu Securities is a brokerage he controls. Planned bankruptcies, made out during the S&L\\'s, money laundering... You ripped off his Treasury Certificates.\\nNEIL: So what?\\nNATE: That\\'s the point. On top of collecting his insurance, maybe he wants to buy back his bonds. From him I can get you 60 cents on the dollar instead of 40. Means an extra 320 to you.\\nNEIL: Try it on.\\nNATE: You know Cezar Kelso?\\nNEIL: By reputation.\\nNATE: He\\'s got this score he\\'s putting\\nNEIL: What do I need look at his score for? I got my own.\\nNATE: He said you\\'ll get near eight figures. Very clean.\\nNEIL: 9:00a.M. tomorrow.\\n\\n', 'answer': 'Take it easy.', 'gold_tag': \"NATE's temporal information\", 'last_speaker': 'NATE'}\n",
      "Last word -> NATE : \"Take it easy.\"\n",
      "prediction :  What for?\n",
      "Real answer : Take it easy.\n",
      "Bert Score : {'precision': [0.838160514831543], 'recall': [0.8634585738182068], 'f1': [0.8506214022636414], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 991.775758830239\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEIL: I bought it.\\nNATE: What I tell you?\\nNEIL: The bonds?\\nNATE: We're on. You call him tomorrow... ... and set a meet.\\nNEIL: How is he?\\n\\n\", 'answer': \"Very cool. He's a businessman.\", 'gold_tag': 'NATE comes across as a cautious and reserved person', 'last_speaker': 'NATE'}\n",
      "Last word -> NATE : \"Very cool. He's a businessman.\"\n",
      "prediction :  Fine.\n",
      "Real answer : Very cool. He's a businessman.\n",
      "Bert Score : {'precision': [0.9318448305130005], 'recall': [0.8983174562454224], 'f1': [0.9147740006446838], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 4604.562823636195\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATE: Worth it?\\nNEIL: There's enough circuit diagrams and blueprints here to build the bank. It's terrific.\\nNATE: His name is Hanna; first name, Vincent. I smeared this sergeant in vice five yards. Hanna's all over you. He's a hot dog. Lieutenant in major Crimes Unit. He's taken down some heavy crews. Blew away Frankie Yonder in Chicago and he was a fucking maniac. Was working Narcotics before that. He's good, Neil. Dedicated. Divorced three times. Current wife's Justine. He's why the extra heat. Vice sergeant says Hanna likes you. Thinks you're some kind of 'star.' 'You do this sharp, you do that sharp. Look how sharp this guy is to figure that.' Funny as a heart attack. With this guy and this much heat, you should pass on the bank.\\nNEIL: I've had heat before.\\nNATE: That's not the point.\\nNEIL: This one's worth the stretch\\nNATE: You sure?\\n\\n\", 'answer': \"I'm sure. Drop me at the garage.\", 'gold_tag': \"NEIL's temporal information\", 'last_speaker': 'NEIL'}\n",
      "Last word -> NEIL : \"I'm sure. Drop me at the garage.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : I'm sure. Drop me at the garage.\n",
      "Bert Score : {'precision': [0.948527455329895], 'recall': [0.8676146864891052], 'f1': [0.9062686562538147], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHERRICK: There you go.\\nROWENA: Are you hungry? Pizza's on me... on my folks.\\nHERRICK: Pizza sounds good. I'll have to call home.\\n\\n\", 'answer': \"Great! I'm starving!\", 'gold_tag': 'ROWENA is hungry', 'last_speaker': 'ROWENA'}\n",
      "Last word -> ROWENA : \"Great! I'm starving!\"\n",
      "prediction :  I'm sure you will.\n",
      "Real answer : Great! I'm starving!\n",
      "Bert Score : {'precision': [0.8534605503082275], 'recall': [0.8405870199203491], 'f1': [0.8469749093055725], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4444444444444445, 'rouge2': 0.28571428571428575, 'rougeL': 0.4444444444444445, 'rougeLsum': 0.4444444444444445}\n",
      "bleu 1/2 : 0.25 0.09128709291752769\n",
      "ppl : 62.997948920045\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHERRICK: ...a symphony that took what George Gershwin and Aaron Copland did with the music of their time and brought it into the world of rock and roll. Took American music to the next step. A grand opus of American music.\\nROWENA: Opus? The only Opus I know is in that comic strip, Bloom County. You know, with Milo and Bill the Cat. So when can. I hear this... opus, symphony thing?\\nHERRICK: I never finished it -- I gave it up. I worked on it for... five years and then... Other people did it better than I ever could.\\nROWENA: Oh, but not like you'd do it. You should finish it.\\nHERRICK: I only got to the first movement.\\nROWENA: So... finish it. You have great things in you, Mr. Herrick. You're a talented man. I've watched you, you've got genius in you.\\nHERRICK: God, look at the time. Tomorrow's a school day, for both of us.\\nROWENA: I told you, my treat.\\nHERRICK: Well, thanks... Can I give you a ride home?\\nROWENA: No, my dad'll be here soon to cash out. Thanks for the talk, and everything.\\nHERRICK: See you at rehearsal.\\n\\n\", 'answer': 'You bet!', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROWENA'}\n",
      "Last word -> ROWENA : \"You bet!\"\n",
      "prediction :  Thanks. I'll see you there.\n",
      "Real answer : You bet!\n",
      "Bert Score : {'precision': [0.8704586625099182], 'recall': [0.8174782991409302], 'f1': [0.8431369662284851], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 43.96187632279497\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROWENA: We're getting creamed.\\nHERRICK: There's no sense in breaking with tradition.\\n\\n\", 'answer': 'I was a cheerleader last year, but I quit. It seemed so... Republican.', 'gold_tag': 'ROWENA was a cheerleader last year but quit because she felt it was too \"Republican\" , ROWENA is hinting at her political beliefs or viewpoints', 'last_speaker': 'ROWENA'}\n",
      "Last word -> ROWENA : \"I was a cheerleader last year, but I quit. It seemed so... Republican.\"\n",
      "prediction :  I'm not breaking with tradition.\n",
      "Real answer : I was a cheerleader last year, but I quit. It seemed so... Republican.\n",
      "Bert Score : {'precision': [0.8748208284378052], 'recall': [0.8601579666137695], 'f1': [0.867427408695221], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473684, 'rouge2': 0.0, 'rougeL': 0.10526315789473684, 'rougeLsum': 0.10526315789473684}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 133.6371444956503\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHERRICK: I've been writing.\\nROWENA: That's good... You haven't seen me in the play yet.\\nHERRICK: I will. I've been working on a surprise for you.\\nROWENA: Really?\\nHERRICK: Yes, but you can't run off to California until I'm done with it.\\n\\n\", 'answer': \"I don't know if I can wait.\", 'gold_tag': 'ROWENA is considering moving to California in the near future but is unsure of the timing', 'last_speaker': 'ROWENA'}\n",
      "Last word -> ROWENA : \"I don't know if I can wait.\"\n",
      "prediction :  Okay.\n",
      "Real answer : I don't know if I can wait.\n",
      "Bert Score : {'precision': [0.9225194454193115], 'recall': [0.82582026720047], 'f1': [0.8714957237243652], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2086.293093463323\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSIDNEY: Spahish...that must show he likes \"spigs\", too.\\nHUNSECKER: I like Harry, but I can\\'t deny he I love this dirty town. Conjugate me a verb, Sidney. For instance, TO PROMISE! You told me you\\'d break up that romance - when?\\nSIDNEY: You want something done, J.J., but I doubt if you yourself know what\\'s involved.\\nHUNSECKER: I\\'m a schoolboy - teach me, teach me.\\nSIDNEY: Why not break it up yourself? You could do it in two minutes flat.\\nHUNSECKER: At this late date you need explanations...? Susie\\'s all I got - now that she\\'s growing up, I want my relationship with her to stay at least at par! I don\\'t intend to antagonize her if I don\\'t have to. Now, be warned, son - I\\'ll have to blitz you...\\nSIDNEY: Frankly, J.J., I don\\'t think you got the cards to blitz me.\\nHUNSECKER: I don\\'t?\\nSIDNEY: Correct me if I\\'m wrong, but I don\\'t think so...\\nHUNSECKER: I\\'ll listen one more minute.\\nSIDNEY: About a year ago, you asked me to do a favor. It was a thing - well, I never did a thing that dirty in all my life. Awright, that brings us up to five weeks ago. \"Sidney, I got a nasty little problem here.\" Did I say no? I\\'m frank to admit - it don\\'t jell as fast as we like... But all of a sudden I CAN\\'T GET YOU ON THE PHONE NO MORE! WHY?... And why, as of this date, am I frozen out of the\\nHUNSECKER: Are you finished?\\nSIDNEY: No, lemme finish. I DON\\'T LIKE THIS JOB! That boy is dumb only on matinee days - otherwise he\\'s got a head. And Susan, like you said, she\\'s growing up. Two heads. What I mean, we got a slippery, dangerous problem here!\\nHUNSECKER: Not \"we\", Sidney, you!\\nSIDNEY: Correct me if I\\'m wrong - WE! Because when I\\'m out on this very slippery limb for you, you have to know what\\'s involved.\\nHUNSECKER: Ha! My right hand hasn\\'t seen my left hand for thirty years!\\nSIDNEY: I\\'ll do it, J.J. - don\\'t get me wrong - in for a penny, in for a pound. I\\'ll see it through, but stop beating me around the head. Let me make a living!\\nHUNSECKER: What you promised - do it! Don\\'t finagle around. It\\'s later than you think.\\nSIDNEY: Excuse it, but it\\'s later than you think. That boy proposed tonight.\\nHUNSECKER: Susie told you that...? No wonder you\\'ve been so \\'feisty\\' tonight. Can you deliver?\\nSIDNEY: Uh huh.\\nHUNSECKER: When?\\nSIDNEY: Tonight. Before you go to bed. The cat is in the bag and the bag is in the river.\\n\\n', 'answer': \"Don't be a two time loser, Sidalee. The sentence could be severe...\", 'gold_tag': 'HUNSECKER is persuasive and manipulative', 'last_speaker': 'HUNSECKER'}\n",
      "Last word -> HUNSECKER : \"Don't be a two time loser, Sidalee. The sentence could be severe...\"\n",
      "prediction :  You're a son of a bitch, Sidney!\n",
      "Real answer : Don't be a two time loser, Sidalee. The sentence could be severe...\n",
      "Bert Score : {'precision': [0.8576205968856812], 'recall': [0.8455489873886108], 'f1': [0.851542055606842], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809525, 'rouge2': 0.0, 'rougeL': 0.09523809523809525, 'rougeLsum': 0.09523809523809525}\n",
      "bleu 1/2 : 0.06993452279385044 0.023887187063648833\n",
      "ppl : 30.218445341542846\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHUNSECKER: So that\\'s what \"integrity\" looks like. Well, I\\'m always willing to learn... How is that slob, D\\'Angelo, your uncle?\\nSIDNEY: My mother\\'s side--her brother. That reminds me, J.J., Susie looks run down. She can stand a vacation and so can you. People say, \"Oh, the great J.J., he\\'s made of iron!\", but you can use a rest, guy.\\nHUNSECKER: What are you so chipper about? If I put a cross on every one of your mistakes, you\\'d look like a graveyard!\\nSIDNEY: But not for anything I did today...\\nHUNSECKER: Sidney, I know human nature. Susie lied to me - she\\'ll see that boy again.\\n\\n', 'answer': 'You\\'re right, J.J. - she won\\'t give him up, but it doesn\\'t matter. Because the real \"money ball\" is the boy, not Susan. And if --', 'gold_tag': \"SIDNEY is aware of HUNSECKER's reputation\", 'last_speaker': 'SIDNEY'}\n",
      "Last word -> SIDNEY : \"You're right, J.J. - she won't give him up, but it doesn't matter. Because the real \"money ball\" is the boy, not Susan. And if --\"\n",
      "prediction :  How do you know?\n",
      "Real answer : You're right, J.J. - she won't give him up, but it doesn't matter. Because the real \"money ball\" is the boy, not Susan. And if --\n",
      "Bert Score : {'precision': [0.8176577091217041], 'recall': [0.8120428323745728], 'f1': [0.8148406147956848], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0625, 'rouge2': 0.0, 'rougeL': 0.0625, 'rougeLsum': 0.0625}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 103.96580450489589\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHUNSECKER: What a cornball you are, Sidney...\\n\\n', 'answer': 'Susie! SUSIE!', 'gold_tag': 'SIDNEY is panicky or alarmed , SIDNEY is shouting for Susie', 'last_speaker': 'SIDNEY'}\n",
      "Last word -> SIDNEY : \"Susie! SUSIE!\"\n",
      "prediction :  I'm sorry. I'm sorry I'm not as sophisticated as you.\n",
      "Real answer : Susie! SUSIE!\n",
      "Bert Score : {'precision': [0.8328197002410889], 'recall': [0.809104323387146], 'f1': [0.8207907676696777], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 10.186006648115294\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOOPER: There's a fantail launch out there that won't make it beyond the breakwater.\\nBRODY: You're tellin' me. I swear, this town has gone crazy.\\nHOOPER: Officer, I wonder if you could tell me where I could find Chief Brody?\\nBRODY: Who are you?\\n\\n\", 'answer': 'Hooper, Matt Hooper. From the Oceanographic Institute.', 'gold_tag': 'HOOPER is Matt Hooper , HOOPER is a representative from the Oceanographic Institute', 'last_speaker': 'HOOPER'}\n",
      "Last word -> HOOPER : \"Hooper, Matt Hooper. From the Oceanographic Institute.\"\n",
      "prediction :  My name is Hooper. I'm a fisherman. I've been watching this fantail launch from the water. I'm not sure it's gonna make it.\n",
      "Real answer : Hooper, Matt Hooper. From the Oceanographic Institute.\n",
      "Bert Score : {'precision': [0.8337725400924683], 'recall': [0.8554465770721436], 'f1': [0.8444705605506897], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17647058823529413, 'rouge2': 0.0625, 'rougeL': 0.17647058823529413, 'rougeLsum': 0.17647058823529413}\n",
      "bleu 1/2 : 0.08695652173913045 0.01988106931218861\n",
      "ppl : 14.660926729124961\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRODY: Let's show Mr. Hooper our accident.\\nHOOPER: Victim One, identified as Christine Watkins, female Caucasian... ...height and weight may only be severed in mid-thorax, eviscerated with no major organs remaining. May I have a drink of water? Right arm severed above the elbow with massive tissue loss from upper musculature. Portions of denuded bone remaining. -- did you notify the coast guard?\\nBRODY: No, it was local jurisdiction.\\n\\n\", 'answer': \"Left arm, head, shoulders, sternum and portions of ribcage intact. Please don't smoke. With minor post- mortem lacerations and abrasions. feeding pattern of large squali, possibly carchaninus lonimanus, or\", 'gold_tag': \"HOOPER's actions suggest a focus on health\", 'last_speaker': 'HOOPER'}\n",
      "Last word -> HOOPER : \"Left arm, head, shoulders, sternum and portions of ribcage intact. Please don't smoke. With minor post- mortem lacerations and abrasions. feeding pattern of large squali, possibly carchaninus lonimanus, or\"\n",
      "prediction :  I'll make the call.\n",
      "Real answer : Left arm, head, shoulders, sternum and portions of ribcage intact. Please don't smoke. With minor post- mortem lacerations and abrasions. feeding pattern of large squali, possibly carchaninus lonimanus, or\n",
      "Bert Score : {'precision': [0.8617159128189087], 'recall': [0.7765833139419556], 'f1': [0.8169377446174622], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 84.15498033012668\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRODY: No, we just checked the beach...\\n\\n', 'answer': \"It wasn't an 'accident,' it wasn't a boat propeller, or a coral reef, or Jack the Ripper. It was a shark. It was a shark.\", 'gold_tag': 'HOOPER is knowledgeable about sharks and other sea accidents , HOOPER suggests a background in marine science or a related field', 'last_speaker': 'HOOPER'}\n",
      "Last word -> HOOPER : \"It wasn't an 'accident,' it wasn't a boat propeller, or a coral reef, or Jack the Ripper. It was a shark. It was a shark.\"\n",
      "prediction :  What'd you find?\n",
      "Real answer : It wasn't an 'accident,' it wasn't a boat propeller, or a coral reef, or Jack the Ripper. It was a shark. It was a shark.\n",
      "Bert Score : {'precision': [0.8444083333015442], 'recall': [0.8006823062896729], 'f1': [0.8219642639160156], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 137.48946113989166\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOOPER: ...And it was Dartmouth Winter weekend, and she was Homecoming Queen, and I was her date; then she got into the fact that her family had more money than my family, and she was right -- her great-grandfather was in mining, and my ancestors were Yankee shipbuilders. So we broke up and I went home with some beatnik from Sarah Lawrence.\\nBRODY: What stinks so bad?\\nHOOPER: Our friend, the shark. We always had a summer place on the water -- Newport, the Vineyard, so I figured I'd major in something I knew about. Oceanography, marine biology. It was that, or design racing yachts like my older brother. Hmmm. He we go. Up the old alimentary canal. Hold the light. We open the abdominal cavity and check the digestive tract. Simple.\\nBRODY: What's that?\\nHOOPER: Half a flounder. Hmmm... a burlap bag... a paint can... aha!\\nBRODY: What? What?!\\nHOOPER: Just as I thought. He drifted up here with the Gulf Stream, from southern waters.\\nBRODY: How can you tell?\\nHOOPER: Florida license plate.\\nBRODY: He ate a car?\\nHOOPER: No, but Tiger sharks are the garbage cans of the ocean. They eat anything. But this one didn't eat any people. There's nothing here... ...Nothing.\\nBRODY: What do we do?\\n\\n\", 'answer': \"If you're looking for a shark, you don't look on land. You go out and chum for him. Only one sure way to find him -- offer him a little something to eat. Chum -- blood, waste meat, fish, anything. They can sense it miles away. If he's out there, we might be able to get a closer look at him. It's a good time, too. They're night feeders...\", 'gold_tag': 'HOOPER is educated, focusing on oceanography and marine biology', 'last_speaker': 'HOOPER'}\n",
      "Last word -> HOOPER : \"If you're looking for a shark, you don't look on land. You go out and chum for him. Only one sure way to find him -- offer him a little something to eat. Chum -- blood, waste meat, fish, anything. They can sense it miles away. If he's out there, we might be able to get a closer look at him. It's a good time, too. They're night feeders...\"\n",
      "prediction :  We'll put him back. He can swim around again, like the rest.\n",
      "Real answer : If you're looking for a shark, you don't look on land. You go out and chum for him. Only one sure way to find him -- offer him a little something to eat. Chum -- blood, waste meat, fish, anything. They can sense it miles away. If he's out there, we might be able to get a closer look at him. It's a good time, too. They're night feeders...\n",
      "Bert Score : {'precision': [0.8689031004905701], 'recall': [0.8245348930358887], 'f1': [0.8461377024650574], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09411764705882353, 'rouge2': 0.0, 'rougeL': 0.047058823529411764, 'rougeLsum': 0.047058823529411764}\n",
      "bleu 1/2 : 0.0014419492005201058 0.00033676677904183653\n",
      "ppl : 48.845422521915005\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOOPER: That's the Cape Light -- we're on the stretch where he's feeding, if he's still here.\\nBRODY: What is all this stuff?\\nHOOPER: Depth-finder, fathometer, sonar, closed-circuit TV -- fore and aft -- RDF, single side band... And two loose nuts behind the wheel.\\nBRODY: Can you tell from that if a big man- eater is around?\\n\\n\", 'answer': 'Sometimes. Look here -- something big, probably a school of mackerel clumped together. And staying right with us.', 'gold_tag': 'HOOPER demonstrates knowledge of marine technology , HOOPER demonstrates knowledge of navigation', 'last_speaker': 'HOOPER'}\n",
      "Last word -> HOOPER : \"Sometimes. Look here -- something big, probably a school of mackerel clumped together. And staying right with us.\"\n",
      "prediction :  It's like he's gone into hiding. He's got the Cape Light right where he wants it.\n",
      "Real answer : Sometimes. Look here -- something big, probably a school of mackerel clumped together. And staying right with us.\n",
      "Bert Score : {'precision': [0.8419603109359741], 'recall': [0.8462352752685547], 'f1': [0.8440923690795898], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05555555555555555, 'rouge2': 0.0, 'rougeL': 0.05555555555555555, 'rougeLsum': 0.05555555555555555}\n",
      "bleu 1/2 : 0.055156056411537216 0.018013892590990767\n",
      "ppl : 25.40721715682658\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHOOPER: I Bought it. Both sets of grandparents set up trust funds for me; stocks went up, so I don't have to touch my principal.\\nBRODY: You're at the Institute full time? Or do you have a job?\\nHOOPER: It is a job. I'm not fooling around like some amateur. It's my life!\\nBRODY: We gotta get back soon... Hey! What the hell? That's Ben Gardner's boat! It's the Flicka! Ben? Ben! What happened?\\nHOOPER: I want to check something. Hold my feet.\\nBRODY: Don't they have lifejackets or something? An extra boat?\\nHOOPER: They must've hit something. He didn't have a dinghy aboard. I'm going down to take a look at his hull.\\nBRODY: Why don't we just tow it in?\\nHOOPER: We will. There's something I've got to find out.\\n\\n\", 'answer': 'Be careful, for chrissake.', 'gold_tag': 'BRODY is concerned about safety', 'last_speaker': 'BRODY'}\n",
      "Last word -> BRODY : \"Be careful, for chrissake.\"\n",
      "prediction :  What?\n",
      "Real answer : Be careful, for chrissake.\n",
      "Bert Score : {'precision': [0.8462649583816528], 'recall': [0.7767738699913025], 'f1': [0.8100317716598511], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRODY: You all right?\\nHOOPER: A White! A Great White, I found a tooth buried in the hull. He must've attacked... I knew it... Gardner's dead in there. I didn't see the mate...\\nBRODY: No shark did that to a boat!\\n\\n\", 'answer': \"Jesus Christ! A Great White! Who'd believe it! We're not talking about a shark, we're talking about a Shark!\", 'gold_tag': \"HOOPER's shock and excitement suggest a level of obsession or intense interest in large predatory sharks\", 'last_speaker': 'HOOPER'}\n",
      "Last word -> HOOPER : \"Jesus Christ! A Great White! Who'd believe it! We're not talking about a shark, we're talking about a Shark!\"\n",
      "prediction :  No. It's a shark.\n",
      "Real answer : Jesus Christ! A Great White! Who'd believe it! We're not talking about a shark, we're talking about a Shark!\n",
      "Bert Score : {'precision': [0.9302674531936646], 'recall': [0.8417758941650391], 'f1': [0.8838121294975281], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222218, 'rouge2': 0.08, 'rougeL': 0.22222222222222218, 'rougeLsum': 0.22222222222222218}\n",
      "bleu 1/2 : 0.005879436464002277 0.0021468666511683054\n",
      "ppl : 98.02426908195206\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAM: I'm thirsty.\\nALI: We don't have any money.\\n\\n\", 'answer': \"I'm thirsty!\", 'gold_tag': \"SAM expresses his thirst twice , SAM's thirst is a temporary state, which will soon change\", 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"I'm thirsty!\"\n",
      "prediction :  I'm thirsty.\n",
      "Real answer : I'm thirsty!\n",
      "Bert Score : {'precision': [0.9873248338699341], 'recall': [0.9580471515655518], 'f1': [0.9724656343460083], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
      "bleu 1/2 : 0.5 0.223606797749979\n",
      "ppl : 57.51121766579805\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALI: I don't know. A big street that started at the station. Yeah, by the beach. Behind? We just came from there!\\nSAM: I'm tired.\\n\\n\", 'answer': \"So am I. He's coming to pick us up. Come on!\", 'gold_tag': 'ALI is expecting someone to pick them up soon', 'last_speaker': 'ALI'}\n",
      "Last word -> ALI : \"So am I. He's coming to pick us up. Come on!\"\n",
      "prediction :  Come on. You want to see the city. I'll show you.\n",
      "Real answer : So am I. He's coming to pick us up. Come on!\n",
      "Bert Score : {'precision': [0.9047781229019165], 'recall': [0.8770204186439514], 'f1': [0.8906830549240112], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.09090909090909091, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.18181818181818182 0.042640143271122095\n",
      "ppl : 23.621950144193395\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALI: Are you happy here?\\nSAM: Mm.\\nALI: What do you like the most at Auntie's?\\nSAM: The dogs.\\nALI: Is that all? Nothing else besides the dogs?\\nSAM: The truck.\\n\\n\", 'answer': 'The dogs and the truck. The house? Auntie? The ocean? We have it good here...', 'gold_tag': \"ALI mentions an Aunt, a truck, and dogs , ALI shows concern for SAM's happiness and preferences\", 'last_speaker': 'ALI'}\n",
      "Last word -> ALI : \"The dogs and the truck. The house? Auntie? The ocean? We have it good here...\"\n",
      "prediction :  The truck?\n",
      "Real answer : The dogs and the truck. The house? Auntie? The ocean? We have it good here...\n",
      "Bert Score : {'precision': [0.9160289168357849], 'recall': [0.8382911682128906], 'f1': [0.8754376769065857], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23529411764705882, 'rouge2': 0.13333333333333333, 'rougeL': 0.23529411764705882, 'rougeLsum': 0.23529411764705882}\n",
      "bleu 1/2 : 0.0007517195964887862 0.00033617922355352767\n",
      "ppl : 851.4250931134661\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALI: Give me a kiss.\\nSAM: I don't want to.\\nALI: Give Daddy a kiss!\\nSAM: No.\\nALI: (using a deep voice) Give Daddy a kiss!\\n\\n\", 'answer': '(deep voice too)... No!', 'gold_tag': \"SAM mirrors ALI's playfulness by mimicking his deep voice\", 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"(deep voice too)... No!\"\n",
      "prediction :  I will not.\n",
      "Real answer : (deep voice too)... No!\n",
      "Bert Score : {'precision': [0.8789222240447998], 'recall': [0.8016862869262695], 'f1': [0.8385294675827026], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 427.56279959073703\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nALI: Wake up, kiddo. It's over. We're going home.\\n\\n\", 'answer': 'Did you win?', 'gold_tag': \"SAM is interested in whether ALI was successful, showing curiosity or support , The phrase 'Did you win?' implies that ALI might be involved in competitive activities\", 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"Did you win?\"\n",
      "prediction :  What?! Are you serious?!\n",
      "Real answer : Did you win?\n",
      "Bert Score : {'precision': [0.823515772819519], 'recall': [0.8472449779510498], 'f1': [0.8352118134498596], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0.25 0.09128709291752769\n",
      "ppl : 51.87719245981585\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSUZETTE: It must be a mistake, Papa.\\nBEN: Of course it is. I went down there, told them. They're looking into it.\\nSUZETTE: Went down where?\\nBEN: John Vorster Square.\\nSUZETTE: You old devil you. Does Ma know?\\nBEN: No. And you're not going to tell her.\\n\\n\", 'answer': \"Be careful. I don't want my favorite Papa in trouble, Gordon or no Gordon.\", 'gold_tag': \"SUZETTE is concerned about her father's well-being , SUZETTE has a close relationship with her father\", 'last_speaker': 'SUZETTE'}\n",
      "Last word -> SUZETTE : \"Be careful. I don't want my favorite Papa in trouble, Gordon or no Gordon.\"\n",
      "prediction :  So you went down to the police and told them about me?\n",
      "Real answer : Be careful. I don't want my favorite Papa in trouble, Gordon or no Gordon.\n",
      "Bert Score : {'precision': [0.8333390951156616], 'recall': [0.8296085000038147], 'f1': [0.8314695954322815], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 40.669354718488485\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBEN: -- How's she doing?\\nSUZETTE: Better... She's waiting for you to ask her to come home.\\nBEN: I doubt it.\\nSUZETTE: Papa, I don't want to interfere...\\nBEN: Then don't.\\nSUZETTE: I know this is going to sound strange coming from me... I mean I haven't exactly been supportive for the past months... I can't say I agree with what you've done but I respect you for what you are... I'm just... destroyed by what's happening to us as a family.\\nBEN: Suzette...\\n\\n\", 'answer': \"Please, Papa, for Mom's sake... For all of our sakes... Let's try and patch it up.\", 'gold_tag': 'SUZETTE aims to mediate family matters , Shared memories', 'last_speaker': 'SUZETTE'}\n",
      "Last word -> SUZETTE : \"Please, Papa, for Mom's sake... For all of our sakes... Let's try and patch it up.\"\n",
      "prediction :  I know. I'm sorry.\n",
      "Real answer : Please, Papa, for Mom's sake... For all of our sakes... Let's try and patch it up.\n",
      "Bert Score : {'precision': [0.8783528804779053], 'recall': [0.8097960352897644], 'f1': [0.8426823616027832], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 40.98218205534661\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSUZETTE: Let me know if there's anything I can do to help.\\nBEN: Thanks. I'm glad you understand.\\nSUZETTE: I don't want to worry about you. That search, this vandalism, those shots... they're really after the evidence you've been accumulating ... Can I look after them for you, Papa?\\nBEN: You don't have to worry. They'll never find them.\\n\\n\", 'answer': 'Where on earth do you keep them?', 'gold_tag': 'Everyday Language', 'last_speaker': 'SUZETTE'}\n",
      "Last word -> SUZETTE : \"Where on earth do you keep them?\"\n",
      "prediction :  It's not just about the evidence, Papa. I'm worried about you.\n",
      "Real answer : Where on earth do you keep them?\n",
      "Bert Score : {'precision': [0.8482562303543091], 'recall': [0.8169039487838745], 'f1': [0.8322849273681641], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1, 'rouge2': 0.0, 'rougeL': 0.1, 'rougeLsum': 0.1}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.77181454811192\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBEN: How are you, Suzette?\\nSUZETTE: Okay, Papa.\\nBEN: Would you like a drink?\\nSUZETTE: No, thanks. I have to go, Papa.\\n\\n', 'answer': 'I know. Look after them.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BEN'}\n",
      "Last word -> BEN : \"I know. Look after them.\"\n",
      "prediction :  I'll walk you out.\n",
      "Real answer : I know. Look after them.\n",
      "Bert Score : {'precision': [0.8812487125396729], 'recall': [0.8933312892913818], 'f1': [0.8872488737106323], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20000000000000004, 'rouge2': 0.0, 'rougeL': 0.20000000000000004, 'rougeLsum': 0.20000000000000004}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 97.25489910843115\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICK: Come on!\\nMALCOLM: Where's Kelly?\\n\\n\", 'answer': \"She's with Sarah!\", 'gold_tag': 'Everyday Language', 'last_speaker': 'NICK'}\n",
      "Last word -> NICK : \"She's with Sarah!\"\n",
      "prediction :  I don't know.\n",
      "Real answer : She's with Sarah!\n",
      "Bert Score : {'precision': [0.8268930912017822], 'recall': [0.8391440510749817], 'f1': [0.8329735398292542], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 52.19149636039691\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMALCOLM: We can\\'t stay in here!\\nNICK: We\\'re sure as hell not going back out there\"\\nMALCOLM: This is single-wall construction! It\\'s just a shack!\\nNICK: It\\'ll hold!\\nMALCOLM: For sixty seconds, maybe! Look at this! You could-\\nNICK: Head for the roof!\\nMALCOLM: I have to find Kelly!\\nNICK: I think she\\'s with Sarah!\\n\\n', 'answer': 'DAMN IT, BE SURE!!', 'gold_tag': 'MALCOLM is protective', 'last_speaker': 'MALCOLM'}\n",
      "Last word -> MALCOLM : \"DAMN IT, BE SURE!!\"\n",
      "prediction :  Sarah?\n",
      "Real answer : DAMN IT, BE SURE!!\n",
      "Bert Score : {'precision': [0.8494093418121338], 'recall': [0.8013338446617126], 'f1': [0.8246714472770691], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 7868.592332733439\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMALCOLM: It's too wide!\\n\\n\", 'answer': 'Help me push this!', 'gold_tag': 'Everyday Language', 'last_speaker': 'NICK'}\n",
      "Last word -> NICK : \"Help me push this!\"\n",
      "prediction :  You're right.\n",
      "Real answer : Help me push this!\n",
      "Bert Score : {'precision': [0.8416346311569214], 'recall': [0.8240426182746887], 'f1': [0.8327456712722778], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 58.40577433756828\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMALCOLM: Something's wrong.\\nNICK: Look! Sarah!\\n\\n\", 'answer': \"SHE'S ALONE!!\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MALCOLM'}\n",
      "Last word -> MALCOLM : \"SHE'S ALONE!!\"\n",
      "prediction :  What?\n",
      "Real answer : SHE'S ALONE!!\n",
      "Bert Score : {'precision': [0.8754017353057861], 'recall': [0.8107399940490723], 'f1': [0.8418309688568115], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCASEY: What!? It was a boring story!\\nAPRIL: That is so perfectly CASEY JONES. I give you opportunity. I give you the chance to become a better man. And what do you do with it?\\nCASEY: Well, maybe if you were home for more than four days at a time, you'd see that I DON'T WANT ANY OF\\nAPRIL: Casey, you better be careful-\\nCASEY: Here I am nice enough to help you out, dress in this get-up and all I get is grief?! Oh boy.\\n\\n\", 'answer': 'Give me strength.', 'gold_tag': 'Everyday Language', 'last_speaker': 'APRIL'}\n",
      "Last word -> APRIL : \"Give me strength.\"\n",
      "prediction :  I'm just trying to help you.\n",
      "Real answer : Give me strength.\n",
      "Bert Score : {'precision': [0.8811424374580383], 'recall': [0.8999389410018921], 'f1': [0.8904414772987366], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.523230711833584\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCASEY: Nah. Ever since you started with the blade weapons you, um... you kinda scare me.\\nAPRIL: Suit yourself. Case?\\nCASEY: Yeah?\\nAPRIL: Are you happy? I mean, with your life. With me.\\nCASEY: Yeah. Sure. You?\\nAPRIL: Yeah.\\nCASEY: I'm going outside for some air.\\n\\n\", 'answer': 'Be safe.', 'gold_tag': \"April shows concern for Casey's well-being\", 'last_speaker': 'APRIL'}\n",
      "Last word -> APRIL : \"Be safe.\"\n",
      "prediction :  Yeah, I'll stay here.\n",
      "Real answer : Be safe.\n",
      "Bert Score : {'precision': [0.8571232557296753], 'recall': [0.8891843557357788], 'f1': [0.8728594779968262], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 45.19362338268346\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCASEY: Wow.\\nAPRIL: Picked it up on my last trip to Japan. You... like it?\\nCASEY: Oh... oh yeah.\\nAPRIL: Where's your mask?\\nCASEY: Mask? What mask? No way...\\n\\n\", 'answer': \"I was saving it for our anniversary. That's our ride.\", 'gold_tag': 'APRIL is thoughtful and sentimental , Shared memories: They have a shared memory of having or soon celebrating an anniversary', 'last_speaker': 'APRIL'}\n",
      "Last word -> APRIL : \"I was saving it for our anniversary. That's our ride.\"\n",
      "prediction : You're kidding. I'm supposed to be on a secret mission.\n",
      "Real answer : I was saving it for our anniversary. That's our ride.\n",
      "Bert Score : {'precision': [0.8692972660064697], 'recall': [0.8679201602935791], 'f1': [0.8686081171035767], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913043, 'rouge2': 0.0, 'rougeL': 0.08695652173913043, 'rougeLsum': 0.08695652173913043}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.565498728277287\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nAPRIL: I had the situation under control.\\nCASEY: You're welcome.\\n\\n\", 'answer': 'Guys! Front door is open. Now!', 'gold_tag': 'Everyday Language', 'last_speaker': 'APRIL'}\n",
      "Last word -> APRIL : \"Guys! Front door is open. Now!\"\n",
      "prediction :  What do you want?\n",
      "Real answer : Guys! Front door is open. Now!\n",
      "Bert Score : {'precision': [0.8365001678466797], 'recall': [0.8384483456611633], 'f1': [0.8374731540679932], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 82.82606459634773\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFAY: What do you mean, you quit?\\nSIMON: I quit my job.\\nFAY: Why!\\nSIMON: There are things I want to do.\\nFAY: Like what?\\nSIMON: 'Opportunity will step out of the way to let a man... pass it by.'\\nFAY: Are you drunk?\\nSIMON: Now you have to go out and get a job!\\nFAY: I am not gettin' a job! Who's gunna look after Mom!\\nSIMON: I will.\\nFAY: Pearl, go outside.\\nSIMON: If you treat Mom like a sick person, she's gunna stay like... you know, a sick person.\\nFAY: Simon, don't be retarded...\\nSIMON: I am not retarded! I can see with my own eyes.\\nFAY: Mom can't be left alone with no one to keep an eye on her.\\n\\n\", 'answer': \"Well, who's been keeping an eye on her while you've been out getting fucked by every OTB winner in town? Aggghhhh!!!\", 'gold_tag': \"SIMON's remarks hint at FAY potentially having a promiscuous lifestyle\", 'last_speaker': 'SIMON'}\n",
      "Last word -> SIMON : \"Well, who's been keeping an eye on her while you've been out getting fucked by every OTB winner in town? Aggghhhh!!!\"\n",
      "prediction :  I'll be there for her.\n",
      "Real answer : Well, who's been keeping an eye on her while you've been out getting fucked by every OTB winner in town? Aggghhhh!!!\n",
      "Bert Score : {'precision': [0.8826729655265808], 'recall': [0.8155503273010254], 'f1': [0.8477851152420044], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06896551724137931, 'rouge2': 0.0, 'rougeL': 0.06896551724137931, 'rougeLsum': 0.06896551724137931}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 57.30828623874965\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFAY: What's up?\\nSIMON: Nothing.\\nFAY: I'm creating my r�sum�. This computer's got a program especially for it. I bought some special stationery too. It's scented. Look. It's roses.\\nSIMON: Can you type my poem into that thing?\\nFAY: That's your poem?\\nSIMON: Yeah.\\n\\n\", 'answer': \"Simon, Mom's right about you. A poem's supposed to be a small, delicate kinda thing. Kinda feminine. Gentle. Look at this. You've made a fuckin' telephone book.\", 'gold_tag': \"FAY has a critical view on the traditional scope and form of poetry , SIMON is a writer, specifically a poet , SIMON's poem is extensive\", 'last_speaker': 'FAY'}\n",
      "Last word -> FAY : \"Simon, Mom's right about you. A poem's supposed to be a small, delicate kinda thing. Kinda feminine. Gentle. Look at this. You've made a fuckin' telephone book.\"\n",
      "prediction :  You want me to type it into your r�sum�?\n",
      "Real answer : Simon, Mom's right about you. A poem's supposed to be a small, delicate kinda thing. Kinda feminine. Gentle. Look at this. You've made a fuckin' telephone book.\n",
      "Bert Score : {'precision': [0.7934311628341675], 'recall': [0.830767810344696], 'f1': [0.8116704225540161], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1, 'rouge2': 0.0, 'rougeL': 0.1, 'rougeLsum': 0.1}\n",
      "bleu 1/2 : 0.015037253692956965 0.005043648217854228\n",
      "ppl : 83.55110087897104\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFAY: Simon, wake up! The guy's in a dream world!\\nSIMON: He's afraid that his reputation will prevent people from giving my work an honest chance.\\nFAY: His reputation as what?\\nSIMON: As a writer.\\nFAY: Gimme a break.\\nSIMON: He's kinda like in exile. Marginalized on account of his ideas.\\nFAY: If he's such a great big fat genius, why doesn't he write books? Like you do.\\nSIMON: He has. He's written a book. It's almost completed. He's been working on it for years. It's just not published.\\nFAY: Yeah, I bet. It's probably disgusting.\\nSIMON: It's a quite serious and difficult piece of work, apparently.\\nFAY: Have you read it?\\nSIMON: No. Not yet. Soon. Certain work needs to be experienced all at once in order for one to appreciate the full force of its character.\\n\\n\", 'answer': \"Yeah, well, what ever. Listen, Simon, forget Henry. Go straight up to this Angus James character yourself and make him read your poem. I'm gunna apply for a job at the one- hour photo joint and then go over to the Mall to see about that job in the bank. Make sure Mom takes her pills. See ya.\", 'gold_tag': \"FAY plans to apply for a job at the one-hour photo joint , FAY plans to go to the Mall to see about a job at the bank , FAY is caring for a person named 'Mom' who is on medication , FAY instructs Simon to ensure that 'Mom' takes her pills\", 'last_speaker': 'FAY'}\n",
      "Last word -> FAY : \"Yeah, well, what ever. Listen, Simon, forget Henry. Go straight up to this Angus James character yourself and make him read your poem. I'm gunna apply for a job at the one- hour photo joint and then go over to the Mall to see about that job in the bank. Make sure Mom takes her pills. See ya.\"\n",
      "prediction :  I'll be damned.\n",
      "Real answer : Yeah, well, what ever. Listen, Simon, forget Henry. Go straight up to this Angus James character yourself and make him read your poem. I'm gunna apply for a job at the one- hour photo joint and then go over to the Mall to see about that job in the bank. Make sure Mom takes her pills. See ya.\n",
      "Bert Score : {'precision': [0.8044316172599792], 'recall': [0.7976586818695068], 'f1': [0.8010308146476746], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.031746031746031744, 'rouge2': 0.0, 'rougeL': 0.031746031746031744, 'rougeLsum': 0.031746031746031744}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 38.22999783310495\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSIMON: Did you see him?\\nFAY: He came by this afternoon.\\nSIMON: Did you talk?\\nFAY: No.\\nSIMON: You've got to tell him, Fay.\\n\\n\", 'answer': \"He thinks I'm a slut.\", 'gold_tag': 'FAY is seen as promiscuous by at least one individual', 'last_speaker': 'FAY'}\n",
      "Last word -> FAY : \"He thinks I'm a slut.\"\n",
      "prediction :  I can't.\n",
      "Real answer : He thinks I'm a slut.\n",
      "Bert Score : {'precision': [0.8905513286590576], 'recall': [0.8996099233627319], 'f1': [0.895057737827301], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2222222222222222, 'rouge2': 0.0, 'rougeL': 0.2222222222222222, 'rougeLsum': 0.2222222222222222}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 127.82165926513017\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nFAY: It's really that bad?\\n\\n\", 'answer': \"It's terrible.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SIMON'}\n",
      "Last word -> SIMON : \"It's terrible.\"\n",
      "prediction :  It's worse than that.\n",
      "Real answer : It's terrible.\n",
      "Bert Score : {'precision': [0.8899499177932739], 'recall': [0.9350888729095459], 'f1': [0.9119611978530884], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.5, 'rouge2': 0.3333333333333333, 'rougeL': 0.5, 'rougeLsum': 0.5}\n",
      "bleu 1/2 : 0.25 0.09128709291752769\n",
      "ppl : 47.67252926959905\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMAGGIE: Oh, Joe, don't-- Forget it.\\nDONNIE: What's the matter?\\nMAGGIE: I liked your moustache. It's the only thing I liked about this thing of yours.\\nDONNIE: Well, what do you want me to do now?\\nMAGGIE: I want you to ask me.\\nDONNIE: You could've said something.\\nMAGGIE: What would you suggest I do--tell Berada to get a message to you that I like your moustache?\\nDONNIE: That's not the point.\\nMAGGIE: I have to ask you about every frigging thing.\\nDONNIE: Maggie, I'll be two seconds.\\nMAGGIE: They were supposed to pick me up five minutes ago.\\nDONNIE: You're going to the movies with the Grants?\\nMAGGIE: Why don't you come?\\nDONNIE: The last thing I want to do tonight is go to the movies with the Grants.\\nMAGGIE: I'm not cancelling.\\nDONNIE: Where is everybody? I didn't say anything? I'm sure I said Well, they should be home anyway.\\nMAGGIE: Sherry's sleeping over at Mom's,\\nDONNIE: Where's Terry?\\nMAGGIE: She's with her boyfriend. Leave my stuff alone.\\nDONNIE: What boyfriend?\\nMAGGIE: K enny. Wha t are you worri ed about? I was 14 when we started dating.\\nDONNIE: That's what I ' m worried about.\\nMAGGIE: He's a nice kid. Nice family.\\nDONNIE: I ' m sure he is. I ' m sure he's practicing his takedowns right now.\\nMAGGIE: Maybe I'11 shave my head next time--� see how you like it.\\nDONNIE: I expect you to have some sense of priorities. I put a roof over y our he ad. I put clo the s o n\\nMAGGIE: Leave my stuff alone.\\nDONNIE: I give you whatever I can give. What I can't give you is a moustache. I don't have a choice. I have to shave the moustache.\\n\\n\", 'answer': \"I don't give a shit about the m oustache. But if yo u're gonna live your life however the fuck you want then let me live mine.\", 'gold_tag': 'MAGGIE asserts her right to live her life as she pleases', 'last_speaker': 'MAGGIE'}\n",
      "Last word -> MAGGIE : \"I don't give a shit about the m oustache. But if yo u're gonna live your life however the fuck you want then let me live mine.\"\n",
      "prediction :  Why?\n",
      "Real answer : I don't give a shit about the m oustache. But if yo u're gonna live your life however the fuck you want then let me live mine.\n",
      "Bert Score : {'precision': [0.8762731552124023], 'recall': [0.7794597148895264], 'f1': [0.8250360488891602], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3142.135932895678\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMAGGIE: I want a divorce.\\nDONNIE: There hasn't been a divorce in my family back to Julius Caesar. Divorce someone else.\\nMAGGIE: I ' m serious.\\nDONNIE: Maggie, I ' m tired. Go to sleep.\\nMAGGIE: will you see a therapist?\\nDONNIE: It's just another six months.\\n\\n\", 'answer': \"I can't sleep for six months, Joe.\", 'gold_tag': 'Maggie expresses her inability to endure the current situation for the six months mentioned by Donnie', 'last_speaker': 'MAGGIE'}\n",
      "Last word -> MAGGIE : \"I can't sleep for six months, Joe.\"\n",
      "prediction :  I want a divorce.\n",
      "Real answer : I can't sleep for six months, Joe.\n",
      "Bert Score : {'precision': [0.8985392451286316], 'recall': [0.8717923164367676], 'f1': [0.8849636912345886], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.11809163818525367 0.043120969391201254\n",
      "ppl : 98.69759367487708\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMAGGIE: I hope (punch) those guys you're hanging out with (punch) are laying you (punch) because I ' m (punch) not anymore! Do it.\\nDONNIE: Maggie--who told you to wear a\\nMAGGIE: What?\\nDONNIE: It's a simple question. You never wore a seat belt before/ Maggie.\\nMAGGIE: Wait a minute--is this--you think I'm having an affair? I didn't s ay that. It's interesting that you would say that, though. You're right--I ' m secretly seeing a man who wants me to 'Buckle Up for Safe ty'. We h ave t hree child ren, Joe--r emember t hem? One of us has to play it safe.\\nDONNIE: I just asked a simple question. You're the one that brought it up with the affair.\\nMAGGIE: Bulls hit. It's so fr iggi ng ironic that you'd think I ' m up to s omet hing. My n ights are homework and basketball games. What are your nights?\\nDONNIE: You know what I'm doing.\\nMAGGIE: I don't know a goddam thing.\\nDONNIE: I'm doing the job. That's the job.\\nMAGGIE: I live like a widow, Joe. That's the only way I can deal with this, with the photographs and memories and our children, and I go on with my life. Like you're already dead.\\nDONNIE: It's for your own protection.\\n\\n\", 'answer': \"It's not protecting me--it's killing me.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MAGGIE'}\n",
      "Last word -> MAGGIE : \"It's not protecting me--it's killing me.\"\n",
      "prediction :  That's right. It's for my own protection.\n",
      "Real answer : It's not protecting me--it's killing me.\n",
      "Bert Score : {'precision': [0.8763760924339294], 'recall': [0.8724144697189331], 'f1': [0.8743908405303955], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.125, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0.14285714285714285 0.048795003647426664\n",
      "ppl : 22.460720033505886\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDONNIE: When did you all of a sudden from nowhere start saying, 'Do it', Maggie?\\nMAGGIE: what? Go to sleep.\\n\\n\", 'answer': \"'Do it.' You never said that-- 'Do it'. You never talked that way before.\", 'gold_tag': \"DONNIE and MAGGIE have a shared memory where MAGGIE has never said 'Do it' before\", 'last_speaker': 'DONNIE'}\n",
      "Last word -> DONNIE : \"'Do it.' You never said that-- 'Do it'. You never talked that way before.\"\n",
      "prediction :  You're saying 'Do it' like you're a robot.\n",
      "Real answer : 'Do it.' You never said that-- 'Do it'. You never talked that way before.\n",
      "Bert Score : {'precision': [0.8885838389396667], 'recall': [0.8762174844741821], 'f1': [0.8823573589324951], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.09090909090909093, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0.05904581909262685 0.01996113009202554\n",
      "ppl : 37.38539773653157\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDONNIE: Where's Terry? She still asleep?\\nMAGGIE: I think so. What's the matter? What profile? Joe, you're scaring me.\\n\\n\", 'answer': 'The twelve warning signs. Our', 'gold_tag': 'Everyday Language', 'last_speaker': 'DONNIE'}\n",
      "Last word -> DONNIE : \"The twelve warning signs. Our\"\n",
      "prediction :  I'm sorry. I'm sorry, Maggie. I know you don't like this.\n",
      "Real answer : The twelve warning signs. Our\n",
      "Bert Score : {'precision': [0.8157023191452026], 'recall': [0.8549249768257141], 'f1': [0.8348531723022461], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 10.876534244110715\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDONNIE: Oversleeping. Short attention span. Hostility to authority. B in g e e at i n g--\\nMAGGIE: That would apply to every\\nDONNIE: Don't tell me my business. Do you know what this is?\\nMAGGIE: Where did you find that?\\nDONNIE: Maggie, I am an FBI agent. That's who I am. I am out there risking my life, 18, 20 hours a day, weekends, Christmas--\\nMAGGIE: You don't have to tell me, Joe.\\nDONNIE: Well, what do you think I ' m doing it for? I am spending my life to put away the guys that make money off this shit, and I'm damned to hell if I ' m gonna have it in my house.\\nMAGGIE: You know, Jules called me this wee k. Do you know they 're looking for you?\\nDONNIE: Don't change the subject.\\nMAGGIE: I'm not changing the subject. You're the subject, Joe. You're becoming like them.\\nDONNIE: I'm not the fucking pothead. Geddadaheah. Go weigh yourself or something. Sleeping Beauty and I are going out to the woodshed. In my next life I ' m gonna marry a Jewish doctor. In the fucking car that I make the payments on, in the fucking driveway of the house that I pay the fucking mortgage on--a goddam m ar i ju an a s e ed --\\n\\n\", 'answer': \"How do you know it isn't mine?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MAGGIE'}\n",
      "Last word -> MAGGIE : \"How do you know it isn't mine?\"\n",
      "prediction :  Don't--\n",
      "Real answer : How do you know it isn't mine?\n",
      "Bert Score : {'precision': [0.8090593814849854], 'recall': [0.8029743432998657], 'f1': [0.8060053586959839], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 628.2060594092808\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nENGLEHORN: Dead slow ahead both, Mr Hayes.\\n\\n', 'answer': 'Dead slow ahead both, Captain.', 'gold_tag': 'HAYES holds a role subordinate to ENGLEHORN , HAYES complies with orders', 'last_speaker': 'HAYES'}\n",
      "Last word -> HAYES : \"Dead slow ahead both, Captain.\"\n",
      "prediction :  I’m going to take the bridge.\n",
      "Real answer : Dead slow ahead both, Captain.\n",
      "Bert Score : {'precision': [0.8708035945892334], 'recall': [0.8480029702186584], 'f1': [0.8592520952224731], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 72.38724469255448\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHAYES: Captain ...\\nENGLEHORN: Check our position. Use the stars.\\n\\n', 'answer': 'There are no stars, Captain.', 'gold_tag': \"HAYES is a crew member , HAYES is tasked with checking the ship's position\", 'last_speaker': 'HAYES'}\n",
      "Last word -> HAYES : \"There are no stars, Captain.\"\n",
      "prediction :  You're right, Captain. I've seen it before.\n",
      "Real answer : There are no stars, Captain.\n",
      "Bert Score : {'precision': [0.8758690357208252], 'recall': [0.9004274010658264], 'f1': [0.8879784941673279], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.14285714285714285 0.048795003647426664\n",
      "ppl : 19.612842996067666\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHAYES: We're shallowing!\\nENGLEHORN: 20 degrees starboard!\\nHAYES: Captain, you don't know where the hell you're going!\\nENGLEHORN: Get me another reading!\\n\\n\", 'answer': 'Another reading!', 'gold_tag': \"HAYES's role involves taking readings and reporting them to the captain\", 'last_speaker': 'HAYES'}\n",
      "Last word -> HAYES : \"Another reading!\"\n",
      "prediction :  I can't get one! I'm at the edge of the field!\n",
      "Real answer : Another reading!\n",
      "Bert Score : {'precision': [0.8308348655700684], 'recall': [0.8289938569068909], 'f1': [0.8299133777618408], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 29.999515184301842\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nENGLEHORN: Give me some power! Half astern, both!\\n\\n', 'answer': 'Half astern, both, Captain!', 'gold_tag': 'HAYES is a crew member or subordinate to ENGLEHORN , HAYES is likely employed on the same ship as ENGLEHORN', 'last_speaker': 'HAYES'}\n",
      "Last word -> HAYES : \"Half astern, both, Captain!\"\n",
      "prediction :  Aye, sir!\n",
      "Real answer : Half astern, both, Captain!\n",
      "Bert Score : {'precision': [0.8655060529708862], 'recall': [0.8320128917694092], 'f1': [0.8484290838241577], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 200.506482258567\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nHAYES: You want me to bring them back?\\n\\n', 'answer': \"I don't give a damn about Carl Denham ... I want this ship fixed and ready to float on the next high tide. We're leaving Mr. Hayes.\", 'gold_tag': 'ENGLEHORN is an authoritative figure concerned about the maintenance and functionality of his ship , ENGLEHORN shows less regard for persons such as Carl Denham , ENGLEHORN intends to have his ship ready to float on the next high tide', 'last_speaker': 'ENGLEHORN'}\n",
      "Last word -> ENGLEHORN : \"I don't give a damn about Carl Denham ... I want this ship fixed and ready to float on the next high tide. We're leaving Mr. Hayes.\"\n",
      "prediction :  You want to go out there and get them?\n",
      "Real answer : I don't give a damn about Carl Denham ... I want this ship fixed and ready to float on the next high tide. We're leaving Mr. Hayes.\n",
      "Bert Score : {'precision': [0.839557409286499], 'recall': [0.8316938877105713], 'f1': [0.8356071710586548], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16216216216216214, 'rouge2': 0.0, 'rougeL': 0.10810810810810811, 'rougeLsum': 0.10810810810810811}\n",
      "bleu 1/2 : 0.045111761078870896 0.008735854968827747\n",
      "ppl : 38.76232495627737\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJAMIE: I should go with you.\\nABBIE: Your mom did tell me to share my life with you...\\n\\n', 'answer': \"I know. I'm sorry, she's from The Depression.\", 'gold_tag': \"JAMIE's mom wants him to learn from ABBIE's life experiences , JAMIE shows a certain level of respect for ABBIE\", 'last_speaker': 'JAMIE'}\n",
      "Last word -> JAMIE : \"I know. I'm sorry, she's from The Depression.\"\n",
      "prediction :  I know, but it's not the same.\n",
      "Real answer : I know. I'm sorry, she's from The Depression.\n",
      "Bert Score : {'precision': [0.894701361656189], 'recall': [0.8792306184768677], 'f1': [0.8868985176086426], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4444444444444445, 'rouge2': 0.125, 'rougeL': 0.4444444444444445, 'rougeLsum': 0.4444444444444445}\n",
      "bleu 1/2 : 0.12383969996431167 0.04229931028018368\n",
      "ppl : 22.406266354881627\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nABBIE: Thanks for coming with me.\\nJAMIE: Yeah.\\n\\n', 'answer': 'I made you this.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ABBIE'}\n",
      "Last word -> ABBIE : \"I made you this.\"\n",
      "prediction :  I'm so sorry, Jamie. I'm just so sorry.\n",
      "Real answer : I made you this.\n",
      "Bert Score : {'precision': [0.8358336687088013], 'recall': [0.8658128380775452], 'f1': [0.8505591750144958], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714288, 'rouge2': 0.0, 'rougeL': 0.14285714285714288, 'rougeLsum': 0.14285714285714288}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.8815972447282\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJAMIE: I understand you. We should go away, just you and me, get up the coast, be alone somewhere.\\nABBIE: Hey - Jamie. You're in love with\\n\\n\", 'answer': 'I know.', 'gold_tag': 'Jamie has feelings for Abbie', 'last_speaker': 'JAMIE'}\n",
      "Last word -> JAMIE : \"I know.\"\n",
      "prediction :  No. I'm not in love with you. I'm in love with my life.\n",
      "Real answer : I know.\n",
      "Bert Score : {'precision': [0.8573917150497437], 'recall': [0.87078857421875], 'f1': [0.8640381693840027], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.69039784822855\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPRIEST: Do you pledge to guide and protect this child if he is left fatherless? Do you promise to shield him against the wickedness of the world?\\n\\n', 'answer': 'Yes, I promise.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MICHAEL'}\n",
      "Last word -> MICHAEL : \"Yes, I promise.\"\n",
      "prediction :  I do.\n",
      "Real answer : Yes, I promise.\n",
      "Bert Score : {'precision': [0.9107730388641357], 'recall': [0.8845404982566833], 'f1': [0.8974651098251343], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4, 'rouge2': 0.0, 'rougeL': 0.4, 'rougeLsum': 0.4}\n",
      "bleu 1/2 : 0.3032653298563167 0.13562437855552414\n",
      "ppl : 911.5091418589274\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPRIEST: Do you renounce Satan.\\nMICHAEL: I do renounce him.\\nPRIEST: And all his works?\\n\\n', 'answer': 'I do renounce them.', 'gold_tag': 'Everyday Language', 'last_speaker': 'MICHAEL'}\n",
      "Last word -> MICHAEL : \"I do renounce them.\"\n",
      "prediction :  All his works.\n",
      "Real answer : I do renounce them.\n",
      "Bert Score : {'precision': [0.8944326639175415], 'recall': [0.8561687469482422], 'f1': [0.8748825192451477], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1102.702113331438\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPRIEST: Do you wish to be baptized?\\n\\n', 'answer': 'I do wish to be baptized.', 'gold_tag': 'MICHAEL wishes to be baptized', 'last_speaker': 'MICHAEL'}\n",
      "Last word -> MICHAEL : \"I do wish to be baptized.\"\n",
      "prediction :  I don't know. I'm not sure I believe in God.\n",
      "Real answer : I do wish to be baptized.\n",
      "Bert Score : {'precision': [0.8724746704101562], 'recall': [0.8996615409851074], 'f1': [0.8858595490455627], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0.10000000000000002 0.03333333333333335\n",
      "ppl : 11.130647069571992\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: What are you studying now, Mrs. Hillyer?\\nMOTHER: More history, Rose.\\nROSE: Are you going to get your degree soon?\\nMOTHER: Well, I am working on my thesis.\\nROSE: It must be wonderful to be so smart. I don't see how you do it, reading all those books, learning all that stuff.\\nMOTHER: Rose, you work too hard. Why don't you go sit down somewhere and drink a Co-Cola?\\nROSE: Mother now, not at all You're so sweet.\\nMOTHER: Really, why don't you go sit down somewhere?\\nROSE: I like to work. I don't mind work. It's the least I can do after all you and Mr. Hillyer have done for me. You're so sweet. There never was nobody like you.\\nMOTHER: Well, you run on now.\\n\\n\", 'answer': \"Yes, Ma'am.\", 'gold_tag': 'ROSE shows respect to MOTHER by referring to her formally', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"Yes, Ma'am.\"\n",
      "prediction :  Do you think I could get a degree, Mother?\n",
      "Real answer : Yes, Ma'am.\n",
      "Bert Score : {'precision': [0.8332300782203674], 'recall': [0.8599532842636108], 'f1': [0.8463807702064514], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 65.78763381755091\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOTHER: Rose, that scruffy-looking man is out in the yard again.\\nROSE: Mrs. Hillyer, I don't know who he is, I really don't.\\n\\n\", 'answer': 'I had better call Daddy.', 'gold_tag': \"MOTHER has a husband she refers to as 'Daddy'\", 'last_speaker': 'MOTHER'}\n",
      "Last word -> MOTHER : \"I had better call Daddy.\"\n",
      "prediction :  It's that fellow from the paper, Mr. Hillyer.\n",
      "Real answer : I had better call Daddy.\n",
      "Bert Score : {'precision': [0.8607953190803528], 'recall': [0.8508573174476624], 'f1': [0.8557974696159363], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 41.975167349883904\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: Never again, never again...\\nMOTHER: I know it was bad, honey. I'm sorry...\\nROSE: No more dentists, no more dentists...\\n\\n\", 'answer': \"It'll get better now.\", 'gold_tag': \"MOTHER is a reassuring figure in ROSE's life , Shared memories\", 'last_speaker': 'MOTHER'}\n",
      "Last word -> MOTHER : \"It'll get better now.\"\n",
      "prediction :  Honey, you're safe now.\n",
      "Real answer : It'll get better now.\n",
      "Bert Score : {'precision': [0.8969390988349915], 'recall': [0.8942654132843018], 'f1': [0.8956002593040466], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20000000000000004, 'rouge2': 0.0, 'rougeL': 0.20000000000000004, 'rougeLsum': 0.20000000000000004}\n",
      "bleu 1/2 : 0.25 0.09128709291752769\n",
      "ppl : 53.176007177311725\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOTHER: Rose, you're very sick. You're burning up. Rose, can you hear me? Rose?\\n\\n\", 'answer': 'What? Wha-at? Mrs. Hillyer?', 'gold_tag': 'ROSE is currently sick , ROSE is currently confused', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"What? Wha-at? Mrs. Hillyer?\"\n",
      "prediction :  *whispering* I'm so sorry, Mother. I'm so sorry.\n",
      "Real answer : What? Wha-at? Mrs. Hillyer?\n",
      "Bert Score : {'precision': [0.8137319087982178], 'recall': [0.8260253667831421], 'f1': [0.8198325634002686], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.778731391819656\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: Justice, that's what he wants, justice for everybody and especially for niggers. And I think that's real nice of him because black people don't have a very good life, you got to admit that, to be a nigger is sometimes practic'ly fatal, but the wife don't understand all of that, she thinks niggers are just so much dirt, which anybody ought to know better if they been on their ass their ownselves -- and that is the cause of his profound unhappiness, Buddy, that no-good-mean wife with all her Southern prejudice against niggers and everything!\\n\\n\", 'answer': 'The Doctor is here. And Brother, supper is ready.', 'gold_tag': \"MOTHER caters to others in the household , MOTHER announces meals and arrivals , MOTHER's announcements pertain to the immediacy of the mealtime and the arrival of the Doctor, which are immediate and transient\", 'last_speaker': 'MOTHER'}\n",
      "Last word -> MOTHER : \"The Doctor is here. And Brother, supper is ready.\"\n",
      "prediction :  Rose, don't you think you're getting a little too far ahead of yourself?\n",
      "Real answer : The Doctor is here. And Brother, supper is ready.\n",
      "Bert Score : {'precision': [0.8264327049255371], 'recall': [0.8554072380065918], 'f1': [0.8406704068183899], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.021789866433688\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: You'll never guess what happened! I have met Mr. Right! I been with him all day and he loves me, I know he does, he loves me and he's going to marry met Be's practi'cly ast me already!\\nMOTHER: Well... well, that's wonderful, Rose.\\n\\n\", 'answer': 'And who do you suppose he is? That policeman who arrested me, the one I bit! He is Mr. Right!', 'gold_tag': 'ROSE has a history of getting into trouble as she mentions being arrested , MOTHER and ROSE share a memory of an incident where ROSE bit a policeman', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"And who do you suppose he is? That policeman who arrested me, the one I bit! He is Mr. Right!\"\n",
      "prediction :  And he's got a job too! He's a... he's a... he's a...\n",
      "Real answer : And who do you suppose he is? That policeman who arrested me, the one I bit! He is Mr. Right!\n",
      "Bert Score : {'precision': [0.8270863890647888], 'recall': [0.8521100282669067], 'f1': [0.8394117951393127], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666663, 'rouge2': 0.0, 'rougeL': 0.16666666666666663, 'rougeLsum': 0.16666666666666663}\n",
      "bleu 1/2 : 0.042784759919382666 0.01413134111126129\n",
      "ppl : 8.691515472296013\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVALENTIN: Thank you, Countess...\\nSOFYA: Call me Sofya Andreyevna. We don\\'t stand on formality here, as you may have observed. Many young men ruin their looks by loose living. You\\'re a real Tolstoyan, I can tell!\\nVALENTIN: I admire your husband immensely.\\nSOFYA: That\\'s excellent. He likes that.\\nVALENTIN: His ideas are beautiful...social justice...the idea...Don\\'t you think?\\nSOFYA: He\\'s very grateful for the help you\\'ve been giving him. He told me so himself. I think it surprises him that a young man would be so diligent. When he was your age, he was whoring in the Caucasus. He wrote it all down. He even gave me a copy, so I could read all the details...\\nVALENTIN: Thank you.\\nSOFYA: You\\'ve read War and Peace?\\nVALENTIN: Many times... twice.\\nSOFYA: When he was writing it, long before Chertkov created that monstrosity at Telyatinki, before all this \"new religion\" and revolutionary nonsense... What do you think of Chertkov, by the way?\\nVALENTIN: He\\'s given me an extraordinary opportunity.\\nSOFYA: But you see what a fool he is, a self-serving puritanical idiot. I have to say, it\\'s been extremely pleasant since they\\'ve locked him in his house. When my husband was writing it, in the mid-sixties, he\\'d bring me pages to re-copy everyday. I was the only one who could read his handwriting. I could read his intentions, too. Afternoons, we\\'d drink tea and discuss changes. \"Natasha wouldn\\'t say that to Prince Andrey,\" or \"Pierre\\'s too simple here. He\\'s not stupid.\" But I don\\'t count anymore. You must help me, Valentin Fedorovich. I want only what is best for my husband and my family. I could tolerate the situation if it only concerned me What I can not do is sit back while they steal my children\\'s inheritance. Do you know I was the only person. I could understand his intention.\\nVALENTIN: I don\\'t believe anyone wants to do that.\\nSOFYA: I have a little gift for you It\\'s a diary. Everyone should always keep a diary.\\nVALENTIN: It\\'s a very popular activity around your husband.\\nSOFYA: You\\'re teasing me, but I trust you\\'ll write the truth.\\nVALENTIN: That may not be so easy.\\n\\n', 'answer': \"Nonsense. You've been listening to your friends at Telyatinki... Write what you see. That's always the place to begin. What. You. See. More tea?\", 'gold_tag': \"SOFYA is manipulative, attempting to sway VALENTIN's opinion about Chertkov , SOFYA values discussing changes over tea , SOFYA dislikes Chertkov , SOFYA is the wife of a writer whom she admires and supports\", 'last_speaker': 'SOFYA'}\n",
      "Last word -> SOFYA : \"Nonsense. You've been listening to your friends at Telyatinki... Write what you see. That's always the place to begin. What. You. See. More tea?\"\n",
      "prediction :  I'm afraid you'll have to make it easy for me. You see, I'm a bit of a mother hen. I've been married to a writer for too long.\n",
      "Real answer : Nonsense. You've been listening to your friends at Telyatinki... Write what you see. That's always the place to begin. What. You. See. More tea?\n",
      "Bert Score : {'precision': [0.8562840223312378], 'recall': [0.8381987810134888], 'f1': [0.8471449017524719], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2413793103448276, 'rouge2': 0.07142857142857142, 'rougeL': 0.1724137931034483, 'rougeLsum': 0.1724137931034483}\n",
      "bleu 1/2 : 0.10714285714285714 0.01992047682223989\n",
      "ppl : 10.509640875625943\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSOFYA: We've become close friends, I think. Tell me everything, dear boy. I love a romance.\\nVALENTIN: It's nothing, really.\\nSOFYA: A young woman in your life is nothing?\\nVALENTIN: Masha is a friend.\\nSOFYA: A lover?\\nVALENTIN: A good friend.\\nSOFYA: That sounds serious enough. I don't mean to annoy you. You forget that I'm an experienced reader. I can read your face, every letter. It's beautifully clear. Do you love her?\\nVALENTIN: Maybe I do.\\n\\n\", 'answer': \"Not something they'd understand, these so called disciples of my husband. They've never understood a word he's written. What do any of them know about love?\", 'gold_tag': \"SOFYA is in a marriage , SOFYA refers to 'my husband'\", 'last_speaker': 'SOFYA'}\n",
      "Last word -> SOFYA : \"Not something they'd understand, these so called disciples of my husband. They've never understood a word he's written. What do any of them know about love?\"\n",
      "prediction :  Then you should tell her.\n",
      "Real answer : Not something they'd understand, these so called disciples of my husband. They've never understood a word he's written. What do any of them know about love?\n",
      "Bert Score : {'precision': [0.8768262267112732], 'recall': [0.831612229347229], 'f1': [0.8536210060119629], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 124.11345156108368\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVALENTIN: Excuse me, Countess. This may not be the time, but-\\nSOFYA: Valentin... and who's this...\\nVALENTIN: Masha...this is Masha.\\nSOFYA: This is your girl. Good. Good. Is there anything I can do for you?\\nVALENTIN: No, no. Not at all. I just wanted to say good bye.\\nSOFYA: Yes...Good bye, good bye. God\\n\\n\", 'answer': 'God bless you, too.', 'gold_tag': \"VALENTIN's is saying goodbye, implying that he may not be seeing SOFYA for some time\", 'last_speaker': 'VALENTIN'}\n",
      "Last word -> VALENTIN : \"God bless you, too.\"\n",
      "prediction :  God bless you, Countess. I'll miss you.\n",
      "Real answer : God bless you, too.\n",
      "Bert Score : {'precision': [0.8941582441329956], 'recall': [0.9415684342384338], 'f1': [0.9172511100769043], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.5, 'rouge2': 0.4, 'rougeL': 0.5, 'rougeLsum': 0.5}\n",
      "bleu 1/2 : 0.42857142857142855 0.3779644730092272\n",
      "ppl : 38.68036428552133\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKEVIN: It's two weeks at most.\\nMRS. LOMAX: You've never been to New York.\\nKEVIN: Every dog gets a day.\\nMRS. LOMAX: Pick a jury... I feel the hand of Mary Ann on this adventure.\\nKEVIN: Mom.\\nMRS. LOMAX: New York is not a good idea.\\nKEVIN: Look, how you fixed for cash?\\nMRS. LOMAX: I have my bad feeling.\\nKEVIN: I put a couple hundred in here... Mary Ann typed out the numbers for you -- phone, the flights -- it's all in there.\\nMRS. LOMAX: Let me tell you about New York.\\nKEVIN: Babylon.\\nMRS. LOMAX: Forewarned is forearmed. 'Fallen, fallen is Babylon the great. It has become a dwelling place of demons.' Revelation Eighteen. Wouldn't hurt you to\\nKEVIN: Couldn't forget it if I tried.\\nMRS. LOMAX: And what happened to Babylon?\\n\\n\", 'answer': \"'Thou mighty city. In one hour\", 'gold_tag': 'Everyday Language', 'last_speaker': 'KEVIN'}\n",
      "Last word -> KEVIN : \"'Thou mighty city. In one hour\"\n",
      "prediction :  Well, the city was destroyed.\n",
      "Real answer : 'Thou mighty city. In one hour\n",
      "Bert Score : {'precision': [0.8827570676803589], 'recall': [0.8363183736801147], 'f1': [0.8589104413986206], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1818181818181818, 'rouge2': 0.0, 'rougeL': 0.1818181818181818, 'rougeLsum': 0.1818181818181818}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 124.23921760575264\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKEVIN: Mom? Ma, what are you doing?\\nMRS. LOMAX: I'm going home, Kevin.\\nKEVIN: What? What are you talking about?\\nMRS. LOMAX: I don't feel right.\\nKEVIN: You just got here. Look, I'm late and I just got my teeth kicked in on the front page, so I gotta run. We'll talk later. Ma, this is New York, there must be twenty-thousand goddamn churches. Take your pick.\\nMRS. LOMAX: You need to do a better job with Mary Ann. She's not well. This place isn't good for her.\\n\\n\", 'answer': \"So stay. Take care of her if you're so concerned! Help me out. This is home. You understand? This is where we live! I'm not going back to Gainesville. Unbelievable. It's a little early for scripture. I'm going to work. You can do whatever you want.\", 'gold_tag': 'KEVIN and MRS. LOMAX have shared memory of living in Gainesville , KEVIN mentions he is late and needs to leave for work', 'last_speaker': 'KEVIN'}\n",
      "Last word -> KEVIN : \"So stay. Take care of her if you're so concerned! Help me out. This is home. You understand? This is where we live! I'm not going back to Gainesville. Unbelievable. It's a little early for scripture. I'm going to work. You can do whatever you want.\"\n",
      "prediction :  Ma, I'm sorry. I'm gonna take care of her.\n",
      "Real answer : So stay. Take care of her if you're so concerned! Help me out. This is home. You understand? This is where we live! I'm not going back to Gainesville. Unbelievable. It's a little early for scripture. I'm going to work. You can do whatever you want.\n",
      "Bert Score : {'precision': [0.9006578922271729], 'recall': [0.8534858226776123], 'f1': [0.8764376044273376], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2622950819672131, 'rouge2': 0.1694915254237288, 'rougeL': 0.13114754098360654, 'rougeLsum': 0.13114754098360654}\n",
      "bleu 1/2 : 0.007284246128983824 0.003863054875227241\n",
      "ppl : 26.923737366698376\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMRS. LOMAX: I never should've left. I knew it. I'll never forgive myself.\\nKEVIN: I was gonna call you, I just...\\nMRS. LOMAX: What I did, Kevin, I thought it was for the best. Loving you was always first for me.\\nKEVIN: There's nothing you could've done.\\nMRS. LOMAX: I could've told you the truth.\\nKEVIN: About what?\\nMRS. LOMAX: I've lied to you, Kevin.\\nKEVIN: When?\\nMRS. LOMAX: Always. Baptist Endeavor Youth Crusade, ninety-sixty-four. I was here. In New York. That night in the elevator, you never let me answer.\\nKEVIN: What are you talking about?\\nMRS. LOMAX: We stayed a week. The Tremont Hotel, it's not there anymore, I went by and it's gone -- they had a restaurant downstairs and we ate there almost every meal --\\nKEVIN: Wait. Stop.\\nMRS. LOMAX: Your father was a waiter in that restaurant.\\nKEVIN: Oh, this is great, Ma... this is just perfect --\\nMRS. LOMAX: -- honey, listen to me --\\nKEVIN: -- Now? You do this now? -- Because, I mean, your timing -- it's superb -- you wait thirty years? -- you fly up here -- you pick today? -- -- obviously I'm not under enough my mind, I need this little -- Why are you doing this now?\\n\\n\", 'answer': \"Because I'm afraid! Kevin. Kevin! 'Behold I send you out as sheep amidst the wolves.'\", 'gold_tag': \"MRS. LOMAX's persona, MRS. LOMAX's temporal information\", 'last_speaker': 'MRS. LOMAX'}\n",
      "Last word -> MRS. LOMAX : \"Because I'm afraid! Kevin. Kevin! 'Behold I send you out as sheep amidst the wolves.'\"\n",
      "prediction :  I'm sorry, Kevin. I'm sorry.\n",
      "Real answer : Because I'm afraid! Kevin. Kevin! 'Behold I send you out as sheep amidst the wolves.'\n",
      "Bert Score : {'precision': [0.8815210461616516], 'recall': [0.8328969478607178], 'f1': [0.8565195202827454], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.34782608695652173, 'rouge2': 0.09523809523809522, 'rougeL': 0.34782608695652173, 'rougeLsum': 0.34782608695652173}\n",
      "bleu 1/2 : 0.054134113294645084 0.013533528323661273\n",
      "ppl : 28.612581966606754\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMRS. LOMAX: Kevin!\\n\\n', 'answer': 'Mary Ann. Hey. Hey! Omigod... Get somebody! Go!', 'gold_tag': 'Everyday Language', 'last_speaker': 'KEVIN'}\n",
      "Last word -> KEVIN : \"Mary Ann. Hey. Hey! Omigod... Get somebody! Go!\"\n",
      "prediction :  Mom?\n",
      "Real answer : Mary Ann. Hey. Hey! Omigod... Get somebody! Go!\n",
      "Bert Score : {'precision': [0.8626498579978943], 'recall': [0.7921121120452881], 'f1': [0.8258775472640991], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1691.1912451868666\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMRS. LOMAX: I could've packed that up for you. I wish you'da let me help you.\\nKEVIN: Finish the story. Nineteen-sixty-four. You're in New York. There's a waiter in a restaurant. Finish the story.\\nMRS. LOMAX: He talked to me. Nobody'd ever really talked to me before. Sixteen years old, a thousand miles away from home, somebody takes an interest... Working so hard, putting himself through school, I'd never met anybody like that. Knew the Bible, every word, just knew it by heart. Every meal, there he was, at my ear and I just... I didn't want that week to ever end. But it did. He came to say goodbye, it was late, and I started to cry and he said not to worry, 'Behold, I send you out as sheep amidst the wolves.' And that just stopped me cold because we'd spent that whole day at Bible study reading Matthew Ten and there was just no way for him to know about that, so I was... I took it as a sign. I let him in. And then everything was different. He was cruel. He was so cruel and I was so ashamed, I thought I'd die... I promised right there if God would let me back into His grace I would never leave again. I prayed there was a reason this terrible thing had happened. There had to be a reason. And there was. It was you. You were my blessing. You were reason enough to endure anything. How much I love you.\\nKEVIN: I want to hear you say it.\\nMRS. LOMAX: His face -- that night -- I knew it was him and the same time I was confused -- and you were so proud you'd come to New York and done all this on your own, I didn't have the heart to tell you --\\nKEVIN: Say it.\\nMRS. LOMAX: -- you wondered yourself -- the apartment, the money, all this attention, everything out of nowhere... Milton. He's your father. Somehow he found us. Tracked you down.\\nKEVIN: No. He's always been there. I know that now. Watching. Waiting. He's been playing us like a game. Jerking us around. Destroying Mary Ann...\\nMRS. LOMAX: What are you doing?\\nKEVIN: I gotta go.\\nMRS. LOMAX: No... let it alone! Stay with me. Forget about him! We can leave here. We can go home! We don't ever have to see him again!\\nKEVIN: I can't do that. You go home. Pray for Mary Ann.\\n\\n\", 'answer': 'Kevin, please... Honey! I love you!', 'gold_tag': 'MRS. LOMAX is deeply loving towards KEVIN', 'last_speaker': 'MRS. LOMAX'}\n",
      "Last word -> MRS. LOMAX : \"Kevin, please... Honey! I love you!\"\n",
      "prediction :  You don't have to do this. You don't have to.\n",
      "Real answer : Kevin, please... Honey! I love you!\n",
      "Bert Score : {'precision': [0.843919575214386], 'recall': [0.8350889682769775], 'f1': [0.8394810557365417], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 8.60212485353382\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEFF: Sprague may be the best criminal prosecutor in the country. He's only in town for a few days...\\n\\n\", 'answer': \"You don't have to sell me, son. Sell him.\", 'gold_tag': \"LAWSON is in a position of authority over JEFF , LAWSON's response was dismissive\", 'last_speaker': 'LAWSON'}\n",
      "Last word -> LAWSON : \"You don't have to sell me, son. Sell him.\"\n",
      "prediction :  How long has he been on the case?\n",
      "Real answer : You don't have to sell me, son. Sell him.\n",
      "Bert Score : {'precision': [0.8424395322799683], 'recall': [0.8449172973632812], 'f1': [0.8436766266822815], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 50.657991072164585\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEFF: What part of the infant were you looking at out there?\\n\\n', 'answer': \"Sometimes I do it better than others. Murtaugh lives in upstate New York. I got problems here. You'll have to go see him by yourself. You okay with that?\", 'gold_tag': 'LAWSON mentions having problems and suggesting solutions , LAWSON may be familiar with Murtaugh from upstate New York , LAWSON has an impending task of visiting Murtaugh in upstate New York', 'last_speaker': 'LAWSON'}\n",
      "Last word -> LAWSON : \"Sometimes I do it better than others. Murtaugh lives in upstate New York. I got problems here. You'll have to go see him by yourself. You okay with that?\"\n",
      "prediction :  The brain.\n",
      "Real answer : Sometimes I do it better than others. Murtaugh lives in upstate New York. I got problems here. You'll have to go see him by yourself. You okay with that?\n",
      "Bert Score : {'precision': [0.8811367750167847], 'recall': [0.8137218952178955], 'f1': [0.8460885882377625], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1860.172051062349\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLAWSON: ... Did he seem credible?\\nJEFF: You'll never find a better witness than Arthur Murtaugh. He has notes, a good memory, and a conscience. And he has guts.\\nLAWSON: And so do you. That's the window where James Earl Ray supposedly perched on a bathtub and shot King.\\nJEFF: Looks like a clear shot.\\nLAWSON: It's a question of tense.\\nJEFF: What?\\n\\n\", 'answer': \"It's a clear shot now. But was it a clear shot on April 4th, 1968?\", 'gold_tag': \"LAWSON is an analytical character , LAWSON has knowledge about historical events regarding James Earl Ray and Martin Luther King's assassination\", 'last_speaker': 'LAWSON'}\n",
      "Last word -> LAWSON : \"It's a clear shot now. But was it a clear shot on April 4th, 1968?\"\n",
      "prediction :  Tense. You're trying to get me to believe that the fatal shot was fired from that window.\n",
      "Real answer : It's a clear shot now. But was it a clear shot on April 4th, 1968?\n",
      "Bert Score : {'precision': [0.863080620765686], 'recall': [0.8627605438232422], 'f1': [0.8629205226898193], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.11764705882352941 0.027116307227332027\n",
      "ppl : 38.816833580971014\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEFF: God bless the Associated Press. This image was taken March 29, a week before the shooting.\\nLAWSON: Look at that tree.\\n\\n', 'answer': 'Listen to this. Press Scimitar. Kay Pitnam Black. \"On the advice of former Mayor Bill Ingram, I went to the rooming house the morning after the assassination.', 'gold_tag': 'JEFF quoted from an article', 'last_speaker': 'JEFF'}\n",
      "Last word -> JEFF : \"Listen to this. Press Scimitar. Kay Pitnam Black. \"On the advice of former Mayor Bill Ingram, I went to the rooming house the morning after the assassination.\"\n",
      "prediction :  I'm aware of it.\n",
      "Real answer : Listen to this. Press Scimitar. Kay Pitnam Black. \"On the advice of former Mayor Bill Ingram, I went to the rooming house the morning after the assassination.\n",
      "Bert Score : {'precision': [0.8800936937332153], 'recall': [0.8294695019721985], 'f1': [0.8540319800376892], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.0625, 'rougeLsum': 0.0625}\n",
      "bleu 1/2 : 0.0007956951991274167 0.00029054680630710076\n",
      "ppl : 72.48585763125766\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLAWSON: Why'd the cops let them destroy a crime scene?\\nJEFF: Did you ever hear of a reporter for the New York Times named Caldwell?\\nLAWSON: Earl Caldwell. There weren't many black reporters working for The Times back then.\\n\\n\", 'answer': '\"I was staying in Room 215...', 'gold_tag': 'Caldwell stayed at least once in Room 215', 'last_speaker': 'JEFF'}\n",
      "Last word -> JEFF : \"\"I was staying in Room 215...\"\n",
      "prediction :  That's right. He was the one who helped us. He was the one who broke the story.\n",
      "Real answer : \"I was staying in Room 215...\n",
      "Bert Score : {'precision': [0.8567008376121521], 'recall': [0.8449646830558777], 'f1': [0.8507922887802124], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08333333333333333, 'rouge2': 0.0, 'rougeL': 0.08333333333333333, 'rougeLsum': 0.08333333333333333}\n",
      "bleu 1/2 : 0.0588235294117647 0.019174124721184262\n",
      "ppl : 14.302597443857707\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEFF: Marrell McCollough, please. Mr. McCollough, My name is Jeff Jenkins. I'd like to ask you a few questions about the King assassination...\\nLAWSON: He actually answered?\\nJEFF: Yep. Your militant Invader is moving up in the world. So, if the shot didn't come from the rooming house... if the man Grace saw was just a decoy, if the gun he dropped was just a plant... why did Ray plead guilty?\\n\\n\", 'answer': \"Maybe it's time we try to talk to him.\", 'gold_tag': \"LAWSON is JEFF's partner or colleague in this investigation , Shared memories: JEFF and LAWSON both seem to be involved in the investigation of the King assassination\", 'last_speaker': 'LAWSON'}\n",
      "Last word -> LAWSON : \"Maybe it's time we try to talk to him.\"\n",
      "prediction :  To save his own skin.\n",
      "Real answer : Maybe it's time we try to talk to him.\n",
      "Bert Score : {'precision': [0.8655029535293579], 'recall': [0.8700529336929321], 'f1': [0.8677719831466675], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 209.08433236405295\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEFF: You think Ray was involved? Jim, with humor and a kind of preacher's rhythm, sets up a question and response as if for the congregation.\\nLAWSON: Let's see what he could have done. Did Ray dismantle the police protection? I need a witness.\\nJEFF: No. That was Mr. Holloman.\\nLAWSON: Say, Hallelujah. Did Ray saw down the trees? I need a witness.\\nJEFF: I can bear witness, brother. No, sir!\\nLAWSON: Say, Hallelujah.\\nJEFF: Did Ray fire the shot? I need a witness.\\nLAWSON: No way, brother. Ray was a bumbling burglar, not a marksman. If he was part of a plot, it's not likely he would have been the triggerman.\\nJEFF: But Ray would be a perfect fallguy.\\nLAWSON: Say Amen, brother.\\n\\n\", 'answer': 'Amen.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JEFF'}\n",
      "Last word -> JEFF : \"Amen.\"\n",
      "prediction :  I'm afraid Ray is the only one with an alibi.\n",
      "Real answer : Amen.\n",
      "Bert Score : {'precision': [0.8515536785125732], 'recall': [0.9351248145103455], 'f1': [0.8913847208023071], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 47.39159674496658\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLAWSON: OK, Jeff, run it down from there.\\n\\n', 'answer': 'The Reporter from the New York Times looked out and saw a white man dressed in coveralls, in the hedges beside the Rooming House.', 'gold_tag': 'JEFF has knowledge of a specific event involving a reporter and a man in coveralls , JEFF may be in a profession such as journalism or law enforcement', 'last_speaker': 'JEFF'}\n",
      "Last word -> JEFF : \"The Reporter from the New York Times looked out and saw a white man dressed in coveralls, in the hedges beside the Rooming House.\"\n",
      "prediction :  Sure thing. Now, we've got a new situation here. We've got a guy who's got a real good idea for a new product.\n",
      "Real answer : The Reporter from the New York Times looked out and saw a white man dressed in coveralls, in the hedges beside the Rooming House.\n",
      "Bert Score : {'precision': [0.8561079502105713], 'recall': [0.8347206115722656], 'f1': [0.8452789783477783], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0.041628407307320904 0.013459916719943097\n",
      "ppl : 8.745260246787561\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAM: Sorry I'm late...\\nVINCENT: What makes you think we're here to meet you?\\nSAM: Who else would you be?\\nVINCENT: Perhaps the police?\\nSAM: I know cops -- and you're no cop.\\nVINCENT: Cigarette?\\n\\n\", 'answer': 'No thanks.', 'gold_tag': 'SAM is a non-smoker', 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"No thanks.\"\n",
      "prediction :  No thanks.\n",
      "Real answer : No thanks.\n",
      "Bert Score : {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
      "bleu 1/2 : 1.0 1.0\n",
      "ppl : 970.8818891597251\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVINCENT: That was a nice move you did on our young friend. Judo?\\nSAM: Jujitsu.\\nVINCENT: Same thing, isn't it?\\nSAM: Not at all. Similar, but not the same.\\nVINCENT: What's the difference?\\n\\n\", 'answer': \"One's a lot more painful than the other.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"One's a lot more painful than the other.\"\n",
      "prediction :  Well, judo is more of a throwing art. It's about taking your opponent down and throwing them. Jujitsu is more about ground fighting. It's about taking your opponent down and then submitting them or knocking them out.\n",
      "Real answer : One's a lot more painful than the other.\n",
      "Bert Score : {'precision': [0.8249024748802185], 'recall': [0.8515815734863281], 'f1': [0.838029682636261], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.08333333333333333, 'rougeLsum': 0.08333333333333333}\n",
      "bleu 1/2 : 0.054054054054054064 0.012253577034896799\n",
      "ppl : 4.986720615641042\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVINCENT: Help yourself. Since when do you smoke?\\nSAM: I have, I don't know, maybe a cigarette a week.\\nVINCENT: A cigarette? As in one? One cigarette a week, who smokes like that?\\nSAM: I do.\\nVINCENT: Christ, I smoke a pack-and-a-half a day, and I tell myself I could be worse. It's just so damned pleasurable.\\nSAM: It has it's moments. Course, you get cancer and die, that's the down side.\\nVINCENT: There is that.\\nSAM: So, Vincent: why bring me along for the ride? Job like this calls for a warm body, somebody who can stand around and look threatening. A tough guy.\\nVINCENT: Like Larry or Swede.\\nSAM: Exactly. Why not bring them?\\nVINCENT: Let's just say I thought the conversational possibilities were limited. Of course, I might have brought Gregor, but he didn't seem like the right candidate -- for this.\\nSAM: Watch that one, he's an ex-spook for sure, maybe Stasi, maybe KGB. He's smart, Gregor is.\\nVINCENT: So is the woman.\\nSAM: Deirdre? Smart, yeah, and seriously goddamned dangerous.\\nVINCENT: I wonder if she truly left the IRA.\\nSAM: I've wondered that myself. None of this answers my question, though... Why bring me?\\nVINCENT: I wanted to see who you were.\\nSAM: Who am I?\\nVINCENT: You were once some kind of special forces. Airborne Ranger, maybe a Navy SEAL. After that you rode shotgun for the CIA in some place like El Salvador or Afghanistan, a real mercenary. Only now -- now you're like the rest of us, it's a very competitive market since the end of the cold war. There's a lot of hired guns out here, and not nearly enough work to go around.\\nSAM: That's right: there's not hardly enough work these days, nothing that pays the big money, anyhow. Then along comes this job, paying so much goddamned money I couldn't afford not to take it. Somebody's paying through the nose for this.\\nVINCENT: They certainly are. Whatever it is we're going to steal, it must be quite something.\\n\\n\", 'answer': 'Whatever it is it must be goddamned priceless. And on that thought we -', 'gold_tag': 'SAM is involved in a job where he sees a potential for a great payout', 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"Whatever it is it must be goddamned priceless. And on that thought we -\"\n",
      "prediction :  It must be.\n",
      "Real answer : Whatever it is it must be goddamned priceless. And on that thought we -\n",
      "Bert Score : {'precision': [0.903870701789856], 'recall': [0.8313321471214294], 'f1': [0.8660852313041687], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.375, 'rouge2': 0.2857142857142857, 'rougeL': 0.375, 'rougeLsum': 0.375}\n",
      "bleu 1/2 : 0.008520511068835796 0.0032999797470777002\n",
      "ppl : 342.65587562925595\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAM: You know, what you pulled back there, that was bullshit.\\nVINCENT: I needed to see if you were a cop. I'm a popular man with the police, Sam, and whenever they try to catch me they always do it with an inside guy -- some man on some job who seems more trustworthy than all the others put together. And that's the guy you have to watch out for. I hate cops...\\nSAM: Well I ain't a cop.\\nVINCENT: How did you know?\\nSAM: Know what?\\nVINCENT: That there was a gun pointed at me.\\nSAM: I saw you look off when Francois nodded his head. I figured he wasn't pointing out a particularly rare shrub, and the rest was easy.\\nVINCENT: But how did you know I would have the presence of mind to pull my weapon when I did?\\n\\n\", 'answer': \"Because that's what I would have done...\", 'gold_tag': 'SAM is adept at reading situations , SAM possesses analytical skills', 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"Because that's what I would have done...\"\n",
      "prediction :  I didn't. I was just trying to get you to talk.\n",
      "Real answer : Because that's what I would have done...\n",
      "Bert Score : {'precision': [0.8607813715934753], 'recall': [0.8212621212005615], 'f1': [0.8405574560165405], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1, 'rouge2': 0.0, 'rougeL': 0.1, 'rougeLsum': 0.1}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 14.925919281667944\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVINCENT: You're a cop...you're a fucking cop...I should kill you.\\n\\n\", 'answer': \"But you can't.\", 'gold_tag': 'SAM is able to maintain his composure even under threats', 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"But you can't.\"\n",
      "prediction :  I understand you're upset, but I assure you I'm here to help.\n",
      "Real answer : But you can't.\n",
      "Bert Score : {'precision': [0.8516771793365479], 'recall': [0.8609095215797424], 'f1': [0.8562685251235962], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.22222222222222224, 'rougeLsum': 0.22222222222222224}\n",
      "bleu 1/2 : 0.08333333333333333 0.027524094128159027\n",
      "ppl : 7.370603472570161\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVINCENT: That makes twice now you've saved my life.\\nSAM: I didn't save your life back there. Risked it, maybe -- but I didn't save shit.\\nVINCENT: You see it your way, I'll see it mine. You need a doctor.\\nSAM: You know one around here? Somebody you trust?\\nVINCENT: No...I thought I'd take you to the hospital.\\nSAM: No hospitals. I'll fix this myself if I have to.\\nVINCENT: Fix it yourself? Why are we even doing this? There's no need to run, Christ... You're a cop.\\nSAM: Not exactly.\\nVINCENT: You're with Interpol -- you're a cop.\\nSAM: If I was a cop, a real cop, I'd have busted you a long time ago. This isn't about you, it's about the job I have to do.\\nVINCENT: And what job is that?\\nSAM: My job, Vincent, a job you don't need to know about. I can't go to the local cops -- they'd never be able to get close enough at this point. It's me or nobody, and I've been on this job too goddamned long not to finish.\\nVINCENT: It looks to me like we're all that's left of our group.\\nSAM: We? There is no we in my world now, Vincent, just me.\\nVINCENT: I'm going with you.\\nSAM: This doesn't involve you, don't you understand? I can't even guarantee you any money out of all this.\\nVINCENT: It isn't about money for me, not anymore.\\nSAM: You don't have to do this.\\n\\n\", 'answer': 'Yes I do.', 'gold_tag': 'Everyday Language', 'last_speaker': 'VINCENT'}\n",
      "Last word -> VINCENT : \"Yes I do.\"\n",
      "prediction :  I have to.\n",
      "Real answer : Yes I do.\n",
      "Bert Score : {'precision': [0.8983645439147949], 'recall': [0.9196152091026306], 'f1': [0.9088656306266785], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.0, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0.3333333333333333 0.12909944487358058\n",
      "ppl : 576.0442511017619\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAM: The Irish representative?\\nVINCENT: Yes.\\nSAM: What's this?\\nVINCENT: The address of the Russian production company. Just in case we need to find them.\\n\\n\", 'answer': 'Thorough man.', 'gold_tag': \"SAM appreciates VINCENT's thoroughness\", 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"Thorough man.\"\n",
      "prediction :  I'm not sure if this is a good idea.\n",
      "Real answer : Thorough man.\n",
      "Bert Score : {'precision': [0.8439366817474365], 'recall': [0.8679728507995605], 'f1': [0.8557860255241394], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 10.238910730931181\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAM: Nice place.\\nVINCENT: I'm not here very much. Something like that.\\nSAM: I know I don't need to say this to you, but I need to say it to you. This is my job, I have to do it.\\nVINCENT: So I do it.\\nSAM: No you don't, and you know it.\\nVINCENT: If our positions were reversed, would you leave me?\\nSAM: In a minute.\\nVINCENT: I think not. (considering the weapons) Do we need anything else?\\n\\n\", 'answer': 'Yeah. We need out fucking heads examined.', 'gold_tag': 'Everyday Language', 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"Yeah. We need out fucking heads examined.\"\n",
      "prediction :  No.\n",
      "Real answer : Yeah. We need out fucking heads examined.\n",
      "Bert Score : {'precision': [0.9659888744354248], 'recall': [0.8757616281509399], 'f1': [0.9186651706695557], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1275.3241709894667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAM: Not here. They might see it.\\nVINCENT: If I'm going to die for the CIA, I'm going to go out smoking. Besides, there's half a forest between us and them, they can't see a goddamned thing.\\nSAM: Time to quit.\\nVINCENT: Just like that?\\nSAM: Not just like that... Just before I turn around and it's six months from now and the first thing I do when I wake up in the morning is light a cigarette.\\nVINCENT: What of it? Samurai pain in the ass.\\nSAM: Would you stop with that...\\nVINCENT: Why? You've got more force of will than anyone I've ever seen. You handle a gun like it's a part of you, you perform surgery on yourself without anesthesia... And most amazing of all, you quit smoking, just like that.\\nSAM: The mark of a true Samurai. What I do for the Company, Vincent, is no different than what you do. We're both hired guns, and this is a job -- like any other job.\\nVINCENT: Why then, Sam, don't you act like this is a job like any other? Surely, if you are a hired gun, you realize that some times you just have to walk away without getting what you came for.\\nSAM: Because I don't walk away.\\nVINCENT: Why not?\\nSAM: It's the one thing I've got left to hold onto. Jean-Pierre is one of your closest friends, is he not?\\nVINCENT: Closest and oldest.\\nSAM: And yet you would have killed him to save my life. You have a sense of honor, Vincent, that I can't even remember anymore. I don't know that I ever even had it to begin with. All I know to do, Vincent, is to finish my job.\\nVINCENT: And when you finish? What then? This package, whatever it is, do you give it to the CIA? Do you really think they deserve it?\\nSAM: That's a good question.\\nVINCENT: Do you have a good answer?\\n\\n\", 'answer': \"No, I don't.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"No, I don't.\"\n",
      "prediction :  I don't know.\n",
      "Real answer : No, I don't.\n",
      "Bert Score : {'precision': [0.8521019816398621], 'recall': [0.8613170385360718], 'f1': [0.8566847443580627], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.75, 'rouge2': 0.6666666666666666, 'rougeL': 0.75, 'rougeLsum': 0.75}\n",
      "bleu 1/2 : 0.3333333333333333 0.12909944487358058\n",
      "ppl : 52.19149636039691\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVINCENT: You have to stop doing that!\\n\\n', 'answer': \"I'll work on it...\", 'gold_tag': 'Everyday Language', 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"I'll work on it...\"\n",
      "prediction :  What?\n",
      "Real answer : I'll work on it...\n",
      "Bert Score : {'precision': [0.8655914068222046], 'recall': [0.8151437640190125], 'f1': [0.8396105170249939], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVINCENT: You son-of-a-bitch...\\nSAM: What?\\nVINCENT: You speak French.\\nSAM: What of it?\\nVINCENT: Nothing... \"Your field dressing saved his life.\" That\\'s three I owe you.\\nSAM: You don\\'t owe me a goddamned thing, Vincent, and you know it. You stepped in front of a bullet for me. I owe you a heavy debt.\\nVINCENT: I know.\\nSAM: You better get some sleep, alright?\\nVINCENT: Tell me something first. The package: what was it?\\nSAM: I don\\'t know. Nobody knows, except a bunch of people who are too dead to tell us. There\\'s probably a couple of guys back at the Company who know, but I don\\'t think they plan to tell me anytime soon.\\nVINCENT: What happened to it?\\nSAM: Gone. Destroyed.\\nVINCENT: I guess that\\'s for the best. Sam, when Gregor had Deirdre by the lake, you could have killed the two of them with one shot. You could have had the package, finished the job. But you didn\\'t, you sacrificed the job to save her life. Why?\\n\\n', 'answer': \"It's what you would have done.\", 'gold_tag': 'SAM places a high value on human life over completing a job', 'last_speaker': 'SAM'}\n",
      "Last word -> SAM : \"It's what you would have done.\"\n",
      "prediction :  It's my job to get people out alive. It's not my job to get them out dead.\n",
      "Real answer : It's what you would have done.\n",
      "Bert Score : {'precision': [0.8383615612983704], 'recall': [0.8571128845214844], 'f1': [0.8476335406303406], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615385, 'rouge2': 0.08333333333333333, 'rougeL': 0.15384615384615385, 'rougeLsum': 0.15384615384615385}\n",
      "bleu 1/2 : 0.0588235294117647 0.019174124721184262\n",
      "ppl : 9.184689196585653\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJAM: Ahh, sunshine.\\nMRS. BRUCE: You're going to be late if you don't hurry up and change soon.\\nJAM: Change? What's wrong with what I got on?\\nMRS. BRUCE: It's dirty laundry for one thing and for another, you still haven't worn the clothes I bought you. You're skating on thin ice already, young man, so I wouldn't push my luck. Now get out of those rags.\\nJAM: But, mom!\\nMRS. BRUCE: Someday you'll see the futility in forging a musical career with those idiots.\\nJAM: They're not idiots.\\nMRS. BRUCE: Now don't forget you're on the honor system tonight. I'll be home a little after one and if you've been partying or playing that satanic KISS music... well, need I remind you of the consequences?\\nJAM: Grounded for the rest of the year?\\n\\n\", 'answer': \"You're a smart boy, Jeremiah. And so handsome.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MRS. BRUCE'}\n",
      "Last word -> MRS. BRUCE : \"You're a smart boy, Jeremiah. And so handsome.\"\n",
      "prediction :  Try for the rest of your life. \n",
      "Real answer : You're a smart boy, Jeremiah. And so handsome.\n",
      "Bert Score : {'precision': [0.8355227112770081], 'recall': [0.866214394569397], 'f1': [0.8505917191505432], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 84.98577605666767\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMRS. BRUCE: I made an appointment with Father Phillip McNulty at St. Bernard's. We're to see him directly where he will register you on the spot.\\nJAM: You mean, you're sending me to... b- b-boarding school?\\nMRS. BRUCE: What else can I do? Oh, records and magazines and comic books are one thing, but tickets? TICKETS? Jeremiah, do you realize what this means? That you're no longer content merely hearing their awful songs or looking at photos of their horrific faces! Now you want to see the devil in the flesh. You want to reach out and touch pure evil... and in Detroit no less!\\nJAM: Mom, three of those tickets don't even belong to me. They're for the guys.\\n\\n\", 'answer': 'And if the \"guys\" have parents who truly love them, they will elevate me to sainthood for getting rid of these blasted things. It\\'s been a long time coming, son, but you\\'re finally going to get the kind of discipline you deserve.', 'gold_tag': \"MRS. BRUCE shows frustration about her son's disobedience , MRS. BRUCE has decided to send JAM to a boarding school to instill discipline\", 'last_speaker': 'MRS. BRUCE'}\n",
      "Last word -> MRS. BRUCE : \"And if the \"guys\" have parents who truly love them, they will elevate me to sainthood for getting rid of these blasted things. It's been a long time coming, son, but you're finally going to get the kind of discipline you deserve.\"\n",
      "prediction :  Oh, you're going to let them in on it?\n",
      "Real answer : And if the \"guys\" have parents who truly love them, they will elevate me to sainthood for getting rid of these blasted things. It's been a long time coming, son, but you're finally going to get the kind of discipline you deserve.\n",
      "Bert Score : {'precision': [0.8516251444816589], 'recall': [0.8302779793739319], 'f1': [0.840816080570221], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222218, 'rouge2': 0.07692307692307693, 'rougeL': 0.14814814814814814, 'rougeLsum': 0.14814814814814814}\n",
      "bleu 1/2 : 0.008520511068835796 0.005217726116595956\n",
      "ppl : 24.89870651733152\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMRS. BRUCE: Someday you'll have a son just like you, Jeremiah. A boy who lies through his teeth, buys demonic records, and smokes the dope just like you.\\nJAM: If I'm anything like you, I'll deserve him.\\nMRS. BRUCE: What?!\\nJAM: I said, I'm sorry!\\n\\n\", 'answer': \"If you truly are sorry, son, then you better pray like you've never prayed before. God willed me to find those tickets because He wanted to hear from you. He knows you need help and He wants you to ask Him for it.\", 'gold_tag': \"MRS. BRUCE is likely a devoutly religious elder woman , MRS. BRUCE referenced praying and believes in God's direct intervention in finding Jam's tickets\", 'last_speaker': 'MRS. BRUCE'}\n",
      "Last word -> MRS. BRUCE : \"If you truly are sorry, son, then you better pray like you've never prayed before. God willed me to find those tickets because He wanted to hear from you. He knows you need help and He wants you to ask Him for it.\"\n",
      "prediction :  You think you're sorry? You think you're sorry?\n",
      "Real answer : If you truly are sorry, son, then you better pray like you've never prayed before. God willed me to find those tickets because He wanted to hear from you. He knows you need help and He wants you to ask Him for it.\n",
      "Bert Score : {'precision': [0.8714394569396973], 'recall': [0.8356246948242188], 'f1': [0.8531563878059387], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18518518518518517, 'rouge2': 0.0, 'rougeL': 0.14814814814814814, 'rougeLsum': 0.14814814814814814}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13.008289464237201\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWAYNE: Victor is looking for a buckskin. What do you think of that one?\\nBRADY: Looks good. Victor doesn’t have money.\\n\\n', 'answer': 'Oh, I think he came up with some recently.', 'gold_tag': \"WAYNE has information on Victor's recent financial circumstances\", 'last_speaker': 'WAYNE'}\n",
      "Last word -> WAYNE : \"Oh, I think he came up with some recently.\"\n",
      "prediction :  We’ll have to do something about that. We need to get him some money.\n",
      "Real answer : Oh, I think he came up with some recently.\n",
      "Bert Score : {'precision': [0.8725804090499878], 'recall': [0.8688784837722778], 'f1': [0.8707254528999329], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08333333333333334, 'rouge2': 0.0, 'rougeL': 0.08333333333333334, 'rougeLsum': 0.08333333333333334}\n",
      "bleu 1/2 : 0.07142857142857141 0.023440361546924773\n",
      "ppl : 24.282042406265735\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWAYNE: What’re you doing with that saddle?\\nBRADY: I was gonna pawn it.\\nWAYNE: Pawn it? For what?\\n\\n', 'answer': 'That big bay horse at Victor’s. Apollo. I think he’s gonna turn out to be a good one.', 'gold_tag': 'BRADY is interested in horses and identifies a potential good horse, Apollo, which he wants to acquire', 'last_speaker': 'BRADY'}\n",
      "Last word -> BRADY : \"That big bay horse at Victor’s. Apollo. I think he’s gonna turn out to be a good one.\"\n",
      "prediction :  To get the money to buy a new one.\n",
      "Real answer : That big bay horse at Victor’s. Apollo. I think he’s gonna turn out to be a good one.\n",
      "Bert Score : {'precision': [0.8528560996055603], 'recall': [0.8555253744125366], 'f1': [0.8541886210441589], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20689655172413793, 'rouge2': 0.0, 'rougeL': 0.20689655172413793, 'rougeLsum': 0.20689655172413793}\n",
      "bleu 1/2 : 0.12262648039048077 0.023746515817818125\n",
      "ppl : 73.3618784989828\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBRADY: Heard about Superbars. He was a good old horse back in 60s or so. Wish he was buckskin.\\nWAYNE: Every body gets color blind in the horse world.\\nBRADY: You can’t ride the color, you can’t ride the papers.\\n\\n', 'answer': 'No.', 'gold_tag': 'Everyday Language', 'last_speaker': 'WAYNE'}\n",
      "Last word -> WAYNE : \"No.\"\n",
      "prediction :  I know. I’m just telling you, you can’t.\n",
      "Real answer : No.\n",
      "Bert Score : {'precision': [0.8265687823295593], 'recall': [0.9208494424819946], 'f1': [0.8711657524108887], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 26.76591269929712\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBEVERLY: Big weekend planned?\\nRACINE: Nope, Small weekend. Tiny little weekend.\\nBEVERLY: There's jazz tonight at the beach... if you're not doing anything...\\nRACINE: Beverly, do yourself a big favor and forget it.\\nBEVERLY: Forget what?\\n\\n\", 'answer': \"Whatever you're thinking.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'RACINE'}\n",
      "Last word -> RACINE : \"Whatever you're thinking.\"\n",
      "prediction :  Forget that I said anything.\n",
      "Real answer : Whatever you're thinking.\n",
      "Bert Score : {'precision': [0.8409414887428284], 'recall': [0.8578899502754211], 'f1': [0.8493312001228333], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 72.70026321053035\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRACINE: Will you get me Mrs. Edmund Walker, please.\\nBEVERLY: I don't have her. Should I?\\n\\n\", 'answer': 'I thought the temporary put her in. She came in while you were on vacation. Look it up. They were in Pinehaven, I think.', 'gold_tag': 'RACINE is familiar with the office processes and systems , BEVERLY recently returned from vacation , BEVERLY was on vacation and is now back at work', 'last_speaker': 'RACINE'}\n",
      "Last word -> RACINE : \"I thought the temporary put her in. She came in while you were on vacation. Look it up. They were in Pinehaven, I think.\"\n",
      "prediction :  No, no. I want to talk to Mrs. Edmund Walker.\n",
      "Real answer : I thought the temporary put her in. She came in while you were on vacation. Look it up. They were in Pinehaven, I think.\n",
      "Bert Score : {'precision': [0.8788306713104248], 'recall': [0.8613893389701843], 'f1': [0.8700225353240967], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.058823529411764705, 'rouge2': 0.0, 'rougeL': 0.058823529411764705, 'rougeLsum': 0.058823529411764705}\n",
      "bleu 1/2 : 0.024659696394160654 0.008219898798053554\n",
      "ppl : 88.16549047104911\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBEVERLY: I get no answer at the Pinehaven number.\\n\\n', 'answer': 'Okay. Try again later.', 'gold_tag': 'RACINE suggests BEVERLY to try again later', 'last_speaker': 'RACINE'}\n",
      "Last word -> RACINE : \"Okay. Try again later.\"\n",
      "prediction :  I'll check it out.\n",
      "Real answer : Okay. Try again later.\n",
      "Bert Score : {'precision': [0.8276537656784058], 'recall': [0.8439763784408569], 'f1': [0.8357353806495667], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 56.603797063026505\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBEVERLY: Is there something wrong with your phone?\\nRACINE: Just off the hook. What?\\n\\n', 'answer': \"Teddy Laursen is in County. He's very anxious to talk to you. He sounded bad. Hey, are you all right?\", 'gold_tag': \"BEVERLY is concerned about others , BEVERLY's job might be related to law or police enforcement\", 'last_speaker': 'BEVERLY'}\n",
      "Last word -> BEVERLY : \"Teddy Laursen is in County. He's very anxious to talk to you. He sounded bad. Hey, are you all right?\"\n",
      "prediction :  I said, I'm sorry.\n",
      "Real answer : Teddy Laursen is in County. He's very anxious to talk to you. He sounded bad. Hey, are you all right?\n",
      "Bert Score : {'precision': [0.8577248454093933], 'recall': [0.8321220874786377], 'f1': [0.844729483127594], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 53.71842568936414\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBASIL: Well, actually I've just broken up with her. But I want her to know she was special. I'm not a heartbreaker.\\nMIA: No, you don't look like one. I’m reading that book!\\nBASIL: What a coincidence.\\nMIA: I love ballet!\\nBASIL: “The Rake’s Progress” is in town next week.\\nMIA: I know! And it’s sold out...\\n\\n\", 'answer': 'You need to find a scalper.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BASIL'}\n",
      "Last word -> BASIL : \"You need to find a scalper.\"\n",
      "prediction :  And I have two tickets.\n",
      "Real answer : You need to find a scalper.\n",
      "Bert Score : {'precision': [0.9053171277046204], 'recall': [0.8898990750312805], 'f1': [0.897541880607605], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 181.97231513294705\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBASIL: Only if you want to. We'd bought the tickets a month ago, when we were together.\\nMIA: It's for Valentine's Day.\\nBASIL: Is that alright?\\nMIA: Yeah. But I have a friend from Italy staying with me at the moment. I can go if you can help find a date for him.\\n\\n\", 'answer': \"Sure. Shouldn't be a problem.\", 'gold_tag': \"BASIL is a problem-solver , BASIL is willing to help MIA with her situation , BASIL immediately agrees to find a date for MIA's friend\", 'last_speaker': 'BASIL'}\n",
      "Last word -> BASIL : \"Sure. Shouldn't be a problem.\"\n",
      "prediction :  I'd like to go myself.\n",
      "Real answer : Sure. Shouldn't be a problem.\n",
      "Bert Score : {'precision': [0.8808017373085022], 'recall': [0.8735001087188721], 'f1': [0.8771357536315918], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 86.88196689528964\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBASIL: Everything okay?\\nMIA: Yeah...\\nBASIL: You're a little withdrawn.\\nMIA: What are we doing?\\nBASIL: Having lunch.\\nMIA: (chooses words carefully) You're a very interesting person. And so easy to talk to. It's just... there's nothing about you... I don't have any of the feelings I usually get that distinguish a lover from a friend.\\nBASIL: Well that's as blunt as a... punch What are you looking for?\\nMIA: I don't know that either! Someone who\\nBASIL: I really don't like ballet -\\nMIA: Of course you do! And you shouldn't have to change who you are to be with someone. Me, I'm into guys who are... masculine. I'm sorry, that's a terrible thing to say.\\nBASIL: It's nothing my psychologist can't get me over.\\nMIA: You see a shrink?\\nBASIL: No, I was joking.\\nMIA: I'm sorry, I'm just a bit of a puzzle.\\nBASIL: Stop apologising. I understand. I reject good people all the time.\\nMIA: You do?\\nBASIL: Well, yeah. I work for the government\\nMIA: You're such a great person. So honest. I'd really love to be friends.\\n\\n\", 'answer': 'Of course!', 'gold_tag': 'Everyday Language', 'last_speaker': 'BASIL'}\n",
      "Last word -> BASIL : \"Of course!\"\n",
      "prediction :  Yeah.\n",
      "Real answer : Of course!\n",
      "Bert Score : {'precision': [0.9419534206390381], 'recall': [0.8207734823226929], 'f1': [0.8771981596946716], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBASIL: I never had a father. Growing up, I didn't have anyone to teach me how to... be a man. Masculine.\\nMIA: I'm so sorry.\\nBASIL: It's been tough.\\nMIA: I know. I never had a mother.\\n\\n\", 'answer': 'Really? Maybe we should introduce your Dad to my Mum?', 'gold_tag': 'Everyday Language', 'last_speaker': 'BASIL'}\n",
      "Last word -> BASIL : \"Really? Maybe we should introduce your Dad to my Mum?\"\n",
      "prediction :  I never had a father.\n",
      "Real answer : Really? Maybe we should introduce your Dad to my Mum?\n",
      "Bert Score : {'precision': [0.8668907880783081], 'recall': [0.8429481983184814], 'f1': [0.8547518253326416], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 118.51778549427581\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIA: His name's Howard. I got him when my boyfriend and I broke up. He's not really an indoors dog. But I And I hate sleeping alone.\\n\\n\", 'answer': 'You must!', 'gold_tag': 'Everyday Language', 'last_speaker': 'BASIL'}\n",
      "Last word -> BASIL : \"You must!\"\n",
      "prediction :  Oh. I see. Well, I think it's lovely that you want to keep him. He's a very cute dog.\n",
      "Real answer : You must!\n",
      "Bert Score : {'precision': [0.8373732566833496], 'recall': [0.8311340808868408], 'f1': [0.8342419862747192], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913042, 'rouge2': 0.0, 'rougeL': 0.08695652173913042, 'rougeLsum': 0.08695652173913042}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 7.15578853617164\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIA: You should grow facial hair. Maybe\\n\\n', 'answer': \"I'd get food caught in it. I am who I am. I'm sorry if you don't like that.\", 'gold_tag': 'BASIL is practical as he is concerned about getting food caught in facial hair , BASIL is comfortable with his appearance', 'last_speaker': 'BASIL'}\n",
      "Last word -> BASIL : \"I'd get food caught in it. I am who I am. I'm sorry if you don't like that.\"\n",
      "prediction :  What?\n",
      "Real answer : I'd get food caught in it. I am who I am. I'm sorry if you don't like that.\n",
      "Bert Score : {'precision': [0.8357444405555725], 'recall': [0.8020535707473755], 'f1': [0.8185524344444275], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIA: I saw her!\\nBASIL: We were just talking.\\nMIA: About what?\\n\\n', 'answer': \"I don't know. Random stuff. How backward Western Australia is without daylight saving.\", 'gold_tag': 'BASIL has opinions about the lack of daylight saving in Western Australia', 'last_speaker': 'BASIL'}\n",
      "Last word -> BASIL : \"I don't know. Random stuff. How backward Western Australia is without daylight saving.\"\n",
      "prediction :  What she was wearing.\n",
      "Real answer : I don't know. Random stuff. How backward Western Australia is without daylight saving.\n",
      "Bert Score : {'precision': [0.8626348376274109], 'recall': [0.8260319828987122], 'f1': [0.8439367413520813], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 136.28544270952793\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBASIL: Hey. What are we doing?\\nMIA: What do you mean?\\nBASIL: You're a very interesting person. But I don't have any of the feelings I usually get that distinguish a lover from a friend.\\nMIA: I didn't mean that! I was confused.\\nBASIL: I'm not. I'm sorry. But I don't like leaving things unsaid. I prefer girls who aren't so... fickle.\\nMIA: Why didn't you tell me this last night?\\n\\n\", 'answer': \"I guess I'm just a bit of a puzzle, really. enjoying quoting her. Mia's anger mounts. You’re only the second guy I’ve ever slept with! Yeah, I’ve heard that before. But... I'd really love to be friends.\", 'gold_tag': \"Basil views himself as a bit of a puzzle , Basil and Mia shared a past intimate moment since Basil was the second guy Mia has ever slept with , Mia is angry at Basil's revelation , Mia has only slept with two men, including Basil\", 'last_speaker': 'BASIL'}\n",
      "Last word -> BASIL : \"I guess I'm just a bit of a puzzle, really. enjoying quoting her. Mia's anger mounts. You’re only the second guy I’ve ever slept with! Yeah, I’ve heard that before. But... I'd really love to be friends.\"\n",
      "prediction :  I didn't want to hurt you.\n",
      "Real answer : I guess I'm just a bit of a puzzle, really. enjoying quoting her. Mia's anger mounts. You’re only the second guy I’ve ever slept with! Yeah, I’ve heard that before. But... I'd really love to be friends.\n",
      "Bert Score : {'precision': [0.8722109198570251], 'recall': [0.8237443566322327], 'f1': [0.8472850918769836], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0.0019011829993358005 0.00046569282560268016\n",
      "ppl : 24.617565098169724\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\n‘55 DOC: Ya-Haaaaaa!!!!!!\\nMARTY: Doc! YAAAAAAAA!!!!!!! Calm down, Do c! It’s me — M arty!\\n‘55 DOC: No! It can’t be you! I just sent you back to the future!\\n\\n', 'answer': 'Right! You did send me back to the future. But I came back: back from the future.', 'gold_tag': 'MARTY has travelled from the future to the past , MARTY and ‘55 DOC share the memory of ‘55 DOC sending MARTY back to the future', 'last_speaker': 'MARTY'}\n",
      "Last word -> MARTY : \"Right! You did send me back to the future. But I came back: back from the future.\"\n",
      "prediction :  I know! I know! I’m back!\n",
      "Real answer : Right! You did send me back to the future. But I came back: back from the future.\n",
      "Bert Score : {'precision': [0.8477133512496948], 'recall': [0.8628495931625366], 'f1': [0.855214536190033], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.02664662434661565 0.009230661443708028\n",
      "ppl : 44.984352487569055\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMARTY: I think you woke the dead w ith that blast.\\n\\n', 'answer': 'Just a few tombs tones, Marty. We’ll set ‘em back up later. Bring the Polaroid. We’ll need to put everything back the way we foun d it.', 'gold_tag': \"'55 DOC is quite nonchalant about the disruption, suggesting a disregard for consequences , '55 DOC plans to make adjustments to the tombstones and take Polaroid pictures later , '55 DOC carries a Polaroid, indicating technological savviness or a hobby of photography\", 'last_speaker': '‘55 DOC'}\n",
      "Last word -> ‘55 DOC : \"Just a few tombs tones, Marty. We’ll set ‘em back up later. Bring the Polaroid. We’ll need to put everything back the way we foun d it.\"\n",
      "prediction :  Don’t worry. I’ll find another way to get us back.\n",
      "Real answer : Just a few tombs tones, Marty. We’ll set ‘em back up later. Bring the Polaroid. We’ll need to put everything back the way we foun d it.\n",
      "Bert Score : {'precision': [0.895350992679596], 'recall': [0.8580852746963501], 'f1': [0.8763220906257629], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1951219512195122, 'rouge2': 0.0, 'rougeL': 0.14634146341463414, 'rougeLsum': 0.14634146341463414}\n",
      "bleu 1/2 : 0.036536704810546924 0.008611783911249627\n",
      "ppl : 24.910397864063402\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\n‘55 DOC: Funny. I’ll see you in the future, but since my future’s in the past, you won’t be seeing me. I know, D oc...\\n\\n', 'answer': 'Look, Doc, ab out the futu re — you r future, I m ean... Marty, don’t worry about my future. Living in the fresh air and wide. ope n spac es, I’ll probably live to the ripe old ag e of 90... maybe 100! And knowing I have a w oma n to share it with... W hy, my future couldn’t be brighter! Doc heads to the Packard. Yeah... Marty, m ay your future be as bright.', 'gold_tag': 'MARTY is concerned about the future', 'last_speaker': 'MARTY'}\n",
      "Last word -> MARTY : \"Look, Doc, ab out the futu re — you r future, I m ean... Marty, don’t worry about my future. Living in the fresh air and wide. ope n spac es, I’ll probably live to the ripe old ag e of 90... maybe 100! And knowing I have a w oma n to share it with... W hy, my future couldn’t be brighter! Doc heads to the Packard. Yeah... Marty, m ay your future be as bright.\"\n",
      "prediction :  You’re right. You’re right.\n",
      "Real answer : Look, Doc, ab out the futu re — you r future, I m ean... Marty, don’t worry about my future. Living in the fresh air and wide. ope n spac es, I’ll probably live to the ripe old ag e of 90... maybe 100! And knowing I have a w oma n to share it with... W hy, my future couldn’t be brighter! Doc heads to the Packard. Yeah... Marty, m ay your future be as bright.\n",
      "Bert Score : {'precision': [0.875372588634491], 'recall': [0.7642564177513123], 'f1': [0.816049337387085], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.04705882352941176, 'rouge2': 0.0, 'rougeL': 0.04705882352941176, 'rougeLsum': 0.04705882352941176}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.593099965859935\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPINZON: You lied! You cheated! We're way past 750 leagues!\\nCOLUMBUS: Six days ago, yes.\\nPINZON: You must be mad...!\\nCOLUMBUS: We have to keep the hopes of these men alive!\\nPINZON: We're on the verge of a mutiny, Colon!\\nCOLUMBUS: You think I don't know that?\\nPINZON: We're lost!\\nCOLUMBUS: The land is there. I know it!\\nPINZON: You don't know anything! Listen Colon, these are my ships, right? So I'm telling you we're turning back!\\nCOLUMBUS: And then what? Half of the water has gone, the rest is nearly putrid! You know that!\\nPINZON: Jesus Maria! I should have never listened to you!\\nCOLUMBUS: You never did. You did all the talking for both of us, remember?\\nPINZON: You bloody...\\nCOLUMBUS: Pinzon, Pinzon... All we can do now is go forward! Think about that!\\nPINZON: You tell that to them!\\n\\n\", 'answer': \"You're right. Let the men decide.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'COLUMBUS'}\n",
      "Last word -> COLUMBUS : \"You're right. Let the men decide.\"\n",
      "prediction :  I will.\n",
      "Real answer : You're right. Let the men decide.\n",
      "Bert Score : {'precision': [0.9020635485649109], 'recall': [0.8734886646270752], 'f1': [0.8875461220741272], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1002.5329194846038\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPINZON: Gold...! Gold!\\nCOLUMBUS: Give it to him!\\n\\n', 'answer': \"By God! That's the worst trade of my life!\", 'gold_tag': 'This hints at a possible greed or strong desire for wealth', 'last_speaker': 'PINZON'}\n",
      "Last word -> PINZON : \"By God! That's the worst trade of my life!\"\n",
      "prediction :  I can't give it to him.\n",
      "Real answer : By God! That's the worst trade of my life!\n",
      "Bert Score : {'precision': [0.8794859647750854], 'recall': [0.8343460559844971], 'f1': [0.8563215732574463], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 34.54611088677052\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOLUMBUS: Utapan! Wait!\\nPINZON: Well... You'll have to continue without me...\\nCOLUMBUS: No. It's enough. What would you say to a drop of Jerez, Pinzon?\\n\\n\", 'answer': \"And a nice slice of Santa Fe lamb! I'd sell my soul for it. Help me up. I've got to piss, gold.\", 'gold_tag': \"PINZON has a taste for Santa Fe lamb , PINZON's health is compromised as he needs help to stand\", 'last_speaker': 'PINZON'}\n",
      "Last word -> PINZON : \"And a nice slice of Santa Fe lamb! I'd sell my soul for it. Help me up. I've got to piss, gold.\"\n",
      "prediction :  Jerez?\n",
      "Real answer : And a nice slice of Santa Fe lamb! I'd sell my soul for it. Help me up. I've got to piss, gold.\n",
      "Bert Score : {'precision': [0.8041417598724365], 'recall': [0.8004127144813538], 'f1': [0.8022729158401489], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1084.7892282174073\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJUDY (O.C.): How do you feel?\\nJIMMY: Relaxed, happy, confident, studly, excited, relieved, delighted... I love you Judy.\\nJUDY (O.C.): You do?\\nJIMMY: Very much so. I always have.\\n\\n', 'answer': 'Me too. Do you want to pull over again?', 'gold_tag': 'JUDY O.C. is in love with Jimmy , JUDY O.C. is possibly driving as she suggests pulling over again', 'last_speaker': 'JUDY (O.C.)'}\n",
      "Last word -> JUDY (O.C.) : \"Me too. Do you want to pull over again?\"\n",
      "prediction :  You know, I have to tell you something.\n",
      "Real answer : Me too. Do you want to pull over again?\n",
      "Bert Score : {'precision': [0.8658152222633362], 'recall': [0.8620373606681824], 'f1': [0.8639221787452698], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23529411764705882, 'rouge2': 0.0, 'rougeL': 0.23529411764705882, 'rougeLsum': 0.23529411764705882}\n",
      "bleu 1/2 : 0.22062422564614886 0.05273927728090481\n",
      "ppl : 19.9806695101847\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJIMMY: Are you getting this? Come on. Are you getting this?\\nJUDY (O.C.): This is where you wanted to take me?\\nJIMMY: Yeah, what's the matter?\\n\\n\", 'answer': 'I wanna go home.', 'gold_tag': 'JUDY O.C. shows signs of discomfort , JUDY O.C. desires to leave the current situation', 'last_speaker': 'JUDY (O.C.)'}\n",
      "Last word -> JUDY (O.C.) : \"I wanna go home.\"\n",
      "prediction :  I can't see anything.\n",
      "Real answer : I wanna go home.\n",
      "Bert Score : {'precision': [0.8945721387863159], 'recall': [0.9039859175682068], 'f1': [0.8992543816566467], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.22222222222222224, 'rougeLsum': 0.22222222222222224}\n",
      "bleu 1/2 : 0.25 0.09128709291752769\n",
      "ppl : 41.61383380325762\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJIMMY: Can I get a double cheese burger, no pickles, large fries and a coke? That\\'s what I fucking missed more than anything. Fast food. And a number two.\\nJUDY (O.C.): What did you do in there all day?\\nJIMMY: Masturbated mostly.\\nJUDY (O.C.): You cheated on me! I want to be the only person responsible for making you cum.\\nJIMMY: I hope you\\'re willing to be on call twenty four hours a day.\\nJUDY (O.C.): Seriously, what did you do? What was a day in the life of Jimmy in the nut house?\\nJIMMY: Well, besides masturbating, I talked and talked and talked and fucking talked until they were satisfied. But basically I told them what they wanted to hear. I said shit like... \"Now that I\\'m finally able to talk about my problems, I now realize that my behavior was inappropriate and harmful to others.\" Then I figured it out. I had to cry as much as possible. Whenever someone would cry they\\'d call it a \"break through.\" So I\\'d be like. You start out slow, then you build it up like this... \"Now I know that using violence is not the answer.\" Then you go like this: I was wrong, I know I was wrong and I\\'ll never do it again. I don\\'t want to hurt people or myself. Boo hoo, waaaaaa, boo-hoo-hoo, waaaaaaa. Then you always give them the officially diagnose you with something, give you a prescription, then you\\'re done.\\nJUDY (O.C.): God, you\\'re a genius. So what did they say you have?\\nJIMMY: ODD. Oppositional Defiance Disorder.\\nJUDY (O.C.): You\\'re so lucky. I wish I was diagnosed with something. What does it mean?\\nJIMMY: ODD is a disorder characterized by an overwhelming pattern of negative, hostile, and defiant behavior which causes severe delusions where the patient can no longer distinguish fantasy from reality.\\nJUDY (O.C.): Wow. I love that!\\nJIMMY: You see. They fucked up my order. I specifically asked for no pickles.\\nJUDY (O.C.): Oh, no! How will ODD Boy handle this? Will his ODD brain be able to withstand a pickle screw up at the drive thru?\\n\\n', 'answer': \"Ooow, jeez, they're hot! I burnt my nipples with the pickles.\", 'gold_tag': 'JIMMY has a somewhat coarse nature', 'last_speaker': 'JIMMY'}\n",
      "Last word -> JIMMY : \"Ooow, jeez, they're hot! I burnt my nipples with the pickles.\"\n",
      "prediction :  I'll be okay. I'll just take it out on the pickle.\n",
      "Real answer : Ooow, jeez, they're hot! I burnt my nipples with the pickles.\n",
      "Bert Score : {'precision': [0.8681857585906982], 'recall': [0.8396990895271301], 'f1': [0.8537049293518066], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16, 'rouge2': 0.0, 'rougeL': 0.16, 'rougeLsum': 0.16}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 28.758426679330075\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOM: What happened to your pants?\\n\\n', 'answer': 'Mom, meet Jango.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CHUCK'}\n",
      "Last word -> CHUCK : \"Mom, meet Jango.\"\n",
      "prediction :  I was playing with my dog and he got away and I chased him and I fell down and I got my pants all dirty.\n",
      "Real answer : Mom, meet Jango.\n",
      "Bert Score : {'precision': [0.833124041557312], 'recall': [0.8642795085906982], 'f1': [0.8484158515930176], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13.07402206022171\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHUCK: Maybe I should take a few days off. Roger's working now, you could use some help around here...\\nMOM: Don't you even think about it.\\nCHUCK: The place is falling apart.\\nMOM: I'm doing fine.\\nCHUCK: Doing great, Mom, don't worry about me.\\nMOM: There's settled folks, and there's nomads. You're just not a settled folk. You never belonged here.\\n\\n\", 'answer': \"Come on inside, Mom. You've had a long day.\", 'gold_tag': 'MOM had a long day', 'last_speaker': 'CHUCK'}\n",
      "Last word -> CHUCK : \"Come on inside, Mom. You've had a long day.\"\n",
      "prediction :  What's that supposed to mean?\n",
      "Real answer : Come on inside, Mom. You've had a long day.\n",
      "Bert Score : {'precision': [0.8200156688690186], 'recall': [0.8375862836837769], 'f1': [0.8287078142166138], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 30.267159103740298\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHUCK: When'd you start working here?\\nMOM: Roger got me on. I wasn't doing anything, and -- but you're back, you're really back. I would have come to Memphis, but --\\n\\n\", 'answer': 'I wanted to come here.', 'gold_tag': 'CHUCK chose to return to his location', 'last_speaker': 'CHUCK'}\n",
      "Last word -> CHUCK : \"I wanted to come here.\"\n",
      "prediction :  No, Mom.\n",
      "Real answer : I wanted to come here.\n",
      "Bert Score : {'precision': [0.8937020897865295], 'recall': [0.8781166076660156], 'f1': [0.8858408331871033], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 221.61240395347997\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMOM: Have some more potato salad.\\nCHUCK: That was great, Mom, just great. I've got all this back pay coming. Why don't you let me get you a place in town?\\nMOM: This is my home. I'm part of the You miss it, don't you? You miss that island.\\nCHUCK: Miss that island? Mom, come on.\\nMOM: What a journey you've had. It seems more than a person should have to bear.\\nCHUCK: The tide saved me, Mom. I lived by it. I'm just wondering where it will take me next.\\n\\n\", 'answer': 'Remember the family motto. In time. It will come to you, in time.', 'gold_tag': 'MOM has a family motto about patience , Shared memories', 'last_speaker': 'MOM'}\n",
      "Last word -> MOM : \"Remember the family motto. In time. It will come to you, in time.\"\n",
      "prediction :  It's good to be home.\n",
      "Real answer : Remember the family motto. In time. It will come to you, in time.\n",
      "Bert Score : {'precision': [0.8499269485473633], 'recall': [0.8513316512107849], 'f1': [0.850628674030304], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.21052631578947367, 'rouge2': 0.0, 'rougeL': 0.21052631578947367, 'rougeLsum': 0.21052631578947367}\n",
      "bleu 1/2 : 0.04037930359893108 0.014276239697197267\n",
      "ppl : 28.10760049425209\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDAD: I don't know. Getting some fresh air, I guess.\\nTJ: It's starting to rain.\\n\\n\", 'answer': 'Yeah.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DAD'}\n",
      "Last word -> DAD : \"Yeah.\"\n",
      "prediction :  Maybe I'll get a cab.\n",
      "Real answer : Yeah.\n",
      "Bert Score : {'precision': [0.8507392406463623], 'recall': [0.9363909363746643], 'f1': [0.8915126323699951], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 56.73788394819386\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDAD: Are you OK?\\n\\n', 'answer': 'Will you just leave me alone.', 'gold_tag': 'TJ prefers solitude , TJ comes off as irritable', 'last_speaker': 'TJ'}\n",
      "Last word -> TJ : \"Will you just leave me alone.\"\n",
      "prediction :  Yeah, I'm fine. I just have a lot of stuff on my mind.\n",
      "Real answer : Will you just leave me alone.\n",
      "Bert Score : {'precision': [0.8688234090805054], 'recall': [0.857458770275116], 'f1': [0.8631037473678589], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1, 'rouge2': 0.0, 'rougeL': 0.1, 'rougeLsum': 0.1}\n",
      "bleu 1/2 : 0.07692307692307693 0.025318484177091663\n",
      "ppl : 9.424420562124679\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDAD: Where have you been?\\nTJ: Sorry.\\nDAD: Where have you been? You lost track of time? It's ten in the morning!\\nTJ: I'm sorry.\\nDAD: I've been up all night. How is that fair to me?\\nTJ: I don't know.\\n\\n\", 'answer': 'Just go to your room.', 'gold_tag': 'DAD values responsibility and accountability', 'last_speaker': 'DAD'}\n",
      "Last word -> DAD : \"Just go to your room.\"\n",
      "prediction :  I'm sorry.\n",
      "Real answer : Just go to your room.\n",
      "Bert Score : {'precision': [0.8605106472969055], 'recall': [0.8550702929496765], 'f1': [0.8577818870544434], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 70.196163546962\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDAD: Morning, Teej.\\nTJ: Hey. Look at you.\\nDAD: I know. It feels weird. I can feel air on my face.\\nTJ: I hardly recognize you.\\nDAD: I think Hesher's gone.\\nTJ: Gone where?\\n\\n\", 'answer': \"I don't know. But I think you should come take a look at this.\", 'gold_tag': 'DAD indicates a preference for facial hair', 'last_speaker': 'DAD'}\n",
      "Last word -> DAD : \"I don't know. But I think you should come take a look at this.\"\n",
      "prediction :  Gone.\n",
      "Real answer : I don't know. But I think you should come take a look at this.\n",
      "Bert Score : {'precision': [0.9229568243026733], 'recall': [0.8164337277412415], 'f1': [0.8664333820343018], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1589.7918816812582\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATALIE: Your Progressed Venus is Gemini, Which tells me that you\\'re a slow starter when it comes to romance. You know what? This is real unprofessional of me. I shouldn\\'t discuss your chart with you until I\\'m all done. I can tell by that look, you think this is all a lot of B.S.\\nBERNIE: No... I just know what the outcome\\'s going to be.\\nNATALIE: The outcome? There\\'s not, like, one particular outcome. A lot of things enter into it. The planets, moon phases...\\nBERNIE: The outcome won\\'t change with me. It\\'ll be all bad.\\nNATALIE: God, I have never met anyone who was so down on themselves. I used to be down on myself, OK? I don\\'t go there anymore. I\\'ve got just three more correspondence classes with this stuff, then I\\'ll have my certificate and everything. And you know how I got OK?\\nBERNIE: You had your chart done.\\nNATALIE: Yes, as a matter of fact that is\\nBERNIE: Do you know what I do at the Shangri- la?\\nNATALIE: I asked around. You\\'re a \"cooler.\" You turn winners into losers.\\nBERNIE: And do you know how I do that?\\nNATALIE: I know there\\'s stuff that goes on in casinos all the time --\\nBERNIE: I do it by being myself. People get next to me and their luck turns. It\\'s always been that way.\\nNATALIE: That sounds to me like a self fulfilling prophecy. There\\'s a whole chapter on that in my course. Anyways, I can see a big factor in your life is that you\\'re lacking companionship. There\\'s nobody to deflect off. If you\\'ve got, as you put it, bad karma, then you need someone with good karma to neutralize it. Well, that\\'s my take on it anyway.\\nBERNIE: I don\\'t know about you, but I\\'m real tired.\\nNATALIE: I have this recurring dream where I\\'m on some beautiful island in the Bahamas. I\\'m sitting on the beach, taking in this amazing sunset with one of these in my hand ...and then it starts to rain. And I wake up and it\\'s my roof leaking on me. Yeah, I\\'m also real tired, Bernie.\\nBERNIE: I only got six more days. Well, almost five really. Then I\\'ll be leaving town.\\nNATALIE: Only five more days? Then we shouldn\\'t waste any more time. Why don\\'t we go back to your place?\\nBERNIE: I, uh... If this is... I don\\'t know... I don\\'t know if I can afford... Oh god... I\\'m so sorry... I didn\\'t mean... You see -- that\\'s exactly what I\\'m talking about. I\\'ve gone and \"cooled\" the damn table.\\n\\n', 'answer': \"Ah, just shut up, Bernie. You haven't gone and cooled anything. Not by a long shot.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'NATALIE'}\n",
      "Last word -> NATALIE : \"Ah, just shut up, Bernie. You haven't gone and cooled anything. Not by a long shot.\"\n",
      "prediction :  Don't worry about it. It's just a table.\n",
      "Real answer : Ah, just shut up, Bernie. You haven't gone and cooled anything. Not by a long shot.\n",
      "Bert Score : {'precision': [0.88286954164505], 'recall': [0.840519368648529], 'f1': [0.8611741065979004], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.14814814814814817, 'rougeLsum': 0.14814814814814817}\n",
      "bleu 1/2 : 0.09196986029286058 0.02198500164370285\n",
      "ppl : 20.372426189865774\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATALIE: You should complain about this.\\nBERNIE: I'm not here that much. Drink? Sorry, all I got's gin.\\nNATALIE: Nah. I've had my fill. Go ahead. You know, once they're dead, they don't really grow back. In case, that's what you're waiting for. So... got any music? Sit. Relax. I promise you, at least one of us has done this before.\\nBERNIE: This is not my first --\\nNATALIE: Sssh. Surprise me. You're doing real good.\\nBERNIE: Sorry...\\n\\n\", 'answer': \"Don't worry, Bernie. I've had worse. We'll try again later.\", 'gold_tag': 'NATALIE is an assertive individual who is experienced in whatever activity they are engaging in', 'last_speaker': 'NATALIE'}\n",
      "Last word -> NATALIE : \"Don't worry, Bernie. I've had worse. We'll try again later.\"\n",
      "prediction :  You're doing real good.\n",
      "Real answer : Don't worry, Bernie. I've had worse. We'll try again later.\n",
      "Bert Score : {'precision': [0.860446572303772], 'recall': [0.8498180508613586], 'f1': [0.8550992608070374], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 85.79568122819748\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBERNIE: I did this to myself. I planted the seed. When Angela took off with Mikey, I didn't... I never made an effort to get back in his life. I figured, the kid don't need a loser for a father. Now it's all come full circle. I give him the money, I open the door to all this... I musta had it coming. Payback.\\n\\n\", 'answer': \"Bernie, it's a big world out there. If you just took off -- if we took off.\", 'gold_tag': 'NATALIE suggests the possibility of both of them leaving their current life', 'last_speaker': 'NATALIE'}\n",
      "Last word -> NATALIE : \"Bernie, it's a big world out there. If you just took off -- if we took off.\"\n",
      "prediction :  Bernie, you're not the problem here. The problem is Mikey. He's the one who's been causing all the trouble.\n",
      "Real answer : Bernie, it's a big world out there. If you just took off -- if we took off.\n",
      "Bert Score : {'precision': [0.8524150848388672], 'recall': [0.8473362922668457], 'f1': [0.84986811876297], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.10256410256410256, 'rougeLsum': 0.10256410256410256}\n",
      "bleu 1/2 : 0.05263157894736841 0.017099639201419235\n",
      "ppl : 9.987107808019443\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATALIE: You awake, Bernie? I -- think I love you. No, I don't think. I'm pretty certain of it. You blind-sided me, Bernie Lootz. I never saw this coming. You shouldn't do that to a girl. There's still things you don't know... should know... I don't want to ruin it...\\nBERNIE: It won't make any difference, Natalie. Whatever you come clean about, I'm not gonna feel any different about you. I'd say the words, but with my luck...\\nNATALIE: Say 'em anyway. To hell with rotten luck. That's overs.\\n\\n\", 'answer': 'I love you, Natalie.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BERNIE'}\n",
      "Last word -> BERNIE : \"I love you, Natalie.\"\n",
      "prediction :  Natalie, I love you.\n",
      "Real answer : I love you, Natalie.\n",
      "Bert Score : {'precision': [0.9448474645614624], 'recall': [0.9389200806617737], 'f1': [0.9418744444847107], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 1.0, 'rouge2': 0.6666666666666666, 'rougeL': 0.75, 'rougeLsum': 0.75}\n",
      "bleu 1/2 : 0.5 0.408248290463863\n",
      "ppl : 96.1078667178273\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATALIE: Bernie? You awake?\\nBERNIE: Yeah.\\nNATALIE: Let's just take off. I mean it. Let's just pack up and go. Tonight.\\nBERNIE: I can't do that. I've got an obligation to Shelly. There's no --\\nNATALIE: Fuck Shelly. He doesn't give a shit about you. Let's just climb into your car and get the hell out of here.\\nBERNIE: I can't do that, Natalie. They'd come after me. And because you were with me... I wouldn't want that on me.\\n\\n\", 'answer': 'Just hold me.', 'gold_tag': \"Natalie cares for Bernie's safety\", 'last_speaker': 'NATALIE'}\n",
      "Last word -> NATALIE : \"Just hold me.\"\n",
      "prediction :  I'm not afraid of them. I'm not afraid of anything. Let's just get out of here.\n",
      "Real answer : Just hold me.\n",
      "Bert Score : {'precision': [0.8452523946762085], 'recall': [0.8908788561820984], 'f1': [0.8674660921096802], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09090909090909091, 'rouge2': 0.0, 'rougeL': 0.09090909090909091, 'rougeLsum': 0.09090909090909091}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 9.337124156251805\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATALIE: Tell me again, Bernie. Tell me it's all gonna be okay.\\n\\n\", 'answer': \"Everything's gonna be fine. This is our time. This is you and me and we're going for it. You look in the mirror, you don't like what you see, don't believe it. You look in my eyes. That's the only mirror you gonna need. Look in my eyes, Natalie. I love you. Marry me?\", 'gold_tag': 'Bernie is supportive and encouraging  , Bernie is deeply in love with Natalie  , Bernie is deeply in love with Natalie , Bernie wishes to marry her', 'last_speaker': 'BERNIE'}\n",
      "Last word -> BERNIE : \"Everything's gonna be fine. This is our time. This is you and me and we're going for it. You look in the mirror, you don't like what you see, don't believe it. You look in my eyes. That's the only mirror you gonna need. Look in my eyes, Natalie. I love you. Marry me?\"\n",
      "prediction :  Of course, Natalie. Of course. I'll tell you everything.\n",
      "Real answer : Everything's gonna be fine. This is our time. This is you and me and we're going for it. You look in the mirror, you don't like what you see, don't believe it. You look in my eyes. That's the only mirror you gonna need. Look in my eyes, Natalie. I love you. Marry me?\n",
      "Bert Score : {'precision': [0.8799750804901123], 'recall': [0.8335340619087219], 'f1': [0.8561252951622009], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11594202898550726, 'rouge2': 0.0, 'rougeL': 0.08695652173913043, 'rougeLsum': 0.08695652173913043}\n",
      "bleu 1/2 : 0.001497321555352326 0.0003551209878434424\n",
      "ppl : 21.568563236290586\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNATALIE: You don't have to do this, Bernie.\\nBERNIE: Yeah, I do. I have to tell him right to his face. I will not look over my shoulder for the rest of my life -- our lives.\\nNATALIE: Bernie, your chart... that first night. I wasn't being straight with you. It's the worst chart I've ever seen. There's nothing in the cards for you. I'm scared...\\nBERNIE: Don't you see, that was before you opened your heart to me. Everything's different now. I got lady luck on my side. Ain't nothing gonna happen to me.\\nNATALIE: It's three thousand dollars. Take it. Maybe Shelly'll accept it as a down payment. We can send him the rest in installments... after we get settled.\\nBERNIE: I don't think --\\nNATALIE: Take it.\\nBERNIE: Whatever happens, I --\\n\\n\", 'answer': 'I know, Bernie. I know.', 'gold_tag': 'NATALIE demonstrates a caring and worried personality', 'last_speaker': 'NATALIE'}\n",
      "Last word -> NATALIE : \"I know, Bernie. I know.\"\n",
      "prediction :  Bernie.\n",
      "Real answer : I know, Bernie. I know.\n",
      "Bert Score : {'precision': [0.9162435531616211], 'recall': [0.8334394693374634], 'f1': [0.8728821873664856], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.33333333333333337, 'rouge2': 0.0, 'rougeL': 0.33333333333333337, 'rougeLsum': 0.33333333333333337}\n",
      "bleu 1/2 : 0.01831563888873418 0.00579191356895553\n",
      "ppl : 1394.6780944776724\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBERNIE: He was drunk. It was just freak luck...\\nNATALIE: Don't give it a name, Bernie. It scares me. All I know is, you're still running hot and that's a good thing. But we're only winners if we keep going. No looking back.\\n\\n\", 'answer': \"Lady luck, Natalie. I'm calling it. Lady luck. And we got it as long as we're together. They can't touch us now.\", 'gold_tag': 'BERNIE uses the analogy of gambling to explain their situation , BERNIE considers himself and NATALIE as winners when they are together , NATALIE believes in BERNIE and his winning streak', 'last_speaker': 'BERNIE'}\n",
      "Last word -> BERNIE : \"Lady luck, Natalie. I'm calling it. Lady luck. And we got it as long as we're together. They can't touch us now.\"\n",
      "prediction :  It's not just about winning. You know what I mean?\n",
      "Real answer : Lady luck, Natalie. I'm calling it. Lady luck. And we got it as long as we're together. They can't touch us now.\n",
      "Bert Score : {'precision': [0.8442357778549194], 'recall': [0.8464657068252563], 'f1': [0.8453493118286133], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.05555555555555555, 'rougeLsum': 0.05555555555555555}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.171298900590632\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nOLIVER: Holy mother.\\n\\n', 'answer': 'Here, help me with this.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ZED'}\n",
      "Last word -> ZED : \"Here, help me with this.\"\n",
      "prediction :  What is it?\n",
      "Real answer : Here, help me with this.\n",
      "Bert Score : {'precision': [0.8415339589118958], 'recall': [0.8651038408279419], 'f1': [0.8531560897827148], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 140.93475091067572\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nOLIVER: This is unbelievable. Look at all of this. It's wonderful to touch.\\n\\n\", 'answer': 'Just help me steer this out.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ZED'}\n",
      "Last word -> ZED : \"Just help me steer this out.\"\n",
      "prediction :  I know. I've never seen anything like it.\n",
      "Real answer : Just help me steer this out.\n",
      "Bert Score : {'precision': [0.8533154726028442], 'recall': [0.8555705547332764], 'f1': [0.8544415235519409], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 25.45501981469484\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nOLIVER: Do you think we should get some cash also?\\nZED: What for?\\nOLIVER: Well, you never know.\\nZED: Money is too easily traceable. You'd never be able to spend it. And forget about exchanging it.\\nOLIVER: That's true.\\nZED: No sir. Your best bet is to get these bars melted down in Tunisia or Korea.\\nOLIVER: Eric knows someone in Portugal.\\n\\n\", 'answer': 'Or Portugal.', 'gold_tag': 'ZED has experience with situations like this', 'last_speaker': 'ZED'}\n",
      "Last word -> ZED : \"Or Portugal.\"\n",
      "prediction :  Are you kidding me?\n",
      "Real answer : Or Portugal.\n",
      "Bert Score : {'precision': [0.7966087460517883], 'recall': [0.8922246098518372], 'f1': [0.8417099714279175], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.382857394752808\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nOLIVER: A what?\\nZED: You know. Something to cover this with. the bank with a platten of gold.\\nOLIVER: Oh, it won't matter. The police know what we're up too.\\nZED: Police?! What do you mean they know what we're up too?\\nOLIVER: You don't know? We've been discovered. But Eric has them under control.\\nZED: No I didn't know! How many police?\\n\\n\", 'answer': 'The building is surrounded.', 'gold_tag': 'OLIVER is involved in a criminal activity, possibly a bank robbery', 'last_speaker': 'OLIVER'}\n",
      "Last word -> OLIVER : \"The building is surrounded.\"\n",
      "prediction :  Three. They were just standing there, watching us. I couldn't do anything. I couldn't even look at them.\n",
      "Real answer : The building is surrounded.\n",
      "Bert Score : {'precision': [0.8483176827430725], 'recall': [0.8742823600769043], 'f1': [0.8611043691635132], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.82646140362313\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICHOLAS: Just a researcher with Radio 4.\\nBETH: What's her name?\\nNICHOLAS: Nadia, Nadia Patel. This hits a nerve.\\nBETH: Patel? She's in your book.\\nNICHOLAS: No, no I met her when I was on Desert Island Discs.\\nBETH: You put her in your book!\\nNICHOLAS: Just the name.\\nBETH: And Desert Island Discs was a year ago.\\nNICHOLAS: Yes but -\\nBETH: Once or twice?\\n\\n\", 'answer': 'I was going to tell you but -', 'gold_tag': \"NICHOLAS's temporal information\", 'last_speaker': 'NICHOLAS'}\n",
      "Last word -> NICHOLAS : \"I was going to tell you but -\"\n",
      "prediction :  I'm not sure.\n",
      "Real answer : I was going to tell you but -\n",
      "Bert Score : {'precision': [0.8758734464645386], 'recall': [0.8193427324295044], 'f1': [0.8466655015945435], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 48.78926453800242\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBETH: How can you lie to my face?\\nNICHOLAS: Can we talk calmly about this? There are people out there -\\nBETH: You look me in the face and LIE!\\nNICHOLAS: For God's sake; we're surrounded by\\n\\n\", 'answer': 'You BASTARD!', 'gold_tag': 'BETH is portrayed as emotional and direct', 'last_speaker': 'BETH'}\n",
      "Last word -> BETH : \"You BASTARD!\"\n",
      "prediction :  I'll get the phone.\n",
      "Real answer : You BASTARD!\n",
      "Bert Score : {'precision': [0.858496904373169], 'recall': [0.8045018315315247], 'f1': [0.8306227922439575], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 111.86692014085547\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICHOLAS: Beth, we're like a pair of compasses...\\nBETH: Don't you dare -\\nNICHOLAS: Joined solidly at the top but with the ends able to roam, in freedom -\\nBETH: That's from her isn't it? Are you keeping her waiting?\\nNICHOLAS: We've talked a lot about the creative mind and we agreed that it needs freedom to explore!\\n\\n\", 'answer': \"Take your freedom. I can't live like this any more. It makes me feel WORTHLESS!\", 'gold_tag': 'BETH feels worthless', 'last_speaker': 'BETH'}\n",
      "Last word -> BETH : \"Take your freedom. I can't live like this any more. It makes me feel WORTHLESS!\"\n",
      "prediction :  I can't believe I'm talking to you -\n",
      "Real answer : Take your freedom. I can't live like this any more. It makes me feel WORTHLESS!\n",
      "Bert Score : {'precision': [0.8414885401725769], 'recall': [0.8379431962966919], 'f1': [0.8397121429443359], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.24000000000000005, 'rouge2': 0.1739130434782609, 'rougeL': 0.24000000000000005, 'rougeLsum': 0.24000000000000005}\n",
      "bleu 1/2 : 0.1042155049196271 0.07877951679267475\n",
      "ppl : 21.1670433192432\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBETH: There's the festival brochure. You're on in the Lanson Marquee. I've marked a few bits in case you want to read.\\nNICHOLAS: You're a marvel. Cheers.\\nBETH: I could come with you.\\nNICHOLAS: Oh, don't. You hate festivals.\\nBETH: But it's only Hadditon. I'll come.\\nNICHOLAS: It's completely boring. You'll hate it. Stay here.\\nBETH: Have you got anything to tell me, Nicholas?\\n\\n\", 'answer': \"Like what? God, it's like living with the effing moral police. Are you ever going to trust me?\", 'gold_tag': \"NICHOLAS shows frustration with Beth's questioning of his honesty\", 'last_speaker': 'NICHOLAS'}\n",
      "Last word -> NICHOLAS : \"Like what? God, it's like living with the effing moral police. Are you ever going to trust me?\"\n",
      "prediction :  No.\n",
      "Real answer : Like what? God, it's like living with the effing moral police. Are you ever going to trust me?\n",
      "Bert Score : {'precision': [0.9202731251716614], 'recall': [0.8169758915901184], 'f1': [0.8655534386634827], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1275.3241709894667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICHOLAS: It's over.\\nBETH: That's Ben Sergeant's dog. Perhaps he's come to beat the shit out of you - good!\\nNICHOLAS: Beth - I finished it. She's been chasing me; this wild crush -\\nBETH: LIAR -\\nNICHOLAS: There's something desperate about her, something almost unhinged -\\nBETH: Good God, even when you try and tell the truth you lie. YOU LIE!! I want you to leave. I want a divorce. I want Stonefield.\\nNICHOLAS: Beth...Don't. You can't.\\n\\n\", 'answer': 'I will. And you - Go home! Bugger Off!!', 'gold_tag': 'BETH is resolute and assertive', 'last_speaker': 'BETH'}\n",
      "Last word -> BETH : \"I will. And you - Go home! Bugger Off!!\"\n",
      "prediction :  I CAN! I'M SICK OF YOU! I'M SICK OF YOU AND YOUR LIES!\n",
      "Real answer : I will. And you - Go home! Bugger Off!!\n",
      "Bert Score : {'precision': [0.825300931930542], 'recall': [0.8566629886627197], 'f1': [0.8406895995140076], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.26086956521739135, 'rouge2': 0.0, 'rougeL': 0.1739130434782609, 'rougeLsum': 0.1739130434782609}\n",
      "bleu 1/2 : 0.07692307692307693 0.025318484177091663\n",
      "ppl : 7.534813729149151\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLUCILLE: Can’t we visit the Tower Of London? And Saint Paul’s. And Harrods.\\nHARDY: Of course.\\nLUCILLE: And Buckingham Palace, where that darling new queen lives.\\n\\n', 'answer': 'Of course my angel, you can visit wherever you like.', 'gold_tag': \"HARDY calls Lucille 'my angel'\", 'last_speaker': 'HARDY'}\n",
      "Last word -> HARDY : \"Of course my angel, you can visit wherever you like.\"\n",
      "prediction :  Buckingham Palace is the Queen’s official residence.\n",
      "Real answer : Of course my angel, you can visit wherever you like.\n",
      "Bert Score : {'precision': [0.8426700234413147], 'recall': [0.8277155756950378], 'f1': [0.8351258635520935], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 35.02181474042004\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLUCILLE: What are you going to say to him?\\n\\n', 'answer': 'Nothing. I have nothing to say.', 'gold_tag': 'Everyday Language', 'last_speaker': 'HARDY'}\n",
      "Last word -> HARDY : \"Nothing. I have nothing to say.\"\n",
      "prediction :  I don't know. I can't think of anything.\n",
      "Real answer : Nothing. I have nothing to say.\n",
      "Bert Score : {'precision': [0.8869908452033997], 'recall': [0.9184772968292236], 'f1': [0.9024595022201538], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.12500000000000003 0.04225771273642583\n",
      "ppl : 11.200782891785941\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLUCILLE: Oliver, I would go to the ends of the earth for you, I would do anything for you, but I won’t stand by and watch Stanley put you in a wooden box and nail the lid shut. There, I’ve said it. I’m sorry, but it’s true.\\n\\n', 'answer': 'You know, you’re absolutely right. Just as soon as we’ve finished up here-', 'gold_tag': \"HARDY's agreement with Lucille's worry suggests a tendency to avoid conflict\", 'last_speaker': 'HARDY'}\n",
      "Last word -> HARDY : \"You know, you’re absolutely right. Just as soon as we’ve finished up here-\"\n",
      "prediction :  You’re right, Lucille. I’m sorry.\n",
      "Real answer : You know, you’re absolutely right. Just as soon as we’ve finished up here-\n",
      "Bert Score : {'precision': [0.896804928779602], 'recall': [0.8507915139198303], 'f1': [0.8731924891471863], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.27272727272727276, 'rouge2': 0.1, 'rougeL': 0.27272727272727276, 'rougeLsum': 0.27272727272727276}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 26.727472701660602\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMULDOON: These raptors are too damn dangerous. One of them tunneled out this morning. He ripped a boy's arm off before I could get a bullet in him.\\nHAMMOND: A bullet? Muldoon - no! Now what? I have five left?\\nMULDOON: John, they're mean as scorpions and smart as chimps. Their little fingers make them natural cage-breakers. We should terminate the raptor program. They're just too smart. Too damn smart.\\nHAMMOND: Oh balls. I will not terminate the raptors just because they're behaving normally. They're hunters. Why can't we contain them properly?\\nMULDOON: John, remember back in '88, when we started to build the containment devices? We ordered cattle prods, tasers, guns that blow out electric nets. They're all too slow for these guys. If we're going to keep the raptors, I want TOW missiles and laser-guided devices.\\nHAMMOND: It's just a zoo, Muldoon. A zoo. Figure out a way to contain them. And we'll sit down and have a nice long discussion about raptors - after my guests leave, okay?\\n\\n\", 'answer': \"Okay! Get a 'dozer, start digging round the pit. We're gonna bury some fence. And wear your rifle when you're working!\", 'gold_tag': 'MULDOON needs to improve the containment system by digging around the pit and burying some fence soon', 'last_speaker': 'MULDOON'}\n",
      "Last word -> MULDOON : \"Okay! Get a 'dozer, start digging round the pit. We're gonna bury some fence. And wear your rifle when you're working!\"\n",
      "prediction :  John, they're not guests. They're monsters.\n",
      "Real answer : Okay! Get a 'dozer, start digging round the pit. We're gonna bury some fence. And wear your rifle when you're working!\n",
      "Bert Score : {'precision': [0.8600206971168518], 'recall': [0.8229113221168518], 'f1': [0.8410568833351135], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12903225806451613, 'rouge2': 0.0, 'rougeL': 0.12903225806451613, 'rougeLsum': 0.12903225806451613}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 45.96887533371738\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMULDOON: John, the generator's shut down. Who cut the power?\\n\\n\", 'answer': \"Arnold's on it. You go out and bring back the tour right away. I don't need any of this!\", 'gold_tag': 'HAMMOND holds authority, likely in a managerial role , HAMMOND is problem-solving in this situation , HAMMOND is dealing with an immediate issue of the generator being shut down and the tour that needs to be brought back , MULDOON has an upcoming task of restoring power and returning the tour', 'last_speaker': 'HAMMOND'}\n",
      "Last word -> HAMMOND : \"Arnold's on it. You go out and bring back the tour right away. I don't need any of this!\"\n",
      "prediction :  What?\n",
      "Real answer : Arnold's on it. You go out and bring back the tour right away. I don't need any of this!\n",
      "Bert Score : {'precision': [0.8652023077011108], 'recall': [0.8031389117240906], 'f1': [0.8330162167549133], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMULDOON: We found Gennaro. He'd badly injured. Harding's tending to him in your quarters. He'll be all right if we can\\nHAMMOND: I'm sure you'll find them.\\nMULDOON: I certainly hope so.\\nHAMMOND: I'm sure we will. After all, I keep telling everyone, this park is made for children.\\nMULDOON: Just so you understand that they're missing, sir.\\n\\n\", 'answer': \"Missing? Of course I know they're missing. You just said that. Look, Bob, let's not get carried away. We've had a little breakdown from the storm or whatever, and as a result we've had a regrettable, unfortunate accident. And that's all that happened. We're dealing with it. Arnold will get the computers cleaned up, and the radio and phone lines open. You'll find those kids and my good friend, Dr. Grant. I'm sure they'll want some of this ice cream. It's very good.\", 'gold_tag': 'HAMMOND is likely the owner or a senior staff member at the park , HAMMOND expects the issues caused by the breakdown to be resolved soon  , HAMMOND likes ice cream', 'last_speaker': 'HAMMOND'}\n",
      "Last word -> HAMMOND : \"Missing? Of course I know they're missing. You just said that. Look, Bob, let's not get carried away. We've had a little breakdown from the storm or whatever, and as a result we've had a regrettable, unfortunate accident. And that's all that happened. We're dealing with it. Arnold will get the computers cleaned up, and the radio and phone lines open. You'll find those kids and my good friend, Dr. Grant. I'm sure they'll want some of this ice cream. It's very good.\"\n",
      "prediction :  Of course.\n",
      "Real answer : Missing? Of course I know they're missing. You just said that. Look, Bob, let's not get carried away. We've had a little breakdown from the storm or whatever, and as a result we've had a regrettable, unfortunate accident. And that's all that happened. We're dealing with it. Arnold will get the computers cleaned up, and the radio and phone lines open. You'll find those kids and my good friend, Dr. Grant. I'm sure they'll want some of this ice cream. It's very good.\n",
      "Bert Score : {'precision': [0.8966848850250244], 'recall': [0.804724395275116], 'f1': [0.8482193946838379], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.04210526315789474, 'rouge2': 0.02150537634408602, 'rougeL': 0.04210526315789474, 'rougeLsum': 0.04210526315789474}\n",
      "bleu 1/2 : 1.2883785545774905e-18 5.761804057576384e-19\n",
      "ppl : 372.21681075022684\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGARDENER: Will he stop that howling?\\nJACK: I don't know.\\nGARDENER: You can stop it, can't you?\\nJACK: No. I can't.\\nGARDENER: Oh cone now. Smart boy like you. You're not thinking...Tell me who you are and I'll let him out.\\n\\n\", 'answer': \"I have told you. I'm nobody. We've never met.\", 'gold_tag': 'JACK is self-effacing, denying having any significance , JACK insists that he and the GARDENER have never met before', 'last_speaker': 'JACK'}\n",
      "Last word -> JACK : \"I have told you. I'm nobody. We've never met.\"\n",
      "prediction :  You're going to kill him.\n",
      "Real answer : I have told you. I'm nobody. We've never met.\n",
      "Bert Score : {'precision': [0.8722164630889893], 'recall': [0.8725874423980713], 'f1': [0.8724019527435303], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352942, 'rouge2': 0.0, 'rougeL': 0.11764705882352942, 'rougeLsum': 0.11764705882352942}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 47.17399254315186\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGARDENER: Refreshed? You've been out for some time.\\nJACK: Where's Wolf?\\nGARDENER: He's quite taken care of. You needn't bother about him.\\nJACK: You didn't...kill him?\\n\\n\", 'answer': \"No, no...on the contrary, a young man with his strength could be a valuable soldier if he could be directed away from energies that confuse and leads him astray...Or perhaps it would be easier to eliminate the energies. You've been to the Other Side that I hear so much. That place Mr. Sloat speaks of with such admiration. No need to deny it. My loudspeakers work as receivers as well. Your bathroom assignment was a well conceived scenario. I knew you would make no attempt as long as you remained in your room on\", 'gold_tag': \"GARDENER is in control and displays a manipulative streak , GARDENER is knowledgeable about Mr. Sloat and the Other Side , JACK is familiar with an entity or location referred to as the 'Other Side' , JACK strategically used the bathroom assignment to stay safe\", 'last_speaker': 'GARDENER'}\n",
      "Last word -> GARDENER : \"No, no...on the contrary, a young man with his strength could be a valuable soldier if he could be directed away from energies that confuse and leads him astray...Or perhaps it would be easier to eliminate the energies. You've been to the Other Side that I hear so much. That place Mr. Sloat speaks of with such admiration. No need to deny it. My loudspeakers work as receivers as well. Your bathroom assignment was a well conceived scenario. I knew you would make no attempt as long as you remained in your room on\"\n",
      "prediction :  He's gone. Don't worry about him. You needn't be afraid of him.\n",
      "Real answer : No, no...on the contrary, a young man with his strength could be a valuable soldier if he could be directed away from energies that confuse and leads him astray...Or perhaps it would be easier to eliminate the energies. You've been to the Other Side that I hear so much. That place Mr. Sloat speaks of with such admiration. No need to deny it. My loudspeakers work as receivers as well. Your bathroom assignment was a well conceived scenario. I knew you would make no attempt as long as you remained in your room on\n",
      "Bert Score : {'precision': [0.877831757068634], 'recall': [0.8191831111907959], 'f1': [0.8474940061569214], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08928571428571429, 'rouge2': 0.0, 'rougeL': 0.07142857142857142, 'rougeLsum': 0.07142857142857142}\n",
      "bleu 1/2 : 0.00017954354255203674 4.193233749233404e-05\n",
      "ppl : 10.97809755864954\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGARDENER: Never mind that! Get on with it!\\nJACK: Do you have an atlas with a map of\\n\\n', 'answer': \"Oregon? It's in Oregon!\", 'gold_tag': 'Everyday Language', 'last_speaker': 'GARDENER'}\n",
      "Last word -> GARDENER : \"Oregon? It's in Oregon!\"\n",
      "prediction :  Oh, you are a fool! I thought you were\n",
      "Real answer : Oregon? It's in Oregon!\n",
      "Bert Score : {'precision': [0.8515715003013611], 'recall': [0.8616544008255005], 'f1': [0.8565833568572998], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 41.460502227367485\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACK: \"In the possession of\"... Thesaurus?\\n\\n', 'answer': 'What...OPEN THIS DOOR YOU LITTLE', 'gold_tag': 'Everyday Language', 'last_speaker': 'GARDENER'}\n",
      "Last word -> GARDENER : \"What...OPEN THIS DOOR YOU LITTLE\"\n",
      "prediction :  \"Of course\"\n",
      "Real answer : What...OPEN THIS DOOR YOU LITTLE\n",
      "Bert Score : {'precision': [0.825440526008606], 'recall': [0.7606321573257446], 'f1': [0.7917122840881348], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 320.9825060577814\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDANTE: You're late.\\nRANDAL: What the hell are you doing here? I thought you were playing hockey at one.\\nDANTE: The boss called. Arthur fell ill.\\nRANDAL: Why are the shutters closed?\\nDANTE: Someone jammed gum in the locks.\\nRANDAL: Bunch of savages in this town.\\nDANTE: That's what I said.\\nRANDAL: Shit, if I'd known you were working, I would've come even later. What time do you have to stay till?\\nDANTE: He assured me that he'd be here by\\nRANDAL: What smells like shoe polish?\\n\\n\", 'answer': 'Go open the sore.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DANTE'}\n",
      "Last word -> DANTE : \"Go open the sore.\"\n",
      "prediction :  Oh, it's you.\n",
      "Real answer : Go open the sore.\n",
      "Bert Score : {'precision': [0.8521987795829773], 'recall': [0.8658149242401123], 'f1': [0.8589528799057007], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 36.91061024170924\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRANDAL: Some guy just came in refusing to pay late fees. He said the store was closed for two hours yesterday. I tore up his membership.\\nDANTE: Shocking abuse of authority.\\nRANDAL: I'm a firm believer in the philosophy of a ruling class, especially since I rule.\\nDANTE: Don't screw with it. It makes us look suspicious.\\n\\n\", 'answer': \"I can't stand a voyeur. I'll be back.\", 'gold_tag': 'RANDAL dislikes voyeurs , RANDAL will be back after some time', 'last_speaker': 'RANDAL'}\n",
      "Last word -> RANDAL : \"I can't stand a voyeur. I'll be back.\"\n",
      "prediction :  What do you mean?\n",
      "Real answer : I can't stand a voyeur. I'll be back.\n",
      "Bert Score : {'precision': [0.802942156791687], 'recall': [0.818794846534729], 'f1': [0.810791015625], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 79.14500084705968\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRANDAL: You were saying?\\nDANTE: Thanks for putting me in a tough spot. You're a good friend.\\nRANDAL: She was pretty young, hunhh?\\nDANTE: Twenty-two; same as us.\\nRANDAL: An embolism in a pool.\\nDANTE: An embarrassing way to die.\\nRANDAL: That's nothing compared to how my cousin Walter died.\\nDANTE: How'd he die?\\nRANDAL: Broke his neck.\\nDANTE: That's embarrassing?\\nRANDAL: He broke his neck trying to suck his own dick.\\nDANTE: Shut the hell up.\\nRANDAL: Bible truth.\\nDANTE: Stop it.\\nRANDAL: I swear.\\nDANTE: Oh, my god.\\nRANDAL: Come on. Haven't you ever tried to suck your own dick?\\nDANTE: No!\\nRANDAL: Yeah sure. You're so repressed.\\nDANTE: Because I never tried to suck my own dick?\\nRANDAL: No, because you won't admit to it. As if a guy's a fucking pervert because he tries to go down on himself. You're as curious as the rest of us, pal. You've tried it.\\nDANTE: Who found him?\\nRANDAL: My cousin? My aunt found him. On his bed, doubled over himself with his legs on top. Dick in his mouth. My aunt freaked out. It was a mess.\\nDANTE: His dick was in his mouth? He made it, hunhh?\\nRANDAL: Yeah, but at what a price.\\nDANTE: I could never reach. You know.\\nRANDAL: What, your dick?\\nDANTE: Yeah. Like you said, you know. I guess everyone tries it, sooner of later.\\n\\n\", 'answer': 'I never tried it. Fucking pervert.', 'gold_tag': 'RANDAL is outgoing and has no qualms about discussing taboo or embarrassing topics', 'last_speaker': 'RANDAL'}\n",
      "Last word -> RANDAL : \"I never tried it. Fucking pervert.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : I never tried it. Fucking pervert.\n",
      "Bert Score : {'precision': [0.9329766631126404], 'recall': [0.8591707348823547], 'f1': [0.8945539593696594], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDANTE: I know it was a bad idea to close the store.\\nRANDAL: Listen to you.\\nDANTE: I can't help it. At least when we were playing hockey outside, I could see if anyone wanted to go in.\\n\\n\", 'answer': \"Nobody's there. It's four o'clock on a Saturday. How many people ever come to the store at four on a Saturday?\", 'gold_tag': \"RANDAL is Dante's coworker , DANTE's temporal information\", 'last_speaker': 'RANDAL'}\n",
      "Last word -> RANDAL : \"Nobody's there. It's four o'clock on a Saturday. How many people ever come to the store at four on a Saturday?\"\n",
      "prediction :  I'm not going to play hockey with you.\n",
      "Real answer : Nobody's there. It's four o'clock on a Saturday. How many people ever come to the store at four on a Saturday?\n",
      "Bert Score : {'precision': [0.8641566038131714], 'recall': [0.8363760709762573], 'f1': [0.8500394225120544], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06060606060606061, 'rouge2': 0.0, 'rougeL': 0.06060606060606061, 'rougeLsum': 0.06060606060606061}\n",
      "bleu 1/2 : 0.024613959400524264 0.008321037005227218\n",
      "ppl : 35.50439921982386\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nIRENE: That means you, honey. Up -- ! No reaction. Easy now, it's okay. And you have a session scheduled this afternoon --\\nMIRANDA: What do you think you're doing? I want to speak to my lawyer -- wait, what are you doing?\\nIRENE: My job.\\n\\n\", 'answer': \"C'mon, Irene, don't do this. I'm calm now, look -- I'm calm -- !\", 'gold_tag': 'MIRANDA demonstrates a level of panic or distress', 'last_speaker': 'MIRANDA'}\n",
      "Last word -> MIRANDA : \"C'mon, Irene, don't do this. I'm calm now, look -- I'm calm -- !\"\n",
      "prediction :  You're kidnapping me?\n",
      "Real answer : C'mon, Irene, don't do this. I'm calm now, look -- I'm calm -- !\n",
      "Bert Score : {'precision': [0.8444002866744995], 'recall': [0.8100564479827881], 'f1': [0.8268718719482422], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 38.73758369428068\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIRANDA: I don't -- I think I'm alright. You go in last because you're special. It's not a Mexican prison, toots. Everybody here minds their own business. If it's all the same, I'd rather --\\n\\n\", 'answer': \"State law says we keep you ladies clean. And I'm a stickler for the law. Now come on. If you go downtown, you gotta dance. The shower, like everything else in this place, is regulated by shifts, so that various groupings of That's five minutes, group one. Alright, ladies, nice and easy.\", 'gold_tag': \"IRENE is a stickler for the law , IRENE has some authority in enforcing hygiene rules , IRENE's possible job role is related to law enforcement or facility management , IRENE refers to the regulated shower shift that is about to commence, indicating that it is time for group one to take showers\", 'last_speaker': 'IRENE'}\n",
      "Last word -> IRENE : \"State law says we keep you ladies clean. And I'm a stickler for the law. Now come on. If you go downtown, you gotta dance. The shower, like everything else in this place, is regulated by shifts, so that various groupings of That's five minutes, group one. Alright, ladies, nice and easy.\"\n",
      "prediction :  I'm not going to take my eyes off you, Miranda. You don't have to go in first. I'm going to make sure you get out of here.\n",
      "Real answer : State law says we keep you ladies clean. And I'm a stickler for the law. Now come on. If you go downtown, you gotta dance. The shower, like everything else in this place, is regulated by shifts, so that various groupings of That's five minutes, group one. Alright, ladies, nice and easy.\n",
      "Bert Score : {'precision': [0.8548451662063599], 'recall': [0.8340005874633789], 'f1': [0.8442941904067993], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.19047619047619047, 'rouge2': 0.024390243902439025, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.07336378338556769 0.010572846470718555\n",
      "ppl : 11.56313585236669\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIRANDA: Shelley? Shelley, can you do me a favor?? Can you go in the shower and tell\\n\\n', 'answer': 'Enough privacy for you? What did you do? What the hell did you do to yourself?!', 'gold_tag': \"IRENE is a direct and assertive person , IRENE reacts strongly to MIRANDA's state , MIRANDA is in a situation where she's been harmed or has harmed herself , MIRANDA is a potentially troubled or distressed individual\", 'last_speaker': 'IRENE'}\n",
      "Last word -> IRENE : \"Enough privacy for you? What did you do? What the hell did you do to yourself?!\"\n",
      "prediction :  I don't know what you're talking about.\n",
      "Real answer : Enough privacy for you? What did you do? What the hell did you do to yourself?!\n",
      "Bert Score : {'precision': [0.8332974910736084], 'recall': [0.822806715965271], 'f1': [0.8280189037322998], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16, 'rouge2': 0.0, 'rougeL': 0.16, 'rougeLsum': 0.16}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 7.684915901628314\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOPPY: Hey, Easy.\\nEASY: That girl called me last night.\\nJOPPY: What girl is that? Uh, huh. That's pretty lucky, hunh?\\nEASY: No, Joppy... Wasn't no luck at all. It was you. You and Coretta was the only ones that had my phone number who knew I was lookin' for her. And Coretta was busy scammin' Daphne so she wouldn't have done it... It was you, man.\\nJOPPY: Maybe she looked in the phone book. What the hell you mean, coming up here all mad like you gonna do something?!...\\nEASY: You damn right! Coretta's dead! Your friend Albright is on my ass. The cops done brought me down once -- Why didn't you just tell Albright your damn self?\\nJOPPY: What did I tell you? To just take that man's money! I didn't tell you to do nothin'! I call myself trying to help you save your house... Don't come up in here startin' no shit with me. Easy, wait! Watch my marble! My uncle left me that when he died! Let's talk. Let's just talk. She asked me to help her 'cause I told her that Albright was lookin' for her. And I figured I could help you make a few bucks and throw Albright off the trail too. She wanted to know something about you so I told her... I guess I must've I don't know... I ain't lyin'... I don't even know her that good. She just asked me to help her. And she asked me not to tell nobody... I guess 'cause of her and Frank Green. I swear I don't know. She didn't tell me. I didn't mean to get you into nothin', Easy... I just... she just... I mean you seen her, Easy... Man, she's something else.\\n\\n\", 'answer': \"Damn, Joppy. Is there any white woman that ever gave you the time of day that you wasn't a sucker for?\", 'gold_tag': \"EASY has a critical view of JOPPY's attraction to white women , JOPPY has a weakness for white women\", 'last_speaker': 'EASY'}\n",
      "Last word -> EASY : \"Damn, Joppy. Is there any white woman that ever gave you the time of day that you wasn't a sucker for?\"\n",
      "prediction :  You must be crazy.\n",
      "Real answer : Damn, Joppy. Is there any white woman that ever gave you the time of day that you wasn't a sucker for?\n",
      "Bert Score : {'precision': [0.8391945958137512], 'recall': [0.8162857294082642], 'f1': [0.8275816440582275], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307693, 'rouge2': 0.0, 'rougeL': 0.07692307692307693, 'rougeLsum': 0.07692307692307693}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 73.78015283342353\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJOPPY: Easy, what the hell you--\\n\\n', 'answer': 'Shut up! Drive this damn thing, Mouse!', 'gold_tag': 'Everyday Language', 'last_speaker': 'EASY'}\n",
      "Last word -> EASY : \"Shut up! Drive this damn thing, Mouse!\"\n",
      "prediction :  You gotta listen to me, man. I'm tellin' ya, it's a real good idea. You gotta get the hell outta here.\n",
      "Real answer : Shut up! Drive this damn thing, Mouse!\n",
      "Bert Score : {'precision': [0.8361383676528931], 'recall': [0.8492350578308105], 'f1': [0.8426358103752136], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5.3214281895843\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEASY: Albright's got the girl. He's gonna kill her. Where would he take her? And you better get it right.\\nJOPPY: Man, I don't--\\nEASY: Don't fool with me, man!\\nJOPPY: There's a cabin out in Malibu on Route 9...\\n\\n\", 'answer': 'Make a right, Mouse!', 'gold_tag': 'Everyday Language', 'last_speaker': 'EASY'}\n",
      "Last word -> EASY : \"Make a right, Mouse!\"\n",
      "prediction :  That's where he's gonna kill her.\n",
      "Real answer : Make a right, Mouse!\n",
      "Bert Score : {'precision': [0.8444452881813049], 'recall': [0.8078203797340393], 'f1': [0.8257269263267517], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 40.72705969116076\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEASY: Is that it up there?\\n\\n', 'answer': \"Yeah, that's it.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'JOPPY'}\n",
      "Last word -> JOPPY : \"Yeah, that's it.\"\n",
      "prediction :  Yes, sir. The main observatory.\n",
      "Real answer : Yeah, that's it.\n",
      "Bert Score : {'precision': [0.8742736577987671], 'recall': [0.854712963104248], 'f1': [0.8643826246261597], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 175.08419817791173\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVIVIAN: What are you doing sitting in here eating?\\nKATE: I was hungry.\\nVIVIAN: We should be working. The rent's over due.\\nKATE: I ran into a pickup truck with four guys. Took me fifteen minutes to take care of them all. How much you make so far? Then we're coasting. We can buy some smoke and kick back till tomorrow. EXT. HOLLYWOOD BLVD. — LATER\\nVIVIAN: We shouldn't let the rent go over every month. One of these days he's going to kick us out of our place.\\nKATE: Who cares? It's a shithole. We'll find another one.\\nVIVIAN: Why don't we work a little longer? Save up for next month.\\nKATE: It's not safe to work past midnight. All the creeps come out. We'll make it up tomorrow. Let's go get high. 3. Keep going. Keep going.\\nVIVIAN: What was that?\\nKATE: Nothing to us. It's late. We'd better get in.\\n\\n\", 'answer': \"Yeah, it's getting cold out.\", 'gold_tag': \"VIVIAN's temporal information: She wants to work longer and is aware that it's getting late and cold outside.\", 'last_speaker': 'VIVIAN'}\n",
      "Last word -> VIVIAN : \"Yeah, it's getting cold out.\"\n",
      "prediction :  Are you okay?\n",
      "Real answer : Yeah, it's getting cold out.\n",
      "Bert Score : {'precision': [0.823576807975769], 'recall': [0.8287910223007202], 'f1': [0.8261756896972656], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 200.53478450245873\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKATE: Whoa, what a view!\\nVIVIAN: What are you doing here?\\nKATE: That's a warm welcome. Just came to visit my pal. Something wrong with that? You weren't kidding when you said it was a nice place.\\nVIVIAN: Kate, you'd better go. He's not going to like it if you're here.\\nKATE: Relax, I'll just say I'm a maid or something. Geez, I thought you'd be glad to see me. We're still friends aren't we, or am I just poor scum to you now?\\nVIVIAN: Of course we're friends. I just don't want him to get mad if he finds you here. Besides the Hotel people are keeping an eye on me.\\nKATE: Look at this. A stocked fridge and everything. Hey, why don't we order some food from Room Service?\\nVIVIAN: We'd better not. He might come back any time.\\nKATE: Well, he certainly didn't waste any time fixing you up to look like an expensive piece, did he? Your hair's really cute, but I don't know if you're going to attract a lot of dates when you get back on the street.\\nVIVIAN: I'll just fluff it up with some spray.\\nKATE: Yeah, like I taught you three months ago when you first got into town. You didn't know nothing back then. You wouldn't have lasted two days without me.\\nVIVIAN: Hey, I know. Why are you acting like this?\\nKATE: I don't know. Last night I started getting worried that you might not come back. That you'd take his money and skip out on me.\\nVIVIAN: I wouldn't do that.\\nKATE: Hell, I would.\\nVIVIAN: Listen… you have any smoke? It's been a couple days and I'm dieing for some.\\nKATE: Yeah, sure, I always walk around in narc land carrying. If you want a smoke let's go back to our place and get high together.\\nVIVIAN: No, I promised him I wouldn't leave.\\nKATE: Give me a break. You're not going to last a week without a smoke. Come on, we'll buy some stuff, get silly and you'll be back here before he gets home.\\nVIVIAN: No, I better not. He might call or something. I don't want to blow this. It's too much money. I can last.\\nKATE: So what's Prince Charming like?\\nVIVIAN: Nice. He's okay. I mean he doesn't hit me or anything.\\nKATE: You look great. You really do look great. I sure miss you.\\n\\n\", 'answer': 'I miss you do. Hey, you want to see what else he got me? I got some great stuff. Come on.', 'gold_tag': \"VIVIAN values her friendship with Kate but displays resistance to Kate's intrusive behavior\", 'last_speaker': 'VIVIAN'}\n",
      "Last word -> VIVIAN : \"I miss you do. Hey, you want to see what else he got me? I got some great stuff. Come on.\"\n",
      "prediction :  Thanks.\n",
      "Real answer : I miss you do. Hey, you want to see what else he got me? I got some great stuff. Come on.\n",
      "Bert Score : {'precision': [0.9204366207122803], 'recall': [0.8351883888244629], 'f1': [0.8757427930831909], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2941.412601702272\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nVIVIAN: And that one is real silk.\\nKATE: It pretty, it's all real pretty. He bought you all this stuff?\\nVIVIAN: I picked it out. But he paid for it. He said I could keep it.\\nKATE: He must like you a lot to buy you all this stuff.\\nVIVIAN: I don't know. He likes to screw me.\\nKATE: Maybe it's more than that. Maybe at the end of the week he'll want you to keep you around.\\nVIVIAN: No, he lives in New York.\\nKATE: So what? He's got bucks. He'll just put you up in some hotel room somewhere. You'd have it made. No more walking, just one steady John.\\nVIVIAN: I don't think he's going to do it. He's just… he doesn't like me that much.\\nKATE: Yeah, yeah you're right. Guy's always like to screw someone new. I'd better get out of here.\\nVIVIAN: Listen, why don't we could order some food from Room Service. What the hell?\\n\\n\", 'answer': \"Nah, I ate some fried chicken. I'm all filled up.\", 'gold_tag': 'KATE recently ate fried chicken', 'last_speaker': 'KATE'}\n",
      "Last word -> KATE : \"Nah, I ate some fried chicken. I'm all filled up.\"\n",
      "prediction :  Oh, yeah. It's good.\n",
      "Real answer : Nah, I ate some fried chicken. I'm all filled up.\n",
      "Bert Score : {'precision': [0.8901865482330322], 'recall': [0.8617949485778809], 'f1': [0.8757606744766235], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 48.93803494787402\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKATE: I still can't believe you. You didn't take the money. You didn't take any of the clothes expect the ones your wearing. You spend a week with a millionare and you end up with nothing.\\nVIVIAN: I've got my pride. It's been a long time since I've had that.\\nKATE: You're nuts. You're just nuts. You're never gonna make it on the street.\\nVIVIAN: Yeah. I think I've got to find a new line of work.\\nKATE: Yeah, we'll you'd better find a new place to live, cause I'm not going to… That's the guy. That's your guy.\\nVIVIAN: No, it isn't. It's someone else.\\nKATE: No, that's your guy. He's looking for you.\\n\\n\", 'answer': \"No, it isn't him.\", 'gold_tag': 'VIVIAN denies a man, presumably the millionaire KATE mentions, looking for her', 'last_speaker': 'VIVIAN'}\n",
      "Last word -> VIVIAN : \"No, it isn't him.\"\n",
      "prediction :  No, he's looking for me.\n",
      "Real answer : No, it isn't him.\n",
      "Bert Score : {'precision': [0.910606861114502], 'recall': [0.9184839129447937], 'f1': [0.9145283699035645], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1818181818181818, 'rouge2': 0.0, 'rougeL': 0.1818181818181818, 'rougeLsum': 0.1818181818181818}\n",
      "bleu 1/2 : 0.2 0.07071067811865477\n",
      "ppl : 90.07741609034456\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRANDOLPH: ... They kicked me out of the corporate penthouse. Big surprise. Sons-a-bitches. That's how I got this beauty. And of course, there's this... That happened after my little visit to the studio the other day. Network security. Fucking savages. I got liens, back taxes, lawyer's bills, threats against my life... I basically got the whole fucking world up my ass. It's okay, I got a loooong memory, son. What dey sow, dey gonna reap.\\nANGELO: Stop doing this to yourself! Wise up! You hear me? Don't piss your life away like this.\\n\\n\", 'answer': \"It's the rhino, Angie. He's been sent by the devil. Sent from hell to destroy me. Smoochy... is the face of evil.\", 'gold_tag': 'RANDOLPH blames his problems on Smoochy, a character he perceives as sent by the devil', 'last_speaker': 'RANDOLPH'}\n",
      "Last word -> RANDOLPH : \"It's the rhino, Angie. He's been sent by the devil. Sent from hell to destroy me. Smoochy... is the face of evil.\"\n",
      "prediction :  ... I ain't pissin' away my life, Angelo. I'm just gettin' it back.\n",
      "Real answer : It's the rhino, Angie. He's been sent by the devil. Sent from hell to destroy me. Smoochy... is the face of evil.\n",
      "Bert Score : {'precision': [0.8387203216552734], 'recall': [0.8490551710128784], 'f1': [0.8438560962677002], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.052631578947368425, 'rouge2': 0.0, 'rougeL': 0.052631578947368425, 'rougeLsum': 0.052631578947368425}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 19.22176524328422\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nANGELO: It's heatin' up out there. Every cop in New York is looking for you. And Tommy Cotter's boys are combin' the streets. You're gonna have to stay put for a while.\\nRANDOLPH: I was an altar boy once. Did you know that? I wanted to be a priest. Do you believe in angels, Angie?\\nANGELO: Angels?\\nRANDOLPH: There was a little angel in pigtails. She was the only one who cared about me. She saved my life.\\nANGELO: You didn't want to kill yourself, Randy. You know that.\\nRANDOLPH: Perhaps it's time to heal. To accept the fact that Smoochy has won and gracefully march forward. True, I'm currently wanted for a murder I didn't commit. But I have faith. Faith that justice will prevail.\\nANGELO: Now you're talkin', kid. This is a big step... I'm proud of you.\\nRANDOLPH: Did you bring lunch?\\nANGELO: Yes.\\nRANDOLPH: Chicken and stars?\\nANGELO: Just like you asked for.\\nRANDOLPH: Can I have some, please?\\nANGELO: For a smile. Atta boy. Here, I got you some crossword puzzles and stuff to read. You okay? Randy?\\n\\n\", 'answer': 'Motherfucker!!!!!!!', 'gold_tag': 'Everyday Language', 'last_speaker': 'RANDOLPH'}\n",
      "Last word -> RANDOLPH : \"Motherfucker!!!!!!!\"\n",
      "prediction :  (SMILES)\n",
      "Real answer : Motherfucker!!!!!!!\n",
      "Bert Score : {'precision': [0.8267492055892944], 'recall': [0.7314496040344238], 'f1': [0.7761850953102112], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 208.96393043622427\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRANDOLPH: Hellooo!\\nANGELO: Randy, is that you?\\nRANDOLPH: Yes, Angelo, my little Twinkie, shouldn't you be getting ready for the big show?\\nANGELO: Listen, Buggy's been here.\\nRANDOLPH: Buggy Double D's? The Dong Man?\\nANGELO: Yeah, he lifted my backstage pass and he's braggin' that he's doing some kind of job for Burke Bennett.\\nRANDOLPH: Sheldon's in trouble. I gotta get down to the Garden.\\nANGELO: The place is crawling with cops. trampoline.\\n\\n\", 'answer': \"I don't care. I have to warn the rhino.\", 'gold_tag': 'RANDOLPH takes immediate action in response to perceived danger', 'last_speaker': 'RANDOLPH'}\n",
      "Last word -> RANDOLPH : \"I don't care. I have to warn the rhino.\"\n",
      "prediction :  Trampoline?\n",
      "Real answer : I don't care. I have to warn the rhino.\n",
      "Bert Score : {'precision': [0.8023738265037537], 'recall': [0.8346650004386902], 'f1': [0.818200945854187], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 596.9957987757895\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBETTY: Well... what do you think about then? I mean... well what do you think about?\\nRITA: What do you mean?\\nBETTY: Well ... if you don't remember anything, I mean what goes through your mind then if you don't remember anything?\\nRITA: Nothing. I do remember the car crash... I told you... I remember the glass ... I think about that sometimes ... I remember walking here, sort of. Now I remember this place and you. That's about it.\\nBETTY: How do you remember how to talk?\\nRITA: I don't know.\\nBETTY: You don't remember anything else?\\nRITA: No There is something...something there I can't tell... I can't describe it. There are things there.... but I'm... here.\\nBETTY: The money. You don't know where it came from?\\nRITA: Unh, unh.\\nBETTY: When you think about them... the money... the key ... does it make you remember anything?\\n\\n\", 'answer': \"The money... I don't know about the money... the key... it makes me feel ... afraid.\", 'gold_tag': 'RITA is capable of feeling fear', 'last_speaker': 'RITA'}\n",
      "Last word -> RITA : \"The money... I don't know about the money... the key... it makes me feel ... afraid.\"\n",
      "prediction :  Unh... unh.\n",
      "Real answer : The money... I don't know about the money... the key... it makes me feel ... afraid.\n",
      "Bert Score : {'precision': [0.829767107963562], 'recall': [0.8301941752433777], 'f1': [0.8299806118011475], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2052.0078656769774\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBETTY: What's wrong with that?\\nRITA: I'm not sure about this.\\n\\n\", 'answer': \"I know you're afraid of something. We'll be careful. Tomorrow we'll go over there and we'll find out.\", 'gold_tag': 'RITA feels fear , BETTY intends to take action to discover something with RITA tomorrow', 'last_speaker': 'BETTY'}\n",
      "Last word -> BETTY : \"I know you're afraid of something. We'll be careful. Tomorrow we'll go over there and we'll find out.\"\n",
      "prediction :  What are you talking about?\n",
      "Real answer : I know you're afraid of something. We'll be careful. Tomorrow we'll go over there and we'll find out.\n",
      "Bert Score : {'precision': [0.8268005847930908], 'recall': [0.8224989175796509], 'f1': [0.8246440887451172], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07407407407407407, 'rouge2': 0.0, 'rougeL': 0.07407407407407407, 'rougeLsum': 0.07407407407407407}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 58.2916451132753\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBETTY: Why didn't you ask him? Sol knows you!\\nRITA: But I don't know, Sol. I never heard of Sol. I'd just get in trouble. That's why we shouldn't go see about Diane Selwyn... it's better not to get in trouble.\\n\\n\", 'answer': \"You're not going to get in trouble. You're going to find out who you are. Finding out who you are gets you out of trouble.\", 'gold_tag': 'BETTY is assertive, encouraging, and resourceful , BETTY is dedicated to helping RITA discover her identity', 'last_speaker': 'BETTY'}\n",
      "Last word -> BETTY : \"You're not going to get in trouble. You're going to find out who you are. Finding out who you are gets you out of trouble.\"\n",
      "prediction :  Sol knows you. You can trust him. He'll help you.\n",
      "Real answer : You're not going to get in trouble. You're going to find out who you are. Finding out who you are gets you out of trouble.\n",
      "Bert Score : {'precision': [0.8940945863723755], 'recall': [0.8646931648254395], 'f1': [0.8791481256484985], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15789473684210525, 'rouge2': 0.0, 'rougeL': 0.15789473684210525, 'rougeLsum': 0.15789473684210525}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 38.8530639408781\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBETTY: What are you doing?\\nRITA: You've been so good to me ... now we know why ... why I was so afraid. We know what kind of trouble I'm in. I shouldn't... ask you... I only have this to offer. I'll give you this if I can stay here for awhile. I don't know what else to do.\\nBETTY: Rita... I want you to stay here and you don't have to give me that money.\\nRITA: But I want to.\\nBETTY: No. We shouldn't touch that money. We don't know about that money. That might be dangerous money. You have to start all over again. You look like a brand new person and you can be a brand new person... whoever you want to be.\\nRITA: It sounds kind of nice ... being somebody\\n\\n\", 'answer': \"Hey, let's introduce the brand new you to Hollywood. We haven't seen the roof garden yet.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'BETTY'}\n",
      "Last word -> BETTY : \"Hey, let's introduce the brand new you to Hollywood. We haven't seen the roof garden yet.\"\n",
      "prediction :  Maybe it is.\n",
      "Real answer : Hey, let's introduce the brand new you to Hollywood. We haven't seen the roof garden yet.\n",
      "Bert Score : {'precision': [0.8955165147781372], 'recall': [0.8330925703048706], 'f1': [0.8631774187088013], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 212.8074576335848\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSCARLETT: Look at the moves they're making,\\nBREAKER: This's their route from the lab.\\n\\n\", 'answer': 'Metal... Oh God...', 'gold_tag': \"SCARLETT shows recognition of metal , SCARLETT implies an understanding or interest in materials or a related field , SCARLETT's reaction suggests sensitivity and emotional depth\", 'last_speaker': 'SCARLETT'}\n",
      "Last word -> SCARLETT : \"Metal... Oh God...\"\n",
      "prediction :  \n",
      "Real answer : Metal... Oh God...\n",
      "Bert Score : {'precision': [0.0], 'recall': [0.0], 'f1': [0.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5830.757790976462\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBREAKER: Okay, I've got a lock on the two remaining warheads. Target one is Moscow! Target Two is Washington!\\n\\n\", 'answer': 'Give Ripcord the coordinates.', 'gold_tag': 'SCARLETT is a person in a position of authority , SCARLETT is capable of directing operations', 'last_speaker': 'SCARLETT'}\n",
      "Last word -> SCARLETT : \"Give Ripcord the coordinates.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction :  Moscow?\n",
      "Real answer : Give Ripcord the coordinates.\n",
      "Bert Score : {'precision': [0.846744179725647], 'recall': [0.8307751417160034], 'f1': [0.8386836647987366], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 5768.892528634968\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBREAKER: Energy overload in the phased array\\n\\n', 'answer': \"Let's get out of here!\", 'gold_tag': 'SCARLETT is assertive and safety-conscious , SCARLETT made an immediate decision to abandon the compromised site', 'last_speaker': 'SCARLETT'}\n",
      "Last word -> SCARLETT : \"Let's get out of here!\"\n",
      "prediction :  What's the problem?\n",
      "Real answer : Let's get out of here!\n",
      "Bert Score : {'precision': [0.8663772344589233], 'recall': [0.849730372428894], 'f1': [0.857973039150238], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 62.66045822959744\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIRK: Hello...! Anybody here?\\nSAAVIK: Indeterminate life signs.\\n\\n', 'answer': 'Phasers on stun. Move out.', 'gold_tag': 'KIRK takes charge and gives orders , SAAVIK is a member of the same team as KIRK', 'last_speaker': 'KIRK'}\n",
      "Last word -> KIRK : \"Phasers on stun. Move out.\"\n",
      "prediction :  Put me through.\n",
      "Real answer : Phasers on stun. Move out.\n",
      "Bert Score : {'precision': [0.8612164258956909], 'recall': [0.8620030283927917], 'f1': [0.8616095185279846], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 744.0209030560378\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSAAVIK: That was close --\\n\\n', 'answer': \"They just don't want us going in there.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'KIRK'}\n",
      "Last word -> KIRK : \"They just don't want us going in there.\"\n",
      "prediction :  Yes. It was.\n",
      "Real answer : They just don't want us going in there.\n",
      "Bert Score : {'precision': [0.8910837769508362], 'recall': [0.8401731848716736], 'f1': [0.8648799061775208], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 241.28518087232388\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIRK: Hold your course. Look sharp...\\n\\n', 'answer': 'At what.', 'gold_tag': 'SAAVIK is acting in a subordinate role , SAAVIK is following orders', 'last_speaker': 'SAAVIK'}\n",
      "Last word -> SAAVIK : \"At what.\"\n",
      "prediction :  Aye, Captain.\n",
      "Real answer : At what.\n",
      "Bert Score : {'precision': [0.8379381895065308], 'recall': [0.8759558796882629], 'f1': [0.8565253019332886], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 286.5485448458647\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKIRK: Time from my mark...\\nSAAVIK: Two minutes, ten seconds.\\n\\n', 'answer': \"Engine room! What's happening?!\", 'gold_tag': 'KIRK is in a command position , KIRK shows urgency', 'last_speaker': 'KIRK'}\n",
      "Last word -> KIRK : \"Engine room! What's happening?!\"\n",
      "prediction :  Good.\n",
      "Real answer : Engine room! What's happening?!\n",
      "Bert Score : {'precision': [0.9254967570304871], 'recall': [0.8154544830322266], 'f1': [0.8669978380203247], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 6379.513322406738\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTHE BEAST: WHAT ARE YOU DOING HERE!? WHAT DID YOU DO TO IT!?\\nBELLE: Nothing.\\n\\n', 'answer': 'DO YOU REALIZE WHAT YOU COULD HAVE DONE!? YOU COULD HAVE DAMNED US ALL! GET OUT! GO!', 'gold_tag': 'Everyday Language', 'last_speaker': 'THE BEAST'}\n",
      "Last word -> THE BEAST : \"DO YOU REALIZE WHAT YOU COULD HAVE DONE!? YOU COULD HAVE DAMNED US ALL! GET OUT! GO!\"\n",
      "prediction :  YOU DID THIS TO IT. YOU DID THIS TO IT. YOU DID THIS TO IT.\n",
      "Real answer : DO YOU REALIZE WHAT YOU COULD HAVE DONE!? YOU COULD HAVE DAMNED US ALL! GET OUT! GO!\n",
      "Bert Score : {'precision': [0.883861243724823], 'recall': [0.8135579824447632], 'f1': [0.847253680229187], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18750000000000003, 'rouge2': 0.0, 'rougeL': 0.18750000000000003, 'rougeLsum': 0.18750000000000003}\n",
      "bleu 1/2 : 0.1750346638085895 0.0330784422323804\n",
      "ppl : 7.633988259598863\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTHE BEAST: Should be something here you can start with...\\nBELLE: It's wonderful.\\nTHE BEAST: Oh. Yes, I suppose it is... Well, if you like it so much, then it's yours.\\nBELLE: Have you really read every one of these books?\\nTHE BEAST: Not all of them. Some are in Greek.\\nBELLE: Was that a joke? Are you making jokes now?\\n\\n\", 'answer': 'Maybe.', 'gold_tag': 'Everyday Language', 'last_speaker': 'THE BEAST'}\n",
      "Last word -> THE BEAST : \"Maybe.\"\n",
      "prediction :  No.\n",
      "Real answer : Maybe.\n",
      "Bert Score : {'precision': [0.9973087310791016], 'recall': [0.9973087310791016], 'f1': [0.9973087310791016], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1275.3241709894667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBELLE: What are you reading?\\nTHE BEAST: Nothing.\\nBELLE: Guinevere and Lancelot.\\nTHE BEAST: Well actually, King Arthur and the Round Table. Knights, and men, and swords and things...\\nBELLE: But still... it's a romance.\\nTHE BEAST: All right. I felt like a change. 66.\\nBELLE: I never thanked you for saving my life.\\nTHE BEAST: Well I never thanked you... for not leaving me to be eaten by wolves.\\nBELLE: They know how to have a good time.\\nTHE BEAST: Yes. But when I enter the room,\\nBELLE: Me, too. The villagers say that I'm a\\nTHE BEAST: I'm sorry. Your village sounds terrible.\\nBELLE: Almost as lonely as your castle.\\n\\n\", 'answer': 'What do you say we run away?', 'gold_tag': 'Everyday Language', 'last_speaker': 'THE BEAST'}\n",
      "Last word -> THE BEAST : \"What do you say we run away?\"\n",
      "prediction :  My castle is lovely. I've got a grand library, a beautiful garden, a moat full of fish.\n",
      "Real answer : What do you say we run away?\n",
      "Bert Score : {'precision': [0.8277705907821655], 'recall': [0.8233476877212524], 'f1': [0.8255531787872314], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.530730128819897\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBELLE: No! It's too far!\\nTHE BEAST: You came back.\\nBELLE: Of course I came back. I'll never leave you again.\\nTHE BEAST: I'm afraid it's my turn to leave.\\nBELLE: We're together now. It's going to be fine. You'll see.\\nTHE BEAST: At least I got to see you one last time.\\n\\n\", 'answer': 'No... please, no...', 'gold_tag': 'Everyday Language', 'last_speaker': 'BELLE'}\n",
      "Last word -> BELLE : \"No... please, no...\"\n",
      "prediction :  I'll always love you.\n",
      "Real answer : No... please, no...\n",
      "Bert Score : {'precision': [0.833006739616394], 'recall': [0.8103944659233093], 'f1': [0.8215450644493103], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 45.90796808290833\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEVE: Oh, Kelly, you're home. Good. I need you to go to the art supply store for me.\\nKELLY: Get Abe to do it.\\nEVE: He was going to but he had to go lead a meeting at Care House.\\nKELLY: What a surprise.\\nEVE: I'll make it up to you.\\nKELLY: Where have I heard that before?\\nEVE: When are you going to give me a break?\\nKELLY: Let me think - maybe when I finally forget every single word of The Little Mermaid soundtrack I'd listen to in the car waiting for him to score. No, probably when I don't prepare myself before I go into the bathroom, expecting to find him passed out on Actually, you know what? I know I'll be able to put it all behind me when I go away to college. Only, I can't go because someone spent my college fund on Mexican Black Tar. So looks like I'll have to try to forget at Shop Rite, where I'll be working for the rest of my life.\\nEVE: You're right. You have every reason to crawl into the corner and give up. But please just get me some paints\\nKELLY: What do you need?\\nEVE: We need burnt sienna, cadmium red, and midnight blue. Two tubes of blue. What happened to your face?\\n\\n\", 'answer': 'Forget it.', 'gold_tag': 'Everyday Language', 'last_speaker': 'KELLY'}\n",
      "Last word -> KELLY : \"Forget it.\"\n",
      "prediction :  You're right. I do have a reason to crawl into the corner and give up.\n",
      "Real answer : Forget it.\n",
      "Bert Score : {'precision': [0.8435876965522766], 'recall': [0.9028818607330322], 'f1': [0.8722282648086548], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 31.672071776043925\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKELLY: I don\\'t want to talk about it.\\nEVE: Well, you\\'re going to have to. Your father\\'s at the hospital.\\nKELLY: Which one of his loser friends ended up there?\\nEVE: They think he has stomach cancer.\\nKELLY: Oh this is just perfect.\\nEVE: Why would you say something like that?\\nKELLY: Because it seems to fit.\\nEVE: \"Seems to fit.\" Do you understand what I just said?\\nKELLY: Why, do you want to say it again?\\nEVE: Kelly -\\n\\n', 'answer': 'I have to go to work.', 'gold_tag': 'KELLY has a job , KELLY needs to go to work', 'last_speaker': 'KELLY'}\n",
      "Last word -> KELLY : \"I have to go to work.\"\n",
      "prediction :  I'm sorry. I know he's not a loser. I just -\n",
      "Real answer : I have to go to work.\n",
      "Bert Score : {'precision': [0.8532755970954895], 'recall': [0.8583409786224365], 'f1': [0.8558008670806885], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 23.854195538629394\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEVE: Oh Kelly. What happened?\\nKELLY: Nothing.\\nEVE: Jesus. Let me see that.\\nKELLY: Ow.\\nEVE: I'm going over to see dad.\\nKELLY: Oh.\\nEVE: And you need to come.\\nKELLY: I don't want to.\\nEVE: At this point that's not an option.\\nKELLY: Now's not a good time, ma.\\nEVE: It's never a good time.\\nKELLY: You can't make me.\\nEVE: It's not about you anymore --\\nKELLY: Don't you get it? It was never about me.\\nEVE: What is wrong with you? When are you going to stop blaming us, blaming him? I'm sick of you being angry. I want to be angry! They just took out half of your father's stomach -\\nKELLY: Enough.\\nEVE: You will not tell me what's enough. You don't know about anything. All you do is fight fake battles, in the woods, on the playground. But this, right here, us - this is the real one, the only one worth anything. The man I love is dying.\\nKELLY: That's between you and him.\\n\\n\", 'answer': \"If I made a mistake, if you felt left out, I'm sorry. But I can only deal with one thing at a time.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'EVE'}\n",
      "Last word -> EVE : \"If I made a mistake, if you felt left out, I'm sorry. But I can only deal with one thing at a time.\"\n",
      "prediction :  I need you to be there for me right now.\n",
      "Real answer : If I made a mistake, if you felt left out, I'm sorry. But I can only deal with one thing at a time.\n",
      "Bert Score : {'precision': [0.8817290663719177], 'recall': [0.8463988900184631], 'f1': [0.8637028336524963], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.05450635860680253 0.012847271929551936\n",
      "ppl : 22.175081890640435\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nKELLY: He looks good.\\n\\n', 'answer': 'He looks just like you.', 'gold_tag': 'EVE thinks the person looks like KELLY', 'last_speaker': 'EVE'}\n",
      "Last word -> EVE : \"He looks just like you.\"\n",
      "prediction :  Yeah, he does. I'll get him.\n",
      "Real answer : He looks just like you.\n",
      "Bert Score : {'precision': [0.8761234283447266], 'recall': [0.8643413782119751], 'f1': [0.8701925277709961], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 36.71771459170794\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRICK: Let's go,let's go, let's go, you shoulda done that ten minutes ago --\\nSTANLEY: We need more dog food --\\nRICK: -- talk in the car, talk in the car, moves your ass, c'mon -- Cmon,cmon,cmon, that one to?\\nSTANLEY: I need this one.\\nRICK: Why the hell do you need all four bags of books to go to school each day?\\n\\n\", 'answer': \"I can't carry all of them. I need them. I need my books. I need them to go to school.\", 'gold_tag': 'STANLEY is a school-going child , STANLEY has academic interests , STANLEY carries four bags of books', 'last_speaker': 'STANLEY'}\n",
      "Last word -> STANLEY : \"I can't carry all of them. I need them. I need my books. I need them to go to school.\"\n",
      "prediction :  You gotta read 'em!\n",
      "Real answer : I can't carry all of them. I need them. I need my books. I need them to go to school.\n",
      "Bert Score : {'precision': [0.8451147675514221], 'recall': [0.8547282814979553], 'f1': [0.8498943448066711], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 94.96539605976453\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nRICK: Be ready at two --\\nSTANLEY: Should be one-thirty.\\nRICK: I got an audition, I won't make it here 'till two, c'mon, I'll see you later. Love you.\\n\\n\", 'answer': 'Love you too.', 'gold_tag': 'STANLEY is close to RICK , STANLEY can express love to RICK', 'last_speaker': 'STANLEY'}\n",
      "Last word -> STANLEY : \"Love you too.\"\n",
      "prediction :  Love you too.\n",
      "Real answer : Love you too.\n",
      "Bert Score : {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
      "bleu 1/2 : 1.0 1.0\n",
      "ppl : 1176.0231774438296\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nSTANLEY: Dad...Dad. You have to be nicer to me, Dad.\\nRICK: Go to bed.\\nSTANLEY: I think that you have to be nicer to me.\\n\\n', 'answer': 'Go to bed.', 'gold_tag': \"RICK is a stern parent , RICK likely has a tendency to dismiss his child's feelings\", 'last_speaker': 'RICK'}\n",
      "Last word -> RICK : \"Go to bed.\"\n",
      "prediction :  I don't have to be anything to you.\n",
      "Real answer : Go to bed.\n",
      "Bert Score : {'precision': [0.8375331163406372], 'recall': [0.8760401606559753], 'f1': [0.8563540577888489], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.12500000000000003 0.04225771273642583\n",
      "ppl : 26.761248235950564\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Why were you buying a coffin?\\nBELA: Because I\\'m planning on dying soon.\\nED: Really?\\nBELA: Yes. I\\'m embarking on another bus- and�truck tour of \"Dracula.\" Twelve cities in ten days, if that\\'s\\nED: You know, I saw you perform \"Dracula.\" In Poughkeepsie, in 1938.\\nBELA: Eh, that was a terrible production. Renfield was a drunk!\\nED: I thought it was great. You were much scarier in real life than you were in the movie.\\nBELA: Thank you.\\nED: I waited to get your autograph, but you never came outside.\\nBELA: I apologize. When I play Dracula, I put myself into a trance. It takes Oh, there\\'s my bus. Shit, where\\'s my transfer?!\\nED: Don\\'t you bave a car?\\n\\n', 'answer': 'I refuse to drive in this country. Too many madmen.', 'gold_tag': 'BELA refuses to drive in America due to his belief of many madmen on the road', 'last_speaker': 'BELA'}\n",
      "Last word -> BELA : \"I refuse to drive in this country. Too many madmen.\"\n",
      "prediction :  No, I can't afford one. I'm not making any money on this tour. I'm doing it for the fun of it.\n",
      "Real answer : I refuse to drive in this country. Too many madmen.\n",
      "Bert Score : {'precision': [0.859368085861206], 'recall': [0.8718468546867371], 'f1': [0.8655624389648438], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.09523809523809525 0.02182178902359924\n",
      "ppl : 10.136807198418712\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Boy, Mr. Lugosi, you must lead such an exciting life. When is your next picture coming out? Ah, you gotta be jokin'! A great man like you... I'll bet you have dozens of 'em lined up.\\nBELA: Back in the old days, yes. But now -- no one give two fucks for Bela.\\nED: But you're a big star!\\n\\n\", 'answer': \"No more. I haven't worked in four years. This town, it chews you up, then spits you out. I'm just an ex-bogeyman. Make a right.\", 'gold_tag': 'BELA has not worked in four years , BELA reveals he has not worked in the film industry for the last four years', 'last_speaker': 'BELA'}\n",
      "Last word -> BELA : \"No more. I haven't worked in four years. This town, it chews you up, then spits you out. I'm just an ex-bogeyman. Make a right.\"\n",
      "prediction :  I'm a big star? You're crazy! I'm a big nothing!\n",
      "Real answer : No more. I haven't worked in four years. This town, it chews you up, then spits you out. I'm just an ex-bogeyman. Make a right.\n",
      "Bert Score : {'precision': [0.8539712429046631], 'recall': [0.8426541090011597], 'f1': [0.8482749462127686], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.24390243902439027, 'rouge2': 0.05128205128205128, 'rougeL': 0.24390243902439027, 'rougeLsum': 0.24390243902439027}\n",
      "bleu 1/2 : 0.044626032029685965 0.010518456621879672\n",
      "ppl : 21.796095376659867\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBELA: They don\\'t want the classic horror films anymore. Today, it\\'s all giant bugs, giant spiders, giant grasshoppers -- who would believe such nonsense!\\nED: The old ones were much spookier. They had castles, full moons...\\nBELA: They were mythic. They had a poetry to them. And you know what else? The women prefer the traditional monsters.\\nED: The women?\\nBELA: The pure horror, it both repels and attracts them. Because in their collective unconsciousness, they have the agony of childbirth. The blood. Take my word for it. You want to \"score\" with a young lady, you take her to see \"Dracula.\" Ugh, what a mess. My wife of twenty years left me last month. I\\'m not much of a housekeeper. Shh! I\\'m coming! I will feed you!\\nED: Well... I guess I should go. Perhaps we could get together again?\\n\\n', 'answer': 'Certainly. But now the children of the night are calling me.', 'gold_tag': \"BELA enjoys speaking about the intricacies and theories of horror , BELA's wife left him last month\", 'last_speaker': 'BELA'}\n",
      "Last word -> BELA : \"Certainly. But now the children of the night are calling me.\"\n",
      "prediction :  What?! Oh, no! Don't be ridiculous! You can't have dinner with a monster!\n",
      "Real answer : Certainly. But now the children of the night are calling me.\n",
      "Bert Score : {'precision': [0.8301827907562256], 'recall': [0.8724562525749207], 'f1': [0.8507947325706482], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 13.435784194427567\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Are you sure this is okay?\\n\\n', 'answer': \"Don't worry. I do it every Halloween.\", 'gold_tag': 'BELA has a recurring activity every Halloween', 'last_speaker': 'BELA'}\n",
      "Last word -> BELA : \"Don't worry. I do it every Halloween.\"\n",
      "prediction :  I'm positive.\n",
      "Real answer : Don't worry. I do it every Halloween.\n",
      "Bert Score : {'precision': [0.8989571928977966], 'recall': [0.8836734890937805], 'f1': [0.8912498354911804], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 188.55053375385492\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Now what?\\n\\n', 'answer': 'I am DRACULA! I am the BAT!! I am DRACUlA! I will LIVE FOREVER!!!', 'gold_tag': \"BELA presents himself as an immortal vampire , BELA identifies as Dracula , BELA identifies as a bat , BELA's claim of immortality implies he believes his current state  will persist indefinitely\", 'last_speaker': 'BELA'}\n",
      "Last word -> BELA : \"I am DRACULA! I am the BAT!! I am DRACUlA! I will LIVE FOREVER!!!\"\n",
      "prediction :  Now, we get out of here.\n",
      "Real answer : I am DRACULA! I am the BAT!! I am DRACUlA! I will LIVE FOREVER!!!\n",
      "Bert Score : {'precision': [0.8627224564552307], 'recall': [0.799394965171814], 'f1': [0.8298522233963013], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 76.80399204073167\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: How \\'bout a western? People love westerns.\\nBELA: But, I don\\'t like horses. Do I have to get on one?\\nED: Eh, forget it. What else is big? Teenagers! Jailbait pics! Yeah... You got the juvenile delinquent, his girlfriend from the wrong side of the tracks --\\nBELA: Who do I play?\\nED: Uh, a cop. NO! You play the father. He\\'s angry! He doesn\\'t like seeing his son -- no -- he doesn\\'t like seeing his daughter behave this way!\\nBELA: Well... can\\'t I play the romantic part? I\\'m tired of always being the bad guy. You know, back in Hungary, I played Romeo! I would like to be the lover again -- me, in a boat, with the girl...\\nED: Sure. Romance, that\\'s great! To engineer your comeback, we\\'re gonna need a whole slate of pictures. Once \"Glen Or Glenda\" takes off, we\\'ll another!\\nBELA: That\\'s good. I could use the money.\\nED: But we need to start off with a bang! Something we know the audience will want to see. Mmm. What was your biggest hit?\\nBELA: Hmm... my biggest hit? That would probably be \"Dracula.\"\\nED: Of course!\\nBELA: Those bastards at Universal. I made so much money for them, and now I can\\'t get the time of day.\\nED: So let\\'s make another \"Dracula.\" Let\\'s make \"The Return of Dracula\"!\\nBELA: We can\\'t. Those sons-a-bitches control the rights.\\nED: They do? Shoot. There must be a way to get around that... Ha-ha! Dr. Acula!\\nBELA: Dracula?\\n\\n', 'answer': \"No! Doctor Acula! You can still wear the cape, have the fangs... but you're a doctor! Not a count. I gotta type this up, while it's still fresh!\", 'gold_tag': \"ED's temporal information: ED has a fresh movie idea that he needs to type up\", 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"No! Doctor Acula! You can still wear the cape, have the fangs... but you're a doctor! Not a count. I gotta type this up, while it's still fresh!\"\n",
      "prediction :  Yeah.\n",
      "Real answer : No! Doctor Acula! You can still wear the cape, have the fangs... but you're a doctor! Not a count. I gotta type this up, while it's still fresh!\n",
      "Bert Score : {'precision': [0.9476217031478882], 'recall': [0.8106208443641663], 'f1': [0.8737837076187134], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBELA: Eddie... my friend.\\nED: Bela, what happened?!\\nBELA: I didn't feel well...\\nED: Let me take you to the hospital.\\nBELA: No hospital. Just take me to the couch...\\nED: Should I call a doctor?\\nBELA: Nah. This happens all the time...\\nED: Is there anything I can get you? Water? A blanket?\\nBELA: Goulash.\\nED: I don't know how to make goulash.\\nBELA: Morphine, with a demerol chaser. Eddie, I'm so broke. I don't know what I'm gonna do...\\n\\n\", 'answer': \"Don't worry. I'll do something.\", 'gold_tag': 'Ed is open to helping Bela financially', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Don't worry. I'll do something.\"\n",
      "prediction :  Bela, you need to see a doctor.\n",
      "Real answer : Don't worry. I'll do something.\n",
      "Bert Score : {'precision': [0.8791478276252747], 'recall': [0.8898774981498718], 'f1': [0.8844801187515259], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 131.86456579691622\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Goodbye! Goodbye!\\nBELA: So how'd we do?\\n\\n\", 'answer': \"We didn't make a dime.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"We didn't make a dime.\"\n",
      "prediction :  You were right. I was wrong.\n",
      "Real answer : We didn't make a dime.\n",
      "Bert Score : {'precision': [0.8964776992797852], 'recall': [0.8724558353424072], 'f1': [0.8843036890029907], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 31.099343759661974\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Bela, I don't know what I'm doin' anymore...\\n\\n\", 'answer': 'Stop worrying. This is going to raise your spirits.', 'gold_tag': 'Everyday Language', 'last_speaker': 'BELA'}\n",
      "Last word -> BELA : \"Stop worrying. This is going to raise your spirits.\"\n",
      "prediction :  I know, Eddie. I've been thinkin' about it too. We've been over the same thing for so long, and we still haven't found anythin' good. Maybe we should just call it quits and go back to bein' friends.\n",
      "Real answer : Stop worrying. This is going to raise your spirits.\n",
      "Bert Score : {'precision': [0.819634735584259], 'recall': [0.8739668130874634], 'f1': [0.8459292650222778], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.04, 'rouge2': 0.0, 'rougeL': 0.04, 'rougeLsum': 0.04}\n",
      "bleu 1/2 : 0.026315789473684213 0.008433490104000938\n",
      "ppl : 5.478684570625996\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBELA: In life, the decisions that haunt you are the ones where you just don't know... where right or wrong will never be answered. Years ago, the Hungarians contacted me. The government wanted me to come home, to be Minister of Culture.\\nED: Really?\\nBELA: It was a very impressive offer. Fancy offices, a big home... I'd be treated like a king.\\nED: So why didn't you do it?\\nBELA: I didn't know if it was a trick. They might arrest me and throw me in a gulag. I am Hungary's most famous emigrant. they'd use me as a lesson to anyone\\nED: But maybe not.\\nBELA: Correct. So instead, I stayed here, waiting for my comeback. Always hoping... the next film, the next film... that would be the one.\\n\\n\", 'answer': 'Your next film. That will be the one.', 'gold_tag': \"ED reassured BELA about her next film , ED is also anticipating BELA's next film\", 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Your next film. That will be the one.\"\n",
      "prediction :  Did you ever think about the possibility that there might not be a next film?\n",
      "Real answer : Your next film. That will be the one.\n",
      "Bert Score : {'precision': [0.8524142503738403], 'recall': [0.8907000422477722], 'f1': [0.8711367249488831], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.43478260869565216, 'rouge2': 0.09523809523809523, 'rougeL': 0.1739130434782609, 'rougeLsum': 0.1739130434782609}\n",
      "bleu 1/2 : 0.2 0.03779644730092273\n",
      "ppl : 26.72579046052236\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBELA: Why are you here??\\nED: Shit! Bela, what's with the gun?\\nBELA: Why aren't you on your honeymoon? Where's Myrna?\\n\\n\", 'answer': \"Norma. She changed her mind. She doesn't wanna marry me. Can you put down the gun?\", 'gold_tag': \"Ed has recently suffered relationship turmoil , Ed's engagement has been called off\", 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Norma. She changed her mind. She doesn't wanna marry me. Can you put down the gun?\"\n",
      "prediction :  I'm sorry, Bela. I'm not with Myrna. I'm here to make things right.\n",
      "Real answer : Norma. She changed her mind. She doesn't wanna marry me. Can you put down the gun?\n",
      "Bert Score : {'precision': [0.8711460828781128], 'recall': [0.8756119608879089], 'f1': [0.8733733296394348], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 21.64066604883499\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: What are you doing?\\nBELA: I was thinking about killing myself.\\nED: Jesus Christ, what an evening. What happened?\\nBELA: Eddie, I received a letter from the government. They're cutting off my unemployment. That's all I've got. Without it, I can't pay the rent...\\nED: Don't you have any savings?\\nBELA: I'm obsolete. I have nothing to live for. Tonight, I should die. And you should come with me.\\nED: Buddy, I don't know if that's such a good idea.\\nBELA: It'll be wonderful. We'll be at peace. In the afterlife, you don't have to worry about finding work.\\nED: Bela, I'm on your side. C'mon, give me the gun... If you give me the gun, I'll make you a drink. What are you drinking?\\nBELA: Formaldehyde.\\n\\n\", 'answer': \"Straight up or on the rocks? Don't worry. Don't worry. Everything's gonna be all right.\", 'gold_tag': \"ED has a sense of humor, evident in his response to BELA's choice of drink\", 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Straight up or on the rocks? Don't worry. Don't worry. Everything's gonna be all right.\"\n",
      "prediction :  It's not that bad. It's like drinking gasoline. I'll make you a drink.\n",
      "Real answer : Straight up or on the rocks? Don't worry. Don't worry. Everything's gonna be all right.\n",
      "Bert Score : {'precision': [0.8644629120826721], 'recall': [0.8514390587806702], 'f1': [0.8579015731811523], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.058823529411764705, 'rouge2': 0.0, 'rougeL': 0.058823529411764705, 'rougeLsum': 0.058823529411764705}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 15.767581493414063\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Everybody out! This is a hospital! Get out of here. What happened?!\\nBELA: Isn't it wonderful? After all these interest again in Bela Lugosi.\\nED: Bela, they're parasites! They just want to exploit you.\\n\\n\", 'answer': \"Fine. Let them! There is no such thing as bad press. A man from New York even said he's putting me on the front page! First celebrity to ever check into rehab. When I get out of here, I will be healthy. Strong! I will be primed for my comeback!\", 'gold_tag': \"BELA Lugosi has checked into rehab , BELA is optimistic about making a comeback after getting healthy , BELA's temporal information: BELA is currently in a rehab facility and plans to make a career comeback after getting out\", 'last_speaker': 'BELA'}\n",
      "Last word -> BELA : \"Fine. Let them! There is no such thing as bad press. A man from New York even said he's putting me on the front page! First celebrity to ever check into rehab. When I get out of here, I will be healthy. Strong! I will be primed for my comeback!\"\n",
      "prediction :  I understand. I know you're right. But I've got to do something. I've got to make a living.\n",
      "Real answer : Fine. Let them! There is no such thing as bad press. A man from New York even said he's putting me on the front page! First celebrity to ever check into rehab. When I get out of here, I will be healthy. Strong! I will be primed for my comeback!\n",
      "Bert Score : {'precision': [0.8711510300636292], 'recall': [0.841620147228241], 'f1': [0.8561310172080994], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1388888888888889, 'rouge2': 0.0, 'rougeL': 0.08333333333333333, 'rougeLsum': 0.08333333333333333}\n",
      "bleu 1/2 : 0.02816888590101102 0.005292012181205726\n",
      "ppl : 11.270377140448526\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nED: Bela, wake up. I've got some good news. The doctor says you're all better. You can come home.\\nBELA: Really? I don't feel so great.\\n\\n\", 'answer': \"No, you look good. And the tests came back fine. C'mon...\", 'gold_tag': \"ED is optimistic about BELA's recovery\", 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"No, you look good. And the tests came back fine. C'mon...\"\n",
      "prediction :  You'll feel better once you get some rest. We've got a lot of catching up to do.\n",
      "Real answer : No, you look good. And the tests came back fine. C'mon...\n",
      "Bert Score : {'precision': [0.8674783706665039], 'recall': [0.8633096218109131], 'f1': [0.8653889894485474], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.06451612903225808, 'rouge2': 0.0, 'rougeL': 0.06451612903225808, 'rougeLsum': 0.06451612903225808}\n",
      "bleu 1/2 : 0.0588235294117647 0.019174124721184262\n",
      "ppl : 9.32164082061476\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBELA: Eddie, I wanna make another picture. When are we gonna make another picture?\\n\\n', 'answer': 'Soon, Bela... Soon.', 'gold_tag': 'ED is in a position to promise BELA the creation of a new picture soon , ED anticipates the creation of another picture soon', 'last_speaker': 'ED'}\n",
      "Last word -> ED : \"Soon, Bela... Soon.\"\n",
      "prediction :  Oh, Bela, you know I love you, but I don't know if I can do another picture with you.\n",
      "Real answer : Soon, Bela... Soon.\n",
      "Bert Score : {'precision': [0.8522503972053528], 'recall': [0.9220584630966187], 'f1': [0.8857811689376831], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913045, 'rouge2': 0.0, 'rougeL': 0.08695652173913045, 'rougeLsum': 0.08695652173913045}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.45350004848714\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nBELA: This is so exciting. Another production! So Eddie, don't we need a sound crew?\\nED: No, this is just the second unit. We'll do the main footage later. Uh... you're a very important and respected man. You're leaving your house... and you're in a hurry to a big social event.\\nBELA: Okay. But what if I'm not in too big a hurry? What if I take a moment to slow down and savor the beauty of life? To smell a flower?\\nED: That's great. Let's do a take. Okay, roll camera! Rolling. Scene One, Take One! And... ACTION!\\n\\n\", 'answer': 'Eddie, how was I? Good. Now what about my close up?', 'gold_tag': 'BELA is an actor involved in a production', 'last_speaker': 'BELA'}\n",
      "Last word -> BELA : \"Eddie, how was I? Good. Now what about my close up?\"\n",
      "prediction :  Okay, I'm gonna stop for a moment and smell a flower.\n",
      "Real answer : Eddie, how was I? Good. Now what about my close up?\n",
      "Bert Score : {'precision': [0.862784206867218], 'recall': [0.8635758757591248], 'f1': [0.8631798624992371], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913043, 'rouge2': 0.0, 'rougeL': 0.08695652173913043, 'rougeLsum': 0.08695652173913043}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 27.03804709192423\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDEKKER: Round up all the hostages, anyone that comes out, grab'em!\\n\\n\", 'answer': 'The rest of you, come with us.', 'gold_tag': 'CONNERS is in a position of authority or leadership , CONNERS gives directives to others', 'last_speaker': 'CONNERS'}\n",
      "Last word -> CONNERS : \"The rest of you, come with us.\"\n",
      "prediction :  Okay, I'll take care of it.\n",
      "Real answer : The rest of you, come with us.\n",
      "Bert Score : {'precision': [0.8694145679473877], 'recall': [0.8792515397071838], 'f1': [0.8743054270744324], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714285, 'rouge2': 0.0, 'rougeL': 0.14285714285714285, 'rougeLsum': 0.14285714285714285}\n",
      "bleu 1/2 : 0.141080287481769 0.04887164517296948\n",
      "ppl : 14.88381273910403\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDEKKER: I think this Lorenz was trying to tell us something.\\nCONNERS: You don't say.\\nDEKKER: The way he spoke... he paused before certain words. Have you ever heard of the Chaos Theory?\\n\\n\", 'answer': 'What?', 'gold_tag': 'CONNERS shows skepticism regarding the Chaos Theory , CONNERS has an apparent lack of knowledge regarding the Chaos Theory', 'last_speaker': 'CONNERS'}\n",
      "Last word -> CONNERS : \"What?\"\n",
      "prediction :  Yes. I have a vague idea of it.\n",
      "Real answer : What?\n",
      "Bert Score : {'precision': [0.8578864336013794], 'recall': [0.8633466958999634], 'f1': [0.8606078624725342], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 69.25176436198457\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDEKKER: You hit?\\n\\n', 'answer': \"I'm fine.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'CONNERS'}\n",
      "Last word -> CONNERS : \"I'm fine.\"\n",
      "prediction :  Yes, I hit.\n",
      "Real answer : I'm fine.\n",
      "Bert Score : {'precision': [0.9051138162612915], 'recall': [0.9018617868423462], 'f1': [0.9034848809242249], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.0, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 552.5290736092182\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCONNERS: Prick used to work for some big-time software company until they caught him dipping into the company's slush fund. They didn't want the publicity so they didn't press charges. Couple years later, he was busted for looting the pension plans of retired cops. For a genius... he's a fucking moron.\\nDEKKER: This was your case. You and York. You made the bust. Why didn't it stick?\\nCONNERS: His lawyer put us on trial. Said we were crooked, abusive, that we planted evidence... We were in the midst of the Pearl Street Bridge fallout. Jury bought it. They let him walk and we were the scapegoats.\\nDEKKER: Was it true?\\nCONNERS: The guy was guilty. He was scum. That was the truth. There's something they don't teach you. The system breaks down. You have to compensate to get results.\\nDEKKER: That gives you the right to break the rules?\\nCONNERS: Break, no. Bend... if it means justice... Absolutely.\\n\\n\", 'answer': \"Another thing they don't teach you.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'DEKKER'}\n",
      "Last word -> DEKKER : \"Another thing they don't teach you.\"\n",
      "prediction :  So you're saying that you're willing to bend the rules in order to achieve justice.\n",
      "Real answer : Another thing they don't teach you.\n",
      "Bert Score : {'precision': [0.8535844087600708], 'recall': [0.8564786911010742], 'f1': [0.8550291061401367], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08333333333333333, 'rouge2': 0.0, 'rougeL': 0.08333333333333333, 'rougeLsum': 0.08333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.54580446264947\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCONNERS: You okay?\\n\\n', 'answer': 'Yeah.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DEKKER'}\n",
      "Last word -> DEKKER : \"Yeah.\"\n",
      "prediction :  Yeah, I'm just trying to get my head around it.\n",
      "Real answer : Yeah.\n",
      "Bert Score : {'precision': [0.8332166075706482], 'recall': [0.9456334114074707], 'f1': [0.8858727812767029], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666669, 'rouge2': 0.0, 'rougeL': 0.16666666666666669, 'rougeLsum': 0.16666666666666669}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 11.1276566916466\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCONNERS: First day in the city and you've already been shot.\\n\\n\", 'answer': 'Why don\\'t I \"just graze\" you with a bullet and see how you feel.', 'gold_tag': 'DEKKER suggests defensiveness and a hint of anger or frustration , DEKKER implies a personality that is likely quick to act or react', 'last_speaker': 'DEKKER'}\n",
      "Last word -> DEKKER : \"Why don't I \"just graze\" you with a bullet and see how you feel.\"\n",
      "prediction :  It was a small caliber. I'm fine.\n",
      "Real answer : Why don't I \"just graze\" you with a bullet and see how you feel.\n",
      "Bert Score : {'precision': [0.8667212128639221], 'recall': [0.8362927436828613], 'f1': [0.8512351512908936], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1739130434782609, 'rouge2': 0.0, 'rougeL': 0.08695652173913045, 'rougeLsum': 0.08695652173913045}\n",
      "bleu 1/2 : 0.05255420588163462 0.017950678673773812\n",
      "ppl : 76.70301562770317\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCONNERS: Take five, guys. Hiya, Damon. How you feeling?\\n\\n', 'answer': \"May I? You remember me, don't you? Thought so.\", 'gold_tag': 'DEKKER has met the person Conners is talking to before , DEKKER assumes that they would remember him , CONNERS and DEKKER both recognize a third party', 'last_speaker': 'DEKKER'}\n",
      "Last word -> DEKKER : \"May I? You remember me, don't you? Thought so.\"\n",
      "prediction :  You look like you’ve been through a war.\n",
      "Real answer : May I? You remember me, don't you? Thought so.\n",
      "Bert Score : {'precision': [0.8662663698196411], 'recall': [0.8263512849807739], 'f1': [0.845838189125061], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2105263157894737, 'rouge2': 0.0, 'rougeL': 0.2105263157894737, 'rougeLsum': 0.2105263157894737}\n",
      "bleu 1/2 : 0.11031211282307446 0.03729230060020541\n",
      "ppl : 17.291387080081563\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCONNERS: You fuckin' hypocrite. You give me shit for my interrogating skills... least I don't threaten them with a lethal overdose.\\n\\n\", 'answer': \"There's never been a single case in recorded medical history of someone overdosing on 200 milliliters of saline. Bend, not break. That's what you said, right?\", 'gold_tag': 'DEKKER mentions medical overdose , DEKKER may have a medical background or knowledge , They both recall a previous conversation where DEKKER told CONNERS about his philosophy of bending, not breaking', 'last_speaker': 'DEKKER'}\n",
      "Last word -> DEKKER : \"There's never been a single case in recorded medical history of someone overdosing on 200 milliliters of saline. Bend, not break. That's what you said, right?\"\n",
      "prediction :  You know that's not what I meant.\n",
      "Real answer : There's never been a single case in recorded medical history of someone overdosing on 200 milliliters of saline. Bend, not break. That's what you said, right?\n",
      "Bert Score : {'precision': [0.8586537837982178], 'recall': [0.823997974395752], 'f1': [0.8409689664840698], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2777777777777778, 'rouge2': 0.058823529411764705, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0.018929216900646192 0.004571840226960005\n",
      "ppl : 21.85797054071167\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCONNERS: You never think of the repercussions. The suspect's mother, father... Brother. How your decision affects them. He had murder in his eyes.\\nDEKKER: John Curtis.\\n\\n\", 'answer': 'It was pouring. Lights everywhere. If he had only done what I said.', 'gold_tag': 'CONNERS is cautious', 'last_speaker': 'CONNERS'}\n",
      "Last word -> CONNERS : \"It was pouring. Lights everywhere. If he had only done what I said.\"\n",
      "prediction :  What?\n",
      "Real answer : It was pouring. Lights everywhere. If he had only done what I said.\n",
      "Bert Score : {'precision': [0.8299077749252319], 'recall': [0.8231942653656006], 'f1': [0.8265373706817627], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714288, 'rouge2': 0.0, 'rougeL': 0.14285714285714288, 'rougeLsum': 0.14285714285714288}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCONNERS: We take them alive!\\n\\n', 'answer': 'All units, all units. Shots fired! Requesting backup immediately!', 'gold_tag': \"DEKKER's call for backup signifies an immediate need for assistance , DEKKER is in a role that can call for backup , DEKKER's role indicates a position of certain authority and responsibility\", 'last_speaker': 'DEKKER'}\n",
      "Last word -> DEKKER : \"All units, all units. Shots fired! Requesting backup immediately!\"\n",
      "prediction :  You know the risks, Conners.\n",
      "Real answer : All units, all units. Shots fired! Requesting backup immediately!\n",
      "Bert Score : {'precision': [0.8529452085494995], 'recall': [0.8375875949859619], 'f1': [0.8451966643333435], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 109.15543387323999\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCASEY: Frock horrors. This weeks top of Roberto.\\nJODY: She looks like a bug. (Car hoots) Wankers!\\nCASEY: You wanna sack your stylist girl.\\n\\n', 'answer': 'Bet they did that on purpose, dressed her up like an insect.', 'gold_tag': 'JODY is critical and frank in her opinions about fashion', 'last_speaker': 'JODY'}\n",
      "Last word -> JODY : \"Bet they did that on purpose, dressed her up like an insect.\"\n",
      "prediction :  I wanna sack my stylist, you're right. I look like a fucking idiot.\n",
      "Real answer : Bet they did that on purpose, dressed her up like an insect.\n",
      "Bert Score : {'precision': [0.8527036905288696], 'recall': [0.8548691868782043], 'f1': [0.85378497838974], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307691, 'rouge2': 0.0, 'rougeL': 0.07692307692307691, 'rougeLsum': 0.07692307692307691}\n",
      "bleu 1/2 : 0.07692307692307693 0.025318484177091663\n",
      "ppl : 21.909963345240904\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJODY: We could walk up the garage.\\nCASEY: I'm supposed to be helping my mum up at Stonefield.\\nJODY: They keep you busy.\\nCASEY: Yeah.\\n\\n\", 'answer': 'You never stop, you!', 'gold_tag': 'Everyday Language', 'last_speaker': 'JODY'}\n",
      "Last word -> JODY : \"You never stop, you!\"\n",
      "prediction :  I'll call the taxi.\n",
      "Real answer : You never stop, you!\n",
      "Bert Score : {'precision': [0.8528752326965332], 'recall': [0.808262050151825], 'f1': [0.8299695253372192], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 75.92204921392697\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJODY: Would you do him?\\nCASEY: No.\\nJODY: What about him?\\nCASEY: He's gay, you dobbin.\\nJODY: So?\\nCASEY: Swipe.\\nJODY: Ben Sergeant... I'd walk through fire to do him.\\nCASEY: The drummer?\\nJODY: He's not just the drummer. He writes the lyrics; it's his band. He's the fucking genius, not Steve Culley or any of these wankers. It's Ben.\\nCASEY: OK. I'd do Ben.\\nJODY: I wanna be her, in that dress with him licking my teapot lids.\\n\\n\", 'answer': 'Yeah... me too.', 'gold_tag': 'CASEY is less assertive or outspoken than JODY', 'last_speaker': 'CASEY'}\n",
      "Last word -> CASEY : \"Yeah... me too.\"\n",
      "prediction :  I'm not doing Ben.\n",
      "Real answer : Yeah... me too.\n",
      "Bert Score : {'precision': [0.8756377696990967], 'recall': [0.857668399810791], 'f1': [0.8665599226951599], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 275.11059896941657\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCASEY: Look at that cellulite...\\nJODY: She been sitting on a bead car-seat or what?\\nCASEY: `Her latest tattoo count was nine, including a Sumatran tiger and `Eternity' written in Sanskrit.'\\nJODY: She'll be getting a barcode done next. Right across there.\\n\\n\", 'answer': \"Nice baby though. I'd like one that colour.\", 'gold_tag': 'CASEY expresses a desire to have a child, particularly one of a certain color', 'last_speaker': 'CASEY'}\n",
      "Last word -> CASEY : \"Nice baby though. I'd like one that colour.\"\n",
      "prediction :  'How'd you get the barcode?'\n",
      "Real answer : Nice baby though. I'd like one that colour.\n",
      "Bert Score : {'precision': [0.8363816738128662], 'recall': [0.8516744375228882], 'f1': [0.8439587950706482], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 67.14409569325052\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCASEY: What if she's got an alarm?\\nJODY: Soon find out.\\nCASEY: What if they come back?\\n\\n\", 'answer': \"If you're too chicken, go home.\", 'gold_tag': 'JODY is adventurous , JODY is potentially reckless', 'last_speaker': 'JODY'}\n",
      "Last word -> JODY : \"If you're too chicken, go home.\"\n",
      "prediction :  That's my problem.\n",
      "Real answer : If you're too chicken, go home.\n",
      "Bert Score : {'precision': [0.8717169761657715], 'recall': [0.8457167148590088], 'f1': [0.8585200309753418], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 98.67971147660239\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJODY: Let's go. I'm freezing my tits off.\\nCASEY: Wait!!\\nJODY: Oh. My. God.\\nCASEY: It's him. From Stonefield.\\n\\n\", 'answer': 'The dirty cheating sod.', 'gold_tag': 'JODY has a straightforward and outspoken nature , JODY uses blunt language , Shared memories - CASEY and JODY are familiar with a person from Stonefield, whom they judge negatively', 'last_speaker': 'JODY'}\n",
      "Last word -> JODY : \"The dirty cheating sod.\"\n",
      "prediction :  He's here?\n",
      "Real answer : The dirty cheating sod.\n",
      "Bert Score : {'precision': [0.8194286227226257], 'recall': [0.8288149833679199], 'f1': [0.8240950107574463], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 213.59320109925292\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCASEY: `Prolific author of intelligent crime novels.'\\nJODY: Fucking `D' list. How could she do that after Ben?\\nCASEY: Maybe she's numbing the pain.\\nJODY: He's not even a proper celeb.\\nCASEY: Maybe older guys know more... you know, bed stuff.\\nJODY: Eww! He's a perv. I hate him.\\n\\n\", 'answer': 'Jode, I know who I feel sorry for.', 'gold_tag': 'CASEY is perceptive and understanding', 'last_speaker': 'CASEY'}\n",
      "Last word -> CASEY : \"Jode, I know who I feel sorry for.\"\n",
      "prediction :  `She's not even a real celebrity. How could she do that after Ben?'\n",
      "Real answer : Jode, I know who I feel sorry for.\n",
      "Bert Score : {'precision': [0.856614351272583], 'recall': [0.8474231362342834], 'f1': [0.851993978023529], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 70.46589687225972\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCASEY: There'll be the divorce and like acrimony and her world'll fall apart...\\nJODY: Yeah.\\nCASEY: But maybe one day, she'll put the bitterness behind her and find a new love...\\nJODY: Don't be daft. She's old, you big sop.\\nCASEY: See? That's D-List's car.\\nJODY: So this is where he hides it when he goes to shag Plastic.\\nCASEY: Yeah. Dirty git.\\nJODY: Big old turd.\\nCASEY: He's a rotten cheater.\\n\\n\", 'answer': \"Like my dad. Come on Case. Let's fuck him up.\", 'gold_tag': 'JODY proposes to take revenge on someone she perceives has wronged her, similar to her father', 'last_speaker': 'JODY'}\n",
      "Last word -> JODY : \"Like my dad. Come on Case. Let's fuck him up.\"\n",
      "prediction : He's not cheating.\n",
      "Real answer : Like my dad. Come on Case. Let's fuck him up.\n",
      "Bert Score : {'precision': [0.8662587404251099], 'recall': [0.8665337562561035], 'f1': [0.8663961887359619], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 31.89066754753787\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCASEY: This is wrong, Jode.\\nJODY: She's asking for it; slut. I'm going to email D-List's wife.\\nCASEY: We should send the photo and be done with it.\\nJODY: Casey.\\nCASEY: What?\\n\\n\", 'answer': \"While I was sitting here. Look. An e-mail from Ben come in. Just like that, when I'm here.\", 'gold_tag': 'JODY receives an e-mail from Ben during the conversation', 'last_speaker': 'JODY'}\n",
      "Last word -> JODY : \"While I was sitting here. Look. An e-mail from Ben come in. Just like that, when I'm here.\"\n",
      "prediction :  We should send the photo and be done with it.\n",
      "Real answer : While I was sitting here. Look. An e-mail from Ben come in. Just like that, when I'm here.\n",
      "Bert Score : {'precision': [0.8540380001068115], 'recall': [0.8481232523918152], 'f1': [0.8510702848434448], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 77.60202284311099\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJODY: `Could drop him off next week. And when I'm back, maybe we could dot dot dot. Ben.'\\nCASEY: He's coming back.\\nJODY: Tamara doesn't deserve him, Case. `Dear Ben, I can't see you as I am shagging an old married man -\\nCASEY: What're you doing??\\nJODY: `But I have found a reliable dog- lover in the village...\\nCASEY: No way, Jody! You're not sending it.\\nJODY: `Call Jody on 07700 900929.'\\nCASEY: You stupid cow!\\nJODY: I'm making something happen!\\nCASEY: You gone too far!\\nJODY: I'm getting him down here.\\nCASEY: / You don't know when to stop! You're an idiot. I'm not having nothing to do with it.\\nJODY: Otherwise my whole life'll go by and I'll be washed up and thirty four like my mum and no one decent will ever even have snogged me!\\nCASEY: You twat.\\n\\n\", 'answer': 'Fuck off then.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JODY'}\n",
      "Last word -> JODY : \"Fuck off then.\"\n",
      "prediction :  You're in.\n",
      "Real answer : Fuck off then.\n",
      "Bert Score : {'precision': [0.8672330379486084], 'recall': [0.8756710290908813], 'f1': [0.8714316487312317], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 124.16293749689183\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOM: For real, Paul. I'm madly in love with that girl.\\n\\n\", 'answer': 'Oh shit.', 'gold_tag': 'Everyday Language', 'last_speaker': 'PAUL'}\n",
      "Last word -> PAUL : \"Oh shit.\"\n",
      "prediction :  Oh, you're in love?\n",
      "Real answer : Oh shit.\n",
      "Bert Score : {'precision': [0.8280647993087769], 'recall': [0.8709635138511658], 'f1': [0.8489726185798645], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 49.3642592557631\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOM: You OK?\\nPAUL: I'm fine.\\nTOM: I just found out. I'm so sorry Paul. If you need anything--\\nPAUL: I need to see Anna.\\nTOM: What do you mean?\\nPAUL: The funeral director won't let me see her Tom. He says I'm not family. Can you talk to him? Put some pressure on him.\\nTOM: I can't do that.\\nPAUL: Tom. You're my friend.\\nTOM: Paul. I can't do it. You sure you're OK?\\nPAUL: I fucked up.\\nTOM: Paul. It was an accident. You should get some rest. Let me drive you home.\\n\\n\", 'answer': 'I always fuck everything up.', 'gold_tag': 'PAUL feels guilt and expresses self-deprecating thoughts', 'last_speaker': 'PAUL'}\n",
      "Last word -> PAUL : \"I always fuck everything up.\"\n",
      "prediction :  I need to see Anna.\n",
      "Real answer : I always fuck everything up.\n",
      "Bert Score : {'precision': [0.8901717662811279], 'recall': [0.8802288770675659], 'f1': [0.885172426700592], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20000000000000004, 'rouge2': 0.0, 'rougeL': 0.20000000000000004, 'rougeLsum': 0.20000000000000004}\n",
      "bleu 1/2 : 0.2 0.07071067811865477\n",
      "ppl : 226.80051330793262\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOM: You're lucky.\\nPAUL: Am I?\\nTOM: They're not pressing charges. What the hell's wrong with you? You're this close to fucking up your career.\\nPAUL: You know what he told me? He told me Anna's alive.\\nTOM: You didn't believe him did you?\\nPAUL: No. Of course not. It's just... I'm having these...\\nTOM: What?\\n\\n\", 'answer': 'Nothing. Forget it.', 'gold_tag': 'Everyday Language', 'last_speaker': 'PAUL'}\n",
      "Last word -> PAUL : \"Nothing. Forget it.\"\n",
      "prediction :  Visions.\n",
      "Real answer : Nothing. Forget it.\n",
      "Bert Score : {'precision': [0.8775794506072998], 'recall': [0.917624831199646], 'f1': [0.8971554636955261], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1056.5561525051226\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTOM: You sure you're going to be OK?\\n\\n\", 'answer': 'Yeah. Thanks Tom.', 'gold_tag': 'Everyday Language', 'last_speaker': 'PAUL'}\n",
      "Last word -> PAUL : \"Yeah. Thanks Tom.\"\n",
      "prediction :  Yeah, I'm fine.\n",
      "Real answer : Yeah. Thanks Tom.\n",
      "Bert Score : {'precision': [0.8590447902679443], 'recall': [0.8989599943161011], 'f1': [0.8785492777824402], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428575, 'rouge2': 0.0, 'rougeL': 0.28571428571428575, 'rougeLsum': 0.28571428571428575}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 38.73067596202411\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTONY: Hey.\\nJAKE: What happened?? Shooting Script 07/27/15 53.\\nTONY: Nothing. I bumped into Joey at soccer.\\nJAKE: But your mom--\\n\\n', 'answer': \"She's so dramatic, she deserves an Academy Award. She doesn't want me to go out so I can help her with this. Look. She's terrible with numbers, you know. You go ahead. I'll come find you as soon as I finish here.\", 'gold_tag': 'TONY looks after his dramatic mother , TONY helps his mother with tasks, particularly those involving numbers , TONY needs to help his mother immediately with her number-related task', 'last_speaker': 'TONY'}\n",
      "Last word -> TONY : \"She's so dramatic, she deserves an Academy Award. She doesn't want me to go out so I can help her with this. Look. She's terrible with numbers, you know. You go ahead. I'll come find you as soon as I finish here.\"\n",
      "prediction :  She's doing fine.\n",
      "Real answer : She's so dramatic, she deserves an Academy Award. She doesn't want me to go out so I can help her with this. Look. She's terrible with numbers, you know. You go ahead. I'll come find you as soon as I finish here.\n",
      "Bert Score : {'precision': [0.8845226764678955], 'recall': [0.8224616050720215], 'f1': [0.8523640036582947], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.04166666666666667, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 7.534431356603514e-07 2.9180727167268367e-07\n",
      "ppl : 137.7234472779853\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTONY: Do you know anyone with a swimming pool?\\nJAKE: No, why?\\nTONY: I would do anything to see her in a bikini. Can you imagine?\\nJAKE: I never thought about that.\\nTONY: So what about you? Who do you like?\\nJAKE: They're all very nice.\\nTONY: You can tell me, you know.\\nJAKE: Tell you what?\\nTONY: If you like someone.\\nJAKE: I don't know.\\nTONY: That's what you always say.\\nJAKE: Well I do have an idea you might like.\\nTONY: What?\\nJAKE: Eva talked about going dancing. There's a matinee club, like after hours, for kids.\\nTONY: When is it?\\nJAKE: Sunday afternoon, in the City. Shooting Script 07/27/15 73.\\nTONY: Let's go!\\nJAKE: It would be fun, right?\\n\\n\", 'answer': \"That would be perfect. If I can just dance with her... Wow, that's getting good, Jake. I'm impressed.\", 'gold_tag': 'TONY is romantically interested in a girl, dreaming of dancing with her at the club', 'last_speaker': 'TONY'}\n",
      "Last word -> TONY : \"That would be perfect. If I can just dance with her... Wow, that's getting good, Jake. I'm impressed.\"\n",
      "prediction :  I'm telling you, I want to see her in a bikini.\n",
      "Real answer : That would be perfect. If I can just dance with her... Wow, that's getting good, Jake. I'm impressed.\n",
      "Bert Score : {'precision': [0.8758679628372192], 'recall': [0.8568167686462402], 'f1': [0.8662376403808594], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.06666666666666667, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.09622060754546369 0.022565732702551407\n",
      "ppl : 19.22006050762725\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nTONY: It ain't worth it, Jake. Get out.\\nJAKE: What time is it?\\nTONY: Nine o'clock.\\nJAKE: At night?\\nTONY: Yeah. At night.\\nJAKE: How many pounds I gotta lose?\\nTONY: Three more, I figure.\\nJAKE: Just give me a chip of ice to put in my mouth. Just a chip of ice.\\nTONY: I'll give you anything you want, Jake. I think you should come out for a few minutes -- give yourself a break.\\n\\n\", 'answer': \"Are you outa your mind? If I come out, I'll lose the title.\", 'gold_tag': 'JAKE is a person driven by his goals', 'last_speaker': 'JAKE'}\n",
      "Last word -> JAKE : \"Are you outa your mind? If I come out, I'll lose the title.\"\n",
      "prediction :  *nods*\n",
      "Real answer : Are you outa your mind? If I come out, I'll lose the title.\n",
      "Bert Score : {'precision': [0.773642897605896], 'recall': [0.8031681180000305], 'f1': [0.7881290316581726], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 218.2736039962527\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOX: ... illegal search of Lindenmeyer' s duplex. Eleven civilian vehicles damaged or destroyed. Twenty�four citizen complaints. And the calls are just starting to come in... I forgot what it's like to have you on the streets.\\nMADISON: Any sign of Lindenmeyer?\\nCOX: None. He could be hiding, he could be helping Sid, or could be in little pieces on Santa Monica beach. next?\\nMADISON: Until we know what new influences are affecting him, we can't be sure.\\n\\n\", 'answer': \"In other words, we collectively don't know shit.\", 'gold_tag': 'COX displays some cynicism and sarcasm in his interactions', 'last_speaker': 'COX'}\n",
      "Last word -> COX : \"In other words, we collectively don't know shit.\"\n",
      "prediction :  Do you think he's a lone wolf?\n",
      "Real answer : In other words, we collectively don't know shit.\n",
      "Bert Score : {'precision': [0.8605641722679138], 'recall': [0.8504927754402161], 'f1': [0.8554988503456116], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 19.060520374203357\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMADISON: I should have told him.\\nCOX: Don't blame yourself. In your shoes, I don't think I would have told Parker, either. So do you think Grimes has become the dominant personality?\\nMADISON: I'm not sure. My guess is that's\\nCOX: You think he's smart?\\n\\n\", 'answer': \"Captain, I'm afraid of how smart Sid 6.7 is. But I'm even more afraid of what's he's becoming.\", 'gold_tag': \"MADISON experiences fear concerning Sid 6.7's increased intelligence and evolving nature\", 'last_speaker': 'MADISON'}\n",
      "Last word -> MADISON : \"Captain, I'm afraid of how smart Sid 6.7 is. But I'm even more afraid of what's he's becoming.\"\n",
      "prediction :  Yes, I do.\n",
      "Real answer : Captain, I'm afraid of how smart Sid 6.7 is. But I'm even more afraid of what's he's becoming.\n",
      "Bert Score : {'precision': [0.8952259421348572], 'recall': [0.8393738269805908], 'f1': [0.8664006590843201], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07692307692307691, 'rouge2': 0.0, 'rougeL': 0.07692307692307691, 'rougeLsum': 0.07692307692307691}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 58.91951451550172\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMADISON: There is no way Parker killed those guards. No way.\\nCOX: I think we both know who did. What's so urgent?\\n\\n\", 'answer': 'I need your help--', 'gold_tag': \"MADISON seeks help from COX , MADISON implies a certain level of trust or reliance on COX's abilities\", 'last_speaker': 'MADISON'}\n",
      "Last word -> MADISON : \"I need your help--\"\n",
      "prediction :  It's just that he's been acting weird lately. Ever since he got back from that trip with you.\n",
      "Real answer : I need your help--\n",
      "Bert Score : {'precision': [0.8244996666908264], 'recall': [0.8286416530609131], 'f1': [0.8265655040740967], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 12.209355606307685\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCOX: Why didn't anybody tell me?!\\nMADISON: I don't set policy. You have the key?\\n\\n\", 'answer': \"This is a police department. I'll be damned if this is going to go on without my knowledge.\", 'gold_tag': 'COX works at a police department', 'last_speaker': 'COX'}\n",
      "Last word -> COX : \"This is a police department. I'll be damned if this is going to go on without my knowledge.\"\n",
      "prediction :  What's the key?\n",
      "Real answer : This is a police department. I'll be damned if this is going to go on without my knowledge.\n",
      "Bert Score : {'precision': [0.8340264558792114], 'recall': [0.8528189063072205], 'f1': [0.8433180451393127], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 93.79320347669515\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nONE TWO: He can't get the planing.\\n\\n\", 'answer': \"He can't get the planing?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'MUMBLES'}\n",
      "Last word -> MUMBLES : \"He can't get the planing?\"\n",
      "prediction :  What's that?\n",
      "Real answer : He can't get the planing?\n",
      "Bert Score : {'precision': [0.8470413684844971], 'recall': [0.8194150924682617], 'f1': [0.8329992890357971], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 87.94740186916538\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nONE TWO: We gotta sell.\\nMUMBLES: And be left with what?\\n\\n', 'answer': 'Just gotta start again,....', 'gold_tag': 'ONE TWO is a risk-taker', 'last_speaker': 'ONE TWO'}\n",
      "Last word -> ONE TWO : \"Just gotta start again,....\"\n",
      "prediction :  We gotta get out.\n",
      "Real answer : Just gotta start again,....\n",
      "Bert Score : {'precision': [0.9193748831748962], 'recall': [0.8923202753067017], 'f1': [0.9056456089019775], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}\n",
      "bleu 1/2 : 0.25 0.09128709291752769\n",
      "ppl : 154.18036691294714\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nONE TWO: You know the lady, the posh one who\\nMUMBLES: The accountant, what about her? You haven't heard from her in a while, too dangerous that one.\\nONE TWO: Says she's got some work, you know,... proper work. I would normally turn her down, but considering,...\\n\\n\", 'answer': \"Let's have a meet.\", 'gold_tag': 'MUMBLES is likely involved in work outside of traditional legal frameworks', 'last_speaker': 'MUMBLES'}\n",
      "Last word -> MUMBLES : \"Let's have a meet.\"\n",
      "prediction : ... She's got a kid, a little one.\n",
      "Real answer : Let's have a meet.\n",
      "Bert Score : {'precision': [0.8763969540596008], 'recall': [0.8960311412811279], 'f1': [0.8861053586006165], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3076923076923077, 'rouge2': 0.0, 'rougeL': 0.3076923076923077, 'rougeLsum': 0.3076923076923077}\n",
      "bleu 1/2 : 0.12500000000000003 0.04225771273642583\n",
      "ppl : 29.247446330849744\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMUMBLES: We\\'ll use rock salt in the shot gun cartridges. Slip \\'em into the revolver, if it starts getting large, we\\'ll bang a couple in to \\'em and that\\'ll slow \\'em down. They won\\'t know the difference between lead or salt and of course Bob\\'s driving. What? He\\'s our driver, the A-teams not complete without the driver. What\\'s happened between you and Bob?\\nONE TWO: I think there might be something\\nMUMBLES: What\\'s that then? That he\\'s a poof?\\nONE TWO: What? Eh? How did you know?\\nMUMBLES: Everybody knows he\\'s a flamer, you\\'re the only one who doesn\\'t. He loves the boys.\\nONE TWO: What are you talking about, I am losing orientation here Mumbles.\\nMUMBLES: Did he make a pass at you, is this what this is all about? Ok so what\\'s the problem? It was supposed to be his last night so you \"took care\" of him, that\\'s what friends do for one another, well done, I won\\'t tell the chaps.\\nONE TWO: Hold on a minute, you won\\'t tell the chaps what?\\nMUMBLES: What did you do? Suck his,...\\nONE TWO: Stop right fuckin there! What is going on here? Does that mean you\\'ve sucked his,...\\nMUMBLES: Well, you must have touched him.\\nONE TWO: Hold on! I am not fucking gay! He wanted a dance that\\'s all!\\n\\n', 'answer': 'Did you give him one?', 'gold_tag': 'MUMBLES is knowledgeable about the personal lives of the people around him, including those of his teammates', 'last_speaker': 'MUMBLES'}\n",
      "Last word -> MUMBLES : \"Did you give him one?\"\n",
      "prediction :  You're going to have to get the gear from the store.\n",
      "Real answer : Did you give him one?\n",
      "Bert Score : {'precision': [0.8764073848724365], 'recall': [0.8670403957366943], 'f1': [0.8716987371444702], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 21.42272789769022\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEVA: Hey Celia, come on now, time for bed...\\n\\n', 'answer': 'Just a bit longer mommy...', 'gold_tag': \"CELIA refers to her mother as 'mommy' , This indicates a close relationship between CELIA and EVA , CELIA's bedtime is soon\", 'last_speaker': 'CELIA'}\n",
      "Last word -> CELIA : \"Just a bit longer mommy...\"\n",
      "prediction :  I can'\n",
      "Real answer : Just a bit longer mommy...\n",
      "Bert Score : {'precision': [0.8333034515380859], 'recall': [0.7959449887275696], 'f1': [0.8141959309577942], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 202.73112394865424\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEVA: Right let’s put you to bed... want to say good night to Snuffles?\\nCELIA: He’s hiding.\\nEVA: I can’t see him anywhere...\\nCELIA: It’s my fault, I thought I closed the door... Kevin says I’m stupid and he’s right... stupid, stupid stupid!\\n\\n', 'answer': 'Don’t worry honey... I’m sure we’ll find him... She doesn’t look so sure.', 'gold_tag': 'EVA is trying to reassure her child  , Uncertainty is visible', 'last_speaker': 'EVA'}\n",
      "Last word -> EVA : \"Don’t worry honey... I’m sure we’ll find him... She doesn’t look so sure.\"\n",
      "prediction :  It’s okay, Celia...\n",
      "Real answer : Don’t worry honey... I’m sure we’ll find him... She doesn’t look so sure.\n",
      "Bert Score : {'precision': [0.8898458480834961], 'recall': [0.8731626272201538], 'f1': [0.8814253211021423], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 175.88281061772943\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEVA: Celie... when you got hurt? What happened?\\n\\n', 'answer': 'I got something in my eye...Kevin helped me wash it out. Mommy! Peek a boo!', 'gold_tag': \"CELIA trusts her brother Kevin as he helped her wash out something from her eye , CELIA is a child as reflected by her speech and playing peek a boo , EVA is CELIA's mother , CELIA recently got something in her eye which Kevin helped her wash out\", 'last_speaker': 'CELIA'}\n",
      "Last word -> CELIA : \"I got something in my eye...Kevin helped me wash it out. Mommy! Peek a boo!\"\n",
      "prediction :  I was in a car accident.\n",
      "Real answer : I got something in my eye...Kevin helped me wash it out. Mommy! Peek a boo!\n",
      "Bert Score : {'precision': [0.899055004119873], 'recall': [0.8400466442108154], 'f1': [0.8685497045516968], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2727272727272727, 'rouge2': 0.0, 'rougeL': 0.2727272727272727, 'rougeLsum': 0.2727272727272727}\n",
      "bleu 1/2 : 0.11156508007421491 0.022313016014842986\n",
      "ppl : 46.09019611133076\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORA: Morning.\\nNICOLE: Sleep well?\\n\\n', 'answer': 'Not a wink.', 'gold_tag': \"CORA didn't sleep at all , CORA's recent experience of insomnia\", 'last_speaker': 'CORA'}\n",
      "Last word -> CORA : \"Not a wink.\"\n",
      "prediction :  Like a baby.\n",
      "Real answer : Not a wink.\n",
      "Bert Score : {'precision': [0.9160287380218506], 'recall': [0.9047595858573914], 'f1': [0.910359263420105], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.0, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0.3333333333333333 0.12909944487358058\n",
      "ppl : 714.2127023776027\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICOLE: Dad hit me first and knocked me down. It didn\\'t hurt that much but I started crying anyway, hoping he would leave me alone. He went over and started hitting Danny.\\nCORA: Ellen, I have no memory of this whatsoever.\\nNICOLE: You were just standing there looking at me. Then you pulled me up and said, \"You\\'re not hurt.\" Like I was disgusting for faking, for doing the only thing I could think of to keep him from hitting me again.\\nCORA: I was worried about Danny.\\nNICOLE: You do remember.\\nCORA: He was smaller than you.\\n\\n', 'answer': 'You were so worried about Danny --', 'gold_tag': 'Everyday Language', 'last_speaker': 'NICOLE'}\n",
      "Last word -> NICOLE : \"You were so worried about Danny --\"\n",
      "prediction :  He's still smaller than me, but he's not dead.\n",
      "Real answer : You were so worried about Danny --\n",
      "Bert Score : {'precision': [0.8679949045181274], 'recall': [0.8396811485290527], 'f1': [0.8536033034324646], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 31.56099238420812\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICOLE: Dad hit me first and knocked me down. It didn't hurt that much but I started crying anyway, hoping he would leave me alone. He went over and started hitting Danny.\\n\\n\", 'answer': 'Ellen, I have no memory -- Oh, God!', 'gold_tag': 'Everyday Language', 'last_speaker': 'CORA'}\n",
      "Last word -> CORA : \"Ellen, I have no memory -- Oh, God!\"\n",
      "prediction :  Why did he hit you?\n",
      "Real answer : Ellen, I have no memory -- Oh, God!\n",
      "Bert Score : {'precision': [0.8401600122451782], 'recall': [0.8229682445526123], 'f1': [0.8314753174781799], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 177.02053035483934\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICOLE: Dad hit me first and knocked me down. It didn't hurt that much but I started crying anyway, hoping he would leave me alone. He went over and started hitting Danny.\\n\\n\", 'answer': 'I...', 'gold_tag': 'Everyday Language', 'last_speaker': 'CORA'}\n",
      "Last word -> CORA : \"I...\"\n",
      "prediction :  Oh, no.\n",
      "Real answer : I...\n",
      "Bert Score : {'precision': [0.8815279006958008], 'recall': [0.838432252407074], 'f1': [0.8594401478767395], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 308.762556376757\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICOLE: Dad hit me first and knocked me down. It didn't hurt that much but I started crying anyway --\\nCORA: I was worried about Danny!\\n\\n\", 'answer': \"I'm sorry, I'm lost...\", 'gold_tag': 'Everyday Language', 'last_speaker': 'NICOLE'}\n",
      "Last word -> NICOLE : \"I'm sorry, I'm lost...\"\n",
      "prediction :  I was worried about Danny too.\n",
      "Real answer : I'm sorry, I'm lost...\n",
      "Bert Score : {'precision': [0.8796554803848267], 'recall': [0.8482674956321716], 'f1': [0.8636764287948608], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666666, 'rouge2': 0.0, 'rougeL': 0.16666666666666666, 'rougeLsum': 0.16666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 89.25892232138906\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORA: I was worried about Danny.\\nNICOLE: You do remember.\\nCORA: He was smaller than you.\\n\\n', 'answer': \"You were so worried about Danny. What about me, Mom? Why weren't --\", 'gold_tag': 'NICOLE feels overlooked by her mother in terms of emotional attention , NICOLE possibly shows signs of resentment', 'last_speaker': 'NICOLE'}\n",
      "Last word -> NICOLE : \"You were so worried about Danny. What about me, Mom? Why weren't --\"\n",
      "prediction :  It was not a question of size.\n",
      "Real answer : You were so worried about Danny. What about me, Mom? Why weren't --\n",
      "Bert Score : {'precision': [0.8510416746139526], 'recall': [0.8378621935844421], 'f1': [0.8444005846977234], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 75.14498524277295\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNICOLE: I am so hungry.\\n\\n', 'answer': 'Oh, I thought this was the TV room.', 'gold_tag': 'Everyday Language', 'last_speaker': 'CORA'}\n",
      "Last word -> CORA : \"Oh, I thought this was the TV room.\"\n",
      "prediction :  Mom, I am so sorry. I had no idea you were hungry.\n",
      "Real answer : Oh, I thought this was the TV room.\n",
      "Bert Score : {'precision': [0.8625169992446899], 'recall': [0.877810001373291], 'f1': [0.8700962662696838], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1, 'rouge2': 0.0, 'rougeL': 0.1, 'rougeLsum': 0.1}\n",
      "bleu 1/2 : 0.08333333333333333 0.027524094128159027\n",
      "ppl : 19.924042073566863\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMUMFORD (V.O.): But I sure didn't want to be a Revenue Officer, where you were face to face abusing -- and getting abused -- all day long... ...And being a Collection Agent was definitely not in my genetic make- up... But there was one job that looked like it might be fun -- Investigator.\\n\\n\", 'answer': 'Are you telling me your last job before becoming a psychologist was --', 'gold_tag': 'Everyday Language', 'last_speaker': 'SKIP (V.O.)'}\n",
      "Last word -> SKIP (V.O.) : \"Are you telling me your last job before becoming a psychologist was --\"\n",
      "prediction :  Mom, I got a job.\n",
      "Real answer : Are you telling me your last job before becoming a psychologist was --\n",
      "Bert Score : {'precision': [0.8877602815628052], 'recall': [0.8368782997131348], 'f1': [0.8615687489509583], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.23529411764705882, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.04037930359893108 0.014276239697197267\n",
      "ppl : 73.02135510488401\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMUMFORD (V.O.): Of course, him being insane didn't make it all right that I fell in love with his wife.\\n\\n\", 'answer': 'Holy shit!', 'gold_tag': \"SKIP V.O.'s reaction implies he is surprised or shocked by this revelation\", 'last_speaker': 'SKIP (V.O.)'}\n",
      "Last word -> SKIP (V.O.) : \"Holy shit!\"\n",
      "prediction :  Of course not, Mumford.\n",
      "Real answer : Holy shit!\n",
      "Bert Score : {'precision': [0.8332394361495972], 'recall': [0.8366959095001221], 'f1': [0.8349640965461731], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 152.3156059840148\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMUMFORD (V.O.): With desktop publishing, you don't have to deal with printers, supply houses, or pesky government agencies. Eventually you do have to get your hands on a typewriter. Ever seen one of those, Skip?\\n\\n\", 'answer': 'Is that like a mimeograph?... What about the name?', 'gold_tag': 'SKIP V.O. may lack experience or knowledge with old technology', 'last_speaker': 'SKIP (V.O.)'}\n",
      "Last word -> SKIP (V.O.) : \"Is that like a mimeograph?... What about the name?\"\n",
      "prediction :  Yeah, I've seen 'em. They're like a cross between a typewriter and a sewing machine. You know, with keys that punch holes in a sheet of paper.\n",
      "Real answer : Is that like a mimeograph?... What about the name?\n",
      "Bert Score : {'precision': [0.837341845035553], 'recall': [0.8588454127311707], 'f1': [0.8479573130607605], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15789473684210528, 'rouge2': 0.05555555555555556, 'rougeL': 0.10526315789473684, 'rougeLsum': 0.10526315789473684}\n",
      "bleu 1/2 : 0.11111111111111109 0.06537204504606134\n",
      "ppl : 5.861254123901874\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMUMFORD (V.O.): ...Mickey Mumford was in Miss Rice's kindergarten class with me. He was killed with his parents in a wreck on their way back from a Steelers game. He was only six years old, which is a real plus, so there's a birth certificate if anyone checks -- but not much else. They died in Pennsylvania, so there's no death certificate in West Virginia... that's also good.\\nSKIP (V.O.): And a birth certificate is enough?\\n\\n\", 'answer': \"Everything flows from that, and what Of course, my IRS training made it easier. Once you've done that, there's not much data you can't access and use any way you want.\", 'gold_tag': 'MUMFORD V.O. has a background in IRS training , MUMFORD V.O. is good at data manipulation , MUMFORD V.O. is likely involved in identity theft', 'last_speaker': 'MUMFORD (V.O.)'}\n",
      "Last word -> MUMFORD (V.O.) : \"Everything flows from that, and what Of course, my IRS training made it easier. Once you've done that, there's not much data you can't access and use any way you want.\"\n",
      "prediction :  It's a good start.\n",
      "Real answer : Everything flows from that, and what Of course, my IRS training made it easier. Once you've done that, there's not much data you can't access and use any way you want.\n",
      "Bert Score : {'precision': [0.884056806564331], 'recall': [0.8290899991989136], 'f1': [0.8556916117668152], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10256410256410256, 'rouge2': 0.0, 'rougeL': 0.10256410256410256, 'rougeLsum': 0.10256410256410256}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 51.88076707556782\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPROTAGONIST: You really want to know?\\nNEIL: I'm not sure.\\nPROTAGONIST: Bring some lead-lined gloves.\\nNEIL: Jesus. Nuclear?\\n\\n\", 'answer': \"When you're on the tour �\", 'gold_tag': 'The PROTAGONIST demonstrates knowledge about nuclear complications', 'last_speaker': 'PROTAGONIST'}\n",
      "Last word -> PROTAGONIST : \"When you're on the tour �\"\n",
      "prediction :  I'm not sure.\n",
      "Real answer : When you're on the tour �\n",
      "Bert Score : {'precision': [0.8530936241149902], 'recall': [0.851816713809967], 'f1': [0.8524547219276428], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 48.78926453800242\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEIL: Vault doors are fireproof, hydraulic closers, simple key and electronic triggers. Surprisingly easy, once there's a lockdown.\\nPROTAGONIST: Why a lockdown?\\nNEIL: Power switches to fail-safe, sealing outer doors, but inner\\nPROTAGONIST: Child's play? They're inside airport security. They have to worry about climate control, not armed raids.\\n\\n\", 'answer': 'So how do we get fire power through the perimeter to trigger a lockdown?', 'gold_tag': 'NEIL possesses extensive knowledge on security systems, specifically vault doors and their mechanisms', 'last_speaker': 'NEIL'}\n",
      "Last word -> NEIL : \"So how do we get fire power through the perimeter to trigger a lockdown?\"\n",
      "prediction :  And the doors are too thick, the wrong size. I can't get them open.\n",
      "Real answer : So how do we get fire power through the perimeter to trigger a lockdown?\n",
      "Bert Score : {'precision': [0.8620402812957764], 'recall': [0.8679019808769226], 'f1': [0.8649611473083496], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1379310344827586, 'rouge2': 0.0, 'rougeL': 0.0689655172413793, 'rougeLsum': 0.0689655172413793}\n",
      "bleu 1/2 : 0.14285714285714285 0.033149677206589796\n",
      "ppl : 25.128061134577752\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEIL: Back wall of the freeport...\\nPROTAGONIST: You've got something?\\n\\n\", 'answer': \"You're not going to like it.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'NEIL'}\n",
      "Last word -> NEIL : \"You're not going to like it.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : You're not going to like it.\n",
      "Bert Score : {'precision': [0.9142755270004272], 'recall': [0.824416995048523], 'f1': [0.8670242428779602], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPROTAGONIST: Don't touch them �\\nNEIL: What the hell happened here?\\n\\n\", 'answer': \"It hasn't happened, yet.\", 'gold_tag': 'PROTAGONIST indicates something that has not happened yet', 'last_speaker': 'PROTAGONIST'}\n",
      "Last word -> PROTAGONIST : \"It hasn't happened, yet.\"\n",
      "prediction :  They were just going to be in the way, so I got rid of them.\n",
      "Real answer : It hasn't happened, yet.\n",
      "Bert Score : {'precision': [0.858700692653656], 'recall': [0.8790649771690369], 'f1': [0.8687635660171509], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.414949936206835\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPROTAGONIST: What happened to the other guy?\\n\\n', 'answer': 'I took care of him.', 'gold_tag': 'NEIL is capable and confident , NEIL takes care of the other guy', 'last_speaker': 'NEIL'}\n",
      "Last word -> NEIL : \"I took care of him.\"\n",
      "prediction :  I'm not sure.\n",
      "Real answer : I took care of him.\n",
      "Bert Score : {'precision': [0.871139407157898], 'recall': [0.8648607134819031], 'f1': [0.8679887652397156], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.22222222222222224, 'rougeLsum': 0.22222222222222224}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 48.78926453800242\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEIL: Mahir and Rohan slipped out clean. I've seen too much and I'm still alive. Which means you've decided to trust me.\\nPROTAGONIST: Or I've lost my edge.\\nNEIL: Oh, your edge is intact.\\nPROTAGONIST: There's a cold war.\\nNEIL: Nuclear?\\nPROTAGONIST: Temporal.\\nNEIL: Time travel?\\nPROTAGONIST: No. Technology that can invert an object's entropy.\\nNEIL: You mean reverse chronology. Like Feynman and Wheeler's notion that a positron is an electron moving backwards in time.\\nPROTAGONIST: Sure, that's exactly what I meant.\\nNEIL: I've a master's in physics.\\nPROTAGONIST: Well, try to keep up.\\nNEIL: The implications of this are �\\nPROTAGONIST: Beyond secret.\\nNEIL: Then why'd you take me in?\\nPROTAGONIST: I thought we'd find the drawing and a couple boxes of bullets.\\nNEIL: You were as surprised as I was.\\nPROTAGONIST: I'm going back to Mumbai for answers. I'll set you up as go- between. But remember � to you, all this is about plutonium. Or when we're done, they'll kill you.\\nNEIL: Won't you have to anyway?\\nPROTAGONIST: I'd rather it was my decision.\\n\\n\", 'answer': 'So would I. I think.', 'gold_tag': 'Everyday Language', 'last_speaker': 'NEIL'}\n",
      "Last word -> NEIL : \"So would I. I think.\"\n",
      "prediction :  I'm just a science teacher.\n",
      "Real answer : So would I. I think.\n",
      "Bert Score : {'precision': [0.8767197132110596], 'recall': [0.8630006909370422], 'f1': [0.869806170463562], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1818181818181818, 'rouge2': 0.0, 'rougeL': 0.1818181818181818, 'rougeLsum': 0.1818181818181818}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 57.08608732580639\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPROTAGONIST: What did you find on the gold?\\nNEIL: Three hundred thousand at today's price, no franks, mould marks. Nothing. Like it came from outer space.\\nPROTAGONIST: Or the future.\\nNEIL: How?\\nPROTAGONIST: Dead drops. He buries his time capsule, transmits the location, then digs it up to collect whatever inverted material they've sent. Someplace that won't be disturbed for centuries. What did the soil sample show?\\nNEIL: Northern Europe or Asia, radioactive. Dried blood was European.\\nPROTAGONIST: Pretty broad.\\nNEIL: This is the start of the run.\\nPROTAGONIST: When does the material arrive?\\nNEIL: Thursday. When does Sator arrive?\\nPROTAGONIST: I don't know. But he'll be here.\\nNEIL: Cargo's in a reinforced truck. Nuclear police front and back � SUVs with serious armour � you can't break in through the windows.\\nPROTAGONIST: And they can't break out.\\nNEIL: I don't follow.\\nPROTAGONIST: You will. So, light convoy through downtown, what's the thinking?\\nNEIL: A crowded, unpredictable traffic pattern makes planning an ambush almost impossible.\\nPROTAGONIST: They have a point. Is the convoy monitored from the air?\\n\\n\", 'answer': 'No, tracked by GPS � a wrong turn or an unscheduled stop, in comes the cavalry.', 'gold_tag': 'Everyday Language', 'last_speaker': 'NEIL'}\n",
      "Last word -> NEIL : \"No, tracked by GPS � a wrong turn or an unscheduled stop, in comes the cavalry.\"\n",
      "prediction :  All the time.\n",
      "Real answer : No, tracked by GPS � a wrong turn or an unscheduled stop, in comes the cavalry.\n",
      "Bert Score : {'precision': [0.8385246992111206], 'recall': [0.8138567805290222], 'f1': [0.8260066509246826], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0.004374576245646989 0.0016942660946105358\n",
      "ppl : 387.10478230108004\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNEIL: You in pain?\\nPROTAGONIST: Must've got nicked in Tallinn. I've been thinking... we're their ancestors. If they destroy us, won't that destroy them?\\nNEIL: Bringing us to the grandfather paradox.\\nPROTAGONIST: The what?\\nNEIL: The classic thought experiment � if you went back in time and killed your own grandfather, how could you have been born to commit the act? There is no answer, it's a paradox. But in the future, those in power clearly believe that you can kick Grandpa down the stairs, gouge his eyes and slit his throat without consequence.\\nPROTAGONIST: Could they be right?\\nNEIL: It doesn't matter. They believe it, so they're willing to destroy us. Can I go back to sleep?\\nPROTAGONIST: No. I thought of something else.\\nNEIL: Great.\\nPROTAGONIST: This reversing the flow of time... doesn't us being here now mean it never happens? That we stop them?\\nNEIL: Optimistically, I'd say that's right.\\nPROTAGONIST: Pessimistically?\\nNEIL: In a parallel-worlds theory, we can't know the relationship between consciousness and multiple realities. Does your head hurt yet?\\nPROTAGONIST: Yes.\\n\\n\", 'answer': 'Try sleep.', 'gold_tag': 'NEIL is somewhat tired and irritable', 'last_speaker': 'NEIL'}\n",
      "Last word -> NEIL : \"Try sleep.\"\n",
      "prediction :  Told you it would.\n",
      "Real answer : Try sleep.\n",
      "Bert Score : {'precision': [0.8423214554786682], 'recall': [0.9020630121231079], 'f1': [0.8711691498756409], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 311.60457043906723\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPROTAGONIST: You knew it was me coming out of that vault. Why didn't you say?\\nNEIL: That's a lot of explaining when someone's about to put a bullet in their own brain. With things the same, I knew you'd be okay. What's happened happened. If I'd told you and you acted differently... who knows? The policy is to suppress.\\nPROTAGONIST: Whose policy?\\n\\n\", 'answer': \"Ours, my friend. We're the people saving the world from what might have been...\", 'gold_tag': 'NEIL is part of an organization aiming to save the world', 'last_speaker': 'NEIL'}\n",
      "Last word -> NEIL : \"Ours, my friend. We're the people saving the world from what might have been...\"\n",
      "prediction :  The company's.\n",
      "Real answer : Ours, my friend. We're the people saving the world from what might have been...\n",
      "Bert Score : {'precision': [0.8681286573410034], 'recall': [0.8150749206542969], 'f1': [0.8407657146453857], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1111111111111111, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 352.00976089511374\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPHIL: How's today then?\\nEARL: Fuckin' bullshit is what this is.\\n\\n\", 'answer': \"Fuckin' bullshit is right, in'it?\", 'gold_tag': \"PHIL agrees with EARL's sentiment\", 'last_speaker': 'PHIL'}\n",
      "Last word -> PHIL : \"Fuckin' bullshit is right, in'it?\"\n",
      "prediction :  So, what's the problem?\n",
      "Real answer : Fuckin' bullshit is right, in'it?\n",
      "Bert Score : {'precision': [0.8532794713973999], 'recall': [0.774900496006012], 'f1': [0.8122034072875977], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 31.56113535434417\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEARL: I'm onna need your help, Phil. ...you gotta help me something today...\\n\\n\", 'answer': \"I'II take care of anything, Earl.\", 'gold_tag': 'PHIL is willing to help Earl', 'last_speaker': 'PHIL'}\n",
      "Last word -> PHIL : \"I'II take care of anything, Earl.\"\n",
      "prediction :  Sure, what do you need?\n",
      "Real answer : I'II take care of anything, Earl.\n",
      "Bert Score : {'precision': [0.8358811140060425], 'recall': [0.8164926171302795], 'f1': [0.8260731101036072], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 27.031595042726092\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEARL: ...n\\'I dowanna do this...sit here, I can see the things, y\\'know...it\\'s gettin\\' there that\\'s the cocksucker...like...I see that pen...I see it, I know it\\'s there, I reach out for it -- no -- ...no...no goddamn use. I have a son, y\\'know?\\nPHIL: You do?\\nEARL: ...ah...\\nPHIL: Where is he?\\nEARL: I don\\'t know...I mean, he\\'s around, he\\'s here, in town, y\\'know, but I don\\'t know...he\\'s a tough one...very.... Do you have a girlfriend, Phil?\\nPHIL: No.\\nEARL: Get a girlfriend.\\nPHIL: I\\'m trying.\\nEARL: And do good things with her...share the thing...all that bullshit is true, y\\'know...find someone and hold on all that...Where\\'s Linda?\\nPHIL: She went out. She said she went out to run some errands. She\\'ll be back.\\nEARL: She\\'s a good girl. She\\'s a little nuts, but she\\'s a good girl I think. She\\'s a little daffy.\\nPHIL: She loves you.\\nEARL: ...ah...maybe...yeah...she\\'s a good one...\\nPHIL: When was the last time you talked to your son?\\nEARL: ....I dunn...o....maybe ten...five, fuck, fuck....that\\'s another thing that goes --\\nPHIL: -- memory?\\nEARL: Time lines, y\\'know? I remember things but not so -- right there -- y\\'know?\\nPHIL: Yeah.\\nEARL: \"yeah.\" the fuck do you know?\\nPHIL: I\\'ve seen it before.\\nEARL: Other fuckin\\' assholes like me.\\nPHIL: There\\'s no asshole like you.\\nEARL: ...cocksucker....\\nPHIL: How come every word you say is either \"cocksucker,\" or \"shitballs,\" or \"fuck?\"\\nEARL: Do me a personal favor --\\nPHIL: Go fuck myself?\\nEARL: You got it. ...I can\\'t hold onto this anymore...\\nPHIL: I\\'ll get you another pain pill. Another morphine pill --\\nEARL: ...gimme that fuckin\\' phone...\\nPHIL: Who are you gonna call?\\nEARL: I wanna see this...where is he, do you know?\\nPHIL: Who?\\nEARL: Jack.\\nPHIL: Is Jack your son? You wanna call him on the phone? We can call him, I can dial the phone if you can remember the number --\\nEARL: -- it\\'s not him. it\\'s not him. He\\'s the fuckin\\' asshole...Phil..c\\'mere... This is so boring...so goddamn... and dying wish and all that, old man on a bed...fuck...wants one thing:\\nPHIL: It\\'s ok.\\nEARL: ...find him on the...Frank. His name\\'s Frank Mackey --\\nPHIL: Frank Mackey. That\\'s your son?\\n\\n', 'answer': \"that'snotmy name...find Lily, gimmme that, give it -- ifyougimmethat....overonthe....fuck.... I can't hold ontothis anymore...\", 'gold_tag': 'EARL is an older man suffering from an illness that affects his ability to reach and hold things', 'last_speaker': 'EARL'}\n",
      "Last word -> EARL : \"that'snotmy name...find Lily, gimmme that, give it -- ifyougimmethat....overonthe....fuck.... I can't hold ontothis anymore...\"\n",
      "prediction : ...fuckin' Frank...\n",
      "Real answer : that'snotmy name...find Lily, gimmme that, give it -- ifyougimmethat....overonthe....fuck.... I can't hold ontothis anymore...\n",
      "Bert Score : {'precision': [0.8381747007369995], 'recall': [0.7602158784866333], 'f1': [0.7972941398620605], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 138.1555866198837\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nEARL: Phil...Phil... I\\'m onna try and talk...I\\'m atryan say some thing some thing... Do you know Lily? Phil..do you know her?\\nPHIL: No.\\nEARL: ...Lily...?\\nPHIL: No.\\nEARL: She\\'s my love...my life...love of it... In school when you\\'re 12 years old. In school, in six grade....and I saw her and I didn\\'t go to that school...but we met. And my friend knew her...I would say, \"What\\'s that girl?\" \"How\\'s that Lily?\" \"Oh, she\\'s a bad girl...she sleeps with guys...\" My friend would say this....but then sometime...I went to another school, you see? But then...when high school at the end, what\\'s that? What is that? When you get to the end?\\nPHIL: Graduation?\\nEARL: No, no, the grade...the grade that you\\'re in? Yeah...So I go to her school for that for grade twelve...and we meet...she was fuckin...like a doll...porcelain doll...and the hips...child bearing hips...y\\'know that? So beautiful. But I didn\\'t have sex with anyone, you know? I was not...I couldn\\'t do anything...always scared, y\\'know... she was...she had some boyfriends...they liked her y\\'know...but I didn\\'t like that. I couldn\\'t get over that I wasn\\'t a man, but she was a woman. Y\\'see? Y\\'see I didn\\'t make her feel ok about that....I would say, \"How many men you been with?\" She told me, I couldn\\'t take it...take that I wasn\\'t a man....because if I hadn\\'t had sex with women...like as many women as she had men...then I was weak...a boy.... But I loved her...you understand? ....well, of course, I wanted to have sex with her...and I did and we were together....we met...age twelve, but then again...age seventeen...something, somethin... I didn\\'t let her forget that I thought she was a bad...a slut.....a slut I would call her and hit her....I hit her for what she did...but we married...Lily and me and we married...but I cheated on her...over and over and over again...because I wanted to be a man and I couldn\\'t let her be a woman...a smart, free person who was something...my mind then, so fuckin\\' stupid, so fuckin....jesus christ, what would I think...did I think....? ...for what I\\'ve done...She\\'s my wife for thirty eight years...I went behind her... over and over...fucking asshole I am that I would go out and fuck and come His mother Lily...these two that I had and I lost .... and this is the regret that you make...the regret you make is the something that you take...blah...blah...blah... something, something..... Gimme a cigarettee? She had cancer...from her...in her stomach and I didn\\'t go anywhere with her...and I didn\\'t do a god thing... for her and to help her....shit...this bitch...the beautiful, beautiful bitch with perfect skin and child bearing hips and so soft...her namewasLilysee? He liked her though he did, his mom, Frank/Jack...he took care of her and she died. She didn\\'t stick with him and he thinks and he hates me, ok...see...I\\'m...that\\'s then what you get? ....are you still walkin\\' in that car...?\\nPHIL: What? Say it again...walking in the car?\\nEARL: ....getthat on the tv....there... ...mistakes like this are not ok... sometimes you make some, and ok...not sometimes to make other one....know that you should do better....I loved Lily. I cheated on her. For thirty five years. And I have this son. And she has cancer. And I\\'m not there. And he\\'s forced to take care of her. He\\'s fourteen years old to take care of his mother and watch her die on him. Little Kid. And I\\'m not there. And She Dies. And I Live My Life. And I\\'m Not Fair. Thirty eight years and she has cancer and I\\'m gone...I leave...I walk out, I can\\'t deal with that...who am I? Who the fuck do I think I am to go and do a thing? Shit on that and that lovely person. I\\'ll go away...I\\'ll go away...I can\\'t hold this..you gotta take this fuckin\\' pen outta my hand...you fuckin\\' piss, cocksucker... .....atke this.....\\nPHIL: I got it.\\n\\n', 'answer': \"OH FUCK...THIS FUCKIN STORY HAS FALLEN APART and I don't even think I can...I got no punchline -- we had good times later, the best times, the love of my life, I thirty eight years -- but never the respect and the...she knew what I did...she knew... all the stupid things I've done but the LOVE was stronger than anything you can think up.\", 'gold_tag': 'EARL is an elderly man expressing his guilt and regret over his past actions', 'last_speaker': 'EARL'}\n",
      "Last word -> EARL : \"OH FUCK...THIS FUCKIN STORY HAS FALLEN APART and I don't even think I can...I got no punchline -- we had good times later, the best times, the love of my life, I thirty eight years -- but never the respect and the...she knew what I did...she knew... all the stupid things I've done but the LOVE was stronger than anything you can think up.\"\n",
      "prediction : I'm sorry.\n",
      "Real answer : OH FUCK...THIS FUCKIN STORY HAS FALLEN APART and I don't even think I can...I got no punchline -- we had good times later, the best times, the love of my life, I thirty eight years -- but never the respect and the...she knew what I did...she knew... all the stupid things I've done but the LOVE was stronger than anything you can think up.\n",
      "Bert Score : {'precision': [0.8667886257171631], 'recall': [0.7881273627281189], 'f1': [0.8255885243415833], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.028169014084507043, 'rouge2': 0.0, 'rougeL': 0.028169014084507043, 'rougeLsum': 0.028169014084507043}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 24.673721807977625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nPHIL: \"It\\'s not going to stop...it\\'s not going to stop....\"\\n\\n', 'answer': '\"...it\\'s not going to stop \\'till you wise up...\"', 'gold_tag': 'Everyday Language', 'last_speaker': 'EARL'}\n",
      "Last word -> EARL : \"\"...it's not going to stop 'till you wise up...\"\"\n",
      "prediction :  \"What's that?\"\n",
      "Real answer : \"...it's not going to stop 'till you wise up...\"\n",
      "Bert Score : {'precision': [0.8505361080169678], 'recall': [0.7999172806739807], 'f1': [0.8244504928588867], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 62.44120340850815\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROBIN: I could ask you to dance. You could say you don’t feel like dancing right now. I could say, Next time, maybe. And I could\\nDIANA: You could saunter away.\\n\\n', 'answer': 'Or I could just not ask.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROBIN'}\n",
      "Last word -> ROBIN : \"Or I could just not ask.\"\n",
      "prediction :  I could ask you to dance. You could say you don't feel like dancing right now. I could say, Next time, maybe. And I could saunter away.\n",
      "Real answer : Or I could just not ask.\n",
      "Bert Score : {'precision': [0.836866557598114], 'recall': [0.8811618089675903], 'f1': [0.8584432005882263], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.17647058823529413, 'rouge2': 0.0625, 'rougeL': 0.17647058823529413, 'rougeLsum': 0.17647058823529413}\n",
      "bleu 1/2 : 0.07407407407407407 0.05337605126836239\n",
      "ppl : 12.441665114768522\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIANA: So where are we going?\\nROBIN: I thought Maidenhead. I know a rather jolly pub by the river.\\nDIANA: This doesn’t look like a jolly pub by the river.\\nROBIN: No. We seem to have missed our way.\\nDIANA: What a surprise.\\nROBIN: Lucky I packed a bottle of wine and a pork pie.\\nDIANA: Good Lord, is that the time? How do you open the door?\\nROBIN: You don’t.\\nDIANA: But I want to get out.\\nROBIN: No you don’t.\\nDIANA: Don’t I?\\nROBIN: You want to kiss me.\\n\\n', 'answer': 'What makes you think I want to -', 'gold_tag': 'Everyday Language', 'last_speaker': 'DIANA'}\n",
      "Last word -> DIANA : \"What makes you think I want to -\"\n",
      "prediction :  I do.\n",
      "Real answer : What makes you think I want to -\n",
      "Bert Score : {'precision': [0.8973737955093384], 'recall': [0.806073784828186], 'f1': [0.8492770791053772], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.22222222222222224, 'rougeLsum': 0.22222222222222224}\n",
      "bleu 1/2 : 0.024893534183931972 0.01113272692709733\n",
      "ppl : 911.5091418589274\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIANA: They tell me you’ve been learning to talk.\\nROBIN: I’m... sorry.\\nDIANA: That’s not what I want to hear.\\nROBIN: You... are... so... lovely.\\n\\n', 'answer': 'Better.', 'gold_tag': 'Everyday Language', 'last_speaker': 'DIANA'}\n",
      "Last word -> DIANA : \"Better.\"\n",
      "prediction :  You’ve been talking with them?\n",
      "Real answer : Better.\n",
      "Bert Score : {'precision': [0.822959840297699], 'recall': [0.9286205768585205], 'f1': [0.8726032972335815], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 125.92202192976345\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROBIN: Why do you keep on coming?\\nDIANA: I don’t really know.\\nROBIN: I’m no damn use to you... You should leave me to rot.\\nDIANA: It wouldn’t look very good. And apparently I love you.\\nROBIN: Not this... You can’t love this.\\nDIANA: Apparently I can.\\nROBIN: I don’t want you to... It makes it harder for me.\\nDIANA: Yes. I can see that. You’d rather just pack it in, I know.\\nROBIN: Bloody machine keeps on breathing for me.\\nDIANA: So it looks as if you’re going to have to stick around for a while.\\nROBIN: Sorry about that.\\nDIANA: I’m not sorry. I’d like Jonathan to know you. And maybe I can make life a little better for you.\\nROBIN: It’s only duty.\\nDIANA: Yes, all right. We know all about that. Everything is as bad as it could be. Breathe - Blue Revision - 26 June 2016 32. But I can’t go on coming in here and have you saying you wish you were dead. You’re not dead, and that’s that. There must be something I can do to make things more bearable. Beat.\\n\\n', 'answer': 'Get me out of here. He knows it’s impossible as he says it.', 'gold_tag': 'ROBIN wishes to be freed from his current situation', 'last_speaker': 'ROBIN'}\n",
      "Last word -> ROBIN : \"Get me out of here. He knows it’s impossible as he says it.\"\n",
      "prediction :  I don’t know... I just don’t know.\n",
      "Real answer : Get me out of here. He knows it’s impossible as he says it.\n",
      "Bert Score : {'precision': [0.8486642241477966], 'recall': [0.8677837252616882], 'f1': [0.8581174612045288], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 22.257658836710952\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIANA: Robin?\\nROBIN: I go on living here like this... Or I leave here and die.\\nDIANA: Yes.\\n\\n', 'answer': 'What are we waiting for?', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROBIN'}\n",
      "Last word -> ROBIN : \"What are we waiting for?\"\n",
      "prediction :  I can't just sit here and wait to die.\n",
      "Real answer : What are we waiting for?\n",
      "Bert Score : {'precision': [0.8589955568313599], 'recall': [0.8575278520584106], 'f1': [0.8582611083984375], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.238388717933198\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIANA: Good night, darling.\\n\\n', 'answer': 'Good night.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROBIN'}\n",
      "Last word -> ROBIN : \"Good night.\"\n",
      "prediction :  Good night, Diana.\n",
      "Real answer : Good night.\n",
      "Bert Score : {'precision': [0.9277451634407043], 'recall': [0.9868079423904419], 'f1': [0.9563655257225037], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.8, 'rouge2': 0.6666666666666666, 'rougeL': 0.8, 'rougeLsum': 0.8}\n",
      "bleu 1/2 : 0.3333333333333333 0.12909944487358058\n",
      "ppl : 179.6912021109705\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIANA: Bottle?\\nROBIN: Please. You know the Marconi shares I bought?... Justin’s hot tip... They’ve almost doubled in price.\\nDIANA: I hope Justin gets something out of it.\\nROBIN: Of course he does... He gets the agreeable sensation of having helped... someone less fortunate than himself.\\nDIANA: Poor Robin, paralysed for life.\\n\\n', 'answer': 'And his poor wife. I hear she’s a saint. Call Teddy, darling... I’ve had an idea.', 'gold_tag': \"ROBIN is married to DIANA , Shared memories: DIANA and ROBIN both remember ROBIN's acquisition of Marconi shares based on Justin's advice\", 'last_speaker': 'ROBIN'}\n",
      "Last word -> ROBIN : \"And his poor wife. I hear she’s a saint. Call Teddy, darling... I’ve had an idea.\"\n",
      "prediction :  I can still do things. I can still move my hands and feet... I can still move. I can still breathe.\n",
      "Real answer : And his poor wife. I hear she’s a saint. Call Teddy, darling... I’ve had an idea.\n",
      "Bert Score : {'precision': [0.8312604427337646], 'recall': [0.8489290475845337], 'f1': [0.8400018811225891], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.15384615384615383, 'rouge2': 0.0, 'rougeL': 0.15384615384615383, 'rougeLsum': 0.15384615384615383}\n",
      "bleu 1/2 : 0.047619047619047616 0.01543033499620919\n",
      "ppl : 10.240641650125832\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIANA: Harder than a pram, I can tell you.\\n\\n', 'answer': 'Well, Jonathan... We’re going to have to do some more thinking.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROBIN'}\n",
      "Last word -> ROBIN : \"Well, Jonathan... We’re going to have to do some more thinking.\"\n",
      "prediction :  What, you're not going to use your superpowers to lift it?\n",
      "Real answer : Well, Jonathan... We’re going to have to do some more thinking.\n",
      "Bert Score : {'precision': [0.8509297370910645], 'recall': [0.8524027466773987], 'f1': [0.8516656160354614], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3333333333333333, 'rouge2': 0.09090909090909091, 'rougeL': 0.3333333333333333, 'rougeLsum': 0.3333333333333333}\n",
      "bleu 1/2 : 0.2727272727272727 0.1651445647689541\n",
      "ppl : 22.98090334839969\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIANA: So. Did you enjoy that? You were\\nROBIN: So were you.\\nDIANA: Me?\\nROBIN: Rory Stewart couldn’t take his eyes off you.\\nDIANA: Oh, Rory. Lucy’s really messed him about. I feel so sorry for him. He says he spends his evenings alone, watching television.\\nROBIN: I expect he’d like you to relieve his loneliness.\\nDIANA: Well, I’m not going to.\\nROBIN: You can if you want to.\\nDIANA: Oh. You’re giving me permission, are you?\\nROBIN: I worry that you don’t have much... fun.\\nDIANA: Don’t worry about me. I’m all right. We manage, don’t we?\\nROBIN: Easy for me... I just sit here... You do all the work... Turns out I’m quite enjoying myself.\\nDIANA: Good old selfish Robin.\\nROBIN: But you... Not so much fun for you.\\nDIANA: Turns out I love you.\\nROBIN: I got lucky with you, didn’t I?... I say, Diana. Run away with me.\\nDIANA: Mustn’t overdo it.\\nROBIN: Why not?... I’m supposed to be testing the limits.\\nDIANA: You are. Every day.\\nROBIN: Haven’t reached breaking point yet, have I?... I can go further.\\nDIANA: Go further where?\\nROBIN: Anywhere... Everywhere.\\nDIANA: What is this, Robin? Is this another of your mad projects?\\n\\n', 'answer': 'I’ve always wanted to see the sun rise over the Mediterranean. Breathe - Green Revision - 8 July 2016 63A.', 'gold_tag': 'ROBIN shows interest in seeing the sunrise over the Mediterranean', 'last_speaker': 'ROBIN'}\n",
      "Last word -> ROBIN : \"I’ve always wanted to see the sun rise over the Mediterranean. Breathe - Green Revision - 8 July 2016 63A.\"\n",
      "prediction : \n",
      "Real answer : I’ve always wanted to see the sun rise over the Mediterranean. Breathe - Green Revision - 8 July 2016 63A.\n",
      "Bert Score : {'precision': [0.0], 'recall': [0.0], 'f1': [0.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : nan\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIANA: Oh God! Sorry. Sorry.\\n\\n', 'answer': 'I can go for longer than that.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROBIN'}\n",
      "Last word -> ROBIN : \"I can go for longer than that.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction :  Don't worry. You were great.\n",
      "Real answer : I can go for longer than that.\n",
      "Bert Score : {'precision': [0.882824182510376], 'recall': [0.8592315912246704], 'f1': [0.8708680868148804], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 50.62933854402548\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nDIANA: Lady Jane Neville.\\nROBIN: Good for?\\nDIANA: A thousand at least, if she’s in the mood.\\nROBIN: Am I plucky or pitiful?\\n\\n', 'answer': 'I think plucky. These old dowagers are tough as nails.', 'gold_tag': 'DIANA is aware of the nature of \"old dowagers\" , ROBIN implies potential hardship but a resilient attitude', 'last_speaker': 'DIANA'}\n",
      "Last word -> DIANA : \"I think plucky. These old dowagers are tough as nails.\"\n",
      "prediction :  Plucky.\n",
      "Real answer : I think plucky. These old dowagers are tough as nails.\n",
      "Bert Score : {'precision': [0.9106280207633972], 'recall': [0.8447140455245972], 'f1': [0.8764335513114929], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3731.0691665459253\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROBIN: I heard a story once, in Kenya... about a group of Mau Mau prisoners... sixty of them... Their leader said to his men... ‘I give you permission to die’... The next morning all sixty were dead. No one speaks. It’s just a matter of will... I’ve gone on long enough. August is a good month. When August comes... I’m going to let myself go.\\nDIANA: What about me?\\nROBIN: You’ll be free at last.\\nDIANA: No! NO! You stupid, stupid man! What do you think I’ve been doing all these years? Your life is my life too!\\nROBIN: Let her go.\\n\\n', 'answer': 'All right! Have it your own way! You always do. Just never, ever say you did it for me.', 'gold_tag': \"DIANA expresses deep frustration and a sense of abandonment at ROBIN's decision to let himself die\", 'last_speaker': 'DIANA'}\n",
      "Last word -> DIANA : \"All right! Have it your own way! You always do. Just never, ever say you did it for me.\"\n",
      "prediction :  Get away from me!\n",
      "Real answer : All right! Have it your own way! You always do. Just never, ever say you did it for me.\n",
      "Bert Score : {'precision': [0.86226886510849], 'recall': [0.8437997102737427], 'f1': [0.8529343605041504], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08695652173913043, 'rouge2': 0.0, 'rougeL': 0.08695652173913043, 'rougeLsum': 0.08695652173913043}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 145.32074703070154\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNORAH: Sorry.\\nROSE: I'm gonna be so late.\\nNORAH: I brought fancy corn!\\nROSE: How can you eat that stuff? He'll be hyper all night. Be good. And no lobsterman stories. He had nightmares all week. Just use some common sense.\\n\\n\", 'answer': \"You're welcome.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'NORAH'}\n",
      "Last word -> NORAH : \"You're welcome.\"\n",
      "prediction :  I have some of that.\n",
      "Real answer : You're welcome.\n",
      "Bert Score : {'precision': [0.866844892501831], 'recall': [0.8536803126335144], 'f1': [0.8602122068405151], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 244.08281468959095\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNORAH: It's about time. I thought your class got over at 9:30.\\nROSE: Why isn't he in bed?\\nNORAH: Said he was scared. I think he was fakin' it though. I'm not taking money.\\nROSE: It's just ten bucks, take it. Dad told me about you getting fired. What happened?\\nNORAH: Nothing.\\nROSE: What, were you stoned or something?\\nNORAH: It was just Mr. Kim being a dick head.\\nROSE: I thought you liked Mr. Kim.\\nNORAH: Yeah, before Mrs. Kim started working there. Now he's a full on gym teacher, I swear to God.\\nROSE: When are you going to grow up and start taking responsibility for--\\nNORAH: Oh please, you love it when I fuck up. Love it. Me screwing up gives you the hugest woody.\\nROSE: Shut up and take the ten.\\nNORAH: There was a diner scene earlier.\\nROSE: Any pie?\\n\\n\", 'answer': 'Completely pie free.', 'gold_tag': 'Everyday Language', 'last_speaker': 'NORAH'}\n",
      "Last word -> NORAH : \"Completely pie free.\"\n",
      "prediction :  No.\n",
      "Real answer : Completely pie free.\n",
      "Bert Score : {'precision': [0.9196631908416748], 'recall': [0.8511548638343811], 'f1': [0.8840838670730591], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1275.3241709894667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNORAH: Think they loved each other?\\n\\n', 'answer': 'Yeah.', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"Yeah.\"\n",
      "prediction :  It's possible.\n",
      "Real answer : Yeah.\n",
      "Bert Score : {'precision': [0.8796440362930298], 'recall': [0.9394582509994507], 'f1': [0.9085677266120911], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 113.21326255026597\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNORAH: You suck.\\nROSE: Money.\\nNORAH: You still suck.\\nROSE: Apparently some crazy bag lady squatter person died and--\\nNORAH: You didn't get me coffee?\\nROSE: I didn't know you wanted any.\\n\\n\", 'answer': 'Of course I...', 'gold_tag': 'NORAH likes coffee', 'last_speaker': 'NORAH'}\n",
      "Last word -> NORAH : \"Of course I...\"\n",
      "prediction :  Didn't know? I'm your wife, you know what I want.\n",
      "Real answer : Of course I...\n",
      "Bert Score : {'precision': [0.8195996284484863], 'recall': [0.8131693601608276], 'f1': [0.8163718581199646], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 39.0789829739364\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNORAH: How long is this gonna take?\\n\\n', 'answer': 'All we have to do is go in and throw everything away. Cake.', 'gold_tag': 'ROSE is in a job that involves cleaning or decluttering , ROSE mentioned throwing everything away', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"All we have to do is go in and throw everything away. Cake.\"\n",
      "prediction :  At least a couple of hours.\n",
      "Real answer : All we have to do is go in and throw everything away. Cake.\n",
      "Bert Score : {'precision': [0.8595052361488342], 'recall': [0.8630626797676086], 'f1': [0.8612802624702454], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 133.58770447403182\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: Where are you going?\\nNORAH: There is no way.\\nROSE: You said you would help me.\\n\\n', 'answer': \"Maybe if you'd gotten me a coffee.\", 'gold_tag': 'NORAH appreciates coffee as a potential motivator', 'last_speaker': 'NORAH'}\n",
      "Last word -> NORAH : \"Maybe if you'd gotten me a coffee.\"\n",
      "prediction :  I know. I did.\n",
      "Real answer : Maybe if you'd gotten me a coffee.\n",
      "Bert Score : {'precision': [0.8709114789962769], 'recall': [0.8205967545509338], 'f1': [0.8450057506561279], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 250.56607260018689\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNORAH: What do we do with that?\\n\\n', 'answer': 'Dumpster?', 'gold_tag': 'Everyday Language', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"Dumpster?\"\n",
      "prediction :  I don't know.\n",
      "Real answer : Dumpster?\n",
      "Bert Score : {'precision': [0.822760283946991], 'recall': [0.7863667011260986], 'f1': [0.8041519522666931], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 52.19149636039691\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNORAH: It seems wrong though doesn't it... to throw everything away. I bet this is her. Wow, look at this. Think it's her daughter? Shouldn't we do something? Try to find her or something?\\nROSE: That's none of your business, Norah. Hand me that.\\nNORAH: What if she doesn't know? Wouldn't you want to know if this was mom?\\n\\n\", 'answer': 'Mom was never like this. Mom would never have been like this. Damnit Norah, we still have a lot of shit to do here. Are you just gonna talk?', 'gold_tag': 'ROSE is task-focused and pragmatic , Shared memories: They both share a past where their mother was present, and have differing opinions about her, ROSE is under a certain time pressure to complete identified tasks', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"Mom was never like this. Mom would never have been like this. Damnit Norah, we still have a lot of shit to do here. Are you just gonna talk?\"\n",
      "prediction :  What if she doesn't care?\n",
      "Real answer : Mom was never like this. Mom would never have been like this. Damnit Norah, we still have a lot of shit to do here. Are you just gonna talk?\n",
      "Bert Score : {'precision': [0.8505284786224365], 'recall': [0.8351651430130005], 'f1': [0.8427767753601074], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 54.03771331761592\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNORAH: Turns out it's against the law to throw bio hazards in the dumpster. Who knew? How perfect was he with the one arm?\\nROSE: Hmm?\\nNORAH: The creepy guy. Do you think he was born like that?\\nROSE: I didn't think he was creepy.\\nNORAH: Dude, he has one arm.\\nROSE: They think we're just a couple of hacks.\\nNORAH: We are a couple of hacks. Stop here.\\nROSE: Why?\\n\\n\", 'answer': 'I gotta thing. Just drop me off here.', 'gold_tag': 'NORAH is not easily intimidated', 'last_speaker': 'NORAH'}\n",
      "Last word -> NORAH : \"I gotta thing. Just drop me off here.\"\n",
      "prediction :  Because I'm not sure I can do this anymore.\n",
      "Real answer : I gotta thing. Just drop me off here.\n",
      "Bert Score : {'precision': [0.8531614542007446], 'recall': [0.8692630529403687], 'f1': [0.8611369729042053], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11111111111111112, 'rouge2': 0.0, 'rougeL': 0.11111111111111112, 'rougeLsum': 0.11111111111111112}\n",
      "bleu 1/2 : 0.11111111111111109 0.03726779962499649\n",
      "ppl : 22.50139631828455\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: I'll drop Oscar by around seven.\\nNORAH: You have class tonight?\\nROSE: Mortgage lenders and financing.\\n\\n\", 'answer': \"Heather's pregnant again. Did you know that? He's never going to leave her. God, you're pathetic.\", 'gold_tag': \"NORAH is cynical and critical, particularly towards Rose and her life choices , NORAH is aware of the goings-on within her social circle, as indicated by her knowledge of Heather's pregnancy , Shared memories\", 'last_speaker': 'NORAH'}\n",
      "Last word -> NORAH : \"Heather's pregnant again. Did you know that? He's never going to leave her. God, you're pathetic.\"\n",
      "prediction :  I'm so proud of you.\n",
      "Real answer : Heather's pregnant again. Did you know that? He's never going to leave her. God, you're pathetic.\n",
      "Bert Score : {'precision': [0.8728805780410767], 'recall': [0.8499889373779297], 'f1': [0.8612826466560364], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 32.43096183867757\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: What the hell?\\nNORAH: I just wanted to give her the\\nROSE: You took the pictures? Why would you do that? We could get in a lot of trouble for that.\\n\\n', 'answer': \"Relax, I didn't give them to her.\", 'gold_tag': 'NORAH is unafraid of potential repercussions', 'last_speaker': 'NORAH'}\n",
      "Last word -> NORAH : \"Relax, I didn't give them to her.\"\n",
      "prediction :  I'm sorry. I was just curious.\n",
      "Real answer : Relax, I didn't give them to her.\n",
      "Bert Score : {'precision': [0.8545972108840942], 'recall': [0.8544413447380066], 'f1': [0.8545193076133728], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13333333333333333, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0.141080287481769 0.04887164517296948\n",
      "ppl : 32.19073678972876\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNORAH: I thought you went to the thing.\\nROSE: I did. I mean, I went to part of it. Most of it.\\nNORAH: What do you mean you went to part of it? It was a one day thing.\\nROSE: I got side tracked.\\nNORAH: Side tracked?\\nROSE: That Above and Beyond guy was there. Carl. We got talking shop and--\\nNORAH: Oh my God, you humped Carl!\\nROSE: I'm already registered for the next one.\\n\\n\", 'answer': \"That's disgusting.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'NORAH'}\n",
      "Last word -> NORAH : \"That's disgusting.\"\n",
      "prediction :  So, you're going to the next one?\n",
      "Real answer : That's disgusting.\n",
      "Bert Score : {'precision': [0.8388974666595459], 'recall': [0.8790479898452759], 'f1': [0.858503520488739], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 43.053059224809346\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: You want a Coke?\\n\\n', 'answer': 'Sure.', 'gold_tag': 'Everyday Language', 'last_speaker': 'NORAH'}\n",
      "Last word -> NORAH : \"Sure.\"\n",
      "prediction :  No thanks, Rose.\n",
      "Real answer : Sure.\n",
      "Bert Score : {'precision': [0.8631644248962402], 'recall': [0.9321416020393372], 'f1': [0.8963279724121094], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 502.6849091067117\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: I can't I... I RSVPed.\\nNORAH: So tell him we can't do it.\\nROSE: It's an insurance company. They could throw us a ton of work. This is our in.\\nNORAH: So, don't go to the damn baby shower. It's not like you ever even liked Paula.\\n\\n\", 'answer': \"I promise I'll come straight after the shower and help finish up.\", 'gold_tag': 'ROSE has a baby shower to attend and plans to help NORAH with work after the shower', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"I promise I'll come straight after the shower and help finish up.\"\n",
      "prediction :  She's not going to get a baby shower.\n",
      "Real answer : I promise I'll come straight after the shower and help finish up.\n",
      "Bert Score : {'precision': [0.873445987701416], 'recall': [0.8582354187965393], 'f1': [0.8657739162445068], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09090909090909093, 'rouge2': 0.0, 'rougeL': 0.09090909090909093, 'rougeLsum': 0.09090909090909093}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 36.718423687567515\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nROSE: Hello, you've reached Sunshine Cleaning. You're call is very important to us so...\\n\\n\", 'answer': 'FUCK!', 'gold_tag': 'Everyday Language', 'last_speaker': 'NORAH'}\n",
      "Last word -> NORAH : \"FUCK!\"\n",
      "prediction :  Hi, is this Norah?\n",
      "Real answer : FUCK!\n",
      "Bert Score : {'precision': [0.8290327787399292], 'recall': [0.8785040378570557], 'f1': [0.8530517220497131], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 142.94699101356466\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNORAH: It was an accident.\\nROSE: Oh my God, what have you done?\\nNORAH: It was an accident.\\nROSE: How does this happen? Huh? How do you burn down a house, Norah? Jesus fucking Christ!\\nNORAH: Jesus Rose, Calm down. Well, if you had been here to help me but no, you're off desperately trying to impress stupid high school people who don't even matter. Prove to your old cheerleading squad that you're not this huge loser. If you had been here doing your job it wouldn't have happened. So don't try to put all this on me.\\nROSE: This is on you. You did this. You set a fucking house on fire! You.\\nNORAH: Oh, go ahead and play the martyr. It's like your favorite thing.\\nROSE: I can't believe I was so stupid to think that you could handle a little bit of responsibility.\\nNORAH: I am so sick of all your holier than thou bullshit. Why don't you take a look at you're own life, huh? You're a real inspiration.\\nROSE: Well maybe if I didn't have to take care of everybody in this family.\\nNORAH: Fuck you. I'm done being your excuse.\\n\\n\", 'answer': \"Oh that's great. Turn everything to shit and then walk away.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ROSE'}\n",
      "Last word -> ROSE : \"Oh that's great. Turn everything to shit and then walk away.\"\n",
      "prediction :  So you burned down the house.\n",
      "Real answer : Oh that's great. Turn everything to shit and then walk away.\n",
      "Bert Score : {'precision': [0.893419623374939], 'recall': [0.8669599890708923], 'f1': [0.8799909949302673], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 104.43648845255534\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nNORAH: I read somewhere that beauty is really all about symmetry. Like having eyes the same size and all that. So, you know, when you factor that in he's like, hot. Listen, I know I fucked up, okay? Like really huge and I know that and I'm sorry, okay?\\nROSE: God, that drives me crazy! That whole `Oh, I'm sorry, I'm just a big fuck up' routine. Like that's a legitimate excuse.\\nNORAH: I really am sorry. But it really isn't all my fault, Rose.\\nROSE: I think there's something wrong with you. The way your brain works. I mean, what the hell? It's like you can't be trusted with anything. You just screw around all the time like it's all a big fucking game. It wasn't a game, Norah. We're not all just here for your amusement. You should have been paying attention. You should have been focused on the job.\\nNORAH: You finished?\\nROSE: I know. I should have been there.\\nNORAH: What are you going to do now?\\nROSE: I got some ideas. I was thinking maybe we could--\\nNORAH: I've got my own ideas.\\nROSE: So, you really think he's hot?\\n\\n\", 'answer': 'Winston? No.', 'gold_tag': 'NORAH has an interest in a person named Winston', 'last_speaker': 'NORAH'}\n",
      "Last word -> NORAH : \"Winston? No.\"\n",
      "prediction :  I'm sorry.\n",
      "Real answer : Winston? No.\n",
      "Bert Score : {'precision': [0.861449122428894], 'recall': [0.865196943283081], 'f1': [0.863318920135498], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 70.196163546962\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHARLENE: Did the Jewish black guy do this to you?\\nMICKY: I didn't get to fight the Jewish black guy.\\nCHARLENE: You didn't go head-body-head.\\nMICKY: He got the flu, the guy who took his place had 16 pounds on me, I nevah shoulda fought him.\\nCHARLENE: So why'd you fight him?\\nMICKY: Nobody woulda got paid. Everybody said I could beat 'im.\\nCHARLENE: Who's everybody?\\nMICKY: My mothah and my brothah.\\n\\n\", 'answer': 'So are you gonna take me to dinnah and movie tonight or what?', 'gold_tag': 'Everyday Language', 'last_speaker': 'CHARLENE'}\n",
      "Last word -> CHARLENE : \"So are you gonna take me to dinnah and movie tonight or what?\"\n",
      "prediction :  Is that what you want?\n",
      "Real answer : So are you gonna take me to dinnah and movie tonight or what?\n",
      "Bert Score : {'precision': [0.8484628200531006], 'recall': [0.7884448766708374], 'f1': [0.8173535466194153], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2222222222222222, 'rouge2': 0.0, 'rougeL': 0.1111111111111111, 'rougeLsum': 0.1111111111111111}\n",
      "bleu 1/2 : 0.04037930359893108 0.014276239697197267\n",
      "ppl : 63.78211076069327\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMICKY: Wow, you look great. You got a nice house.\\nCHARLENE: Thanks. It's an apahtment building.\\nMICKY: Oh.\\nCHARLENE: There's five of 'em in there, one-a my old roommates lives in one.\\nMICKY: Old roommates from where?\\nCHARLENE: College, but a lot a good it did me, I'm workin' in a bah.\\nMICKY: You seem to enjoy it. You're very populah down there -\\nCHARLENE: Uh yuh. Popular. I need to get the hell outta that place. If I don't drink while I'm workin' I'd kill myself -\\nMICKY: What college?\\nCHARLENE: U.R.I. Full boat.\\nMICKY: Scholarship? For what?\\nCHARLENE: I was a high jumpah.\\nMICKY: A high jumpah?! You gotta be kiddin' me.\\nCHARLENE: Fuck you, I cleahed 5-10, I was New England Champ, but so what, I nevah graduated. I pahtied too much.\\n\\n\", 'answer': 'You?!', 'gold_tag': 'MICKY is fascinated by CHARLENE', 'last_speaker': 'MICKY'}\n",
      "Last word -> MICKY : \"You?!\"\n",
      "prediction :  So you're saying you're a high jumper.\n",
      "Real answer : You?!\n",
      "Bert Score : {'precision': [0.8509284257888794], 'recall': [0.8206286430358887], 'f1': [0.8355039358139038], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.19999999999999998, 'rouge2': 0.0, 'rougeL': 0.19999999999999998, 'rougeLsum': 0.19999999999999998}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 30.04531142679717\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHARLENE: What the hell we doin' in Richie Rich Lexington? You come to this theatah a lot?\\nMICKY: Oh yuh, it's a good movie theatah. They have good movies.\\nCHARLENE: Like what?\\nMICKY: Bell-ah Epa-cue.\\nCHARLENE: I think Belle Epic is how ya say it and I nevah heard of it. Is it only playin' up here in Lexington?\\nMICKY: Oh yuh. And I heard it's a good movie.\\nCHARLENE: From who?\\n\\n\", 'answer': 'Guy at work -', 'gold_tag': 'MICKY seeks movie recommendations from his colleagues', 'last_speaker': 'MICKY'}\n",
      "Last word -> MICKY : \"Guy at work -\"\n",
      "prediction : My friend. He saw it at the theater and he said it was good.\n",
      "Real answer : Guy at work -\n",
      "Bert Score : {'precision': [0.8481783270835876], 'recall': [0.8233816027641296], 'f1': [0.8355960845947266], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.07142857142857141 0.023440361546924773\n",
      "ppl : 21.81493077079295\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHARLENE: That's what you wanted to see? There wasn't even any sex. What Lowell guy on a road crew saw that movie in Lexington and recommended it??\\nMICKY: Where's the keys, I musta lost 'em in the theatah, I'm a dummy [WALKS\\n\\n\", 'answer': \"Micky. [He stops, turns] They're in your hand.\", 'gold_tag': 'CHARLENE is analytical', 'last_speaker': 'CHARLENE'}\n",
      "Last word -> CHARLENE : \"Micky. [He stops, turns] They're in your hand.\"\n",
      "prediction :  I'm so glad you came home.\n",
      "Real answer : Micky. [He stops, turns] They're in your hand.\n",
      "Bert Score : {'precision': [0.8631106019020081], 'recall': [0.8469003438949585], 'f1': [0.8549286127090454], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 32.03961373224712\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHARLENE: What's going on? You afraid to run into your girlfriend? You have a girlfriend, just say it, that's why you took me to Lexington.\\nMICKY: I don't have a girlfriend. I came here because I don't wanna show my face in Lowell.\\nCHARLENE: - What do you have to be ashamed of? I told everyone I was gonna win that fight and get back on track. I told Kasie we'd get a biggah place so she could move in. You said you never shoulda fought that guy, but your mothah and your brothah wanted ya to do it.\\nMICKY: What's the difference, I'm alone in the ring anyway.\\nCHARLENE: You think your family's lookin' out for ya?\\nMICKY: You can't say that about my family.\\n\\n\", 'answer': 'What else could I say after what you told me? Look at your face, look at you.', 'gold_tag': 'CHARLENE is straightforward and assertive', 'last_speaker': 'CHARLENE'}\n",
      "Last word -> CHARLENE : \"What else could I say after what you told me? Look at your face, look at you.\"\n",
      "prediction :  So, they just threw you out there to get beat up?\n",
      "Real answer : What else could I say after what you told me? Look at your face, look at you.\n",
      "Bert Score : {'precision': [0.8473232984542847], 'recall': [0.8502918481826782], 'f1': [0.8488050103187561], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.07142857142857142, 'rouge2': 0.0, 'rougeL': 0.07142857142857142, 'rougeLsum': 0.07142857142857142}\n",
      "bleu 1/2 : 0.052688934434982675 0.017474942612447388\n",
      "ppl : 69.96278294850022\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCHARLENE: Holy shit. Your mothah's here with your sistahs.\\nMICKY: Don't answah the door.\\n\\n\", 'answer': \"I'm not hidin' from your crazy fuckin' family, Micky!\", 'gold_tag': 'Charlene shows her strong personality , Charlene does not back down from confrontations , Charlene is independent and confrontational', 'last_speaker': 'CHARLENE'}\n",
      "Last word -> CHARLENE : \"I'm not hidin' from your crazy fuckin' family, Micky!\"\n",
      "prediction :  What's wrong?\n",
      "Real answer : I'm not hidin' from your crazy fuckin' family, Micky!\n",
      "Bert Score : {'precision': [0.8420438766479492], 'recall': [0.8015046119689941], 'f1': [0.8212742209434509], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 105.20381087433657\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORNELIUS: Do you have to work tonight?\\nZIRA: No.\\n\\n', 'answer': 'Neither do I.', 'gold_tag': \"CORNELIUS doesn't have work tonight\", 'last_speaker': 'CORNELIUS'}\n",
      "Last word -> CORNELIUS : \"Neither do I.\"\n",
      "prediction :  Okay. I have to go to work tonight.\n",
      "Real answer : Neither do I.\n",
      "Bert Score : {'precision': [0.8679043650627136], 'recall': [0.8695847988128662], 'f1': [0.8687437772750854], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 43.505608139145956\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZIRA: That's Bright Eyes. The one I was telling you about.\\nCORNELIUS: What's so special about him?\\nZIRA: Watch. Hello, Bright Eyes. How's our throat today? Look -- she remembers.\\nCORNELIUS: Remembers what?\\nZIRA: The blood transfusion.\\n\\n\", 'answer': \"Zira, come on. You know they can't -- Oh oh. Here comes Number One.\", 'gold_tag': 'Cornelius works closely with Zira likely in a scientific or research capacity', 'last_speaker': 'CORNELIUS'}\n",
      "Last word -> CORNELIUS : \"Zira, come on. You know they can't -- Oh oh. Here comes Number One.\"\n",
      "prediction :  The blood transfusion?\n",
      "Real answer : Zira, come on. You know they can't -- Oh oh. Here comes Number One.\n",
      "Bert Score : {'precision': [0.8113540410995483], 'recall': [0.8027033805847168], 'f1': [0.8070055246353149], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 262.06524567299135\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORNELIUS: It's a stunt. Humans don't write.\\nZIRA: Dear, you're a scientist. Don't you believe your own eyes?\\n\\n\", 'answer': 'Where did you learn to do this?', 'gold_tag': 'Everyday Language', 'last_speaker': 'CORNELIUS'}\n",
      "Last word -> CORNELIUS : \"Where did you learn to do this?\"\n",
      "prediction :  I'm a physicist, not a poet.\n",
      "Real answer : Where did you learn to do this?\n",
      "Bert Score : {'precision': [0.8944936990737915], 'recall': [0.8597431182861328], 'f1': [0.8767741918563843], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 18.81840152313684\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORNELIUS: Jefferson Public School, Fort Wayne, Indiana? Back on that planet you say you came from? Um-hm. He may be intelligent, but he's also mad.\\nZIRA: 'And you're a fool'.\\nCORNELIUS: Now, just a minute --\\nZIRA: Oh, Cornelius, be quiet. 'Dodge was killed in the hunt. What happened to Landon?' I don't know.\\nCORNELIUS: And they fell out of the sky with you?\\nZIRA: 'Not fell -- flew!'\\nCORNELIUS: Flight is a scientific impossibility.\\nZIRA: And even if it weren't, why fly? Where would it get you?\\nCORNELIUS: Well, now...\\n\\n\", 'answer': \"'Do you have maps?'\", 'gold_tag': 'Everyday Language', 'last_speaker': 'ZIRA'}\n",
      "Last word -> ZIRA : \"'Do you have maps?'\"\n",
      "prediction : 'I've been up there. I know.\n",
      "Real answer : 'Do you have maps?'\n",
      "Bert Score : {'precision': [0.8903478384017944], 'recall': [0.8779731392860413], 'f1': [0.8841171860694885], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 31.199677336737388\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCORNELIUS: We are here ... You were captured about here.\\nZIRA: You fell in the water here? ... you came ashore ... you marched across the desert ... the mountains ... many days and nights ... and reached the jungle.\\nCORNELIUS: Out - of - the - question!.\\nZIRA: Cornelius, why do you insist on provoking him?\\n\\n', 'answer': \"No creature can survive in that part of the Forbidden Zone. I've been there. I've seen it.\", 'gold_tag': 'CORNELIUS has been to the Forbidden Zone', 'last_speaker': 'CORNELIUS'}\n",
      "Last word -> CORNELIUS : \"No creature can survive in that part of the Forbidden Zone. I've been there. I've seen it.\"\n",
      "prediction :  I do not insist on anything.\n",
      "Real answer : No creature can survive in that part of the Forbidden Zone. I've been there. I've seen it.\n",
      "Bert Score : {'precision': [0.8690484166145325], 'recall': [0.8538550734519958], 'f1': [0.8613847494125366], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 65.83043639968314\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nZIRA: 'Then how do you account for me?,\\nCORNELIUS: I don't. And I'm not going to try.\\nZIRA: But what about your theory? The existence of someone like Taylor might prove it.\\nCORNELIUS: Zira, are you trying to get my head cut off?\\nZIRA: Don't be foolish. If it's true, they'll have to accept it.\\nCORNELIUS: No, they won't -\\nZIRA: hypothesis -\\nCORNELIUS: It's probably wrong --\\nZIRA: -- that the ape evolved from a lower order of primate, possibly man. In his trip to the Forbidden Zone he discovered traces of a culture older than recorded time -\\nCORNELIUS: The evidence was very meager --\\nZIRA: You didn't think so then.\\nCORNELIUS: That was before Dr. Zaius and half the Academy said the idea was heresy.\\nZIRA: How can scientific truth be heresy? What if Taylor is exactly the proof you needed? A mutation. A missing link between the unevolved primate and the ape -\\nCORNELIUS: He's touchy, isn't he?\\nZIRA: 'I am not a missing link.'\\nCORNELIUS: Because if he is a missing link, it means the Sacred Scrolls aren't worth their parchment.\\nZIRA: Well, maybe they're not.\\nCORNELIUS: No, thank you'. I won't get into that battle.\\nZIRA: Oh, Cornelius, show some strength!\\n\\n\", 'answer': \"Zira, listen to me. We've got a fine future ahead of us. Marriage. Stimulating careers. I'm up for a raise --\", 'gold_tag': 'CORNELIUS plans to get married , CORNELIUS is concerned about his career, mentioning being up for a raise', 'last_speaker': 'CORNELIUS'}\n",
      "Last word -> CORNELIUS : \"Zira, listen to me. We've got a fine future ahead of us. Marriage. Stimulating careers. I'm up for a raise --\"\n",
      "prediction :  Zira, you're a scientist. Don't you know that it's not the strength of your ideas that counts, but the strength of the men who believe in them?\n",
      "Real answer : Zira, listen to me. We've got a fine future ahead of us. Marriage. Stimulating careers. I'm up for a raise --\n",
      "Bert Score : {'precision': [0.8500171303749084], 'recall': [0.8652690649032593], 'f1': [0.8575752973556519], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11538461538461538, 'rouge2': 0.0, 'rougeL': 0.11538461538461538, 'rougeLsum': 0.11538461538461538}\n",
      "bleu 1/2 : 0.11111111111111109 0.02067245576486808\n",
      "ppl : 9.183940315330313\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE OWEN: Charlie?\\n\\n', 'answer': 'Yes. Hi.', 'gold_tag': 'Everyday Language', 'last_speaker': 'KAUFMAN'}\n",
      "Last word -> KAUFMAN : \"Yes. Hi.\"\n",
      "prediction :  Yes, sir?\n",
      "Real answer : Yes. Hi.\n",
      "Bert Score : {'precision': [0.7946078181266785], 'recall': [0.924816906452179], 'f1': [0.8547821044921875], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.5, 'rouge2': 0.0, 'rougeL': 0.5, 'rougeLsum': 0.5}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 501.68348735899554\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE OWEN: So the whole ecosystem is six thousand old. About that. Five or six.\\nKAUFMAN: Okay.\\n\\n', 'answer': \"Now the Fakahatchee is the largest of all the cyrpess strands, probably in the world. I don't know of any cypress strand bigger. It's about twenty miles long, or nineteen, nineteen to twenty, nineteen... and right here it's about five miles wide, four and a half, five. So, again, it's twenty miles long, three to five miles wide. And over here --\", 'gold_tag': 'MIKE OWEN is knowledgeable about ecosystems', 'last_speaker': 'MIKE OWEN'}\n",
      "Last word -> MIKE OWEN : \"Now the Fakahatchee is the largest of all the cyrpess strands, probably in the world. I don't know of any cypress strand bigger. It's about twenty miles long, or nineteen, nineteen to twenty, nineteen... and right here it's about five miles wide, four and a half, five. So, again, it's twenty miles long, three to five miles wide. And over here --\"\n",
      "prediction :  Yeah. I'm a pretty good guesser. But I'm a lousy scientist.\n",
      "Real answer : Now the Fakahatchee is the largest of all the cyrpess strands, probably in the world. I don't know of any cypress strand bigger. It's about twenty miles long, or nineteen, nineteen to twenty, nineteen... and right here it's about five miles wide, four and a half, five. So, again, it's twenty miles long, three to five miles wide. And over here --\n",
      "Bert Score : {'precision': [0.8737462162971497], 'recall': [0.7794619798660278], 'f1': [0.8239155411720276], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05128205128205129, 'rouge2': 0.0, 'rougeL': 0.05128205128205129, 'rougeLsum': 0.05128205128205129}\n",
      "bleu 1/2 : 0.0008811709507286618 0.0002922513419727717\n",
      "ppl : 14.824863713167238\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nMIKE OWEN: What Laroche did was wrong. Those flowers belong to all of us, all 250 million of us -- 250? I think it's up to 270 now -- And belonging to all of us means they belong to none of us. Nobody has a right to take them. Not me, not you, not John Laroche, not...\\nKAUFMAN: Listen, um, Susan Orlean wrote about a legendary creature called a Swamp Ape. Have you ever heard stories or --\\nMIKE OWEN: Tourist garbage! I don't know why people need to invent silly creatures to make nature fascinating. Isn't nature amazing enough?\\n\\n\", 'answer': 'I just asked because she mentioned it.', 'gold_tag': 'Everyday Language', 'last_speaker': 'KAUFMAN'}\n",
      "Last word -> KAUFMAN : \"I just asked because she mentioned it.\"\n",
      "prediction :  So, if you don't know anything about the Swamp Ape, then you can't say that the legend is garbage.\n",
      "Real answer : I just asked because she mentioned it.\n",
      "Bert Score : {'precision': [0.8483477830886841], 'recall': [0.8551552295684814], 'f1': [0.851737916469574], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.82027671400324\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nIRENE: Excuse me, Jerome. I'm sorry to bother you.\\nJEROME: No bother.\\nIRENE: I've been asked to compile a log for the investigators--they want to know everyone's whereabouts last night.\\nJEROME: Last night? I was at home.\\nIRENE: Can that be, er, verified? Were you alone?\\nJEROME: No it can't be verified. Yes I was alone. Looks bad, doesn't it, Irene? What about you? Where were you last night?\\nIRENE: I was at home.\\nJEROME: Were you alone?\\nIRENE: Yes.\\nJEROME: So we don't know for sure about you, either.\\nIRENE: No.\\nJEROME: Why don't we say we were together?\\nIRENE: Why would we do that?\\nJEROME: I have better things to do this week than answer the foolish questions of some flatfoot. Don't you? Well, shall we say we spent the evening together?\\n\\n\", 'answer': 'To be convincing, Jerome, I would have to know what that was like.', 'gold_tag': 'Everyday Language', 'last_speaker': 'IRENE'}\n",
      "Last word -> IRENE : \"To be convincing, Jerome, I would have to know what that was like.\"\n",
      "prediction :  Fine.\n",
      "Real answer : To be convincing, Jerome, I would have to know what that was like.\n",
      "Bert Score : {'precision': [0.9197909832000732], 'recall': [0.8318785429000854], 'f1': [0.8736286759376526], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 4604.562823636195\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEROME: We were looking at each other. You stopped.\\nIRENE: I'm sorry. I didn't mean anything.\\nJEROME: We were just looking.\\nIRENE: I know about you. Here, take it. If you're still interested, let me know.\\n\\n\", 'answer': 'Sorry, the wind caught it.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JEROME'}\n",
      "Last word -> JEROME : \"Sorry, the wind caught it.\"\n",
      "prediction :  I'm not interested.\n",
      "Real answer : Sorry, the wind caught it.\n",
      "Bert Score : {'precision': [0.8831910490989685], 'recall': [0.8641844987869263], 'f1': [0.8735844492912292], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 83.39391968957155\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEROME: Have they found our friend?\\nIRENE: Friend?\\nJEROME: It was a mercy-killing after all.\\nIRENE: They found an eyelash.\\nJEROME: Where?\\nIRENE: In the South Wing.\\nJEROME: Does it have a name?\\nIRENE: Just some In-Valid. Vincent-- (trying to come up with the last name) --somebody.\\nJEROME: Perhaps we ought to celebrate, Irene.\\n\\n', 'answer': 'You celebrate, Jerome?', 'gold_tag': 'Everyday Language', 'last_speaker': 'IRENE'}\n",
      "Last word -> IRENE : \"You celebrate, Jerome?\"\n",
      "prediction :  I don't think that's a good idea.\n",
      "Real answer : You celebrate, Jerome?\n",
      "Bert Score : {'precision': [0.8268228769302368], 'recall': [0.8265649080276489], 'f1': [0.8266938924789429], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 8.014703941214668\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nIRENE: You didn't know?\\nJEROME: Yes...yes...\\nIRENE: You're angry--\\n\\n\", 'answer': 'Why would I be angry? It was beautiful.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JEROME'}\n",
      "Last word -> JEROME : \"Why would I be angry? It was beautiful.\"\n",
      "prediction :  I am angry. I'm angry with you for lying to me.\n",
      "Real answer : Why would I be angry? It was beautiful.\n",
      "Bert Score : {'precision': [0.9011105298995972], 'recall': [0.8841009736061096], 'f1': [0.8925247192382812], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0.0909090909090909 0.03015113445777637\n",
      "ppl : 20.0181382462867\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEROME: Better not. Don't want to give you a contaminated specimen...if you get my meaning. Thanks. You never know where those swabs have been.\\n\\n\", 'answer': 'I want to show you something.', 'gold_tag': 'Everyday Language', 'last_speaker': 'IRENE'}\n",
      "Last word -> IRENE : \"I want to show you something.\"\n",
      "prediction :  I'm not asking you to give me anything. I'm asking you to help me. I'm asking you to tell me what you know about my husband's death.\n",
      "Real answer : I want to show you something.\n",
      "Bert Score : {'precision': [0.8733516931533813], 'recall': [0.9020419120788574], 'f1': [0.8874650001525879], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16216216216216214, 'rouge2': 0.0, 'rougeL': 0.16216216216216214, 'rougeLsum': 0.16216216216216214}\n",
      "bleu 1/2 : 0.07407407407407407 0.016878989451394436\n",
      "ppl : 5.081626219938799\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nIRENE: Come on! We'll miss it!\\n\\n\", 'answer': \"Come on. We'll miss it.\", 'gold_tag': 'Jerome also expresses concern about missing the same event', 'last_speaker': 'JEROME'}\n",
      "Last word -> JEROME : \"Come on. We'll miss it.\"\n",
      "prediction :  I know, but I don't think I can do it.\n",
      "Real answer : Come on. We'll miss it.\n",
      "Bert Score : {'precision': [0.8620268106460571], 'recall': [0.8809453845024109], 'f1': [0.8713834285736084], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352942, 'rouge2': 0.0, 'rougeL': 0.11764705882352942, 'rougeLsum': 0.11764705882352942}\n",
      "bleu 1/2 : 0.10000000000000002 0.03333333333333335\n",
      "ppl : 11.934012643292595\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nIRENE: What did I tell you? I envy you, Jerome.\\nJEROME: You'll be next.\\nIRENE: I don't think so. The only trip I'll make in space is around the sun-- --on this satellite right here. (blurting out what's really on her mind) --Listen, I don't want to waste your time and I really don't want you to waste mine. I don't know what you're after but I have a feeling I'm not it. It's here. My heart. I'm careful--weekly check-ups. I'm on a drug maintenance program, blood thinners, diet-- I just want you to know what you'd be getting yourself into.\\nJEROME: What exactly is wrong?\\nIRENE: Nothing yet. I'll start experiencing symptoms in my late-fifties. But unless they come up with something between now and then, I won't live much past 67. Of course I think about it every day.\\n\\n\", 'answer': 'Of course.', 'gold_tag': \"JEROME's responses indicate understanding and patience\", 'last_speaker': 'JEROME'}\n",
      "Last word -> JEROME : \"Of course.\"\n",
      "prediction :  I'm sorry.\n",
      "Real answer : Of course.\n",
      "Bert Score : {'precision': [0.8787058591842651], 'recall': [0.8923876285552979], 'f1': [0.8854939341545105], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 70.196163546962\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nIRENE: So you didn't do it after all.\\n\\n\", 'answer': 'I guess somebody beat me to it.', 'gold_tag': 'Shared memories', 'last_speaker': 'JEROME'}\n",
      "Last word -> JEROME : \"I guess somebody beat me to it.\"\n",
      "prediction :  What are you talking about?\n",
      "Real answer : I guess somebody beat me to it.\n",
      "Bert Score : {'precision': [0.81480872631073], 'recall': [0.8315814137458801], 'f1': [0.8231096267700195], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 58.2916451132753\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nIRENE: Jerome! What about the car?\\nJEROME: Let's walk.\\nIRENE: Who are they?\\nJEROME: It's not safe. I shouldn't have brought you here.\\nIRENE: I can't.\\nJEROME: Come on.\\nIRENE: My medication. I left it back there.\\n\\n\", 'answer': \"We'll get it later. Irene, please.\", 'gold_tag': 'JEROME is concerned for IRENE', 'last_speaker': 'JEROME'}\n",
      "Last word -> JEROME : \"We'll get it later. Irene, please.\"\n",
      "prediction :  It's okay.\n",
      "Real answer : We'll get it later. Irene, please.\n",
      "Bert Score : {'precision': [0.8858944177627563], 'recall': [0.8779155015945435], 'f1': [0.881886899471283], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2, 'rouge2': 0.0, 'rougeL': 0.2, 'rougeLsum': 0.2}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 87.14335918583589\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nIRENE: (referring to the shins) What happened?\\nJEROME: You remember the \\'99 Chrysler LeBaron? It\\'s the exact height of the front fender. Looked right instead of left.\\nIRENE: So you\\'re not so smart after all. I want you to know--if it ever came to it-- I\\'d be willing to get an ovum from the Egg Bank. In fact, I\\'d rather use a donor egg-- --if it came to it.\\nJEROME: But \"if it came to it\" then it couldn\\'t have your-- (searching for an appropriate body part) --nose.\\nIRENE: You hypocrite. Do you think for one moment you\\'d be doing what you\\'re doing if it wasn\\'t for who you are--what you are? Don\\'t you get any satisfaction knowing that your children will be able to live to a ripe old age unless they do something foolish?\\n\\n', 'answer': \"That's precisely what scaresme--that they won't do anything foolish or courageous or anything--worth a Goddamn.\", 'gold_tag': 'JEROME reflects on the potential risks of having children who may not take risks or carry out courageous actions', 'last_speaker': 'JEROME'}\n",
      "Last word -> JEROME : \"That's precisely what scaresme--that they won't do anything foolish or courageous or anything--worth a Goddamn.\"\n",
      "prediction :  I'm not sure I'm comfortable with this. I'm not sure I'm comfortable with anything.\n",
      "Real answer : That's precisely what scaresme--that they won't do anything foolish or courageous or anything--worth a Goddamn.\n",
      "Bert Score : {'precision': [0.8530080318450928], 'recall': [0.8177101016044617], 'f1': [0.83498615026474], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05405405405405406, 'rouge2': 0.0, 'rougeL': 0.05405405405405406, 'rougeLsum': 0.05405405405405406}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 4.839925316260696\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nIRENE: What is it?\\nJEROME: I forgot something--something at home. I'll see you later.\\nIRENE: I'll miss you. --when you go away.\\n\\n\", 'answer': 'We could go together one day.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JEROME'}\n",
      "Last word -> JEROME : \"We could go together one day.\"\n",
      "prediction :  I'll be back soon.\n",
      "Real answer : We could go together one day.\n",
      "Bert Score : {'precision': [0.8722535967826843], 'recall': [0.8784600496292114], 'f1': [0.8753458261489868], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 43.296090971303165\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEROME: Here, take it. If you're still interested, let me know.\\n\\n\", 'answer': \"Jerome's words from their first encounter) Sorry, the wind caught it.\", 'gold_tag': \"IRENE and JEROME share a memory of a past encounter, implied by IRENE citing JEROME's words from their first meeting.\", 'last_speaker': 'IRENE'}\n",
      "Last word -> IRENE : \"Jerome's words from their first encounter) Sorry, the wind caught it.\"\n",
      "prediction :  What?\n",
      "Real answer : Jerome's words from their first encounter) Sorry, the wind caught it.\n",
      "Bert Score : {'precision': [0.8411293029785156], 'recall': [0.8100269436836243], 'f1': [0.8252852559089661], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2442.6387257455463\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEROME: A year is a long time.\\n\\n', 'answer': 'Not so long--just once around the sun.', 'gold_tag': \"IRENE perceives the concept of a year as a shorter amount of time, associating it simply with the earth's orbit around the sun\", 'last_speaker': 'IRENE'}\n",
      "Last word -> IRENE : \"Not so long--just once around the sun.\"\n",
      "prediction :  Yes, but it's worth it.\n",
      "Real answer : Not so long--just once around the sun.\n",
      "Bert Score : {'precision': [0.8666363954544067], 'recall': [0.8253339529037476], 'f1': [0.8454810380935669], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 32.82615871876027\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWYATT: Out! Commiserations, Messer. Good game. Develop akiller instinct and you'll beat the crap out of me. They asked if we'd fancy a post-game cocktail. Don't worry, I got us out of it.\\nJONATHAN: Oh? I would've been happy to.\\n\\n\", 'answer': \"Are you kidding? They're a couple of first years at Merrill. Screw that, we can do better. Hey, you OK?\", 'gold_tag': 'WYATT is competitive and judgmental , WYATT dismissed the first years at Merrill', 'last_speaker': 'WYATT'}\n",
      "Last word -> WYATT : \"Are you kidding? They're a couple of first years at Merrill. Screw that, we can do better. Hey, you OK?\"\n",
      "prediction :  I'm not going to get you killed, Jon. I'm not going to get you killed.\n",
      "Real answer : Are you kidding? They're a couple of first years at Merrill. Screw that, we can do better. Hey, you OK?\n",
      "Bert Score : {'precision': [0.8440849781036377], 'recall': [0.8438622951507568], 'f1': [0.8439736366271973], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.10526315789473684, 'rouge2': 0.0, 'rougeL': 0.10526315789473684, 'rougeLsum': 0.10526315789473684}\n",
      "bleu 1/2 : 0.09553750807650524 0.022112636314852756\n",
      "ppl : 12.669764738246311\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWYATT: Man, I remember when these first came out. I think I was a frosh at boarding school. (chuckles; fingers a string) Jeez, are these strings natural gut?\\n\\n', 'answer': \"Actually, it's a hybrid weave: natural gut and Kevlar. They're pretty obscure now. I should replace them, they're all frayed...\", 'gold_tag': 'JONATHAN has knowledge about hybrid weave strings made of natural gut and Kevlar , JONATHAN is aware that these strings are somewhat obscure , JONATHAN suggests a potential interest or involvement in music or sports that use such equipment , JONATHAN is conscious about the state of these strings , JONATHAN notes they need to be replaced due to being frayed', 'last_speaker': 'JONATHAN'}\n",
      "Last word -> JONATHAN : \"Actually, it's a hybrid weave: natural gut and Kevlar. They're pretty obscure now. I should replace them, they're all frayed...\"\n",
      "prediction :  Yeah, they are. I don't know if you can even find them anymore. (pauses) I'm glad you like 'em.\n",
      "Real answer : Actually, it's a hybrid weave: natural gut and Kevlar. They're pretty obscure now. I should replace them, they're all frayed...\n",
      "Bert Score : {'precision': [0.8446536660194397], 'recall': [0.8429935574531555], 'f1': [0.8438228368759155], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.13636363636363635, 'rouge2': 0.0, 'rougeL': 0.13636363636363635, 'rougeLsum': 0.13636363636363635}\n",
      "bleu 1/2 : 0.049933130527180895 0.016222931808031155\n",
      "ppl : 9.627135574316823\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJONATHAN: She's a hooker. Hold on - you knew? What - are all the women here prostitutes?\\nWYATT: That depends on what you mean by that word. Stretch the definition and you could incorporate most of the men as well. You know in Amsterdam prostitutes not only belong to a union, they have to pay taxes.\\nJONATHAN: You seem to possess quite a store of international trivia.\\nWYATT: Not really. I just get around... Jonathan, relax. It's not like she just shot your dog. I was only trying to help. Besides, what are you looking for - a relationship? As if you have time for one? This was your first day off in how long?\\nJONATHAN: Three weeks.\\nWYATT: Four for me. Face it, we've mortgaged our youth. Pimped out our twenties. But we still have needs. And there's nothing shameful about wanting them met.\\nJONATHAN: So you sleep with hookers?\\nWYATT: Me? Never.\\nJONATHAN: So how do you - meet your needs?\\nWYATT: What if I told you... Christ, I sound like an infommercial.\\nJONATHAN: What were you going to say?\\nWYATT: Listen. You don't think that women have these same urges? Young women, just like ourselves, successful and working their asses off to stay that way? You better believe they do.\\nJONATHAN: And?\\nWYATT: And - well - let's just say, there's a way...a way it can be taken care of.\\n\\n\", 'answer': 'You make it sound like a mob hit.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JONATHAN'}\n",
      "Last word -> JONATHAN : \"You make it sound like a mob hit.\"\n",
      "prediction :  What is it?\n",
      "Real answer : You make it sound like a mob hit.\n",
      "Bert Score : {'precision': [0.8727421760559082], 'recall': [0.8639521598815918], 'f1': [0.868324875831604], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.18181818181818182, 'rouge2': 0.0, 'rougeL': 0.18181818181818182, 'rougeLsum': 0.18181818181818182}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 140.93475091067572\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWYATT: I wonder what the Founding Fathers would make of this scene.\\nJONATHAN: I'm just glad to be outside. I've got to tell you, this has been great,\\nWYATT: Yes?... Shit. Okay, see if you can.gettme on the 6:15 out of JFK tonight... Fine. Rutherford needs me to join him asap in London to paper some financing with Lloyds. I tell you about this?\\nJONATHAN: No - no you didn't.\\nWYATT: Yeah, I should be gone a few weeks.\\nJONATHAN: Sounds exciting.\\n\\n\", 'answer': \"Nah, it'll be boring as sin. Shit, I'd better get back. You ready?\", 'gold_tag': 'WYATT considers the forthcoming trip to London as boring', 'last_speaker': 'WYATT'}\n",
      "Last word -> WYATT : \"Nah, it'll be boring as sin. Shit, I'd better get back. You ready?\"\n",
      "prediction :  I'm sorry, man. I can't leave now. I have to get to the airport.\n",
      "Real answer : Nah, it'll be boring as sin. Shit, I'd better get back. You ready?\n",
      "Bert Score : {'precision': [0.8841825723648071], 'recall': [0.862553596496582], 'f1': [0.8732341527938843], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.12903225806451615, 'rouge2': 0.0, 'rougeL': 0.12903225806451615, 'rougeLsum': 0.12903225806451615}\n",
      "bleu 1/2 : 0.07142857142857141 0.023440361546924773\n",
      "ppl : 12.703381398025675\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nWYATT: Long time no see. I have some instructions. Follow them and I might let her live.\\nJONATHAN: Where is she?\\nWYATT: This should\\'ve been simpler. I frame you, you panic...\\nJONATHAN: Where is she?! Goddamn it tell me what you did to--\\nWYATT: Press pause on the questions and listen. The brokerage firm you\\'re auditing is Clute Nichols. As a standard part of that audit you\\'re temporarily privy to all client accounts as well as access codes required for transactions. At 11 p.m. tonight you\\'re going to skim from those accounts a total of $200 million and transfer that money to an account I\\'ve established overseas.\\nJONATHAN: I can\\'t - I have no idea how to even-\\nWYATT: I know you don\\'t. But I do. Your passport. Now, please. It\\'s all in there. 11 pm tonight. Their banks will just be opening.\\nJONATHAN: It won\\'t work - they screen for stuff like this. It\\'ll be discovered eventually.\\nWYATT: I can live with eventually. I always have.\\nJONATHAN: This account overseas - it\\'s in my name, isn\\'t it? Why\\'d you pick me?\\nWYATT: You answered the ad, Jonathan. \"Feeling all alone out there? Have a great job, fine personality and good looks to match, but no time to.meet that special someone? Help is just a phone call away -\"\\nJONATHAN: The ad - in Money magazine...\\nWYATT: Told you to block that Caller ID. Of course I had to scope out a whole lot of losers before I hit the jackpot. After all, there only so many Jonathan Messers out there. If you screw with me, well - you saw what I did to that Blonde? That\\'s kindness compared to what I\\'ll do to your little .girlfriend. You won\\'t even recognize her when I\\'m through.\\nJONATHAN: Why should I believe you? Everything you told me was lies.\\n\\n', 'answer': \"Not lies, Jonathan. Foreplay. And now... now you're fucked. Remember: be smart. I'll be watching you. And... feel free to take a shower, looks like you could do with one.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'WYATT'}\n",
      "Last word -> WYATT : \"Not lies, Jonathan. Foreplay. And now... now you're fucked. Remember: be smart. I'll be watching you. And... feel free to take a shower, looks like you could do with one.\"\n",
      "prediction :  You don't believe me? I'm sorry to hear that, Jonathan. You really are a very special person. I've never met anyone like you before.\n",
      "Real answer : Not lies, Jonathan. Foreplay. And now... now you're fucked. Remember: be smart. I'll be watching you. And... feel free to take a shower, looks like you could do with one.\n",
      "Bert Score : {'precision': [0.8555895090103149], 'recall': [0.8365447521209717], 'f1': [0.8459599614143372], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2711864406779661, 'rouge2': 0.03508771929824561, 'rougeL': 0.20338983050847456, 'rougeLsum': 0.20338983050847456}\n",
      "bleu 1/2 : 0.16225016313987603 0.07412109777302411\n",
      "ppl : 8.02027410543601\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJONATHAN: They don't let you use your own computer.\\n\\n\", 'answer': 'They will now.', 'gold_tag': 'Everyday Language', 'last_speaker': 'WYATT'}\n",
      "Last word -> WYATT : \"They will now.\"\n",
      "prediction :  I don't have one.\n",
      "Real answer : They will now.\n",
      "Bert Score : {'precision': [0.8702665567398071], 'recall': [0.8712575435638428], 'f1': [0.8707617521286011], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 46.5360650249794\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nOFFICER PASKI: It's the strangest thing Father.\\nGRAHAM: Don't call me Father.\\nOFFICER PASKI: What's that?\\nGRAHAM: Don't call me Father. It's just Graham now.\\nOFFICER PASKI: Sorry.\\nGRAHAM: You said something was strange. What's strange? What about them?\\n\\n\", 'answer': 'There are none.', 'gold_tag': 'Everyday Language', 'last_speaker': 'OFFICER PASKI'}\n",
      "Last word -> OFFICER PASKI : \"There are none.\"\n",
      "prediction :  I think that's exactly what we need to find out.\n",
      "Real answer : There are none.\n",
      "Bert Score : {'precision': [0.8302654027938843], 'recall': [0.8591164946556091], 'f1': [0.8444445729255676], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 21.535276829244406\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nGRAHAM: It's not broken.\\nOFFICER PASKI: What kind of machine can bend a stalk of corn over without cracking it?\\nGRAHAM: Can't be by hand... It's too perfect.\\nOFFICER PASKI: Doesn't sound much like Lionel Prichard and the Wolfington brothers. They can't take a piss without wetting the front of their pants. Second thing this week I can't explain.\\nGRAHAM: What was the first thing?\\nOFFICER PASKI: Some animals around the county exhibiting uncharacteristic behavior. Sometimes violent behavior. Theo Henry had two of his fingers bit off by his cow.\\nGRAHAM: Sounds like a virus.\\nOFFICER PASKI: No Father, they're edgy. On alert. Like they act when they smell a predator around... Peeing on themselves and everything.\\nGRAHAM: Edgar, please don't call me Father.\\nOFFICER PASKI: What's wrong?\\n\\n\", 'answer': \"I don't hear my children.\", 'gold_tag': 'GRAHAM has children', 'last_speaker': 'GRAHAM'}\n",
      "Last word -> GRAHAM : \"I don't hear my children.\"\n",
      "prediction :  It's just a long story.\n",
      "Real answer : I don't hear my children.\n",
      "Bert Score : {'precision': [0.8714805245399475], 'recall': [0.8766704797744751], 'f1': [0.8740677833557129], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 68.5006584126974\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nOFFICER PASKI: Don't ask me what I think. Cause I can't think straight right now. I'm going back to the station. Have a cup of Marcia's coffee and try to think clear. After that I might make some calls. Hoaxes... People got way too much But I'll tell you something, what I said in their, still goes. You and your family have been through a lot in the last two days... Not to mention what happened to you all seven months ago.\\nGRAHAM: Six months. And three weeks.\\nOFFICER PASKI: It's left its mark still. The last thing these children need to do, is worry about some crazy things happening in the world. Take them into town. Get their minds -- your good medicine.\\nGRAHAM: It's good advice... Say hi to Marcia for me.\\n\\n\", 'answer': 'You take care of yourself... Graham.', 'gold_tag': 'OFFICER PASKI plans to have a coffee and make some calls at the station in the near future', 'last_speaker': 'OFFICER PASKI'}\n",
      "Last word -> OFFICER PASKI : \"You take care of yourself... Graham.\"\n",
      "prediction :  I will.\n",
      "Real answer : You take care of yourself... Graham.\n",
      "Bert Score : {'precision': [0.9077856540679932], 'recall': [0.8325766324996948], 'f1': [0.8685560822486877], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1002.5329194846038\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINDA: She did that deliberately.\\nLUCY: She's a beast. How'd you do that?\\n\\n\", 'answer': \"Must've been a defective puck.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'LINDA'}\n",
      "Last word -> LINDA : \"Must've been a defective puck.\"\n",
      "prediction :  I'm sorry.\n",
      "Real answer : Must've been a defective puck.\n",
      "Bert Score : {'precision': [0.8676761984825134], 'recall': [0.8556543588638306], 'f1': [0.8616234064102173], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 70.196163546962\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLUCY: Keep an eye peeled for Myra. She's out to get you.\\nLINDA: But what for?\\n\\n\", 'answer': \"She just hates anybody who isn't afraid of her.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'LUCY'}\n",
      "Last word -> LUCY : \"She just hates anybody who isn't afraid of her.\"\n",
      "prediction :  She's got a bee in her bonnet about you.\n",
      "Real answer : She just hates anybody who isn't afraid of her.\n",
      "Bert Score : {'precision': [0.8407278060913086], 'recall': [0.8595616817474365], 'f1': [0.8500403761863708], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20000000000000004, 'rouge2': 0.0, 'rougeL': 0.20000000000000004, 'rougeLsum': 0.20000000000000004}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.77272244303827\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLUCY: Hey, Linda! It's my roommate. You'll love her. She's really off the wall! Linda babes! There's this all-night party at Eddie's... his folks are away...\\nLINDA: Oh, I don't know. I'm not signed out for an overnight.\\nLUCY: Go back, sign in, and climb out the bathroom window. McCloskey's always zonked out: she'll never hear you.\\nLINDA: It doesn't seem right.\\nLUCY: Please, as a favour to me? So I won't be the only girl?\\nLINDA: Look at that guy!\\nLUCY: What a space cadet. Hey, you dingleberry! Get outta the street!\\nLINDA: Why is he acting so strangely?\\n\\n\", 'answer': \"I dunno, but he's gonna get creamed.\", 'gold_tag': 'LUCY is planning to attend a night party', 'last_speaker': 'LUCY'}\n",
      "Last word -> LUCY : \"I dunno, but he's gonna get creamed.\"\n",
      "prediction :  Well, that's what I want to know.\n",
      "Real answer : I dunno, but he's gonna get creamed.\n",
      "Bert Score : {'precision': [0.8489840030670166], 'recall': [0.8681873083114624], 'f1': [0.8584782481193542], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0.14285714285714285 0.048795003647426664\n",
      "ppl : 18.01353704411976\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLUCY: Omigod, it's a runaway!\\nLINDA: Lucy; come back!\\n\\n\", 'answer': \"Somebody's gotta do something!!\", 'gold_tag': 'Everyday Language', 'last_speaker': 'LUCY'}\n",
      "Last word -> LUCY : \"Somebody's gotta do something!!\"\n",
      "prediction :  I'm going to get it.\n",
      "Real answer : Somebody's gotta do something!!\n",
      "Bert Score : {'precision': [0.8930730223655701], 'recall': [0.8585937023162842], 'f1': [0.8754940032958984], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 51.89000779448364\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEZZIE: You up?\\nJACOB: No. Have you seen my glasses?\\nJEZZIE: Where\\'d you leave \\'em?\\nJACOB: I don\\'t know.\\nJEZZIE: Did you look around the headboard?\\nJACOB: Jezzie, I can\\'t see.\\nJEZZIE: Maybe you left \\'em in the bathroom.\\nJACOB: Thanks.\\nJEZZIE: Your kid dropped it off.\\nJACOB: Who? Jed?\\nJEZZIE: No. The little one.\\nJACOB: Eli. Why can\\'t you remember their names?\\nJEZZIE: They\\'re weird names.\\nJACOB: They\\'re Biblical. They were prophets.\\nJEZZIE: Well, personally, I never went for church names.\\nJACOB: And where do you think Jezebel comes from?\\nJEZZIE: I don\\'t let anybody call me that.\\nJACOB: You\\'re a real heathen, you know that, Jezzie? Jesus, how did I ever get involved with such a ninny?\\nJEZZIE: You sold your soul, remember? That\\'s what you told me.\\nJACOB: Yeah, but for what?\\nJEZZIE: A good lay.\\nJACOB: And look what I got.\\nJEZZIE: The best.\\nJACOB: I must have been out of my head.\\nJEZZIE: Jake, you are never out of your head!\\nJACOB: What\\'s in here?\\nJEZZIE: Pictures. Your wife was gonna toss \\'em so \"what\\'s his name\" brought \\'em over on his way to school.\\nJACOB: Look at these, will ya? I don\\'t believe it. Jesus, these are fantastic. Look, here\\'s my Dad ... And here\\'s my brother, when we were down in Florida.\\nJEZZIE: Lemme see.\\nJACOB: Here. Look. This is me and Sarah when I was still at City College.\\nJEZZIE: That\\'s Sarah?\\nJACOB: What?\\nJEZZIE: Why you left.\\nJACOB: What do you mean you can see?\\nJEZZIE: Look at her face. A real bitch.\\nJACOB: She looked good then.\\nJEZZIE: Not to me.\\nJACOB: Well, you didn\\'t marry her.\\nJEZZIE: What\\'s wrong? Is that the one who died?\\nJACOB: Gabe. Sorry. it just took me by surprise. I didn\\'t expect to see him this morning ... God, what I wouldn\\'t ... He was the cutest little guy. Like an angel, you know. He had this smile ... Fuck, I don\\'t even remember this picture. Wait. Don\\'t.\\nJEZZIE: I don\\'t like things that make you cry.\\nJACOB: I just want to look ... God, this is me! Look. It\\'s dated right after I was born. What a kid. Cute, huh? So much promise.\\n\\n', 'answer': \"It's amazing, huh Jake? Your whole life ... right in front of you. What a mess!\", 'gold_tag': 'Everyday Language', 'last_speaker': 'JEZZIE'}\n",
      "Last word -> JEZZIE : \"It's amazing, huh Jake? Your whole life ... right in front of you. What a mess!\"\n",
      "prediction :  What are you gonna do?\n",
      "Real answer : It's amazing, huh Jake? Your whole life ... right in front of you. What a mess!\n",
      "Bert Score : {'precision': [0.8468732237815857], 'recall': [0.827795684337616], 'f1': [0.8372257947921753], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.19047619047619047, 'rouge2': 0.0, 'rougeL': 0.09523809523809523, 'rougeLsum': 0.09523809523809523}\n",
      "bleu 1/2 : 0.022160631672466777 0.007834966465489321\n",
      "ppl : 55.520945684385296\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACOB: Ready?\\n\\n', 'answer': \"Just gettin' rid of the garbage.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'JEZZIE'}\n",
      "Last word -> JEZZIE : \"Just gettin' rid of the garbage.\"\n",
      "prediction :  Yeah.\n",
      "Real answer : Just gettin' rid of the garbage.\n",
      "Bert Score : {'precision': [0.9359393119812012], 'recall': [0.8348742127418518], 'f1': [0.8825227618217468], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 3087.0088326606033\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEZZIE: Jake!\\nJACOB: How's it going? I'm going home.\\nJEZZIE: What's wrong?\\nJACOB: I don't know. One of these days, I'm gonna see Louis. My back's killing me.\\nJEZZIE: Now? What about the boss? He's not gonna like it. Well, I'll miss riding home with you. I was looking forward to it. I enjoy crushing into you.\\n\\n\", 'answer': 'Gently. My back.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JACOB'}\n",
      "Last word -> JACOB : \"Gently. My back.\"\n",
      "prediction :  I don't care.\n",
      "Real answer : Gently. My back.\n",
      "Bert Score : {'precision': [0.8487670421600342], 'recall': [0.8755912780761719], 'f1': [0.8619704842567444], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 66.16079898082417\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEZZIE: Maybe it's all the pressure, Jake. The money. Things like that. Or your wife.\\nJACOB: Why do you bring her up?\\nJEZZIE: 'Cause she's always on your mind.\\nJACOB: When was the last time I said a word?\\nJEZZIE: It has nothin' to do with talkin'. Or maybe it's the war. It's still there, Jake. Even if you never say a word about it. You can't spend two years in Vietnam ...\\nJACOB: What does that have to do with anything? Does it explain the barricaded subway stations? Does it explain those Godforsaken creatures?\\nJEZZIE: New York is filled with creatures. Everywhere. And lots of stations are closed.\\nJACOB: They're like demons, Jez.\\nJEZZIE: Demons, Jake? Come on. They're winos and bag ladies. Low life. That's all they are. The streets are crawling with 'em. Don't make em into somethin' they're not. It's the pressure, honey. That's all it is.\\nJACOB: Those guys tried to kill me tonight. They were aiming right at me.\\nJEZZIE: Kids on a joy ride. Happens all the\\nJACOB: They weren't human!\\n\\n\", 'answer': 'Come on. What were they, Jake? You still love me?', 'gold_tag': \"JEZZIE is unsure about JACOB's feelings for her\", 'last_speaker': 'JEZZIE'}\n",
      "Last word -> JEZZIE : \"Come on. What were they, Jake? You still love me?\"\n",
      "prediction :  Jake, don't be a fool.\n",
      "Real answer : Come on. What were they, Jake? You still love me?\n",
      "Bert Score : {'precision': [0.867615818977356], 'recall': [0.8424466848373413], 'f1': [0.8548460602760315], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.125, 'rouge2': 0.0, 'rougeL': 0.125, 'rougeLsum': 0.125}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 49.17275585795928\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEZZIE: Jake. You\\'re gonna be all right, Jake. You\\'re gonna be fine.\\nJACOB: Am I home?\\nJEZZIE: You\\'re here. Home. The doctor said you\\'re lucky your brains didn\\'t boil. What a night, Jake. It was crazy. You kept sayin\\' \"Sarah, close the window,\" over and over. And talkin\\' to your kids. Even the dead one. Weird. You know you melted 200 pounds of ice in 8 hours. Amazing, huh?\\nJACOB: Are we in Brooklyn?\\n\\n', 'answer': \"You're right here, Jake. You just rest. The doctor said you had a virus. That's what they say when they don't know what it is. You can't do anything for a week. He says you gotta recuperate. Now you just lie here. Mrs. Sandelman made you some chicken soup. It'll warm you up.\", 'gold_tag': \"JEZZIE is familiar with Mrs. Sandelman , JEZZIE is skeptical about the doctor's diagnosis , JACOB has been diagnosed with a virus and has been directed to rest for a week , Mrs. Sandelman might be a mutual acquaintance that prepared chicken soup for Jacob\", 'last_speaker': 'JEZZIE'}\n",
      "Last word -> JEZZIE : \"You're right here, Jake. You just rest. The doctor said you had a virus. That's what they say when they don't know what it is. You can't do anything for a week. He says you gotta recuperate. Now you just lie here. Mrs. Sandelman made you some chicken soup. It'll warm you up.\"\n",
      "prediction :  You're in the Bronx, Jake. You're home.\n",
      "Real answer : You're right here, Jake. You just rest. The doctor said you had a virus. That's what they say when they don't know what it is. You can't do anything for a week. He says you gotta recuperate. Now you just lie here. Mrs. Sandelman made you some chicken soup. It'll warm you up.\n",
      "Bert Score : {'precision': [0.903759241104126], 'recall': [0.8361333012580872], 'f1': [0.8686320781707764], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1492537313432836, 'rouge2': 0.061538461538461535, 'rougeL': 0.11940298507462686, 'rougeLsum': 0.11940298507462686}\n",
      "bleu 1/2 : 0.0003999417926084776 9.659511988726353e-05\n",
      "ppl : 20.672997549192942\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEZZIE: So tell me ... am I still an angel?\\nJACOB: With wings. You transport me, you know that? You carry me away.\\nJEZZIE: We're all angels, you know ... ... and devils. It's just what you choose to see.\\nJACOB: I love you, Jez.\\nJEZZIE: I know.\\nJACOB: Underneath all the bullshit, just\\nJEZZIE: Remember that.\\nJACOB: You know what? I feel ... exorcised ... like the demons are gone.\\nJEZZIE: How come? The army?\\n\\n\", 'answer': \"In a way. At least now I have some idea of what was happening. If we can only get them to admit ... to explain what they did ... I don't know. Maybe it'd clear things up in my head. I'll tell you something, Jez, honestly ... I thought they were real.\", 'gold_tag': 'JACOB is currently embarking on a journey of self-discovery and dealing with a complex issue with the army , The military has been involved in something disturbing that JACOB wants them to admit', 'last_speaker': 'JACOB'}\n",
      "Last word -> JACOB : \"In a way. At least now I have some idea of what was happening. If we can only get them to admit ... to explain what they did ... I don't know. Maybe it'd clear things up in my head. I'll tell you something, Jez, honestly ... I thought they were real.\"\n",
      "prediction :  The army? You know what? I don't think the army's got a fucking clue what's going on. I don't think they know what they're fighting.\n",
      "Real answer : In a way. At least now I have some idea of what was happening. If we can only get them to admit ... to explain what they did ... I don't know. Maybe it'd clear things up in my head. I'll tell you something, Jez, honestly ... I thought they were real.\n",
      "Bert Score : {'precision': [0.8572150468826294], 'recall': [0.8318834900856018], 'f1': [0.844359278678894], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.26829268292682923, 'rouge2': 0.075, 'rougeL': 0.17073170731707316, 'rougeLsum': 0.17073170731707316}\n",
      "bleu 1/2 : 0.08150292615478538 0.03395955256449391\n",
      "ppl : 8.303224270045838\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEZZIE: I put a frozen dinner in the oven, a Manhandler. It'll be ready at a quarter of. I threw a little salad together. It's in the fridge. I also bought some apple juice, Red Cheek. Don't drink it all. Oh, and Jake, your lawyer called.\\nJACOB: He did? When?\\nJEZZIE: While you were in the shower.\\nJACOB: Why didn't you call me?\\nJEZZIE: He didn't give me a chance. Look, honey, don't get upset, but he's not taking your case.\\nJACOB: What? What do you mean?\\nJEZZIE: He said you didn't have one.\\nJACOB: What's he talking about?\\nJEZZIE: I don't know. That's all he said. He wasn't very friendly. Oh, yeah. He said your buddies backed down. They chickened out, he said.\\nJACOB: I don't believe this.\\n\\n\", 'answer': \"Baby, I'm sorry. I feel terrible. I'd stay and talk but I'm so late. Look, don't be upset. We'll talk when I get home. See you around midnight. Bye. And don't brood. Watch T.V. or something.\", 'gold_tag': \"JEZZIE is conscious of her own schedule , JEZZIE is preparing to leave and informs JACOB that she'll return home around midnight\", 'last_speaker': 'JEZZIE'}\n",
      "Last word -> JEZZIE : \"Baby, I'm sorry. I feel terrible. I'd stay and talk but I'm so late. Look, don't be upset. We'll talk when I get home. See you around midnight. Bye. And don't brood. Watch T.V. or something.\"\n",
      "prediction :  Maybe it's for the best.\n",
      "Real answer : Baby, I'm sorry. I feel terrible. I'd stay and talk but I'm so late. Look, don't be upset. We'll talk when I get home. See you around midnight. Bye. And don't brood. Watch T.V. or something.\n",
      "Bert Score : {'precision': [0.8448445796966553], 'recall': [0.8208572268486023], 'f1': [0.8326781392097473], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 23.361445741630963\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEZZIE: What are you doing here? Are you all right? How do you expect to pay for this? Everyone's looking for you, Jake. I dodged people all over the place, you're gonna do.\\nJACOB: I'm gonna make love to you. That's what I'm gonna do.\\nJEZZIE: Are you out of your mind?\\nJACOB: Yep. Finally. I love you, Jez.\\nJEZZIE: God, I can't keep up with all your changes.\\nJACOB: Me neither.\\n\\n\", 'answer': \"What's gotten into you?\", 'gold_tag': 'Everyday Language', 'last_speaker': 'JEZZIE'}\n",
      "Last word -> JEZZIE : \"What's gotten into you?\"\n",
      "prediction :  So, what are you gonna do?\n",
      "Real answer : What's gotten into you?\n",
      "Bert Score : {'precision': [0.8825243711471558], 'recall': [0.8555698394775391], 'f1': [0.8688380718231201], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.3636363636363636, 'rouge2': 0.0, 'rougeL': 0.3636363636363636, 'rougeLsum': 0.3636363636363636}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 29.80672813025529\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEZZIE: I want to go with you, Jake. Wherever you go.\\nJACOB: It's not practical, Jez. It'll be hard enough alone.\\nJEZZIE: I can waitress. I'm good.\\nJACOB: No. Things are too hot. Later. I'll send for you.\\nJEZZIE: Bullshit!\\nJACOB: I promise.\\nJEZZIE: Please.\\nJACOB: No. I'm a marked man, Jez. I'm the only one left. I don't want to expose you to that. It's not right for you or me. Be reasonable.\\nJEZZIE: Reasonable? Reasonable? Jake ... You're gettin' me angry.\\nJACOB: I love you when you're angry.\\n\\n\", 'answer': \"Oh yeah? Try leavin' without me.\", 'gold_tag': 'JEZZIE is willing to accompany JACOB despite the unclear but evidently dangerous circumstances , JEZZIE displays a strong-willed temperament, refusing to back down from her decision to accompany JACOB', 'last_speaker': 'JEZZIE'}\n",
      "Last word -> JEZZIE : \"Oh yeah? Try leavin' without me.\"\n",
      "prediction :  I want to go with you, Jake. Wherever you go.\n",
      "Real answer : Oh yeah? Try leavin' without me.\n",
      "Bert Score : {'precision': [0.8615984916687012], 'recall': [0.8316671252250671], 'f1': [0.8463682532310486], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 21.142712436304592\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEZZIE: So tell me ... am I still an angel?\\n\\n', 'answer': 'With wings. You transport me, you know that? You carry me away.', 'gold_tag': 'JACOB expresses romantic feelings towards JEZZIE , JACOB views JEZZIE as a transportive figure', 'last_speaker': 'JACOB'}\n",
      "Last word -> JACOB : \"With wings. You transport me, you know that? You carry me away.\"\n",
      "prediction :  You are still an angel.\n",
      "Real answer : With wings. You transport me, you know that? You carry me away.\n",
      "Bert Score : {'precision': [0.8717209100723267], 'recall': [0.8508138060569763], 'f1': [0.8611404895782471], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.11764705882352941, 'rouge2': 0.0, 'rougeL': 0.11764705882352941, 'rougeLsum': 0.11764705882352941}\n",
      "bleu 1/2 : 0.0493193927883213 0.017437038542312454\n",
      "ppl : 126.52196817970972\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACOB: NO!\\n\\n', 'answer': 'Jake, are you all ... ? Jake? Jake?', 'gold_tag': 'Everyday Language', 'last_speaker': 'JEZZIE'}\n",
      "Last word -> JEZZIE : \"Jake, are you all ... ? Jake? Jake?\"\n",
      "prediction :  I know.\n",
      "Real answer : Jake, are you all ... ? Jake? Jake?\n",
      "Bert Score : {'precision': [0.8667527437210083], 'recall': [0.7922000885009766], 'f1': [0.8278012275695801], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 663.9337011017111\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJEZZIE: It's going to be all right, Jake. It's going to be all right. Don't be afraid. I've got you now.\\n\\n\", 'answer': 'Hold me, Jezzie. Hold me.', 'gold_tag': 'Everyday Language', 'last_speaker': 'JACOB'}\n",
      "Last word -> JACOB : \"Hold me, Jezzie. Hold me.\"\n",
      "prediction :  I can't believe you're here. I can't believe you're here with me.\n",
      "Real answer : Hold me, Jezzie. Hold me.\n",
      "Bert Score : {'precision': [0.8450616002082825], 'recall': [0.870082437992096], 'f1': [0.857389509677887], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.09523809523809523, 'rouge2': 0.0, 'rougeL': 0.09523809523809523, 'rougeLsum': 0.09523809523809523}\n",
      "bleu 1/2 : 0.08333333333333333 0.027524094128159027\n",
      "ppl : 7.034041524386954\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nJACOB: Hello? Is anyone home? Jed? Elie? Dad- dy's here. Sarah, is that you? I hope you don't mind. I needed to come home.\\nJEZZIE: Hello, Jake. I knew you'd come here in the end.\\nJACOB: Where's Sarah? Where are the boys?\\nJEZZIE: Sit down, Jake.\\nJACOB: Where are they?\\nJEZZIE: Sit down!\\nJACOB: No! What's going on? Where's my family?\\nJEZZIE: It's over, Jake. It's all over.\\nJACOB: Where have they gone?\\nJEZZIE: Wake up! Stop playing with yourself. It's finished.\\nJACOB: What's going on? This isn't happening.\\nJEZZIE: Your capacity for self-delusion is remarkable, Dr. Singer.\\nJACOB: Oh God!\\nJEZZIE: What's wrong, Jake? Forget to take your antidote?\\nJACOB: Goddamn you!\\n\\n\", 'answer': \"I loved your chemist, Jake. The height of fantasy. And your vision of paradise. A most romantic creation. You're quite a dreamer, Jake. Only it's time to wake up. There is nowhere to run, Jacob. You're home.\", 'gold_tag': \"JEZZIE's remarks about JACOB's chemist and his vision of paradise\", 'last_speaker': 'JEZZIE'}\n",
      "Last word -> JEZZIE : \"I loved your chemist, Jake. The height of fantasy. And your vision of paradise. A most romantic creation. You're quite a dreamer, Jake. Only it's time to wake up. There is nowhere to run, Jacob. You're home.\"\n",
      "prediction :  You're in a state of suspended animation, Jake.\n",
      "Real answer : I loved your chemist, Jake. The height of fantasy. And your vision of paradise. A most romantic creation. You're quite a dreamer, Jake. Only it's time to wake up. There is nowhere to run, Jacob. You're home.\n",
      "Bert Score : {'precision': [0.8858950734138489], 'recall': [0.8647644519805908], 'f1': [0.8752022981643677], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.20408163265306123, 'rouge2': 0.0425531914893617, 'rougeL': 0.163265306122449, 'rougeLsum': 0.163265306122449}\n",
      "bleu 1/2 : 0.013324548668177743 0.002252259799849522\n",
      "ppl : 22.486272805283413\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nYORGI: I don't believe it! You can't shoot a cop in the middle of the street!\\nXANDER: Had to do what I had to do.\\n\\n\", 'answer': \"You say you get a million, you get the million. Some cop gives us shit, he's dead. Jesus Christ, man, you're hard-core!\", 'gold_tag': \"Yorgi acknowledges Xander's ruthlessness , Yorgi is less accustomed to such direct and violent tactics\", 'last_speaker': 'YORGI'}\n",
      "Last word -> YORGI : \"You say you get a million, you get the million. Some cop gives us shit, he's dead. Jesus Christ, man, you're hard-core!\"\n",
      "prediction :  You're gonna get us all killed!\n",
      "Real answer : You say you get a million, you get the million. Some cop gives us shit, he's dead. Jesus Christ, man, you're hard-core!\n",
      "Bert Score : {'precision': [0.8533276319503784], 'recall': [0.8414306640625], 'f1': [0.8473373651504517], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.25, 'rouge2': 0.06666666666666667, 'rougeL': 0.1875, 'rougeLsum': 0.1875}\n",
      "bleu 1/2 : 0.023161150407600514 0.0056733000354475885\n",
      "ppl : 24.417098653154575\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nXANDER: You got a great set-up here Yorgi. You really know how to live.\\nYORGI: It's a beautiful town, Prague. It's been good to me.\\nXANDER: I've been here before, when I was a kid. My old man was in the service, we used to live on the Army base in Hamburg.\\nYORGI: You, an Army brat? I don't see that one at all. Did you join the service as well?\\nXANDER: Hell no. My dad was a straight up tin soldier. Somehow he pissed this general off and got himself dishonorably discharged. Had a court martial and everything. The charges were total bullshit, so he was sure he'd get his name cleared, but it didn't happen.\\nYORGI: Connections and politics, it's the same everywhere.\\nXANDER: My old man, he bought into the system, and it screwed him. So he swallowed a bullet. Me, I don't believe in nothing I can't see and touch.\\n\\n\", 'answer': \"Next week these idiots are having a peace conference here. What the hell are they going to talk about? It's the system itself that causes all the world's problems. You're okay, buddy. Come on, it's getting early.\", 'gold_tag': 'YORGI mentions the upcoming peace conference to be held the next week , YORGI is critical of politics and the system', 'last_speaker': 'YORGI'}\n",
      "Last word -> YORGI : \"Next week these idiots are having a peace conference here. What the hell are they going to talk about? It's the system itself that causes all the world's problems. You're okay, buddy. Come on, it's getting early.\"\n",
      "prediction :  That's a good attitude to have.\n",
      "Real answer : Next week these idiots are having a peace conference here. What the hell are they going to talk about? It's the system itself that causes all the world's problems. You're okay, buddy. Come on, it's getting early.\n",
      "Bert Score : {'precision': [0.8591793179512024], 'recall': [0.8312219381332397], 'f1': [0.8449694514274597], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.16666666666666669, 'rouge2': 0.0, 'rougeL': 0.08333333333333334, 'rougeLsum': 0.08333333333333334}\n",
      "bleu 1/2 : 0.0019011829993358005 0.00046569282560268016\n",
      "ppl : 29.92446566313935\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nYORGI: Xander, my friend, that can only be you. Why don't we put our weapons down for a few minutes and discuss this like friends. How would you like to come to work for us instead? We could Rage Against the Machine together.\\nXANDER: Speaking of people that are full of shit, funny you should mention those guys! They put their records out through Sony, one of the biggest corporate machines on the planet. Some revolutionaries, huh?\\n\\n\", 'answer': \"Come on, you're the one who's fooling yourself. Why risk your life for your government when we can offer you a future that is truly free?\", 'gold_tag': \"YORGI is persuasive , YORGI offers a future of 'true' freedom\", 'last_speaker': 'YORGI'}\n",
      "Last word -> YORGI : \"Come on, you're the one who's fooling yourself. Why risk your life for your government when we can offer you a future that is truly free?\"\n",
      "prediction :  Well, maybe they're just a little more aware of what's going on than you are.\n",
      "Real answer : Come on, you're the one who's fooling yourself. Why risk your life for your government when we can offer you a future that is truly free?\n",
      "Bert Score : {'precision': [0.8706993460655212], 'recall': [0.849694013595581], 'f1': [0.8600684404373169], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.22222222222222224, 'rouge2': 0.0, 'rougeL': 0.13333333333333333, 'rougeLsum': 0.13333333333333333}\n",
      "bleu 1/2 : 0.06404070681197324 0.014822543392541448\n",
      "ppl : 10.39911617614693\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nYORGI: Hurry up, kill him!\\n\\n', 'answer': \"Hey! We're on your side!\", 'gold_tag': \"XANDER suggests he is on YORGI's side\", 'last_speaker': 'XANDER'}\n",
      "Last word -> XANDER : \"Hey! We're on your side!\"\n",
      "prediction :  No.\n",
      "Real answer : Hey! We're on your side!\n",
      "Bert Score : {'precision': [0.9426082968711853], 'recall': [0.8302090167999268], 'f1': [0.8828454613685608], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 1275.3241709894667\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADAM: Is that a birthday cake?!\\nCLERK: Yes, it is.\\nADAM: Gee-ma-nee!\\n\\n', 'answer': 'Bakersfield.', 'gold_tag': 'CLERK has knowledge of Bakersfield', 'last_speaker': 'CLERK'}\n",
      "Last word -> CLERK : \"Bakersfield.\"\n",
      "prediction :  I know, right?\n",
      "Real answer : Bakersfield.\n",
      "Bert Score : {'precision': [0.8099702000617981], 'recall': [0.8353472948074341], 'f1': [0.8224630355834961], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 116.74439390378859\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADAM: Good evening. I want to stay at this hotel.\\nCLERK: Fill this out please. And I'll need a card.\\nADAM: A card?\\nCLERK: Yes, sir.\\n\\n\", 'answer': 'Of course!', 'gold_tag': 'Everyday Language', 'last_speaker': 'ADAM'}\n",
      "Last word -> ADAM : \"Of course!\"\n",
      "prediction :  Oh, okay.\n",
      "Real answer : Of course!\n",
      "Bert Score : {'precision': [0.881222128868103], 'recall': [0.8373542428016663], 'f1': [0.8587282299995422], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 279.201484853545\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nADAM: Hi. I, deed a., guitar case.\\nCLERK: What kind of guitar do yoiz have?\\nADAM: T don't have a guitar.\\n\\n\", 'answer': 'Okay. Yeah.we got those. i', 'gold_tag': 'CLERK works in a place , The place sells guitar cases', 'last_speaker': 'CLERK'}\n",
      "Last word -> CLERK : \"Okay. Yeah.we got those. i\"\n",
      "prediction :  What are you doing with the case?\n",
      "Real answer : Okay. Yeah.we got those. i\n",
      "Bert Score : {'precision': [0.8323779106140137], 'recall': [0.8667583465576172], 'f1': [0.8492202758789062], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 69.19396729671432\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCATHY: She was fine. Said it was a dreadful bore, what with Mona Lauder and her gossip.\\nFRANK: Cathy, I’m sorry.\\nCATHY: Darling, you’ve nothing to be sorry for. It was all just a silly wretched mistake!\\nFRANK: Feel so tired.\\n\\n', 'answer': 'Course you do. You sleep now.', 'gold_tag': 'CATHY is a sympathetic and understanding person , FRANK desires rest', 'last_speaker': 'CATHY'}\n",
      "Last word -> CATHY : \"Course you do. You sleep now.\"\n",
      "prediction :  You’re tired. You’re all in.\n",
      "Real answer : Course you do. You sleep now.\n",
      "Bert Score : {'precision': [0.8660261034965515], 'recall': [0.8869452476501465], 'f1': [0.8763608336448669], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.30769230769230765, 'rouge2': 0.0, 'rougeL': 0.30769230769230765, 'rougeLsum': 0.30769230769230765}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 46.60965012108341\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCATHY: Mr. Maynard... left an estimate... for the roof. I put it in the kitchen. Twelve hundred something. I assume you’ll want - a second opinion...\\nFRANK: Cathy -\\nCATHY: I can’t - Silence.\\nFRANK: I know. I don’t -\\nCATHY: What?\\nFRANK: I don't even... See... Once. Long time ago. Long long time ago. I had... problems. I just figured... that was - that was it. I never... imagined...\\nCATHY: You had... problems?\\nFRANK: Yes.\\nCATHY: You never... spoke to anyone? A doctor?\\nFRANK: No.\\nCATHY: No one? I don't... I don't understand.\\nFRANK: I don't either.\\nCATHY: What if... I mean there must be people who - who...\\nFRANK: I don't know.\\n\\n\", 'answer': \"There must be. Frank? Because... Otherwise, I just - I don't know what - Oh Frank! Thank you.\", 'gold_tag': 'CATHY is perhaps a bit worried', 'last_speaker': 'CATHY'}\n",
      "Last word -> CATHY : \"There must be. Frank? Because... Otherwise, I just - I don't know what - Oh Frank! Thank you.\"\n",
      "prediction :  I don't know what to say...\n",
      "Real answer : There must be. Frank? Because... Otherwise, I just - I don't know what - Oh Frank! Thank you.\n",
      "Bert Score : {'precision': [0.8689802885055542], 'recall': [0.821735143661499], 'f1': [0.8446975946426392], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.4166666666666667, 'rouge2': 0.36363636363636365, 'rougeL': 0.4166666666666667, 'rougeLsum': 0.4166666666666667}\n",
      "bleu 1/2 : 0.09022352215774179 0.08559354856234011\n",
      "ppl : 22.005226284243722\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCATHY: But Frank, you must have liked him enough to want to see him again.\\nFRANK: Who else am I going see?\\nCATHY: Well - I'm sure there are numerous doctors - in Hartford or in Springfield - if you don't - if you aren't certain about -\\nFRANK: Look! I just want to get the whole fucking thing over with! Can you understand that?!\\nCATHY: Frank! Please don't -\\n\\n\", 'answer': \"I'm sorry. I'm sorry. Cathy, I'm so sorry.\", 'gold_tag': \"FRANK shows regret after his outburst , FRANK is mindful of CATHY's feelings\", 'last_speaker': 'FRANK'}\n",
      "Last word -> FRANK : \"I'm sorry. I'm sorry. Cathy, I'm so sorry.\"\n",
      "prediction :  I can't believe that I'm stuck with you -\n",
      "Real answer : I'm sorry. I'm sorry. Cathy, I'm so sorry.\n",
      "Bert Score : {'precision': [0.8306692838668823], 'recall': [0.8575840592384338], 'f1': [0.8439120650291443], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.28571428571428564, 'rouge2': 0.10526315789473685, 'rougeL': 0.28571428571428564, 'rougeLsum': 0.28571428571428564}\n",
      "bleu 1/2 : 0.11111111111111109 0.03726779962499649\n",
      "ppl : 17.728158599932353\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCATHY: Frank?\\nFRANK: Hmm.\\nCATHY: Did you see him?\\nFRANK: Yea.\\nCATHY: When?\\nFRANK: Yesterday.\\nCATHY: You didn't say a word. So how was it? With Bowman? Did you feel -\\nFRANK: It's fine.\\nCATHY: And there's nothing more you care to share with your very own adoring wife?\\nFRANK: Cathleen, what I discuss with this doctor. It's private. That's - part of it. Alright? I'm sorry.\\n\\n\", 'answer': \"I understand, dear. I do. Oh and Frank, wait'll you see the hors d'oeuvres! The caterers are doing such a marvelous job. I think you're going to be very pleased this year, darling. I really do.\", 'gold_tag': \"CATHY is in charge of organizing events at home , CATHY has organized an event involving caterers who are preparing hors d'oeuvres, which will happen soon\", 'last_speaker': 'CATHY'}\n",
      "Last word -> CATHY : \"I understand, dear. I do. Oh and Frank, wait'll you see the hors d'oeuvres! The caterers are doing such a marvelous job. I think you're going to be very pleased this year, darling. I really do.\"\n",
      "prediction :  That's it. You're sorry?\n",
      "Real answer : I understand, dear. I do. Oh and Frank, wait'll you see the hors d'oeuvres! The caterers are doing such a marvelous job. I think you're going to be very pleased this year, darling. I really do.\n",
      "Bert Score : {'precision': [0.8283976316452026], 'recall': [0.8062841892242432], 'f1': [0.8171913623809814], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08888888888888889, 'rouge2': 0.046511627906976744, 'rougeL': 0.08888888888888889, 'rougeLsum': 0.08888888888888889}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 44.82634951821359\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nCATHY: No. I was awake.\\nFRANK: I didn’t want to - upset the children.\\nCATHY: No. Of course.\\nFRANK: How are they, by the way?\\n\\n', 'answer': \"Fine. Just fine. They still ask when you'll be coming home.\", 'gold_tag': \"CATHY is a mother concerned about her children's welfare , CATHY is dealing with a separation from FRANK , Both CATHY and FRANK share the experience of being parents to their children who are missing FRANK\", 'last_speaker': 'CATHY'}\n",
      "Last word -> CATHY : \"Fine. Just fine. They still ask when you'll be coming home.\"\n",
      "prediction :  I don’t know. They’re not here.\n",
      "Real answer : Fine. Just fine. They still ask when you'll be coming home.\n",
      "Bert Score : {'precision': [0.8606200218200684], 'recall': [0.8706073760986328], 'f1': [0.8655849099159241], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1, 'rouge2': 0.0, 'rougeL': 0.1, 'rougeLsum': 0.1}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 27.962809544135094\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLANDON: Reverend Sullivan. Can I ask you something?\\nREV. SULLIVAN: Does it have to do with Jamie?\\n\\n', 'answer': 'Yes, sir.', 'gold_tag': 'Everyday Language', 'last_speaker': 'LANDON'}\n",
      "Last word -> LANDON : \"Yes, sir.\"\n",
      "prediction :  Yes.\n",
      "Real answer : Yes, sir.\n",
      "Bert Score : {'precision': [0.964163601398468], 'recall': [0.8595567345619202], 'f1': [0.9088600873947144], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.6666666666666666, 'rouge2': 0.0, 'rougeL': 0.6666666666666666, 'rougeLsum': 0.6666666666666666}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2104.611116571625\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLANDON: I'd like to take Jamie to dinner on New Year's Eve.\\nREV. SULLIVAN: That won't be possible.\\nLANDON: I'm sorry I haven't always treated Jamie the way -- I should have. She deserves better. I care for her.\\nREV. SULLIVAN: I don't want to see her hurt.\\nLANDON: I wouldn't do that --\\nREV. SULLIVAN: This week.\\nLANDON: Ever again.\\n\\n\", 'answer': 'Have her home by one. And drive carefully.', 'gold_tag': 'REV. SULLIVAN insists that Jamie should be home by one on New Year’s Eve', 'last_speaker': 'REV. SULLIVAN'}\n",
      "Last word -> REV. SULLIVAN : \"Have her home by one. And drive carefully.\"\n",
      "prediction :  Jamie deserves better.\n",
      "Real answer : Have her home by one. And drive carefully.\n",
      "Bert Score : {'precision': [0.8600559234619141], 'recall': [0.8556512594223022], 'f1': [0.8578479290008545], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 227.44197288198222\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nREV. SULLIVAN: Landon. You're not the quiet type.\\nLANDON: No.\\nREV. SULLIVAN: So talk to us about something.\\nLANDON: Like what, sir?\\nREV. SULLIVAN: You decide. How about your family?\\nLANDON: Okay. Sure. My grandfather. When he was seven, he shook the hand of an old guy, a war vet or something, who had once shaken President Lincoln's hand. Made a big impression on him. My cousin Mike. He's from a big family. He's the fifth kid. He heard that every fifth child in the world is Chinese. So he thought he was. We didn't tell him any different for years --\\nREV. SULLIVAN: Your parents are divorced?\\nLANDON: Since I was five. My mom's a cocktail waitress.\\nREV. SULLIVAN: How do you -- the two of you -- get by?\\nLANDON: Materially or spiritually?\\nREV. SULLIVAN: Either. Both.\\n\\n\", 'answer': \"I don't know. We used to try to believe in each other.\", 'gold_tag': 'LANDON possesses a level of depth', 'last_speaker': 'LANDON'}\n",
      "Last word -> LANDON : \"I don't know. We used to try to believe in each other.\"\n",
      "prediction :  Materially, we don't. Spiritually, we're okay.\n",
      "Real answer : I don't know. We used to try to believe in each other.\n",
      "Bert Score : {'precision': [0.8523833155632019], 'recall': [0.8645883202552795], 'f1': [0.8584424257278442], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.2857142857142857, 'rouge2': 0.10526315789473685, 'rougeL': 0.2857142857142857, 'rougeLsum': 0.2857142857142857}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 64.22947609263062\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nREV. SULLIVAN: It's her decision and she's decided not to tell people -- at least for now.\\nLANDON: How -- how long does she have?\\nREV. SULLIVAN: Two, three months. Maybe less. Maybe more.\\nLANDON: So you've given up.\\nREV. SULLIVAN: Her doctors have. Jamie and I. We're still praying for a miracle.\\nLANDON: Praying.\\nREV. SULLIVAN: Landon. We've lived with this for over a year now and --\\n\\n\", 'answer': 'If there is a God, how could he let this happen??!!', 'gold_tag': 'LANDON is conflicted about religion', 'last_speaker': 'LANDON'}\n",
      "Last word -> LANDON : \"If there is a God, how could he let this happen??!!\"\n",
      "prediction :  What do you want me to do?\n",
      "Real answer : If there is a God, how could he let this happen??!!\n",
      "Bert Score : {'precision': [0.8422514200210571], 'recall': [0.8201538920402527], 'f1': [0.831055760383606], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 21.92352315085215\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLANDON: Where's Jamie?!\\n\\n\", 'answer': 'At school. Where you should be.', 'gold_tag': 'REV. SULLIVAN is an adult , REV. SULLIVAN may have a role in the managing or administration of a school', 'last_speaker': 'REV. SULLIVAN'}\n",
      "Last word -> REV. SULLIVAN : \"At school. Where you should be.\"\n",
      "prediction :  He's not here, Landon.\n",
      "Real answer : At school. Where you should be.\n",
      "Bert Score : {'precision': [0.8663851022720337], 'recall': [0.8784791231155396], 'f1': [0.8723902106285095], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 57.837133400740115\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLANDON: I've almost finished the rocker. Did she order mirrors?\\nREV. SULLIVAN: In there. You have materials for the side bearings?\\nLANDON: I'm using an old phonographic turntable.\\nREV. SULLIVAN: For the focuser?\\nLANDON: A chrome-plated brass pipe from a drain line. You know about this stuff?\\nREV. SULLIVAN: I helped Jamie with the first one.\\nLANDON: I thought she built it herself.\\nREV. SULLIVAN: She did. But hardly anyone does anything truly alone.\\n\\n\", 'answer': 'I need to do this alone.', 'gold_tag': 'Landon is determined to finish the project alone', 'last_speaker': 'LANDON'}\n",
      "Last word -> LANDON : \"I need to do this alone.\"\n",
      "prediction :  That's a good way to say it.\n",
      "Real answer : I need to do this alone.\n",
      "Bert Score : {'precision': [0.8847100734710693], 'recall': [0.8962308168411255], 'f1': [0.8904331922531128], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.14285714285714288, 'rouge2': 0.0, 'rougeL': 0.14285714285714288, 'rougeLsum': 0.14285714285714288}\n",
      "bleu 1/2 : 0.14285714285714285 0.048795003647426664\n",
      "ppl : 26.080422336235454\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLANDON: A few minutes ago. I have to ask you something.\\n\\n', 'answer': \"When I was seventeen, I was sent up for a year for stealing a car. Sometimes I still feel that boy inside me and I don't like him. But I like you.\", 'gold_tag': 'REV. SULLIVAN was sent up for a year , REV. SULLIVAN was sent up for stealing a car , REV. SULLIVAN was seventeen at the time', 'last_speaker': 'REV. SULLIVAN'}\n",
      "Last word -> REV. SULLIVAN : \"When I was seventeen, I was sent up for a year for stealing a car. Sometimes I still feel that boy inside me and I don't like him. But I like you.\"\n",
      "prediction :  Ask me anything.\n",
      "Real answer : When I was seventeen, I was sent up for a year for stealing a car. Sometimes I still feel that boy inside me and I don't like him. But I like you.\n",
      "Bert Score : {'precision': [0.8774373531341553], 'recall': [0.837302565574646], 'f1': [0.8569002747535706], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.05555555555555555, 'rouge2': 0.0, 'rougeL': 0.05555555555555555, 'rougeLsum': 0.05555555555555555}\n",
      "bleu 1/2 : 2.1120235358186548e-05 8.179831981023755e-06\n",
      "ppl : 135.49381725059797\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINCOLN: S o r r y I'm late.\\nESTER: I t ' s okay. I was waiting to tell you something anyway. Guess what? M y baby - I felt it move. And it's the weirdest feeling too. I can't explain it. It's like being more... more h e r e . I'm sorry. I'm all excited and we're supposed to be finding peace of mind.\\nLINCOLN: I have to cancel, Ester.\\nESTER: S o I'll see you at breakfast tomorrow?\\nLINCOLN: I don't think so.\\nESTER: Did I do something wrong, Lincoln?\\n\\n\", 'answer': 'No.', 'gold_tag': 'Everyday Language', 'last_speaker': 'LINCOLN'}\n",
      "Last word -> LINCOLN : \"No.\"\n",
      "prediction :  I'm sorry, Ester. I don't think I can do this anymore.\n",
      "Real answer : No.\n",
      "Bert Score : {'precision': [0.8301035165786743], 'recall': [0.9147872924804688], 'f1': [0.8703904151916504], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 14.962100814505416\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nESTER: Please . . . don't come any closer. I don't want to get contaminated.\\nLINCOLN: Ester, I'm not contaminated.\\nESTER: But they said...\\nLINCOLN: I'm not contaminated! Contaminants, pathogens... it's just what they tell us to keep us inside.\\nESTER: What do you mean?\\nLINCOLN: I saw it. Why they keep us here. To use us. To take things from us.\\nESTER: You're not making sense.\\nLINCOLN: Your baby... they're going to take your baby away... you understand?\\nESTER: M y baby? Why would they do that?\\nLINCOLN: I don't know! But I saw it!\\nESTER: You're scaring me, Lincoln... I want to go back now.\\nLINCOLN: You can't go back! Don't you get it? A VOICE (O.S.) N o b o d y move! Stay right where you are!\\nESTER: Don't hurt him! Lincoln?\\n\\n\", 'answer': 'RUN!!!', 'gold_tag': 'Everyday Language', 'last_speaker': 'LINCOLN'}\n",
      "Last word -> LINCOLN : \"RUN!!!\"\n",
      "prediction :  I'm sorry, Ester. I'm sorry.\n",
      "Real answer : RUN!!!\n",
      "Bert Score : {'precision': [0.8484508395195007], 'recall': [0.8215881586074829], 'f1': [0.8348034620285034], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 36.223794012065746\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINCOLN: We have to keep going.\\nESTER: P l e a s e . . . Please, I want to go back...\\n\\n', 'answer': \"T h o s e men - that's what they want too. We have to keep going, Ester.\", 'gold_tag': 'Everyday Language', 'last_speaker': 'LINCOLN'}\n",
      "Last word -> LINCOLN : \"T h o s e men - that's what they want too. We have to keep going, Ester.\"\n",
      "prediction :  I can't let you go back.\n",
      "Real answer : T h o s e men - that's what they want too. We have to keep going, Ester.\n",
      "Bert Score : {'precision': [0.8789147138595581], 'recall': [0.8166349530220032], 'f1': [0.8466309905052185], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.08, 'rouge2': 0.0, 'rougeL': 0.08, 'rougeLsum': 0.08}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 47.45616949760008\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nESTER: Lincoln , what is that? On your face?\\nLINCOLN: A r e you alright?\\nESTER: M y throat... it feels dry...\\n\\n', 'answer': \"O k a y . . . I'll get you some water.\", 'gold_tag': \"LINCOLN is concerned about ESTER's health\", 'last_speaker': 'LINCOLN'}\n",
      "Last word -> LINCOLN : \"O k a y . . . I'll get you some water.\"\n",
      "prediction :  I can't help you with that, okay? I'm sorry.\n",
      "Real answer : O k a y . . . I'll get you some water.\n",
      "Bert Score : {'precision': [0.860471248626709], 'recall': [0.804054856300354], 'f1': [0.8313069939613342], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.1904761904761905, 'rouge2': 0.0, 'rougeL': 0.1904761904761905, 'rougeLsum': 0.1904761904761905}\n",
      "bleu 1/2 : 0.07961459006375435 0.026703545307500107\n",
      "ppl : 15.239696814605587\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nESTER: I can't... I can't breathe... my throat... it's so... dry...\\nLINCOLN: I ' l l find you some water. I t ' s going to be okay, Ester.\\nESTER: N o . . . no, it isn't...\\nLINCOLN: I ' l l find you some water, okay?\\nESTER: An d then what, Lincoln?\\nLINCOLN: I ' l l find another way. Out of state.\\nESTER: An d then what? What if they find us?\\nLINCOLN: The n we'll keep going.\\nESTER: I can't... I can't run anymore...\\nLINCOLN: We ' l l keep going till we get there.\\nESTER: The Island... You mean, The Island?\\nLINCOLN: N o w I'm going to get some water. But I want you to stay here. It'll be safer.\\n\\n\", 'answer': \"Don't go yet. Stay with me, Lincoln. Stay with me for a little while.\", 'gold_tag': \"ESTER's temporal information\", 'last_speaker': 'ESTER'}\n",
      "Last word -> ESTER : \"Don't go yet. Stay with me, Lincoln. Stay with me for a little while.\"\n",
      "prediction :  Okay.\n",
      "Real answer : Don't go yet. Stay with me, Lincoln. Stay with me for a little while.\n",
      "Bert Score : {'precision': [0.9116907119750977], 'recall': [0.8422025442123413], 'f1': [0.8755700588226318], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 2086.293093463323\n",
      "This is a wo tag evaluation\n",
      "{'prompt': '\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINCOLN: A r e you alright?\\nESTER: I feel better after I sleep.\\n\\n', 'answer': 'The man out there... he said everything has a spirit... every living thing... but not...', 'gold_tag': 'LINCOLN is interested in spiritual aspects of life', 'last_speaker': 'LINCOLN'}\n",
      "Last word -> LINCOLN : \"The man out there... he said everything has a spirit... every living thing... but not...\"\n",
      "prediction :  It's good that you're feeling better.\n",
      "Real answer : The man out there... he said everything has a spirit... every living thing... but not...\n",
      "Bert Score : {'precision': [0.8416221141815186], 'recall': [0.8071163892745972], 'f1': [0.8240081667900085], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 16.7889936802205\n",
      "This is a wo tag evaluation\n",
      "{'prompt': \"\\nTask: Generate the next response in the dialogue based on the provided history. The response should logically follow and predict the next reply considering the context of the conversation.\\n\\n**Dialogue History**:\\nLINCOLN: He l l o , stranger.\\nESTER: You look tired, Lincoln.\\nLINCOLN: Ester...\\nESTER: I t ' s okay. I know. Katherine told me. She told me a lot of things. About how they used a tiny part of her to make me. She said it wasn't so very different.\\nLINCOLN: What do you mean?\\nESTER: F r o m this... From having a baby. She told me how they use us... And I keep thinking... about the others... the ones we left behind, about how they'll never know... how they'll... I'm going to be okay, Lincoln.\\n\\n\", 'answer': 'I know.', 'gold_tag': 'LINCOLN exhibits concern and care for ESTER', 'last_speaker': 'LINCOLN'}\n",
      "Last word -> LINCOLN : \"I know.\"\n",
      "prediction :  Ester...\n",
      "Real answer : I know.\n",
      "Bert Score : {'precision': [0.809217631816864], 'recall': [0.8847211003303528], 'f1': [0.8452866673469543], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}\n",
      "Rouge Score : {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n",
      "bleu 1/2 : 0 0\n",
      "ppl : 4814.783748282628\n"
     ]
    }
   ],
   "source": [
    "bertscore_eval = load(\"bertscore\")\n",
    "rouge_eval = evaluate.load('rouge') \n",
    "\n",
    "for prompt in json_data:\n",
    "    bert_score, rough_score, bleu_1, bleu_2, infer_sentence, ppl = evaluation_chat_system(2, prompt ,model, tokenizer,device, bertscore_eval, rouge_eval)\n",
    "    bert.append(bert_score)\n",
    "    rough.append(rough_score)\n",
    "    bleu_1_list.append(bleu_1)\n",
    "    bleu_2_list.append(bleu_2)\n",
    "    infer.append(infer_sentence)\n",
    "    ppl_list.append(ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eb19f8-f35c-4139-a86b-5052afefb925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ber = [i['precision'][0] for i in bert]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29ade18-3cbf-45ed-873b-66134a5caf7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "818fb296-add7-4a7f-95aa-650551c84d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean(tensor_list):\n",
    "    # Move tensors to CPU and convert to numpy arrays\n",
    "    valid_tensors = [t for t in tensor_list if not torch.isnan(t)]\n",
    "    cpu_tensors = [t.cpu().numpy() for t in valid_tensors]\n",
    "    cpu_tensors = [float(i) for i in cpu_tensors]\n",
    "\n",
    "    return cpu_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15247f07-d59e-43fa-9e9c-d55a8b200c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "722.6492043087733"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sorted(calculate_mean(ppl_list))[:-50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8c9b511-1313-4d7e-8f47-e38bd926264e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.30459368245648"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([i for i in ppl_list if i< 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20ceca01-fbce-457b-8bb6-77dcf9cbbc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1739"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ppl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00c45661-23c8-4106-9a63-de5d3a3078a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10 단위로 나누고, 100 이상 값을 하나로 묶기\n",
    "bins = list(range(0, 101, 10)) + [float('inf')]\n",
    "hist, bin_edges = np.histogram(ppl_list, bins=bins)\n",
    "\n",
    "# 막대 그래프 그리기\n",
    "bin_labels = [f'{i}-{i+9}' for i in range(0, 100, 10)] + ['100+']\n",
    "plt.bar(bin_labels, hist, edgecolor='black')\n",
    "\n",
    "# 그래프 제목과 축 레이블 설정\n",
    "plt.title('Distribution of Data')\n",
    "plt.xlabel('Value Range')\n",
    "plt.ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9732855-7dc3-430b-aabb-62bbd2784937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAHfCAYAAACmi1eOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABZUElEQVR4nO3deXhMZ/8G8HuyjUQ2SSQRkohdaqldal9jrX2PNag29q2oWsqLUqpapX2rduXV0paiYtfa11REbCGIBAmJhOzf3x/55dRIcETkTLg/1zUX85wzZ77zGDP3nPOc5+hEREBEREREL2SidQFERERE+QWDExEREZFKDE5EREREKjE4EREREanE4ERERESkEoMTERERkUoMTkREREQqMTgRERERqcTgRERERKQSgxPRW6J48eLo16+f1mW88ebNm4cSJUrA1NQU7777rtblEFEuY3AiyodWrFgBnU6HEydOZLu8YcOGqFChwis/z7Zt2zBt2rRX3s7bYufOnRg/fjzq1KmD5cuXY9asWc9ct1+/ftDpdMrN2toaJUqUQOfOnfHLL78gPT09x3WsW7cOCxcuzPHjiejZzLQugIjyRmhoKExMXu630rZt27B48WKGJ5X27NkDExMTLFu2DBYWFi9cX6/X44cffgAAPH78GNevX8eWLVvQuXNnNGzYEL/99htsbW1fuo5169bh3LlzGDly5Es/loiej8GJ6C2h1+u1LuGlJSQkoGDBglqXodqdO3dgaWmpKjQBgJmZGfz8/AzaZs6ciTlz5mDixIkYNGgQNmzY8DpKJaIc4qE6orfE02OcUlJSMH36dJQuXRoFChSAo6Mj6tati8DAQAAZh5IWL14MAAaHlDIlJCRgzJgxcHd3h16vR9myZfHFF19ARAye9/Hjxxg+fDicnJxgY2OD999/H7du3YJOpzPYkzVt2jTodDqcP38ePXv2RKFChVC3bl0AQFBQEPr164cSJUqgQIECcHV1xYABAxAdHW3wXJnbuHjxIvz8/GBnZ4fChQvj008/hYjgxo0baNeuHWxtbeHq6or58+er6rvU1FTMmDEDJUuWhF6vR/HixTFp0iQkJSUp6+h0OixfvhwJCQlKX61YsULV9p82YcIENG/eHBs3bsTFixeV9t9++w2tW7eGm5sb9Ho9SpYsiRkzZiAtLU1Zp2HDhvjjjz9w/fp1pY7ixYsDAJKTkzFlyhRUq1YNdnZ2KFiwIOrVq4e9e/fmqE6itxH3OBHlY7Gxsbh3716W9pSUlBc+dtq0aZg9ezYGDhyImjVrIi4uDidOnMCpU6fQrFkzfPDBB4iIiEBgYCBWr15t8FgRwfvvv4+9e/fC398f7777Lv7880+MGzcOt27dwpdffqms269fP/zvf/9D7969Ubt2bezfvx+tW7d+Zl1dunRB6dKlMWvWLCWEBQYG4urVq+jfvz9cXV0RHByM77//HsHBwThy5IhBoAOAbt26oXz58pgzZw7++OMPzJw5Ew4ODvjuu+/QuHFjfP7551i7di3Gjh2LGjVqoH79+s/tq4EDB2LlypXo3LkzxowZg6NHj2L27NkICQnB5s2bAQCrV6/G999/j2PHjimH3957770X/js8S+/evbFz504EBgaiTJkyADLGtllbW2P06NGwtrbGnj17MGXKFMTFxWHevHkAgE8++QSxsbG4efOm8u9gbW0NAIiLi8MPP/yAHj16YNCgQXj48CGWLVsGX19fHDt2jIPZidQQIsp3li9fLgCee3vnnXcMHuPp6Sl9+/ZV7leuXFlat2793OcJCAiQ7D4mfv31VwEgM2fONGjv3Lmz6HQ6uXz5soiInDx5UgDIyJEjDdbr16+fAJCpU6cqbVOnThUA0qNHjyzP9+jRoyxtP/30kwCQAwcOZNnG4MGDlbbU1FQpVqyY6HQ6mTNnjtJ+//59sbS0NOiT7Jw5c0YAyMCBAw3ax44dKwBkz549Slvfvn2lYMGCz92e2nVPnz4tAGTUqFFKW3b98MEHH4iVlZUkJiYqba1btxZPT88s66ampkpSUpJB2/3798XFxUUGDBigqm6itx0P1RHlY4sXL0ZgYGCWW6VKlV74WHt7ewQHB+PSpUsv/bzbtm2Dqakphg8fbtA+ZswYiAi2b98OANixYwcA4KOPPjJYb9iwYc/c9pAhQ7K0WVpaKn9PTEzEvXv3ULt2bQDAqVOnsqw/cOBA5e+mpqaoXr06RAT+/v5Ku729PcqWLYurV68+sxYg47UCwOjRow3ax4wZAwD4448/nvv4nMrcS/Tw4UOl7cl+ePjwIe7du4d69erh0aNHuHDhwgu3aWpqqoy/Sk9PR0xMDFJTU1G9evVs+5GIsuKhOqJ8rGbNmqhevXqW9kKFCmV7CO9Jn332Gdq1a4cyZcqgQoUKaNGiBXr37q0qdF2/fh1ubm6wsbExaC9fvryyPPNPExMTeHl5GaxXqlSpZ2776XUBICYmBtOnT8f69etx584dg2WxsbFZ1vfw8DC4b2dnhwIFCsDJySlL+9PjpJ6W+RqertnV1RX29vbKa81t8fHxAGDQx8HBwZg8eTL27NmDuLg4g/Wz64fsrFy5EvPnz8eFCxcMDulm1+9ElBX3OBG9perXr48rV67gxx9/RIUKFfDDDz+gatWqyvgcrTy5VyVT165d8d///hdDhgzBpk2bsHPnTmVvVnbzHZmamqpqA5BlMPuzPD2O6nU7d+4cgH9D5oMHD9CgQQOcPXsWn332GbZs2YLAwEB8/vnnALLvh6etWbMG/fr1Q8mSJbFs2TLs2LEDgYGBaNy48SvNG0X0NuEeJ6K3mIODA/r374/+/fsjPj4e9evXx7Rp05RDXc8KC56enti1axcePnxosEck83CRp6en8md6ejrCwsJQunRpZb3Lly+rrvH+/fvYvXs3pk+fjilTpijtOTnEmBOZr+HSpUvKHjUAiIqKwoMHD5TXmttWr14NnU6HZs2aAQD27duH6OhobNq0yWAwe1hYWJbHPuvf7eeff0aJEiWwadMmg3WmTp2ay9UTvbm4x4noLfX0ISpra2uUKlXK4BT7zDmUHjx4YLBuq1atkJaWhm+++cag/csvv4ROp0PLli0BAL6+vgCAb7/91mC9r7/+WnWdmXuKnt4zlFczY7dq1Srb51uwYAEAPPcMwZyaM2cOdu7ciW7duimBM7t+SE5OztK3QMa/W3aH7rLbxtGjR3H48OFcrZ/oTcY9TkRvKW9vbzRs2BDVqlWDg4MDTpw4gZ9//hlDhw5V1qlWrRoAYPjw4fD19YWpqSm6d++Otm3bolGjRvjkk09w7do1VK5cGTt37sRvv/2GkSNHomTJksrjO3XqhIULFyI6OlqZjiBzbiI1h79sbW1Rv359zJ07FykpKShatCh27tyZ7Z6W16Fy5cro27cvvv/+e+Vw2bFjx7By5Uq0b98ejRo1yvG2U1NTsWbNGgAZg96vX7+O33//HUFBQWjUqBG+//57Zd333nsPhQoVQt++fTF8+HDodDqsXr0620ON1apVw4YNGzB69GjUqFED1tbWaNu2Ldq0aYNNmzahQ4cOaN26NcLCwrB06VJ4e3srY6qI6AU0PKOPiHIoczqC48ePZ7u8QYMGL5yOYObMmVKzZk2xt7cXS0tLKVeunPznP/+R5ORkZZ3U1FQZNmyYFC5cWHQ6ncHUBA8fPpRRo0aJm5ubmJubS+nSpWXevHmSnp5u8LwJCQkSEBAgDg4OYm1tLe3bt5fQ0FABYDA9QOZUAnfv3s3yem7evCkdOnQQe3t7sbOzky5dukhERMQzpzR4ehvPOvU/u37KTkpKikyfPl28vLzE3Nxc3N3dZeLEiQZTADzvebLTt29fg+kjrKyspHjx4tKpUyf5+eefJS0tLctj/v77b6ldu7ZYWlqKm5ubjB8/Xv78808BIHv37lXWi4+Pl549e4q9vb0AUKYmSE9Pl1mzZomnp6fo9XqpUqWKbN26Vfr27Zvt9AVElJVOROXISCKiXHLmzBlUqVIFa9asQa9evbQuh4hINY5xIqLX6vHjx1naFi5cCBMTkxfO2E1EZGw4xomIXqu5c+fi5MmTaNSoEczMzLB9+3Zs374dgwcPhru7u9blERG9FB6qI6LXKjAwENOnT8f58+cRHx8PDw8P9O7dG5988gnMzPjbjYjyFwYnIiIiIpU4xomIiIhIJQYnIiIiIpU4wAAZ13iKiIiAjY1Nnl+PioiIiHJGRPDw4UO4ubnBxCRv9gUxOAGIiIjg2T1ERET51I0bN1CsWLE8eS4GJ0C5SOmNGzdga2urcTVERESkRlxcHNzd3Q0uNv66MTjh3+tl2draMjgRERHlM3k5zIaDw4mIiIhUYnAiIiIiUonBiYiIiEglBiciIiIilRiciIiIiFRicCIiIiJSicGJiIiISCUGJyIiIiKVGJyIiIiIVGJwIiIiIlKJwYmIiIhIJQYnIiIiIpUYnIiIiIhUMtO6ADI+4eHhuHfvntZlvBQnJyd4eHhoXQYREb3hGJzIQHh4OMqWK4/Ex4+0LuWlFLC0QuiFEIYnIiJ6rRicyMC9e/eQ+PgRHNuMgbmju9blqJISfQPRW+fj3r17DE5ERPRaMThRtswd3aF3LaV1GUREREaFg8OJiIiIVGJwIiIiIlKJwYmIiIhIJQYnIiIiIpUYnIiIiIhUYnAiIiIiUonBiYiIiEglBiciIiIilRiciIiIiFTizOH0xggJCdG6hJfCCxMTEeU/DE6U76XF3wd0Ovj5+WldykvhhYmJiPIfBifK99KT4gERXpiYiIheOwYnemPwwsRERPS6cXA4ERERkUoMTkREREQqMTgRERERqcTgRERERKQSgxMRERGRSgxORERERCoxOBERERGpxOBEREREpJKmwWn27NmoUaMGbGxs4OzsjPbt2yM0NNRgnYYNG0Kn0xnchgwZYrBOeHg4WrduDSsrKzg7O2PcuHFITU3Ny5dCREREbwFNZw7fv38/AgICUKNGDaSmpmLSpElo3rw5zp8/j4IFCyrrDRo0CJ999ply38rKSvl7WloaWrduDVdXVxw6dAi3b99Gnz59YG5ujlmzZuXp6yEiIqI3m6bBaceOHQb3V6xYAWdnZ5w8eRL169dX2q2srODq6prtNnbu3Inz589j165dcHFxwbvvvosZM2bg448/xrRp02BhYfFaXwMRERG9PYxqjFNsbCwAwMHBwaB97dq1cHJyQoUKFTBx4kQ8evRIWXb48GFUrFgRLi4uSpuvry/i4uIQHByc7fMkJSUhLi7O4EZERET0IkZzkd/09HSMHDkSderUQYUKFZT2nj17wtPTE25ubggKCsLHH3+M0NBQbNq0CQAQGRlpEJoAKPcjIyOzfa7Zs2dj+vTpr+mVEBER0ZvKaIJTQEAAzp07h7/++sugffDgwcrfK1asiCJFiqBJkya4cuUKSpYsmaPnmjhxIkaPHq3cj4uLg7u7e84KJyIioreGURyqGzp0KLZu3Yq9e/eiWLFiz123Vq1aAIDLly8DAFxdXREVFWWwTub9Z42L0uv1sLW1NbgRERERvYimwUlEMHToUGzevBl79uyBl5fXCx9z5swZAECRIkUAAD4+Pvjnn39w584dZZ3AwEDY2trC29v7tdRNREREbydND9UFBARg3bp1+O2332BjY6OMSbKzs4OlpSWuXLmCdevWoVWrVnB0dERQUBBGjRqF+vXro1KlSgCA5s2bw9vbG71798bcuXMRGRmJyZMnIyAgAHq9XsuXR0RERG8YTfc4LVmyBLGxsWjYsCGKFCmi3DZs2AAAsLCwwK5du9C8eXOUK1cOY8aMQadOnbBlyxZlG6ampti6dStMTU3h4+MDPz8/9OnTx2DeJyIiIqLcoOkeJxF57nJ3d3fs37//hdvx9PTEtm3bcqssIiIiomwZxeBwIiIiovyAwYmIiIhIJQYnIiIiIpUYnIiIiIhUYnAiIiIiUonBiYiIiEglBiciIiIilRiciIiIiFRicCIiIiJSicGJiIiISCUGJyIiIiKVGJyIiIiIVGJwIiIiIlKJwYmIiIhIJQYnIiIiIpUYnIiIiIhUYnAiIiIiUonBiYiIiEglBiciIiIilRiciIiIiFRicCIiIiJSicGJiIiISCUGJyIiIiKVGJyIiIiIVGJwIiIiIlKJwYmIiIhIJQYnIiIiIpUYnIiIiIhUYnAiIiIiUonBiYiIiEglBiciIiIilRiciIiIiFRicCIiIiJSicGJiIiISCUGJyIiIiKVGJyIiIiIVGJwIiIiIlKJwYmIiIhIJQYnIiIiIpUYnIiIiIhUYnAiIiIiUonBiYiIiEglBiciIiIilRiciIiIiFRicCIiIiJSicGJiIiISCUGJyIiIiKVzLQugOhtFhISonUJL83JyQkeHh5al0FEpAkGJyINpMXfB3Q6+Pn5aV3KSytgaYXQCyEMT0T0VmJwItJAelI8IALHNmNg7uiudTmqpUTfQPTW+bh37x6DExG9lRiciDRk7ugOvWsprcsgIiKVODiciIiISCUGJyIiIiKVGJyIiIiIVNI0OM2ePRs1atSAjY0NnJ2d0b59e4SGhhqsk5iYiICAADg6OsLa2hqdOnVCVFSUwTrh4eFo3bo1rKys4OzsjHHjxiE1NTUvXwoRERG9BTQNTvv370dAQACOHDmCwMBApKSkoHnz5khISFDWGTVqFLZs2YKNGzdi//79iIiIQMeOHZXlaWlpaN26NZKTk3Ho0CGsXLkSK1aswJQpU7R4SURERPQG0/Ssuh07dhjcX7FiBZydnXHy5EnUr18fsbGxWLZsGdatW4fGjRsDAJYvX47y5cvjyJEjqF27Nnbu3Inz589j165dcHFxwbvvvosZM2bg448/xrRp02BhYaHFSyMiIqI3kFGNcYqNjQUAODg4AABOnjyJlJQUNG3aVFmnXLly8PDwwOHDhwEAhw8fRsWKFeHi4qKs4+vri7i4OAQHB2f7PElJSYiLizO4EREREb2I0QSn9PR0jBw5EnXq1EGFChUAAJGRkbCwsIC9vb3Bui4uLoiMjFTWeTI0ZS7PXJad2bNnw87OTrm5u+efCQiJiIhIO0YTnAICAnDu3DmsX7/+tT/XxIkTERsbq9xu3Ljx2p+TiIiI8j+jmDl86NCh2Lp1Kw4cOIBixYop7a6urkhOTsaDBw8M9jpFRUXB1dVVWefYsWMG28s86y5znafp9Xro9fpcfhVERET0ptN0j5OIYOjQodi8eTP27NkDLy8vg+XVqlWDubk5du/erbSFhoYiPDwcPj4+AAAfHx/8888/uHPnjrJOYGAgbG1t4e3tnTcvhIiIiN4Kmu5xCggIwLp16/Dbb7/BxsZGGZNkZ2cHS0tL2NnZwd/fH6NHj4aDgwNsbW0xbNgw+Pj4oHbt2gCA5s2bw9vbG71798bcuXMRGRmJyZMnIyAggHuViIiIKFdpGpyWLFkCAGjYsKFB+/Lly9GvXz8AwJdffgkTExN06tQJSUlJ8PX1xbfffqusa2pqiq1bt+LDDz+Ej48PChYsiL59++Kzzz7Lq5dBREREbwlNg5OIvHCdAgUKYPHixVi8ePEz1/H09MS2bdtyszQiIiKiLIzmrDoiIiIiY8fgRERERKQSgxMRERGRSgxORERERCoxOBERERGpxOBEREREpBKDExEREZFKDE5EREREKjE4EREREanE4ERERESkEoMTERERkUoMTkREREQqMTgRERERqcTgRERERKQSgxMRERGRSgxORERERCoxOBERERGpxOBEREREpBKDExEREZFKDE5EREREKjE4EREREanE4ERERESkEoMTERERkUoMTkREREQqMTgRERERqcTgRERERKQSgxMRERGRSgxORERERCoxOBERERGpxOBEREREpBKDExEREZFKDE5EREREKjE4EREREanE4ERERESkEoMTERERkUo5Ck5Xr17N7TqIiIiIjF6OglOpUqXQqFEjrFmzBomJibldExEREZFRylFwOnXqFCpVqoTRo0fD1dUVH3zwAY4dO5bbtREREREZlRwFp3fffRdfffUVIiIi8OOPP+L27duoW7cuKlSogAULFuDu3bu5XScRERGR5l5pcLiZmRk6duyIjRs34vPPP8fly5cxduxYuLu7o0+fPrh9+3Zu1UlERESkuVcKTidOnMBHH32EIkWKYMGCBRg7diyuXLmCwMBAREREoF27drlVJxEREZHmzHLyoAULFmD58uUIDQ1Fq1atsGrVKrRq1QomJhk5zMvLCytWrEDx4sVzs1YiIiIiTeUoOC1ZsgQDBgxAv379UKRIkWzXcXZ2xrJly16pOCIiIiJjkqPgdOnSpReuY2Fhgb59++Zk80RERERGKUdjnJYvX46NGzdmad+4cSNWrlz5ykURERERGaMcBafZs2fDyckpS7uzszNmzZr1ykURERERGaMcBafw8HB4eXllaff09ER4ePgrF0VERERkjHIUnJydnREUFJSl/ezZs3B0dHzlooiIiIiMUY6CU48ePTB8+HDs3bsXaWlpSEtLw549ezBixAh07949t2skIiIiMgo5OqtuxowZuHbtGpo0aQIzs4xNpKeno0+fPhzjRERERG+sHAUnCwsLbNiwATNmzMDZs2dhaWmJihUrwtPTM7frIyIiIjIaOQpOmcqUKYMyZcrkVi1ERERERi1HwSktLQ0rVqzA7t27cefOHaSnpxss37NnT64UR0RERGRMchScRowYgRUrVqB169aoUKECdDpdbtdFREREZHRyFJzWr1+P//3vf2jVqtUrPfmBAwcwb948nDx5Erdv38bmzZvRvn17ZXm/fv2yzETu6+uLHTt2KPdjYmIwbNgwbNmyBSYmJujUqRO++uorWFtbv1JtRERERE/L0XQEFhYWKFWq1Cs/eUJCAipXrozFixc/c50WLVrg9u3byu2nn34yWN6rVy8EBwcjMDAQW7duxYEDBzB48OBXro2IiIjoaTna4zRmzBh89dVX+Oabb17pMF3Lli3RsmXL566j1+vh6uqa7bKQkBDs2LEDx48fR/Xq1QEAX3/9NVq1aoUvvvgCbm5uOa6NiIiI6Gk5Ck5//fUX9u7di+3bt+Odd96Bubm5wfJNmzblSnEAsG/fPjg7O6NQoUJo3LgxZs6cqcxOfvjwYdjb2yuhCQCaNm0KExMTHD16FB06dMh2m0lJSUhKSlLux8XF5Vq9RG+DkJAQrUt4KU5OTvDw8NC6DCJ6A+QoONnb2z8zlOSmFi1aoGPHjvDy8sKVK1cwadIktGzZEocPH4apqSkiIyPh7Oxs8BgzMzM4ODggMjLymdudPXs2pk+f/rrLJ3rjpMXfB3Q6+Pn5aV3KSylgaYXQCyEMT0T0ynIUnJYvX57bdWTrycu3VKxYEZUqVULJkiWxb98+NGnSJMfbnThxIkaPHq3cj4uLg7u7+yvVSvQ2SE+KB0Tg2GYMzB3zx/+ZlOgbiN46H/fu3WNwIqJXluMJMFNTU7Fv3z5cuXIFPXv2hI2NDSIiImBra/vazmgrUaIEnJyccPnyZTRp0gSurq64c+dOlrpiYmKeOS4KyBg3pdfrX0uNRG8Dc0d36F1f/QQRIqL8JkfB6fr162jRogXCw8ORlJSEZs2awcbGBp9//jmSkpKwdOnS3K4TAHDz5k1ER0ejSJEiAAAfHx88ePAAJ0+eRLVq1QBkTL6Znp6OWrVqvZYaiIiI6O2Vo+kIRowYgerVq+P+/fuwtLRU2jt06IDdu3er3k58fDzOnDmDM2fOAADCwsJw5swZhIeHIz4+HuPGjcORI0dw7do17N69G+3atUOpUqXg6+sLAChfvjxatGiBQYMG4dixY/j7778xdOhQdO/enWfUERERUa7L0R6ngwcP4tChQ7CwsDBoL168OG7duqV6OydOnECjRo2U+5njjvr27YslS5YgKCgIK1euxIMHD+Dm5obmzZtjxowZBofZ1q5di6FDh6JJkybKBJiLFi3KycsiIiIieq4cBaf09HSkpaVlab958yZsbGxUb6dhw4YQkWcu//PPP1+4DQcHB6xbt071cxIRERHlVI4O1TVv3hwLFy5U7ut0OsTHx2Pq1KmvfBkWIiIiImOVoz1O8+fPh6+vL7y9vZGYmIiePXvi0qVLcHJyynJJFCIiIqI3RY6CU7FixXD27FmsX78eQUFBiI+Ph7+/P3r16mUwWJyIiIjoTZLjeZzMzMzy3ezBRERERK8iR8Fp1apVz13ep0+fHBVDREREZMxyFJxGjBhhcD8lJQWPHj2ChYUFrKysGJyIiIjojZSjs+ru379vcIuPj0doaCjq1q3LweFERET0xspRcMpO6dKlMWfOnCx7o4iIiIjeFLkWnICMAeMRERG5uUkiIiIio5GjMU6///67wX0Rwe3bt/HNN9+gTp06uVIYERERkbHJUXBq3769wX2dTofChQujcePGmD9/fm7URURERGR0cnytOiIiIqK3Ta6OcSIiIiJ6k+Voj9Po0aNVr7tgwYKcPAURERGR0clRcDp9+jROnz6NlJQUlC1bFgBw8eJFmJqaomrVqsp6Op0ud6okIiIiMgI5Ck5t27aFjY0NVq5ciUKFCgHImBSzf//+qFevHsaMGZOrRRIREREZgxyNcZo/fz5mz56thCYAKFSoEGbOnMmz6oiIiOiNlaPgFBcXh7t372Zpv3v3Lh4+fPjKRREREREZoxwFpw4dOqB///7YtGkTbt68iZs3b+KXX36Bv78/OnbsmNs1EhERERmFHI1xWrp0KcaOHYuePXsiJSUlY0NmZvD398e8efNytUAiIiIiY5Gj4GRlZYVvv/0W8+bNw5UrVwAAJUuWRMGCBXO1OCIiIiJj8koTYN6+fRu3b99G6dKlUbBgQYhIbtVFREREZHRyFJyio6PRpEkTlClTBq1atcLt27cBAP7+/pyKgIiIiN5YOQpOo0aNgrm5OcLDw2FlZaW0d+vWDTt27Mi14oiIiIiMSY7GOO3cuRN//vknihUrZtBeunRpXL9+PVcKIyIiIjI2OdrjlJCQYLCnKVNMTAz0ev0rF0VERERkjHIUnOrVq4dVq1Yp93U6HdLT0zF37lw0atQo14ojIiIiMiY5OlQ3d+5cNGnSBCdOnEBycjLGjx+P4OBgxMTE4O+//87tGomIiIiMQo72OFWoUAEXL15E3bp10a5dOyQkJKBjx444ffo0SpYsmds1EhERERmFl97jlJKSghYtWmDp0qX45JNPXkdNREREREbppfc4mZubIygo6HXUQkRERGTUcnSozs/PD8uWLcvtWoiIiIiMWo4Gh6empuLHH3/Erl27UK1atSzXqFuwYEGuFEdERERkTF4qOF29ehXFixfHuXPnULVqVQDAxYsXDdbR6XS5Vx0RERGREXmp4FS6dGncvn0be/fuBZBxiZVFixbBxcXltRRHREREZExeaoyTiBjc3759OxISEnK1ICIiIiJjlaPB4ZmeDlJEREREb7KXCk46nS7LGCaOaSIiIqK3xUuNcRIR9OvXT7mQb2JiIoYMGZLlrLpNmzblXoVERERERuKlglPfvn0N7vv5+eVqMURERETG7KWC0/Lly19XHURERERG75UGhxMRERG9TRiciIiIiFRicCIiIiJSicGJiIiISCUGJyIiIiKVGJyIiIiIVGJwIiIiIlKJwYmIiIhIJQYnIiIiIpUYnIiIiIhUYnAiIiIiUonBiYiIiEglBiciIiIilTQNTgcOHEDbtm3h5uYGnU6HX3/91WC5iGDKlCkoUqQILC0t0bRpU1y6dMlgnZiYGPTq1Qu2trawt7eHv78/4uPj8/BVEBER0dtC0+CUkJCAypUrY/Hixdkunzt3LhYtWoSlS5fi6NGjKFiwIHx9fZGYmKis06tXLwQHByMwMBBbt27FgQMHMHjw4Lx6CURERPQWMdPyyVu2bImWLVtmu0xEsHDhQkyePBnt2rUDAKxatQouLi749ddf0b17d4SEhGDHjh04fvw4qlevDgD4+uuv0apVK3zxxRdwc3PLdttJSUlISkpS7sfFxeXyKyMiIqI3kdGOcQoLC0NkZCSaNm2qtNnZ2aFWrVo4fPgwAODw4cOwt7dXQhMANG3aFCYmJjh69Ogztz179mzY2dkpN3d399f3QoiIiOiNYbTBKTIyEgDg4uJi0O7i4qIsi4yMhLOzs8FyMzMzODg4KOtkZ+LEiYiNjVVuN27cyOXqiYiI6E2k6aE6rej1euj1eq3LICIionzGaPc4ubq6AgCioqIM2qOiopRlrq6uuHPnjsHy1NRUxMTEKOsQERER5RajDU5eXl5wdXXF7t27lba4uDgcPXoUPj4+AAAfHx88ePAAJ0+eVNbZs2cP0tPTUatWrTyvmYiIiN5smh6qi4+Px+XLl5X7YWFhOHPmDBwcHODh4YGRI0di5syZKF26NLy8vPDpp5/Czc0N7du3BwCUL18eLVq0wKBBg7B06VKkpKRg6NCh6N69+zPPqCMiIiLKKU2D04kTJ9CoUSPl/ujRowEAffv2xYoVKzB+/HgkJCRg8ODBePDgAerWrYsdO3agQIECymPWrl2LoUOHokmTJjAxMUGnTp2waNGiPH8tRERE9ObTNDg1bNgQIvLM5TqdDp999hk+++yzZ67j4OCAdevWvY7yiIiIiAwY7RgnIiIiImPD4ERERESkEoMTERERkUoMTkREREQqMTgRERERqcTgRERERKTSW3mtOiJ6+4SEhGhdwktxcnKCh4eH1mUQ0VMYnIjojZYWfx/Q6eDn56d1KS+lgKUVQi+EMDwRGRkGJyJ6o6UnxQMicGwzBuaO7lqXo0pK9A1Eb52Pe/fuMTgRGRkGJyJ6K5g7ukPvWkrrMogon+PgcCIiIiKVGJyIiIiIVGJwIiIiIlKJwYmIiIhIJQ4OJyIyUpx7isj4MDgRERkZzj1FZLwYnIiIjAznniIyXgxORERGinNPERkfDg4nIiIiUonBiYiIiEglBiciIiIilRiciIiIiFRicCIiIiJSicGJiIiISCUGJyIiIiKVGJyIiIiIVGJwIiIiIlKJwYmIiIhIJQYnIiIiIpUYnIiIiIhUYnAiIiIiUonBiYiIiEglBiciIiIilcy0LoCIiN4cISEhWpfwUpycnODh4aF1GZSPMDgREdErS4u/D+h08PPz07qUl1LA0gqhF0IYnkg1BiciInpl6UnxgAgc24yBuaO71uWokhJ9A9Fb5+PevXsMTqQagxMREeUac0d36F1LaV0G0WvDweFEREREKjE4EREREanE4ERERESkEoMTERERkUoMTkREREQqMTgRERERqcTgRERERKQSgxMRERGRSgxORERERCoxOBERERGpxOBEREREpBKDExEREZFKDE5EREREKjE4EREREanE4ERERESkEoMTERERkUpGHZymTZsGnU5ncCtXrpyyPDExEQEBAXB0dIS1tTU6deqEqKgoDSsmIiKiN5lRBycAeOedd3D79m3l9tdffynLRo0ahS1btmDjxo3Yv38/IiIi0LFjRw2rJSIiojeZmdYFvIiZmRlcXV2ztMfGxmLZsmVYt24dGjduDABYvnw5ypcvjyNHjqB27dp5XSoRERG94Yx+j9OlS5fg5uaGEiVKoFevXggPDwcAnDx5EikpKWjatKmybrly5eDh4YHDhw8/d5tJSUmIi4szuBERERG9iFEHp1q1amHFihXYsWMHlixZgrCwMNSrVw8PHz5EZGQkLCwsYG9vb/AYFxcXREZGPne7s2fPhp2dnXJzd3d/ja+CiIiI3hRGfaiuZcuWyt8rVaqEWrVqwdPTE//73/9gaWmZ4+1OnDgRo0ePVu7HxcUxPBEREdELGXVwepq9vT3KlCmDy5cvo1mzZkhOTsaDBw8M9jpFRUVlOybqSXq9Hnq9/jVXS0RE+UFISIjWJbwUJycneHh4aF3GWytfBaf4+HhcuXIFvXv3RrVq1WBubo7du3ejU6dOAIDQ0FCEh4fDx8dH40qJiMjYpcXfB3Q6+Pn5aV3KSylgaYXQCyEMTxox6uA0duxYtG3bFp6enoiIiMDUqVNhamqKHj16wM7ODv7+/hg9ejQcHBxga2uLYcOGwcfHh2fUERHRC6UnxQMicGwzBuaO+WO4Rkr0DURvnY979+4xOGnEqIPTzZs30aNHD0RHR6Nw4cKoW7cujhw5gsKFCwMAvvzyS5iYmKBTp05ISkqCr68vvv32W42rJiKi/MTc0R1611Jal0H5hFEHp/Xr1z93eYECBbB48WIsXrw4jyoiIiKit5lRT0dAREREZEwYnIiIiIhUYnAiIiIiUonBiYiIiEglBiciIiIilRiciIiIiFRicCIiIiJSicGJiIiISCUGJyIiIiKVGJyIiIiIVGJwIiIiIlLJqK9VR0RERFmFhIRoXcJLcXJygoeHh9Zl5AoGJyIionwiLf4+oNPBz89P61JeSgFLK4ReCHkjwhODExERUT6RnhQPiMCxzRiYO7prXY4qKdE3EL11Pu7du8fgRERERHnP3NEdetdSWpfxVuLgcCIiIiKVuMfpNQsPD8e9e/e0LkO1/DbgkIiIKC8xOL1G4eHhKFuuPBIfP9K6FCIiIsoFDE6v0b1795D4+FG+GsT3+OoJxB5co3UZRERERonBKQ/kp0F8KdE3tC6BiIjIaHFwOBEREZFKDE5EREREKjE4EREREanE4ERERESkEoMTERERkUoMTkREREQqMTgRERERqcTgRERERKQSgxMRERGRSgxORERERCoxOBERERGpxOBEREREpBKDExEREZFKDE5EREREKjE4EREREanE4ERERESkEoMTERERkUoMTkREREQqMTgRERERqcTgRERERKQSgxMRERGRSgxORERERCoxOBERERGpxOBEREREpBKDExEREZFKDE5EREREKjE4EREREanE4ERERESkEoMTERERkUoMTkREREQqMTgRERERqcTgRERERKQSgxMRERGRSgxORERERCq9McFp8eLFKF68OAoUKIBatWrh2LFjWpdEREREb5g3Ijht2LABo0ePxtSpU3Hq1ClUrlwZvr6+uHPnjtalERER0RvkjQhOCxYswKBBg9C/f394e3tj6dKlsLKywo8//qh1aURERPQGMdO6gFeVnJyMkydPYuLEiUqbiYkJmjZtisOHD2f7mKSkJCQlJSn3Y2NjAQBxcXG5Wlt8fHzG80VeRnpyYq5u+3VJib4BgDW/bvmxZiB/1s2a8wZrzhv5suaYmwAyvhNz+3s2c3sikqvbfS7J527duiUA5NChQwbt48aNk5o1a2b7mKlTpwoA3njjjTfeeOPtDbhduXIlLyKHiIjk+z1OOTFx4kSMHj1auZ+eno6YmBg4OjpCp9NpWJl6cXFxcHd3x40bN2Bra6t1Oaqw5rzBmvMGa84brDnv5Me6Y2Nj4eHhAQcHhzx7znwfnJycnGBqaoqoqCiD9qioKLi6umb7GL1eD71eb9Bmb2//ukp8rWxtbfPNGzwTa84brDlvsOa8wZrzTn6s28Qk74Zs5/vB4RYWFqhWrRp2796ttKWnp2P37t3w8fHRsDIiIiJ60+T7PU4AMHr0aPTt2xfVq1dHzZo1sXDhQiQkJKB///5al0ZERERvkDciOHXr1g13797FlClTEBkZiXfffRc7duyAi4uL1qW9Nnq9HlOnTs1yyNGYsea8wZrzBmvOG6w57+THurWoWSeSl+fwEREREeVf+X6MExEREVFeYXAiIiIiUonBiYiIiEglBiciIiIilRiciIiIiFRicHpD8ORIIiKi14/BKR9LT09X/p5frrFHRESUn70RE2C+jS5cuICFCxciMTERpqammDx5MooVKwZzc3OtS8s16enpeXr9oZyIjY3Fw4cPodfrYW1tDUtLS4hIvgqyxl7vm9DHgPH3MwBERkYiNDQUFhYWcHFxQYkSJbQu6aWxn1+P/Fjz68IJMPOh8+fPo27dunj//fdRuHBhHDp0CCEhIZg+fTq6d++OwoULa13iS7t8+TI2bdqEhIQEFClSBIMGDYKpqanWZT3XP//8g169esHc3Bx3795FnTp18NFHH6FevXpG++EdHh6O4OBg3LlzBzVq1IC3tzcAIC0tzSj7Oz/2MZD/+hnI6Ov3338fjo6OePjwIRISEjB9+nT079/faH/AsJ/zRn6s+bUSylcSExOlbdu2EhAQYNBevnx5KVq0qHz++efy4MEDjarLmX/++UccHByka9eu0qhRI6lUqZJ4e3vLmTNnJC0tTevysnX16lVxcXGRsWPHSmhoqKxcuVIaNGggdnZ2EhgYKCIi6enpGldpKCgoSJydnaVly5bi5OQktWvXFj8/P6WPU1NTNa7QUH7sY5H8188iIjdv3hQPDw+ZOHGiPHjwQIKDg2XUqFGi0+lkzpw58vDhQ61LzIL9nDfyY81PS09Pz9XvEganfObRo0dSq1YtWbNmjYiI8qbt1auXVK1aVdzc3GTv3r0iYpxfKk+LjY0VHx8fGTt2rIiIJCUlyZEjR6RAgQJSsWJFOXjwoIgY32v58ssvpV27dgZts2fPFp1OJxYWFrJ9+3ZtCnuGqKgoeeedd2TSpEmSkpIiMTExMnPmTNHpdNKsWTPlQ8WYgmp+62OR/NnPIiLbt2+XRo0ayaNHj5S2rVu3il6vFxMTE/niiy9ExHj+H7Kf805+rFlEZNasWfLLL7+IiEhKSoqIiERERMiaNWskOTn5lbb9Fu5jy98KFCiAtLQ0/PHHHwAAa2trREVF4dChQ1i2bBkqVaqEiRMnAsgfA8ZjY2MRFxeHLl26AADMzc1RoUIF1KhRA48fP4afnx9iY2Oh0+mM6szB+/fvIzIyEvHx8Uqbt7c3OnfujC5dumD69Om4ceOGhhUaunz5MkxNTfHhhx/CzMwMhQoVQteuXVG8eHGcOXMGLVq0gIgY1W73/NbHQP7sZwCIiYnBiRMncPv2baXN2dkZnTp1wqeffopJkybh8OHDRvOZwn7OO/mx5nv37iE6OhpffvkltmzZAjMzM1y/fh0VKlTA1atXX3kssHG9q+i55P/HdIwcORLHjx+Hj48PJk2ahDJlyqBx48Z49913MXLkSMTFxSEqKkrrclUxNzdHYmIi/vrrLwAZYe/u3bu4e/culi5dioIFC2L8+PHKMq1lhjdXV1dERUXh4MGDiIyMRFhYGPz9/VG7dm0MGjQIt27dwt27dzWu9l9JSUmIjY1FRESE0vbo0SM4ODjg008/RXh4ONatWwdA+6kt0tLSAABFihTJV30M5K9+fvTokfJ3b29vVK5cGd988w0OHTqEkydPokWLFvDw8MDHH3+MWrVqITg4WMNqDeWnfn5SuXLlUKlSpXzRz5lnbeenmjM5OTkhICAATZo0wcKFC7F8+XI0aNAAXbp0UXYsvJJX2l9FmoiNjZXt27dLmzZtpHv37rJgwQJl2Zo1a6Rs2bISExOjYYXqPXr0SAYPHiyNGjWSIUOGyOrVq8XOzk4++ugjERGZNGmStGzZUuMqM3b1pqSkGOz679SpkxQpUkRKly4tNjY28uGHHyrL3NzcZPHixVqUmq0bN25IyZIlpXv37rJmzRrZu3ev2NnZycSJE0VEpE6dOjJy5EhNa7x69apcunTJoK1r165G38eJiYnK3yMiIqRUqVJG3c8iIufPn5cePXrIgQMHlLb58+dLvXr1xNbWVpydnQ3qrFatmgwdOlSLUhUXL16UCxcuiEjGuBtjfz+LZLwfDh06JFu3blXa5s6da9T9HBcXJ3FxcXL79m2lbcGCBVKnTh2jrflZ4uPjZeTIkaLX6w2+R171sCKDUz6TlJRkcP/J484iIsOGDZM2bdpkaTcWjx8/FhHDwXrh4eEyYcIEqVq1qtSsWVOmT5+urD9z5kypVauWcoxaCyEhITJ48GDx8fGRoUOHym+//aYs27Rpk2zcuFH++OMPEcl4XdeuXZMqVaooY820EBkZKfv27ZPdu3fLjRs3RETk9OnTUrVqVSlZsqS4u7vLhAkTlPX9/PykW7duWpUrERERotPpxNraWv755x+DZZs3b5aff/7Z6PpYROTEiRPSsmVLiYqKUt7PQUFBRtvPIhknY9jZ2cmIESPk/PnzBl8ily5dkhMnTsiJEydEJKOvY2NjpUWLFrJ8+XKNKhYJDg4WMzMzqVq1qvKj8OzZs1KtWjWj7eegoCApU6aMVKpUSXQ6nXTq1ElZduXKFTl58qTR9XNQUJDUr19fqlSpIlWrVpUhQ4ZIfHy8iGR8ThvjeyOzliffx5ljmCIiIsTV1VVq1KghderUUT5DXhWDk5FKS0vLclZI5i/bK1euyKJFiwyW/f333zJ27FixsbGRs2fP5lmdL+P8+fPy3nvvya5du0Qk482eGYiSk5MlLS1N7t69a/CY3r17i7+/v2aDPM+dOyeOjo7i7+8vw4YNk6ZNm0qrVq3k8uXL2a7/+PFj+fTTT6VkyZJy8+bNPK42Q1BQkHh7e4u3t7cUL15cfH19lfB07949uXnzpoSGhirrp6amSuvWrZXAqsUgz5iYGKlcubK0aNFCXF1d5cyZM89c1xj6WETkzJkzYmVlJcOGDVPaMvvu7t27RtnPsbGxUrduXRkxYoTSFh0dnSWsZrp7965MmTJFXFxcnvmef91Onz4tBQoUkCpVqkj58uUNajXW9/OVK1ekSJEiMn36dLl06ZIcOHBAChYsqISOpxlDP1+8eFGcnZ1l4sSJsnnzZlm7dq3Y29tLs2bN5PDhw1k+g42h5szvxOwGe1++fFnc3d1l6NChcvnyZZk2bZo0bNhQNm3a9MrPy+BkhIKDg6VXr17SpEkTGTJkiGzdulUJUZcvXxYXFxfx8/MzeMz3338vDRs2NNrQFBYWJqVLlxYnJyepUqWK7N69W0SefZroqVOnZMKECWJnZyfnzp3L63JFJGOvTY0aNZQz/kREjh8/Lk5OTtn+cvnnn39k4MCBYm9vL6dOncrLUhXnz5+XwoULy4QJE+T69euyfv16KV269DM/sG/cuCGTJk0SJycngy+fvJSeni7R0dFSvnx5WbVqlXTp0kWKFCmiHJYJCgpS3iPG0MciGXs7bGxsZPz48Urbw4cP5cGDB9nu7TWGfhbJ2GtQqVIl5ZBohw4dpEqVKmJlZSW+vr6yf/9+pa/DwsKkR48e4uzsrFlfnz59WgoWLKiEoPLly0uPHj2eub6x9PPChQuladOmyhGChIQEadq0qezYsUPWrVsnkZGRSqC7evWq5v0sIjJjxgzp3r27QdvIkSNFp9NJ/fr1JSQkREQyftQbw3vj3Llz0qFDB2natKny3s3s7/T0dOnSpYvBeyUsLEzGjRsnLVu2lPj4+FcK1AxORubChQtiZ2cn3bt3lwkTJkjlypWlevXqMmbMGLl7967Url1bBgwYkO0/+v379/O+YBWSkpJk2LBh0rFjR1m/fr10795dKlasqISnpz169Eg+//xzKVWqlJw+fTpvi33Crl27pEOHDkoNmX3eokUL+fbbbw3aRDJ+ZS5ZskT5gMlrDx48kAYNGhjsARERadKkiaxatUp+++035QszLS1Nrl69KpMnTxY3NzdNP7AzfxT07t1bTpw4IZcuXZKOHTtK0aJFpVmzZtKjRw9lbrKrV69q2sciGXto9Hq9NG3aVEQy+nLgwIFSv359ZXxTcHCwssxY+lkkY69CxYoV5ebNm9KjRw9p1aqV/PHHH/L3339L1apVpVatWkpgTU9Pl927d2cZd5ZXLl26JCYmJgaH4L766ispX768BAUFZVk/LCzMaPp5xIgRUqVKFeX+vHnzxNzcXOrUqSOFChWSKlWqyKFDh5TlWvZzpm7duknr1q1F5N9pHJYuXSojR44UV1dX6dKli8H6WtZ88eJFsbW1lcGDB8u4ceOkc+fOotPpZOrUqXL9+nURyRir9fT35LVr17Ic1cgJBicjkp6eLpMmTZKuXbsqbXFxcTJz5kypWrWqNG/eXFauXJnlccY2V0l2duzYId9//72IiBw5ckS6dev23PD0+PFjiYqKyssSswgODpZly5Yp9zP/EzZu3FimTJmS7WO0nHTv4cOHsmLFCjl+/LjSNmPGDDExMZHKlStLtWrVxNTUVI4ePSoiGX185swZ5TCe1vr166fsWbh+/boUL15cTExMZO3atSLyb/8bw/t92LBhUqhQIdmwYYM0adJEGjZsKN98841MmzZNmjdvLiVKlFC+VBITE42mn2NjY6VIkSIyZMgQGTBggPJeEMkYSOvp6SnDhw/XsMJ/bd68WfnMyBQaGiq2trbK3EFPSkpKMpp+Pnr0qFhaWkqdOnWkc+fOotfrZceOHcq8exUqVDD4nDcG33//vVSoUEGZH+3SpUtiaWkpGzZskL1790rhwoU1D6SZJk+eLM2bNzdoW7RokTg6Osr48eMNBraL5P7hWgYnI9OvXz+pX7++QVtcXJxyJsacOXM0qix3HTp0KEt4SkxM1Oyw3Is8+R+vbdu2MnXqVOX+woUL5aefftKgqqyenMV348aN4uTkJL/++qvcv39foqOjpX379tKoUSNlwKcxyOzbzz77TMaMGSMiIn369JHChQtL48aNxdPTU06ePKllidnKPIzRvHlzg1+xR48elerVq8usWbOMIuRlyqxlxYoV4ujoKKampnL48GER+fekkxEjRmTZs2AsMuufPHmylCpVSvM9NC9y9OhRmTdvngwfPlz69+8vIv+ezDN9+nTx8fFRTpYxBkFBQdKjRw9xcXERHx8fsbS0VM5uvnHjhtjb2ysz9mttzJgxSnB68sShpUuXipWVlSxZskREXt+PLM7jZCTk/+caqVq1KtLS0hAaGqoss7GxwcCBA1GuXDn8/vvvePjwoVZlvrLMuUF8fHwwfPhwvPPOOxg5ciQCAwMxfvx4NGrUyOhen/z//FmZ/0b29vawtLQEAEyaNAkTJkxAhQoVtCxRYW1trfy9SZMmCAwMRLt27WBvbw8HBwe4ubnB3NwcBQsW1LBKQ5nzczVu3Bj3799Hx44dsXPnTuzcuROLFy9GyZIl0atXLyQlJRnVnDxffvklvvnmG/Tt2xdOTk7Ke7tmzZoQEVy+fNmoJmDMrKVhw4bo06cPAOB///sfAMDCwgJAxsSBzs7O2hT4Ak/Wn5ycjNOnTwP4d94vY5Keno6aNWti7NixSElJQXJyMgAonxtXrlyBl5eXUV1Pr2LFipgxYwa+/fZbdOzYEWvWrMHixYsBAImJiShZsiScnJw0rjKDh4cHDh8+jIiICJiZmSn9+8EHH+Djjz/GuHHjcOPGjdf3/++1xDHKscuXL4uTk5MMGDBA2XuQ+Ys8PDxcdDqdUV5q4kWyO1VUROTw4cPSo0cPMTExEXt7e4NDB1rLPOyW+Ysm8zW0a9dOZs2aJbNmzZICBQo8c+C1FjJrfHrXdOb9QYMGyYgRIyQlJcUoLpHwZB+HhISITqcTLy8vgz1MwcHBRnH45UmZv2TT09MN9hqkpaVJYmKitGvXTr766iutysvWk7/MY2NjZcyYMWJiYiIdOnSQSZMmyZAhQ6RQoUJy/vx5Das09OR79MnD4J07d5aKFStqUdILZfZz5hlfGzduFEdHR1m0aJH89ddfMn78eHFycjKqveuZn8nPGmowduxYKVu2rObDJzIlJSVJ/fr1pXbt2nLv3j0R+Xeqm9u3b4u7u3uunD33LAxORmjPnj2i1+slICDA4BDA7du3pXLlygaDCvODzP+MmW9wEcMPxPfff1/s7e2N4oMk8wsx88Pv+vXr0rVrV4mIiFDW6datm+j1eilYsKDBeCKtZfZzdhd5TkxMlE8//VRcXFw0HVgt8uw+FhH57bffND0hQI3n9XNSUpJMmTJFihYtalSHkjL7+urVq/Lee+9JVFSUxMXFya5du6RJkybSrFkz6dixY7aDrrWSXT9nvncOHDggTk5OsnnzZi1Ke6bMfr527Zq89957Eh4eLtevX5eJEyeKlZWVlCtXTqpVq/bc6TbyWmbNYWFh8t5770lYWJiybPfu3dK1a1dxdHTU7P9laGiojB8/Xvr16ycLFy6UixcvKrXVrFlTmjRpItHR0cr6MTExUq5cOdmyZctrq4nByUj9/vvvotfrlTPRzp8/LxMmTJAiRYoY3a/v58kcO3Ht2jUpUqSIweD21NRUmT17tlhZWWn2nzIiIkKOHj0qO3bsyPJrKywsTNzc3CQgIMAg6I0YMULc3NyeOfeNFjJ/MV67dk0qVqxoMEnn3r17ZdCgQeLi4qLJ4E41fTxkyJA8rysnntfPu3fvln79+omTk5Nmg2jDw8Plzz//lNWrV0tMTIzBhLnXrl2TokWLysCBAw0ek/nF+fTkulp6Xj+LZHw5NmjQQK5evapFear6edCgQUpbcnKyXLlyRUJDQw2+5POSmpoHDx5s8Fl3//59GTJkiGY/aoODg8XOzk5atGghnTp1Ejs7O2ncuLGsWrVKRES2bNkiNWvWFC8vL/nzzz9lz549MnnyZHF1dVXOrnsdGJyM2MmTJ6VBgwbi6ekpJUuWlDJlyhjNWQ1Pe9avAhHDL8enDw/t3LlTs0MDZ8+eFU9PTylTpozY2dlJuXLlZN26dcpevpIlS8oHH3yQpeajR48a/CrLS5cuXZLZs2fLhAkTZN26dQaDwa9cuSJFixbNUvO2bdtk8uTJmuxpymkfay0n/fz777/LmDFjNH0/u7q6SsWKFcXW1lY8PDxk5syZEh4eLiIidevWzfJ/8MkZl7X4N8hJP2fuddLqDNac9LPWclLzk4ejtZCUlCR+fn4GAfTSpUvSrVs3qVGjhnz33Xci8u/lgwoXLixlypSRd95557WfTMLgZORiY2MlLCxMgoKCcmX+idchu18FTZs2VU4l/s9//iPDhw83qg+SO3fuSLly5WTSpEly5coVuXXrlnTr1k3Kly8v06ZNk9TUVDl9+rTBWRla13/u3Dmxt7eXBg0aSP369cXMzEw6deok27ZtExGRDz/8UPz9/bOtU4u9CTnpY2PwKv385HXr8lJMTIxUrVpVxo8fr1z+ZcyYMVKrVi3p27ev3L9/X65evarpdBlPe5V+FtFuhvv81s/5seZMzZo1k8GDB4vIv//e169fl379+kmdOnWU94pIxqWxbt26lSffkwxO9Eqe96ugdu3aBvMgGZPg4GApXrx4loHdH3/8sXh7e8u8efMkISFBo+qyevTokbRp00YCAgKUtpMnT0r16tWlSZMmz5wPS0v5rY9F8mc/i2R8mXh6eiqXM8r09ddfS82aNSUgIMBgjKHW2M95Jz/WnJqaKsnJydK/f3/p3LmzJCYmGlxl4sqVK+Lj42MwF1ZeBmnjOVeW8iULCwtERUUpp5SLCEqVKoW5c+eiXLly+PHHH7F161aNq8wqJSUFqampePToEQDg8ePHAIA5c+agadOm+Pbbb3H58mUA/06hoCVLS0vExMQopwOnp6ejatWqWL16NdLS0jBnzhycPXtW4yoNJSUl5as+BvJnPwMZp+pbWVkhIiICAJCamgoAGDp0KLp06YI9e/bgr7/+AmAcfW1paYno6Gj2cx7Q6XSwtLTMFzVnTi1hamoKc3Nz9O3bF5s3b8Z3330HnU4HExMTpKWloUSJEpg9ezZ+/vlnBAcHA/h3WpM8kWcRjd44an8VaH2V8mepUaOGNGrUSLn/5GGW6tWrZ7luk5YePnwojRo1UgZRp6amKoN6g4ODpVixYgYXbtVKRESEcrkRkYx+zA99nPmejYuLk0aNGsmHH34oIsbbzyIZ1z978hDs+++/L1WqVFHOQnty+oGWLVsa/Dto5caNG3L8+HFJTU3NN/38tDZt2hh9P6elpRkcAu/SpYtUrFjRqGsODQ2VL774wuAMZhGRL774QkxMTOS///2vQfvJkyelfPnymow3ZXCil/b0sfB9+/aJqampwbw1mevs27dPTExMNJ9qID4+XuLi4iQ2NlZpO3XqlDg7OxtcCDLzA2X06NHStm3bPK/zSdHR0RISEqJcrHTLli2i0+nkl19+EZGMD8fMs4/WrVsnhQoVeq1nkrzIzZs3xdHRUTp06KDMSH369GlxcnIy2j4WyaixTZs2ymzqGzduNOp+Fsm42HHr1q1l//79St13794VLy8vadasWZYxbQsXLpR69eppOo7l3Llz4u7uLqNGjRIRkZ9++sno+/nGjRuyYcMG+eWXX5QTc4y9n4ODg6V3797SqFEj6d+/v2zbtk3u3LkjlStXlkaNGhllzZcuXRIHBwfR6XQyceJEg3FKCQkJMn36dNHpdDJ58mQ5deqUREdHy4QJE6RUqVJy586dPK+XwYleSn76VZApODhYmjdvLlWqVBE3NzdZs2aNiGRMmPbTTz+Jk5OTdO7cWZKTk5VfaX5+ftK9e3fNJor8559/pEqVKlKxYkUxNzeX6dOnS2JiogwbNkz0en2WOUq2bdsm5cuX13Sswt69e8XMzEwaN24sffr0Ub5o1q9fL4UKFZL27dsbVR+LiJw5c0YsLS3l448/VtpSUlJk6NChotfr5ffffzdY3xj6OXNQ9QcffKCcFZXp8OHD4ubmJg0aNJCLFy8qkwL6+/tLq1atNJty4MyZM2JlZSVeXl7i4uKiXEss8/28detWg/WNoZ+DgoLE09NTqlevLi4uLtK2bVvlR8zhw4elWLFiRtfPISEhUqhQIfH395f58+eLr6+vlChRQkaMGCF///23vPPOO1KnTh2jqjk+Pl4GDBgg/fr1k8WLF4tOp5Nx48YZBKK0tDRZuXKluLq6StGiRaVcuXLi5uam2aWYGJxItfz2q0AkIzQ5OjrKqFGjZO3atTJ69GgxNzdXvtQTEhLk999/l2LFikm5cuWkffv20rVrVylYsKBm8zRl1jx27FgJDg6WL774QnQ6ndy6dUtu3bolgwYNEnNzc1myZIncvn1bHj9+LBMmTJDKlStLTEyMJjWLZOwhe//99+W7776TqlWrSs+ePZVpKX799Vfx9vaWsmXLGkUfi2Scol2wYEEZN26cQXtqaqrcu3dPAgICjK6f4+PjpXnz5sohLpGML8vTp08r87udO3dOvL29pXTp0lKzZk1p166dWFtby9mzZzWpOTOcTpo0Se7evSve3t4yc+ZMEcmYkHPw4MFibm4u3333ndH0c+a8RhMmTJD4+HjZtm2buLq6GlzZwNj6OTExUXr16mVwkebHjx/Lu+++KzqdTnr06CFBQUFSq1YtKVGihFHULJJxosDixYtl/fr1IiKyYcOGbMOTSMbUNvv375ft27fLzZs3tShXRBicSKX8+KsgOjpamjdvnuVq7w0bNpRhw4YZtMXFxcn48eNl4MCBMnToUINxOnnp7t27Ur9+fYPxHenp6eLr6ytHjhyRoKAgOXbsmHz77bdiYWEhXl5eUqlSJc2vXJ6amip37tyRMmXKyM2bN2XTpk1So0YN8ff3lwYNGkjXrl0lLi5Oxo4dq3kfi2TMwu/q6iq+vr5K/SNHjpSWLVuKt7e3fP3117J3715ZtGiRUfVzYmKi1K1bV06dOiWpqani6+srNWrUEGtra6lVq5b88MMPyrqLFi2SCRMmyNSpU+XChQua1Hv27FnR6/UyadIkEcn4jOjcubNUq1ZNWSciIkJmzZolFhYWUqJECaPo5++++04aNmxosCe0VatW8t1338mKFStk7969Srsx9HOmJk2ayLRp00Tk30uQjB8/Xjp27CjVqlWTxYsXi0jGGXXGUrOIZLno+Pr160Wn08nYsWOVH+gpKSmaH7rNxOBEquTHXwWRkZFSs2ZNOXDggIj8OwC4f//+0qtXLxERg8HsmbScV+jevXsya9YsgwlEP/vsM9HpdFKpUiXx8PCQFi1ayPnz5+XChQuyYcMGWb9+vVy7dk2zmkX+PRW4V69esmPHDhER+eOPP8TJyUmsra0NvtBFtO1jkYzg1KFDB6levbr8+uuv0qJFC2nSpImMGTNGPvroIylZsqQMHDhQ4uPj5ezZs0bTz5GRkVK4cGHZuXOnjBo1Snx9feXs2bOyfft2GTdunLi6usq6des0rfFJx44dk08//VRE/v03v3DhgtjZ2ck333xjsK4x9fPSpUulRIkSSnibOXOm6HQ6adq0qVSvXl2cnZ2VeeqMQXp6uiQkJEi9evWkd+/eyjjCmzdviqenp/z444/i5+cn9erV07jS50tNTVU+SzLHwI0bN05u3bolo0aNko4dO0p8fLzmc+oxOJFq+e1XgYgYBJDMgaeTJ0+W3r17G6z35KBxrf9TxsXFKX/P/PDYsGGDREdHy759+6R69eoyZcoUDSt8tj59+siECRNEJGPsRKFChcTb21sGDBigDBgX0b6PRTL2dPTp00csLS2lWbNmBuNp1qxZI3Z2dq/1elc5kZ6eLt27d5ehQ4dKmzZtlJAqkjGQ2c/PT4YMGSIpKSmaz/ycnfT0dHnw4IFyuDazTq2D9NMyr+lXqlQp6dSpk+h0Ovn1118lPT1doqKiZPjw4dKwYUO5e/euUfXzX3/9JSYmJlK/fn3p3bu3FCxYULnEzj///CM2NjYSEhKiDAQ3hpqf9uSP2fXr14u5ubmULVtWzMzMjOY6lmZ5N/EB5XcFCxYEkDHXhomJCbp16wYRQc+ePaHT6TBy5Eh88cUXuH79OlatWgUrK6u8nVsjG6VLlwaQMT+Jubk5gIy5pu7cuaOsM3v2bOj1egwfPhxmZmaa12xjY6P83cfHBydOnEDVqlUBAA0aNICLiwtOnTqlVXnZEhHodDo0btwYYWFh+Oijj7Bt2zacPHkSZ86cwbhx42BhYYEqVapAr9dr3scAUKRIEcyePRtFixZF06ZN4ejoqLyOXr16Ydq0adi/fz/atGmjdakKnU6HMWPGoGHDhnj06BEGDx6sLCtWrBhcXFxw/PhxmJqaKn1sDH2dSafTwc7ODr1790bnzp0xfPhw1KlTR+uysvDy8sKaNWtw/PhxnD9/HjqdDu3atQMAODs7w83NDfv374e1tTVMTDKmQzSGfq5Tpw6OHDmCRYsWQa/XY+7cufjoo48AAFevXkWxYsVQpEgRmJqaAjCOmp/25JyA3bp1w/fff48zZ87g1KlTqFixosbVZWBwopdmamoKEUF6ejq6d+8OnU6H3r174/fff8eVK1dw/PhxJWQZCxMTE+VLMfM+AEyZMgUzZ87E6dOnYWZmfP8dPD094enpCSAj/CUnJ8Pa2hqVKlXSuDJDmf3q5eWF/v37w8XFBVu3boWXlxe8vLyg0+lQuXJl6PV6jSs15ObmhgkTJqBAgQIAMl6HiCAmJgaFCxdGlSpVNK4wq+rVq2P79u1o0KABvv/+e5QoUQLvvPMOgIyJXcuUKYPU1FTlh4IxatOmDZo1a4YlS5agatWqsLS01LqkLDLfuz/88ANOnDiB5ORkWFhYAACioqJQvHhxZcJGY1KjRg2sWrUqSyg6ePAgXFxcjDIsPU2n0yEtLQ3jxo3D3r17cebMGaMJTQA4ASbl3JMXCG3cuLE4ODhIUFCQxlU9W+bu36lTp8rgwYNl3rx5otfrNRu8nhOffvqpeHh4GByCNCbJycmybNky5SwdYzwUoMaUKVOkdOnSmo+1eZ79+/eLm5ub1KxZU/z9/aV3795iZ2en6ZmKL2P27Nlia2urTE1grDKvxTl37lxZtWqVjB8/Xuzt7Y36s+5JQUFB8tFHH4mtra2cOXNG63JUS01NlR9++MFoDs89yfh+YlO+YfS/Cp6SuZfJ3Nwc//3vf2Fra4u//vpLOQxmzDZu3Ij9+/dj/fr1CAwMVA5BGhtzc3P069fPqA5fvIz169dj79692LhxI3bv3q3s7TNG9evXx549e7BmzRocOXIEpUuXxl9//YUKFSpoXdpzyf/v+f3ggw/w888/IzExUeuSnsvb2xubN2/GoEGDYGJigqJFi2L//v1G/VmXKSkpCZcvX0ZMTAwOHjxodHuqn8fU1BQDBgwwys8QnYiI1kVQ/pWWloYVK1agWrVqePfdd7UuR5UTJ06gZs2aOHfuHLy9vbUuR5Xg4GB89tlnmDZtGsqXL691OW+soKAgTJo0CZ9//rly+Cs/yLzGWGZgzQ9EBI8ePTK6w/rPEhMTg5SUFOj1etjb22tdjmqZ14zML/2cHzA40SuTJ8YO5RcJCQn57oMkJSXFqMetvCmeHMtCRPQ0BiciIiIilfLPfl0iIiIijTE4EREREanE4ERERESkEoMTERERkUoMTkREREQqMTgRERERqcTgRESaadiwIUaOHKl1GUREqjE4EdFLa9u2LVq0aJHtsoMHD0Kn0yEoKCiPq8retWvXoNPplJuDgwMaNGiAgwcPal0aEeVDDE5E9NL8/f0RGBiImzdvZlm2fPlyVK9e3eiui7Vr1y7cvn0bBw4cgJubG9q0aYOoqCityyKifIbBiYheWps2bVC4cGGsWLHCoD0+Ph4bN26Ev78/oqOj0aNHDxQtWhRWVlaoWLEifvrpp+duV6fT4ddffzVos7e3N3ieGzduoGvXrrC3t4eDgwPatWuHa9euvbBmR0dHuLq6okKFCpg0aRLi4uJw9OhRZfnq1atRvXp12NjYwNXVFT179sSdO3eU5fv27YNOp8Pu3btRvXp1WFlZ4b333kNoaKjB88ycORPOzs6wsbHBwIEDMWHChCzXcfzhhx9Qvnx5FChQAOXKlcO33377wvqJyDgwOBHRSzMzM0OfPn2wYsUKPHnVpo0bNyItLQ09evRAYmIiqlWrhj/++APnzp3D4MGD0bt3bxw7dizHz5uSkgJfX1/Y2Njg4MGD+Pvvv2FtbY0WLVogOTlZ1TYeP36MVatWAYDBNelSUlIwY8YMnD17Fr/++iuuXbuGfv36ZXn8J598gvnz5+PEiRMwMzPDgAEDlGVr167Ff/7zH3z++ec4efIkPDw8sGTJEoPHr127FlOmTMF//vMfhISEYNasWfj000+xcuXKHPQIEeU5ISLKgZCQEAEge/fuVdrq1asnfn5+z3xM69atZcyYMcr9Bg0ayIgRI5T7AGTz5s0Gj7Gzs5Ply5eLiMjq1aulbNmykp6erixPSkoSS0tL+fPPP7N9zrCwMAEglpaWUrBgQdHpdAJAqlWrJsnJyc+s9fjx4wJAHj58KCIie/fuFQCya9cuZZ0//vhDAMjjx49FRKRWrVoSEBBgsJ06depI5cqVlfslS5aUdevWGawzY8YM8fHxeWYtRGQ8uMeJiHKkXLlyeO+99/Djjz8CAC5fvoyDBw/C398fAJCWloYZM2agYsWKcHBwgLW1Nf7880+Eh4fn+DnPnj2Ly5cvw8bGBtbW1rC2toaDgwMSExNx5cqV5z52w4YNOH36NH755ReUKlUKK1asgLm5ubL85MmTaNu2LTw8PGBjY4MGDRoAQJZ6nxy7VaRIEQBQDumFhoaiZs2aBus/eT8hIQFXrlyBv7+/Ur+1tTVmzpz5wvqJyDiYaV0AEeVf/v7+GDZsGBYvXozly5ejZMmSSuCYN28evvrqKyxcuBAVK1ZEwYIFMXLkyOceUtPpdAaH/oCMQ2iZ4uPjUa1aNaxduzbLYwsXLvzcWt3d3VG6dGmULl0aqamp6NChA86dOwe9Xo+EhAT4+vrC19cXa9euReHChREeHg5fX98s9T4ZtnQ6HQAgPT39uc/9ZP0A8N///he1atUyWGZqaqpqG0SkLe5xIqIc69q1K0xMTLBu3TqsWrUKAwYMUMLE33//jXbt2sHPzw+VK1dGiRIlcPHixedur3Dhwrh9+7Zy/9KlS3j06JFyv2rVqrh06RKcnZ1RqlQpg5udnZ3qujt37gwzMzNlUPaFCxcQHR2NOXPmoF69eihXrpzBwHC1ypYti+PHjxu0PXnfxcUFbm5uuHr1apb6vby8Xvr5iCjvMTgRUY5ZW1ujW7dumDhxIm7fvm0wmLp06dIIDAzEoUOHEBISgg8++OCFp/83btwY33zzDU6fPo0TJ05gyJAhBnt4evXqBScnJ7Rr1w4HDx5EWFgY9u3bh+HDh2c7NcKz6HQ6DB8+HHPmzMGjR4/g4eEBCwsLfP3117h69Sp+//13zJgx46X7Y9iwYVi2bBlWrlyJS5cuYebMmQgKClLCJABMnz4ds2fPxqJFi3Dx4kX8888/WL58ORYsWPDSz0dEeY/BiYheib+/P+7fvw9fX1+4ubkp7ZMnT0bVqlXh6+uLhg0bwtXVFe3bt3/utubPnw93d3fUq1cPPXv2xNixY2FlZaUst7KywoEDB+Dh4YGOHTuifPny8Pf3R2JiImxtbV+q7r59+yIlJQXffPONMrXCxo0b4e3tjTlz5uCLL754qe0BGcFu4sSJGDt2LKpWrYqwsDD069cPBQoUUNYZOHAgfvjhByxfvhwVK1ZEgwYNsGLFCu5xIsondPL0gAIiIso1zZo1g6urK1avXq11KUSUCzg4nIgolzx69AhLly6Fr68vTE1N8dNPP2HXrl0IDAzUujQiyiXc40RElEseP36Mtm3b4vTp00hMTETZsmUxefJkdOzYUevSiCiXMDgRERERqcTB4UREREQqMTgRERERqcTgRERERKQSgxMRERGRSgxORERERCoxOBERERGpxOBEREREpBKDExEREZFK/wfAI3Hj0XzVTgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bins = list(range(0, 101, 10)) + [float('inf')]\n",
    "\n",
    "# 플롯 그리기\n",
    "plt.hist(sorted(ppl_list), bins=bins, edgecolor='black', align='left')\n",
    "\n",
    "# x축 레이블 설정\n",
    "bin_labels = [f'{i}-{i+9}' for i in range(0, 100, 10)] + ['100+']\n",
    "plt.xticks(bins[:-1], bin_labels, rotation=45)\n",
    "\n",
    "# 플롯 제목과 축 레이블 설정\n",
    "plt.title('Histogram of Data')\n",
    "plt.xlabel('Value Range')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 플롯 표시\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30e4c4b5-cdf1-48ab-af4b-61339454e183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458.59769982704154"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array = np.array(ppl_list)\n",
    "\n",
    "# NaN 값을 제외하고 평균 계산\n",
    "mean_value = np.nanmean(data_array)\n",
    "mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63b611d7-82c2-4939-a5ca-ee0328e774ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPL : 458.59769982704154, \n",
      "BertScore : 0.8608927405929346 \n",
      "rouge1 : 0.1055118869909077 \n",
      "rouge2 : 0.02198041612414733 \n",
      "rougeL : 0.09848514792146265 \n",
      "rougeLsum : 0.09848514792146265, \n",
      "bleu_1 : 0.03795522364934471 \n",
      "bleu_2 : 0.017187785138514416 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ber = [i['precision'][0] for i in bert]\n",
    "\n",
    "rouge1 = np.mean([i['rouge1'] for i in rough])\n",
    "\n",
    "rouge2 = np.mean([i['rouge2'] for i in rough])\n",
    "\n",
    "rougeL = np.mean([i['rougeL'] for i in rough])\n",
    "\n",
    "rougeLsum = np.mean([i['rougeLsum'] for i in rough])\n",
    "\n",
    "mean_bleu_1 = np.mean(bleu_1_list)\n",
    "\n",
    "mean_bleu_2 = np.mean(bleu_2_list)\n",
    "\n",
    "print(f'PPL : {mean_value}, \\nBertScore : {np.mean(ber)} \\nrouge1 : {rouge1} \\nrouge2 : {rouge2} \\nrougeL : {rougeL} \\nrougeLsum : {rougeLsum}, \\nbleu_1 : {mean_bleu_1} \\nbleu_2 : {mean_bleu_2} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47caa1ae-711e-4060-9a71-15f64f51090e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19517634426364913"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_ngrams(infer, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08fa72dc-9ad3-467a-b3ec-952aee300ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5661651234567902"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "distinct_ngrams(infer, 1)\n",
    "distinct_ngrams(infer, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "caa08015-d452-4e88-9ef5-7c826b6bc1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8492068219184875"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd9710af-4079-465a-8c69-380b3710f70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge1 = np.mean([i['rouge1'] for i in rough])\n",
    "\n",
    "rouge2 = np.mean([i['rouge2'] for i in rough])\n",
    "\n",
    "rougeL = np.mean([i['rougeL'] for i in rough])\n",
    "\n",
    "rougeLsum = np.mean([i['rougeLsum'] for i in rough])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6046ebd4-0ad1-49e2-b439-f32c6c1b1297",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bleu = np.mean([i['bleu'] for i in bleu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fa16661-0c26-4fc1-97e5-857f1b8d11ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPL : 6.603209018707275, \n",
      "BertScore : 0.8492068219184875 \n",
      "rouge1 : 0.0864367417136198 \n",
      "rouge2 : 0.016000117526532315 \n",
      "rougeL : 0.07990215447014093 \n",
      "rougeLsum : 0.07990215447014093, \n",
      "bleu : 0.007389715194612174\n"
     ]
    }
   ],
   "source": [
    "print(f'PPL : {calculate_mean(ppl_list)}, \\nBertScore : {np.mean(ber)} \\nrouge1 : {rouge1} \\nrouge2 : {rouge2} \\nrougeL : {rougeL} \\nrougeLsum : {rougeLsum}, \\nbleu : {mean_bleu}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230233e6-40f8-416c-ac0e-ba6b52dfbfac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
