[2024-05-07 17:19:56,155] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-05-07 17:19:57,007] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-05-07 17:19:57,007] [INFO] [runner.py:568:main] cmd = /home/chanho/anaconda3/envs/COMEDY/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMV19 --master_addr=127.0.0.1 --master_port=8888 --enable_each_rank_log=None training/SFT/main.py --model_name_or_path /home/chanho/Model/COMEDY/EPISODE/result/model_path --train_data_path /home/chanho/Model/COMEDY/EPISODE/result/dataset/train_data.json --valid_data_path /home/chanho/Model/COMEDY/EPISODE/result/dataset/test_data.json --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --data_output_path /home/chanho/Model/COMEDY/EPISODE/result/output_path/data --max_seq_len 2048 --learning_rate 1e-5 --weight_decay 0.1 --num_train_epochs 500 --num_train_samples 3945 /home/chanho/Model/COMEDY/EPISODE/result/dataset/train_data.json --gradient_accumulation_steps 4 --lr_scheduler_type cosine --num_warmup_steps 400 --seed 42 --zero_stage 2 --save_interval 2000 --log_interval 100 --eval_interval 100 --output_dir /home/chanho/Model/COMEDY/EPISODE/result/output_path/2024-05-07-16.19.53 --gradient_checkpointing --tensorboard_path /home/chanho/Model/COMEDY/EPISODE/result/log_path/2024-05-07-16.19.53
[2024-05-07 17:19:58,486] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[2024-05-07 17:19:59,008] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1]}
[2024-05-07 17:19:59,008] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=2, node_rank=0
[2024-05-07 17:19:59,008] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})
[2024-05-07 17:19:59,008] [INFO] [launch.py:164:main] dist_world_size=2
[2024-05-07 17:19:59,008] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1
[2024-05-07 17:19:59,008] [INFO] [launch.py:256:main] process 1603239 spawned with command: ['/home/chanho/anaconda3/envs/COMEDY/bin/python', '-u', 'training/SFT/main.py', '--local_rank=0', '--model_name_or_path', '/home/chanho/Model/COMEDY/EPISODE/result/model_path', '--train_data_path', '/home/chanho/Model/COMEDY/EPISODE/result/dataset/train_data.json', '--valid_data_path', '/home/chanho/Model/COMEDY/EPISODE/result/dataset/test_data.json', '--per_device_train_batch_size', '1', '--per_device_eval_batch_size', '1', '--data_output_path', '/home/chanho/Model/COMEDY/EPISODE/result/output_path/data', '--max_seq_len', '2048', '--learning_rate', '1e-5', '--weight_decay', '0.1', '--num_train_epochs', '500', '--num_train_samples', '3945', '/home/chanho/Model/COMEDY/EPISODE/result/dataset/train_data.json', '--gradient_accumulation_steps', '4', '--lr_scheduler_type', 'cosine', '--num_warmup_steps', '400', '--seed', '42', '--zero_stage', '2', '--save_interval', '2000', '--log_interval', '100', '--eval_interval', '100', '--output_dir', '/home/chanho/Model/COMEDY/EPISODE/result/output_path/2024-05-07-16.19.53', '--gradient_checkpointing', '--tensorboard_path', '/home/chanho/Model/COMEDY/EPISODE/result/log_path/2024-05-07-16.19.53']
[2024-05-07 17:19:59,009] [INFO] [launch.py:256:main] process 1603240 spawned with command: ['/home/chanho/anaconda3/envs/COMEDY/bin/python', '-u', 'training/SFT/main.py', '--local_rank=1', '--model_name_or_path', '/home/chanho/Model/COMEDY/EPISODE/result/model_path', '--train_data_path', '/home/chanho/Model/COMEDY/EPISODE/result/dataset/train_data.json', '--valid_data_path', '/home/chanho/Model/COMEDY/EPISODE/result/dataset/test_data.json', '--per_device_train_batch_size', '1', '--per_device_eval_batch_size', '1', '--data_output_path', '/home/chanho/Model/COMEDY/EPISODE/result/output_path/data', '--max_seq_len', '2048', '--learning_rate', '1e-5', '--weight_decay', '0.1', '--num_train_epochs', '500', '--num_train_samples', '3945', '/home/chanho/Model/COMEDY/EPISODE/result/dataset/train_data.json', '--gradient_accumulation_steps', '4', '--lr_scheduler_type', 'cosine', '--num_warmup_steps', '400', '--seed', '42', '--zero_stage', '2', '--save_interval', '2000', '--log_interval', '100', '--eval_interval', '100', '--output_dir', '/home/chanho/Model/COMEDY/EPISODE/result/output_path/2024-05-07-16.19.53', '--gradient_checkpointing', '--tensorboard_path', '/home/chanho/Model/COMEDY/EPISODE/result/log_path/2024-05-07-16.19.53']
[2024-05-07 17:20:01,523] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-05-07 17:20:01,536] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3
[93m [WARNING] [0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible
/home/chanho/anaconda3/envs/COMEDY/lib/python3.11/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
/home/chanho/anaconda3/envs/COMEDY/lib/python3.11/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations
  warnings.warn(
Namespace(data_path=['Dahoas/rm-static'], data_split='6,2,2', data_output_path='/home/chanho/Model/COMEDY/EPISODE/result/output_path/data', model_name_or_path='/home/chanho/Model/COMEDY/EPISODE/result/model_path', per_device_train_batch_size=1, per_device_eval_batch_size=1, max_seq_len=2048, learning_rate=1e-05, weight_decay=0.1, num_train_epochs=500, gradient_accumulation_steps=4, lr_scheduler_type=<SchedulerType.COSINE: 'cosine'>, num_warmup_steps=400, output_dir='/home/chanho/Model/COMEDY/EPISODE/result/output_path/2024-05-07-16.19.53', seed=42, local_rank=1, gradient_checkpointing=True, offload=False, zero_stage=2, lora_dim=0, lora_module_name='decoder.layers.', only_optimize_lora=False, tensorboard_path='/home/chanho/Model/COMEDY/EPISODE/result/log_path/2024-05-07-16.19.53', save_interval=2000, log_interval=100, eval_interval=100, train_data_path='/home/chanho/Model/COMEDY/EPISODE/result/dataset/train_data.json', valid_data_path='/home/chanho/Model/COMEDY/EPISODE/result/dataset/test_data.json', num_train_samples=3945, ntk_RoPE_scaling_ratio=1, deepspeed=False, deepspeed_config=None, deepscale=False, deepscale_config=None)
['/home/chanho/Model/COMEDY/EPISODE/result/dataset/train_data.json']
Namespace(data_path=['Dahoas/rm-static'], data_split='6,2,2', data_output_path='/home/chanho/Model/COMEDY/EPISODE/result/output_path/data', model_name_or_path='/home/chanho/Model/COMEDY/EPISODE/result/model_path', per_device_train_batch_size=1, per_device_eval_batch_size=1, max_seq_len=2048, learning_rate=1e-05, weight_decay=0.1, num_train_epochs=500, gradient_accumulation_steps=4, lr_scheduler_type=<SchedulerType.COSINE: 'cosine'>, num_warmup_steps=400, output_dir='/home/chanho/Model/COMEDY/EPISODE/result/output_path/2024-05-07-16.19.53', seed=42, local_rank=0, gradient_checkpointing=True, offload=False, zero_stage=2, lora_dim=0, lora_module_name='decoder.layers.', only_optimize_lora=False, tensorboard_path='/home/chanho/Model/COMEDY/EPISODE/result/log_path/2024-05-07-16.19.53', save_interval=2000, log_interval=100, eval_interval=100, train_data_path='/home/chanho/Model/COMEDY/EPISODE/result/dataset/train_data.json', valid_data_path='/home/chanho/Model/COMEDY/EPISODE/result/dataset/test_data.json', num_train_samples=3945, ntk_RoPE_scaling_ratio=1, deepspeed=False, deepspeed_config=None, deepscale=False, deepscale_config=None)
['/home/chanho/Model/COMEDY/EPISODE/result/dataset/train_data.json']
[2024-05-07 17:20:01,956] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-05-07 17:20:01,956] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-05-07 17:20:02,294] [INFO] [comm.py:637:init_distributed] cdb=None
/home/chanho/anaconda3/envs/COMEDY/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/chanho/anaconda3/envs/COMEDY/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.
Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use
`config.hidden_activation` if you want to override this behaviour.
See https://github.com/huggingface/transformers/pull/29402 for more details.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.
Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use
`config.hidden_activation` if you want to override this behaviour.
See https://github.com/huggingface/transformers/pull/29402 for more details.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.27s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.63it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.64it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.41it/s]
trainable params: 1,843,200 || all params: 2,508,015,616 || trainable%: 0.073492365368111
trainable params: 1,843,200 || all params: 2,508,015,616 || trainable%: 0.073492365368111
____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
args.global_rank 1
Using /home/chanho/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/chanho/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...
/home/chanho/anaconda3/envs/COMEDY/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module fused_adam...
Time to load fused_adam op: 0.06122112274169922 seconds
____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
args.global_rank 0
Using /home/chanho/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/chanho/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...
/home/chanho/anaconda3/envs/COMEDY/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module fused_adam...
Time to load fused_adam op: 0.08137249946594238 seconds
[2024-05-07 17:20:07,394] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.2, git-hash=unknown, git-branch=unknown
[2024-05-07 17:20:07,394] [INFO] [comm.py:662:init_distributed] Distributed backend already initialized
[2024-05-07 17:20:09,556] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-05-07 17:20:09,557] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-05-07 17:20:09,557] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-05-07 17:20:09,558] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2024-05-07 17:20:09,558] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[2024-05-07 17:20:09,558] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-05-07 17:20:09,558] [INFO] [stage_1_and_2.py:148:__init__] Reduce bucket size 500,000,000
[2024-05-07 17:20:09,558] [INFO] [stage_1_and_2.py:149:__init__] Allgather bucket size 500,000,000
[2024-05-07 17:20:09,558] [INFO] [stage_1_and_2.py:150:__init__] CPU Offload: False
[2024-05-07 17:20:09,558] [INFO] [stage_1_and_2.py:151:__init__] Round robin gradient partitioning: False
[2024-05-07 17:20:10,112] [INFO] [utils.py:779:see_memory_usage] Before initializing optimizer states
[2024-05-07 17:20:10,112] [INFO] [utils.py:780:see_memory_usage] MA 4.68 GB         Max_MA 4.68 GB         CA 4.74 GB         Max_CA 5 GB 
[2024-05-07 17:20:10,112] [INFO] [utils.py:787:see_memory_usage] CPU Virtual Memory:  used = 14.49 GB, percent = 11.5%
[2024-05-07 17:20:10,244] [INFO] [utils.py:779:see_memory_usage] After initializing optimizer states
[2024-05-07 17:20:10,244] [INFO] [utils.py:780:see_memory_usage] MA 4.68 GB         Max_MA 4.68 GB         CA 4.74 GB         Max_CA 5 GB 
[2024-05-07 17:20:10,244] [INFO] [utils.py:787:see_memory_usage] CPU Virtual Memory:  used = 14.52 GB, percent = 11.6%
[2024-05-07 17:20:10,244] [INFO] [stage_1_and_2.py:543:__init__] optimizer state initialized
[2024-05-07 17:20:10,379] [INFO] [utils.py:779:see_memory_usage] After initializing ZeRO optimizer
[2024-05-07 17:20:10,380] [INFO] [utils.py:780:see_memory_usage] MA 4.68 GB         Max_MA 4.68 GB         CA 4.74 GB         Max_CA 5 GB 
[2024-05-07 17:20:10,380] [INFO] [utils.py:787:see_memory_usage] CPU Virtual Memory:  used = 14.53 GB, percent = 11.6%
[2024-05-07 17:20:10,381] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[2024-05-07 17:20:10,381] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-05-07 17:20:10,381] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f3d2fa06850>
[2024-05-07 17:20:10,381] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.95)]
[2024-05-07 17:20:10,381] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f3d2fb80c50>
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 4
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   gradient_clipping ............ 1.0
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-05-07 17:20:10,382] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   steps_per_print .............. 10
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   train_batch_size ............. 8
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  1
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   world_size ................... 2
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=30000000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=30000000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-05-07 17:20:10,383] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-05-07 17:20:10,383] [INFO] [config.py:986:print_user_config]   json = {
    "train_batch_size": 8, 
    "train_micro_batch_size_per_gpu": 1, 
    "steps_per_print": 10, 
    "zero_optimization": {
        "stage": 2, 
        "offload_param": {
            "device": "none"
        }, 
        "offload_optimizer": {
            "device": "none"
        }, 
        "stage3_param_persistence_threshold": 1.000000e+04, 
        "stage3_max_live_parameters": 3.000000e+07, 
        "stage3_prefetch_bucket_size": 3.000000e+07, 
        "memory_efficient_linear": false
    }, 
    "bf16": {
        "enabled": true
    }, 
    "gradient_clipping": 1.0, 
    "prescale_gradients": false, 
    "wall_clock_breakdown": false, 
    "hybrid_engine": {
        "enabled": false, 
        "inference_tp_size": 1, 
        "release_inference_cache": false, 
        "pin_parameters": true, 
        "tp_gather_partition_size": 8
    }
}
wandb: Currently logged in as: cksgh0984 (organization-chanho). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: cksgh0984 (organization-chanho). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /home/chanho/Model/COMEDY/EPISODE/wandb/run-20240507_172010-a6zkp5uj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-moon-11
wandb: ⭐️ View project at https://wandb.ai/organization-chanho/Shared%20Memory
wandb: 🚀 View run at https://wandb.ai/organization-chanho/Shared%20Memory/runs/a6zkp5uj
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /home/chanho/Model/COMEDY/EPISODE/wandb/run-20240507_172011-4o7vtso6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-meadow-12
wandb: ⭐️ View project at https://wandb.ai/organization-chanho/Shared%20Memory
wandb: 🚀 View run at https://wandb.ai/organization-chanho/Shared%20Memory/runs/4o7vtso6
***** Running training *****
***** Evaluating perplexity, Epoch 0/500 *****
Beginning of Epoch 1/500
[2024-05-07 17:20:37,703] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[2.5000000000000004e-07], mom=[(0.9, 0.95)]
[2024-05-07 17:20:37,703] [INFO] [timer.py:260:stop] epoch=0/micro_step=40/global_step=10, RunningAvgSamplesPerSec=3.3367468650935153, CurrSamplesPerSec=3.3167332742825213, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:21:01,962] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[5.000000000000001e-07], mom=[(0.9, 0.95)]
[2024-05-07 17:21:01,962] [INFO] [timer.py:260:stop] epoch=0/micro_step=80/global_step=20, RunningAvgSamplesPerSec=3.3225875530173314, CurrSamplesPerSec=3.3056808034570784, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 13.899540599029843
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 1103196.5, loss: 13.913424491882324
[2024-05-07 17:22:07,853] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[7.5e-07], mom=[(0.9, 0.95)]
[2024-05-07 17:22:07,854] [INFO] [timer.py:260:stop] epoch=0/micro_step=120/global_step=30, RunningAvgSamplesPerSec=3.312097624610758, CurrSamplesPerSec=3.287907605047756, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:22:32,327] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[1.0000000000000002e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:22:32,328] [INFO] [timer.py:260:stop] epoch=0/micro_step=160/global_step=40, RunningAvgSamplesPerSec=3.304928173015956, CurrSamplesPerSec=3.285979241817597, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:22:56,798] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[1.25e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:22:56,799] [INFO] [timer.py:260:stop] epoch=0/micro_step=200/global_step=50, RunningAvgSamplesPerSec=3.3006980287881467, CurrSamplesPerSec=3.2868505727670394, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 13.994986220971862
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 1090605.125, loss: 13.901937484741211
[2024-05-07 17:24:02,835] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=0, lr=[1.5e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:24:02,836] [INFO] [timer.py:260:stop] epoch=0/micro_step=240/global_step=60, RunningAvgSamplesPerSec=3.2978119294168695, CurrSamplesPerSec=3.2794610392358408, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:24:27,278] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=0, lr=[1.75e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:24:27,279] [INFO] [timer.py:260:stop] epoch=0/micro_step=280/global_step=70, RunningAvgSamplesPerSec=3.2961308617219647, CurrSamplesPerSec=3.289996613368898, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 13.957115658097885
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 1032782.5, loss: 13.847494125366211
[2024-05-07 17:25:33,245] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=0, lr=[2.0000000000000003e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:25:33,246] [INFO] [timer.py:260:stop] epoch=0/micro_step=320/global_step=80, RunningAvgSamplesPerSec=3.2949321180424502, CurrSamplesPerSec=3.293272149703468, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:25:57,682] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=0, lr=[2.25e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:25:57,683] [INFO] [timer.py:260:stop] epoch=0/micro_step=360/global_step=90, RunningAvgSamplesPerSec=3.294158635314979, CurrSamplesPerSec=3.2884247742581416, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:26:22,148] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=0, lr=[2.5e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:26:22,149] [INFO] [timer.py:260:stop] epoch=0/micro_step=400/global_step=100, RunningAvgSamplesPerSec=3.2933330194302184, CurrSamplesPerSec=3.2834891471776633, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 13.958305004528931
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 900205.125, loss: 13.710134506225586
[2024-05-07 17:27:28,184] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=0, lr=[2.7500000000000004e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:27:28,185] [INFO] [timer.py:260:stop] epoch=0/micro_step=440/global_step=110, RunningAvgSamplesPerSec=3.2923413862926822, CurrSamplesPerSec=3.282991516813741, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:27:52,664] [INFO] [logging.py:96:log_dist] [Rank 0] step=120, skipped=0, lr=[3e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:27:52,665] [INFO] [timer.py:260:stop] epoch=0/micro_step=480/global_step=120, RunningAvgSamplesPerSec=3.2916121922101187, CurrSamplesPerSec=3.286781029579669, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 13.847843371465535
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 683742.6875, loss: 13.435104370117188
[2024-05-07 17:28:58,724] [INFO] [logging.py:96:log_dist] [Rank 0] step=130, skipped=0, lr=[3.2500000000000002e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:28:58,724] [INFO] [timer.py:260:stop] epoch=0/micro_step=520/global_step=130, RunningAvgSamplesPerSec=3.29093672648989, CurrSamplesPerSec=3.27961393437768, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:29:23,184] [INFO] [logging.py:96:log_dist] [Rank 0] step=140, skipped=0, lr=[3.5e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:29:23,185] [INFO] [timer.py:260:stop] epoch=0/micro_step=560/global_step=140, RunningAvgSamplesPerSec=3.2905005857001735, CurrSamplesPerSec=3.2894279984420662, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:29:47,655] [INFO] [logging.py:96:log_dist] [Rank 0] step=150, skipped=0, lr=[3.7500000000000005e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:29:47,656] [INFO] [timer.py:260:stop] epoch=0/micro_step=600/global_step=150, RunningAvgSamplesPerSec=3.290083017658138, CurrSamplesPerSec=3.281374697772011, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 13.78807302520993
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 486739.0, loss: 13.095312118530273
[2024-05-07 17:30:53,655] [INFO] [logging.py:96:log_dist] [Rank 0] step=160, skipped=0, lr=[4.000000000000001e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:30:53,655] [INFO] [timer.py:260:stop] epoch=0/micro_step=640/global_step=160, RunningAvgSamplesPerSec=3.2897386960915664, CurrSamplesPerSec=3.2866451712875073, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:31:18,118] [INFO] [logging.py:96:log_dist] [Rank 0] step=170, skipped=0, lr=[4.25e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:31:18,119] [INFO] [timer.py:260:stop] epoch=0/micro_step=680/global_step=170, RunningAvgSamplesPerSec=3.2894903210131328, CurrSamplesPerSec=3.286462971400677, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 13.65368917052994
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 322090.8125, loss: 12.68250846862793
[2024-05-07 17:32:24,112] [INFO] [logging.py:96:log_dist] [Rank 0] step=180, skipped=0, lr=[4.5e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:32:24,113] [INFO] [timer.py:260:stop] epoch=0/micro_step=720/global_step=180, RunningAvgSamplesPerSec=3.2892396063637874, CurrSamplesPerSec=3.2874166865061287, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:32:48,590] [INFO] [logging.py:96:log_dist] [Rank 0] step=190, skipped=0, lr=[4.75e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:32:48,591] [INFO] [timer.py:260:stop] epoch=0/micro_step=760/global_step=190, RunningAvgSamplesPerSec=3.2889509886985495, CurrSamplesPerSec=3.27935911706098, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:33:13,049] [INFO] [logging.py:96:log_dist] [Rank 0] step=200, skipped=0, lr=[5e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:33:13,050] [INFO] [timer.py:260:stop] epoch=0/micro_step=800/global_step=200, RunningAvgSamplesPerSec=3.2887688138527627, CurrSamplesPerSec=3.285360545906825, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 13.51455540811822
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 207096.1875, loss: 12.2409029006958
[2024-05-07 17:34:19,057] [INFO] [logging.py:96:log_dist] [Rank 0] step=210, skipped=0, lr=[5.2500000000000006e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:34:19,058] [INFO] [timer.py:260:stop] epoch=0/micro_step=840/global_step=210, RunningAvgSamplesPerSec=3.2885159432811166, CurrSamplesPerSec=3.2805700926611756, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:34:43,531] [INFO] [logging.py:96:log_dist] [Rank 0] step=220, skipped=0, lr=[5.500000000000001e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:34:43,532] [INFO] [timer.py:260:stop] epoch=0/micro_step=880/global_step=220, RunningAvgSamplesPerSec=3.2883381379222523, CurrSamplesPerSec=3.28385965688346, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 13.337789017669898
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 128879.6875, loss: 11.766622543334961
[2024-05-07 17:35:49,566] [INFO] [logging.py:96:log_dist] [Rank 0] step=230, skipped=0, lr=[5.75e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:35:49,567] [INFO] [timer.py:260:stop] epoch=0/micro_step=920/global_step=230, RunningAvgSamplesPerSec=3.2881206247442103, CurrSamplesPerSec=3.2865434458916387, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:36:14,052] [INFO] [logging.py:96:log_dist] [Rank 0] step=240, skipped=0, lr=[6e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:36:14,053] [INFO] [timer.py:260:stop] epoch=0/micro_step=960/global_step=240, RunningAvgSamplesPerSec=3.2878988752620173, CurrSamplesPerSec=3.2879752627975005, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:36:38,497] [INFO] [logging.py:96:log_dist] [Rank 0] step=250, skipped=0, lr=[6.25e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:36:38,498] [INFO] [timer.py:260:stop] epoch=0/micro_step=1000/global_step=250, RunningAvgSamplesPerSec=3.287852889788516, CurrSamplesPerSec=3.2883467856809308, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 13.148017881157157
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 78687.4765625, loss: 11.273239135742188
[2024-05-07 17:37:44,473] [INFO] [logging.py:96:log_dist] [Rank 0] step=260, skipped=0, lr=[6.5000000000000004e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:37:44,474] [INFO] [timer.py:260:stop] epoch=0/micro_step=1040/global_step=260, RunningAvgSamplesPerSec=3.287761984247375, CurrSamplesPerSec=3.287854447340575, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:38:08,932] [INFO] [logging.py:96:log_dist] [Rank 0] step=270, skipped=0, lr=[6.750000000000001e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:38:08,933] [INFO] [timer.py:260:stop] epoch=0/micro_step=1080/global_step=270, RunningAvgSamplesPerSec=3.287667723781638, CurrSamplesPerSec=3.2838728335296383, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 12.956873314906856
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 49087.4296875, loss: 10.801348686218262
[2024-05-07 17:39:14,968] [INFO] [logging.py:96:log_dist] [Rank 0] step=280, skipped=0, lr=[7e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:39:14,968] [INFO] [timer.py:260:stop] epoch=0/micro_step=1120/global_step=280, RunningAvgSamplesPerSec=3.2874476166094366, CurrSamplesPerSec=3.2835241701022504, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:39:39,438] [INFO] [logging.py:96:log_dist] [Rank 0] step=290, skipped=0, lr=[7.25e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:39:39,439] [INFO] [timer.py:260:stop] epoch=0/micro_step=1160/global_step=290, RunningAvgSamplesPerSec=3.287315971214941, CurrSamplesPerSec=3.2798902716152876, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:40:03,900] [INFO] [logging.py:96:log_dist] [Rank 0] step=300, skipped=0, lr=[7.500000000000001e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:40:03,901] [INFO] [timer.py:260:stop] epoch=0/micro_step=1200/global_step=300, RunningAvgSamplesPerSec=3.2872557629172965, CurrSamplesPerSec=3.2873310162751848, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 12.767032465867258
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 30742.171875, loss: 10.333370208740234
[2024-05-07 17:41:09,930] [INFO] [logging.py:96:log_dist] [Rank 0] step=310, skipped=0, lr=[7.75e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:41:09,931] [INFO] [timer.py:260:stop] epoch=0/micro_step=1240/global_step=310, RunningAvgSamplesPerSec=3.2871565693171476, CurrSamplesPerSec=3.284238286556819, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:41:34,410] [INFO] [logging.py:96:log_dist] [Rank 0] step=320, skipped=0, lr=[8.000000000000001e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:41:34,411] [INFO] [timer.py:260:stop] epoch=0/micro_step=1280/global_step=320, RunningAvgSamplesPerSec=3.2870238998563663, CurrSamplesPerSec=3.280258366144619, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 12.569222521910202
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 19514.41015625, loss: 9.878896713256836
[2024-05-07 17:42:40,411] [INFO] [logging.py:96:log_dist] [Rank 0] step=330, skipped=0, lr=[8.25e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:42:40,412] [INFO] [timer.py:260:stop] epoch=0/micro_step=1320/global_step=330, RunningAvgSamplesPerSec=3.286940600071184, CurrSamplesPerSec=3.2863042872526353, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:43:04,889] [INFO] [logging.py:96:log_dist] [Rank 0] step=340, skipped=0, lr=[8.5e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:43:04,890] [INFO] [timer.py:260:stop] epoch=0/micro_step=1360/global_step=340, RunningAvgSamplesPerSec=3.2868582009025875, CurrSamplesPerSec=3.2813564069091643, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:43:29,359] [INFO] [logging.py:96:log_dist] [Rank 0] step=350, skipped=0, lr=[8.750000000000001e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:43:29,360] [INFO] [timer.py:260:stop] epoch=0/micro_step=1400/global_step=350, RunningAvgSamplesPerSec=3.286804601659393, CurrSamplesPerSec=3.2878067679504013, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 12.359444225625767
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 12433.353515625, loss: 9.428136825561523
[2024-05-07 17:44:35,385] [INFO] [logging.py:96:log_dist] [Rank 0] step=360, skipped=0, lr=[9e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:44:35,386] [INFO] [timer.py:260:stop] epoch=0/micro_step=1440/global_step=360, RunningAvgSamplesPerSec=3.286665910452223, CurrSamplesPerSec=3.284531479177157, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:44:59,865] [INFO] [logging.py:96:log_dist] [Rank 0] step=370, skipped=0, lr=[9.250000000000001e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:44:59,866] [INFO] [timer.py:260:stop] epoch=0/micro_step=1480/global_step=370, RunningAvgSamplesPerSec=3.286595823781658, CurrSamplesPerSec=3.286119228750284, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 12.153675366051589
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 8096.46875, loss: 8.999183654785156
[2024-05-07 17:46:05,857] [INFO] [logging.py:96:log_dist] [Rank 0] step=380, skipped=0, lr=[9.5e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:46:05,858] [INFO] [timer.py:260:stop] epoch=0/micro_step=1520/global_step=380, RunningAvgSamplesPerSec=3.286563401620455, CurrSamplesPerSec=3.2853332038303003, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:46:30,334] [INFO] [logging.py:96:log_dist] [Rank 0] step=390, skipped=0, lr=[9.75e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:46:30,335] [INFO] [timer.py:260:stop] epoch=0/micro_step=1560/global_step=390, RunningAvgSamplesPerSec=3.2864981266535778, CurrSamplesPerSec=3.2806409770188947, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:46:54,795] [INFO] [logging.py:96:log_dist] [Rank 0] step=400, skipped=0, lr=[1e-05], mom=[(0.9, 0.95)]
[2024-05-07 17:46:54,795] [INFO] [timer.py:260:stop] epoch=0/micro_step=1600/global_step=400, RunningAvgSamplesPerSec=3.2864823253580138, CurrSamplesPerSec=3.2867555955377727, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 11.945984846796563
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 5357.2626953125, loss: 8.586204528808594
[2024-05-07 17:48:00,760] [INFO] [logging.py:96:log_dist] [Rank 0] step=410, skipped=0, lr=[9.99999995942546e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:48:00,761] [INFO] [timer.py:260:stop] epoch=0/micro_step=1640/global_step=410, RunningAvgSamplesPerSec=3.286462847536116, CurrSamplesPerSec=3.289865004911105, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:48:25,216] [INFO] [logging.py:96:log_dist] [Rank 0] step=420, skipped=0, lr=[9.999999837701839e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:48:25,217] [INFO] [timer.py:260:stop] epoch=0/micro_step=1680/global_step=420, RunningAvgSamplesPerSec=3.2864568916937515, CurrSamplesPerSec=3.2861784452033813, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 11.735470830518173
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 3641.7744140625, loss: 8.200212478637695
[2024-05-07 17:49:31,201] [INFO] [logging.py:96:log_dist] [Rank 0] step=430, skipped=0, lr=[9.99999963482914e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:49:31,202] [INFO] [timer.py:260:stop] epoch=0/micro_step=1720/global_step=430, RunningAvgSamplesPerSec=3.286408326955403, CurrSamplesPerSec=3.283430027605547, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:49:55,651] [INFO] [logging.py:96:log_dist] [Rank 0] step=440, skipped=0, lr=[9.999999350807368e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:49:55,652] [INFO] [timer.py:260:stop] epoch=0/micro_step=1760/global_step=440, RunningAvgSamplesPerSec=3.2864082730444197, CurrSamplesPerSec=3.279730618668048, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:50:20,117] [INFO] [logging.py:96:log_dist] [Rank 0] step=450, skipped=0, lr=[9.999998985636525e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:50:20,118] [INFO] [timer.py:260:stop] epoch=0/micro_step=1800/global_step=450, RunningAvgSamplesPerSec=3.286380364842304, CurrSamplesPerSec=3.285306505535916, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 11.529516906224643
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 2558.208984375, loss: 7.847044467926025
[2024-05-07 17:51:26,098] [INFO] [logging.py:96:log_dist] [Rank 0] step=460, skipped=0, lr=[9.999998539316615e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:51:26,099] [INFO] [timer.py:260:stop] epoch=0/micro_step=1840/global_step=460, RunningAvgSamplesPerSec=3.286351277230012, CurrSamplesPerSec=3.286863129489514, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:51:50,558] [INFO] [logging.py:96:log_dist] [Rank 0] step=470, skipped=0, lr=[9.999998011847652e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:51:50,558] [INFO] [timer.py:260:stop] epoch=0/micro_step=1880/global_step=470, RunningAvgSamplesPerSec=3.286347050353205, CurrSamplesPerSec=3.2901169410993893, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 1/500 with loss 11.328382197459831
evaluating model ...
***** Evaluating perplexity, Epoch 1/500 *****
ppl: 1841.23388671875, loss: 7.518171310424805
[2024-05-07 17:52:56,509] [INFO] [logging.py:96:log_dist] [Rank 0] step=480, skipped=0, lr=[9.999997403229637e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:52:56,510] [INFO] [timer.py:260:stop] epoch=0/micro_step=1920/global_step=480, RunningAvgSamplesPerSec=3.286317103754861, CurrSamplesPerSec=3.2878383392838124, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:53:20,947] [INFO] [logging.py:96:log_dist] [Rank 0] step=490, skipped=0, lr=[9.999996713462585e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:53:20,947] [INFO] [timer.py:260:stop] epoch=0/micro_step=1960/global_step=490, RunningAvgSamplesPerSec=3.2863668695735786, CurrSamplesPerSec=3.2925515150016507, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
4
4
Beginning of Epoch 2/500
[2024-05-07 17:53:45,385] [INFO] [logging.py:96:log_dist] [Rank 0] step=500, skipped=0, lr=[9.999995942546506e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:53:45,386] [INFO] [timer.py:260:stop] epoch=1/micro_step=27/global_step=500, RunningAvgSamplesPerSec=3.286382915797088, CurrSamplesPerSec=3.285587985286035, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 7.232665357918575
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 1321.56103515625, loss: 7.186550617218018
saving model ... to step 2000
/home/chanho/anaconda3/envs/COMEDY/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/home/chanho/anaconda3/envs/COMEDY/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[2024-05-07 17:54:59,592] [INFO] [logging.py:96:log_dist] [Rank 0] step=510, skipped=0, lr=[9.999995090481412e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:54:59,593] [INFO] [timer.py:260:stop] epoch=1/micro_step=67/global_step=510, RunningAvgSamplesPerSec=3.2866603208800655, CurrSamplesPerSec=3.297093870357509, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:55:23,926] [INFO] [logging.py:96:log_dist] [Rank 0] step=520, skipped=0, lr=[9.999994157267316e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:55:23,927] [INFO] [timer.py:260:stop] epoch=1/micro_step=107/global_step=520, RunningAvgSamplesPerSec=3.2868839251793864, CurrSamplesPerSec=3.2893689872787344, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 7.105048711909804
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 948.697509765625, loss: 6.855072021484375
[2024-05-07 17:56:29,767] [INFO] [logging.py:96:log_dist] [Rank 0] step=530, skipped=0, lr=[9.999993142904235e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:56:29,767] [INFO] [timer.py:260:stop] epoch=1/micro_step=147/global_step=530, RunningAvgSamplesPerSec=3.286934843433624, CurrSamplesPerSec=3.285558065718932, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:56:54,201] [INFO] [logging.py:96:log_dist] [Rank 0] step=540, skipped=0, lr=[9.999992047392183e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:56:54,201] [INFO] [timer.py:260:stop] epoch=1/micro_step=187/global_step=540, RunningAvgSamplesPerSec=3.286910755780062, CurrSamplesPerSec=3.2895147454712648, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:57:18,624] [INFO] [logging.py:96:log_dist] [Rank 0] step=550, skipped=0, lr=[9.99999087073118e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:57:18,624] [INFO] [timer.py:260:stop] epoch=1/micro_step=227/global_step=550, RunningAvgSamplesPerSec=3.2868978507484066, CurrSamplesPerSec=3.2818689491503674, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 6.942822225229189
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 676.4822387695312, loss: 6.516889572143555
[2024-05-07 17:58:24,517] [INFO] [logging.py:96:log_dist] [Rank 0] step=560, skipped=0, lr=[9.999989612921246e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:58:24,517] [INFO] [timer.py:260:stop] epoch=1/micro_step=267/global_step=560, RunningAvgSamplesPerSec=3.286884512258854, CurrSamplesPerSec=3.284875854456635, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 17:58:48,922] [INFO] [logging.py:96:log_dist] [Rank 0] step=570, skipped=0, lr=[9.999988273962398e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:58:48,923] [INFO] [timer.py:260:stop] epoch=1/micro_step=307/global_step=570, RunningAvgSamplesPerSec=3.2869175266231627, CurrSamplesPerSec=3.290032743022865, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 6.776322183637996
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 492.20367431640625, loss: 6.198877334594727
[2024-05-07 17:59:54,798] [INFO] [logging.py:96:log_dist] [Rank 0] step=580, skipped=0, lr=[9.99998685385466e-06], mom=[(0.9, 0.95)]
[2024-05-07 17:59:54,798] [INFO] [timer.py:260:stop] epoch=1/micro_step=347/global_step=580, RunningAvgSamplesPerSec=3.2869018062681756, CurrSamplesPerSec=3.286163962721509, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:00:19,233] [INFO] [logging.py:96:log_dist] [Rank 0] step=590, skipped=0, lr=[9.999985352598054e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:00:19,234] [INFO] [timer.py:260:stop] epoch=1/micro_step=387/global_step=590, RunningAvgSamplesPerSec=3.286884220750093, CurrSamplesPerSec=3.2829722443014933, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:00:43,670] [INFO] [logging.py:96:log_dist] [Rank 0] step=600, skipped=0, lr=[9.999983770192606e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:00:43,671] [INFO] [timer.py:260:stop] epoch=1/micro_step=427/global_step=600, RunningAvgSamplesPerSec=3.286863346468282, CurrSamplesPerSec=3.289821460313277, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 6.600560593438315
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 377.0684814453125, loss: 5.9324116706848145
[2024-05-07 18:01:49,525] [INFO] [logging.py:96:log_dist] [Rank 0] step=610, skipped=0, lr=[9.999982106638341e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:01:49,526] [INFO] [timer.py:260:stop] epoch=1/micro_step=467/global_step=610, RunningAvgSamplesPerSec=3.286884306466799, CurrSamplesPerSec=3.280127856279188, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:02:13,949] [INFO] [logging.py:96:log_dist] [Rank 0] step=620, skipped=0, lr=[9.999980361935284e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:02:13,950] [INFO] [timer.py:260:stop] epoch=1/micro_step=507/global_step=620, RunningAvgSamplesPerSec=3.2868911321284915, CurrSamplesPerSec=3.2850414761251616, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 6.45777193179428
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 307.0667724609375, loss: 5.727046012878418
[2024-05-07 18:03:19,792] [INFO] [logging.py:96:log_dist] [Rank 0] step=630, skipped=0, lr=[9.999978536083465e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:03:19,792] [INFO] [timer.py:260:stop] epoch=1/micro_step=547/global_step=630, RunningAvgSamplesPerSec=3.2868972005670014, CurrSamplesPerSec=3.2826809357193136, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:03:44,202] [INFO] [logging.py:96:log_dist] [Rank 0] step=640, skipped=0, lr=[9.999976629082917e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:03:44,202] [INFO] [timer.py:260:stop] epoch=1/micro_step=587/global_step=640, RunningAvgSamplesPerSec=3.2869293730622835, CurrSamplesPerSec=3.2867475468723306, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:04:08,612] [INFO] [logging.py:96:log_dist] [Rank 0] step=650, skipped=0, lr=[9.999974640933663e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:04:08,613] [INFO] [timer.py:260:stop] epoch=1/micro_step=627/global_step=650, RunningAvgSamplesPerSec=3.2869588697029744, CurrSamplesPerSec=3.289447669300361, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 6.336138916697904
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 263.3155517578125, loss: 5.573334217071533
[2024-05-07 18:05:14,416] [INFO] [logging.py:96:log_dist] [Rank 0] step=660, skipped=0, lr=[9.999972571635744e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:05:14,417] [INFO] [timer.py:260:stop] epoch=1/micro_step=667/global_step=660, RunningAvgSamplesPerSec=3.2870065164280056, CurrSamplesPerSec=3.289332549748872, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:05:38,831] [INFO] [logging.py:96:log_dist] [Rank 0] step=670, skipped=0, lr=[9.999970421189185e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:05:38,831] [INFO] [timer.py:260:stop] epoch=1/micro_step=707/global_step=670, RunningAvgSamplesPerSec=3.2870232626232405, CurrSamplesPerSec=3.288703887655856, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 6.223154591598301
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 234.99603271484375, loss: 5.459551811218262
[2024-05-07 18:06:44,700] [INFO] [logging.py:96:log_dist] [Rank 0] step=680, skipped=0, lr=[9.999968189594029e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:06:44,701] [INFO] [timer.py:260:stop] epoch=1/micro_step=747/global_step=680, RunningAvgSamplesPerSec=3.287019805961688, CurrSamplesPerSec=3.2942679846710616, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:07:09,103] [INFO] [logging.py:96:log_dist] [Rank 0] step=690, skipped=0, lr=[9.999965876850306e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:07:09,103] [INFO] [timer.py:260:stop] epoch=1/micro_step=787/global_step=690, RunningAvgSamplesPerSec=3.287048243239727, CurrSamplesPerSec=3.2904847533389106, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:07:33,506] [INFO] [logging.py:96:log_dist] [Rank 0] step=700, skipped=0, lr=[9.999963482958057e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:07:33,507] [INFO] [timer.py:260:stop] epoch=1/micro_step=827/global_step=700, RunningAvgSamplesPerSec=3.287071928698156, CurrSamplesPerSec=3.2867646100898673, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 6.129458284493091
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 215.28652954101562, loss: 5.371954917907715
[2024-05-07 18:08:39,407] [INFO] [logging.py:96:log_dist] [Rank 0] step=710, skipped=0, lr=[9.999961007917321e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:08:39,408] [INFO] [timer.py:260:stop] epoch=1/micro_step=867/global_step=710, RunningAvgSamplesPerSec=3.287055563303031, CurrSamplesPerSec=3.2861308144101358, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:09:03,829] [INFO] [logging.py:96:log_dist] [Rank 0] step=720, skipped=0, lr=[9.999958451728135e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:09:03,830] [INFO] [timer.py:260:stop] epoch=1/micro_step=907/global_step=720, RunningAvgSamplesPerSec=3.2870585661072247, CurrSamplesPerSec=3.289966290878928, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 6.041481898854957
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 200.03993225097656, loss: 5.2985029220581055
[2024-05-07 18:10:09,795] [INFO] [logging.py:96:log_dist] [Rank 0] step=730, skipped=0, lr=[9.999955814390543e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:10:09,796] [INFO] [timer.py:260:stop] epoch=1/micro_step=947/global_step=730, RunningAvgSamplesPerSec=3.2870449526670775, CurrSamplesPerSec=3.2884189733275355, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:10:34,204] [INFO] [logging.py:96:log_dist] [Rank 0] step=740, skipped=0, lr=[9.99995309590459e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:10:34,205] [INFO] [timer.py:260:stop] epoch=1/micro_step=987/global_step=740, RunningAvgSamplesPerSec=3.2870685411970193, CurrSamplesPerSec=3.2876057565378707, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:10:58,671] [INFO] [logging.py:96:log_dist] [Rank 0] step=750, skipped=0, lr=[9.999950296270315e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:10:58,672] [INFO] [timer.py:260:stop] epoch=1/micro_step=1027/global_step=750, RunningAvgSamplesPerSec=3.2870316550511323, CurrSamplesPerSec=3.2800044105589095, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 5.96467465399769
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 187.55099487304688, loss: 5.23403787612915
[2024-05-07 18:12:04,676] [INFO] [logging.py:96:log_dist] [Rank 0] step=760, skipped=0, lr=[9.999947415487766e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:12:04,677] [INFO] [timer.py:260:stop] epoch=1/micro_step=1067/global_step=760, RunningAvgSamplesPerSec=3.287024381165199, CurrSamplesPerSec=3.2897611448856705, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:12:29,138] [INFO] [logging.py:96:log_dist] [Rank 0] step=770, skipped=0, lr=[9.99994445355699e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:12:29,139] [INFO] [timer.py:260:stop] epoch=1/micro_step=1107/global_step=770, RunningAvgSamplesPerSec=3.287005846534801, CurrSamplesPerSec=3.2847022108363233, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 5.897241714045049
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 176.72500610351562, loss: 5.174581527709961
[2024-05-07 18:13:35,190] [INFO] [logging.py:96:log_dist] [Rank 0] step=780, skipped=0, lr=[9.999941410478034e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:13:35,191] [INFO] [timer.py:260:stop] epoch=1/micro_step=1147/global_step=780, RunningAvgSamplesPerSec=3.28697529049633, CurrSamplesPerSec=3.2813564069091643, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:13:59,645] [INFO] [logging.py:96:log_dist] [Rank 0] step=790, skipped=0, lr=[9.99993828625095e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:13:59,646] [INFO] [timer.py:260:stop] epoch=1/micro_step=1187/global_step=790, RunningAvgSamplesPerSec=3.286972705387725, CurrSamplesPerSec=3.2873815804955777, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:14:24,078] [INFO] [logging.py:96:log_dist] [Rank 0] step=800, skipped=0, lr=[9.999935080875785e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:14:24,079] [INFO] [timer.py:260:stop] epoch=1/micro_step=1227/global_step=800, RunningAvgSamplesPerSec=3.286997037920774, CurrSamplesPerSec=3.2870437637293097, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 5.838573448826764
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 166.89305114746094, loss: 5.117339611053467
[2024-05-07 18:15:30,111] [INFO] [logging.py:96:log_dist] [Rank 0] step=810, skipped=0, lr=[9.999931794352592e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:15:30,112] [INFO] [timer.py:260:stop] epoch=1/micro_step=1267/global_step=810, RunningAvgSamplesPerSec=3.2869691976155457, CurrSamplesPerSec=3.284144745979265, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:15:54,564] [INFO] [logging.py:96:log_dist] [Rank 0] step=820, skipped=0, lr=[9.99992842668143e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:15:54,565] [INFO] [timer.py:260:stop] epoch=1/micro_step=1307/global_step=820, RunningAvgSamplesPerSec=3.286960802197278, CurrSamplesPerSec=3.285147289778589, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 5.783810308770724
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 158.30657958984375, loss: 5.064520835876465
[2024-05-07 18:17:00,621] [INFO] [logging.py:96:log_dist] [Rank 0] step=830, skipped=0, lr=[9.999924977862342e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:17:00,622] [INFO] [timer.py:260:stop] epoch=1/micro_step=1347/global_step=830, RunningAvgSamplesPerSec=3.2869567507112194, CurrSamplesPerSec=3.284096531267859, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:17:25,085] [INFO] [logging.py:96:log_dist] [Rank 0] step=840, skipped=0, lr=[9.999921447895396e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:17:25,086] [INFO] [timer.py:260:stop] epoch=1/micro_step=1387/global_step=840, RunningAvgSamplesPerSec=3.2869254799823073, CurrSamplesPerSec=3.285675173368689, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:17:49,535] [INFO] [logging.py:96:log_dist] [Rank 0] step=850, skipped=0, lr=[9.999917836780642e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:17:49,535] [INFO] [timer.py:260:stop] epoch=1/micro_step=1427/global_step=850, RunningAvgSamplesPerSec=3.286930212686217, CurrSamplesPerSec=3.2890181886617866, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 5.7318683574882066
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 151.4853057861328, loss: 5.020476341247559
[2024-05-07 18:18:55,626] [INFO] [logging.py:96:log_dist] [Rank 0] step=860, skipped=0, lr=[9.999914144518141e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:18:55,627] [INFO] [timer.py:260:stop] epoch=1/micro_step=1467/global_step=860, RunningAvgSamplesPerSec=3.2868964175391455, CurrSamplesPerSec=3.283743964042713, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:19:20,062] [INFO] [logging.py:96:log_dist] [Rank 0] step=870, skipped=0, lr=[9.999910371107955e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:19:20,063] [INFO] [timer.py:260:stop] epoch=1/micro_step=1507/global_step=870, RunningAvgSamplesPerSec=3.2869094772821748, CurrSamplesPerSec=3.2904011817599153, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 5.685991414471184
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 145.00811767578125, loss: 4.976778984069824
[2024-05-07 18:20:26,127] [INFO] [logging.py:96:log_dist] [Rank 0] step=880, skipped=0, lr=[9.99990651655014e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:20:26,129] [INFO] [timer.py:260:stop] epoch=1/micro_step=1547/global_step=880, RunningAvgSamplesPerSec=3.2869028153332707, CurrSamplesPerSec=3.283802773551371, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:20:50,575] [INFO] [logging.py:96:log_dist] [Rank 0] step=890, skipped=0, lr=[9.999902580844762e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:20:50,575] [INFO] [timer.py:260:stop] epoch=1/micro_step=1587/global_step=890, RunningAvgSamplesPerSec=3.2869093761253243, CurrSamplesPerSec=3.2889475865891002, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:21:14,992] [INFO] [logging.py:96:log_dist] [Rank 0] step=900, skipped=0, lr=[9.999898563991885e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:21:14,993] [INFO] [timer.py:260:stop] epoch=1/micro_step=1627/global_step=900, RunningAvgSamplesPerSec=3.2869472213444886, CurrSamplesPerSec=3.289536674812791, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 5.64271244496345
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 139.6693572998047, loss: 4.939267158508301
[2024-05-07 18:22:21,004] [INFO] [logging.py:96:log_dist] [Rank 0] step=910, skipped=0, lr=[9.999894465991574e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:22:21,005] [INFO] [timer.py:260:stop] epoch=1/micro_step=1667/global_step=910, RunningAvgSamplesPerSec=3.286965395957277, CurrSamplesPerSec=3.29088589146709, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:22:45,438] [INFO] [logging.py:96:log_dist] [Rank 0] step=920, skipped=0, lr=[9.999890286843894e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:22:45,439] [INFO] [timer.py:260:stop] epoch=1/micro_step=1707/global_step=920, RunningAvgSamplesPerSec=3.286991139740143, CurrSamplesPerSec=3.287666959333257, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 5.600307251967193
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 135.07110595703125, loss: 4.905790328979492
[2024-05-07 18:23:51,458] [INFO] [logging.py:96:log_dist] [Rank 0] step=930, skipped=0, lr=[9.999886026548913e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:23:51,459] [INFO] [timer.py:260:stop] epoch=1/micro_step=1747/global_step=930, RunningAvgSamplesPerSec=3.2869814356506173, CurrSamplesPerSec=3.29102210058546, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:24:15,915] [INFO] [logging.py:96:log_dist] [Rank 0] step=940, skipped=0, lr=[9.999881685106703e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:24:15,915] [INFO] [timer.py:260:stop] epoch=1/micro_step=1787/global_step=940, RunningAvgSamplesPerSec=3.286982209277999, CurrSamplesPerSec=3.287243740293258, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:24:40,329] [INFO] [logging.py:96:log_dist] [Rank 0] step=950, skipped=0, lr=[9.999877262517331e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:24:40,329] [INFO] [timer.py:260:stop] epoch=1/micro_step=1827/global_step=950, RunningAvgSamplesPerSec=3.2870229453603925, CurrSamplesPerSec=3.2933329171817034, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 5.560527568700341
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 130.65765380859375, loss: 4.872570037841797
[2024-05-07 18:25:46,328] [INFO] [logging.py:96:log_dist] [Rank 0] step=960, skipped=0, lr=[9.999872758780871e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:25:46,328] [INFO] [timer.py:260:stop] epoch=1/micro_step=1867/global_step=960, RunningAvgSamplesPerSec=3.287041798431337, CurrSamplesPerSec=3.292351215193013, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:26:10,761] [INFO] [logging.py:96:log_dist] [Rank 0] step=970, skipped=0, lr=[9.999868173897395e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:26:10,761] [INFO] [timer.py:260:stop] epoch=1/micro_step=1907/global_step=970, RunningAvgSamplesPerSec=3.287059770526115, CurrSamplesPerSec=3.2860390968395614, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 2/500 with loss 5.524198033761459
evaluating model ...
***** Evaluating perplexity, Epoch 2/500 *****
ppl: 126.9630126953125, loss: 4.843884468078613
[2024-05-07 18:27:16,772] [INFO] [logging.py:96:log_dist] [Rank 0] step=980, skipped=0, lr=[9.999863507866978e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:27:16,773] [INFO] [timer.py:260:stop] epoch=1/micro_step=1947/global_step=980, RunningAvgSamplesPerSec=3.2870608415464, CurrSamplesPerSec=3.290017581375018, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
4
4
Beginning of Epoch 3/500
[2024-05-07 18:27:41,202] [INFO] [logging.py:96:log_dist] [Rank 0] step=990, skipped=0, lr=[9.999858760689696e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:27:41,202] [INFO] [timer.py:260:stop] epoch=2/micro_step=14/global_step=990, RunningAvgSamplesPerSec=3.287077276916294, CurrSamplesPerSec=3.291155415687665, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:28:05,618] [INFO] [logging.py:96:log_dist] [Rank 0] step=1000, skipped=0, lr=[9.999853932365623e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:28:05,619] [INFO] [timer.py:260:stop] epoch=2/micro_step=54/global_step=1000, RunningAvgSamplesPerSec=3.287084823606446, CurrSamplesPerSec=3.286195502512408, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.8458117518508645
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 123.81098937988281, loss: 4.81874418258667
saving model ... to step 4000
[2024-05-07 18:29:19,689] [INFO] [logging.py:96:log_dist] [Rank 0] step=1010, skipped=0, lr=[9.999849022894843e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:29:19,690] [INFO] [timer.py:260:stop] epoch=2/micro_step=94/global_step=1010, RunningAvgSamplesPerSec=3.287247351779929, CurrSamplesPerSec=3.2953424154920152, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:29:44,032] [INFO] [logging.py:96:log_dist] [Rank 0] step=1020, skipped=0, lr=[9.99984403227743e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:29:44,033] [INFO] [timer.py:260:stop] epoch=2/micro_step=134/global_step=1020, RunningAvgSamplesPerSec=3.287352239479705, CurrSamplesPerSec=3.2977383844277677, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.8422333298215445
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 120.78695678710938, loss: 4.7940168380737305
[2024-05-07 18:30:49,996] [INFO] [logging.py:96:log_dist] [Rank 0] step=1030, skipped=0, lr=[9.99983896051347e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:30:49,997] [INFO] [timer.py:260:stop] epoch=2/micro_step=174/global_step=1030, RunningAvgSamplesPerSec=3.287372686310786, CurrSamplesPerSec=3.2896614841325436, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:31:14,406] [INFO] [logging.py:96:log_dist] [Rank 0] step=1040, skipped=0, lr=[9.99983380760304e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:31:14,407] [INFO] [timer.py:260:stop] epoch=2/micro_step=214/global_step=1040, RunningAvgSamplesPerSec=3.287384333297016, CurrSamplesPerSec=3.2935026254729918, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:31:38,824] [INFO] [logging.py:96:log_dist] [Rank 0] step=1050, skipped=0, lr=[9.999828573546231e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:31:38,825] [INFO] [timer.py:260:stop] epoch=2/micro_step=254/global_step=1050, RunningAvgSamplesPerSec=3.2873881617398233, CurrSamplesPerSec=3.2868756863079303, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.81593603753858
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 117.9515609741211, loss: 4.770262241363525
[2024-05-07 18:32:44,874] [INFO] [logging.py:96:log_dist] [Rank 0] step=1060, skipped=0, lr=[9.99982325834312e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:32:44,874] [INFO] [timer.py:260:stop] epoch=2/micro_step=294/global_step=1060, RunningAvgSamplesPerSec=3.287369528483595, CurrSamplesPerSec=3.286230905039688, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:33:09,307] [INFO] [logging.py:96:log_dist] [Rank 0] step=1070, skipped=0, lr=[9.999817861993797e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:33:09,308] [INFO] [timer.py:260:stop] epoch=2/micro_step=334/global_step=1070, RunningAvgSamplesPerSec=3.2873543537391425, CurrSamplesPerSec=3.281082710107744, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.807468420317193
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 115.43911743164062, loss: 4.748732566833496
[2024-05-07 18:34:15,322] [INFO] [logging.py:96:log_dist] [Rank 0] step=1080, skipped=0, lr=[9.99981238449835e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:34:15,323] [INFO] [timer.py:260:stop] epoch=2/micro_step=374/global_step=1080, RunningAvgSamplesPerSec=3.2873449402071513, CurrSamplesPerSec=3.2840071770791504, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:34:39,730] [INFO] [logging.py:96:log_dist] [Rank 0] step=1090, skipped=0, lr=[9.999806825856866e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:34:39,730] [INFO] [timer.py:260:stop] epoch=2/micro_step=414/global_step=1090, RunningAvgSamplesPerSec=3.2873547201319244, CurrSamplesPerSec=3.2907593755620765, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:35:04,158] [INFO] [logging.py:96:log_dist] [Rank 0] step=1100, skipped=0, lr=[9.999801186069438e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:35:04,158] [INFO] [timer.py:260:stop] epoch=2/micro_step=454/global_step=1100, RunningAvgSamplesPerSec=3.2873436007208365, CurrSamplesPerSec=3.2845610585324465, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.787500473289573
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 113.3313217163086, loss: 4.730302810668945
[2024-05-07 18:36:10,239] [INFO] [logging.py:96:log_dist] [Rank 0] step=1110, skipped=0, lr=[9.999795465136156e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:36:10,240] [INFO] [timer.py:260:stop] epoch=2/micro_step=494/global_step=1110, RunningAvgSamplesPerSec=3.2873356326708474, CurrSamplesPerSec=3.2853219454604807, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:36:34,667] [INFO] [logging.py:96:log_dist] [Rank 0] step=1120, skipped=0, lr=[9.999789663057112e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:36:34,668] [INFO] [timer.py:260:stop] epoch=2/micro_step=534/global_step=1120, RunningAvgSamplesPerSec=3.2873256124144374, CurrSamplesPerSec=3.283779956497375, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.780033838813138
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 111.39685821533203, loss: 4.713086128234863
[2024-05-07 18:37:40,721] [INFO] [logging.py:96:log_dist] [Rank 0] step=1130, skipped=0, lr=[9.9997837798324e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:37:40,722] [INFO] [timer.py:260:stop] epoch=2/micro_step=574/global_step=1130, RunningAvgSamplesPerSec=3.287307207980143, CurrSamplesPerSec=3.283513245440091, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:38:05,113] [INFO] [logging.py:96:log_dist] [Rank 0] step=1140, skipped=0, lr=[9.999777815462118e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:38:05,114] [INFO] [timer.py:260:stop] epoch=2/micro_step=614/global_step=1140, RunningAvgSamplesPerSec=3.2873389670480986, CurrSamplesPerSec=3.2911305595104934, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:38:29,533] [INFO] [logging.py:96:log_dist] [Rank 0] step=1150, skipped=0, lr=[9.99977176994636e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:38:29,534] [INFO] [timer.py:260:stop] epoch=2/micro_step=654/global_step=1150, RunningAvgSamplesPerSec=3.2873370683799608, CurrSamplesPerSec=3.2809964072212283, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.77385088951076
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 109.30582427978516, loss: 4.6941375732421875
[2024-05-07 18:39:35,524] [INFO] [logging.py:96:log_dist] [Rank 0] step=1160, skipped=0, lr=[9.999765643285226e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:39:35,524] [INFO] [timer.py:260:stop] epoch=2/micro_step=694/global_step=1160, RunningAvgSamplesPerSec=3.2873346768626965, CurrSamplesPerSec=3.2876125209453515, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:39:59,935] [INFO] [logging.py:96:log_dist] [Rank 0] step=1170, skipped=0, lr=[9.999759435478817e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:39:59,936] [INFO] [timer.py:260:stop] epoch=2/micro_step=734/global_step=1170, RunningAvgSamplesPerSec=3.287341395302723, CurrSamplesPerSec=3.289900163983048, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.762073548655843
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 107.4749755859375, loss: 4.677246570587158
[2024-05-07 18:41:05,923] [INFO] [logging.py:96:log_dist] [Rank 0] step=1180, skipped=0, lr=[9.999753146527228e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:41:05,924] [INFO] [timer.py:260:stop] epoch=2/micro_step=774/global_step=1180, RunningAvgSamplesPerSec=3.287343205394635, CurrSamplesPerSec=3.2905809143076254, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:41:30,317] [INFO] [logging.py:96:log_dist] [Rank 0] step=1190, skipped=0, lr=[9.999746776430567e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:41:30,318] [INFO] [timer.py:260:stop] epoch=2/micro_step=814/global_step=1190, RunningAvgSamplesPerSec=3.287372975988321, CurrSamplesPerSec=3.2927692879274466, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:41:54,746] [INFO] [logging.py:96:log_dist] [Rank 0] step=1200, skipped=0, lr=[9.999740325188933e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:41:54,747] [INFO] [timer.py:260:stop] epoch=2/micro_step=854/global_step=1200, RunningAvgSamplesPerSec=3.2873703583551084, CurrSamplesPerSec=3.2852360627216077, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.751270634707937
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 105.9395980834961, loss: 4.662858009338379
[2024-05-07 18:43:00,758] [INFO] [logging.py:96:log_dist] [Rank 0] step=1210, skipped=0, lr=[9.999733792802436e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:43:00,760] [INFO] [timer.py:260:stop] epoch=2/micro_step=894/global_step=1210, RunningAvgSamplesPerSec=3.287365944708801, CurrSamplesPerSec=3.282404128063568, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:43:25,200] [INFO] [logging.py:96:log_dist] [Rank 0] step=1220, skipped=0, lr=[9.999727179271175e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:43:25,201] [INFO] [timer.py:260:stop] epoch=2/micro_step=934/global_step=1220, RunningAvgSamplesPerSec=3.287350696436038, CurrSamplesPerSec=3.2863738102669995, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.740803206103972
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 104.37757110595703, loss: 4.648002624511719
[2024-05-07 18:44:31,199] [INFO] [logging.py:96:log_dist] [Rank 0] step=1230, skipped=0, lr=[9.999720484595264e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:44:31,200] [INFO] [timer.py:260:stop] epoch=2/micro_step=974/global_step=1230, RunningAvgSamplesPerSec=3.2873506117061098, CurrSamplesPerSec=3.2895466721096325, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:44:55,607] [INFO] [logging.py:96:log_dist] [Rank 0] step=1240, skipped=0, lr=[9.999713708774806e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:44:55,608] [INFO] [timer.py:260:stop] epoch=2/micro_step=1014/global_step=1240, RunningAvgSamplesPerSec=3.287369985234147, CurrSamplesPerSec=3.2847822775580817, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:45:20,016] [INFO] [logging.py:96:log_dist] [Rank 0] step=1250, skipped=0, lr=[9.999706851809915e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:45:20,017] [INFO] [timer.py:260:stop] epoch=2/micro_step=1054/global_step=1250, RunningAvgSamplesPerSec=3.2873997543277755, CurrSamplesPerSec=3.288987561819653, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.731834909435478
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 102.83104705810547, loss: 4.6330742835998535
[2024-05-07 18:46:26,046] [INFO] [logging.py:96:log_dist] [Rank 0] step=1260, skipped=0, lr=[9.9996999137007e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:46:26,046] [INFO] [timer.py:260:stop] epoch=2/micro_step=1094/global_step=1260, RunningAvgSamplesPerSec=3.287406018830513, CurrSamplesPerSec=3.2937218174898755, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:46:50,468] [INFO] [logging.py:96:log_dist] [Rank 0] step=1270, skipped=0, lr=[9.999692894447277e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:46:50,469] [INFO] [timer.py:260:stop] epoch=2/micro_step=1134/global_step=1270, RunningAvgSamplesPerSec=3.287422387125286, CurrSamplesPerSec=3.2903082577299774, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.722788939109216
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 101.45962524414062, loss: 4.6196489334106445
[2024-05-07 18:47:56,502] [INFO] [logging.py:96:log_dist] [Rank 0] step=1280, skipped=0, lr=[9.999685794049756e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:47:56,502] [INFO] [timer.py:260:stop] epoch=2/micro_step=1174/global_step=1280, RunningAvgSamplesPerSec=3.287421900733254, CurrSamplesPerSec=3.285621122646856, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:48:20,956] [INFO] [logging.py:96:log_dist] [Rank 0] step=1290, skipped=0, lr=[9.999678612508254e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:48:20,957] [INFO] [timer.py:260:stop] epoch=2/micro_step=1214/global_step=1290, RunningAvgSamplesPerSec=3.2874187735059506, CurrSamplesPerSec=3.2918735016228116, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:48:45,402] [INFO] [logging.py:96:log_dist] [Rank 0] step=1300, skipped=0, lr=[9.999671349822887e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:48:45,403] [INFO] [timer.py:260:stop] epoch=2/micro_step=1254/global_step=1300, RunningAvgSamplesPerSec=3.287426806402877, CurrSamplesPerSec=3.290839092358367, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.716780899817164
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 100.27716827392578, loss: 4.607928276062012
[2024-05-07 18:49:51,448] [INFO] [logging.py:96:log_dist] [Rank 0] step=1310, skipped=0, lr=[9.999664005993773e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:49:51,449] [INFO] [timer.py:260:stop] epoch=2/micro_step=1294/global_step=1310, RunningAvgSamplesPerSec=3.287422381220257, CurrSamplesPerSec=3.2901392010812587, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:50:15,922] [INFO] [logging.py:96:log_dist] [Rank 0] step=1320, skipped=0, lr=[9.999656581021032e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:50:15,923] [INFO] [timer.py:260:stop] epoch=2/micro_step=1334/global_step=1320, RunningAvgSamplesPerSec=3.287408107259259, CurrSamplesPerSec=3.2851247756644253, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.709567534018722
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 99.08966064453125, loss: 4.59601354598999
[2024-05-07 18:51:21,999] [INFO] [logging.py:96:log_dist] [Rank 0] step=1330, skipped=0, lr=[9.999649074904783e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:51:22,001] [INFO] [timer.py:260:stop] epoch=2/micro_step=1374/global_step=1330, RunningAvgSamplesPerSec=3.287392924530715, CurrSamplesPerSec=3.2855831595125484, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:51:46,442] [INFO] [logging.py:96:log_dist] [Rank 0] step=1340, skipped=0, lr=[9.99964148764515e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:51:46,443] [INFO] [timer.py:260:stop] epoch=2/micro_step=1414/global_step=1340, RunningAvgSamplesPerSec=3.2874022443800293, CurrSamplesPerSec=3.2904269949219382, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:52:10,859] [INFO] [logging.py:96:log_dist] [Rank 0] step=1350, skipped=0, lr=[9.999633819242254e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:52:10,859] [INFO] [timer.py:260:stop] epoch=2/micro_step=1454/global_step=1350, RunningAvgSamplesPerSec=3.2874219396179343, CurrSamplesPerSec=3.2875796655126224, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.701476616489617
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 97.89035034179688, loss: 4.583835601806641
[2024-05-07 18:53:16,904] [INFO] [logging.py:96:log_dist] [Rank 0] step=1360, skipped=0, lr=[9.99962606969622e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:53:16,904] [INFO] [timer.py:260:stop] epoch=2/micro_step=1494/global_step=1360, RunningAvgSamplesPerSec=3.287425937350042, CurrSamplesPerSec=3.287747170657298, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:53:41,335] [INFO] [logging.py:96:log_dist] [Rank 0] step=1370, skipped=0, lr=[9.999618239007174e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:53:41,336] [INFO] [timer.py:260:stop] epoch=2/micro_step=1534/global_step=1370, RunningAvgSamplesPerSec=3.2874314098198325, CurrSamplesPerSec=3.289921775895618, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.6936083345284585
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 96.87800598144531, loss: 4.5734405517578125
[2024-05-07 18:54:47,381] [INFO] [logging.py:96:log_dist] [Rank 0] step=1380, skipped=0, lr=[9.999610327175245e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:54:47,381] [INFO] [timer.py:260:stop] epoch=2/micro_step=1574/global_step=1380, RunningAvgSamplesPerSec=3.287438144495813, CurrSamplesPerSec=3.2877445935257916, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:55:11,837] [INFO] [logging.py:96:log_dist] [Rank 0] step=1390, skipped=0, lr=[9.999602334200556e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:55:11,838] [INFO] [timer.py:260:stop] epoch=2/micro_step=1614/global_step=1390, RunningAvgSamplesPerSec=3.2874333048779953, CurrSamplesPerSec=3.2817286821682683, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:55:36,290] [INFO] [logging.py:96:log_dist] [Rank 0] step=1400, skipped=0, lr=[9.999594260083244e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:55:36,291] [INFO] [timer.py:260:stop] epoch=2/micro_step=1654/global_step=1400, RunningAvgSamplesPerSec=3.287435879684724, CurrSamplesPerSec=3.2862177094630765, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.686729942090409
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 95.80594635009766, loss: 4.562313556671143
[2024-05-07 18:56:42,329] [INFO] [logging.py:96:log_dist] [Rank 0] step=1410, skipped=0, lr=[9.999586104823434e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:56:42,330] [INFO] [timer.py:260:stop] epoch=2/micro_step=1694/global_step=1410, RunningAvgSamplesPerSec=3.287442077252773, CurrSamplesPerSec=3.290541545714785, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:57:06,792] [INFO] [logging.py:96:log_dist] [Rank 0] step=1420, skipped=0, lr=[9.999577868421261e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:57:06,793] [INFO] [timer.py:260:stop] epoch=2/micro_step=1734/global_step=1420, RunningAvgSamplesPerSec=3.287441629486739, CurrSamplesPerSec=3.28603813141868, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.6793003268179465
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 94.88418579101562, loss: 4.552644729614258
[2024-05-07 18:58:12,887] [INFO] [logging.py:96:log_dist] [Rank 0] step=1430, skipped=0, lr=[9.99956955087686e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:58:12,888] [INFO] [timer.py:260:stop] epoch=2/micro_step=1774/global_step=1430, RunningAvgSamplesPerSec=3.2874342695647143, CurrSamplesPerSec=3.283447698993705, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:58:37,349] [INFO] [logging.py:96:log_dist] [Rank 0] step=1440, skipped=0, lr=[9.999561152190362e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:58:37,349] [INFO] [timer.py:260:stop] epoch=2/micro_step=1814/global_step=1440, RunningAvgSamplesPerSec=3.2874234633502053, CurrSamplesPerSec=3.284877783933323, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 18:59:01,777] [INFO] [logging.py:96:log_dist] [Rank 0] step=1450, skipped=0, lr=[9.999552672361906e-06], mom=[(0.9, 0.95)]
[2024-05-07 18:59:01,778] [INFO] [timer.py:260:stop] epoch=2/micro_step=1854/global_step=1450, RunningAvgSamplesPerSec=3.287435098822078, CurrSamplesPerSec=3.288174063819781, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.6713495158224765
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 93.87373352050781, loss: 4.541937828063965
[2024-05-07 19:00:07,810] [INFO] [logging.py:96:log_dist] [Rank 0] step=1460, skipped=0, lr=[9.999544111391631e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:00:07,811] [INFO] [timer.py:260:stop] epoch=2/micro_step=1894/global_step=1460, RunningAvgSamplesPerSec=3.2874371988258044, CurrSamplesPerSec=3.286670925551211, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:00:32,253] [INFO] [logging.py:96:log_dist] [Rank 0] step=1470, skipped=0, lr=[9.999535469279674e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:00:32,254] [INFO] [timer.py:260:stop] epoch=2/micro_step=1934/global_step=1470, RunningAvgSamplesPerSec=3.287438042012791, CurrSamplesPerSec=3.2877107690492773, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 3/500 with loss 4.664800972979959
evaluating model ...
***** Evaluating perplexity, Epoch 3/500 *****
ppl: 92.6923828125, loss: 4.529273986816406
4
4
Beginning of Epoch 4/500
[2024-05-07 19:01:38,273] [INFO] [logging.py:96:log_dist] [Rank 0] step=1480, skipped=0, lr=[9.999526746026173e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:01:38,274] [INFO] [timer.py:260:stop] epoch=3/micro_step=1/global_step=1480, RunningAvgSamplesPerSec=3.287436084455545, CurrSamplesPerSec=3.281164846439277, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:02:02,667] [INFO] [logging.py:96:log_dist] [Rank 0] step=1490, skipped=0, lr=[9.999517941631274e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:02:02,668] [INFO] [timer.py:260:stop] epoch=3/micro_step=41/global_step=1490, RunningAvgSamplesPerSec=3.287448508144779, CurrSamplesPerSec=3.2878132110304255, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:02:27,071] [INFO] [logging.py:96:log_dist] [Rank 0] step=1500, skipped=0, lr=[9.999509056095119e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:02:27,071] [INFO] [timer.py:260:stop] epoch=3/micro_step=81/global_step=1500, RunningAvgSamplesPerSec=3.2874601173694664, CurrSamplesPerSec=3.290080809596158, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.54726378216463
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 91.69683074951172, loss: 4.518476486206055
saving model ... to step 6000
[2024-05-07 19:03:41,155] [INFO] [logging.py:96:log_dist] [Rank 0] step=1510, skipped=0, lr=[9.999500089417848e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:03:41,156] [INFO] [timer.py:260:stop] epoch=3/micro_step=121/global_step=1510, RunningAvgSamplesPerSec=3.2875548716472935, CurrSamplesPerSec=3.295253742761588, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:04:05,513] [INFO] [logging.py:96:log_dist] [Rank 0] step=1520, skipped=0, lr=[9.999491041599611e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:04:05,514] [INFO] [timer.py:260:stop] epoch=3/micro_step=161/global_step=1520, RunningAvgSamplesPerSec=3.287614659257629, CurrSamplesPerSec=3.2962527195404836, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.5323978978234365
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 90.86607360839844, loss: 4.509374618530273
[2024-05-07 19:05:11,508] [INFO] [logging.py:96:log_dist] [Rank 0] step=1530, skipped=0, lr=[9.999481912640554e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:05:11,508] [INFO] [timer.py:260:stop] epoch=3/micro_step=201/global_step=1530, RunningAvgSamplesPerSec=3.287620620014971, CurrSamplesPerSec=3.2833085821199663, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:05:35,947] [INFO] [logging.py:96:log_dist] [Rank 0] step=1540, skipped=0, lr=[9.999472702540827e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:05:35,948] [INFO] [timer.py:260:stop] epoch=3/micro_step=241/global_step=1540, RunningAvgSamplesPerSec=3.287606004720637, CurrSamplesPerSec=3.2884582911468265, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:06:00,341] [INFO] [logging.py:96:log_dist] [Rank 0] step=1550, skipped=0, lr=[9.999463411300575e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:06:00,341] [INFO] [timer.py:260:stop] epoch=3/micro_step=281/global_step=1550, RunningAvgSamplesPerSec=3.287623427331316, CurrSamplesPerSec=3.288088676318815, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.528720585505168
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 90.01082611083984, loss: 4.499917984008789
[2024-05-07 19:07:06,338] [INFO] [logging.py:96:log_dist] [Rank 0] step=1560, skipped=0, lr=[9.99945403891995e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:07:06,339] [INFO] [timer.py:260:stop] epoch=3/micro_step=321/global_step=1560, RunningAvgSamplesPerSec=3.287611412976586, CurrSamplesPerSec=3.2904663607737996, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:07:30,744] [INFO] [logging.py:96:log_dist] [Rank 0] step=1570, skipped=0, lr=[9.999444585399105e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:07:30,745] [INFO] [timer.py:260:stop] epoch=3/micro_step=361/global_step=1570, RunningAvgSamplesPerSec=3.2876136910789153, CurrSamplesPerSec=3.286336795333019, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.5289743082863945
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 89.34051513671875, loss: 4.492443561553955
[2024-05-07 19:08:36,773] [INFO] [logging.py:96:log_dist] [Rank 0] step=1580, skipped=0, lr=[9.999435050738195e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:08:36,774] [INFO] [timer.py:260:stop] epoch=3/micro_step=401/global_step=1580, RunningAvgSamplesPerSec=3.287595137221387, CurrSamplesPerSec=3.285812238528448, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:09:01,174] [INFO] [logging.py:96:log_dist] [Rank 0] step=1590, skipped=0, lr=[9.999425434937372e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:09:01,174] [INFO] [timer.py:260:stop] epoch=3/micro_step=441/global_step=1590, RunningAvgSamplesPerSec=3.287600819154626, CurrSamplesPerSec=3.291798578739085, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:09:25,575] [INFO] [logging.py:96:log_dist] [Rank 0] step=1600, skipped=0, lr=[9.999415737996795e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:09:25,576] [INFO] [timer.py:260:stop] epoch=3/micro_step=481/global_step=1600, RunningAvgSamplesPerSec=3.2876073384851328, CurrSamplesPerSec=3.287832862580468, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.5132558011517085
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 88.625, loss: 4.484400749206543
[2024-05-07 19:10:31,556] [INFO] [logging.py:96:log_dist] [Rank 0] step=1610, skipped=0, lr=[9.99940595991662e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:10:31,557] [INFO] [timer.py:260:stop] epoch=3/micro_step=521/global_step=1610, RunningAvgSamplesPerSec=3.2876129163779932, CurrSamplesPerSec=3.286380891479819, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:10:55,946] [INFO] [logging.py:96:log_dist] [Rank 0] step=1620, skipped=0, lr=[9.999396100697003e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:10:55,947] [INFO] [timer.py:260:stop] epoch=3/micro_step=561/global_step=1620, RunningAvgSamplesPerSec=3.2876259479128027, CurrSamplesPerSec=3.2882633226652835, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.513900853018475
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 87.97445678710938, loss: 4.4770331382751465
[2024-05-07 19:12:01,897] [INFO] [logging.py:96:log_dist] [Rank 0] step=1630, skipped=0, lr=[9.999386160338107e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:12:01,898] [INFO] [timer.py:260:stop] epoch=3/micro_step=601/global_step=1630, RunningAvgSamplesPerSec=3.2876347409179076, CurrSamplesPerSec=3.2910463095471973, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:12:26,280] [INFO] [logging.py:96:log_dist] [Rank 0] step=1640, skipped=0, lr=[9.999376138840093e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:12:26,280] [INFO] [timer.py:260:stop] epoch=3/micro_step=641/global_step=1640, RunningAvgSamplesPerSec=3.287657879653727, CurrSamplesPerSec=3.2917840466781016, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:12:50,646] [INFO] [logging.py:96:log_dist] [Rank 0] step=1650, skipped=0, lr=[9.999366036203125e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:12:50,647] [INFO] [timer.py:260:stop] epoch=3/micro_step=681/global_step=1650, RunningAvgSamplesPerSec=3.2876921248356177, CurrSamplesPerSec=3.2934224563291465, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.510621773587526
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 87.40287017822266, loss: 4.470515251159668
[2024-05-07 19:13:56,579] [INFO] [logging.py:96:log_dist] [Rank 0] step=1660, skipped=0, lr=[9.999355852427364e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:13:56,579] [INFO] [timer.py:260:stop] epoch=3/micro_step=721/global_step=1660, RunningAvgSamplesPerSec=3.2877005987215466, CurrSamplesPerSec=3.28532258879382, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:14:20,966] [INFO] [logging.py:96:log_dist] [Rank 0] step=1670, skipped=0, lr=[9.999345587512976e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:14:20,967] [INFO] [timer.py:260:stop] epoch=3/micro_step=761/global_step=1670, RunningAvgSamplesPerSec=3.2877186592404803, CurrSamplesPerSec=3.290330197652613, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.505159611307132
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 86.81592559814453, loss: 4.463776588439941
[2024-05-07 19:15:26,917] [INFO] [logging.py:96:log_dist] [Rank 0] step=1680, skipped=0, lr=[9.99933524146013e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:15:26,918] [INFO] [timer.py:260:stop] epoch=3/micro_step=801/global_step=1680, RunningAvgSamplesPerSec=3.287721833775043, CurrSamplesPerSec=3.2885182365168224, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:15:51,314] [INFO] [logging.py:96:log_dist] [Rank 0] step=1690, skipped=0, lr=[9.999324814268991e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:15:51,314] [INFO] [timer.py:260:stop] epoch=3/micro_step=841/global_step=1690, RunningAvgSamplesPerSec=3.2877305235735275, CurrSamplesPerSec=3.283475009695002, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:16:15,707] [INFO] [logging.py:96:log_dist] [Rank 0] step=1700, skipped=0, lr=[9.99931430593973e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:16:15,708] [INFO] [timer.py:260:stop] epoch=3/micro_step=881/global_step=1700, RunningAvgSamplesPerSec=3.2877441651425747, CurrSamplesPerSec=3.2873039634456975, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.500223053646627
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 86.39448547363281, loss: 4.458911895751953
[2024-05-07 19:17:21,665] [INFO] [logging.py:96:log_dist] [Rank 0] step=1710, skipped=0, lr=[9.999303716472514e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:17:21,665] [INFO] [timer.py:260:stop] epoch=3/micro_step=921/global_step=1710, RunningAvgSamplesPerSec=3.2877518979236604, CurrSamplesPerSec=3.2885156581763604, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:17:46,055] [INFO] [logging.py:96:log_dist] [Rank 0] step=1720, skipped=0, lr=[9.999293045867522e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:17:46,055] [INFO] [timer.py:260:stop] epoch=3/micro_step=961/global_step=1720, RunningAvgSamplesPerSec=3.287766435330814, CurrSamplesPerSec=3.289311268025226, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.495352368669462
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 85.72471618652344, loss: 4.451128005981445
[2024-05-07 19:18:51,979] [INFO] [logging.py:96:log_dist] [Rank 0] step=1730, skipped=0, lr=[9.999282294124922e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:18:51,980] [INFO] [timer.py:260:stop] epoch=3/micro_step=1001/global_step=1730, RunningAvgSamplesPerSec=3.2877820514409155, CurrSamplesPerSec=3.2949751343249227, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:19:16,396] [INFO] [logging.py:96:log_dist] [Rank 0] step=1740, skipped=0, lr=[9.999271461244888e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:19:16,396] [INFO] [timer.py:260:stop] epoch=3/micro_step=1041/global_step=1740, RunningAvgSamplesPerSec=3.287802652622343, CurrSamplesPerSec=3.292382550813003, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:19:40,800] [INFO] [logging.py:96:log_dist] [Rank 0] step=1750, skipped=0, lr=[9.999260547227599e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:19:40,800] [INFO] [timer.py:260:stop] epoch=3/micro_step=1081/global_step=1750, RunningAvgSamplesPerSec=3.2878238744202064, CurrSamplesPerSec=3.292638749955597, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.4919302626139554
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 85.20073699951172, loss: 4.444999694824219
[2024-05-07 19:20:46,768] [INFO] [logging.py:96:log_dist] [Rank 0] step=1760, skipped=0, lr=[9.999249552073229e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:20:46,768] [INFO] [timer.py:260:stop] epoch=3/micro_step=1121/global_step=1760, RunningAvgSamplesPerSec=3.287841775839265, CurrSamplesPerSec=3.294879039903816, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:21:11,166] [INFO] [logging.py:96:log_dist] [Rank 0] step=1770, skipped=0, lr=[9.999238475781957e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:21:11,167] [INFO] [timer.py:260:stop] epoch=3/micro_step=1161/global_step=1770, RunningAvgSamplesPerSec=3.2878627599978096, CurrSamplesPerSec=3.294197157036659, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.489220774324634
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 84.6260986328125, loss: 4.438229560852051
[2024-05-07 19:22:17,117] [INFO] [logging.py:96:log_dist] [Rank 0] step=1780, skipped=0, lr=[9.999227318353965e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:22:17,118] [INFO] [timer.py:260:stop] epoch=3/micro_step=1201/global_step=1780, RunningAvgSamplesPerSec=3.2878723508426813, CurrSamplesPerSec=3.290220823591856, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:22:41,532] [INFO] [logging.py:96:log_dist] [Rank 0] step=1790, skipped=0, lr=[9.999216079789432e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:22:41,532] [INFO] [timer.py:260:stop] epoch=3/micro_step=1241/global_step=1790, RunningAvgSamplesPerSec=3.28788734376206, CurrSamplesPerSec=3.289846619273641, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:23:05,935] [INFO] [logging.py:96:log_dist] [Rank 0] step=1800, skipped=0, lr=[9.999204760088542e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:23:05,936] [INFO] [timer.py:260:stop] epoch=3/micro_step=1281/global_step=1800, RunningAvgSamplesPerSec=3.2879018650721923, CurrSamplesPerSec=3.290459907290912, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.486320679475361
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 84.025146484375, loss: 4.431105613708496
[2024-05-07 19:24:11,880] [INFO] [logging.py:96:log_dist] [Rank 0] step=1810, skipped=0, lr=[9.999193359251477e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:24:11,880] [INFO] [timer.py:260:stop] epoch=3/micro_step=1321/global_step=1810, RunningAvgSamplesPerSec=3.2879210734722677, CurrSamplesPerSec=3.2936665317963216, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:24:36,287] [INFO] [logging.py:96:log_dist] [Rank 0] step=1820, skipped=0, lr=[9.999181877278424e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:24:36,288] [INFO] [timer.py:260:stop] epoch=3/micro_step=1361/global_step=1820, RunningAvgSamplesPerSec=3.2879371725844027, CurrSamplesPerSec=3.2914259526487673, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.48151043416791
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 83.49980163574219, loss: 4.424831390380859
[2024-05-07 19:25:42,247] [INFO] [logging.py:96:log_dist] [Rank 0] step=1830, skipped=0, lr=[9.999170314169567e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:25:42,248] [INFO] [timer.py:260:stop] epoch=3/micro_step=1401/global_step=1830, RunningAvgSamplesPerSec=3.287956604997856, CurrSamplesPerSec=3.2901927553151413, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:26:06,661] [INFO] [logging.py:96:log_dist] [Rank 0] step=1840, skipped=0, lr=[9.999158669925096e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:26:06,661] [INFO] [timer.py:260:stop] epoch=3/micro_step=1441/global_step=1840, RunningAvgSamplesPerSec=3.2879724390237755, CurrSamplesPerSec=3.2922678718078786, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:26:31,059] [INFO] [logging.py:96:log_dist] [Rank 0] step=1850, skipped=0, lr=[9.999146944545198e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:26:31,060] [INFO] [timer.py:260:stop] epoch=3/micro_step=1481/global_step=1850, RunningAvgSamplesPerSec=3.2879929827957857, CurrSamplesPerSec=3.294796862589376, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.479341602485991
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 83.08550262451172, loss: 4.419857978820801
[2024-05-07 19:27:37,052] [INFO] [logging.py:96:log_dist] [Rank 0] step=1860, skipped=0, lr=[9.999135138030064e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:27:37,052] [INFO] [timer.py:260:stop] epoch=3/micro_step=1521/global_step=1860, RunningAvgSamplesPerSec=3.2880059547190785, CurrSamplesPerSec=3.289632457864198, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:28:01,475] [INFO] [logging.py:96:log_dist] [Rank 0] step=1870, skipped=0, lr=[9.999123250379887e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:28:01,476] [INFO] [timer.py:260:stop] epoch=3/micro_step=1561/global_step=1870, RunningAvgSamplesPerSec=3.288007842580526, CurrSamplesPerSec=3.290385694057103, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.475822415336825
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 82.67143249511719, loss: 4.414861679077148
[2024-05-07 19:29:07,474] [INFO] [logging.py:96:log_dist] [Rank 0] step=1880, skipped=0, lr=[9.999111281594857e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:29:07,474] [INFO] [timer.py:260:stop] epoch=3/micro_step=1601/global_step=1880, RunningAvgSamplesPerSec=3.2880139166977376, CurrSamplesPerSec=3.2877336407619637, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:29:31,893] [INFO] [logging.py:96:log_dist] [Rank 0] step=1890, skipped=0, lr=[9.99909923167517e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:29:31,894] [INFO] [timer.py:260:stop] epoch=3/micro_step=1641/global_step=1890, RunningAvgSamplesPerSec=3.288017496037148, CurrSamplesPerSec=3.288075788024636, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:29:56,296] [INFO] [logging.py:96:log_dist] [Rank 0] step=1900, skipped=0, lr=[9.999087100621024e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:29:56,297] [INFO] [timer.py:260:stop] epoch=3/micro_step=1681/global_step=1900, RunningAvgSamplesPerSec=3.288030923900081, CurrSamplesPerSec=3.2887902741508666, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.47131666415523
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 82.20823669433594, loss: 4.409244537353516
[2024-05-07 19:31:02,315] [INFO] [logging.py:96:log_dist] [Rank 0] step=1910, skipped=0, lr=[9.999074888432612e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:31:02,315] [INFO] [timer.py:260:stop] epoch=3/micro_step=1721/global_step=1910, RunningAvgSamplesPerSec=3.2880269284260026, CurrSamplesPerSec=3.2844736080663455, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:31:26,715] [INFO] [logging.py:96:log_dist] [Rank 0] step=1920, skipped=0, lr=[9.999062595110134e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:31:26,715] [INFO] [timer.py:260:stop] epoch=3/micro_step=1761/global_step=1920, RunningAvgSamplesPerSec=3.2880422784286543, CurrSamplesPerSec=3.287799358439592, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.468326002676614
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 81.80802154541016, loss: 4.404364109039307
[2024-05-07 19:32:32,718] [INFO] [logging.py:96:log_dist] [Rank 0] step=1930, skipped=0, lr=[9.999050220653789e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:32:32,719] [INFO] [timer.py:260:stop] epoch=3/micro_step=1801/global_step=1930, RunningAvgSamplesPerSec=3.288053233251589, CurrSamplesPerSec=3.2918990149349083, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:32:57,163] [INFO] [logging.py:96:log_dist] [Rank 0] step=1940, skipped=0, lr=[9.999037765063776e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:32:57,164] [INFO] [timer.py:260:stop] epoch=3/micro_step=1841/global_step=1940, RunningAvgSamplesPerSec=3.288047563312564, CurrSamplesPerSec=3.287610588254659, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:33:21,587] [INFO] [logging.py:96:log_dist] [Rank 0] step=1950, skipped=0, lr=[9.999025228340303e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:33:21,588] [INFO] [timer.py:260:stop] epoch=3/micro_step=1881/global_step=1950, RunningAvgSamplesPerSec=3.288058735669945, CurrSamplesPerSec=3.2910049931339382, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 4/500 with loss 4.464633972132554
evaluating model ...
***** Evaluating perplexity, Epoch 4/500 *****
ppl: 81.49220275878906, loss: 4.4004950523376465
[2024-05-07 19:34:27,535] [INFO] [logging.py:96:log_dist] [Rank 0] step=1960, skipped=0, lr=[9.999012610483567e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:34:27,535] [INFO] [timer.py:260:stop] epoch=3/micro_step=1921/global_step=1960, RunningAvgSamplesPerSec=3.2880685882646525, CurrSamplesPerSec=3.2895392547545454, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:34:51,952] [INFO] [logging.py:96:log_dist] [Rank 0] step=1970, skipped=0, lr=[9.998999911493775e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:34:51,953] [INFO] [timer.py:260:stop] epoch=3/micro_step=1961/global_step=1970, RunningAvgSamplesPerSec=3.2880787486232133, CurrSamplesPerSec=3.2859538201830607, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
4
4
Beginning of Epoch 5/500
Epoch 5/500 with loss 4.313054928412805
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 81.16365814208984, loss: 4.396454811096191
[2024-05-07 19:35:57,982] [INFO] [logging.py:96:log_dist] [Rank 0] step=1980, skipped=0, lr=[9.998987131371134e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:35:57,983] [INFO] [timer.py:260:stop] epoch=4/micro_step=28/global_step=1980, RunningAvgSamplesPerSec=3.2880747889905817, CurrSamplesPerSec=3.2824689906347047, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:36:22,398] [INFO] [logging.py:96:log_dist] [Rank 0] step=1990, skipped=0, lr=[9.998974270115852e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:36:22,398] [INFO] [timer.py:260:stop] epoch=4/micro_step=68/global_step=1990, RunningAvgSamplesPerSec=3.288065374058523, CurrSamplesPerSec=3.2881073645248415, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:36:46,800] [INFO] [logging.py:96:log_dist] [Rank 0] step=2000, skipped=0, lr=[9.998961327728135e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:36:46,801] [INFO] [timer.py:260:stop] epoch=4/micro_step=108/global_step=2000, RunningAvgSamplesPerSec=3.28806517993128, CurrSamplesPerSec=3.287121690511397, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.396688712381684
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 80.73078918457031, loss: 4.39110803604126
saving model ... to step 8000
Repo card metadata block was not found. Setting CardData to empty.
[2024-05-07 19:38:00,883] [INFO] [logging.py:96:log_dist] [Rank 0] step=2010, skipped=0, lr=[9.998948304208196e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:38:00,885] [INFO] [timer.py:260:stop] epoch=4/micro_step=148/global_step=2010, RunningAvgSamplesPerSec=3.288143953837316, CurrSamplesPerSec=3.2961869872920535, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:38:25,219] [INFO] [logging.py:96:log_dist] [Rank 0] step=2020, skipped=0, lr=[9.998935199556245e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:38:25,220] [INFO] [timer.py:260:stop] epoch=4/micro_step=188/global_step=2020, RunningAvgSamplesPerSec=3.28819597608814, CurrSamplesPerSec=3.295060232717384, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.407834794040017
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 80.44960021972656, loss: 4.387619495391846
[2024-05-07 19:39:31,138] [INFO] [logging.py:96:log_dist] [Rank 0] step=2030, skipped=0, lr=[9.998922013772493e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:39:31,139] [INFO] [timer.py:260:stop] epoch=4/micro_step=228/global_step=2030, RunningAvgSamplesPerSec=3.288210046362323, CurrSamplesPerSec=3.285035365514465, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:39:55,547] [INFO] [logging.py:96:log_dist] [Rank 0] step=2040, skipped=0, lr=[9.99890874685716e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:39:55,548] [INFO] [timer.py:260:stop] epoch=4/micro_step=268/global_step=2040, RunningAvgSamplesPerSec=3.288210403588679, CurrSamplesPerSec=3.2824821561229918, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:40:19,961] [INFO] [logging.py:96:log_dist] [Rank 0] step=2050, skipped=0, lr=[9.998895398810454e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:40:19,962] [INFO] [timer.py:260:stop] epoch=4/micro_step=308/global_step=2050, RunningAvgSamplesPerSec=3.2882090975465976, CurrSamplesPerSec=3.2899914520545366, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.406359699968332
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 80.03591918945312, loss: 4.382464408874512
[2024-05-07 19:41:26,037] [INFO] [logging.py:96:log_dist] [Rank 0] step=2060, skipped=0, lr=[9.998881969632594e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:41:26,038] [INFO] [timer.py:260:stop] epoch=4/micro_step=348/global_step=2060, RunningAvgSamplesPerSec=3.2881889474730444, CurrSamplesPerSec=3.282538672589521, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:41:50,514] [INFO] [logging.py:96:log_dist] [Rank 0] step=2070, skipped=0, lr=[9.998868459323798e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:41:50,515] [INFO] [timer.py:260:stop] epoch=4/micro_step=388/global_step=2070, RunningAvgSamplesPerSec=3.288152742237915, CurrSamplesPerSec=3.2869780762540883, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.399658091131769
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 79.76518249511719, loss: 4.3790740966796875
[2024-05-07 19:42:56,562] [INFO] [logging.py:96:log_dist] [Rank 0] step=2080, skipped=0, lr=[9.998854867884289e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:42:56,563] [INFO] [timer.py:260:stop] epoch=4/micro_step=428/global_step=2080, RunningAvgSamplesPerSec=3.288139071728407, CurrSamplesPerSec=3.290314065328083, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:43:20,993] [INFO] [logging.py:96:log_dist] [Rank 0] step=2090, skipped=0, lr=[9.998841195314282e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:43:20,994] [INFO] [timer.py:260:stop] epoch=4/micro_step=468/global_step=2090, RunningAvgSamplesPerSec=3.288128091793722, CurrSamplesPerSec=3.282713693310596, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:43:45,406] [INFO] [logging.py:96:log_dist] [Rank 0] step=2100, skipped=0, lr=[9.998827441614004e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:43:45,407] [INFO] [timer.py:260:stop] epoch=4/micro_step=508/global_step=2100, RunningAvgSamplesPerSec=3.2881263252449773, CurrSamplesPerSec=3.286845743283941, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.392548566673234
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 79.38970184326172, loss: 4.374355792999268
[2024-05-07 19:44:51,418] [INFO] [logging.py:96:log_dist] [Rank 0] step=2110, skipped=0, lr=[9.998813606783674e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:44:51,419] [INFO] [timer.py:260:stop] epoch=4/micro_step=548/global_step=2110, RunningAvgSamplesPerSec=3.2881204638513104, CurrSamplesPerSec=3.287046983771088, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:45:15,966] [INFO] [logging.py:96:log_dist] [Rank 0] step=2120, skipped=0, lr=[9.998799690823518e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:45:15,967] [INFO] [timer.py:260:stop] epoch=4/micro_step=588/global_step=2120, RunningAvgSamplesPerSec=3.288040202435577, CurrSamplesPerSec=3.292726312650318, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.396402078973916
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 79.05836486816406, loss: 4.370173454284668
[2024-05-07 19:46:21,923] [INFO] [logging.py:96:log_dist] [Rank 0] step=2130, skipped=0, lr=[9.99878569373376e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:46:21,924] [INFO] [timer.py:260:stop] epoch=4/micro_step=628/global_step=2130, RunningAvgSamplesPerSec=3.2880492823963094, CurrSamplesPerSec=3.2919710356585705, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:46:46,422] [INFO] [logging.py:96:log_dist] [Rank 0] step=2140, skipped=0, lr=[9.998771615514633e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:46:46,423] [INFO] [timer.py:260:stop] epoch=4/micro_step=668/global_step=2140, RunningAvgSamplesPerSec=3.287991841917634, CurrSamplesPerSec=3.288034546162219, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:47:10,949] [INFO] [logging.py:96:log_dist] [Rank 0] step=2150, skipped=0, lr=[9.998757456166359e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:47:10,950] [INFO] [timer.py:260:stop] epoch=4/micro_step=708/global_step=2150, RunningAvgSamplesPerSec=3.2879274974091146, CurrSamplesPerSec=3.2934861387576904, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.393186446159117
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 78.8671875, loss: 4.367753028869629
[2024-05-07 19:48:16,910] [INFO] [logging.py:96:log_dist] [Rank 0] step=2160, skipped=0, lr=[9.998743215689173e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:48:16,911] [INFO] [timer.py:260:stop] epoch=4/micro_step=748/global_step=2160, RunningAvgSamplesPerSec=3.2879278111600834, CurrSamplesPerSec=3.290141136746091, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:48:41,439] [INFO] [logging.py:96:log_dist] [Rank 0] step=2170, skipped=0, lr=[9.998728894083303e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:48:41,439] [INFO] [timer.py:260:stop] epoch=4/micro_step=788/global_step=2170, RunningAvgSamplesPerSec=3.287853767797316, CurrSamplesPerSec=3.2907551800482024, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.392180233424
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 78.54484558105469, loss: 4.363657474517822
[2024-05-07 19:49:47,469] [INFO] [logging.py:96:log_dist] [Rank 0] step=2180, skipped=0, lr=[9.998714491348979e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:49:47,470] [INFO] [timer.py:260:stop] epoch=4/micro_step=828/global_step=2180, RunningAvgSamplesPerSec=3.287817122004149, CurrSamplesPerSec=3.292361229604652, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:50:11,884] [INFO] [logging.py:96:log_dist] [Rank 0] step=2190, skipped=0, lr=[9.998700007486441e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:50:11,885] [INFO] [timer.py:260:stop] epoch=4/micro_step=868/global_step=2190, RunningAvgSamplesPerSec=3.287822808999043, CurrSamplesPerSec=3.288744501636755, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:50:36,431] [INFO] [logging.py:96:log_dist] [Rank 0] step=2200, skipped=0, lr=[9.998685442495921e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:50:36,432] [INFO] [timer.py:260:stop] epoch=4/micro_step=908/global_step=2200, RunningAvgSamplesPerSec=3.2877496714343004, CurrSamplesPerSec=3.285234132824005, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.386930073991924
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 78.294921875, loss: 4.360469818115234
[2024-05-07 19:51:42,395] [INFO] [logging.py:96:log_dist] [Rank 0] step=2210, skipped=0, lr=[9.998670796377654e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:51:42,396] [INFO] [timer.py:260:stop] epoch=4/micro_step=948/global_step=2210, RunningAvgSamplesPerSec=3.287757904517674, CurrSamplesPerSec=3.292043059533665, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:52:06,916] [INFO] [logging.py:96:log_dist] [Rank 0] step=2220, skipped=0, lr=[9.998656069131879e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:52:06,917] [INFO] [timer.py:260:stop] epoch=4/micro_step=988/global_step=2220, RunningAvgSamplesPerSec=3.2876986068445078, CurrSamplesPerSec=3.292565407666337, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.383499889948055
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 78.0213623046875, loss: 4.35697078704834
[2024-05-07 19:53:12,878] [INFO] [logging.py:96:log_dist] [Rank 0] step=2230, skipped=0, lr=[9.998641260758835e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:53:12,878] [INFO] [timer.py:260:stop] epoch=4/micro_step=1028/global_step=2230, RunningAvgSamplesPerSec=3.2877157479731633, CurrSamplesPerSec=3.2853077921907534, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:53:37,312] [INFO] [logging.py:96:log_dist] [Rank 0] step=2240, skipped=0, lr=[9.998626371258763e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:53:37,313] [INFO] [timer.py:260:stop] epoch=4/micro_step=1068/global_step=2240, RunningAvgSamplesPerSec=3.2877195850234857, CurrSamplesPerSec=3.2881041424051984, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:54:01,766] [INFO] [logging.py:96:log_dist] [Rank 0] step=2250, skipped=0, lr=[9.998611400631903e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:54:01,767] [INFO] [timer.py:260:stop] epoch=4/micro_step=1108/global_step=2250, RunningAvgSamplesPerSec=3.2877185514545664, CurrSamplesPerSec=3.2866992557074735, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.382025632575516
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 77.724365234375, loss: 4.353156566619873
[2024-05-07 19:55:07,873] [INFO] [logging.py:96:log_dist] [Rank 0] step=2260, skipped=0, lr=[9.9985963488785e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:55:07,874] [INFO] [timer.py:260:stop] epoch=4/micro_step=1148/global_step=2260, RunningAvgSamplesPerSec=3.2877035083407047, CurrSamplesPerSec=3.281891097664688, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:55:32,313] [INFO] [logging.py:96:log_dist] [Rank 0] step=2270, skipped=0, lr=[9.998581215998796e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:55:32,314] [INFO] [timer.py:260:stop] epoch=4/micro_step=1188/global_step=2270, RunningAvgSamplesPerSec=3.2877108644965567, CurrSamplesPerSec=3.2872585543400237, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.382359833729139
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 77.49545288085938, loss: 4.350207328796387
[2024-05-07 19:56:38,167] [INFO] [logging.py:96:log_dist] [Rank 0] step=2280, skipped=0, lr=[9.998566001993038e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:56:38,167] [INFO] [timer.py:260:stop] epoch=4/micro_step=1228/global_step=2280, RunningAvgSamplesPerSec=3.2877342512424255, CurrSamplesPerSec=3.2934088796831755, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:57:02,572] [INFO] [logging.py:96:log_dist] [Rank 0] step=2290, skipped=0, lr=[9.998550706861474e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:57:02,573] [INFO] [timer.py:260:stop] epoch=4/micro_step=1268/global_step=2290, RunningAvgSamplesPerSec=3.2877530787577878, CurrSamplesPerSec=3.290030807485572, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:57:27,137] [INFO] [logging.py:96:log_dist] [Rank 0] step=2300, skipped=0, lr=[9.99853533060435e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:57:27,138] [INFO] [timer.py:260:stop] epoch=4/micro_step=1308/global_step=2300, RunningAvgSamplesPerSec=3.2876843473590713, CurrSamplesPerSec=3.2824856883451345, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.381292192970444
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 77.26123046875, loss: 4.34718132019043
[2024-05-07 19:58:33,089] [INFO] [logging.py:96:log_dist] [Rank 0] step=2310, skipped=0, lr=[9.998519873221916e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:58:33,090] [INFO] [timer.py:260:stop] epoch=4/micro_step=1348/global_step=2310, RunningAvgSamplesPerSec=3.2876974358311957, CurrSamplesPerSec=3.287010275668796, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 19:58:57,519] [INFO] [logging.py:96:log_dist] [Rank 0] step=2320, skipped=0, lr=[9.998504334714426e-06], mom=[(0.9, 0.95)]
[2024-05-07 19:58:57,520] [INFO] [timer.py:260:stop] epoch=4/micro_step=1388/global_step=2320, RunningAvgSamplesPerSec=3.2877074104038804, CurrSamplesPerSec=3.2920963527703577, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.377108203040229
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 76.99812316894531, loss: 4.343769073486328
[2024-05-07 20:00:03,461] [INFO] [logging.py:96:log_dist] [Rank 0] step=2330, skipped=0, lr=[9.998488715082127e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:00:03,462] [INFO] [timer.py:260:stop] epoch=4/micro_step=1428/global_step=2330, RunningAvgSamplesPerSec=3.287723016573285, CurrSamplesPerSec=3.2953550371810336, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:00:27,893] [INFO] [logging.py:96:log_dist] [Rank 0] step=2340, skipped=0, lr=[9.998473014325276e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:00:27,894] [INFO] [timer.py:260:stop] epoch=4/micro_step=1468/global_step=2340, RunningAvgSamplesPerSec=3.2877283728739566, CurrSamplesPerSec=3.2860883340567324, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:00:52,346] [INFO] [logging.py:96:log_dist] [Rank 0] step=2350, skipped=0, lr=[9.998457232444128e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:00:52,347] [INFO] [timer.py:260:stop] epoch=4/micro_step=1508/global_step=2350, RunningAvgSamplesPerSec=3.287726633018018, CurrSamplesPerSec=3.28252390105246, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.37763231586953
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 76.83979797363281, loss: 4.341712474822998
[2024-05-07 20:01:58,373] [INFO] [logging.py:96:log_dist] [Rank 0] step=2360, skipped=0, lr=[9.998441369438935e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:01:58,373] [INFO] [timer.py:260:stop] epoch=4/micro_step=1548/global_step=2360, RunningAvgSamplesPerSec=3.287724881690935, CurrSamplesPerSec=3.2862756420514856, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:02:22,798] [INFO] [logging.py:96:log_dist] [Rank 0] step=2370, skipped=0, lr=[9.998425425309962e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:02:22,799] [INFO] [timer.py:260:stop] epoch=4/micro_step=1588/global_step=2370, RunningAvgSamplesPerSec=3.2877304054988317, CurrSamplesPerSec=3.289795979194372, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.375584105120929
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 76.52120971679688, loss: 4.337557315826416
[2024-05-07 20:03:28,813] [INFO] [logging.py:96:log_dist] [Rank 0] step=2380, skipped=0, lr=[9.99840940005746e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:03:28,813] [INFO] [timer.py:260:stop] epoch=4/micro_step=1628/global_step=2380, RunningAvgSamplesPerSec=3.287735911586374, CurrSamplesPerSec=3.28549147250965, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:03:53,228] [INFO] [logging.py:96:log_dist] [Rank 0] step=2390, skipped=0, lr=[9.998393293681693e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:03:53,228] [INFO] [timer.py:260:stop] epoch=4/micro_step=1668/global_step=2390, RunningAvgSamplesPerSec=3.2877457616252554, CurrSamplesPerSec=3.2882778236573227, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:04:17,636] [INFO] [logging.py:96:log_dist] [Rank 0] step=2400, skipped=0, lr=[9.998377106182921e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:04:17,637] [INFO] [timer.py:260:stop] epoch=4/micro_step=1708/global_step=2400, RunningAvgSamplesPerSec=3.287760701067007, CurrSamplesPerSec=3.2909807847800425, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.372749930157414
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 76.37962341308594, loss: 4.3357062339782715
[2024-05-07 20:05:23,611] [INFO] [logging.py:96:log_dist] [Rank 0] step=2410, skipped=0, lr=[9.99836083756141e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:05:23,611] [INFO] [timer.py:260:stop] epoch=4/micro_step=1748/global_step=2410, RunningAvgSamplesPerSec=3.2877734943124417, CurrSamplesPerSec=3.2932401507093862, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:05:48,018] [INFO] [logging.py:96:log_dist] [Rank 0] step=2420, skipped=0, lr=[9.99834448781742e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:05:48,018] [INFO] [timer.py:260:stop] epoch=4/micro_step=1788/global_step=2420, RunningAvgSamplesPerSec=3.287787073412628, CurrSamplesPerSec=3.2878322182636266, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.371504799147962
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 76.1489028930664, loss: 4.332681655883789
[2024-05-07 20:06:54,026] [INFO] [logging.py:96:log_dist] [Rank 0] step=2430, skipped=0, lr=[9.998328056951216e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:06:54,026] [INFO] [timer.py:260:stop] epoch=4/micro_step=1828/global_step=2430, RunningAvgSamplesPerSec=3.287791129389308, CurrSamplesPerSec=3.2889259874737387, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:07:18,453] [INFO] [logging.py:96:log_dist] [Rank 0] step=2440, skipped=0, lr=[9.998311544963069e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:07:18,454] [INFO] [timer.py:260:stop] epoch=4/micro_step=1868/global_step=2440, RunningAvgSamplesPerSec=3.287796792590101, CurrSamplesPerSec=3.2920963527703577, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:07:42,880] [INFO] [logging.py:96:log_dist] [Rank 0] step=2450, skipped=0, lr=[9.998294951853245e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:07:42,881] [INFO] [timer.py:260:stop] epoch=4/micro_step=1908/global_step=2450, RunningAvgSamplesPerSec=3.2878044189170907, CurrSamplesPerSec=3.2815248830933914, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 5/500 with loss 4.368442457506187
evaluating model ...
***** Evaluating perplexity, Epoch 5/500 *****
ppl: 75.95353698730469, loss: 4.330110549926758
[2024-05-07 20:08:48,863] [INFO] [logging.py:96:log_dist] [Rank 0] step=2460, skipped=0, lr=[9.998278277622011e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:08:48,864] [INFO] [timer.py:260:stop] epoch=4/micro_step=1948/global_step=2460, RunningAvgSamplesPerSec=3.287813838301526, CurrSamplesPerSec=3.290496692482458, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
4
4
Beginning of Epoch 6/500
[2024-05-07 20:09:13,271] [INFO] [logging.py:96:log_dist] [Rank 0] step=2470, skipped=0, lr=[9.998261522269642e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:09:13,272] [INFO] [timer.py:260:stop] epoch=5/micro_step=15/global_step=2470, RunningAvgSamplesPerSec=3.2878262814492856, CurrSamplesPerSec=3.293609308208622, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.336885487161031
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 75.72279357910156, loss: 4.327068328857422
[2024-05-07 20:10:19,196] [INFO] [logging.py:96:log_dist] [Rank 0] step=2480, skipped=0, lr=[9.998244685796405e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:10:19,197] [INFO] [timer.py:260:stop] epoch=5/micro_step=55/global_step=2480, RunningAvgSamplesPerSec=3.2878417114319793, CurrSamplesPerSec=3.2895744068641557, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:10:43,588] [INFO] [logging.py:96:log_dist] [Rank 0] step=2490, skipped=0, lr=[9.998227768202575e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:10:43,588] [INFO] [timer.py:260:stop] epoch=5/micro_step=95/global_step=2490, RunningAvgSamplesPerSec=3.287853114794296, CurrSamplesPerSec=3.2912277267015533, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:11:07,978] [INFO] [logging.py:96:log_dist] [Rank 0] step=2500, skipped=0, lr=[9.99821076948843e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:11:07,979] [INFO] [timer.py:260:stop] epoch=5/micro_step=135/global_step=2500, RunningAvgSamplesPerSec=3.2878625497914804, CurrSamplesPerSec=3.2909901453013175, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.344667235164778
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 75.54556274414062, loss: 4.324726104736328
saving model ... to step 10000
Repo card metadata block was not found. Setting CardData to empty.
[2024-05-07 20:12:21,888] [INFO] [logging.py:96:log_dist] [Rank 0] step=2510, skipped=0, lr=[9.99819368965424e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:12:21,888] [INFO] [timer.py:260:stop] epoch=5/micro_step=175/global_step=2510, RunningAvgSamplesPerSec=3.287938667044472, CurrSamplesPerSec=3.3028323829716446, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:12:46,202] [INFO] [logging.py:96:log_dist] [Rank 0] step=2520, skipped=0, lr=[9.998176528700288e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:12:46,203] [INFO] [timer.py:260:stop] epoch=5/micro_step=215/global_step=2520, RunningAvgSamplesPerSec=3.2879875692632776, CurrSamplesPerSec=3.29846453409862, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.3430049923940315
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 75.32569122314453, loss: 4.321811676025391
[2024-05-07 20:13:52,116] [INFO] [logging.py:96:log_dist] [Rank 0] step=2530, skipped=0, lr=[9.99815928662685e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:13:52,117] [INFO] [timer.py:260:stop] epoch=5/micro_step=255/global_step=2530, RunningAvgSamplesPerSec=3.288007190657289, CurrSamplesPerSec=3.285729869361752, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:14:16,503] [INFO] [logging.py:96:log_dist] [Rank 0] step=2540, skipped=0, lr=[9.998141963434204e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:14:16,504] [INFO] [timer.py:260:stop] epoch=5/micro_step=295/global_step=2540, RunningAvgSamplesPerSec=3.288017697755515, CurrSamplesPerSec=3.2858083773815046, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:14:40,902] [INFO] [logging.py:96:log_dist] [Rank 0] step=2550, skipped=0, lr=[9.998124559122632e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:14:40,903] [INFO] [timer.py:260:stop] epoch=5/micro_step=335/global_step=2550, RunningAvgSamplesPerSec=3.2880232601661534, CurrSamplesPerSec=3.287584819262565, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.3415809453757275
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 75.20167541503906, loss: 4.320163726806641
[2024-05-07 20:15:46,879] [INFO] [logging.py:96:log_dist] [Rank 0] step=2560, skipped=0, lr=[9.99810707369242e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:15:46,879] [INFO] [timer.py:260:stop] epoch=5/micro_step=375/global_step=2560, RunningAvgSamplesPerSec=3.2880312187594884, CurrSamplesPerSec=3.288154408190784, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:16:11,275] [INFO] [logging.py:96:log_dist] [Rank 0] step=2570, skipped=0, lr=[9.998089507143848e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:16:11,275] [INFO] [timer.py:260:stop] epoch=5/micro_step=415/global_step=2570, RunningAvgSamplesPerSec=3.288042635008297, CurrSamplesPerSec=3.2861707211971636, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.331405283372148
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 74.99816131591797, loss: 4.317452430725098
[2024-05-07 20:17:17,262] [INFO] [logging.py:96:log_dist] [Rank 0] step=2580, skipped=0, lr=[9.998071859477202e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:17:17,263] [INFO] [timer.py:260:stop] epoch=5/micro_step=455/global_step=2580, RunningAvgSamplesPerSec=3.288049571556332, CurrSamplesPerSec=3.2904215095911207, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:17:41,681] [INFO] [logging.py:96:log_dist] [Rank 0] step=2590, skipped=0, lr=[9.99805413069277e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:17:41,682] [INFO] [timer.py:260:stop] epoch=5/micro_step=495/global_step=2590, RunningAvgSamplesPerSec=3.288050798318464, CurrSamplesPerSec=3.286657726440642, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:18:06,101] [INFO] [logging.py:96:log_dist] [Rank 0] step=2600, skipped=0, lr=[9.998036320790835e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:18:06,102] [INFO] [timer.py:260:stop] epoch=5/micro_step=535/global_step=2600, RunningAvgSamplesPerSec=3.2880487997033567, CurrSamplesPerSec=3.2863754196308697, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.331748744696654
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 74.71087646484375, loss: 4.3136138916015625
[2024-05-07 20:19:12,079] [INFO] [logging.py:96:log_dist] [Rank 0] step=2610, skipped=0, lr=[9.998018429771692e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:19:12,081] [INFO] [timer.py:260:stop] epoch=5/micro_step=575/global_step=2610, RunningAvgSamplesPerSec=3.2880408726459533, CurrSamplesPerSec=3.2888157396927133, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:19:36,491] [INFO] [logging.py:96:log_dist] [Rank 0] step=2620, skipped=0, lr=[9.998000457635628e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:19:36,492] [INFO] [timer.py:260:stop] epoch=5/micro_step=615/global_step=2620, RunningAvgSamplesPerSec=3.288041986147055, CurrSamplesPerSec=3.2880487229357307, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.333396794457517
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 74.54049682617188, loss: 4.311332702636719
[2024-05-07 20:20:42,459] [INFO] [logging.py:96:log_dist] [Rank 0] step=2630, skipped=0, lr=[9.997982404382935e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:20:42,460] [INFO] [timer.py:260:stop] epoch=5/micro_step=655/global_step=2630, RunningAvgSamplesPerSec=3.288045465744013, CurrSamplesPerSec=3.288448300464301, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:21:06,879] [INFO] [logging.py:96:log_dist] [Rank 0] step=2640, skipped=0, lr=[9.997964270013907e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:21:06,879] [INFO] [timer.py:260:stop] epoch=5/micro_step=695/global_step=2640, RunningAvgSamplesPerSec=3.2880460026741707, CurrSamplesPerSec=3.287658584079311, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:21:31,270] [INFO] [logging.py:96:log_dist] [Rank 0] step=2650, skipped=0, lr=[9.997946054528837e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:21:31,271] [INFO] [timer.py:260:stop] epoch=5/micro_step=735/global_step=2650, RunningAvgSamplesPerSec=3.288058256237343, CurrSamplesPerSec=3.29126420623133, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.330914495444974
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 74.3241958618164, loss: 4.3084259033203125
[2024-05-07 20:22:37,227] [INFO] [logging.py:96:log_dist] [Rank 0] step=2660, skipped=0, lr=[9.997927757928024e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:22:37,228] [INFO] [timer.py:260:stop] epoch=5/micro_step=775/global_step=2660, RunningAvgSamplesPerSec=3.2880666851822555, CurrSamplesPerSec=3.293873135194995, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:23:01,636] [INFO] [logging.py:96:log_dist] [Rank 0] step=2670, skipped=0, lr=[9.99790938021176e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:23:01,637] [INFO] [timer.py:260:stop] epoch=5/micro_step=815/global_step=2670, RunningAvgSamplesPerSec=3.2880731297057633, CurrSamplesPerSec=3.2872534016129613, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.330567566591551
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 74.15324401855469, loss: 4.306123733520508
[2024-05-07 20:24:07,609] [INFO] [logging.py:96:log_dist] [Rank 0] step=2680, skipped=0, lr=[9.997890921380345e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:24:07,610] [INFO] [timer.py:260:stop] epoch=5/micro_step=855/global_step=2680, RunningAvgSamplesPerSec=3.2880701148971476, CurrSamplesPerSec=3.2850424409605075, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:24:32,026] [INFO] [logging.py:96:log_dist] [Rank 0] step=2690, skipped=0, lr=[9.99787238143408e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:24:32,027] [INFO] [timer.py:260:stop] epoch=5/micro_step=895/global_step=2690, RunningAvgSamplesPerSec=3.288070848857204, CurrSamplesPerSec=3.290965937165859, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:24:56,444] [INFO] [logging.py:96:log_dist] [Rank 0] step=2700, skipped=0, lr=[9.997853760373267e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:24:56,445] [INFO] [timer.py:260:stop] epoch=5/micro_step=935/global_step=2700, RunningAvgSamplesPerSec=3.288071822314934, CurrSamplesPerSec=3.2852547185153353, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.325460816544504
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 74.20320892333984, loss: 4.306797027587891
[2024-05-07 20:26:02,467] [INFO] [logging.py:96:log_dist] [Rank 0] step=2710, skipped=0, lr=[9.997835058198204e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:26:02,468] [INFO] [timer.py:260:stop] epoch=5/micro_step=975/global_step=2710, RunningAvgSamplesPerSec=3.288060983625658, CurrSamplesPerSec=3.283131891770564, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:26:26,900] [INFO] [logging.py:96:log_dist] [Rank 0] step=2720, skipped=0, lr=[9.997816274909198e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:26:26,901] [INFO] [timer.py:260:stop] epoch=5/micro_step=1015/global_step=2720, RunningAvgSamplesPerSec=3.288061455487667, CurrSamplesPerSec=3.28790245028574, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.3238838025861694
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 73.92803955078125, loss: 4.303081512451172
[2024-05-07 20:27:32,937] [INFO] [logging.py:96:log_dist] [Rank 0] step=2730, skipped=0, lr=[9.997797410506552e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:27:32,937] [INFO] [timer.py:260:stop] epoch=5/micro_step=1055/global_step=2730, RunningAvgSamplesPerSec=3.288061937000592, CurrSamplesPerSec=3.288599456310969, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:27:57,390] [INFO] [logging.py:96:log_dist] [Rank 0] step=2740, skipped=0, lr=[9.997778464990574e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:27:57,391] [INFO] [timer.py:260:stop] epoch=5/micro_step=1095/global_step=2740, RunningAvgSamplesPerSec=3.2880609369563047, CurrSamplesPerSec=3.284846912578323, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:28:21,849] [INFO] [logging.py:96:log_dist] [Rank 0] step=2750, skipped=0, lr=[9.997759438361567e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:28:21,850] [INFO] [timer.py:260:stop] epoch=5/micro_step=1135/global_step=2750, RunningAvgSamplesPerSec=3.288056118679824, CurrSamplesPerSec=3.2826054672863823, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.3226371214747115
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 73.81233215332031, loss: 4.301514148712158
[2024-05-07 20:29:27,849] [INFO] [logging.py:96:log_dist] [Rank 0] step=2760, skipped=0, lr=[9.997740330619846e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:29:27,850] [INFO] [timer.py:260:stop] epoch=5/micro_step=1175/global_step=2760, RunningAvgSamplesPerSec=3.2880488831015398, CurrSamplesPerSec=3.2914960154125645, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:29:52,287] [INFO] [logging.py:96:log_dist] [Rank 0] step=2770, skipped=0, lr=[9.997721141765719e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:29:52,288] [INFO] [timer.py:260:stop] epoch=5/micro_step=1215/global_step=2770, RunningAvgSamplesPerSec=3.2880494910728304, CurrSamplesPerSec=3.281428929774472, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.323151620523666
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 73.64767456054688, loss: 4.299281597137451
[2024-05-07 20:30:58,277] [INFO] [logging.py:96:log_dist] [Rank 0] step=2780, skipped=0, lr=[9.997701871799495e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:30:58,278] [INFO] [timer.py:260:stop] epoch=5/micro_step=1255/global_step=2780, RunningAvgSamplesPerSec=3.28805303333377, CurrSamplesPerSec=3.2847719876403163, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:31:22,719] [INFO] [logging.py:96:log_dist] [Rank 0] step=2790, skipped=0, lr=[9.997682520721488e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:31:22,720] [INFO] [timer.py:260:stop] epoch=5/micro_step=1295/global_step=2790, RunningAvgSamplesPerSec=3.288052056122433, CurrSamplesPerSec=3.2886571505859017, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:31:47,170] [INFO] [logging.py:96:log_dist] [Rank 0] step=2800, skipped=0, lr=[9.997663088532015e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:31:47,171] [INFO] [timer.py:260:stop] epoch=5/micro_step=1335/global_step=2800, RunningAvgSamplesPerSec=3.2880536078892333, CurrSamplesPerSec=3.283358380108079, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.322043879364605
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 73.52728271484375, loss: 4.297647476196289
[2024-05-07 20:32:53,189] [INFO] [logging.py:96:log_dist] [Rank 0] step=2810, skipped=0, lr=[9.997643575231386e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:32:53,190] [INFO] [timer.py:260:stop] epoch=5/micro_step=1375/global_step=2810, RunningAvgSamplesPerSec=3.288054157673377, CurrSamplesPerSec=3.2875455223273726, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:33:17,616] [INFO] [logging.py:96:log_dist] [Rank 0] step=2820, skipped=0, lr=[9.997623980819921e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:33:17,617] [INFO] [timer.py:260:stop] epoch=5/micro_step=1415/global_step=2820, RunningAvgSamplesPerSec=3.2880622509653206, CurrSamplesPerSec=3.2901975946390296, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.320602924438254
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 73.35462951660156, loss: 4.2952961921691895
[2024-05-07 20:34:23,609] [INFO] [logging.py:96:log_dist] [Rank 0] step=2830, skipped=0, lr=[9.997604305297938e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:34:23,610] [INFO] [timer.py:260:stop] epoch=5/micro_step=1455/global_step=2830, RunningAvgSamplesPerSec=3.2880687799431483, CurrSamplesPerSec=3.2896572914176874, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:34:48,049] [INFO] [logging.py:96:log_dist] [Rank 0] step=2840, skipped=0, lr=[9.997584548665758e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:34:48,050] [INFO] [timer.py:260:stop] epoch=5/micro_step=1495/global_step=2840, RunningAvgSamplesPerSec=3.288066770365986, CurrSamplesPerSec=3.289203251401329, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:35:12,488] [INFO] [logging.py:96:log_dist] [Rank 0] step=2850, skipped=0, lr=[9.997564710923698e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:35:12,488] [INFO] [timer.py:260:stop] epoch=5/micro_step=1535/global_step=2850, RunningAvgSamplesPerSec=3.28806707569909, CurrSamplesPerSec=3.284338583404721, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.320273542466062
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 73.26518249511719, loss: 4.294075965881348
[2024-05-07 20:36:18,533] [INFO] [logging.py:96:log_dist] [Rank 0] step=2860, skipped=0, lr=[9.997544792072082e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:36:18,534] [INFO] [timer.py:260:stop] epoch=5/micro_step=1575/global_step=2860, RunningAvgSamplesPerSec=3.2880666254694564, CurrSamplesPerSec=3.288935658684349, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:36:42,982] [INFO] [logging.py:96:log_dist] [Rank 0] step=2870, skipped=0, lr=[9.997524792111232e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:36:42,982] [INFO] [timer.py:260:stop] epoch=5/micro_step=1615/global_step=2870, RunningAvgSamplesPerSec=3.2880645253425445, CurrSamplesPerSec=3.2838243054283303, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.31898144786493
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 73.07898712158203, loss: 4.291532039642334
[2024-05-07 20:37:49,003] [INFO] [logging.py:96:log_dist] [Rank 0] step=2880, skipped=0, lr=[9.997504711041472e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:37:49,005] [INFO] [timer.py:260:stop] epoch=5/micro_step=1655/global_step=2880, RunningAvgSamplesPerSec=3.2880604088572385, CurrSamplesPerSec=3.28894694183528, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:38:13,442] [INFO] [logging.py:96:log_dist] [Rank 0] step=2890, skipped=0, lr=[9.997484548863132e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:38:13,443] [INFO] [timer.py:260:stop] epoch=5/micro_step=1695/global_step=2890, RunningAvgSamplesPerSec=3.288066682492317, CurrSamplesPerSec=3.288720326527284, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:38:37,884] [INFO] [logging.py:96:log_dist] [Rank 0] step=2900, skipped=0, lr=[9.997464305576536e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:38:37,885] [INFO] [timer.py:260:stop] epoch=5/micro_step=1735/global_step=2900, RunningAvgSamplesPerSec=3.2880715530990945, CurrSamplesPerSec=3.2859386961060943, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.317230914804457
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 72.97029113769531, loss: 4.290044784545898
[2024-05-07 20:39:43,952] [INFO] [logging.py:96:log_dist] [Rank 0] step=2910, skipped=0, lr=[9.997443981182012e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:39:43,953] [INFO] [timer.py:260:stop] epoch=5/micro_step=1775/global_step=2910, RunningAvgSamplesPerSec=3.2880608404112994, CurrSamplesPerSec=3.2845346942986637, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:40:08,389] [INFO] [logging.py:96:log_dist] [Rank 0] step=2920, skipped=0, lr=[9.997423575679893e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:40:08,390] [INFO] [timer.py:260:stop] epoch=5/micro_step=1815/global_step=2920, RunningAvgSamplesPerSec=3.288064290011276, CurrSamplesPerSec=3.2895086182075106, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.315012937651453
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 72.93938446044922, loss: 4.289619445800781
[2024-05-07 20:41:14,430] [INFO] [logging.py:96:log_dist] [Rank 0] step=2930, skipped=0, lr=[9.997403089070505e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:41:14,431] [INFO] [timer.py:260:stop] epoch=5/micro_step=1855/global_step=2930, RunningAvgSamplesPerSec=3.288059616285525, CurrSamplesPerSec=3.2895053933410185, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:41:38,884] [INFO] [logging.py:96:log_dist] [Rank 0] step=2940, skipped=0, lr=[9.997382521354186e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:41:38,885] [INFO] [timer.py:260:stop] epoch=5/micro_step=1895/global_step=2940, RunningAvgSamplesPerSec=3.2880567321342364, CurrSamplesPerSec=3.2860419931056097, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:42:03,317] [INFO] [logging.py:96:log_dist] [Rank 0] step=2950, skipped=0, lr=[9.997361872531267e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:42:03,318] [INFO] [timer.py:260:stop] epoch=5/micro_step=1935/global_step=2950, RunningAvgSamplesPerSec=3.2880594783348425, CurrSamplesPerSec=3.2892042186828983, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 6/500 with loss 4.313692438301507
evaluating model ...
***** Evaluating perplexity, Epoch 6/500 *****
ppl: 72.78483581542969, loss: 4.287498474121094
4
4
Beginning of Epoch 7/500
[2024-05-07 20:43:09,349] [INFO] [logging.py:96:log_dist] [Rank 0] step=2960, skipped=0, lr=[9.997341142602083e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:43:09,350] [INFO] [timer.py:260:stop] epoch=6/micro_step=2/global_step=2960, RunningAvgSamplesPerSec=3.288058902900031, CurrSamplesPerSec=3.2843266889070883, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:43:33,784] [INFO] [logging.py:96:log_dist] [Rank 0] step=2970, skipped=0, lr=[9.997320331566971e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:43:33,785] [INFO] [timer.py:260:stop] epoch=6/micro_step=42/global_step=2970, RunningAvgSamplesPerSec=3.288051943101267, CurrSamplesPerSec=3.27894284037967, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.311406114827031
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 72.69573974609375, loss: 4.286273956298828
[2024-05-07 20:44:39,802] [INFO] [logging.py:96:log_dist] [Rank 0] step=2980, skipped=0, lr=[9.997299439426269e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:44:39,803] [INFO] [timer.py:260:stop] epoch=6/micro_step=82/global_step=2980, RunningAvgSamplesPerSec=3.288042589230911, CurrSamplesPerSec=3.293191668569857, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:45:04,225] [INFO] [logging.py:96:log_dist] [Rank 0] step=2990, skipped=0, lr=[9.997278466180315e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:45:04,226] [INFO] [timer.py:260:stop] epoch=6/micro_step=122/global_step=2990, RunningAvgSamplesPerSec=3.288039750832871, CurrSamplesPerSec=3.2824709172849302, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:45:28,635] [INFO] [logging.py:96:log_dist] [Rank 0] step=3000, skipped=0, lr=[9.997257411829453e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:45:28,635] [INFO] [timer.py:260:stop] epoch=6/micro_step=162/global_step=3000, RunningAvgSamplesPerSec=3.288044539382, CurrSamplesPerSec=3.293140925459418, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.305333404146003
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 72.57036590576172, loss: 4.284546852111816
saving model ... to step 12000
Repo card metadata block was not found. Setting CardData to empty.
[2024-05-07 20:46:42,581] [INFO] [logging.py:96:log_dist] [Rank 0] step=3010, skipped=0, lr=[9.99723627637402e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:46:42,582] [INFO] [timer.py:260:stop] epoch=6/micro_step=202/global_step=3010, RunningAvgSamplesPerSec=3.2880950970450287, CurrSamplesPerSec=3.3001323222525825, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:47:06,937] [INFO] [logging.py:96:log_dist] [Rank 0] step=3020, skipped=0, lr=[9.99721505981436e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:47:06,938] [INFO] [timer.py:260:stop] epoch=6/micro_step=242/global_step=3020, RunningAvgSamplesPerSec=3.28812510647428, CurrSamplesPerSec=3.2952346496228806, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.298180928460727
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 72.407470703125, loss: 4.282299518585205
[2024-05-07 20:48:12,884] [INFO] [logging.py:96:log_dist] [Rank 0] step=3030, skipped=0, lr=[9.997193762150819e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:48:12,886] [INFO] [timer.py:260:stop] epoch=6/micro_step=282/global_step=3030, RunningAvgSamplesPerSec=3.2881320410842423, CurrSamplesPerSec=3.2857655836105137, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:48:37,288] [INFO] [logging.py:96:log_dist] [Rank 0] step=3040, skipped=0, lr=[9.997172383383742e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:48:37,289] [INFO] [timer.py:260:stop] epoch=6/micro_step=322/global_step=3040, RunningAvgSamplesPerSec=3.28813910411959, CurrSamplesPerSec=3.290125328883279, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:49:01,723] [INFO] [logging.py:96:log_dist] [Rank 0] step=3050, skipped=0, lr=[9.997150923513476e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:49:01,724] [INFO] [timer.py:260:stop] epoch=6/micro_step=362/global_step=3050, RunningAvgSamplesPerSec=3.2881337868841163, CurrSamplesPerSec=3.2850443706329, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.302914592954847
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 72.29077911376953, loss: 4.280686378479004
[2024-05-07 20:50:07,746] [INFO] [logging.py:96:log_dist] [Rank 0] step=3060, skipped=0, lr=[9.997129382540371e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:50:07,747] [INFO] [timer.py:260:stop] epoch=6/micro_step=402/global_step=3060, RunningAvgSamplesPerSec=3.288132195499119, CurrSamplesPerSec=3.2888192855589327, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:50:32,155] [INFO] [logging.py:96:log_dist] [Rank 0] step=3070, skipped=0, lr=[9.997107760464773e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:50:32,156] [INFO] [timer.py:260:stop] epoch=6/micro_step=442/global_step=3070, RunningAvgSamplesPerSec=3.288134205825057, CurrSamplesPerSec=3.2876125209453515, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.291016437351576
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 72.25782775878906, loss: 4.280228614807129
[2024-05-07 20:51:38,136] [INFO] [logging.py:96:log_dist] [Rank 0] step=3080, skipped=0, lr=[9.997086057287035e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:51:38,137] [INFO] [timer.py:260:stop] epoch=6/micro_step=482/global_step=3080, RunningAvgSamplesPerSec=3.2881341326483065, CurrSamplesPerSec=3.2936199768623085, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:52:02,528] [INFO] [logging.py:96:log_dist] [Rank 0] step=3090, skipped=0, lr=[9.997064273007509e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:52:02,529] [INFO] [timer.py:260:stop] epoch=6/micro_step=522/global_step=3090, RunningAvgSamplesPerSec=3.2881420671953885, CurrSamplesPerSec=3.2891629485083143, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:52:26,930] [INFO] [logging.py:96:log_dist] [Rank 0] step=3100, skipped=0, lr=[9.99704240762655e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:52:26,930] [INFO] [timer.py:260:stop] epoch=6/micro_step=562/global_step=3100, RunningAvgSamplesPerSec=3.288144339267783, CurrSamplesPerSec=3.28627210166804, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.294444945239853
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 72.09754943847656, loss: 4.278007984161377
[2024-05-07 20:53:32,897] [INFO] [logging.py:96:log_dist] [Rank 0] step=3110, skipped=0, lr=[9.997020461144509e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:53:32,897] [INFO] [timer.py:260:stop] epoch=6/micro_step=602/global_step=3110, RunningAvgSamplesPerSec=3.288144787294551, CurrSamplesPerSec=3.289448636725691, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:53:57,274] [INFO] [logging.py:96:log_dist] [Rank 0] step=3120, skipped=0, lr=[9.996998433561746e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:53:57,275] [INFO] [timer.py:260:stop] epoch=6/micro_step=642/global_step=3120, RunningAvgSamplesPerSec=3.288156431842258, CurrSamplesPerSec=3.2939439488965223, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.296562923266036
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 72.06861114501953, loss: 4.2776079177856445
[2024-05-07 20:55:03,270] [INFO] [logging.py:96:log_dist] [Rank 0] step=3130, skipped=0, lr=[9.996976324878615e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:55:03,271] [INFO] [timer.py:260:stop] epoch=6/micro_step=682/global_step=3130, RunningAvgSamplesPerSec=3.288155630943542, CurrSamplesPerSec=3.2880896429449513, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:55:27,672] [INFO] [logging.py:96:log_dist] [Rank 0] step=3140, skipped=0, lr=[9.99695413509548e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:55:27,672] [INFO] [timer.py:260:stop] epoch=6/micro_step=722/global_step=3140, RunningAvgSamplesPerSec=3.2881564659737355, CurrSamplesPerSec=3.2924562080212088, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:55:52,054] [INFO] [logging.py:96:log_dist] [Rank 0] step=3150, skipped=0, lr=[9.996931864212695e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:55:52,055] [INFO] [timer.py:260:stop] epoch=6/micro_step=762/global_step=3150, RunningAvgSamplesPerSec=3.288164818803264, CurrSamplesPerSec=3.288721293524839, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.293261946565308
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 71.92796325683594, loss: 4.2756547927856445
[2024-05-07 20:56:58,042] [INFO] [logging.py:96:log_dist] [Rank 0] step=3160, skipped=0, lr=[9.996909512230627e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:56:58,043] [INFO] [timer.py:260:stop] epoch=6/micro_step=802/global_step=3160, RunningAvgSamplesPerSec=3.2881716470293805, CurrSamplesPerSec=3.293084366510448, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:57:22,425] [INFO] [logging.py:96:log_dist] [Rank 0] step=3170, skipped=0, lr=[9.996887079149635e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:57:22,426] [INFO] [timer.py:260:stop] epoch=6/micro_step=842/global_step=3170, RunningAvgSamplesPerSec=3.288180110235033, CurrSamplesPerSec=3.2905609072001005, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.292405450302931
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 71.87562561035156, loss: 4.274927139282227
[2024-05-07 20:58:28,424] [INFO] [logging.py:96:log_dist] [Rank 0] step=3180, skipped=0, lr=[9.996864564970085e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:58:28,424] [INFO] [timer.py:260:stop] epoch=6/micro_step=882/global_step=3180, RunningAvgSamplesPerSec=3.2881793022714336, CurrSamplesPerSec=3.2882965140134957, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:58:52,813] [INFO] [logging.py:96:log_dist] [Rank 0] step=3190, skipped=0, lr=[9.996841969692342e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:58:52,814] [INFO] [timer.py:260:stop] epoch=6/micro_step=922/global_step=3190, RunningAvgSamplesPerSec=3.288182584418147, CurrSamplesPerSec=3.2866419520329235, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 20:59:17,196] [INFO] [logging.py:96:log_dist] [Rank 0] step=3200, skipped=0, lr=[9.996819293316774e-06], mom=[(0.9, 0.95)]
[2024-05-07 20:59:17,197] [INFO] [timer.py:260:stop] epoch=6/micro_step=962/global_step=3200, RunningAvgSamplesPerSec=3.288189241933191, CurrSamplesPerSec=3.2898501673631144, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.289481291460917
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 71.77301025390625, loss: 4.273497581481934
[2024-05-07 21:00:23,119] [INFO] [logging.py:96:log_dist] [Rank 0] step=3210, skipped=0, lr=[9.996796535843745e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:00:23,120] [INFO] [timer.py:260:stop] epoch=6/micro_step=1002/global_step=3210, RunningAvgSamplesPerSec=3.28819599126061, CurrSamplesPerSec=3.292322141439886, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 21:00:47,521] [INFO] [logging.py:96:log_dist] [Rank 0] step=3220, skipped=0, lr=[9.996773697273626e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:00:47,522] [INFO] [timer.py:260:stop] epoch=6/micro_step=1042/global_step=3220, RunningAvgSamplesPerSec=3.2882062354021047, CurrSamplesPerSec=3.286395375873816, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.289554348161446
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 71.73014831542969, loss: 4.272899627685547
[2024-05-07 21:01:53,443] [INFO] [logging.py:96:log_dist] [Rank 0] step=3230, skipped=0, lr=[9.99675077760679e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:01:53,444] [INFO] [timer.py:260:stop] epoch=6/micro_step=1082/global_step=3230, RunningAvgSamplesPerSec=3.2882199415439692, CurrSamplesPerSec=3.2940855854343485, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 21:02:17,847] [INFO] [logging.py:96:log_dist] [Rank 0] step=3240, skipped=0, lr=[9.996727776843609e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:02:17,847] [INFO] [timer.py:260:stop] epoch=6/micro_step=1122/global_step=3240, RunningAvgSamplesPerSec=3.2882273766597225, CurrSamplesPerSec=3.2926713834782326, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 21:02:42,232] [INFO] [logging.py:96:log_dist] [Rank 0] step=3250, skipped=0, lr=[9.996704694984453e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:02:42,233] [INFO] [timer.py:260:stop] epoch=6/micro_step=1162/global_step=3250, RunningAvgSamplesPerSec=3.288241334202621, CurrSamplesPerSec=3.293200395249624, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.288275867165206
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 71.63125610351562, loss: 4.271520137786865
[2024-05-07 21:03:48,184] [INFO] [logging.py:96:log_dist] [Rank 0] step=3260, skipped=0, lr=[9.996681532029699e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:03:48,185] [INFO] [timer.py:260:stop] epoch=6/micro_step=1202/global_step=3260, RunningAvgSamplesPerSec=3.288253454625901, CurrSamplesPerSec=3.2909171992001234, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 21:04:12,589] [INFO] [logging.py:96:log_dist] [Rank 0] step=3270, skipped=0, lr=[9.996658287979722e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:04:12,590] [INFO] [timer.py:260:stop] epoch=6/micro_step=1242/global_step=3270, RunningAvgSamplesPerSec=3.288264829358353, CurrSamplesPerSec=3.292611932792487, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.288748467597931
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 71.49665069580078, loss: 4.269639015197754
[2024-05-07 21:05:18,514] [INFO] [logging.py:96:log_dist] [Rank 0] step=3280, skipped=0, lr=[9.996634962834899e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:05:18,515] [INFO] [timer.py:260:stop] epoch=6/micro_step=1282/global_step=3280, RunningAvgSamplesPerSec=3.2882736239500376, CurrSamplesPerSec=3.2882623559370288, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 21:05:42,930] [INFO] [logging.py:96:log_dist] [Rank 0] step=3290, skipped=0, lr=[9.99661155659561e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:05:42,930] [INFO] [timer.py:260:stop] epoch=6/micro_step=1322/global_step=3290, RunningAvgSamplesPerSec=3.2882809712401824, CurrSamplesPerSec=3.2906009216584438, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 21:06:07,331] [INFO] [logging.py:96:log_dist] [Rank 0] step=3300, skipped=0, lr=[9.996588069262234e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:06:07,332] [INFO] [timer.py:260:stop] epoch=6/micro_step=1362/global_step=3300, RunningAvgSamplesPerSec=3.2882934610505936, CurrSamplesPerSec=3.2870650161216344, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.286810077830245
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 71.45053100585938, loss: 4.26899528503418
[2024-05-07 21:07:13,273] [INFO] [logging.py:96:log_dist] [Rank 0] step=3310, skipped=0, lr=[9.996564500835154e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:07:13,274] [INFO] [timer.py:260:stop] epoch=6/micro_step=1402/global_step=3310, RunningAvgSamplesPerSec=3.2882998767882845, CurrSamplesPerSec=3.2927269588867794, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 21:07:37,667] [INFO] [logging.py:96:log_dist] [Rank 0] step=3320, skipped=0, lr=[9.996540851314747e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:07:37,668] [INFO] [timer.py:260:stop] epoch=6/micro_step=1442/global_step=3320, RunningAvgSamplesPerSec=3.288309624117305, CurrSamplesPerSec=3.2905347692487528, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.288080643438985
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 71.45560455322266, loss: 4.26906681060791
[2024-05-07 21:08:43,625] [INFO] [logging.py:96:log_dist] [Rank 0] step=3330, skipped=0, lr=[9.996517120701404e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:08:43,626] [INFO] [timer.py:260:stop] epoch=6/micro_step=1482/global_step=3330, RunningAvgSamplesPerSec=3.2883160843873322, CurrSamplesPerSec=3.2891548880482313, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 21:09:08,038] [INFO] [logging.py:96:log_dist] [Rank 0] step=3340, skipped=0, lr=[9.996493308995504e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:09:08,039] [INFO] [timer.py:260:stop] epoch=6/micro_step=1522/global_step=3340, RunningAvgSamplesPerSec=3.288323156952366, CurrSamplesPerSec=3.291999134284247, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 21:09:32,430] [INFO] [logging.py:96:log_dist] [Rank 0] step=3350, skipped=0, lr=[9.996469416197437e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:09:32,431] [INFO] [timer.py:260:stop] epoch=6/micro_step=1562/global_step=3350, RunningAvgSamplesPerSec=3.288335589040509, CurrSamplesPerSec=3.2926003013876843, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.286824012881559
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 71.34745025634766, loss: 4.267551422119141
[2024-05-07 21:10:38,387] [INFO] [logging.py:96:log_dist] [Rank 0] step=3360, skipped=0, lr=[9.99644544230759e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:10:38,388] [INFO] [timer.py:260:stop] epoch=6/micro_step=1602/global_step=3360, RunningAvgSamplesPerSec=3.2883471121627426, CurrSamplesPerSec=3.2952508302346026, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 21:11:02,786] [INFO] [logging.py:96:log_dist] [Rank 0] step=3370, skipped=0, lr=[9.996421387326354e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:11:02,787] [INFO] [timer.py:260:stop] epoch=6/micro_step=1642/global_step=3370, RunningAvgSamplesPerSec=3.288356851432085, CurrSamplesPerSec=3.292517591545657, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.285928175647935
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 71.26994323730469, loss: 4.26646614074707
[2024-05-07 21:12:08,713] [INFO] [logging.py:96:log_dist] [Rank 0] step=3380, skipped=0, lr=[9.996397251254116e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:12:08,714] [INFO] [timer.py:260:stop] epoch=6/micro_step=1682/global_step=3380, RunningAvgSamplesPerSec=3.2883689023701703, CurrSamplesPerSec=3.289581824377768, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 21:12:33,095] [INFO] [logging.py:96:log_dist] [Rank 0] step=3390, skipped=0, lr=[9.99637303409127e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:12:33,096] [INFO] [timer.py:260:stop] epoch=6/micro_step=1722/global_step=3390, RunningAvgSamplesPerSec=3.288385471318088, CurrSamplesPerSec=3.2917272114051572, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 21:12:57,485] [INFO] [logging.py:96:log_dist] [Rank 0] step=3400, skipped=0, lr=[9.996348735838207e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:12:57,485] [INFO] [timer.py:260:stop] epoch=6/micro_step=1762/global_step=3400, RunningAvgSamplesPerSec=3.2883978288033444, CurrSamplesPerSec=3.2920947377984398, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.28444930117571
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 71.16694641113281, loss: 4.26501989364624
[2024-05-07 21:14:03,423] [INFO] [logging.py:96:log_dist] [Rank 0] step=3410, skipped=0, lr=[9.996324356495322e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:14:03,424] [INFO] [timer.py:260:stop] epoch=6/micro_step=1802/global_step=3410, RunningAvgSamplesPerSec=3.288406994504644, CurrSamplesPerSec=3.290919781307789, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 21:14:27,806] [INFO] [logging.py:96:log_dist] [Rank 0] step=3420, skipped=0, lr=[9.996299896063012e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:14:27,807] [INFO] [timer.py:260:stop] epoch=6/micro_step=1842/global_step=3420, RunningAvgSamplesPerSec=3.288422000700964, CurrSamplesPerSec=3.29465031243495, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
Epoch 7/500 with loss 4.283157610778441
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
ppl: 71.27384948730469, loss: 4.266519546508789
[2024-05-07 21:15:33,749] [INFO] [logging.py:96:log_dist] [Rank 0] step=3430, skipped=0, lr=[9.996275354541674e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:15:33,750] [INFO] [timer.py:260:stop] epoch=6/micro_step=1882/global_step=3430, RunningAvgSamplesPerSec=3.2884360281444462, CurrSamplesPerSec=3.288671977374573, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 21:15:58,151] [INFO] [logging.py:96:log_dist] [Rank 0] step=3440, skipped=0, lr=[9.996250731931704e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:15:58,152] [INFO] [timer.py:260:stop] epoch=6/micro_step=1922/global_step=3440, RunningAvgSamplesPerSec=3.288443055328719, CurrSamplesPerSec=3.293755442445079, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
[2024-05-07 21:16:22,546] [INFO] [logging.py:96:log_dist] [Rank 0] step=3450, skipped=0, lr=[9.996226028233504e-06], mom=[(0.9, 0.95)]
[2024-05-07 21:16:22,546] [INFO] [timer.py:260:stop] epoch=6/micro_step=1962/global_step=3450, RunningAvgSamplesPerSec=3.2884527729341446, CurrSamplesPerSec=3.293522991643311, MemAllocated=6.65GB, MaxMemAllocated=18.41GB
4
Epoch 7/500 with loss 4.283541916226784
evaluating model ...
***** Evaluating perplexity, Epoch 7/500 *****
[rank1]:[E ProcessGroupNCCL.cpp:563] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=20946, OpType=ALLREDUCE, NumelIn=1843200, NumelOut=1843200, Timeout(ms)=600000) ran for 600046 milliseconds before timing out.
[rank1]:[E ProcessGroupNCCL.cpp:1537] [PG 1 Rank 1] Timeout at NCCL work: 20946, last enqueued NCCL work: 20947, last completed NCCL work: 20945.
[rank1]:[E ProcessGroupNCCL.cpp:577] [Rank 1] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank1]:[E ProcessGroupNCCL.cpp:583] [Rank 1] To avoid data inconsistency, we are taking the entire process down.
[rank1]:[E ProcessGroupNCCL.cpp:1414] [PG 1 Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=20946, OpType=ALLREDUCE, NumelIn=1843200, NumelOut=1843200, Timeout(ms)=600000) ran for 600046 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:565 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f783c57a897 in /home/chanho/anaconda3/envs/COMEDY/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x7f77efdaa1b2 in /home/chanho/anaconda3/envs/COMEDY/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1a0 (0x7f77efdaefd0 in /home/chanho/anaconda3/envs/COMEDY/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x7f77efdb031c in /home/chanho/anaconda3/envs/COMEDY/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdbbf4 (0x7f783badbbf4 in /home/chanho/anaconda3/envs/COMEDY/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f783d694ac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f783d726a40 in /lib/x86_64-linux-gnu/libc.so.6)

[2024-05-07 21:26:27,566] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 1603239
[2024-05-07 21:26:27,841] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 1603240
[2024-05-07 21:26:27,841] [ERROR] [launch.py:325:sigkill_handler] ['/home/chanho/anaconda3/envs/COMEDY/bin/python', '-u', 'training/SFT/main.py', '--local_rank=1', '--model_name_or_path', '/home/chanho/Model/COMEDY/EPISODE/result/model_path', '--train_data_path', '/home/chanho/Model/COMEDY/EPISODE/result/dataset/train_data.json', '--valid_data_path', '/home/chanho/Model/COMEDY/EPISODE/result/dataset/test_data.json', '--per_device_train_batch_size', '1', '--per_device_eval_batch_size', '1', '--data_output_path', '/home/chanho/Model/COMEDY/EPISODE/result/output_path/data', '--max_seq_len', '2048', '--learning_rate', '1e-5', '--weight_decay', '0.1', '--num_train_epochs', '500', '--num_train_samples', '3945', '/home/chanho/Model/COMEDY/EPISODE/result/dataset/train_data.json', '--gradient_accumulation_steps', '4', '--lr_scheduler_type', 'cosine', '--num_warmup_steps', '400', '--seed', '42', '--zero_stage', '2', '--save_interval', '2000', '--log_interval', '100', '--eval_interval', '100', '--output_dir', '/home/chanho/Model/COMEDY/EPISODE/result/output_path/2024-05-07-16.19.53', '--gradient_checkpointing', '--tensorboard_path', '/home/chanho/Model/COMEDY/EPISODE/result/log_path/2024-05-07-16.19.53'] exits with return code = -6
